Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"Zhenxiang Li, T. Zheng, Wang Yang, Hongyong Fu, Wenbo Wu","A Robust Fault Diagnosis Method for Rolling Bearings Based on Deep Convolutional Neural Network",2019,"","","","",1,"2022-07-13 10:09:04","","10.1109/phm-qingdao46334.2019.8943018","","",,,,,0,0.00,0,5,3,"Fault diagnosis of rolling bearings has been an important and challenging research issue. The existing conventional algorithms for diagnosing rolling bearings rely on artificial feature extraction requiring a wealth of knowledge of signal handling, expertise and human efforts, lacking adaptability. With the capacity for learning features from original signals automatically, deep learning methods can solve the shortcomings of conventional diagnosis methods. This paper puts forward a deep learning method for rolling bearing fault diagnosis based on two-dimensional convolutional neural network, called 2dCNN-FD. The method has the capability of automatic feature extraction and robust noise tolerance. Experimental results demonstrate that comparing with other traditional diagnosis algorithms, the 2dCNN-FD model achieves high diagnosis accuracy and better robustness under different noise conditions.","",""
1,"Guanzhong Tian, Jun Chen, Xianfang Zeng, Yong Liu","Pruning by Training: A Novel Deep Neural Network Compression Framework for Image Processing",2021,"","","","",2,"2022-07-13 10:09:04","","10.1109/LSP.2021.3054315","","",,,,,1,1.00,0,4,1,"Filter pruning for a pre-trained convolutional neural network is most normally performed through human-made constraints or criteria such as norms, ranks, etc. Typically, the pruning pipeline comprises two-stage: first learn a sparse structure from the original model, then optimize the weights in the new prune model. One disadvantage of using human-made criteria to prune filters is that the design and selection of threshold criteria depend on complicated prior knowledge. Besides, the pruning process is less robust due to the impact of directly regularizing on filters. To address the problems mentioned, we propose an effective one-stage pruning framework: introducing a trainable collaborative layer to jointly prune and learn neural networks in one go. In our framework, we first add a binary collaborative layer for each original filter. Then, a new type of gradient estimator - asymptotic gradient estimator is first introduced to pass the gradient in the binary collaborative layer. Finally, we simultaneously learn the sparse structure and optimize the weights from the original model in the training process. Our evaluation results on typical benchmarks, CIFAR and ImageNet, demonstrate very promising results against other state-of-the-art filter pruning methods.","",""
1,"Gang Xiang, Ruishi Lin","Robust Anomaly Detection for Multivariate Data of Spacecraft Through Recurrent Neural Networks and Extreme Value Theory",2021,"","","","",3,"2022-07-13 10:09:04","","10.1109/access.2021.3136505","","",,,,,1,1.00,1,2,1,"Spacecraft anomaly detection which could find anomalies in the telemetry or test data in advance and avoid the occurrence of catastrophic failures after taking corresponding measures has elicited the attention of researchers both in academia and aerospace industry. Current spacecraft anomaly detection systems require costly knowledge and human expertise to identify a true anomaly. Moreover, some new problems and challenges such as large volume of test data, imbalanced data distribution and the scarcity of faulty labeled samples have emerged. In this work, we propose an unsupervised anomaly detection algorithm combining Gated Recurrent Unit (GRU) based Recurrent Neural Network (RNN) and Extreme Value Theory (EVT). First, we develop a two-layer ensemble learning based predictor framework which stacks three GRU-based networks with different architectures to learn and capture the normal behavior of multiple channels of data. Then, the prediction errors are calculated and smoothed using Exponentially Weighted Moving Average (EWMA) algorithm. Next, we propose a detection rule setting anomaly threshold automatically through EVT which does not assume any parent distribution on the prediction errors. To the best of our knowledge, it is the first attempt that stacked GRU-based predictors with EVT has been employed into the spacecraft anomaly detection. Through extensive experiments conducted on public datasets as well as real data sampled from a launch vehicle, we show that the proposed detection algorithm is superior to other state-of-the-art anomaly detection approaches in terms of model performance and robustness.","",""
2,"K. B. Low, U. U. Sheikh","Human Re-identification with Global and Local Siamese Convolution Neural Network",2017,"","","","",4,"2022-07-13 10:09:04","","10.12928/TELKOMNIKA.V15I2.6121","","",,,,,2,0.40,1,2,5,"Human re-identification is an important task in surveillance system to determine whether the same human re-appears in multiple cameras with disjoint views. Mostly, appearance based approaches are used to perform human re-identification task because they are less constrained than biometric based approaches. Most of the research works apply hand-crafted feature extractors and then simple matching methods are used. However, designing a robust and stable feature requires expert knowledge and takes time to tune the features. In this paper, we propose a global and local structure of Siamese Convolution Neural Network which automatically extracts features from input images to perform human re-identification task. Besides, most of the current human re-identification task in single-shot approaches do not consider occlusion issue due to lack of tracking information. Therefore, we apply a decision fusion technique to combine global and local features for occlusion cases in single-shot approaches.","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",5,"2022-07-13 10:09:04","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
3,"A. Giannakidis, K. Kamnitsas, V. Spadotto, J. Keegan, Gillian Smith, B. Glocker, D. Rueckert, S. Ernst, M. Gatzoulis, D. Pennell, S. Babu-Narayan, D. Firmin","Fast Fully Automatic Segmentation of the Severely Abnormal Human Right Ventricle from Cardiovascular Magnetic Resonance Images Using a Multi-Scale 3D Convolutional Neural Network",2016,"","","","",6,"2022-07-13 10:09:04","","10.1109/SITIS.2016.16","","",,,,,3,0.50,0,12,6,"Cardiac magnetic resonance (CMR) is regarded as the reference examination for cardiac morphology in tetralogy of Fallot (ToF) patients allowing images of high spatial resolution and high contrast. The detailed knowledge of the right ventricular anatomy is critical in ToF management. The segmentation of the right ventricle (RV) in CMR images from ToF patients is a challenging task due to the high shape and image quality variability. In this paper we propose a fully automatic deep learning-based framework to segment the RV from CMR anatomical images of the whole heart. We adopt a 3D multi-scale deep convolutional neural network to identify pixels that belong to the RV. Our robust segmentation framework was tested on 26 ToF patients achieving a Dice similarity coefficient of 0.8281±0.1010 with reference to manual annotations performed by expert cardiologists. The proposed technique is also computationally efficient, which may further facilitate its adoption in the clinical routine.","",""
16,"Yifang Chen, Xiangui Kang, Z. J. Wang, Qiong Zhang","Densely Connected Convolutional Neural Network for Multi-purpose Image Forensics under Anti-forensic Attacks",2018,"","","","",7,"2022-07-13 10:09:04","","10.1145/3206004.3206013","","",,,,,16,4.00,4,4,4,"Multiple-purpose forensics has been attracting increasing attention worldwide. However, most of the existing methods based on hand-crafted features often require domain knowledge and expensive human labour and their performances can be affected by factors such as image size and JPEG compression. Furthermore, many anti-forensic techniques have been applied in practice, making image authentication more difficult. Therefore, it is of great importance to develop methods that can automatically learn general and robust features for image operation detectors with the capability of countering anti-forensics. In this paper, we propose a new convolutional neural network (CNN) approach for multi-purpose detection of image manipulations under anti-forensic attacks. The dense connectivity pattern, which has better parameter efficiency than the traditional pattern, is explored to strengthen the propagation of general features related to image manipulation detection. When compared with three state-of-the-art methods, experiments demonstrate that the proposed CNN architecture can achieve a better performance (i.e., with a 11% improvement in terms of detection accuracy under anti-forensic attacks). The proposed method can also achieve better robustness against JPEG compression with maximum improvement of 13% on accuracy under low-quality JPEG compression.","",""
66,"Z. Zheng, Pengyu Hong","Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks",2018,"","","","",8,"2022-07-13 10:09:04","","","","",,,,,66,16.50,33,2,4,"It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategy to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks.","",""
0,"Hai Jiang, Jing Liu, H. Cheng","Short-Term TLE Uncertainty Estimation Using an Artificial Neural Network Model",2018,"","","","",9,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,3,4,"A growing number of space activities have created an orbital debris environment that poses increasing impact risks to existing space systems and human space flight. Accurate knowledge of orbit propagation errors of space debris is essential for many types of analyses, such as space surveillance network tasking, conjunction analysis etc. Unfortunately, for two-line elements (TLEs) this is not available. In this paper, a new short-term TLE uncertainty estimation method based on an artificial neural network model is proposed. Object properties, orbit type, space environment and prediction time-span are considered as the input of the network, the propagation errors in the direction of downrange, normal and conormald are as the output of the network. In order to assure the chosen orbit for training is not for an object using station keeping, only debris and R/B are used. The network’s efficiency is demonstrated with some objects with high ephemeris data. Overall, the method proves accurate, computationally fast, and robust, and is applicable to any object in the satellite catalogue, especially for those newly launched objects.","",""
10,"Chunling Cheng, Xianwei Wei, Zhou Jian","Emotion recognition algorithm based on convolution neural network",2017,"","","","",10,"2022-07-13 10:09:04","","10.1109/ISKE.2017.8258786","","",,,,,10,2.00,3,3,5,"Emotional recognition is a very challenging nature of the topic in the field of Brain — Computer Interface (BCI). This technology has been applied in many fields, such as The electroencephalogram (EEG) signals. The EEG signals can intuitively express the human emotional state and has attracted attentions of many researchers. Besides, it has a strong correlation during a period. To preserve the correlation, this paper presents an emotion recognition algorithm based on convolution neural network (ERACNN). In this paper, the EEG signals are pretreated, and then the parameters of CNN are selected. Finally, the classification model of emotion recognition is trained. Experimental results show that the results based on ERACNN is more robust than these based on Support Vector Machine (SVM). Besides, ERACNN can improve the classification accuracy of emotion recognition compared with the similar CNN algorithm.","",""
9,"Alexander Hanbo Li, A. Sethy","Knowledge Enhanced Attention for Robust Natural Language Inference",2019,"","","","",11,"2022-07-13 10:09:04","","","","",,,,,9,3.00,5,2,3,"Neural network models have been very successful at achieving high accuracy on natural language inference (NLI) tasks. However, as demonstrated in recent literature, when tested on some simple adversarial examples, most of the models suffer a significant drop in performance. This raises the concern about the robustness of NLI models. In this paper, we propose to make NLI models robust by incorporating external knowledge to the attention mechanism using a simple transformation. We apply the new attention to two popular types of NLI models: one is Transformer encoder, and the other is a decomposable model, and show that our method can significantly improve their robustness. Moreover, when combined with BERT pretraining, our method achieves the human-level performance on the adversarial SNLI data set.","",""
0,"Rassa Ghavami Modegh, Ahmadali Salimi, H. Rabiee","LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks",2022,"","","","",12,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,3,1,"Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. The complex computation behind their reasoning is not sufficiently human-understandable to develop trust. External explainer methods have tried to interpret the network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection while improving the model’s performance. Moreover, several weakly-supervised knowledge injection methodologies are provided to enhance the process of training. We verified our claims by evaluating several LAP-extended models on three different datasets, including Imagenet. The proposed framework offers more valid humanunderstandable and more faithful-to-the-model interpretations than the commonly used white-box explainer methods.","",""
0,"G. I. Parisi","Multimodal Learning of Actions with Deep Neural Network Self-Organization",2017,"","","","",13,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,5,"Perceiving the actions of other people is one of the most important social skills of human beings. We are able to reliably discern a variety of socially relevant information from people’s body motion such as intentions, identity, gender, and affective states. This ability is supported by highly developed visual skills and the integration of additional modalities that in concert contribute to providing a robust perceptual experience. Multimodal integration is a fundamental feature of the brain that together with widely studied biological mechanisms for action perception has served as inspiration for the development of artificial systems. However, computational mechanisms for processing and integrating knowledge reliably from multiple perceptual modalities are still to be fully investigated.  The goal of this thesis is to study and develop artificial learning architectures for action perception. In light of a wide understanding of the brain areas and underlying neural mechanisms for processing biological motion patterns, we propose a series of neural network models for learning multimodal action representations. Consistent with neurophysiological studies evidencing a hierarchy of cortical layers driven by the distribution of the input, we demonstrate how computational models of input-driven self-organization can account for the learning of action features with increasing complexity of representation. For this purpose, we introduce a novel model of recurrent self-organization for learning action features with increasingly large spatiotemporal receptive fields. Visual representations obtained through unsupervised learning are incrementally associated to symbolic action labels for the purpose of action classification.  From a multimodal perspective, we propose a model in which multimodal action representations can develop from neural network organization in terms of associative connectivity patterns between unimodal representations. We report a set of experiments showing that deep self-organizing hierarchies allow to learn statistically significant features of actions, with multimodal representations emerging from co-occurring audiovisual stimuli. We evaluated our neural network architectures on the tasks of human action recognition, body motion assessment, and the detection of abnormal behavior. Finally, we conducted two robot experiments that provide quantitative evidence for the advantages of multimodal integration for triggering sensory-driven motor behavior. The first scenario consists of an assistive task for the detection of falls, whereas in the second experiment we propose audiovisual integration in an interactive reinforcement learning scenario. Together, our results demonstrate that deep neural self-organization can account for robust action perception, yielding state-of-the-art performance also in the presence of sensory uncertainty and conflict.  The research presented in this thesis comprises interdisciplinary aspects of action perception and multimodal integration for the development of efficient neurocognitive architectures. While the brain mechanisms for multimodal perception are still to be fully understood, the proposed neural network architectures may be seen as a basis for modeling higher-level cognitive functions.","",""
12454,"Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun","Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",2015,"","","","",14,"2022-07-13 10:09:04","","10.1109/ICCV.2015.123","","",,,,,12454,1779.14,3114,4,7,"Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.","",""
17,"Wanxiang Shen, X. Zeng, F. Zhu, Y. Wang, C. Qin, Ying Tan, Yu Yang Jiang, Y. Chen","Out-of-the-box deep learning prediction of pharmaceutical properties by broadly learned knowledge-based molecular representations",2021,"","","","",15,"2022-07-13 10:09:04","","10.1038/S42256-021-00301-6","","",,,,,17,17.00,2,8,1,"","",""
9,"Chenyu Liu, Mingdai Yang, Xiaowei Sun","Towards Robust Human Millimeter Wave Imaging Inspection System in Real Time with Deep Learning",2018,"","","","",16,"2022-07-13 10:09:04","","10.2528/PIER18012601","","",,,,,9,2.25,3,3,4,"With the ever-growing requirements of human security check in public, near-field millimeter wave (MMW) imaging techniques have been developing rapidly in recent years. Due to the lack of MMW images, low resolution and indistinguishable texture in most MMW images, it is still a great challenge to do high performance object detection task on MMW images. In this paper, we propose a novel framework to automatically detect concealed weapons and potential dangerous objects based on a single human millimeter wave image, in which a deep convolutional neural network (CNN) is presented to simultaneously extract features, detect suspicious objects, and give the confidence score. Unlike traditional optical image level solutions, we comprehensively analyze the original MMW data for object representation, incorporate domain-specific knowledge to design and train our network. Moreover, combined with the modern focal loss theory, we devise an effective loss function elaborately to optimize our model. Experimental results on both our dataset and real world data show the effectiveness and improvement of our method compared with the state-of-the-arts.","",""
0,"H. Mehraj, A. H. Mir","Robust Multimodal Biometric System Based on Feature Level Fusion of Optimiseddeepnet Features",2021,"","","","",17,"2022-07-13 10:09:04","","10.1007/s11277-021-09075-x","","",,,,,0,0.00,0,2,1,"","",""
0,"Christian David M'arton, L'eo Gagnon, Guillaume Lajoie, Kanaka Rajan","Efficient and robust multi-task learning in the brain with modular latent primitives",2021,"","","","",18,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,4,1,"Biological agents do not have inﬁnite resources to learn new things. For this reason, a central aspect of human learning is the ability to recycle previously acquired knowledge in a way that allows for faster, less resource-intensive acquisition of new skills. In spite of that, how neural networks in the brain leverage existing knowledge to learn new computations is not well understood. In this work, we study this question in artiﬁcial recurrent neural networks (RNNs) trained on a corpus of commonly used neuroscience tasks. Combining brain-inspired inductive biases we call functional and structural, we propose a system that learns new tasks by building on top of pre-trained latent dynamics organised into separate recurrent modules. These modules, acting as prior knowledge acquired previously through evolution or development, are pre-trained on the statistics of the full corpus of tasks so as to be independent and maximally informative. The resulting model, we call a Modular Latent Primitives (MoLaP) network, allows for learning multiple tasks while keeping parameter counts, and updates, low. We also show that the skills acquired with our approach are more robust to a broad range of perturbations compared to those acquired with other multi-task learning strategies, and that generalisation to new tasks is facilitated. This work offers a new perspective on achieving efﬁcient multi-task learning in the brain, illustrating the beneﬁts of leveraging pre-trained latent dynamical primitives. models of biologically plausible multi-task learning. Finally, we show that generalization to new tasks that share basic structure with the corpus is also facilitated. This draws a path towards cheaper multitask solutions, and offers new hypotheses for how continual learning might be implemented in the biological brain. which are used to pre-train separate network modules. B. During task training, recurrent weights remain frozen and only input and readout weights are adjusted. Task-speciﬁc responses can be obtained via separate readout weights. C. Parameter overview for the various multi-task training methods. Parameters trained (or updated) and total network size is compared across the three methods. MoLaP makes ∼ 2 orders of magnitude fewer parameter updates than DNI, at a relatively moderate increase of total parameter count.","",""
14,"Jianfeng Gao, Baolin Peng, Chengkun Li, Jinchao Li, Shahin Shayandeh, Lars Lidén, H. Shum","Robust Conversational AI with Grounded Text Generation",2020,"","","","",19,"2022-07-13 10:09:04","","","","",,,,,14,7.00,2,7,2,"This article presents a hybrid approach based on a Grounded Text Generation (GTG) model to building robust task bots at scale. GTG is a hybrid model which uses a large-scale Transformer neural network as its backbone, combined with symbol-manipulation modules for knowledge base inference and prior knowledge encoding, to generate responses grounded in dialog belief state and real-world knowledge for task completion. GTG is pre-trained on large amounts of raw text and human conversational data, and can be fine-tuned to complete a wide range of tasks.  The hybrid approach and its variants are being developed simultaneously by multiple research teams. The primary results reported on task-oriented dialog benchmarks are very promising, demonstrating the big potential of this approach. This article provides an overview of this progress and discusses related methods and technologies that can be incorporated for building robust conversational AI systems.","",""
13,"Shreya Ghosh, Abhinav Dhall, Garima Sharma, Sarthak Gupta, N. Sebe","Speak2Label: Using Domain Knowledge for Creating a Large Scale Driver Gaze Zone Estimation Dataset",2020,"","","","",20,"2022-07-13 10:09:04","","10.1109/ICCVW54120.2021.00324","","",,,,,13,6.50,3,5,2,"Labelling of human behavior analysis data is a complex and time consuming task. In this paper, a fully automatic technique for labelling an image based gaze behavior dataset for driver gaze zone estimation is proposed. Domain knowledge is added to the data recording paradigm and later labels are generated in an automatic manner using Speech To Text conversion (STT). In order to remove the noise in the STT process due to different illumination and ethnicity of subjects in our data, the speech frequency and energy are analysed. The resultant Driver Gaze in the Wild (DGW) dataset contains 586 recordings, captured during different times of the day including evenings. The large scale dataset contains 338 subjects with an age range of 18-63 years. As the data is recorded in different lighting conditions, an illumination robust layer is proposed in the Convolutional Neural Network (CNN). The extensive experiments show the variance in the dataset resembling real-world conditions and the effectiveness of the proposed CNN pipeline. The proposed network is also fine-tuned for the eye gaze prediction task, which shows the discriminativeness of the representation learnt by our network on the proposed DGW dataset. Project Page: https://sites.google.com/view/drivergazeprediction/home","",""
0,"Jumi Kalita, K. K. Sarma, P. Sarmah","Classification of Child Disability Using Artificial Neural Network",2014,"","","","",21,"2022-07-13 10:09:04","","10.1007/978-3-319-01285-8_6","","",,,,,0,0.00,0,3,8,"","",""
9,"K. Haribabu, G. Subrahmanyam, Deepak Mishra","A robust digital image watermarking technique using auto encoder based convolutional neural networks",2015,"","","","",22,"2022-07-13 10:09:04","","10.1109/WCI.2015.7495522","","",,,,,9,1.29,3,3,7,"Watermarking plays a very important role in providing authentication, ownership and transmission of secret information. The existing techniques of watermarking in literature are based on either spatial domain or transformation domain. Human brain consists of large number of neurons which are capable of doing paralleling tasking accurately. This resulted in the evaluation of neural network architectures, providing wide range of well connected features representing the input of the network. Convolutional Neural Networks(CNN) which were evolved in early 90s became popular and are being in use in wide range of tasks like classification, detection, recognition, patch matching. In this paper, we propose a digital image watermarking technique using auto-encoder based CNN which is robust to different noises and attacks like salt & pepper, Gaussian and JPEG effect. The proposed method, to the best of our knowledge, is the very first attempt of CNN in the domain of watermarking. We compare the performance of the proposed technique with the existing techniques which are based on spatial domain and transform domain. We show that the proposed method of watermarking using auto encoder based CNN (ACNNWM) gives better or on par results with the existing methods.","",""
14,"Haofeng Li, Guanbin Li, Yizhou Yu","ROSA: Robust Salient Object Detection Against Adversarial Attacks",2019,"","","","",23,"2022-07-13 10:09:04","","10.1109/TCYB.2019.2914099","","",,,,,14,4.67,5,3,3,"Recently, salient object detection has witnessed remarkable improvement owing to the deep convolutional neural networks which can harvest powerful features for images. In particular, the state-of-the-art salient object detection methods enjoy high accuracy and efficiency from fully convolutional network (FCN)-based frameworks which are trained from end to end and predict pixel-wise labels. However, such framework suffers from adversarial attacks which confuse neural networks via adding quasi-imperceptible noises to input images without changing the ground truth annotated by human subjects. To our knowledge, this paper is the first one that mounts successful adversarial attacks on salient object detection models and verifies that adversarial samples are effective on a wide range of existing methods. Furthermore, this paper proposes a novel end-to-end trainable framework to enhance the robustness for arbitrary FCN-based salient object detection models against adversarial attacks. The proposed framework adopts a novel idea that first introduces some new generic noise to destroy adversarial perturbations, and then learns to predict saliency maps for input images with the introduced noise. Specifically, our proposed method consists of a segment-wise shielding component, which preserves boundaries and destroys delicate adversarial noise patterns and a context-aware restoration component, which refines saliency maps through global contrast modeling. The experimental results suggest that our proposed framework improves the performance significantly for state-of-the-art models on a series of datasets.","",""
12,"Jiahang Wang, Sheng Jin, Wentao Liu, Weizhong Liu, C. Qian, Ping Luo","When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks",2021,"","","","",24,"2022-07-13 10:09:04","","10.1109/CVPR46437.2021.01168","","",,,,,12,12.00,2,6,1,"Human pose estimation is a fundamental yet challenging task in computer vision, which aims at localizing human anatomical keypoints. However, unlike human vision that is robust to various data corruptions such as blur and pixelation, current pose estimators are easily confused by these corruptions. This work comprehensively studies and addresses this problem by building rigorous robust benchmarks, termed COCO-C, MPII-C, and OCHuman-C, to evaluate the weaknesses of current advanced pose estimators, and a new algorithm termed AdvMix is proposed to improve their robustness in different corruptions. Our work has several unique benefits. (1) AdvMix is model-agnostic and capable in a wide-spectrum of pose estimation models. (2) AdvMix consists of adversarial augmentation and knowledge distillation. Adversarial augmentation contains two neural network modules that are trained jointly and competitively in an adversarial manner, where a generator network mixes different corrupted images to confuse a pose estimator, improving the robustness of the pose estimator by learning from harder samples. To compensate for the noise patterns by adversarial augmentation, knowledge distillation is applied to transfer clean pose structure knowledge to the target pose estimator. (3) Extensive experiments show that AdvMix significantly increases the robustness of pose estimations across a wide range of corruptions, while maintaining accuracy on clean data in various challenging benchmark datasets.","",""
16,"Huijuan Yang, J. Patra, C. W. Chan","An artificial neural network-based scheme for robust watermarking of audio signals",2002,"","","","",25,"2022-07-13 10:09:04","","10.1109/ICASSP.2002.5743970","","",,,,,16,0.80,5,3,20,"Digital watermarking is a technique by which the author information is embedded into the host signal (text, audio, image or video) that is imperceptible to the human senses. In this paper, we present a novel scheme for watermarking on audio signals using artificial neural networks (ANNs). The ANN is used to estimate the watermark scaling factor (WSP) intelligently from the knowledge of host audio signal. The power spectrum of the watermark signal remains below the minimum masking threshold (MMT) of the host signal when these WSFs are used in the watermarking process. This not only ensures inaudibility of the watermark signal, but also improves the capacity and robustness of the watermarking process. Using one music signal, we have shown the robustness of the scheme under some attacks to the watermarked audio signal.","",""
13,"R. del Amor, Sandra Morales, Adrián Colomer, M. Mogensen, Mikkel Jensen, N. Israelsen, O. Bang, V. Naranjo","Automatic Segmentation of Epidermis and Hair Follicles in Optical Coherence Tomography Images of Normal Skin by Convolutional Neural Networks",2020,"","","","",26,"2022-07-13 10:09:04","","10.3389/fmed.2020.00220","","",,,,,13,6.50,2,8,2,"Optical coherence tomography (OCT) is a well-established bedside imaging modality that allows analysis of skin structures in a non-invasive way. Automated OCT analysis of skin layers is of great relevance to study dermatological diseases. In this paper, an approach to detect the epidermal layer along with the follicular structures in healthy human OCT images is presented. To the best of the authors' knowledge, the approach presented in this paper is the only epidermis detection algorithm that segments the pilosebaceous unit, which is of importance in the progression of several skin disorders such as folliculitis, acne, lupus erythematosus, and basal cell carcinoma. The proposed approach is composed of two main stages. The first stage is a Convolutional Neural Network based on U-Net architecture. The second stage is a robust post-processing composed by a Savitzky-Golay filter and Fourier Domain Filtering to fully define the borders belonging to the hair follicles. After validation, an average Dice of 0.83 ± 0.06 and a thickness error of 10.25 μm is obtained on 270 human skin OCT images. Based on these results, the proposed method outperforms other state-of-the-art methods for epidermis segmentation. It demonstrates that the proposed image segmentation method successfully detects the epidermal region in a fully automatic way in addition to defining the follicular skin structures as main novelty.","",""
0,"Yaou Zhao, Yuehui Chen, M. Jiang","A novel ensemble of probabilistic neural network for predicting protein-protein interactions",2012,"","","","",27,"2022-07-13 10:09:04","","10.1109/BMEI.2012.6513055","","",,,,,0,0.00,0,3,10,"The knowledge of protein-protein interactions (PPIs) in cells is indispensable for deep understanding the biological process. Although many computational methods have been developed for identification of PPIs, there are still many difficulties due to high computation complexity and noisy data. In this paper, we proposed an ensemble of probabilistic neural network (PNN) to predict PPIs from primary sequence which achieved promising results. The key advantage of the algorithm is that it combines variety of physicochemical property features to construct diverse individual classifiers for ensemble prediction. What makes the method much more attractive is that it not only generated much more diverse and robust individual classifiers, but also contains different interaction physicochemical information which dictated the structure and the function of proteins. Moreover, the PNN is robust to noise and trained easily, it is suitable for dealing with the large scale noisy PPIs data. Experiment results on H. pylori and Human datasets show that our proposed method performs at least 8% higher accuracy than the best of other related works.","",""
11,"Gamal K. O. Crichton, Simon Baker, Yufan Guo, A. Korhonen","Neural networks for open and closed Literature-based Discovery",2020,"","","","",28,"2022-07-13 10:09:04","","10.1371/journal.pone.0232891","","",,,,,11,5.50,3,4,2,"Literature-based Discovery (LBD) aims to discover new knowledge automatically from large collections of literature. Scientific literature is growing at an exponential rate, making it difficult for researchers to stay current in their discipline and easy to miss knowledge necessary to advance their research. LBD can facilitate hypothesis testing and generation and thus accelerate scientific progress. Neural networks have demonstrated improved performance on LBD-related tasks but are yet to be applied to it. We propose four graph-based, neural network methods to perform open and closed LBD. We compared our methods with those used by the state-of-the-art LION LBD system on the same evaluations to replicate recently published findings in cancer biology. We also applied them to a time-sliced dataset of human-curated peer-reviewed biological interactions. These evaluations and the metrics they employ represent performance on real-world knowledge advances and are thus robust indicators of approach efficacy. In the first experiments, our best methods performed 2-4 times better than the baselines in closed discovery and 2-3 times better in open discovery. In the second, our best methods performed almost 2 times better than the baselines in open discovery. These results are strong indications that neural LBD is potentially a very effective approach for generating new scientific discoveries from existing literature. The code for our models and other information can be found at: https://github.com/cambridgeltl/nn_for_LBD.","",""
0,"Fabrizio Russo, F. Toni","Causal Discovery and Injection for Feed-Forward Neural Networks",2022,"","","","",29,"2022-07-13 10:09:04","","10.48550/arXiv.2205.09787","","",,,,,0,0.00,0,2,1,"Neural networks have proven to be eective at solving a wide range of problems but it is often unclear whether they learn any meaningful causal relationship: this poses a problem for the robustness of neural network models and their use for high-stakes decisions. We propose a novel method overcoming this issue by injecting knowledge in the form of (possibly partial) causal graphs into feed-forward neural networks, so that the learnt model is guaranteed to conform to the graph, hence adhering to expert knowledge. This knowledge may be given up-front or during the learning process, to improve the model through human-AI collaboration. We apply our method to synthetic and real (tabular) data showing that it is robust against noise and can improve causal discovery and prediction performance in low data regimes.","",""
23,"S. Jaiswal, G. Nandi","Robust real-time emotion detection system using CNN architecture",2019,"","","","",30,"2022-07-13 10:09:04","","10.1007/s00521-019-04564-4","","",,,,,23,7.67,12,2,3,"","",""
2,"Fukai Zhang, Cong Wang","Deterministic learning from neural control for uncertain nonlinear pure‐feedback systems by output feedback",2020,"","","","",31,"2022-07-13 10:09:04","","10.1002/rnc.4902","","",,,,,2,1.00,1,2,2,"The essence of intelligence lies in the acquisition/learning and utilization of knowledge. However, how to implement learning in dynamical environments for nonlinear systems is a challenging issue. This article investigates the deterministic learning (DL) control problem for uncertain pure‐feedback systems by output feedback, which achieves the human‐like learning and control in a simple way. To reduce the complexity of control design and analysis, first, by combining an appropriate system transformation, the original pure‐feedback system is transformed into a simple normal nonaffine system. An observer is then introduced to estimate the transformed system states. Based on the backstepping and dynamic surface control techniques, a simple adaptive neural control scheme is first developed to guarantee the finite time convergence of the tracking error using only one neural network (NN) approximator. Second, through DL, the exponential convergence of the NN weights is obtained with the satisfaction of partial persistent excitation condition. Thus, locally accurate approximation/learning of the transformed unknown system dynamics is achieved and stored as constant NNs. Finally, by utilizing the stored knowledge, an experience‐based controller is constructed and a novel learning control scheme is further proposed to improve the control performance without any further adaptation online for the estimate neural weights. Simulation results have been given to illustrate that the proposed scheme not only can learn and memorize knowledge like humans but also can utilize experience to achieve superior control performance.","",""
150,"H. Rahmani, A. Mian, M. Shah","Learning a Deep Model for Human Action Recognition from Novel Viewpoints",2016,"","","","",32,"2022-07-13 10:09:04","","10.1109/TPAMI.2017.2691768","","",,,,,150,25.00,50,3,6,"Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a set of non-linear transformations that connects the views. The R-NKTM is learned from 2D projections of dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.","",""
0,"A. Nawaz, A. S. Arora, W. Ali, Nikita T. Saxena, Mohd Shariq Khan, C. Yun, Moonyong Lee","Intelligent Human–Machine Interface: An Agile Operation and Decision Support for an ANAMMOX SBR System at a Pilot-Scale Wastewater Treatment Plant",2022,"","","","",33,"2022-07-13 10:09:04","","10.1109/tii.2022.3153468","","",,,,,0,0.00,0,7,1,"Eco-efficient anaerobic ammonium oxidation (ANAMMOX) can eliminate toxic nutrients from wastewater and has been used in several nutrient removal technologies. However, its implementation for robust operation remains challenging because of process nonlinearity and time-variant characteristic, higher energy consumption, excess sludge produced, and biomass loss during sludge pumping. Also, sensor failure, process startup, and shut down present additional difficulties. In this article, an intelligent human–machine interface using an advanced numerical solution for a knowledge-based system (called ANKSys) was developed by integrating the fully optimized-functionality (soft sensing, decision making, and simulating model) data driven by supervisory control. This control consists of advanced algorithms (artificial neural network, Kalman filter, principal component analysis, least-square technique/renowned root-mean-squared error) using commercial software (MATLAB R2018a, Microsoft Visual Studio IDE 2016, Microsoft SQL Server 2014, OPC Automation with XGT series programmable logic controller). The developed ANKSys can help in online monitoring and optimal process operation by assessing risk and failure occurrences, acquiring data for data analysis, and managing operating expenditure. In real-time implementation, ANKSys enhanced the energy efficiency, i.e., 16% of a pilot-scale “LEAOX” wastewater treatment plant located at Daegu, Republic of Korea. Using this strategy, an optimal and sustainable operation for the removal of biological nitrogen was achieved.","",""
8,"D. Parhi, M. K. Singh","Heuristic-rule-based hybrid neural network for navigation of a mobile robot",2010,"","","","",34,"2022-07-13 10:09:04","","10.1243/09544054JEM1736","","",,,,,8,0.67,4,2,12,"Abstract The current paper presents a novel technique for a mobile robot to navigate in a real-world dynamic environment. When an autonomous mobile robot navigates in an unknown environment it is required to plan a path based on the information gathered from sensors in order to avoid obstacles and reach a target. This research idea is related to the basis of human perception, by using heuristic information for the navigation of mobile robots in cluttered dynamic environments which provides a general, robust, safe, and optimized path. The heuristic-rule-based network (HRBN) consists of a simple algorithm which makes the predefined estimation function much smaller. The estimation function should be adequately defined for desired movement in the environment. A navigation system using the rule-based technique allows a mobile robot to travel in an environment about which the robot has no prior knowledge. This heuristic rule is applied in conjunction with an artificial neural network (ANN). The ANN is trained by back-propagation algorithms. The HRBN provides an optimum trajectory which increases the effectiveness of a mobile robot. In a multiple-robot environment, a Petri net model (PNM) is used to prevent inter-robot collision during navigation. A series of simulations and experiments is conducted using mobile robots to show the effectiveness of the proposed algorithm.","",""
2,"Jie Fang, Jianwu Lin","Prior knowledge distillation based on financial time series",2020,"","","","",35,"2022-07-13 10:09:04","","10.1109/INDIN45582.2020.9442199","","",,,,,2,1.00,1,2,2,"One of the major characteristics of financial time series is that they contain a large amount of nonstationary noise, which is challenging for deep neural networks. People normally use various features to address this problem. However, the performance of these features depends on the choice of hyper-parameters. In this paper, we propose to use neural networks to represent these indicators and train a large network constructed of smaller networks as feature layers to fine-tune the prior knowledge represented by the indicators. During back propagation, prior knowledge is transferred from human logic to machine logic via gradient descent. Prior knowledge is the neural network's deep belief and teaches the network to not be affected by non-stationary noise. Moreover, co-distillation is applied to distill the structure into a much smaller size to reduce redundant features and the risk of overfitting. In addition, the decisions of the smaller networks in terms of gradient descent are more robust and cautious than those of large networks. In numerical experiments, we find that our algorithm is faster and more accurate than traditional methods on real financial datasets. We also conduct experiments to verify the method.","",""
19,"Han Zou, Jianfei Yang, Yuxun Zhou, Lihua Xie, C. Spanos","Robust WiFi-Enabled Device-Free Gesture Recognition via Unsupervised Adversarial Domain Adaptation",2018,"","","","",36,"2022-07-13 10:09:04","","10.1109/ICCCN.2018.8487345","","",,,,,19,4.75,4,5,4,"Accurate human gesture recognition is becoming a cornerstone for myriad emerging applications in human-computer interaction. Existing gesture recognition systems either require dedicated extra infrastructure or user's active cooperation. Although some WiFi-enabled gesture recognition systems have been proposed, they are vulnerable to environmental dynamics and rely on the tedious data re-labeling and expert knowledge each time being implemented in a new environment. In this paper, we propose a WiFi- enabled device-free adaptive gesture recognition scheme, WiADG, that is able to identify human gestures accurately and consistently under environmental dynamics via adversarial domain adaptation. Firstly, a novel OpenWrt-based IoT platform is developed, enabling the direct collection of Channel State Information (CSI) measurements from commercial IoT devices. After constructing an accurate source classifier with labeled source CSI data via the proposed convolutional neural network in the source domain (original environment), we design an unsupervised domain adaptation scheme to reduce the domain discrepancy between the source and the target domain (new environment) and thus improve the generalization performance of the source classifier. The domain- adversarial objective is to train a generator (target encoder) to map the unlabeled target data to a domain invariant latent feature space so that a domain discriminator cannot distinguish the domain labels of the data. In the phase of implementation, we utilize the trained target encoder to map the target CSI frame to the latent feature space and use the source classifier to identify various gestures performed by the user. We implement WiADG on commercial WiFi routers and conduct experiments in multiple indoor environments. The results validate that WiADG achieves 98% gesture recognition accuracy in the original environment. Furthermore, the proposed unsupervised adversarial domain adaptation is able to enhance the recognition accuracy of WiADG by 25% on average without the needs of labeled data collection and new classifier generation when implements it in new environments.","",""
16,"Ramyar Saeedi, S. Norgaard, A. Gebremedhin","A closed-loop deep learning architecture for robust activity recognition using wearable sensors",2017,"","","","",37,"2022-07-13 10:09:04","","10.1109/BigData.2017.8257960","","",,,,,16,3.20,5,3,5,"Human activity recognition (HAR) plays a central role in health-care, fitness and sport applications because of its potential to enable context-aware human monitoring. With the increase in popularity of wearable devices, we are witnessing a large influx in availability of human activity data. For effective analysis and interpretation of these heterogeneous and high-volume streaming data, we need powerful algorithms. In particular, there is a strong need for developing algorithms for robust classification of human activity data that specifically address challenges associated with dynamic environments (e.g. different users, signal heterogeneity). We use the term robust here in two, orthogonal senses: 1) leveraging related data in such a way that knowledge is transferred to a new context; and 2) actively reconfiguring machine learning algorithms such that they can be applied in a new context. In this paper, we propose an architecture that combines an active learning approach with a novel deep network. Our deep neural network exploits both Convolutional and Long Short-Term Memory (LSTM) layers in order to learn hierarchical representation of features and capture time dependencies from raw-data. The active learning process allows us to choose the best instances for fine-tuning the deep network to the new setting in which the system operates (i.e. a new subject). We demonstrate the efficacy of the architecture using real data of human activity. We show that the accuracy of activity recognition reaches over 90% by annotating less than 20% of unlabeled data.","",""
5,"Artur Jordão, R. Kloss, W. R. Schwartz","Latent HyperNet: Exploring the Layers of Convolutional Neural Networks",2018,"","","","",38,"2022-07-13 10:09:04","","10.1109/IJCNN.2018.8489506","","",,,,,5,1.25,2,3,4,"Since Convolutional Neural Networks (ConvNets) are able to simultaneously learn features and classifiers to discriminate different categories of activities, recent works have employed ConvNets approaches to perform human activity recognition (HAR) based on wearable sensors, allowing the removal of expensive human work and expert knowledge. However, these approaches have their power of discrimination limited mainly by the large number of parameters that compose the network and the reduced number of samples available for training. Inspired by this, we propose an accurate and robust approach, referred to as Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and projects them, individually, onto a low dimensionality (latent) space. Then, these latent features are concatenated and presented to a classifier. To demonstrate the robustness and accuracy of the LHN, we evaluate it using four different network architectures in five publicly available HAR datasets based on wearable sensors, which vary in the sampling rate and number of activities. We experimentally demonstrate that the proposed LHN is able to capture rich information, improving the results regarding the original ConvNets. Furthermore, the method outperforms existing state-of-the-art methods, on average, by 5.1 percentage points.","",""
0,"H. Wong, T. Caelli, L. Guan","Edge characterization using a model-based neural network",1999,"","","","",39,"2022-07-13 10:09:04","","10.1109/ICASSP.1999.759938","","",,,,,0,0.00,0,3,23,"In this paper, we investigate the feasibility of characterizing significant image edges using a model-based neural network with modular architecture. Instead of employing traditional mathematical models for characterization, we ask human users to select what they regard as significant features on an image, and then incorporate these selected edges directly as training examples for the network. Unlike conventional edge detection schemes where decision thresholds have to be specified, the current NN-based edge characterization scheme implicitly represents these decision parameters in the form of network weights which are updated during the training process. Experiments have confirmed that the resulting network is capable of generalizing this previously acquired knowledge to identify important edges in images not included in the training set. Most importantly, the current approach is very robust against noise contaminations, such that no re-training of the network is required when it is applied to noisy images.","",""
2,"Moonis Ali, B. Whitehead, U. Gupta, H. Ferber","Identification and interpretation of patterns in rocket engine data: Artificial intelligence and neural network approaches",1995,"","","","",40,"2022-07-13 10:09:04","","","","",,,,,2,0.07,1,4,27,"This paper describes an expert system which is designed to perform automatic data analysis, identify anomalous events, and determine the characteristic features of these events. We have employed both artificial intelligence and neural net approaches in the design of this expert system. The artificial intelligence approach is useful because it provides (1) the use of human experts' knowledge of sensor behavior and faulty engine conditions in interpreting data; (2) the use of engine design knowledge and physical sensor locations in establishing relationships among the events of multiple sensors; (3) the use of stored analysis of past data of faulty engine conditions; and (4) the use of knowledge-based reasoning in distinguishing sensor failure from actual faults. The neural network approach appears promising because neural nets (1) can be trained on extremely noisy data and produce classifications which are more robust under noisy conditions than other classification techniques; (2) avoid the necessity of noise removal by digital filtering and therefore avoid the need to make assumptions about frequency bands or other signal characteristics of anomalous behavior; (3) can, in effect, generate their own feature detectors based on the characteristics of the sensor data used in training; and (4) are inherently parallel and therefore are potentially implementable in special-purpose parallel hardware.","",""
0,"Wu Wen, J. Callahan","Verification and Validation of KBS with Neural Network Components",1996,"","","","",41,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,2,26,"Artificial Neural Network (ANN) play an important role in developing robust Knowledge Based Systems (KBS). The ANN based components used in these systems learn to give appropriate predictions through training with correct input-output data patterns. Unlike traditional KBS that depends on a rule database and a production engine, the ANN based system mimics the decisions of an expert without specifically formulating the if-than type of rules. In fact, the ANNs demonstrate their superiority when such if-then type of rules are hard to generate by human expert. Verification of traditional knowledge based system is based on the proof of consistency and completeness of the rule knowledge base and correctness of the production engine.These techniques, however, can not be directly applied to ANN based components.In this position paper, we propose a verification and validation procedure for KBS with ANN based components. The essence of the procedure is to obtain an accurate system specification through incremental modification of the specifications using an ANN rule extraction algorithm.","",""
0,"Hristian L Iisberg","Possible Low-Priced , Robust Expert Systems Using Neural Networks and Minimal Entropy Coding C",2007,"","","","",42,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,15,"Within this paper the following research results are presented. A combination of minimal entropy coding and neural network technique is proposed for low-priced and robust expert system building A ""thesis of tractabilit y""' describing the size and complexity of ordinary human expertise when using the above-mentioned methods in knowledge engineering is given. Developmental and maintenance costs of expert and decision support systems can be cut down by more than 90 percent below the costs encountered when rule-based shells are used. A PC-based expert system shell (named ZEUS) incorporating the abovementioned principles has been developed, and two expert systems have been made. Both cases are tractable and significant cost reduction has been venfied in specific cases. Principles, techniques, and functionaliti es ofthe program ZEUS are described and evaluated.","",""
12,"S. Yadav, Smita Sharma, S. Kumar","A robust approach for offline English character recognition",2015,"","","","",43,"2022-07-13 10:09:04","","10.1109/ABLAZE.2015.7154980","","",,,,,12,1.71,4,3,7,"Recognition rate of offline handwritten English character is still bounded due to large variation of shape, slants, and scales in hand writings. A sophisticated hand written character recognition system requires a better feature extraction technique that would take care of such variation of hand writing. In this paper, we propose a recognition model based on Artificial Neural Network (ANN) supported by novel feature extraction technique. Hand written data has continued to persist as a means of recording information in day-to-day life with the introduction of latest technologies. The constant development of computer tools lead to the requirement of easier interface between human and computers. Recognition of handwritten characters by computers is complicated task as compared to typed character. The proposed system is been implemented using MATLAB successfully. The ANN accepts the input as a scanned image. This input undergoes a sequence of pre-processing steps; binarization and normalization. Then features are extracted and matched from the stored data in the database. A data-base of 2600 samples is collected from 100 writers for each character. 1041 samples have been used to train the neural network and the rest are used to test recognition model. Using our proposed recognition system we have achieved a good average recognition rate of about 86.74 percent with minimum training time.","",""
376,"Rui Zhao, Ruqiang Yan, Jinjiang Wang, K. Mao","Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks",2017,"","","","",44,"2022-07-13 10:09:04","","10.3390/s17020273","","",,,,,376,75.20,94,4,5,"In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","",""
11,"Yousif Khaireddin, Z. Chen","Facial Emotion Recognition: State of the Art Performance on FER2013",2021,"","","","",45,"2022-07-13 10:09:04","","","","",,,,,11,11.00,6,2,1,"Facial emotion recognition (FER) is significant for human-computer interaction such as clinical practice and behavioral description. Accurate and robust FER by computer models remains challenging due to the heterogeneity of human faces and variations in images such as different facial pose and lighting. Among all techniques for FER, deep learning models, especially Convolutional Neural Networks (CNNs) have shown great potential due to their powerful automatic feature extraction and computational efficiency. In this work, we achieve the highest singlenetwork classification accuracy on the FER2013 dataset. We adopt the VGGNet architecture, rigorously fine-tune its hyperparameters, and experiment with various optimization methods. To our best knowledge, our model achieves state-of-theart single-network accuracy of 73.28 % on FER2013 without using extra training data.","",""
8,"Y. Ji, Sunmok Kim, Young-Joo Kim, Ki-Baek Lee","Human‐like sign‐language learning method using deep learning",2018,"","","","",46,"2022-07-13 10:09:04","","10.4218/etrij.2018-0066","","",,,,,8,2.00,2,4,4,"This paper proposes a human‐like sign‐language learning method that uses a deep‐learning technique. Inspired by the fact that humans can learn sign language from just a set of pictures in a book, in the proposed method, the input data are pre‐processed into an image. In addition, the network is partially pre‐trained to imitate the preliminarily obtained knowledge of humans. The learning process is implemented with a well‐known network, that is, a convolutional neural network. Twelve sign actions are learned in 10 situations, and can be recognized with an accuracy of 99% in scenarios with low‐cost equipment and limited data. The results show that the system is highly practical, as well as accurate and robust.","",""
153,"Zhongrui Wang, Can Li, Wenhao Song, Mingyi Rao, D. Belkin, Yunning Li, Peng Yan, Hao Jiang, Peng Lin, Miao Hu, J. Strachan, Ning Ge, Mark D. Barnell, Qing Wu, A. Barto, Qinru Qiu, R. Williams, Q. Xia, J. Yang","Reinforcement learning with analogue memristor arrays",2019,"","","","",47,"2022-07-13 10:09:04","","10.1038/S41928-019-0221-6","","",,,,,153,51.00,15,19,3,"","",""
1,"Yuqiao Wu, Xiaoyi Geng, Zili Liu, Zhenwei Shi","Tropical Cyclone Forecast Using Multitask Deep Learning Framework",2022,"","","","",48,"2022-07-13 10:09:04","","10.1109/lgrs.2021.3132395","","",,,,,1,1.00,0,4,1,"A tropical cyclone is a robust weather system that affects human daily life. Accurate and rapid tropical cyclone forecast can guide human disaster prevention and mitigation work against tropical cyclones. The mainstream tropical cyclone forecasting method is numerical forecasting, which requires abundant prior knowledge and luxurious calculation. Nowadays, machine learning methods have received increasing attention for which they can overcome these disadvantages. However, existing machine learning methods usually ignored some potential factors since they mainly concentrated on one aspect of the tropical cyclone forecast. This letter proposes a multitask machine learning framework to forecast tropical cyclone path and intensity, which possesses two modules: one is the prediction module and the other is the estimate module. We use an improved generative adversarial network as the prediction module to predict the tropical cyclone spatial data at a certain moment in the future. Then, we use two different deep neural networks as the estimation module to extract the position and intensity from the generated prediction data. The method we propose is a general and relatively accurate tropical cyclone forecast method. We reach a 24-h path forecast error of 116 km and a 24-h intensity forecast error of 13.06 kt.","",""
1,"Seungwoong Ha, Hawoong Jeong","Discovering conservation laws from trajectories via machine learning",2021,"","","","",49,"2022-07-13 10:09:04","","","","",,,,,1,1.00,1,2,1,"Invariants and conservation laws convey critical information about the underlying dynamics of a system, yet it is generally infeasible to find them from large-scale data without any prior knowledge or human insight. We propose ConservNet to achieve this goal, a neural network that spontaneously discovers a conserved quantity from grouped data where the members of each group share invariants, similar to a general experimental setting where trajectories from different trials are observed. As a neural network trained with a novel and intuitive loss function called noise-variance loss, ConservNet learns the hidden invariants in each group of multi-dimensional observables in a data-driven, endto-end manner. Our model successfully discovers underlying invariants from the simulated systems having invariants as well as a real-world double pendulum trajectory. Since the model is robust to various noises and data conditions compared to baseline, our approach is directly applicable to experimental data for discovering hidden conservation laws and further, general relationships between variables.","",""
1,"Yonghui Wang, V. Zarghami, Suxia Cui","Fake Face Detection using Local Binary Pattern and Ensemble Modeling",2021,"","","","",50,"2022-07-13 10:09:04","","10.1109/ICIP42928.2021.9506460","","",,,,,1,1.00,0,3,1,"Fake faces generated with Generative Adversarial Networks (GANs) are becoming more and more realistic and getting harder to be identified directly by human beings. However, CNN (Convolutional Neural network) based deep learning architecture can achieve almost perfect detection accuracy on such fake faces. In this paper we present a study of fake face detection with the exploration of the global texture features based on the empirical knowledge that the textures of fake faces are quite different from those of real faces. A new architecture, LBP (Local Binary Pattern)-Net, is designed to utilize binary representation image texture for the effective identification of fake images. Experimental results show that the proposed method is more robust than existing algorithms for detecting fake images edited by different image augmentation methods, such as blurring, cutout, brightness and color changing, equalization, etc. Ensemble models are also experimented to combine advantages of individual models. The most significant effect of ensemble models is the robustness for detecting edited fake images compared to single models. Experimental results show that our ensemble models outperform single models for detecting fake images.","",""
0,"Xu Chang, Zhitong Zhang, Honglei An, Hongxu Ma, Qing Wei","Learning fast and agile quadrupedal locomotion over complex terrain",2022,"","","","",51,"2022-07-13 10:09:04","","10.48550/arXiv.2207.00797","","",,,,,0,0.00,0,5,1,": In this paper, we propose a robust controller that achieves natural and stably fast locomotion on a real blind quadruped robot. With only proprioceptive information, the quadruped robot can move at a maximum speed of 10 times its body length, and has the ability to pass through various complex terrains. The controller is trained in the simulation environment by model-free reinforcement learning. In this paper, the proposed loose neighborhood control architecture not only guarantees the learning rate, but also obtains an action network that is easy to transfer to a real quadruped robot. Our research finds that there is a problem of data symmetry loss during training, which leads to unbalanced performance of the learned controller on the left-right symmetric quadruped robot structure, and proposes a mirror-world neural network to solve the performance problem. The learned controller composed of the mirror-world network can make the robot achieve excellent anti-disturbance ability. No specific human knowledge such as a foot trajectory generator are used in the training architecture. The learned controller can coordinate the robot's gait frequency and locomotion speed, and the locomotion pattern is more natural and reasonable than the artificially designed controller. Our controller has excellent anti-disturbance performance, and has good generalization ability to reach locomotion speeds it has never learned and traverse terrains it has never seen before. complex terrains, and the maximum locomotion speed can approach the hardware limit.","",""
0,"H. Jiang, J. Liu, H. Cheng","ORBITAL UNCERTAINTY ESTIMATION SUPPORT FOR AUTONOMOUS SPACE DEBRIS OBSERVATION",2021,"","","","",52,"2022-07-13 10:09:04","","10.22201/ia.14052059p.2021.53.32","","",,,,,0,0.00,0,3,1,"The continually increased space debris have posed great impact risks to existing space systems and human space ﬂight. Accurate knowledge of propagation errors of space debris orbit is essential for many types of uses, such as space surveillance network tasking, conjunction analysis etc. Unfortunately, propagation error is not available for a two-line element (TLE). In this paper, a new TLE uncertainty estimation method based on neural network model is proposed. Object properties, space environment and predicted time-span are considered as the input of the network, the propagation errors in the direction of downrange, normal and conormal are as the output of the network. In order to assure the chosen orbit for training is not stable, only debris and rocket bodies are used. The network's effciency is demonstrated with some objects with continuous TLE data. Overall, the method proves accurate, computationally fast, and robust, and is applicable to any object in the satellite catalogue, especially for those newly launched objects.","",""
0,"V. Noel Jeygar Robert, K. Vidya","Effective cooperative spectrum sensing using deep recurrent reinforced learning‐based Q‐routing in multihop cognitive radio networks",2021,"","","","",53,"2022-07-13 10:09:04","","10.1002/dac.4982","","",,,,,0,0.00,0,2,1,"Cognitive radio network (CRN) is a promising technology that mitigates the scarcity of spectrum. The main challenge faced in the opportunistic CRN is the spectrum sensing (SS). The traditional methods of SS use detectors to find the available bands, which appear to provide unreliable performance in the case of actual environment where noise is predominant. Literature has proved that employing an artificial intelligence (AI) model for routing overcomes the lack of network knowledge and lack of human intervention and helps to learn robust patterns. Reinforced learning (RL) is a dynamically learning process that selects the actions based on continuous feedback received from the dynamic environment to maximize the reward. Deep reinforcement learning (DRL) models have proven to be successful at learning control policies image inputs. However, they struggle with learning policies that require longer term information. Recurrent neural network (RNN) architectures have been used in tasks dealing with longer term dependencies between data points. Motivated by the performance of AI models, these architectures are investigated in this work to overcome the difficulties arising from learning policies with long‐term dependencies. Thus, a deep recurrent reinforced learning‐based Q‐routing (DRRL‐based Q‐routing) is developed. The proposed study suggests a multihop CRN operated in an interweave mode. This algorithm finds optimal routing path between the secondary user transmitter (SUT) and the secondary user destination (SUD), optimal SS duration, and individual secondary user (SU) power requirements for SS and data transmission process while minimizing the end‐to‐end outage under the constraints of energy causality, SS reliability, interference threshold, and individual link throughput.","",""
0,"Tongzhou Mu, Kaixiang Lin, Fei Niu, G. Thattai","Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning",2022,"","","","",54,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,4,1,"We present a two-step hybrid reinforcement learning (RL) policy that is designed to generate interpretable and robust hierarchical policies on the RL problem with graph-based input. Unlike prior deep reinforcement learning policies parameterized by an end-to-end black-box graph neural network, our approach disentangles the decision-making process into two steps. The first step is a simplified classification problem that maps the graph input to an action group where all actions share a similar semantic meaning. The second step implements a sophisticated rule-miner that conducts explicit one-hop reasoning over the graph and identifies decisive edges in the graph input without the necessity of heavy domain knowledge. This two-step hybrid policy presents human-friendly interpretations and achieves better performance in terms of generalization and robustness. Extensive experimental studies on four levels of complex text-based games have demonstrated the superiority of the proposed method compared to the state-of-the-art.","",""
2,"Artur Jordão, R. Kloss, W. R. Schwartz","Latent hypernet: Exploring all Layers from Convolutional Neural Networks",2017,"","","","",55,"2022-07-13 10:09:04","","","","",,,,,2,0.40,1,3,5,"Since Convolutional Neural Networks (ConvNets) are able to simultaneously learn features and classifiers to discriminate different categories of activities, recent works have employed ConvNets approaches to perform human activity recognition (HAR) based on wearable sensors, allowing the removal of expensive human work and expert knowledge. However, these approaches have their power of discrimination limited mainly by the large number of parameters that compose the network and the reduced number of samples available for training. Inspired by this, we propose an accurate and robust approach, referred to as Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and projects them, individually, onto a low dimensionality space (latent). Then, these latent features are concatenated and presented to a classifier. To demonstrate the robustness and accuracy of the LHN, we evaluate it using four different networks architectures in five publicly available HAR datasets based on wearable sensors, which vary in the sampling rate and number of activities. Our experiments demonstrate that the proposed LHN is able to produce rich information, improving the results regarding the original ConvNets. Furthermore, the method outperforms existing state-of-the-art methods.","",""
45,"N. Morgulis, Alexander Kreines, Shachar Mendelowitz, Yuval Weisglass","Fooling a Real Car with Adversarial Traffic Signs",2019,"","","","",56,"2022-07-13 10:09:04","","","","",,,,,45,15.00,11,4,3,"The attacks on the neural-network-based classifiers using adversarial images have gained a lot of attention recently. An adversary can purposely generate an image that is indistinguishable from a innocent image for a human being but is incorrectly classified by the neural networks. The adversarial images do not need to be tuned to a particular architecture of the classifier - an image that fools one network can fool another one with a certain success rate.The published works mostly concentrate on the use of modified image files for attacks against the classifiers trained on the model databases. Although there exists a general understanding that such attacks can be carried in the real world as well, the works considering the real-world attacks are scarce. Moreover, to the best of our knowledge, there have been no reports on the attacks against real production-grade image classification systems.In our work we present a robust pipeline for reproducible production of adversarial traffic signs that can fool a wide range of classifiers, both open-source and production-grade in the real world. The efficiency of the attacks was checked both with the neural-network-based classifiers and legacy computer vision systems. Most of the attacks have been performed in the black-box mode, e.g. the adversarial signs produced for a particular classifier were used to attack a variety of other classifiers. The efficiency was confirmed in drive-by experiments with a production-grade traffic sign recognition systems of a real car.","",""
144,"A. Garcez, L. Lamb, D. Gabbay","Neural-Symbolic Cognitive Reasoning",2008,"","","","",57,"2022-07-13 10:09:04","","10.1007/978-3-540-73246-4","","",,,,,144,10.29,48,3,14,"","",""
8,"William A. Young, Trevor J. Bihl, G. Weckman","Artificial Neural Networks for Business Analytics",2014,"","","","",58,"2022-07-13 10:09:04","","10.4018/978-1-4666-5202-6.CH019","","",,,,,8,1.00,3,3,8,"Humans are naturally suited for recognizing and interpreting patterns; however, large and complex datasets, as in Big Data, preclude efficient human analysis. Computational pattern recognition encompasses means of describing, classifying, grouping, categorization, and/or clustering data (Jain, Duin, & Mao, 2000). Expanding on the concept of pattern recognition is knowledge discovery in datasets (KDD), the process of finding non-obvious patterns or trends in datasets primarily to assist in understanding complicated systems (Mannila, 1996). Within a world of decreasing cost of computer storage, increasing capabilities of computer processing performances, and increasing complexity of today’s business problems to solve, data analysts are encouraged to adopt more robust data mining methods. One such methodology described in this chapter is an artificial neural network (ANN).","",""
13,"S. Lu, James W. Hall","Emulating human process control functions with neural networks",1992,"","","","",59,"2022-07-13 10:09:04","","","","",,,,,13,0.43,7,2,30,"This investigation demonstrates that neural networks can perform some of the tasks in controlling complex systems that have been traditionally reserved for humans. Neural networks can be used to fuse different types of knowledge from many sources into a general process model. This technique allows process models to be formed for systems that are too complex to be modeled with conventional tools. By adding relatively few local measurements, a general process model can be calibrated into a numerically accurate local model of the process. This local model can then used for steady-state process optimization. The architectures and training techniques needed to produce neural networks capable of performing these functions are discussed. This technology was applied to the control of a complex system--a grain harvesting combine. Field tests of the harvesting process under neural network control demonstrated that the controller was robust and capable of exceeding the performance of expert human operators.","",""
84,"R. Rysdyk, A. Calise","Robust nonlinear adaptive flight control for consistent handling qualities",2005,"","","","",60,"2022-07-13 10:09:04","","10.1109/TCST.2005.854345","","",,,,,84,4.94,42,2,17,"A flight control design is presented that combines model inversion control with an online adaptive neural network (NN). The NN cancels the error due to approximate inversion. Both linear and nonlinear NNs are described. Lyapunov stability analysis leads to the online NN update laws that guarantee boundedness. The controller takes advantage of any available knowledge for system inversion, and compensates for the effects of the remaining approximations. The result is a consistency in response which is particularly relevant in human operation of some unconventional modern aircraft. A tiltrotor aircraft is capable of converting from stable and responsive fixed wing flight to sluggish and unstable hover in helicopter configuration. The control design is demonstrated to provide a tilt-rotor pilot with consistent handling qualities during conversion from fixed wing flight to hover.","",""
9,"Yilun Chen, P. Palanisamy, P. Mudalige, Katharina Muelling, J. Dolan","Learning On-Road Visual Control for Self-Driving Vehicles With Auxiliary Tasks",2018,"","","","",61,"2022-07-13 10:09:04","","10.1109/WACV.2019.00041","","",,,,,9,2.25,2,5,4,"A safe and robust on-road navigation system is a crucial component of achieving fully automated vehicles. NVIDIA recently proposed an End-to-End algorithm that can directly learn steering commands from raw pixels of a front camera by using one convolutional neural network. In this paper, we leverage auxiliary information aside from raw images and design a novel network structure, called Auxiliary Task Network (ATN), to help boost the driving performance while maintaining the advantage of minimal training data and an End-to-End training method. In this network, we introduce human prior knowledge into vehicle navigation by transferring features from image recognition tasks. Image semantic segmentation is applied as an auxiliary task for navigation. We consider temporal information by introducing an LSTM module and optical flow to the network. Finally, we combine vehicle kinematics with a sensor fusion step. We discuss the benefits of our method over state-of-the-art visual navigation methods both in the Udacity simulation environment and on the real-world Comma.ai dataset.","",""
10,"J. C. V. Tieck, Tristan Schnell, Jacques Kaiser, Felix Mauch, A. Roennau, R. Dillmann","Generating Pointing Motions for a Humanoid Robot by Combining Motor Primitives",2019,"","","","",62,"2022-07-13 10:09:04","","10.3389/fnbot.2019.00077","","",,,,,10,3.33,2,6,3,"The human motor system is robust, adaptive and very flexible. The underlying principles of human motion provide inspiration for robotics. Pointing at different targets is a common robotics task, where insights about human motion can be applied. Traditionally in robotics, when a motion is generated it has to be validated so that the robot configurations involved are appropriate. The human brain, in contrast, uses the motor cortex to generate new motions reusing and combining existing knowledge before executing the motion. We propose a method to generate and control pointing motions for a robot using a biological inspired architecture implemented with spiking neural networks. We outline a simplified model of the human motor cortex that generates motions using motor primitives. The network learns a base motor primitive for pointing at a target in the center, and four correction primitives to point at targets up, down, left and right from the base primitive, respectively. The primitives are combined to reach different targets. We evaluate the performance of the network with a humanoid robot pointing at different targets marked on a plane. The network was able to combine one, two or three motor primitives at the same time to control the robot in real-time to reach a specific target. We work on extending this work from pointing to a given target to performing a grasping or tool manipulation task. This has many applications for engineering and industry involving real robots.","",""
17,"Ismael Abdulrahman, G. Radman","Wide-Area-Based Adaptive Neuro-Fuzzy SVC Controller for Damping Interarea Oscillations",2018,"","","","",63,"2022-07-13 10:09:04","","10.1109/CJECE.2018.2868754","","",,,,,17,4.25,9,2,4,"Low-frequency interarea oscillation is a major problem in interconnected power systems with weak tie-lines that causes several stability problems if not damped. Fuzzy logic controller can generate human knowledge-based control rules to solve complex nonlinear problems. Unlike a neural network, fuzzy systems cannot learn from data, and it takes a long time to modify the membership functions. The adaptive neuro-fuzzy inference system (ANFIS) is a robust and intelligent system that integrates the capabilities of fuzzy logic and neural networks with several advantages such as adaptability, robustness, rapidity, and flexibility. In this paper, an ANFIS-based controller is proposed for controlling the reactive power provided by static var compensator to damp interarea oscillations. The controller input is a remote signal provided by a wide-area measurement system, and it is calculated as the center-of-inertia difference of generator rotor speed deviations. Moreover, a proportional-plus-derivative time-delay compensator with adaptive parameters is added to the controller to reduce the influence of time delay. A two-area four-machine test system is used and simulated with a Simulink-based package developed for the work of this paper. The time-domain simulations and frequency response analysis demonstrate the capability of the proposed controller to effectively damp interarea oscillations, under a small- and large-scale disturbances and against a wide range of time delays and load uncertainty.","",""
13,"Martino Mensio, Giuseppe Rizzo, M. Morisio","Multi-turn QA: A RNN Contextual Approach to Intent Classification for Goal-oriented Systems",2018,"","","","",64,"2022-07-13 10:09:04","","10.1145/3184558.3191539","","",,,,,13,3.25,4,3,4,"QA systems offer a human friendly interface to navigate through knowledge, which can range from encyclopedic to domain-specific. Generally, a QA system is designed to provide an answer to a specific question once (so-called single turn) and state-of-the-art systems reach nowadays robust performance in such a scenario. However, most of the interactions with QA systems are based on multiple handshakes of question/answer pairs, where the human being refines the questions further, while the system can collect the necessary information and generate a compelling final answer through multiple turns. In this paper, we investigate and experiment a multi-turn QA system that is suited to work given a particular domain of knowledge and configurable goals. Our approach models the entire dialogue as a sequence of turns, i.e. questions and answers, using a Recurrent Neural Network which is firstly trained to understand natural language, classifying entities and intents using prior knowledge of domain-specific interactions, and provide answers according to the domain used as background knowledge. We have compared our approach with state-of-the-art sequence-based intent classification using a well-known and standardized gold standard observing an increase of 17.16% of F1. Results show the robustness of the approach and the competitive results motivate the adoption in multi-turn QA scenarios.","",""
44,"R. T. Santos, J. C. Nievola, A. Freitas","Extracting comprehensible rules from neural networks via genetic algorithms",2000,"","","","",65,"2022-07-13 10:09:04","","10.1109/ECNN.2000.886228","","",,,,,44,2.00,15,3,22,"A common problem in KDD (Knowledge Discovery in Databases) is the presence of noise in the data being mined. Neural networks are robust and have a good tolerance to noise, which makes them suitable for mining very noisy data. However, they have the well-known disadvantage of not discovering any high-level rule that can be used as a support for human decision making. In this work we present a method for extracting accurate, comprehensible rules from neural networks. The proposed method uses a genetic algorithm to find a good neural network topology. This topology is then passed to a rule extraction algorithm, and the quality of the extracted rules is then fed back to the genetic algorithm. The proposed system is evaluated on three public-domain data sets and the results show that the approach is valid.","",""
417,"R. Lyon","A computational model of filtering, detection, and compression in the cochlea",1982,"","","","",66,"2022-07-13 10:09:04","","10.1109/ICASSP.1982.1171644","","",,,,,417,10.43,417,1,40,"We claim that speech analysis algorithms should be based on computational models of human audition, starting at the ears. While much is known about how hearing works, little of this knowledge has been applied in the speech analysis field. We propose models of the inner ear, or cochlea, which are expressed as time- and place-domain signal processing operations; i.e. the models are computational expressions of the important functions of the cochlea. The main parts of the models concern mechanical filtering effects and the mapping of mechanical vibrations into neural representation. Our model cleanly separates these effects into time-invariant linear filtering based on a simple cascade/parallel filterbank network of second-order sections, plus transduction and compression based on half-wave rectification with a nonlinear coupled automatic gain control network. Compared to other speech analysis techniques, this model does a much better job of preserving important detail in both time and frequency, which is important for robust sound analysis. We discuss the ways in which this model differs from more detailed cochlear models.","",""
1,"Yong-Jian Zheng","FEATURE EXTRACTION: A NEURAL NETvVORI( ORIENTED APPROACH",2010,"","","","",67,"2022-07-13 10:09:04","","","","",,,,,1,0.08,1,1,12,"Extracting features from digital images is the first goal of almost all image understanding systems. It is also difficult to solve because of the presence of noises and various photometric anomalies. Another difficulty for it is the fact that features and objects are recognized by using not only the information contained in image data but also our a priori knowledge about the semantics of the world. Thus, a feature extraction system should be robust to reduce the influence of noises and flexible to integrate different levels of knowledge for a wide range of data. In this paper, a two-stage paradigm for feature extraction is proposed, based on our conjectures about human vision ability. It includes local feature grouping and new feature describing. Based on laws of perceptual grouping and neural network modeling, we develop a novel approach for feature grouping, which finds the partion of an image into so called feature-support regions. In order to give abstract descript.ions to these regions, one needs a priori knowledge about their semantics to construct models. So we also discuss model driven methods for feature describing. To demonstrate our approach, we present its application in the limited domain of finding and describing st.raight lines in a digital image. This approach can be extended to extract other more complex symbolic image events like arcs, polylines, and polygons.","",""
0,"NetworkComponentsWu Wen, John CallahanNASA","Veri cation and Validation of KBS With Neural",2007,"","","","",68,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,2,15,"Artiicial Neural Networks(ANN) play an important role in developing robust Knowledge Based Systems(KBS). The ANN based components used in these systems learn to give appropriate predictions through training with correct input-output data patterns. Unlike traditional KBS that depends on a rule database and a production engine, the ANN based system mimics the decisions of an expert without speciically formulating the if-then type of rules. In fact, the ANNs demonstrate their superiority when such if-then type of rules are hard to generate by human expert. Veriication of traditional knowledge based system is based on the proof of consistency and completeness of the rule knowledge base and correctness of the production engine. These techniques , however, can not be directly applied to ANN based components. In this position paper, we propose a veriication and validation procedure for KBS with ANN based components. The essence of this procedure is to obtain an accurate system speciication through incremental modii-cation of the speciications using an ANN rule extraction algorithm. First, the ANN based components are speciied using available domain knowledge and implemented based on this speciica-tion. Next, past data sets are used to train the ANN components. An rule extraction algorithm is then applied to the trained ANN. Extracted rules are then analyzed and incrementally incorporated into the system speciication. Finally, the modiied speciications are veriied for cor-rectness and the product tested against the correct speciications.","",""
4,"J. Couchet, J. M. Font, D. Manrique","Using Evolved Fuzzy Neural Networks for Injury Detection from Isokinetic Curves",2008,"","","","",69,"2022-07-13 10:09:04","","10.1007/978-1-84882-215-3_17","","",,,,,4,0.29,1,3,14,"","",""
1,"Kai Yi, Shi-tao Chen, Yu Chen, Chao Xia, N. Zheng","Cognition-Based Deep Learning: Progresses and Perspectives",2018,"","","","",70,"2022-07-13 10:09:04","","10.1007/978-3-319-92007-8_11","","",,,,,1,0.25,0,5,4,"","",""
0,"Qinyun Liu","Solution Generation through Hybrid Intelligence and Creativity based on Investment Portfolio",2018,"","","","",71,"2022-07-13 10:09:04","","10.23940/IJPE.18.07.P29.16411650","","",,,,,0,0.00,0,1,4,"Artificial Intelligence (AI) has been developed to be robust on computing. Learning can be achieved by connecting to heterogeneous data using AI algorithms, such as the Artificial Neural Network. Knowledge can be learned, and rules in the database can be discovered by machines through heuristic algorithms. However, creativity has not been achieved by computers like the human brain by using AI algorithms individually. This research serves to explore a method to achieve creative solution generation by utilizing a relationship between intelligence and creativity, assuming intelligence is the subset of creativity. Under this relationship, the computing can be fulfilled using AI algorithms. The theories of achieving creativity is the guidance of this method.","",""
2,"Singh Mukesh Kumar, Mishra Deepak Kumar, R. Parhi Dayal, Singh Mahendra Prasad","Intelligent Controller for Mobile Robot Based on Heuristic Rule Base Network",2011,"","","","",72,"2022-07-13 10:09:04","","10.4028/www.scientific.net/AMR.403-408.4777","","",,,,,2,0.18,1,4,11,"This paper is related to the human perception based idea by using heuristic information for the navigation of mobile robots in cluttered dynamic environments which provides a general, robust, safe and optimized path. The heuristic rule base network consists of a simple algorithm which makes predefined estimation function very smaller. The estimation function should be adequately defined for desired movement in the environments. A navigation system using rule based technique that allows a mobile robot to travel in an environment about, which the robot has no prior knowledge. This heuristic rule is applied in conjunction with artificial neural network. The proposed intelligent controller provides an optimum trajectory which increases the effectiveness of a mobile robot. A series of simulations test has been conducted to show the effectiveness of the proposed algorithm.","",""
2,"Miguel Tena Aniés","Master Degree Project in Speech Technology Robust Speech Recognition with an Auditory Model",2004,"","","","",73,"2022-07-13 10:09:04","","","","",,,,,2,0.11,2,1,18,"This report describes a phoneme recognition system based on properties of the human auditory system. The first part of the paper summarizes knowledge about the physiology of the auditory system, which is the origin of the computational model used in the study and implemented with Matlab. The model, which extracts the critical information of the speech signal, works as an input for a neural network that is trained on the TIMIT speech database to classify English phonemes. The model is shown to be more robust to telephone disturbances of the speech signal than a system based on conventional acoustic processing techniques (MFCC) used in speech recognition. Speech Music and Hearing KTH Miguel Tena Aniés 1 Table of contents Table of contents ..............................................................................................................................1","",""
2,"Yongsheng Zhao, Jun Wu, Yifeng Zhu, Hongxiang Yu, R. Xiong","A learning framework towards real-time detection and localization of a ball for robotic table tennis system",2017,"","","","",74,"2022-07-13 10:09:04","","10.1109/RCAR.2017.8311842","","",,,,,2,0.40,0,5,5,"As a real-time serving system interacting with a highly dynamic environment, robotic table tennis system has a high requirement against the accuracy and robustness of real-time detection and localization of a ping-pong ball. Relative to its size, the ball is a high speed flying-spinning object. The existing methods use general features such as color and shape to detect and localize the ball, which rigidly depends on the prior knowledge. Their performance is susceptible to the change of the environment, e.g., the light condition, the color of ball, and the disturbance of human players' presence in the image. In this paper, we propose a learning framework that trains a convolutional neural network to detect and localize a ball with high accuracy. It learns useful features from data directly without any prior knowledge. Therefore, the proposed method can effectively deal with the situation when the ball's color is changing in real-time. And it is more robust to the light condition and the disturbance of human players' presence. The effectiveness and accuracy of the method is verified using the collected data set, in comparison with the state-of-the-art method.","",""
6,"K. Noda, Naoya Hashimoto, K. Nakadai, T. Ogata","Sound source separation for robot audition using deep learning",2015,"","","","",75,"2022-07-13 10:09:04","","10.1109/HUMANOIDS.2015.7363579","","",,,,,6,0.86,2,4,7,"Noise robust speech recognition is crucial for effective human-machine interaction in real-world environments. Sound source separation (SSS) is one of the most widely used approaches for addressing noise robust speech recognition by extracting a target speaker's speech signal while suppressing simultaneous unintended signals. However, conventional SSS algorithms, such as independent component analysis or nonlinear principal component analysis, are limited in modeling complex projections with scalability. Moreover, conventional systems required designing an independent subsystem for noise reduction (NR) in addition to the SSS. To overcome these issues, we propose a deep neural network (DNN) framework for modeling the separation function (SF) of an SSS system. By training a DNN to predict clean sound features of a target sound from corresponding multichannel deteriorated sound feature inputs, we enable the DNN to model the SF for extracting the target sound without prior knowledge regarding the acoustic properties of the surrounding environment. Moreover, the same DNN is trained to function simultaneously as a NR filter. Our proposed SSS system is evaluated using an isolated word recognition task and a large vocabulary continuous speech recognition task when either nondirectional or directional noise is accumulated in the target speech. Our evaluation results demonstrate that DNN performs noticeably better than the baseline approach, especially when directional noise is accumulated with a low signal-to-noise ratio.","",""
1,"J. Roorda, M. Crowe","Artificial Neural Systems Application to the Simulation of Air Combat Decision Making",1992,"","","","",76,"2022-07-13 10:09:04","","","","",,,,,1,0.03,1,2,30,"Abstract : The research goals of this project were to ascertain the applicability of Artificial Neural Systems (ANS) technology to expert systems tasks in general and to support the simulation of Air Combat Maneuvering (ACM) decision-making in the training environment. In the experiments conducted under this program, neural networks have aptly displayed their unique capabilities to overcome some of the more difficult aspects of knowledge engineering. ANS approaches have been shown to be capable of producing robust, generalized solutions even under novel circumstances. By capturing and simulating the expertise of human pilots in a neural network, students may be provided with expert training devices which may come very close to the look and feel of real air-to-air combat. It is expected that ANS technology will continue to provide new solutions to the simulation of human performance for training purposes.","",""
7,"S. Rahman, I. Drezga, J. Rajagopalan","Knowledge enhanced connectionist models for short-term electric load forecasting",1993,"","","","",77,"2022-07-13 10:09:04","","10.1109/ANN.1993.264314","","",,,,,7,0.24,2,3,29,"This paper addresses short-term load forecasting using machine learning and neural network techniques. Neural networks, though accurate in weekday load forecasting, are poor at forecasting maximum daily load, weekend and holiday loads. This necessitates development of a robust forecasting technique to complement the neural networks for enhanced reliability of forecast and improved overall accuracy. The statistical decision tree method produces robust forecasts and human intelligible rules. These rules provide understanding of factors driving load demand. Decision trees when combined with neural network forecasts, produce robust and accurate forecasts. Simulations are performed on a service area susceptible to large and sudden changes in weather and load. Forecasts obtained by the proposed method are accurate under diverse conditions.<<ETX>>","",""
11,"P. Dorairaj, Surendra Kumar, R. Prasad","Dynamic Control of Three-Link SCARA Manipulator using Adaptive Neuro Fuzzy Inference System",2008,"","","","",78,"2022-07-13 10:09:04","","10.1109/ICNSC.2008.4525478","","",,,,,11,0.79,4,3,14,"In this work the adaptive neuro-fuzzy inference system (ANFIS) controller is designed for the dynamic control (continuous path control) of the three-link selective compliant assembly robot arm (SCARA) manipulator. This ANFIS controller is designed to overcome the unmodeled dynamics and in the presence of structured and unstructured uncertainties of SCARA. The proposed controller-building technique combines artificial neural networks with fuzzy logic. The ANFIS control combines the advantages of neural networks (learning and adaptability) with the advantages of fuzzy logic (use of expert knowledge) to achieve the goal of robust control of robot dynamic systems. The fuzzy sets are used to formalize the level of human perception of the physical system. The neural network on the other hand performs all the necessary computations and regarding their learning capabilities, they enable an adaptation of the existing controller through its learning to the changes in the system behavior. The experimental ANFIS simulation results show very good SCARA tracking performance.","",""
19,"A. So, W. L. Chan, W. Tse","Self-learning fuzzy air handling system controller",1997,"","","","",79,"2022-07-13 10:09:04","","10.1177/014362449701800206","","",,,,,19,0.76,6,3,25,"Modem air-conditioning commonly employ the 'central all-air system' and the variable air volume (VAV) system, in particular, is widely used everywhere around the world for energy conservation. Proportional-integral-differential (PID) control for air handling units (AHUs) is simple and straightforward but static fuzzy control is very often more robust, more energy efficient and faster in responding to changes due to executing expert knowledge. However, AHU control is highly dynamic where the system characteristics vary continuously. The static fuzzy rules are quite general in nature. They cannot be effective and optimal for all operating conditions because they are based on linguistic rules suggested by human experts. A new self-learning fuzzy controller has been designed in which the control policy is adaptable to changes in the control process and the environment. The controller can therefore always be operating at its optimal settings. The air handling system is modelled continuously by an artificial neural network. Although the process is quite intensive computationally, no system model needs to be assumed beforehand. Based on the minimisation of a performance indicator addresses both set-point errors and energy consumption, the self-learning ability continuously updates the defuzzification parameters of the controller. Computer simulation has revealed that the new self-learning fuzzy controller can achieve an even faster response rate and better energy consumption profile than those of the static fuzzy controller.","",""
5,"Franz Rothlauf, J. Branke, S. Cagnoni, E. Costa, C. Cotta, R. Drechsler, E. Lutton, P. Machado, J. H. Moore, Juan Romero, George D. Smith, Giovanni Squillero, H. Takagi","Applications of Evolutionary Computing, EvoWorkshops 2006: EvoBIO, EvoCOMNET, EvoHOT, EvoIASP, EvoINTERACTION, EvoMUSART, and EvoSTOC, Budapest, Hungary, April 10-12, 2006, Proceedings",2006,"","","","",80,"2022-07-13 10:09:04","","10.1007/11732242","","",,,,,5,0.31,1,13,16,"","",""
0,"J. Ortiz-Rodríguez, M. Martinez-Blanco, H. Vega-Carrillo, Ramón López Velarde","Development of a new software tool , based on ANN technology , in neutron spectrometry and dosimetry research",2007,"","","","",81,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,4,15,"Artificial Intelligence is a branch of study which enhances the capability of computers by giving them human-like intelligence. The brain architecture has been extensively studied and attempts have been made to emulate it as in the Artificial Neural Network technology. A large variety of neural network architectures have been developed and they have gained wide-spread popularity over the last few decades. Their application is considered as a substitute for many classical techniques that have been used for many years, as in the case of neutron spectrometry and dosimetry research areas. In previous works, a new approach called Robust Design of Artificial Neural network was applied to build an ANN topology capable to solve the neutron spectrometry and dosimetry problems within the Matlab® programming environment. In this work, the knowledge stored at Matlab® ANN’s synaptic weights was extracted in order to develop for first time a customized software application based on ANN technology, which is proposed to be used in the neutron spectrometry and simultaneous dosimetry fields.","",""
1,"G. Naik, D. Kumar, H. Weghorn, Vijay P. Singh, M. Palaniswami","Improving Isometric Hand Gesture Identification for HCI based on Independent Component Analysis in Bio-signal Processing",2007,"","","","",82,"2022-07-13 10:09:04","","10.5220/0002427301710180","","",,,,,1,0.07,0,5,15,"Hand gesture identification has various human computer interaction (HCI) applications. There is an urgent need for establishing a simple yet robust system that can be used to identify subtle complex hand actions and gestures for control of prosthesis and other computer assisted devices. Here, an approach is explained to demonstrate how hand gestures can be identified from isometric muscular activity, where signal level is low and changes are very subtle. Obvious difficulties arise from a very poor signal to noise ratio in the recorded electromyograms (EMG). Independent component analysis (ICA) is applied to separate these low-level muscle activities. The order and magnitude ambiguity of ICA have been overcome by using a priori knowledge of the hand muscle anatomy and a fixed un-mixing matrix. The classification is achieved using a back-propagation neural network. Experimental results are shown, where the system was able to reliably recognize motionless gestures. The system was tested across users to investigate the impact of inter-subject variation. The experimental results demonstrate an overall accuracy of 96%, and the system was shown being insensitive against electrode positions, since these successful experiments were repeated on different days. The advantage of such a system is, that it is easy to train by a lay user, and that it can easily be implemented as real-time processing after an initial training. Hence, EMG-based input devices can provide an effective solution for designing mobile interfaces that are subtle and intimate, and there exist a range of applications for communication, emotive machines and human computer interface.","",""
1,"S. Perry, L. Guan, P. Varjavandi","Incorporating local statistics in image error measurement for adaptive image restoration",2006,"","","","",83,"2022-07-13 10:09:04","","10.1117/1.2181927","","",,,,,1,0.06,0,3,16,"This paper presents an image restoration technique incorpo- rating local statistical knowledge in the cost function. Instead of using a conventional grayscale-based error measurement such as the mean squared error, we compare local statistical information about regions in two images using a new error measure. Transient features such as edges and textures are more strongly emphasized than relatively homo- geneous regions. With the addition of this local information, we attempt to provide a measure closer to human visual appraisal. We then extend the popular constrained squared-error cost function by incorporating this image error measure. Due to its nonlinear nature, conventional restora- tion algorithms cannot optimize this cost function efficiently. Therefore we seek an iterative approach. In particular, an extended neural network algorithm is proposed to perform the restoration. It is shown that this technique is efficient, effective, and robust. It compares favorably with other techniques when applied to both grayscale and color images. The results of a subjective survey comparing the proposed algorithm with a more conventional neural network algorithm are presented. The subjects tested in the survey overwhelmingly favored the results provided by the proposed method. © 2006 Society of Photo-Optical Instrumentation","",""
27,"Masahiro Mitsuhara, Hiroshi Fukui, Yusuke Sakashita, Takanori Ogata, Tsubasa Hirakawa, Takayoshi Yamashita, H. Fujiyoshi","Embedding Human Knowledge in Deep Neural Network via Attention Map",2019,"","","","",84,"2022-07-13 10:09:04","","10.5220/0010335806260636","","",,,,,27,9.00,4,7,3,"In this work, we aim to realize a method for embedding human knowledge into deep neural networks. While the conventional method to embed human knowledge has been applied for non-deep machine learning, it is challenging to apply it for deep learning models due to the enormous number of model parameters. To tackle this problem, we focus on the attention mechanism of an attention branch network (ABN). In this paper, we propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert. Our fine-tuning method can train a network so that the output attention map corresponds to the edited ones. As a result, the fine-tuned network can output an attention map that takes into account human knowledge. Experimental results with ImageNet, CUB-200-2010, and IDRiD demonstrate that it is possible to obtain a clear attention map for a visual explanation and improve the classification performance. Our findings can be a novel framework for optimizing networks through human intuitive editing via a visual interface and suggest new possibilities for human-machine cooperation in addition to the improvement of visual explanations.","",""
4,"Georgios Panagiotatos, N. Passalis, Alexandros Iosifidis, M. Gabbouj, A. Tefas","Curriculum-based Teacher Ensemble for Robust Neural Network Distillation",2019,"","","","",85,"2022-07-13 10:09:04","","10.23919/EUSIPCO.2019.8903112","","",,,,,4,1.33,1,5,3,"Neural network distillation is used for transferring the knowledge from a complex teacher network into a lightweight student network, improving in this way the performance of the student network. However, neural distillation does not always lead to consistent results, with several factors affecting the efficiency of the knowledge distillation process. In this paper it is experimentally demonstrated that the selected teacher can indeed have a significant effect on knowledge transfer. To overcome this limitation, we propose a curriculum-based teacher ensemble that allows for performing robust and efficient knowledge distillation. The proposed method is motivated by the way that humans learn through a curriculum, as well as supported by recent findings that hints to the existence of critical learning periods in neural networks. The effectiveness of the proposed approach, compared to various distillation variants, is demonstrated using three image datasets and different network architectures.","",""
1,"Huilin Ge, Yuewei Dai, Zhiyu Zhu, Biao Wang","Robust face recognition based on multi-task convolutional neural network.",2021,"","","","",86,"2022-07-13 10:09:04","","10.3934/mbe.2021329","","",,,,,1,1.00,0,4,1,"PURPOSE Due to the lack of prior knowledge of face images, large illumination changes, and complex backgrounds, the accuracy of face recognition is low. To address this issue, we propose a face detection and recognition algorithm based on multi-task convolutional neural network (MTCNN).   METHODS In our paper, MTCNN mainly uses three cascaded networks, and adopts the idea of candidate box plus classifier to perform fast and efficient face recognition. The model is trained on a database of 50 faces we have collected, and Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and receiver operating characteristic (ROC) curve are used to analyse MTCNN, Region-CNN (R-CNN) and Faster R-CNN.   RESULTS The average PSNR of this technique is 1.24 dB higher than that of R-CNN and 0.94 dB higher than that of Faster R-CNN. The average SSIM value of MTCNN is 10.3% higher than R-CNN and 8.7% higher than Faster R-CNN. The Area Under Curve (AUC) of MTCNN is 97.56%, the AUC of R-CNN is 91.24%, and the AUC of Faster R-CNN is 92.01%. MTCNN has the best comprehensive performance in face recognition. For the face images with defective features, MTCNN still has the best effect.   CONCLUSIONS This algorithm can effectively improve face recognition to a certain extent. The accuracy rate and the reduction of the false detection rate of face detection can not only be better used in key places, ensure the safety of property and security of the people, improve safety, but also better reduce the waste of human resources and improve efficiency.","",""
248,"Lukas Schott, Jonas Rauber, M. Bethge, Wieland Brendel","Towards the first adversarially robust neural network model on MNIST",2018,"","","","",87,"2022-07-13 10:09:04","","","","",,,,,248,62.00,62,4,4,"Despite much effort, deep neural networks remain highly susceptible to tiny input perturbations and even for MNIST, one of the most common toy datasets in computer vision, no neural network model exists for which adversarial perturbations are large and make semantic sense to humans. We show that even the widely recognized and by far most successful defense by Madry et al. (1) overfits on the L-infinity metric (it's highly susceptible to L2 and L0 perturbations), (2) classifies unrecognizable images with high certainty, (3) performs not much better than simple input binarization and (4) features adversarial perturbations that make little sense to humans. These results suggest that MNIST is far from being solved in terms of adversarial robustness. We present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. We derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness on MNIST against L0, L2 and L-infinity perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class.","",""
5985,"David Silver, Julian Schrittwieser, K. Simonyan, Ioannis Antonoglou, Aja Huang, A. Guez, T. Hubert, Lucas baker, Matthew Lai, A. Bolton, Yutian Chen, T. Lillicrap, Fan Hui, L. Sifre, George van den Driessche, T. Graepel, D. Hassabis","Mastering the game of Go without human knowledge",2017,"","","","",88,"2022-07-13 10:09:04","","10.1038/nature24270","","",,,,,5985,1197.00,599,17,5,"","",""
5,"Hang Su, Wen Qi, Zhijun Li, Ziyang Chen, G. Ferrigno, E. Momi","Deep Neural Network Approach in EMG-Based Force Estimation for Human–Robot Interaction",2021,"","","","",89,"2022-07-13 10:09:04","","10.1109/TAI.2021.3066565","","",,,,,5,5.00,1,6,1,"In the human–robot interaction, especially when hand contact appears directly on the robot arm, the dynamics of the human arm presents an essential component in human–robot interaction and object manipulation. Modeling and estimation of the human arm dynamics show great potential for achieving more natural and safer interaction. To enrich the dexterity and guarantee the accuracy of the manipulation, mapping the motor functionality of muscle using biosignals becomes a popular topic. In this article, a novel algorithm was constructed using deep learning to explore the potential model between surface electromyography (sEMG) signals of the human arm and interaction force for human–robot interaction. Its features were extracted by adopting the convolutional neural network from the sEMG signals automatically without using prior knowledge of the biomechanical model. The experiments prove the lower error ($< \text{0.4}\,N$) of the designed regression by comparing it with other approaches, such as artificial neural network and long short-term memory. It should be also mentioned that the antinoise ability is an important index to apply this technique in practical applications. Hence, we also add different Gaussian noises into the dataset to demonstrate the robustness against measurement noises by using the proposed model. Finally, it demonstrates the performance of the proposed algorithm using the Myo controller and KUKA LWR4+ robot.","",""
1,"Peng Lu, Yang Gao, Hao Xi, Yabin Zhang, Chao Gao, Bing Zhou, Hongpo Zhang, Liwei Chen, Xiaobo Mao","KecNet: A Light Neural Network for Arrhythmia Classification Based on Knowledge Reinforcement",2021,"","","","",90,"2022-07-13 10:09:04","","10.1155/2021/6684954","","",,,,,1,1.00,0,9,1,"Acquiring electrocardiographic (ECG) signals and performing arrhythmia classification in mobile device scenarios have the advantages of short response time, almost no network bandwidth consumption, and human resource savings. In recent years, deep neural networks have become a popular method to efficiently and accurately simulate nonlinear patterns of ECG data in a data-driven manner but require more resources. Therefore, it is crucial to design deep learning (DL) algorithms that are more suitable for resource-constrained mobile devices. In this paper, KecNet, a lightweight neural network construction scheme based on domain knowledge, is proposed to model ECG data by effectively leveraging signal analysis and medical knowledge. To evaluate the performance of KecNet, we use the Association for the Advancement of Medical Instrumentation (AAMI) protocol and the MIT-BIH arrhythmia database to classify five arrhythmia categories. The result shows that the ACC, SEN, and PRE achieve 99.31%, 99.45%, and 98.78%, respectively. In addition, it also possesses high robustness to noisy environments, low memory usage, and physical interpretability advantages. Benefiting from these advantages, KecNet can be applied in practice, especially wearable and lightweight mobile devices for arrhythmia classification.","",""
3,"Xinsong Zhang, Tianyi Liu, Pengshuai Li, Weijia Jia, Hai Zhao","Robust Neural Relation Extraction via Multi-Granularity Noises Reduction",2021,"","","","",91,"2022-07-13 10:09:04","","10.1109/tkde.2020.2964747","","",,,,,3,3.00,1,5,1,"Distant supervision is widely used to extract relational facts with automatically labeled datasets to reduce high cost of human annotation. However, current distantly supervised methods suffer from the common problems of word-level and sentence-level noises, which come from a large proportion of irrelevant words in a sentence and inaccurate relation labels for numerous sentences. The problems lead to unacceptable precision in relation extraction and are critical for the success of using distant supervision. In this paper, we propose a novel and robust neural approach to deal with both problems by reducing influences of the multi-granularity noises. Three levels of noises from word, sentence until knowledge type are carefully considered in this work. We first initiate a question-answering based relation extractor (QARE) to remove noisy words in a sentence. Then we use multi-focus multi-instance learning (MMIL) to alleviate the effects of sentence-level noise by utilizing wrongly labeled sentences properly. Finally, to enhance our method against all the noises, we initialize parameters in our method with a priori knowledge learned from the relevant task of entity type classification by transfer learning. Extensive experiments on both existing benchmark and an improved larger dataset demonstrate that our proposed approach remarkably achieves new state-of-the-art performance.","",""
1,"Zhiwen Xiao, Xin Xu, Huanlai Xing, R. Qu, Fuhong Song, Bowen Zhao","RNTS: Robust Neural Temporal Search for Time Series Classification",2021,"","","","",92,"2022-07-13 10:09:04","","10.1109/IJCNN52387.2021.9534392","","",,,,,1,1.00,0,6,1,"Over the years, a large number of deep learning algorithms have been developed for time series classification (TSC). These algorithms were usually invented by researchers with prior knowledge and experience. However, it is a critical challenge for beginners to design decent structures to address various TSC problems. To this end, we propose a robust neural temporal search (RNTS) framework for identifying the relationships and features in TSC data, which mainly contains a temporal search network and an attentional LSTM network. To be specific, inspired by the idea of neural architecture search (NAS), the temporal search network automatically transforms its structure for each dataset according to its characteristics, responsible for extracting basic features. The attentional LSTM network is used to explore the complex shapelets and relationships the former may ignore. Experimental results demonstrate that RNTS achieves the best overall performance on 24 standard datasets selected from the UCR 2018 archive, in terms of three measures based on the top-l accuracy, compared with a number of state-of-the-art approaches.","",""
19,"Xin Zhong, Pei-Chi Huang, Spyridon Mastorakis, F. Shih","An Automated and Robust Image Watermarking Scheme Based on Deep Neural Networks",2019,"","","","",93,"2022-07-13 10:09:04","","10.1109/TMM.2020.3006415","","",,,,,19,6.33,5,4,3,"Digital image watermarking is the process of embedding and extracting a watermark covertly on a cover-image. To dynamically adapt image watermarking algorithms, deep learning–based image watermarking schemes have attracted increased attention during recent years. However, existing deep learning–based watermarking methods neither fully apply the fitting ability to learn and automate the embedding and extracting algorithms, nor achieve the properties of robustness and blindness simultaneously. In this paper, a robust and blind image watermarking scheme based on deep learning neural networks is proposed. To minimize the requirement of domain knowledge, the fitting ability of deep neural networks is exploited to learn and generalize an automated image watermarking algorithm. A deep learning architecture is specially designed for image watermarking tasks, which will be trained in an unsupervised manner to avoid human intervention and annotation. To facilitate flexible applications, the robustness of the proposed scheme is achieved without requiring any prior knowledge or adversarial examples of possible attacks. A challenging case of watermark extraction from phone camera–captured images demonstrates the robustness and practicality of the proposal. The experiments, evaluation, and application cases confirm the superiority of the proposed scheme.","",""
8,"Masaki Uto, Masashi Okano","Robust Neural Automated Essay Scoring Using Item Response Theory",2020,"","","","",94,"2022-07-13 10:09:04","","10.1007/978-3-030-52237-7_44","","",,,,,8,4.00,4,2,2,"","",""
1,"E. R., D. Jain, K. Kotecha, Sharnil Pandya, Sai Siddhartha Reddy, R. E, V. Varadarajan, Aniket Mahanti, S. V","Hybrid Deep Neural Network for Handling Data Imbalance in Precursor MicroRNA",2021,"","","","",95,"2022-07-13 10:09:04","","10.3389/fpubh.2021.821410","","",,,,,1,1.00,0,9,1,"Over the last decade, the field of bioinformatics has been increasing rapidly. Robust bioinformatics tools are going to play a vital role in future progress. Scientists working in the field of bioinformatics conduct a large number of researches to extract knowledge from the biological data available. Several bioinformatics issues have evolved as a result of the creation of massive amounts of unbalanced data. The classification of precursor microRNA (pre miRNA) from the imbalanced RNA genome data is one such problem. The examinations proved that pre miRNAs (precursor microRNAs) could serve as oncogene or tumor suppressors in various cancer types. This paper introduces a Hybrid Deep Neural Network framework (H-DNN) for the classification of pre miRNA in imbalanced data. The proposed H-DNN framework is an integration of Deep Artificial Neural Networks (Deep ANN) and Deep Decision Tree Classifiers. The Deep ANN in the proposed H-DNN helps to extract the meaningful features and the Deep Decision Tree Classifier helps to classify the pre miRNA accurately. Experimentation of H-DNN was done with genomes of animals, plants, humans, and Arabidopsis with an imbalance ratio up to 1:5000 and virus with a ratio of 1:400. Experimental results showed an accuracy of more than 99% in all the cases and the time complexity of the proposed H-DNN is also very less when compared with the other existing approaches.","",""
0,"Bing Liu, G. Qi, Lu Pan, Shangfu Duan, Tianxing Wu","Incorporating Human Knowledge in Neural Relation Extraction with Reinforcement Learning",2019,"","","","",96,"2022-07-13 10:09:04","","10.1109/IJCNN.2019.8852431","","",,,,,0,0.00,0,5,3,"Relation Extraction (RE) aims at extracting semantic relation of entities from text and it is a crucial task in natural language processing. Deep neural network (DNN) based models have achieved excellent performance in RE. However, they still have several problems remaining to be addressed: (1) humans can hardly take measures to amend the DNN-based RE systems because it is difficult to encode human intention to guide them to capture desired patterns. (2) DNN-based RE models may suffer from not having sufficient background information for making predictions. To handle these issues, we propose an RE framework based on reinforcement learning, which can enhance existing DNN-based RE models by incorporating human knowledge including soft rules and relation evidence. The introduction of soft rules enable human to impose an effect on the RE result and correct the RE system, while the relation evidence help supplement the background information without limiting its types and sources. The experimental results show that our approach can reinforce existing DNN-based RE models effectively and outperforms state-of-the-art RE methods.","",""
22,"Bo Li, Cheng Han, Baoxing Bai","Hybrid approach for human posture recognition using anthropometry and BP neural network based on Kinect V2",2019,"","","","",97,"2022-07-13 10:09:04","","10.1186/S13640-018-0393-4","","",,,,,22,7.33,7,3,3,"","",""
9,"A. Bhandare, D. Kaur","Designing Convolutional Neural Network Architecture Using Genetic Algorithms",2021,"","","","",98,"2022-07-13 10:09:04","","10.21307/ijanmc-2021-024","","",,,,,9,9.00,5,2,1,"Abstract In this paper, genetic algorithm (GA) is used to optimally determine the architecture of a convolutional neural network (CNN) that is used to classify handwritten numbers. The CNN is a class of deep feed-forward network, which have seen major success in the field of visual image analysis. During training, a good CNN architecture is capable of extracting complex features from the given training data; however, at present, there is no standard way to determine the architecture of a CNN. Domain knowledge and human expertise are required in order to design a CNN architecture. Typically architectures, The GA determine the exact architecture of a CNN by evolving the various hyper parameters of the architecture for a given application. The proposed method was tested on the MNIST dataset. The results show that the genetic algorithm is capable of generating successful CNN architectures. The proposed method performs the entire process of architecture generation without any human intervention.","",""
15,"M. Gogate, K. Dashtipour, P. Bell, A. Hussain","Deep Neural Network Driven Binaural Audio Visual Speech Separation",2020,"","","","",99,"2022-07-13 10:09:04","","10.1109/IJCNN48605.2020.9207517","","",,,,,15,7.50,4,4,2,"The central auditory pathway exploits the auditory signals and visual information sent by both ears and eyes to segregate speech from multiple competing noise sources and help disambiguate phonological ambiguity. In this study, inspired from this unique human ability, we present a deep neural network (DNN) that ingest the binaural sounds received at the two ears as well as the visual frames to selectively suppress the competing noise sources individually at both ears. The model exploits the noisy binaural cues and noise robust visual cues to improve speech intelligibility. The comparative simulation results in terms of objective metrics such as PESQ, STOI, SI-SDR and DBSTOI demonstrate significant performance improvement of the proposed audio-visual (AV) DNN as compared to the audio-only (A-only) variant of the proposed model. Finally, subjective listening tests with the real noisy AV ASPIRE corpus shows the superiority of the proposed AV DNN as compared to state-of-the-art approaches.","",""
4,"N. Jain, Vedika Gupta, Shubham Shubham, Agam Madan, Ankit Chaudhary, K. Santosh","Understanding cartoon emotion using integrated deep neural network on large dataset",2021,"","","","",100,"2022-07-13 10:09:04","","10.1007/s00521-021-06003-9","","",,,,,4,4.00,1,6,1,"","",""
2,"Wenyan Yang, N. Strokina, N. Serbenyuk, J. Pajarinen, R. Ghabcheloo, J. Vihonen, M. M. Aref, Joni-Kristian Kämäräinen","Neural Network Controller for Autonomous Pile Loading Revised",2021,"","","","",101,"2022-07-13 10:09:04","","10.1109/ICRA48506.2021.9561804","","",,,,,2,2.00,0,8,1,"We have recently proposed two pile loading controllers that learn from human demonstrations: a neural network (NNet) [1] and a random forest (RF) controller [2]. In the field experiments the RF controller obtained clearly better success rates. In this work, the previous findings are drastically revised by experimenting summer time trained controllers in winter conditions. The winter experiments revealed a need for additional sensors, more training data, and a controller that can take advantage of these. Therefore, we propose a revised neural controller (NNetV2) which has a more expressive structure and uses a neural attention mechanism to focus on important parts of the sensor and control signals. Using the same data and sensors to train and test the three controllers, NNetV2 achieves better robustness against drastically changing conditions and superior success rate. To the best of our knowledge, this is the first work testing a learning-based controller for a heavy-duty machine in drastically varying outdoor conditions and delivering high success rate in winter, being trained in summer.","",""
1,"Ke Ding, Tsukasa Kimura, Ken-ichi Fukui, M. Numao","EEG emotion Enhancement using Task-specific Domain Adversarial Neural Network",2021,"","","","",102,"2022-07-13 10:09:04","","10.1109/IJCNN52387.2021.9533310","","",,,,,1,1.00,0,4,1,"Electroencephalogram (EEG) signal has been widely applied in detecting human emotion. Individual differences limit the generalization in cross-subject classification since the release of emotion will be definitely different across persons even with the same emotion stimuli. Previous research utilizes domain adaptation to solve this problem in a leave-one-subject-out training that is learning common emotion-related features from many subjects and testing on a new subject, which requires abundant labeled data. This paper proposed a novel one-to-one domain adaptation method, the Task-specific Domain Adversarial Neural Network (T-DANN) which transfers knowledge from either one subject to predict on another subject or knowledge from one phase to predict on another phase within the same subject. Therefore, T-DANN is more flexible and requires much less data during training. T-DANN is an adversarial training method which adapts the conditional distribution between domains and adapts classification boundaries between classes simultaneously. Compared with data from different subjects, phase data from the same subject has much deeper correlation thus enhances the prediction of emotion in new phase. We evaluated our method on EEG emotion benchmark dataset SEED. The experiments showed that our proposed method outperformed other baseline methods in cross-subject adaptation. By cross-phase adaptation, our method achieved accuracy that approximately 3% lower than the state-of-the-art method but only used 1/14 labeled data, indicating the priority of our proposed method in real-time application.","",""
7,"Muhammad Fayyaz, Mussarat Yasmin, Muhammad Sharif, M. Raza","J-LDFR: joint low-level and deep neural network feature representations for pedestrian gender classification",2020,"","","","",103,"2022-07-13 10:09:04","","10.1007/s00521-020-05015-1","","",,,,,7,3.50,2,4,2,"","",""
4,"Yu Yu, W. Lu, Yang Liu, Hong-Bo Zhu","Neural-Network-Based Root Mean Delay Spread Model for Ubiquitous Indoor Internet-of-Things Scenarios",2020,"","","","",104,"2022-07-13 10:09:04","","10.1109/JIOT.2020.2979766","","",,,,,4,2.00,1,4,2,"Massive robust communication demands among machines and humans are required in ubiquitous Internet-of-Things (IoT) applications. To design the appropriate communication system, the knowledge of the propagation characteristics for various IoTs scenarios is necessary. In this article, a measurement-based neural-network-based root-mean-square (RMS) delay spread model for ubiquitous indoor IoTs scenarios is presented. The proposed model is a two-layer feedforward neural network plus a random variable, characterizing the average RMS delay spread and uncertain shadowing effect, respectively. The neural network consists of five inputs, including transmitting/receiving antennas (Tx/Rx) separation, frequency, antenna height, environment, and line-of-sight/non-line-of-sight (LOS/NLOS) propagation condition, seven hidden layer neurons, and one output layer neuron. Compared with different configurations of the neural network, the hyperbolic tangent sigmoid functions and the Levenberg–Marquardt backpropagation algorithm are selected as neurons’ activation functions and training method, respectively. Additionally, the random variable is found to follow the normal distribution using the maximum-likelihood estimation. Finally, the novel model is experimentally validated to be accurate, general, and extensible compared with the conventional normally distributed RMS delay spread model. This model is well applicable to the design and planning of the ubiquitous communication links for future IoTs scenarios.","",""
24,"Tianyu Kang, W. Ding, Luoyan Zhang, D. Ziemek, Kourosh Zarringhalam","A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data",2017,"","","","",105,"2022-07-13 10:09:04","","10.1186/s12859-017-1984-2","","",,,,,24,4.80,5,5,5,"","",""
49,"Ying Shen, Yang Deng, Min Yang, Yaliang Li, Nan Du, Wei Fan, Kai Lei","Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs",2018,"","","","",106,"2022-07-13 10:09:04","","10.1145/3209978.3210081","","",,,,,49,12.25,7,7,4,"Ranking question answer pairs has attracted increasing attention recently due to its broad applications such as information retrieval and question answering (QA). Significant progresses have been made by deep neural networks. However, background information and hidden relations beyond the context, which play crucial roles in human text comprehension, have received little attention in recent deep neural networks that achieve the state of the art in ranking QA pairs. In the paper, we propose KABLSTM, a Knowledge-aware Attentive Bidirectional Long Short-Term Memory, which leverages external knowledge from knowledge graphs (KG) to enrich the representational learning of QA sentences. Specifically, we develop a context-knowledge interactive learning architecture, in which a context-guided attentive convolutional neural network (CNN) is designed to integrate knowledge embeddings into sentence representations. Besides, a knowledge-aware attention mechanism is presented to attend interrelations between each segments of QA pairs. KABLSTM is evaluated on two widely-used benchmark QA datasets: WikiQA and TREC QA. Experiment results demonstrate that KABLSTM has robust superiority over competitors and sets state-of-the-art.","",""
268,"Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh","Towards Robust Neural Networks via Random Self-ensemble",2017,"","","","",107,"2022-07-13 10:09:04","","10.1007/978-3-030-01234-2_23","","",,,,,268,53.60,67,4,5,"","",""
122,"Bowen Xu, Deheng Ye, Zhenchang Xing, Xin Xia, Guibin Chen, Shanping Li","Predicting semantically linkable knowledge in developer online forums via convolutional neural network",2016,"","","","",108,"2022-07-13 10:09:04","","10.1145/2970276.2970357","","",,,,,122,20.33,20,6,6,"Consider a question and its answers in Stack Overflow as a knowledge unit. Knowledge units often contain semantically relevant knowledge, and thus linkable for different purposes, such as duplicate questions, directly linkable for problem solving, indirectly linkable for related information. Recognising different classes of linkable knowledge would support more targeted information needs when users search or explore the knowledge base. Existing methods focus on binary relatedness (i.e., related or not), and are not robust to recognize different classes of semantic relatedness when linkable knowledge units share few words in common (i.e., have lexical gap). In this paper, we formulate the problem of predicting semantically linkable knowledge units as a multiclass classification problem, and solve the problem using deep learning techniques. To overcome the lexical gap issue, we adopt neural language model (word embeddings) and convolutional neural network (CNN) to capture word- and document-level semantics of knowledge units. Instead of using human-engineered classifier features which are hard to design for informal user-generated content, we exploit large amounts of different types of user-created knowledge-unit links to train the CNN to learn the most informative wordlevel and document-level features for the multiclass classification task. Our evaluation shows that our deep-learning based approach significantly and consistently outperforms traditional methods using traditional word representations and human-engineered classifier features.","",""
3,"Yuxuan Zhao, Jin Yang, Jinlong Lin, Dunshan Yu, Xixin Cao","A 3D Convolutional Neural Network for Emotion Recognition based on EEG Signals",2020,"","","","",109,"2022-07-13 10:09:04","","10.1109/IJCNN48605.2020.9207420","","",,,,,3,1.50,1,5,2,"As an important field of research in Human-Machine Interactions, emotion recognition based on the electroencephalography (EEG) signals has become common research. The traditional machine learning approaches use well-designed classifiers with hand-crafted features which may be limited to domain knowledge. Motivated by the outstanding performance of deep learning approaches in recognition tasks, we proposed a 3D convolutional neural network model to extract the spatial-temporal features automatically in the EEG signals. By the pre-processing method with baseline signals and the electrode topological structure relocated, the proposed model achieves a high accuracy rate of 96.61%, 96.43% in the Two class classification task (low/high arousal, low/high valence) and 93.53% in the Four class classification task (low arousal and low valence/high arousal and low valence/low arousal and high valence/high arousal and high valence) in the DEAP dataset, and 97.52%, 96.96% in the Two class classification task and 95.86% in the Four class classification task in the AMIGOS dataset.","",""
8,"Andrea E. Frank, A. Kubota, L. Riek","Wearable activity recognition for robust human-robot teaming in safety-critical environments via hybrid neural networks",2019,"","","","",110,"2022-07-13 10:09:04","","10.1109/IROS40897.2019.8968615","","",,,,,8,2.67,3,3,3,"In this work, we present a novel non-visual HAR system that achieves state-of-the-art performance on realistic SCE tasks via a single wearable sensor. We leverage surface electromyography and inertial data from a low-profile wearable sensor to attain performant robot perception while remaining unobtrusive and user-friendly. By capturing both convolutional and temporal features with a hybrid CNN-LSTM classifier, our system is able to robustly and effectively classify complex, full-body human activities with only this single sensor. We perform a rigorous analysis of our method on two datasets representative of SCE tasks, and compare performance with several prominent HAR algorithms. Results show our system substantially outperforms rival algorithms in identifying complex human tasks from minimal sensing hardware, achieving F1-scores up to 84% over 31 strenuous activity classes. To our knowledge, we are the first to robustly identify complex full-body tasks using a single, unobtrusive sensor feasible for real-world use in SCEs. Using our approach, robots will be able to more reliably understand human activity, enabling them to safely navigate sensitive, crowded spaces.","",""
3,"Shanlin Zhong, Junjie Zhou, Hong Qiao","Bioinspired Gain-Modulated Recurrent Neural Network for Controlling Musculoskeletal Robot.",2021,"","","","",111,"2022-07-13 10:09:04","","10.1109/TNNLS.2021.3071196","","",,,,,3,3.00,1,3,1,"The motor cortex can arouse abundant transient responses to generate complex movements with the regulation of neuromodulators, while its architecture remains unchanged. This characteristic endows humans with flexible and robust abilities in adapting to dynamic environments, which is exactly the bottleneck in the control of complex robots. In this article, inspired by the mechanisms of the motor cortex in encoding information and modulating motor commands, a biologically plausible gain-modulated recurrent neural network is proposed to control a highly redundant, coupled, and nonlinear musculoskeletal robot. As the characteristics observed in the motor cortex, this network is able to learn gain patterns for arousing transient responses to complete the desired movements, while the connections of synapses keep unchanged, and the dynamic stability of the network is maintained. A novel learning rule that mimics the mechanism of neuromodulators in regulating the learning process of the brain is put forward to learn gain patterns effectively. Meanwhile, inspired by error-based movement correction mechanism in the cerebellum, gain patterns learned from demonstration samples are leveraged as prior knowledge to improve calculation efficiency of the network in controlling novel movements. Experiments were conducted on an upper extremity musculoskeletal model with 11 muscles and a general articulated robot to perform goal-directed tasks. The results indicate that the gain-modulated neural network can effectively control a complex robot to complete various movements with high accuracy, and the proposed algorithms make it possible to realize fast generalization and incremental learning ability.","",""
1,"Nazanin Fouladgar, Marjan Alirezaie, Kary Främling","CN-waterfall: a deep convolutional neural network for multimodal physiological affect detection",2021,"","","","",112,"2022-07-13 10:09:04","","10.1007/s00521-021-06516-3","","",,,,,1,1.00,0,3,1,"","",""
0,"Ioannis E. Polykretis, Guangzhi Tang, Praveenram Balachandar, K. Michmizos","A Spiking Neural Network Mimics the Oculomotor System to Control a Biomimetic Robotic Head Without Learning on a Neuromorphic Hardware",2022,"","","","",113,"2022-07-13 10:09:04","","10.1109/TMRB.2022.3155278","","",,,,,0,0.00,0,4,1,"Facilitated by the emergence of neuromorphic hardware, neuromorphic algorithms mimic the brain’s asynchronous computation to improve energy efficiency, low latency, and robustness, which are crucial for a wide variety of real-time robotic applications. However, the limited on-chip learning abilities hinder the applicability of neuromorphic computing to real-world robotic tasks. Biomimetism can overcome this limitation by complementing or replacing training with the knowledge of the brain’s connectome associated with the targeted behavior. By drawing inspiration from the human oculomotor network, we designed a spiking neural network (SNN) that tracked visual targets in real-time. We deployed the biomimetic controller on Intel’s Loihi neuromorphic processor to control an in-house robotic head. The robot’s behavior resembled the smooth pursuit and saccadic eye movements observed in humans, while the SNN on Loihi exhibited similar performance to a CPU-run PID controller. Interestingly, this behavior emerged from the SNN without training, which places the biomimetic design as an alternative to the energy- and data-greedy learning-based methods. This work reinforces our on-going efforts to devise energy-efficient autonomous robots that mimic the robustness and versatility of their biological counterparts.","",""
0,"Soroush Mahjoubi, Fan Ye, Yi Bao, Weina Meng, Xian Zhang","Identification and classification of exfoliated graphene flakes from microscopy images using a hierarchical deep convolutional neural network",2022,"","","","",114,"2022-07-13 10:09:04","","10.48550/arXiv.2203.15252","","",,,,,0,0.00,0,5,1,"Identiﬁcation of the mechanically exfoliated graphene ﬂakes and classiﬁcation of the thickness is important in the nanomanufacturing of next-generation materials and devices that overcome the bottleneck of Moore’s Law. Currently, identiﬁcation and classiﬁcation of exfoliated graphene ﬂakes are conducted by human via inspecting the optical microscope images. The existing state-of-the-art automatic identiﬁcation by machine learning is not able to accommodate images with different backgrounds while different backgrounds are unavoidable in experiments. This paper presents a deep learning method to automatically identify and classify the thickness of exfoliated graphene ﬂakes on Si/SiO2 substrates from optical microscope images with various settings and background colors. The presented method uses a hierarchical deep convolutional neural network that is capable of learning new images while preserving the knowledge from previous images. The deep learning model was trained and used to classify exfoliated graphene ﬂakes into monolayer (1L), bi-layer (2L), tri-layer (3L), four-to-six-layer (4-6L), seven-to-ten-layer (7-10L), and bulk categories. Compared with existing machine learning methods, the presented method possesses high accuracy and efﬁciency as well as robustness to the backgrounds and resolutions of images. The results indicated that our deep learning model has accuracy as high as 99% in identifying and classifying exfoliated graphene ﬂakes. This research will shed light on scaled-up manufacturing and characterization of graphene for advanced materials and devices.","",""
5,"Ting-Bing Xu, Cheng-Lin Liu","Deep Neural Network Self-Distillation Exploiting Data Representation Invariance",2020,"","","","",115,"2022-07-13 10:09:04","","10.1109/TNNLS.2020.3027634","","",,,,,5,2.50,3,2,2,"To harvest small networks with high accuracies, most existing methods mainly utilize compression techniques such as low-rank decomposition and pruning to compress a trained large model into a small network or transfer knowledge from a powerful large model (teacher) to a small network (student). Despite their success in generating small models of high performance, the dependence of accompanying assistive models complicates the training process and increases memory and time cost. In this article, we propose an elegant self-distillation (SD) mechanism to obtain high-accuracy models directly without going through an assistive model. Inspired by the invariant recognition in the human vision system, different distorted instances of the same input should possess similar high-level data representations. Thus, we can learn data representation invariance between different distorted versions of the same sample. Especially, in our learning algorithm based on SD, the single network utilizes the maximum mean discrepancy metric to learn the global feature consistency and the Kullback–Leibler divergence to constrain the posterior class probability consistency across the different distorted branches. Extensive experiments on MNIST, CIFAR-10/100, and ImageNet data sets demonstrate that the proposed method can effectively reduce the generalization error for various network architectures, such as AlexNet, VGGNet, ResNet, Wide ResNet, and DenseNet, and outperform existing model distillation methods with little extra training efforts.","",""
3,"Hailin Wang, Ke Qin, R. Zakari, Guisong Liu, Guoming Lu","Deep neural network-based relation extraction: an overview",2021,"","","","",116,"2022-07-13 10:09:04","","10.1007/s00521-021-06667-3","","",,,,,3,3.00,1,5,1,"","",""
6,"Xueyuan She, Yun Long, S. Mukhopadhyay","Improving Robustness of ReRAM-based Spiking Neural Network Accelerator with Stochastic Spike-timing-dependent-plasticity",2019,"","","","",117,"2022-07-13 10:09:04","","10.1109/IJCNN.2019.8851825","","",,,,,6,2.00,2,3,3,"Spike-timing-dependent-plasticity (STDP) is an unsupervised learning algorithm for spiking neural network (SNN), which promises to achieve deeper understanding of human brain and more powerful artificial intelligence. While conventional computing system fails to simulate SNN efficiently, process-inmemory (PIM) based on devices such as ReRAM can be used in designing fast and efficient STDP based SNN accelerators, as it operates in high resemblance with biological neural network. However, the real-life implementation of such design still suffers from impact of input noise and device variation. In this work, we present a novel stochastic STDP algorithm that uses spiking frequency information to dynamically adjust synaptic behavior. The algorithm is tested in pattern recognition task with noisy input and shows accuracy improvement over deterministic STDP. In addition, we show that the new algorithm can be used for designing a robust ReRAM based SNN accelerator that has strong resilience to device variation.","",""
0,"","Neural Network Training Using Genetic Algorithms Series In Machine Perception And Artificial Intelligence",2021,"","","","",118,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,0,1,"Knowledge-Based Intelligent Information and Engineering Systems 2Nature-inspired Methods in Chemometrics: Genetic Algorithms and Artificial Neural NetworksParallel Implementations of Backpropagation Neural Networks on TransputersEvolutionary Algorithms and Neural NetworksTraining Neural Networks Using Hybrids with Genetic AlgorithmsNeural Network Training Using Genetic AlgorithmsGene Expression ProgrammingTraining a Neural Network with a Genetic AlgorithmMethods and Applications of Artificial IntelligenceClassification and Learning Using Genetic AlgorithmsPractical Computer Vision Applications Using Deep Learning with CNNsIntelligent Hybrid SystemsNeurogenetic LearningAdvances in Neural Networks ISNN 2007Hybrid Intelligent SystemsEncyclopedia of Computer Science and TechnologyMachine LearningUsing a Genetic Algorithm in Training an Artificial Neural Network to Implement the XOR FunctionGenetic and Evolutionary Computation — GECCO 2004Handbook of Fuzzy ComputationNeural Network Data Analysis Using SimulnetTMArtificial Neural Nets and Genetic AlgorithmsApplied Soft Computing Technologies: The Challenge of ComplexityGenetic Algorithm for Artificial Neural Network Training for the Purpose of Automated Part RecognitionNEURAL NETWORKS, FUZZY LOGIC AND GENETIC ALGORITHMAutomatic Generation of Neural Network Architecture Using Evolutionary ComputationPGANETThe Sixth International Symposium on Neural Networks (ISNN 2009)Evolutionary Machine Learning TechniquesModeling Decisions for Artificial IntelligenceEmpirical Studies on the Utility of Genetic Algorithms for Training and Designing of Neural NetworksTraining Neural Networks Using Genetic AlgorithmsTraining feedforward neural networks using genetic algorithmsMetaheuristic Procedures for Training Neural NetworksArtificial Neural Nets and Genetic AlgorithmsNature-Inspired Computing: Concepts, Methodologies, Tools, and ApplicationsApplications of Evolutionary ComputingArtificial Intelligence and CreativityArtificial Neural Nets and Genetic AlgorithmsDeep Learning Using Genetic Algorithms Creativity is one of the least understood aspects of intelligence and is often seen as `intuitive' and not susceptible to rational enquiry. Recently, however, there has been a resurgence of interest in the area, principally in artificial intelligence and cognitive science, but also in psychology, philosophy, computer science, logic, mathematics, sociology, and architecture and design. This volume brings this work together and provides an overview of this rapidly developing field. It addresses a range of issues. Can computers be creative? Can they help us to understand human creativity? How can artificial intelligence (AI) enhance human creativity? How, in particular, can it contribute to the `sciences of the artificial', such as design? Does the new wave of AI (connectionism, geneticism and artificial life) offer more promise in these areas than classical, symbol-handling AI? What would the implications be for AI and cognitive science if computers could not be creative? These issues are explored in five interrelated parts, each of which is introducted and explained by a leading figure in the field. Prologue (Margaret Boden) Part I: Foundational Issues (Terry Dartnall) Part II: Creativity and Cognition (Graeme S. Halford and Robert Levinson) Part III: Creativity and Connectionism (Chris Thornton) Part IV: Creativity and Design (John Gero) Part V: Human Creativity Enhancement (Ernest Edmonds) Epilogue (Douglas Hofstadter) For researchers in AI, cognitive science, computer science, philosophy, psychology, mathematics, logic, sociology, and architecture and design; and anyone interested in the rapidly growing field of artificial intelligence and creativity.From the contents: Neural networks – theory and applications: NNs (= neural networks) classifier on continuous data domains– quantum associative memory – a new class of neuron-like discrete filters to image processing – modular NNs for improving generalisation properties – presynaptic inhibition modelling for image processing application – NN recognition system for a curvature primal sketch – NN based nonlinear temporalspatial noise rejection system – relaxation rate for improving Hopfield network – Oja's NN and influence of the learning gain on its dynamics Genetic algorithms – theory and applications: transposition: a biological-inspired mechanism to use with GAs (= genetic algorithms) – GA for decision tree induction – optimising decision classifications using GAs – scheduling tasks with intertask communication onto multiprocessors by GAs – design of robust networks with GA – effect of degenerate coding on GAs – multiple traffic signal control using a GA – evolving musical harmonisation – niched-penalty approach for constraint handling in GAs – GA with dynamic population size – GA with dynamic niche clustering for multimodal function optimisation Soft computing and uncertainty: self-adaptation of evolutionary constructed decision trees by information spreading – evolutionary programming of near optimal NNsArtificial neural networks and genetic algorithms both are areas of research","",""
9,"Min Yang, Chengming Li, Ying Shen, Qingyao Wu, Zhou Zhao, Xiaojun Chen","Hierarchical Human-Like Deep Neural Networks for Abstractive Text Summarization",2020,"","","","",119,"2022-07-13 10:09:04","","10.1109/TNNLS.2020.3008037","","",,,,,9,4.50,2,6,2,"Developing an abstractive text summarization (ATS) system that is capable of generating concise, appropriate, and plausible summaries for the source documents is a long-term goal of artificial intelligence (AI). Recent advances in ATS are overwhelmingly contributed by deep learning techniques, which have taken the state-of-the-art of ATS to a new level. Despite the significant success of previous methods, generating high-quality and human-like abstractive summaries remains a challenge in practice. The human reading cognition, which is essential for reading comprehension and logical thinking, is still relatively new territory and underexplored in deep neural networks. In this article, we propose a novel Hierarchical Human-like deep neural network for ATS (HH-ATS), inspired by the process of how humans comprehend an article and write the corresponding summary. Specifically, HH-ATS is composed of three primary components (i.e., a knowledge-aware hierarchical attention module, a multitask learning module, and a dual discriminator generative adversarial network), which mimic the three stages of human reading cognition (i.e., rough reading, active reading, and postediting). Experimental results on two benchmark data sets (CNN/Daily Mail and Gigaword) demonstrate that HH-ATS consistently and substantially outperforms the compared methods.","",""
3,"R. Visser, J. Bathelt, H. Scholte, M. Kindt","Robust BOLD Responses to Faces But Not to Conditioned Threat: Challenging the Amygdala's Reputation in Human Fear and Extinction Learning",2021,"","","","",120,"2022-07-13 10:09:04","","10.1523/JNEUROSCI.0857-21.2021","","",,,,,3,3.00,1,4,1,"Most of our knowledge about human emotional memory comes from animal research. Based on this work, the amygdala is often labeled the brain's “fear center”, but it is unclear to what degree neural circuitries underlying fear and extinction learning are conserved across species. Neuroimaging studies in humans yield conflicting findings, with many studies failing to show amygdala activation in response to learned threat. Such null findings are often treated as resulting from MRI-specific problems related to measuring deep brain structures. Here we test this assumption in a mega-analysis of three studies on fear acquisition (n = 98; 68 female) and extinction learning (n = 79; 53 female). The conditioning procedure involved the presentation of two pictures of faces and two pictures of houses: one of each pair was followed by an electric shock [a conditioned stimulus (CS+)], the other one was never followed by a shock (CS–), and participants were instructed to learn these contingencies. Results revealed widespread responses to the CS+ compared with the CS– in the fear network, including anterior insula, midcingulate cortex, thalamus, and bed nucleus of the stria terminalis, but not the amygdala, which actually responded stronger to the CS–. Results were independent of spatial smoothing, and of individual differences in trait anxiety and conditioned pupil responses. In contrast, robust amygdala activation distinguished faces from houses, refuting the idea that a poor signal could account for the absence of effects. Moving forward, we suggest that, apart from imaging larger samples at higher resolution, alternative statistical approaches may be used to identify cross-species similarities in fear and extinction learning. SIGNIFICANCE STATEMENT The science of emotional memory provides the foundation of numerous theories on psychopathology, including stress and anxiety disorders. This field relies heavily on animal research, which suggests a central role of the amygdala in fear learning and memory. However, this finding is not strongly corroborated by neuroimaging evidence in humans, and null findings are too easily explained away by methodological limitations inherent to imaging deep brain structures. In a large nonclinical sample, we find widespread BOLD activation in response to learned fear, but not in the amygdala. A poor signal could not account for the absence of effects. While these findings do not disprove the involvement of the amygdala in human fear learning, they challenge its typical portrayals and illustrate the complexities of translational science.","",""
0,"Zhen Zhang, Xiaoyan Yu, Xianwei Rong, M. Iwata","Spatial-Temporal Neural Network for P300 Detection",2021,"","","","",121,"2022-07-13 10:09:04","","10.1109/access.2021.3132024","","",,,,,0,0.00,0,4,1,"P300 spellers are common brain-computer interface (BCI) systems designed to transfer information between human brains and computers. In most P300 detections, the P300 signals are collected by averaging multiple electroencephalographic (EEG) changes to the same target stimuli, so the participants are obliged to endure multiple repeated stimuli. In this study, a spatial-temporal neural network (STNN) based on deep learning (DL) is proposed for P300 detection. It detects P300 signals by combining the outputs from a temporal unit and a spatial unit. The temporal unit is a flexible framework consisting of several temporal modules designed for analyzing brain potential changes in the time domain. The spatial unit combines one-dimensional convolutions (Conv1Ds) and linear layers to generalize P300 features from the space domain, and it can decode EEG signals recorded using different numbers of electrodes. Both amyotrophic lateral sclerosis (ALS) patients and healthy subjects can benefit from this study. In the within-subject P300 detection and the cross-subject P300 detection, our approach gained higher performance with fewer repeated stimuli than other comparative approaches. Furthermore, we applied the proposed STNN in the P300 detection challenge of BCI Competition III. The accuracy score was 89% in the fifth round of repeated stimuli, outperforming the best result in the literature (accuracy = 80%) to the best of our knowledge. The results demonstrate that the proposed STNN performs well with limited stimuli and is robust enough for various P300 detections. Our model can be found at: https://github.com/Zhangzhenkut/STNN.","",""
15,"Wen-juan Wei, Bei Shi, Xin Guan, Jingyun Ma, Yachen Wang, Jing Liu","Mapping theme trends and knowledge structures for human neural stem cells: a quantitative and co-word biclustering analysis for the 2013–2018 period",2019,"","","","",122,"2022-07-13 10:09:04","","10.4103/1673-5374.257535","","",,,,,15,5.00,3,6,3,"Neural stem cells, which are capable of multi-potential differentiation and self-renewal, have recently been shown to have clinical potential for repairing central nervous system tissue damage. However, the theme trends and knowledge structures for human neural stem cells have not yet been studied bibliometrically. In this study, we retrieved 2742 articles from the PubMed database from 2013 to 2018 using “Neural Stem Cells” as the retrieval word. Co-word analysis was conducted to statistically quantify the characteristics and popular themes of human neural stem cell-related studies. Bibliographic data matrices were generated with the Bibliographic Item Co-Occurrence Matrix Builder. We identified 78 high-frequency Medical Subject Heading (MeSH) terms. A visual matrix was built with the repeated bisection method in gCLUTO software. A social network analysis network was generated with Ucinet 6.0 software and GraphPad Prism 5 software. The analyses demonstrated that in the 6-year period, hot topics were clustered into five categories. As suggested by the constructed strategic diagram, studies related to cytology and physiology were well-developed, whereas those related to neural stem cell applications, tissue engineering, metabolism and cell signaling, and neural stem cell pathology and virology remained immature. Neural stem cell therapy for stroke and Parkinson’s disease, the genetics of microRNAs and brain neoplasms, as well as neuroprotective agents, Zika virus, Notch receptor, neural crest and embryonic stem cells were identified as emerging hot spots. These undeveloped themes and popular topics are potential points of focus for new studies on human neural stem cells.","",""
101,"G. Ning, Zhi Zhang, Zhiquan He","Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation",2017,"","","","",123,"2022-07-13 10:09:04","","10.1109/TMM.2017.2762010","","",,,,,101,20.20,34,3,5,"Human pose estimation using deep neural networks aims to map input images with large variations into multiple body keypoints, which must satisfy a set of geometric constraints and interdependence imposed by the human body model. This is a very challenging nonlinear manifold learning process in a very high dimensional feature space. We believe that the deep neural network, which is inherently an algebraic computation system, is not the most efficient way to capture highly sophisticated human knowledge, for example those highly coupled geometric characteristics and interdependence between keypoints in human poses. In this work, we propose to explore how external knowledge can be effectively represented and injected into the deep neural networks to guide its training process using learned projections that impose proper prior. Specifically, we use the stacked hourglass design and inception-resnet module to construct a fractal network to regress human pose images into heatmaps with no explicit graphical modeling. We encode external knowledge with visual features, which are able to characterize the constraints of human body models and evaluate the fitness of intermediate network output. We then inject these external features into the neural network using a projection matrix learned using an auxiliary cost function. The effectiveness of the proposed inception-resnet module and the benefit in guided learning with knowledge projection is evaluated on two widely used human pose estimation benchmarks. Our approach achieves state-of-the-art performance on both datasets.","",""
3,"Artur Petrosyan, M. Sinkin, M. Lebedev, A. Ossadtchi","Decoding and interpreting cortical signals with a compact convolutional neural network",2021,"","","","",124,"2022-07-13 10:09:04","","10.1088/1741-2552/abe20e","","",,,,,3,3.00,1,4,1,"Objective. Brain–computer interfaces (BCIs) decode information from neural activity and send it to external devices. The use of Deep Learning approaches for decoding allows for automatic feature engineering within the specific decoding task. Physiologically plausible interpretation of the network parameters ensures the robustness of the learned decision rules and opens the exciting opportunity for automatic knowledge discovery. Approach. We describe a compact convolutional network-based architecture for adaptive decoding of electrocorticographic (ECoG) data into finger kinematics. We also propose a novel theoretically justified approach to interpreting the spatial and temporal weights in the architectures that combine adaptation in both space and time. The obtained spatial and frequency patterns characterizing the neuronal populations pivotal to the specific decoding task can then be interpreted by fitting appropriate spatial and dynamical models. Main results. We first tested our solution using realistic Monte-Carlo simulations. Then, when applied to the ECoG data from Berlin BCI competition IV dataset, our architecture performed comparably to the competition winners without requiring explicit feature engineering. Using the proposed approach to the network weights interpretation we could unravel the spatial and the spectral patterns of the neuronal processes underlying the successful decoding of finger kinematics from an ECoG dataset. Finally we have also applied the entire pipeline to the analysis of a 32-channel EEG motor-imagery dataset and observed physiologically plausible patterns specific to the task. Significance. We described a compact and interpretable CNN architecture derived from the basic principles and encompassing the knowledge in the field of neural electrophysiology. For the first time in the context of such multibranch architectures with factorized spatial and temporal processing we presented theoretically justified weights interpretation rules. We verified our recipes using simulations and real data and demonstrated that the proposed solution offers a good decoder and a tool for investigating motor control neural mechanisms.","",""
15,"S. Mahdavifar, A. Ghorbani","DeNNeS: deep embedded neural network expert system for detecting cyber attacks",2020,"","","","",125,"2022-07-13 10:09:04","","10.1007/s00521-020-04830-w","","",,,,,15,7.50,8,2,2,"","",""
8,"Lorena Guachi, R. Guachi, F. Bini, F. Marinozzi","Automatic Colorectal Segmentation with Convolutional Neural Network",2018,"","","","",126,"2022-07-13 10:09:04","","10.14733/CADCONFP.2018.312-316","","",,,,,8,2.00,2,4,4,"Introduction: In the recent years, modern medicine uses image processing technique, such as image segmentation in Computer Aided Diagnosis System (CAD) in order to reduce the dependence of diagnosis by doctors’ knowledge and experience, as well as to locate the prior tissue lesions timely and effectively [6]. Medical image segmentation uses several imaging modalities (MRI, Computed Tomography (CT), Positron Emission Tomography (PET), X-RAY, Ultrasound). However, it is a challenge yet, due to added noise, artifacts, limitations, and unclear edges [8]. In this way, colon tissues segmentation in human abdominal CT images is the base of analysis and identification of cancer nidus, providing powerful information in a CAD, such as early polyps detection, which can reduce the incidence of colon cancer [3],[6],[14]. Colon segmentation techniques can also be used in colorectal tissues simulations to make preoperative plans and simulations of surgery [4]. Some colon segmentation algorithms are introduced in literature, each one having its own model, computational complexity, and overall quality. Such as Local region based active contours [6], which is based on local statistics of tissue of interest and background, instead of global statistics. In [15], an isotropic volume reconstructed from the CT images is used to extract a thick region encompassing the entire colon, where mean curvature, dimensionless ratio sphericity and minimum polyp size are used as parameters to filter anomalies and reduce false positives. Classifications of multispectral colorectal cancer tissues [5], classify tissues samples using convolutional neural network (CNN) and uses active contours technique to extract colorectal regions corresponding to pathological tissues. Although some works presented in literature have demonstrated how CNN provides effective results to analyze colon images, those works are based on the segmentation image regions containing pathological colorectal tissues [5],[7], and glandular colon structure [10]. On the contrary, the analysis of colon tissues as pre-processing task for applications, as tissues simulations, is our motivation to challenge the use of pixel-wise segmentation with CNN. In order to overcome the problem of misclassifying colon tissue pixels, in this paper, we propose a method for automatic colon tissues segmentation based on spatial features learned with CNN. The proposed method has been compared to three state-of-the-art methods. Preliminary experimental results demonstrate the proposed method achieves a higher robustness in terms of sensitivity and similarity, and reduces the number of misclassified colon tissue pixels.","",""
1,"Liping Zhang","An intelligent information retrieval algorithm based on knowledge discovery and self-organizing feature map neural network",2016,"","","","",127,"2022-07-13 10:09:04","","10.1109/INVENTIVE.2016.7830120","","",,,,,1,0.17,1,1,6,"Information retrieval is usually referring to the text information retrieval, including information storage, organization, performance, many aspects, such as query, access and its core is the text indexing and retrieval of information. Under the trend of intelligent data analysis and mining, in this paper, we propose a novel information retrieval algorithm based on knowledge discovery and self-organizing feature map neural network. Knowledge discovery is one of the major intellectual activities of human, the current knowledge discovery activities are increasingly based on network data resources and environment. Enhance semantic correlation method, that is, on the basis of the existing association, found the correlation between the data source, a new connection between different sources of data, or further connection, this process is the process of knowledge discovery activities. For enhancement, we introduce the self-organizing feature map neural network into the method to integrate the semantic information. Since Kohonen self-organizing neural network is put forward, the self-organizing feature map algorithm as a kind of very effective clustering method, in the vector quantization and pattern recognition has been widely research and application. With the reasonable of the mentioned techniques, we propose the enhanced retrieval algorithm. The experimental simulation proves that our method obtains higher robustness and accuracy compared with the other state-of-the-art algorithms.","",""
2,"Simone Dari, Nikolay Kadrileev, E. Hüllermeier","A Neural Network-Based Driver Gaze Classification System with Vehicle Signals",2020,"","","","",128,"2022-07-13 10:09:04","","10.1109/IJCNN48605.2020.9207709","","",,,,,2,1.00,1,3,2,"Driver monitoring can play an essential part in avoiding accidents by warning the driver and shifting the driver’s attention to the traffic scenery in time during critical situations. This may apply for the different levels of automated driving, for take-over requests as well as for driving in manual mode. A great proxy for this purpose has always been the driver’s gazing direction. The aim of this work is to introduce a robust gaze detection system. In this regard, we make several contributions that are novel in the area of gaze detection systems. In particular, we propose a deep learning approach to predict gaze regions, which is based on informative features such as eye landmarks and head pose angles of the driver. Moreover, we introduce different post-processing techniques that improve the accuracy by exploiting temporal information from videos and the availability of other vehicle signals. Last but not least, we confirm our method with a leave-one-driver-out cross-validation. Unlike previous studies, we do not use gazes to predict maneuver changes, but we consider the human-computer-interaction aspect and use vehicle signals to improve the performance of the estimation. The proposed system is able to achieve an accuracy of 92.3% outperforming earlier landmark-based gaze estimators.","",""
8,"Yi Yang, F. Chen, Xiaoming Chen, Yan Dai, Zhenyang Chen, Jiang Ji, Tong Zhao","Video system for human attribute analysis using compact convolutional neural network",2016,"","","","",129,"2022-07-13 10:09:04","","10.1109/ICIP.2016.7532424","","",,,,,8,1.33,1,7,6,"Convolutional neural networks show their advantage in human attribute analysis (e.g. age, gender and ethnicity). However, they experience issues (e.g. robustness and responsiveness) when deployed in an intelligent video system. We propose one compact CNN model and apply it in our video system motivated by the full consideration of performance and usability. With the proposed web image mining and labelling strategy, we construct a large training set which covers various image conditions. The proposed CNN model successfully achieves a mean absolute error (MAE) of 3.23 years on the Morph 2 dataset, using the same test policy as our counterparts. This is the state-of-the-art score to our knowledge using CNN for age estimation. The proposed video analysis system employs this compact CNN model and demonstrated good performance in both dataset tests and deployment in real-world environments.","",""
1,"M. H. Mozaffari, Chanho Kim, Won-sook Lee","Ultrasound Tongue Contour Extraction using Dilated Convolutional Neural Network",2019,"","","","",130,"2022-07-13 10:09:04","","10.1109/BIBM47256.2019.8983002","","",,,,,1,0.33,0,3,3,"One application of medical ultrasound imaging is to visualize and characterize human tongue shape and motion to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it requires knowledge about the tongue structure and ultrasound data interpretation for users to recognize tongue gestures. Moreover, quantitative analysis of tongue motion needs the tongue contour to be extracted, tracked and visualized automatically. This paper presents two novel deep neural networks that benefit from the ability of global prediction of encoding-decoding fully convolutional networks and the capability of full-resolution extraction of dilated convolutions. Assessment studies over datasets from different ultrasound machines disclosed the outstanding performances of the proposed models in terms of accuracy and robustness.","",""
8,"S. Saha, Rimita Lahiri, A. Konar, Bonny Banerjee, A. Nagar","Human skeleton matching for e-learning of dance using a probabilistic neural network",2016,"","","","",131,"2022-07-13 10:09:04","","10.1109/IJCNN.2016.7727411","","",,,,,8,1.33,2,5,6,"With the growing interest in the domain of human computer interaction (HCI) these days, budding research professionals are coming up with novel ideas of developing more versatile and flexible modes of communication between a man and a machine. Using the attributes of internet, the scientists have been able to create a web based social platform for learning any desired art by the subject himself/herself, and this particular procedure is termed as electronic learning or e-learning. In this paper, we propose a novel application of gesture dependent e-learning of dance. This e-learning procedure may provide help to many dance enthusiasts who cannot learn the art because of the scarcity of resources despite having great zeal. The paper mainly deals with recognition of different dance gestures of a trained user such that after detecting the discrepancies between the gestures shown and actually performed by a novice; the user can rectify his faults. The elementary knowledge of geometry has been employed to introduce the concept of planes in the feature extraction stage. Actually, five planes have been constructed to signify major body parts while keeping the synchronous parts in one unit. Then four distances and four angular features have been obtained to provide entire positional information of the different body joints. Finally, using a probabilistic neural network the dance gestures have been classified after training the said network with sufficient amount of data recorded from numerous subjects to maintain generality.","",""
0,"Srungeer Simha, J. Goudswaard, P. Devarakota, P. Somawanshi","Neural Network Assisted Seismic Velocity Editing",2019,"","","","",132,"2022-07-13 10:09:04","","10.2118/197919-ms","","",,,,,0,0.00,0,4,3,"  Normal Move-Out (NMO) velocity pick editing is the segregation of good and bad picks from an unsupervised auto-picking algorithm. As not all these picks are correct, manual velocity editing is required. This is time consuming, repetitive and typically requires a seismic expert for days to weeks. Automating it would require an algorithm that mimics the domain knowledge and expertise of a seismic processor; a deterministic approach would therefore likely fail. Alternatively, we propose a machine learning algorithm to identify valid time-velocity picks.  The proposed approach is a supervised classification approach which utilizes human interpreted velocity picks (1-5% of all picks) as training data. The algorithm learns to recognize the features of a valid velocity pick from metadata such as semblance energy, depth, areal location etc. and utilizes said understanding to segregate valid picks from invalid ones (multiples etc.) amongst the remaining velocity picks. The algorithm has been trained using synthetic NMO picks created by finite-difference forward modelling CMP data, including multiples, in the Marmousi model and auto-picking the move-out. The ground-truth NMO picks were created directly from the velocity model.  The trained classification neural network shows a very high > 97% accuracy on segregation of valid and invalid NMO velocity picks based on a 5% input data set. Further reduction of the training data set to 1% of velocity picks reduces test accuracy only by an additional 2 percentage points. Training and execution time of the neural network on a dataset of ~ 40000 velocity picks are also extremely fast (< 5 mins). Initial results on RMO picks also show a very similar performance characteristic.  The metadata for all valid picks spans a multi-dimensional feature space, from which the neural network constructs a non-linear selection criterion. A human can either manually QC each pick or perform attribute-based selection using only lower dimensional linear selection criteria. The robustness and speed of the neural network outperforms the manual editing while also reducing cycle time; the resulting velocity models will be superior, leading to improved signal processing and imaging results further in the processing sequence.  Automating velocity picking and editing has been a research objective for many years now, but only since the availability of modern computation and optimization algorithms can we properly deploy this to augment the high-quality modern velocity picking software and significantly decrease turn-around time by automating the picking and QC process.","",""
2,"Yichuan Zhang, Yixing Lan, Qiang Fang, Xin Xu, Junxiang Li, Yujun Zeng","Efficient Reinforcement Learning from Demonstration via Bayesian Network-Based Knowledge Extraction",2021,"","","","",133,"2022-07-13 10:09:04","","10.1155/2021/7588221","","",,,,,2,2.00,0,6,1,"Reinforcement learning from demonstration (RLfD) is considered to be a promising approach to improve reinforcement learning (RL) by leveraging expert demonstrations as the additional decision-making guidance. However, most existing RLfD methods only regard demonstrations as low-level knowledge instances under a certain task. Demonstrations are generally used to either provide additional rewards or pretrain the neural network-based RL policy in a supervised manner, usually resulting in poor generalization capability and weak robustness performance. Considering that human knowledge is not only interpretable but also suitable for generalization, we propose to exploit the potential of demonstrations by extracting knowledge from them via Bayesian networks and develop a novel RLfD method called Reinforcement Learning from demonstration via Bayesian Network-based Knowledge (RLBNK). The proposed RLBNK method takes advantage of node influence with the Wasserstein distance metric (NIW) algorithm to obtain abstract concepts from demonstrations and then a Bayesian network conducts knowledge learning and inference based on the abstract data set, which will yield the coarse policy with corresponding confidence. Once the coarse policy's confidence is low, another RL-based refine module will further optimize and fine-tune the policy to form a (near) optimal hybrid policy. Experimental results show that the proposed RLBNK method improves the learning efficiency of corresponding baseline RL algorithms under both normal and sparse reward settings. Furthermore, we demonstrate that our RLBNK method delivers better generalization capability and robustness than baseline methods.","",""
86,"Yilong Yang, Qingfeng Wu, Ming Qiu, Yingdong Wang, Xiaowei Chen","Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",2018,"","","","",134,"2022-07-13 10:09:04","","10.1109/IJCNN.2018.8489331","","",,,,,86,21.50,17,5,4,"As a challenging pattern recognition task, automatic real-time emotion recognition based on multi-channel EEG signals is becoming an important computer-aided method for emotion disorder diagnose in neurology and psychiatry. Traditional machine learning approaches require to design and extract various features from single or multiple channels based on comprehensive domain knowledge. Consequently, these approaches may be an obstacle for non-domain experts. On the contrast, deep learning approaches have been used successfully in many recent literatures to learn features and classify different types of data. In this paper, baseline signals are considered and a simple but effective pre-processing method has been proposed to improve the recognition accuracy. Meanwhile, a hybrid neural network which combines `Convolutional Neural Network (CNN)’ and `Recurrent Neural Network (RNN)’ has been applied to classify human emotion states by effectively learning compositional spatial-temporal representation of raw EEG streams. The CNN module is used to mine the inter-channel correlation among physically adjacent EEG signals by converting the chain-like EEG sequence into 2D-like frame sequence. The LSTM module is adopted to mine contextual information. Experiments are carried out in a segment-level emotion identification task, on the DEAP benchmarking dataset. Our experimental results indicate that the proposed pre-processing method can increase emotion recognition accuracy by 32% approximately and the model achieves a high performance with a mean accuracy of 90.80% and 91.03% on valence and arousal classification task respectively.","",""
2,"Ao Luo, F. Yang, Xin Li, Yuezun Li, Z. Jiao, Hong Cheng, Siwei Lyu","Robust Scene Parsing by Mining Supportive Knowledge From Dataset.",2021,"","","","",135,"2022-07-13 10:09:04","","10.1109/TNNLS.2021.3107194","","",,,,,2,2.00,0,7,1,"Scene parsing, or semantic segmentation, aims at labeling all pixels in an image with the predefined categories of things and stuff. Learning a robust representation for each pixel is crucial for this task. Existing state-of-the-art (SOTA) algorithms employ deep neural networks to learn (discover) the representations needed for parsing from raw data. Nevertheless, these networks discover desired features or representations only from the given image (content), ignoring more generic knowledge contained in the dataset. To overcome this deficiency, we make the first attempt to explore the meaningful supportive knowledge, including general visual concepts (i.e., the generic representations for objects and stuff) and their relations from the whole dataset to enhance the underlying representations of a specific scene for better scene parsing. Specifically, we propose a novel supportive knowledge mining module (SKMM) and a knowledge augmentation operator (KAO), which can be easily plugged into modern scene parsing networks. By taking image-specific content and dataset-level supportive knowledge into full consideration, the resulting model, called knowledge augmented neural network (KANN), can better understand the given scene and provide greater representational power. Experiments are conducted on three challenging scene parsing and semantic segmentation datasets: Cityscapes, Pascal-Context, and ADE20K. The results show that our KANN is effective and achieves better results than all existing SOTA methods.","",""
59,"H. Moayedi, Mansour Mosallanezhad, A. S. Rashid, Wan Amizah Wan Jusoh, M. A. Muazu","A systematic review and meta-analysis of artificial neural network application in geotechnical engineering: theory and applications",2019,"","","","",136,"2022-07-13 10:09:04","","10.1007/s00521-019-04109-9","","",,,,,59,19.67,12,5,3,"","",""
52,"Kasun Amarasinghe, K. Kenney, M. Manic","Toward Explainable Deep Neural Network Based Anomaly Detection",2018,"","","","",137,"2022-07-13 10:09:04","","10.1109/HSI.2018.8430788","","",,,,,52,13.00,17,3,4,"Anomaly detection in industrial processes is crucial for general process monitoring and process health assessment. Deep Neural Networks (DNNs) based anomaly detection has received increased attention in recent work. Albeit their high accuracy, the black-box nature of DNNs is a drawback in practical deployment. Especially in industrial anomaly detection systems, explanations of DNN detected anomalies are crucial. This paper presents a framework for DNN based anomaly detection which provides explanations of detected anomalies. The framework answers the following questions during online processing: 1) “why is it an anomaly?” and 2) “what is the confidence?” Further, the framework can be used offline to evaluate the “knowledge” of the trained DNN. The framework reduces the opaqueness of the DNN based anomaly detector and thus improves human operators' trust in the algorithm. This paper implements the first steps of the presented framework on the benchmark KDD-NSL dataset for Denial of Service (DoS) attack detection. Offline DNN explanations showed that the DNN was detecting DoS attacks based on features indicating destination of connection, frequency and amount of data transferred while showing an accuracy around 97%.","",""
0,"U. Cnrs","Neural Network and Wavelet Multiresolution System for Human Being Detection",2017,"","","","",138,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,5,"ABSTRACT Many applications, in robotics, require identification of human being. Using complex methods, based on modelmatching are too computationally expensive and not always justified. We propose a fast and simple method for identification of human being. This method takes profit of the learning capabilities of a neural network. The idea is to train a neural network on some images of persons. In order to reduce the amount of this data (images), we use waveletmultiresolution propriety analysis that allows to bring significant information content of image. This one thus ischaracterised by its approximation at a given resolution. After the training phase, the generalization capabilities of the network allow it to identify no-learned images.We describe here the proposed method, and we present experimental results obtained on a data base of 437 images.Key words: Segmentation - Neural Network -Identification-Image Processing-Wavelet Multiresolution. 1. INTRODUCTION Human is able to localise and identify a human being very quickly, in different situations and with a good reliability.This capability is very robust: this one resists to important image changes due to modification of point of view or lightingconditions, etc....That why, the visual analysis by the humans has fascinated a lot of scientifics like Aristote or Darwin,since centuries. The automatic detection systems are interesting by theory knowledge that they will can bring to us aboutthe visual human system. But they have a lot of practical applications like: perception of autonomous vehicles, controlaccess (banks,..), etc.The connexionist models (neural networks) give a panoply of methods for classification, event detection and signal","",""
3,"Ritabrata Sanyal, K. Chakrabarty","Two Stream Deep Convolutional Neural Network for Eye State Recognition and Blink Detection",2019,"","","","",139,"2022-07-13 10:09:04","","10.1109/IEMENTech48150.2019.8981102","","",,,,,3,1.00,2,2,3,"Eye state recognition and blink detection has been an important research problem in various fields like driver fatigue and drowsiness measurement, dry eye detection, video spoofing detection, psychological status analysis and many others. Hence an automated eye state classification and blink detection algorithm which is robust to a variety of conditions is required for this purpose. To this end, we propose a novel approach towards detection of eye blinks from a video stream by classifying the eye state of every frame as open or closed. First the eyes are localized from a frame with robust state-of-the-art facial landmark detectors. Then binary masks of the eyes are computed to capture and focus on how much the eyes are open. We propose a novel two stream convolutional neural network model which is jointly trained with the extracted eye patches, their masks as inputs and the corresponding eye state as output. With the eye state predicted by our network for every frame, we model a Finite State Machine to check for blinks by comparing number of consecutive frames with eyes closed against average human blink duration. Extensive experimentation has been done on a various number of popular benchmark datasets both for eye state classification and blink detection. Our proposed eye state classifier achieves a 3.2% and 3.86% improvement over the state-of-the-art in terms of accuracy and equal error rate (EER). The blink detector achieves a 1–2 % improvement over the state-of-the-art in terms of precision and recall. Hence our algorithm outperforms the existing methods for eye state classification and blink detection to the best of our knowledge.","",""
74,"Hong Liu, Juanhui Tu, Mengyuan Liu","Two-Stream 3D Convolutional Neural Network for Skeleton-Based Action Recognition",2017,"","","","",140,"2022-07-13 10:09:04","","","","",,,,,74,14.80,25,3,5,"It remains a challenge to efficiently extract spatialtemporal information from skeleton sequences for 3D human action recognition. Although most recent action recognition methods are based on Recurrent Neural Networks which present outstanding performance, one of the shortcomings of these methods is the tendency to overemphasize the temporal information. Since 3D convolutional neural network(3D CNN) is a powerful tool to simultaneously learn features from both spatial and temporal dimensions through capturing the correlations between three dimensional signals, this paper proposes a novel two-stream model using 3D CNN. To our best knowledge, this is the first application of 3D CNN in skeleton-based action recognition. Our method consists of three stages. First, skeleton joints are mapped into a 3D coordinate space and then encoding the spatial and temporal information, respectively. Second, 3D CNN models are seperately adopted to extract deep features from two streams. Third, to enhance the ability of deep features to capture global relationships, we extend every stream into multitemporal version. Extensive experiments on the SmartHome dataset and the large-scale NTU RGB-D dataset demonstrate that our method outperforms most of RNN-based methods, which verify the complementary property between spatial and temporal information and the robustness to noise.","",""
1,"J. Constantin, A. Bigand, I. Constantin","Pooling spike neural network for fast rendering in global illumination",2019,"","","","",141,"2022-07-13 10:09:04","","10.1007/s00521-018-3941-z","","",,,,,1,0.33,0,3,3,"","",""
0,"Farhat Roohi","FUZZY CLUSTERING THROUGH NEURAL NETWORK",2018,"","","","",142,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,4,"Management of data has always been a key concern for scientist, scholars and industry alike. But information explosion due to information and communication technology boom has resulted in a world overloaded with data and information that too growing at an ever increasing exponential rate. Analyzing such big data requires robust techniques to first classify the data so the further analysis reduced to some manageable group of data. This way it becomes systematic and easy. But grouping of data comes at a cost of accuracy and precision of information, as group analysis works on averages and distance between data points within and between clusters is also a cause of concern. Therefore it is imperative to have such data clustering techniques which are fast, able to handle big data and classify data as per the natural logic to facilitate the process of finding knowledge hidden in the data. Fuzzy logic and artificial neural networks are such two concepts which have found increasing application in classification and clustering techniques which have made them more realistic accurate and precise. As such, apart from data clustering, neurofuzzy methodology is widely used in data mining, artificial intelligence, image recognition, knowledge management, control processes, etc. Neurofuzzy methodology performs better in terms finding sequences, associations and patterns in data besides having quick self-learning capability almost comparable to human intelligence. Against this backdrop the current paper attempts to create a conceptual understanding of neurofuzzy methodology and its application to data clustering.","",""
2,"Dongcheng Zhao, Yang Li, Yi Zeng, Jihang Wang, Qian Zhang","Spiking CapsNet: A Spiking Neural Network With A Biologically Plausible Routing Rule Between Capsules",2021,"","","","",143,"2022-07-13 10:09:04","","","","",,,,,2,2.00,0,5,1,"Spiking neural network (SNN) has attracted much attention due to their powerful spatio-temporal information representation ability. Capsule Neural Network (CapsNet) does well in assembling and coupling features at different levels. Here, we propose Spiking CapsNet by introducing the capsules into the modelling of spiking neural networks. In addition, we propose a more biologically plausible Spike Timing Dependent Plasticity routing mechanism. By fully considering the spatio-temporal relationship between the lowlevel spiking capsules and the high-level spiking capsules, the coupling ability between them is further improved. We have verified experiments on the MNIST and FashionMNIST datasets. Compared with other excellent SNN models, our algorithm still achieves high performance. Our Spiking CapsNet fully combines the strengthens of SNN and CapsNet, and shows strong robustness to noise and affine transformation. By adding different Salt-Pepper and Gaussian noise to the test dataset, the experimental results demonstrate that our Spiking CapsNet shows a more robust performance when there is more noise, while the artificial neural network can not correctly clarify. As well, our Spiking CapsNet shows strong generalization to affine transformation on the AffNIST dataset. Introduction Convolutional Neural Networks (CNNs) have obtained tremendous success in various domains, such as object classification (He et al. 2016), visual tracking (Danelljan et al. 2015), object segmentation (Chen et al. 2017), and so on due to the powerful feature representation ability. However, there still exist several limitations associated with CNNs. First, high-level features are obtained by low-level weighting features while ignoring the spatial relationship between them. A face is just a simple combination of the features of eyes, nose, and mouth. Even if the positions of these features change relatively, the classifier will still consider it to be a face. Secondly, the commonly used pooling operation *These authors contributed equally. Corresponding Author. is destructive to the spatial relationship. To tackle the problems, CapsNet (Sabour, Frosst, and Hinton 2017; Hinton, Sabour, and Frosst 2018) proposes the concept of capsules, which uses the vector or matrix instead of values to encode the information. It uses a group of neurons to denote more properties. Each neuron provides a scalar output that represents the attributes of the corresponding feature, such as position, color, and texture. The length of the vector represents the probability of these properties. In addition to the capsule concept, the routing scheme is used to ensure the output of the lower-capsule to the closely related higher-capsule. Although CapsNet mimics the multi-layer visual system with a parse tree-like structure, it is still far from the human brain’s information processing mechanism. Considered as the third-generation artificial neural network, the spiking neural networks (SNNs) (Roy, Jaiswal, and Panda 2019; Kim et al. 2019; Thiele et al. 2019; Zhang et al. 2019b), use the discrete spikes to transfer information, which is more biologically plausible and more energy efficient. The SNNs present strong sparsity and neurons that do not emit spikes do not update the network weights. In recent years, SNNs have significantly facilitated the development of event-based neuromorphic hardware platforms(Pei et al. 2019), showing desired low latency and high efficiency. On the other hand, due to the spike encoding mechanism, the SNNs are very robust to the input disturbance and have shown excellent performance in terms of anti-noise(Cheng et al. 2020; Chowdhury, Lee, and Roy 2020; Zhang et al. 2019a; Li et al. 2020; Uysal, Sathyendra, and Harris 2007). Many traditional SNN structures are inspired by brain area connections to imitate certain brain area functions. Still, it is hard to expand to a deeper network structure due to its complex network connections (Zhao et al. 2020b; Zhao, Zeng, and Xu 2018; Fang, Zeng, and Zhao 2021). To carry out more complex tasks, the feedforward fully connected structure is introduced (Zhang et al. 2018; Sun, Zeng, and Zhang 2021) to transmit information in the form of a fully connected way. However, this connection method will cause excessive parameters and overfitting, which is difficult to extend to deeper neural networks and more complex tasks. To tackle the problems, ar X iv :2 11 1. 07 78 5v 1 [ cs .N E ] 1 5 N ov 2 02 1 GLSNN (Zhao et al. 2020a) introduces the feedback connections to transfer the global error to the hidden layers to get the corresponding target. Combining with the local synaptic plasticity learning rules, the performance and stability are further improved. Convolutional neural networks have attracted wide attention due to their superior feature extraction capabilities. Recent works (Wu et al. 2018, 2019; Jin, Zhang, and Li 2018; Zhang and Li 2020) introduce the convolutional structures into the modelling of SNNs. The parameter sharing mechanism of convolutions dramatically reduces the number of parameters and can further deepen the structure of the SNNs and improve the performance of complex tasks. LISNN (Cheng et al. 2020) further enhances the performance of the SNNs and their robustness to noise by introducing the lateral connections. BackEISNN (Zhao, Zeng, and Li 2021) has demonstrated superior performance on multiple datasets by introducing self-feedback connections and the excitatory-inhibitory neurons. However, these structures all use pooling operations to ensure translation invariance, leading to the spatial information loss. To tackle the problems mentioned above, we introduce the capsule structure in the spiking neural network, so as to take full advantage of the spatial and temporal characteristics. In the capsule neural network domains, much work is integrated into the modelling of routing mechanisms, which can be roughly divided into two categories, the supervised and the unsupervised. For the unsupervised ones, the dynamic routing (Sabour, Frosst, and Hinton 2017) uses the inner product to denote the agreement. Furthermore, the vector capsule is replaced with the matrix, and the modified EM-algorithm is used to model the agreement between capsules (Hinton, Sabour, and Frosst 2018). The group equivariant capsule networks (Lenssen, Fey, and Libuschewski 2018) present a generic routing by agreement algorithm defined on elements of a group. (Choi et al. 2019) proposes a fast forward pass routing with attention modules to keep spatial attention. Riberio et al. (Ribeiro, Leontidis, and Kollias 2020) propose a routing algorithm derived from Variational Bayes to fit a gaussian mixture model. In (Tsai et al. 2020)’s work, the routing procedure resembles an inverted attention algorithm. (Zhang et al. 2021) generalizes the existing routing methods within the framework of weighted kernel density estimation. Efficient-CapsNet (Mazzia, Salvetti, and Chiaberge 2021) replaces the dynamic routing with a novel noniterative, highly parallelizable self-attention routing. For the supervised ones, Wang et al. (Wang and Liu 2018) formulate the routing strategy as an optimization problem that minimizes the distance between the current coupling distribution and its last states. (Li et al. 2018) approximates the routing process with a master and an aide branch to communicate in a fast, supervised, and one-time pass fashion. G-CapsNet (Chen and Crandall 2018) embeds the routing procedure into the optimization procedure and makes the coefficients trainable. Self-Routing (Hahn, Pyeon, and Kim 2019) routes each capsule independently by its subordinate routing network. STAR-CAPS (Ahmed and Torresani 2019) designs a straight-through attentive routing by utilizing attention modules augmented by differentiable binary routers. GF-CapsNet (Ding et al. 2020) adopts a supervised group-routing to equally spilled capsules into groups to reduce routing parameters. Both the supervised and the unsupervised ones only consider the spatial relationship between capsules while ignoring the temporal relationship. This paper adopts the biologically plausible Spike Timing Dependent Plasticity (STDP) (Bi and Poo 1998; Diehl and Cook 2015) for dynamic routing between the spiking capsules, which fully considers the causal relationship between capsules and significantly improves routing efficiency. This paper proposes the Spiking CapsNet, which can combine the characteristics of the capsule neural network and the spiking neural network well. And our contributions can be summarized below. • To our best knowledge, this is the first work to introduce the capsule structures into the modelling of SNNs, which can combine their rich spatio-temporal information processing capabilities. • We introduce a more biological routing algorithm between the spiking capsules to optimize the relationship between capsules in both spatial and temporal domains. The routing algorithm fully considers the spatial relationship between the part and the whole and the causality of the spike sequences in temporal domains. • The experimental results show that our proposed Spiking CapsNet does well on the MNIST and FashionMNIST datasets compared with the current best SNN. It can achieve the best noise robustness under different SaltPepper noise intensities and different variance of Gaussian noise. As well as, it shows excellent generalization and invariance to affine-transformations. Methods This section will introduce the learning and inference process of our proposed Spiking CapsNet in detail. Firstly, we describe the spiking neuron model, followed by the description of the capsule operation process, which is very different from the traditional value-based operation. Then, we will give a detailed description of our STDP routing mechanism. Finally, the introduction of the whole Spiking CapsNet will be given. Spiking Neuron Model","",""
2,"V. Bahrami, A. Kalhor, M. T. Masouleh","Dynamic model estimating and designing controller for the 2-DoF planar robot in interaction with cable-driven robot based on adaptive neural network",2021,"","","","",144,"2022-07-13 10:09:04","","10.3233/JIFS-210180","","",,,,,2,2.00,1,3,1,"This study intends to investigate the dynamic model estimation and the design of an adaptive neural network based controller for a passive planar robot, performing 2-DoF motion pattern which is in interaction with an actuated cable-driven robot. In fact, the main goal of applying this structure is to use a number of light cables to drive serial robot links and track the desired reference model by the robot’s end-effector. The under study system can be used as a rehabilitation setup which is helpful for those with arm disability. In this way, upon applying sliding mode error dynamics, it is necessary to determine a vector that contains the matrices related to the robot dynamics. However, finding these matrices requires the use of computational approaches such as Newton-Euler or Lagrange. In addition, since the purpose of this paper is to express comprehensive methods, so with increasing the number of links and degrees of freedom of the robot, finding the dynamics of the robot becomes more difficult. Therefore, the Adaptive Neural Network (ANN) with specific inputs has been used for estimation unknown matrices of the system and the controller design has been performed based on it. So, the main idea in using an adaptive controller is the fact there is no pre-knowledge for the dynamic modeling of the system since the human arm could have different dynamic properties. Hence, the controller is formed by an ANN and robust term. In this way, the adaptation laws of the parameters are extracted by Lyapunov approach, and as a result, as aforementioned, the asymptotic stability of the whole of the system is guaranteed. Simulation results certify the efficiency of the proposed method. Finally, using the Roots Mean Square Error (RMSE) criteria, it has been revealed that, in the presence of bounded disturbance with different amplitude, adding the robust term to the controller leads to improve the tracking error about 34% and 62%, respectively.","",""
0,"B. Mukunthan","A NEURAL NETWORK APPROACH FOR THE PRECISE PATTERN RECOGNITION OF HUMAN DNA",2012,"","","","",145,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,10,"The primary goal of bio informatics and neural networks solely is to increase our understanding of biological processes and focus on developing and applying computationally intensive techniques (e.g., pattern recognition, data mining, machine learning algorithms, and visualization) to achieve this goal. The neural networks exhibit characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, parallel and high speed information processing. Neural networks learn by examples they can therefore be trained with known examples of a problem to ‘acquire’ knowledge about it. Once appropriately trained, the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. The perfect blend made of bioinformatics and neural networks results in efficient pattern analysis techniques. The conventional techniques and algorithms employed by forensic scientists to assist in the identification of individuals on the basis of their respective DNA profiles involves more computational steps and mathematical formulas that leads to more time and space complexity resulting in complicated and less efficient algorithms which can be shorted out by emerging Artificial Neural Network approach.","",""
2,"Fang Wan, Chaoyang Song","Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs",2017,"","","","",146,"2022-07-13 10:09:04","","10.3389/frobt.2018.00086","","",,,,,2,0.40,1,2,5,"The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized grasping pose through logical learning.","",""
29,"C. Corbane, V. Syrris, F. Sabo, P. Politis, M. Melchiorri, M. Pesaresi, P. Soille, T. Kemper","Convolutional Neural Networks for Global Human Settlements Mapping from Sentinel-2 Satellite Imagery",2020,"","","","",147,"2022-07-13 10:09:04","","10.1007/S00521-020-05449-7","","",,,,,29,14.50,4,8,2,"","",""
8,"Quan Zhou, Dezong Zhao, B. Shuai, Yanfei Li, Huw Williams, Hongming Xu","Knowledge Implementation and Transfer With an Adaptive Learning Network for Real-Time Power Management of the Plug-in Hybrid Vehicle",2021,"","","","",148,"2022-07-13 10:09:04","","10.1109/TNNLS.2021.3093429","","",,,,,8,8.00,1,6,1,"Essential decision-making tasks such as power management in future vehicles will benefit from the development of artificial intelligence technology for safe and energy-efficient operations. To develop the technique of using neural network and deep learning in energy management of the plug-in hybrid vehicle and evaluate its advantage, this article proposes a new adaptive learning network that incorporates a deep deterministic policy gradient (DDPG) network with an adaptive neuro-fuzzy inference system (ANFIS) network. First, the ANFIS network is built using a new global K-fold fuzzy learning (GKFL) method for real-time implementation of the offline dynamic programming result. Then, the DDPG network is developed to regulate the input of the ANFIS network with the real-world reinforcement signal. The ANFIS and DDPG networks are integrated to maximize the control utility (CU), which is a function of the vehicle’s energy efficiency and the battery state-of-charge. Experimental studies are conducted to testify the performance and robustness of the DDPG-ANFIS network. It has shown that the studied vehicle with the DDPG-ANFIS network achieves 8% higher CU than using the MATLAB ANFIS toolbox on the studied vehicle. In five simulated real-world driving conditions, the DDPG-ANFIS network increased the maximum mean CU value by 138% over the ANFIS-only network and 5% over the DDPG-only network.","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",149,"2022-07-13 10:09:04","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
6,"Hoang-Quynh Le, Duy-Cat Can, T. Dang, Mai-Vu Tran, Quang-Thuy Ha, Nigel Collier","Improving chemical-induced disease relation extraction with learned features based on convolutional neural network",2017,"","","","",150,"2022-07-13 10:09:04","","10.1109/KSE.2017.8119474","","",,,,,6,1.20,1,6,5,"There have been an increasing number of various machine learning-based models successfully proposed and applied for automatic chemical-induced disease (CID) relation extraction. They, however, usually require carefully handcrafted rich feature sets, which rely on expert knowledge, thus require expensive human labor but normally still cannot generalize data well enough. In this paper, we propose a CID relation extraction model that learns features automatically through a Convolutional Neural Network (CNN) instead of traditional handcrafted features. We exploit the shortest dependency path between a disease and a chemical for identifying their CID relation. Dependency relations, with and without their direction information, are further investigated. Experimental results on benchmark datasets (namely the BioCreative V dataset) are very potential, demonstrating the effectiveness of our proposed model for CID relation extraction.","",""
2,"Andreas Huemer, M. Gongora, D. Elizondo","A robust reinforcement based self constructing neural network",2010,"","","","",151,"2022-07-13 10:09:04","","10.1109/IJCNN.2010.5596762","","",,,,,2,0.17,1,3,12,"Usually, many high-skilled human resources are required to create sophisticated control systems. Automatic generation of control systems can overcome these requirements. Because of their versatility and flexibility neural networks gained an important role for this task. While evolutionary methods have been relatively successful in generating neural networks, they have some limitations, in addition to being computationally expensive, because they rely on adapting populations instead of individuals. Reinforcement methods on the other hand can improve and adapt the behaviour of an individual; the reinforcement methods that are presented in this paper can grow a neural network during operation. We show that neural networks can be created for various domains without changing any parameters. Additionally, our neural network can learn the action selection policy and the value function locally within the neurons. These features make our neural network highly flexible and distinguish it from other reinforcement based constructive neural networks.","",""
25,"A. Vessoni, R. Herai, Jerome V. Karpiak, Angelica M S Leal, C. Trujillo, A. Quinet, L. F. Agnez Lima, C. Menck, A. Muotri","Cockayne syndrome-derived neurons display reduced synapse density and altered neural network synchrony.",2016,"","","","",152,"2022-07-13 10:09:04","","10.1093/hmg/ddw008","","",,,,,25,4.17,3,9,6,"Cockayne syndrome (CS) is a rare genetic disorder in which 80% of cases are caused by mutations in the Excision Repair Cross-Complementation group 6 gene (ERCC6). The encoded ERCC6 protein is more commonly referred to as Cockayne Syndrome B protein (CSB). Classical symptoms of CS patients include failure to thrive and a severe neuropathology characterized by microcephaly, hypomyelination, calcification and neuronal loss. Modeling the neurological aspect of this disease has proven difficult since murine models fail to mirror classical neurological symptoms. Therefore, a robust human in vitro cellular model would advance our fundamental understanding of the disease and reveal potential therapeutic targets. Herein, we successfully derived functional CS neural networks from human CS induced pluripotent stem cells (iPSCs) providing a new tool to facilitate studying this devastating disease. We identified dysregulation of the Growth Hormone/Insulin-like Growth Factor-1 (GH/IGF-1) pathway as well as pathways related to synapse formation, maintenance and neuronal differentiation in CSB neurons using unbiased RNA-seq gene expression analyses. Moreover, when compared to unaffected controls, CSB-deficient neural networks displayed altered electrophysiological activity, including decreased synchrony, and reduced synapse density. Collectively, our work reveals that CSB is required for normal neuronal function and we have established an alternative to previously available models to further study neural-specific aspects of CS.","",""
2,"Jyun-Yu Jiang, Yichao Zhou, Xiusi Chen, Yan-Ru Jhou, Liqi Zhao, Sabrina Liu, Po-Chun Yang, Jule Ahmar, Wei Wang","COVID-19 Surveiller: toward a robust and effective pandemic surveillance system based on social media mining",2021,"","","","",153,"2022-07-13 10:09:04","","10.1098/rsta.2021.0125","","",,,,,2,2.00,0,9,1,"The outbreak of the novel coronavirus, COVID-19, has become one of the most severe pandemics in human history. In this paper, we propose to leverage social media users as social sensors to simultaneously predict the pandemic trends and suggest potential risk factors for public health experts to understand spread situations and recommend proper interventions. More precisely, we develop novel deep learning models to recognize important entities and their relations over time, thereby establishing dynamic heterogeneous graphs to describe the observations of social media users. A dynamic graph neural network model can then forecast the trends (e.g. newly diagnosed cases and death rates) and identify high-risk events from social media. Based on the proposed computational method, we also develop a web-based system for domain experts without any computer science background to easily interact with. We conduct extensive experiments on large-scale datasets of COVID-19 related tweets provided by Twitter, which show that our method can precisely predict the new cases and death rates. We also demonstrate the robustness of our web-based pandemic surveillance system and its ability to retrieve essential knowledge and derive accurate predictions across a variety of circumstances. Our system is also available at http://scaiweb.cs.ucla.edu/covidsurveiller/. This article is part of the theme issue ‘Data science approachs to infectious disease surveillance’.","",""
2,"Seok-Hwan Choi, Jinmyeong Shin, Peng Liu, Yoon-Ho Choi","EEJE: Two-Step Input Transformation for Robust DNN Against Adversarial Examples",2021,"","","","",154,"2022-07-13 10:09:04","","10.1109/tnse.2020.3008394","","",,,,,2,2.00,1,4,1,"Adversarial examples are human-imperceptible perturbations to inputs to machine learning models. While attacking machine learning models, adversarial examples cause the model to make a false positive or a false negative. So far, two representative defense architectures have shown a significant effect: (1) model retraining architecture; and (2) input transformation architecture. However, previous defense methods belonging to these two architectures do not produce good outputs for every input, i.e., adversarial examples and legitimate inputs. Specifically, model retraining methods generate false negatives for unknown adversarial examples, and input transformation methods generate false positives for legitimate inputs. To produce good-enough outputs for every input, we propose and evaluate a new input transformation architecture based on two-step input transformation. To solve the limitations of the previous two defense methods, we intend to answer the following question: How to maintain the performance of Deep Neural Network (DNN) models for legitimate inputs while providing good robustness against various adversarial examples? From the evaluation results under various conditions, we show that the proposed two-step input transformation architecture provides good robustness to DNN models against state-of-the-art adversarial perturbations, while maintaining the high accuracy even for legitimate inputs.","",""
2,"Rafael Berral-Soler, F. J. Madrid-Cuevas, R. Muñoz-Salinas, Manuel J. Mar'in-Jim'enez","RealHePoNet: a robust single-stage ConvNet for head pose estimation in the wild",2020,"","","","",155,"2022-07-13 10:09:04","","10.1007/s00521-020-05511-4","","",,,,,2,1.00,1,4,2,"","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",156,"2022-07-13 10:09:04","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
2,"Yingying Wang, Ming Chang, Hongwei Chen, Yueou Ren, Qiuju Li","Research on Fault Diagnosis Expert System Fusing the Neural Network Knowledge",2011,"","","","",157,"2022-07-13 10:09:04","","10.1109/IHMSC.2011.54","","",,,,,2,0.18,0,5,11,"For a complicated system based on high technology, once a part breaks down, the entire system can not work normally. Moreover, due to the complexity of its structure and fault causes, the fault diagnosis of the system is also complex and indeterminate, a single test equipment can hardly finish a difficult diagnose task, and fault diagnosis expert system can resolve these problems effectively. The traditional diagnose expert systems have many problems such as the bottleneck of knowledge acquisition, the fragility of knowledge, the pool ability of self-study, the inefficient reasoning, and the monotonicity of reasoning, so there are certain limitations. But the artifical neural networks technology is a new system, it is an mathematical model that applies the structure like the joint of synapses in hypothalamic neurons, which has the strong ability to study, and can learn from samples, obtain knowledge, store it in the network in the form of weight and threshold, and it is easy to implement the parallel processing, has the character of association memory, own the better robust. it ability of adaptive self-study is manifested mainly in adjusting the weight of network according to the change of enviroment by learning algorithms, so as to adapt to the environmental change. But the neural network can not explain its own reasoning. Therefore we will apply the neural network to the expert knowledge system, which can make them learn each other's good points mutually for common progress, constructing the new neural network expert system. The system is applied to the power fault diagnosis, achieving good results.","",""
27,"Emre Çakir, Ezgi C. Ozan, T. Virtanen","Filterbank learning for deep neural network based polyphonic sound event detection",2016,"","","","",158,"2022-07-13 10:09:04","","10.1109/IJCNN.2016.7727634","","",,,,,27,4.50,9,3,6,"Deep learning techniques such as deep feedforward neural networks and deep convolutional neural networks have recently been shown to improve the performance in sound event detection compared to traditional methods such as Gaussian mixture models. One of the key factors of this improvement is the capability of deep architectures to automatically learn higher levels of acoustic features in each layer. In this work, we aim to combine the feature learning capabilities of deep architectures with the empirical knowledge of human perception. We use the first layer of a deep neural network to learn a mapping from a high-resolution magnitude spectrum to smaller amount of frequency bands, which effectively learns a filterbank for the sound event detection task. We initialize the first hidden layer weights to match with the perceptually motivated mel filterbank magnitude response. We also integrate this initialization scheme with context windowing by using an appropriately constrained deep convolutional neural network. The proposed method does not only result with better detection accuracy, but also provides insight on the frequencies deemed essential for better discrimination of given sound events.","",""
11,"I. Salgado, I. Chairez","Adaptive Unknown Input Estimation by Sliding Modes and Differential Neural Network Observer",2018,"","","","",159,"2022-07-13 10:09:04","","10.1109/TNNLS.2017.2730847","","",,,,,11,2.75,6,2,4,"In this paper, a differential neural network (DNN) implemented as a robust observer estimates the dynamics of perturbed uncertain nonlinear systems affected by exogenous unknown inputs. In the first stage, the identification error converges into a neighborhood around the origin. Then, the second-order sliding mode supertwisting algorithm implemented as a robust exact differentiator reconstructed the unknown inputs. The approach proposed in this paper can be applied in the case of full access to the state vector (identification problem) and in the case of partial access to the state vector (estimation problem). In the second case, the nonlinear system under study must have well-defined full relative degree with respect to the unknown input. Numerical examples showed the effectiveness of the proposed algorithm. The first example tested the DNN working as an identifier into a mathematical model describing the dynamics of a spatial minisatellite. The second example (with a DNN implemented as an observer) tested the methodology of this paper over a single link flexible robot manipulator represented in a canonical (Brunovsky) form. In both examples, the mathematical models served as data generators in the testing of the neural networks. Even when not exact mathematical description of both models was used in the input estimation, the accuracy obtained with the DNN is comparable with the case of applying a high-order differentiator with complete knowledge of the plant.","",""
0,"Jing Huang","Knowledge graph representation learning and graph neural networks for language understanding",2022,"","","","",160,"2022-07-13 10:09:04","","10.1145/3534540.3534710","","",,,,,0,0.00,0,1,1,"As AI technologies become mature in natural language processing, speech recognition and computer vision, ""intelligent"" user interfaces emerge to handle complex and diverse tasks that require human-like knowledge and reasoning capability. In Part 1, I will present our recent work on knowledge graph representation learning using Graph Neural Networks (GNNs): the first approach is called orthogonal transform embedding (OTE), which integrates graph context into the embedding distance scoring function and improves prediction accuracy on complex relations such as the difficult N-to-1, 1-to-N and N-to-N cases; the second approach is called multi-hop attention GNN (MAGNA), a principled way to incorporate multi-hop context information into every layer of attention computation. MAGNA uses a diffusion prior on attention values, to efficiently account for all paths between the pair of disconnected nodes. Experimental results on knowledge graph completion as well as node classification benchmarks show that MAGNA achieves state-of-the-art results. In Part 2, I will present how we take advantage of GNNs for language understanding and reasoning tasks. We show that combined with large pre-trained language models and knowledge graph embeddings, GNNs are proven effective in multi-hop reading comprehension across documents, improving time sensitivity for question answering over temporal knowledge graphs, and constructing robust syntactic information for aspect-level sentiment analysis.","",""
18,"Claudio Ciancio, G. Ambrogio, F. Gagliardi, R. Musmanno","Heuristic techniques to optimize neural network architecture in manufacturing applications",2016,"","","","",161,"2022-07-13 10:09:04","","10.1007/s00521-015-1994-9","","",,,,,18,3.00,5,4,6,"","",""
32,"Baifeng Shi, Dinghuai Zhang, Qi Dai, Zhanxing Zhu, Yadong Mu, Jingdong Wang","Informative Dropout for Robust Representation Learning: A Shape-bias Perspective",2020,"","","","",162,"2022-07-13 10:09:04","","","","",,,,,32,16.00,5,6,2,"Convolutional Neural Networks (CNNs) are known to rely more on local texture rather than global shape when making decisions. Recent work also indicates a close relationship between CNN's texture-bias and its robustness against distribution shift, adversarial perturbation, random corruption, etc. In this work, we attempt at improving various kinds of robustness universally by alleviating CNN's texture bias. With inspiration from the human visual system, we propose a light-weight model-agnostic method, namely Informative Dropout (InfoDrop), to improve interpretability and reduce texture bias. Specifically, we discriminate texture from shape based on local self-information in an image, and adopt a Dropout-like algorithm to decorrelate the model output from the local texture. Through extensive experiments, we observe enhanced robustness under various scenarios (domain generalization, few-shot classification, image corruption, and adversarial perturbation). To the best of our knowledge, this work is one of the earliest attempts to improve different kinds of robustness in a unified model, shedding new light on the relationship between shape-bias and robustness, also on new approaches to trustworthy machine learning algorithms. Code is available at this https URL.","",""
0,"Soumik Mondal, S. Yeo, Arulmurugan Ambikapathi","H-Stegonet: A Hybrid Deep Learning Framework for Robust Steganalysis",2021,"","","","",163,"2022-07-13 10:09:04","","10.1109/ICME51207.2021.9428374","","",,,,,0,0.00,0,3,1,"Steganalysis can be characterized as detecting a weak noise signal (hidden information) in textured regions of naturally occurring images. These noise signals are typically not perceptible to human eyes, which renders steganalysis a challenging task. On the other hand, recent breakthroughs in deep learning have seen remarkable progress in many applications, ranging from object recognition and segmentation to image generations. While there were efforts to build deep learning networks to perform steganalysis, the proposed architectures exhibit some limitations and a high tendency to overfit. We propose a hybrid deep learning architecture, namely H-StegoNet, to perform spatial steganalysis in this work. Precisely, by combining two different neural networks inspired by handcrafted features and the U-Net, we design a robust architecture that outperforms the existing approaches. Moreover, the experiments we performed under more realistic assumptions, including encoding with the syndrome trellis codes and assuming no prior knowledge of the payload used, thereby defining a rigorous and standard operation procedure for evaluating any steganalysis algorithm.","",""
12,"Diego Manzanas Lopez, Patrick Musau, Hoang-Dung Tran, Taylor T. Johnson","Verification of Closed-loop Systems with Neural Network Controllers",2019,"","","","",164,"2022-07-13 10:09:04","","10.29007/btv1","","",,,,,12,4.00,3,4,3,"This benchmark suite presents a detailed description of a series of closed-loop control systems with artificial neural network controllers. In many applications, feed-forward neural networks are heavily involved in the implementation of controllers by learning and representing control laws through several methods such as model predictive control (MPC) and reinforcement learning (RL). The type of networks that we consider in this manuscript are feed-forward neural networks consisting of multiple hidden layers with ReLU activation functions and a linear activation function in the output layer. While neural network controllers have been able to achieve desirable performance in many contexts, they also present a unique challenge in that it is difficult to provide any guarantees about the correctness of their behavior or reason about the stability a system that employs their use. Thus, from a controls perspective, it is necessary to verify them in conjunction with their corresponding plants in closed-loop. While there have been a handful of works proposed towards the verification of closed-loop systems with feed-forward neural network controllers, this area still lacks attention and a unified set of benchmark examples on which verification techniques can be evaluated and compared. Thus, to this end, we present a range of closed-loop control systems ranging from two to six state variables, and a range of controllers with sizes in the range of eleven neurons to a few hundred neurons in more complex systems. Category: Academic Difficulty: High Acknowledgement The material presented in this paper is based upon work supported by the National Science Foundation (NSF) under grant number SHF 1736323, the Air Force Office of Scientific Research (AFOSR) through contract numbers FA9550-15-1-0258, FA9550-16-10246, and FA9550-18-1-0122, and the Defense Advanced Research Projects Agency (DARPA) through contract number FA8750-18-C-0089. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of AFOSR, DARPA, or NSF G. Frehse and M. Althoff (eds.), ARCH19 (EPiC Series in Computing, vol. 61), pp. 201–210 Closed-loop Systems with Neural Network Controllers Manzanas Lopez, Musau, Tran and Johnson 1 Context and Origins. In recent years, advances in Artficial Intelligence (AI) have enabled a diverse range of technologies that are directly impacting people’s everyday lives [16]. Particularly, within this space, machine learning methods such as Deep Learning (DL) have achieved levels of accuracy and performance that are competitive or better than humans for tasks such as pattern and image recognition [12], natural language processing [7], and knowledge representation and reasoning [15,22]. Despite these achievements, there have been reservations about incorporating them into safety critical systems [11] due to their susceptibility to unexpected and errant behavior from a slight perturbation in their inputs [18]. Furthermore, neural networks are often viewed as ""black boxes"" since the underlying operation of the neuron activations is often indiscernible [22]. In light of these challenges, there has been significant work towards the creation of methods and verification tools that can formally reason about the behavior of neural networks [22]. However, the vast majority of these techniques have only been able to deal with feed-forward neural networks with piecewise-linear activation functions [4]. Additionally, the bulk of these methods have primarily considered the verification of input-output properties of neural networks in isolation [22], and there are only a handful of works that have explicitly addressed the verification of closed-loop control systems with neural network controllers [5, 8, 19–21]. One of the central challenges in verifying neural network control systems is that applying existing methodology to these systems is not straightforward [9], and a simple combination of verification tools for non-linear ordinary differential equations along with a neural network reachability tool suffers from severe overestimation errors [5]. Still, the verification of closed loop neural network systems is deeply important as they naturally arise in safety critical systems [5] such as autonomous vehicles, and complex control systems that make use of model predictive control and reinforcement learning [16]. Thus, there is a compelling need for methods and advanced software tools that can effectively deal with the complexities exhibited by these systems [5]. Inspired by a shortage of verification methods for closed-loop neural network control systems in the research literature, the central contribution of this paper is the provision of a set of executable benchmarks that have been synthesized using methods such as reinforcement learning [17], and model predictive control [14]. The problems elucidated in the paper are modeled using Simulink/Stateflow (SLSF) and are available at the following github repository1. We aim to provide a thorough problem description to which the numerous tools and approaches for non-linear systems and neural network verification present in the research community can be evaluated and compared [22]. If the research community is able to devise acceptable solutions to the aformentioned challenges they will stimulate the development of robust and intelligent systems with the potential to bring unparalleled benefits to numerous application domains. 2 Description of benchmarks. In this manuscript, we present a set of linear and non-linear closed-loop systems with continuoustime plants and feedforward neural networks controllers trained using different controls schemes such as reinforcement learning or model predictive control (MPC). A typical architecture describing the structure of these systems is displayed in Figure 2.1. All the neural networks 1https://github.com/verivital/ARCH-2019","",""
4,"H. Najafi","A neural network approach to digital data hiding based on the perceptual masking model of the human vision system",2010,"","","","",165,"2022-07-13 10:09:04","","10.1108/17563781011066693","","",,,,,4,0.33,4,1,12,"Purpose – The purpose of this paper is to present a novel approach for digital watermarking and steganography technique that uses neural networks. The performance of the proposed solution in terms of its capacity, transparency, and robustness is investigated.Design/methodology/approach – The proposed technique trains a neural network to learn the perceptual masking model of the human vision system. Once trained, the neural network identifies pixels whose most significant alteration will be least perceptible to the human eye. The image is then altered based on the network recommendation to include the watermark or the covert data.Findings – Experimental results demonstrate that the proposed technique offers excellent transparency and good capacity. In addition, since neural networks store their learned knowledge in a distributed fashion, steganalysis of the image without access to the network is very difficult, if not impossible. Results demonstrate good performance of the proposed solution in terms of its...","",""
0,"Nathan C L Kong","Are models trained on temporally-continuous data streams more adversarially robust?",2021,"","","","",166,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,1,"Task-optimized convolutional neural networks are the most quantitatively accurate models of the primate visual system. Unlike humans, however, these models can easily be fooled by modifying their inputs with human-imperceptible image perturbations, resulting in poor adversarial robustness . Prior work showed that modifying a model’s training objective or its architecture can improve its adversarial robustness. Another ingredient in building computational models of sensory cortex is the training dataset and, to our knowledge, its effect on a model’s adversarial robustness has not been investigated. Motivated by observations that newborn chicks ( Gallus gallus ) develop more invariant visual representations when reared with more temporally-continuous visual experience, we here evaluate a model’s adversarial robustness when it is trained on a more naturalistic dataset—a longitudinal video dataset collected from the perspective of infants (SAYCam; Sullivan et al., 2020). By evaluating the adversarial robustness of models on 26 -way classiﬁcation of a set of annotated video frames from this dataset, we ﬁnd that, across multiple objective functions, models that have been pre-trained on SAYCam video frames are more adversarially robust than those that have been pre-trained on ImageNet. Our results suggest that to build models that are more adversarially robust, additional efforts should be made in curating datasets that are more similar to the natural image sequences and the visual experience that infants receive.","",""
4,"R. Ning, Jiang Li, Chunsheng Xin, Hongyi Wu","Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks",2021,"","","","",167,"2022-07-13 10:09:04","","10.1109/INFOCOM42981.2021.9488902","","",,,,,4,4.00,1,4,1,"This paper reports a new clean-label data poisoning backdoor attack, named Invisible Poison, which stealthily and aggressively plants a backdoor in neural networks. It converts a regular trigger to a noised trigger that can be easily concealed inside images for training NN, with the objective to plant a backdoor that can be later activated by the trigger. Compared with existing data poisoning backdoor attacks, this newfound attack has the following distinct properties. First, it is a blackbox attack, requiring zero-knowledge of the target model. Second, this attack utilizes ""invisible poison"" to achieve stealthiness where the trigger is disguised as ‘noise’, and thus can easily evade human inspection. On the other hand, this noised trigger remains effective in the feature space to poison training data. Third, the attack is practical and aggressive. A backdoor can be effectively planted with a small amount of poisoned data and is robust to most data augmentation methods during training. The attack is fully tested on multiple benchmark datasets including MNIST, Cifar10, and ImageNet10, as well as application specific data sets such as Yahoo Adblocker and GTSRB. Two countermeasures, namely Supervised and Unsupervised Poison Sample Detection, are introduced to defend the attack.","",""
2,"Sulaiman Khan, Hazrat Ali, Z. Ullah, N. Minallah, S. Maqsood, Abdul Hafeez","Higher Accurate Recognition of Handwritten Pashto Letters through Zoning Feature by using K-Nearest Neighbour and Artificial Neural Network",2019,"","","","",168,"2022-07-13 10:09:04","","10.14569/IJACSA.2018.091070","","",,,,,2,0.67,0,6,3,"This paper presents a recognition system for handwritten Pashto letters. However, handwritten character recognition is a challenging task. These letters not only differ in shape and style but also vary among individuals. The recognition becomes further daunting due to the lack of standard datasets for inscribed Pashto letters. In this work, we have designed a database of moderate size, which encompasses a total of 4488 images, stemming from 102 distinguishing samples for each of the 44 letters in Pashto. The recognition framework uses zoning feature extractor followed by K-Nearest Neighbour (KNN) and Neural Network (NN) classifiers for classifying individual letter. Based on the evaluation of the proposed system, an overall classification accuracy of approximately 70.05% is achieved by using KNN while 72% is achieved by using NN. Keywords—KNN, deep neural network, OCR, zoning technique, Pashto, character recognition, classification sectionIntroduction In this modern technological and digital age, optical character recognition (OCR) systems play a vital role in machine learning and automatic recognition problems. OCR is a section of software tool that converts printed text and images to machine readable form and enables the machine to recognize images or text like humans. OCR systems are commercially available for isolated languages, which include Chinese, English, Japanese, and others. However, few OCR systems are available for cursive languages such as Persian and Arabic and are not highly robust. To the best of our knowledge, there is no such commercial OCR system available for carved Pashto letters recognition; however, such systems exist in research labs. Handwritten letters recognition is a daunting task mainly because of variations in writing styles of different users. Handwritten letters recognition can be done either offline or online. Online character recognition is simpler and easier to implement due to the temporal based information such as velocity, time, number of strokes, and direction for writing. In addition, the trace of the pen is a few pixels wide so this does not require thinning techniques for classification. On the other hand, offline character recognition system implementation is even laborious due to high variations in writing and font styles of every user. In our paper, we present inscribed of handwritten Pashto letters. Pashto is a major language of Pashtun tribe in Pakistan and the official language of Afghanistan. In censes 2007 2009, it was estimated that about 40 60 millions of people around the world are native speakers of this language. Pashto letters can be shaped into six different formats, which make the recognition process challenging. Furthermore, the count of character dots and occurrence of these dots that varies from letter to letter make the problem challenging. In order to address these problems, research shows the use of high level features based on the structural information of letters. An OCR based system using deep learning network model that incorporates Biand Multi-dimensional long short term memory for printed Pashto text recognition has been suggested [1]. A web-based survey shows that Pashto script contains a huge number of unique ligature [2]. Such ligature makes the implementation of OCR system for carved Pashto challenging. As printed letters contain a constant shape/style and font size; thus, the said technique fails in our case due to higher higher variations in style and font in case of inscribed letters. Riaz et al. [3] has presented the development of an OCR system for cursive Pashto script using scale invariant feature transform and principle component analysis. In order to address this issue, we present a system for handwritten Pashto letters recognition, which has the following key contributions: • As there is no standard handwritten Pashto letters database for testing an algorithm; thus, one of the contribution of this work is to develop and present a medium-sized database of 4488 (102 samples for each letter) for further research work. • The second contribution of this research work is to provide a base result as a benchmark for Pashto language. For this purpose, the performance results of the state-of-the-art classifiers−KNN and deep Neural Network are used based on zoning features. • Our proposed handwritten Pashto letters recognition system is efficient, simple, and cost-effective. • We provide comprehensive results for analyzing the proposed system for handwritten Pashto letters recognition, which may help the researchers to further explore this area. This paper is divided in seven sections: Section I explains the related work. Section II captures the background informawww.ijacsa.thesai.org 1 | P a g e ar X iv :1 90 4. 03 39 1v 1 [ cs .C V ] 6 A pr 2 01 9 (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 9, No. 10, 2018 tion about the classifiers and feature extraction algorithm used in this research work. Section III delineates the methodology. Section IV discusses about the feature extraction, which is very important in the area of pattern recognition and machine learning while section V demonstrates the experimental results followed by the conclusions and future work in Section VI.","",""
5,"D. Hagos, P. Engelstad, A. Yazidi, Ø. Kure","Recurrent Neural Network-Based Prediction of TCP Transmission States from Passive Measurements",2018,"","","","",169,"2022-07-13 10:09:04","","10.1109/NCA.2018.8548064","","",,,,,5,1.25,1,4,4,"Long Short-Term Memory (LSTM) neural networks are a state-of-the-art techniques when it comes to sequence learning and time series prediction models. In this paper, we have used LSTM-based Recurrent Neural Networks (RNN) for building a generic prediction model for Transmission Control Protocol (TCP) connection characteristics from passive measurements. To the best of our knowledge, this is the first work that attempts to apply LSTM for demonstrating how a network operator can identify the most important system-wide TCP per-connection states of a TCP client that determine a network condition (e.g., cwnd) from passive traffic measured at an intermediate node of the network without having access to the sender. We found out that LSTM learners outperform the state-of-the-art classical machine learning prediction models. Through an extensive experimental evaluation on multiple scenarios, we demonstrate the scalability and robustness of our approach and its potential for monitoring TCP transmission states related to network congestion from passive measurements. Our results based on emulated and realistic settings suggest that Deep Learning is a promising tool for monitoring system-wide TCP states from passive measurements and we believe that the methodology presented in our paper may strengthen future research work in the computer networking community.","",""
7,"S. Bhattacharya, Samir Roy, S. Chowdhury","A neural network-based intelligent cognitive state recognizer for confidence-based e-learning system",2016,"","","","",170,"2022-07-13 10:09:04","","10.1007/s00521-016-2430-5","","",,,,,7,1.17,2,3,6,"","",""
2,"Pingchuan Ma, Shuai Wang","MT-Teql: Evaluating and Augmenting Neural NLIDB on Real-world Linguistic and Schema Variations",2021,"","","","",171,"2022-07-13 10:09:04","","10.14778/3494124.3494139","","",,,,,2,2.00,1,2,1,"  Natural Language Interface to Database (NLIDB) translates human utterances into SQL queries and enables database interactions for non-expert users. Recently, neural network models have become a major approach to implementing NLIDB. However, neural NLIDB faces challenges due to variations in natural language and database schema design. For instance, one user intent or database conceptual model can be expressed in  various forms.  However, existing benchmarks, using hold-out datasets, cannot provide thorough understanding of how good neural NLIDBs really are in real-world situations and its robustness against such variations. A key difficulty is to annotate SQL queries for inputs under real-world variations, requiring considerable manual effort and expert knowledge.    To systematically assess the robustness of neural NLIDBs without extensive manual effort, we propose MT-Teql, a unified framework to benchmark NLIDBs against real-world language and schema variations. Inspired by recent advances in DBMS metamorphic testing, MT-Teql implements semantics-preserving transformations on utterances and database schemas to generate their variants. NLIDBs can thus be examined for robustness utilizing utterances/schemas and their variants without requiring manual intervention.  We benchmarked nine neural NLIDBs using 62,430 inputs and identified 15,433 defects. We analyzed potential root causes of defects and conducted a user study to show how MT-Teql can assist developers to systematically assess NLIDBs. We further show that the transformed (error-triggering) inputs can be used to augment popular NLIDBs and eliminate 46.5%(±5.0%) errors made by them without compromising their accuracy on standard benchmarks. We summarize lessons from this study that can provide insights to select and design NLIDBs that fit particular usage scenarios.","",""
9,"Weiyi Huang, Qiang Qu, Min Yang","Interactive knowledge-enhanced attention network for answer selection",2020,"","","","",172,"2022-07-13 10:09:04","","10.1007/s00521-019-04630-x","","",,,,,9,4.50,3,3,2,"","",""
0,"Po-Ssu Huang, K. A. Thompson","Harnessing Human Neural Networks for Protein Design.",2019,"","","","",173,"2022-07-13 10:09:04","","10.1021/acs.biochem.9b00820","","",,,,,0,0.00,0,2,3,"C proteins to fulfill a variety of functional needs has long been a goal of biochemists. This requires a thorough understanding of the relationship between the sequence of a polypeptide chain and the resulting protein structure. In recent years, the field of protein design has finally reached a stage where it is possbile to use physical and chemical principles to guild the design of novel protein structures. The goal of designing a protein structure is to produce an amino acid sequence that can fold into a target shape. To compute the sequence, most current methods explicitly model every atom in the system (with implicit solvent) to find a configuration that satisfies all of the interactions that each residue can make in its environment. While we are not yet capabale of using these methods to design proteins with any arbitrary function, our ability to create structures that significantly differ from those observed in structural databases has reached new heights. Protein design has become more robust with recent advances in computer processing power, design algorithms, and the decreased cost with DNA synthesis. These breakthroughs have provided the tools to run large-scale simulations, test design hypotheses, and experimentally iterate on and confirm designs. Nonetheless, the word “design” implies the involvement of cognitive activity in determining the outcome. This is arguably the most critical and least tractable element of the approach. Although any new amino acid sequence that can be generated rationally for a protein can be considered a design, in recent years, the meaning of designing a protein “de novo” has referred largely to designs in which both the structure and the sequence are modeled and created from scratch. When both the backbone and sequence are unknown at the onset, a protein designer must creatively choose a topology and construct the proper structural elements to form the backbone. A number of strategies to restrict the local backbone geometries to be native-like have been employed, for example, by borrowing true fragments from actual proteins to initiate the construction or extensively idealizing the peptide chain according to reliable chemical knowledge or parametric equations. While computer algorithms have largely automated specific steps of protein design, the protein designer still controls the process and makes certain that the resulting structures are coherent. But what decisions do human designers make that today’s automated algorithms do not? This question prompted the development of Foldit, a video game that applies a graphical user interface to the protein modeling suite Rosetta. In addition to serving as an excellent educational tool, Foldit aims to explore the strategies humans use to solve protein structure puzzles in hopes that these operations can be analyzed to improve or automate design algorithms. Foldit began with puzzles that challenged players to predict the folds of natural amino acid sequences (Figure 1A). Recently, it has been extended to allow players to modify previously designed proteins or design novel proteins from scratch (Figure 1B,C). There are three main components involved in the design of proteins: scoring metrics to guide the moves, strategies to change the structure, and sequence tweaks to improve models (Figure 1D,E). In Foldit, the latter two are controlled by human players. There is little difference between what a player may do compared to what a trained protein designer might because their objectives are the same: to follow the score provided by the force field as it is not possible to mentally follow the entire system of thousands of atoms. In a study published in Nature, Koepnick et al. let Foldit players design a folded peptide starting from a linear chain. Players were exceptionally good at exploring the conformational space, as seen in an early iteration of the game, where the players’ structures were truly novel and expressive. While many of these creative models would not likely fold to their target structures, the real implication of the crowd sourcing brilliance is that now every aspect of the Rosetta scoring function is being tested, and exploited, in unintended ways by the players to achieve a better score. Fixing scoring deficits identified by players will eventually make the scoring metric more robust. Indeed, in subsequent rounds, Foldit was configured to enforce packing and backbone regularization rules; remarkably, these improvements provided sound guidance, and the citizen scientists were able to design proteins at the same level of accuracy as expert designers who are trained in structural biology. Perhaps not surprisingly, with the imposition of build rules, the models produced in Foldit are no longer shockingly different from designs that trained experts have long been able to produce. However, for nonscientists to achieve these novel designs by simply maximizing the game score, the Foldit experiment shows that the scoring scheme (i.e., the Rosetta force field) must be remarkably robust. By specifying the secondary structure content required or other more general rules, the scientists behind Foldit also seem to be able to guide players into creating a wide variety of structures within specific folds. The quality of the models seems only as good as the rules set by the scientists. It will be fascinating to see how this interplay between knowledge-derived rules and human creativity can be harnessed to advance science. Automated computer algorithms today cannot carry out the design tasks like the human Foldit players; the calculations would take far too long to sample to produce a viable structure","",""
60,"Z. Man, X. Yu, K. Eshraghian, M. Palaniswami","A robust adaptive sliding mode tracking control using an RBF neural network for robotic manipulators",1995,"","","","",174,"2022-07-13 10:09:04","","10.1109/ICNN.1995.487738","","",,,,,60,2.22,15,4,27,"A new robust adaptive sliding mode tracking control scheme using an RBF neural network is proposed for rigid robotic manipulators to achieve robustness and asymptotic error convergence. A key feature of this scheme is that the prior knowledge of the upper bound of the system uncertainties is not required. An adaptive RBF neural network is used to learn the upper bound of system uncertainties. The output of the neural network is then used as a compensator parameter in the sense that the effects of the system uncertainties can be eliminated and asymptotic error convergence can be obtained for the closed loop robotic control system.","",""
33,"G. Rovithakis","Robust redesign of a neural network controller in the presence of unmodeled dynamics",2004,"","","","",175,"2022-07-13 10:09:04","","10.1109/TNN.2004.837782","","",,,,,33,1.83,33,1,18,"This work presents a neural network control redesign, which achieves robust stabilization in the presence of unmodeled dynamics restricted to be input to output practically stable (IOpS), without requiring any prior knowledge on any bounding function. Moreover, the state of the unmodeled dynamics is permitted to go unbounded provided that the nominal system state and/or the control input also go unbounded. The neural network controller is equipped with a resetting strategy to deal with the problem of possible division by zero, which may appear since we consider unknown input vector fields with unknown signs. The uniform ultimate boundedness of the system output to an arbitrarily small set, plus the boundedness of all other signals in the closed-loop is guaranteed.","",""
0,"M. Swarna, N. Sudhakar, N. Vadaparthi","An effective tropical cyclone intensity estimation model using Convolutional Neural Networks",2021,"","","","",176,"2022-07-13 10:09:04","","10.54302/mausam.v72i2.616","","",,,,,0,0.00,0,3,1,"The tropical cyclones in India is a common natural disaster happening every year. As per the statistics, about three cyclones hit India's east coast in the Bay of Bengal, which damaged human lives, crops and property. It is essential to predict the cyclones in advance to prevent and reduce huge damage. The techniques used are based on numerical models that require vast expertise and higher skill sets to achieve better prediction accuracy. The usage of Convolutional Neural Networks shall overcome various issues like domain knowledge, the scope for human errors. Hence, in this paper, we attempted to predict cyclone intensity using Convolutional Neural Networks by proposing a simple and robust architecture for Tropical Cyclone intensity estimation. The results yielded better performance than the state-of-the-art techniques with reduced computation time.","",""
1,"Wenlu Zhang, Lusi Li, Vincent Cheong, Bo Fu, Mehrdad Aliasgari","Deep Encoder-Decoder Neural Networks for Retinal Blood Vessels Dense Prediction",2021,"","","","",177,"2022-07-13 10:09:04","","10.2991/ijcis.d.210308.001","","",,,,,1,1.00,0,5,1,"Automatic segmentation of retinal blood vessels from fundus images is of great importance in assessing the condition of vascular network in human eyes. The task is primary challenging due to the low contrast of images, the variety of vessels and potential pathology. Previous studies have proposed shallow machine learning based methods to tackle the problem. However, these methods require specific domain knowledge, and the efficiency and robustness of these methods are not satisfactory for medical diagnosis. In recent years, deep learning models have made great progress in various segmentation tasks. In particular, Fully Convolutional Network and U-net have achieved promising results in end-to-end dense prediction tasks. In this study, we propose a novel encoder-decoder architecture based on the vanilla U-net architecture for retinal blood vessels segmentation. The proposed deep learning architecture integrates hybrid dilation convolutions and pixel transposed convolutions in the encoderdecoder model. Such design enables global dense feature extraction and resolves the common “gridding” and “checkerboard” issues in the regular U-net. Furthermore, the proposed network can be efficiently and directly implemented for any semantic segmentation applications. We evaluate the proposed network on two retinal blood vessels data sets. The experimental results show that our proposed model outperforms the baseline U-net model.","",""
9,"M. Matsugu, Katsuhiko Mori, Y. Mitari, Y. Keneda","Facial expression recognition combined with robust face detection in a convolutional neural network",2003,"","","","",178,"2022-07-13 10:09:04","","10.1109/IJCNN.2003.1223759","","",,,,,9,0.47,2,4,19,"Reliable detection of ordinary facial expressions (e.g., smile) despite the variability among individuals as well as face appearance is an important step toward the realization of perceptual user interface and the next generation imaging system with autonomous perception of persons. We describe a robust facial expression recognition system using the result of face detection by a convolutional neural network and rule-based processing. In this study, we address the problem of subject independence as well as translation, rotation, and scale invariance in the recognition of facial expression. The result shows reliable detection of smiles with recognition rate of 97.6% for 5600 still images of more than 10 subjects. The proposed algorithm demonstrated the ability to discriminate smiling from talking based on the saliency score in the proposed algorithm. To the best of our knowledge, it is the first facial expression recognition model with the property of subject independence combined with robustness to variability in facial appearance.","",""
185,"T. G. Thuruthel, Benjamin Shih, C. Laschi, M. Tolley","Soft robot perception using embedded soft sensors and recurrent neural networks",2019,"","","","",179,"2022-07-13 10:09:04","","10.1126/scirobotics.aav1488","","",,,,,185,61.67,46,4,3,"Recurrent neural networks with an unstructured redundant soft sensor topology allow robust multimodal proprioceptive capabilities. Recent work has begun to explore the design of biologically inspired soft robots composed of soft, stretchable materials for applications including the handling of delicate materials and safe interaction with humans. However, the solid-state sensors traditionally used in robotics are unable to capture the high-dimensional deformations of soft systems. Embedded soft resistive sensors have the potential to address this challenge. However, both the soft sensors—and the encasing dynamical system—often exhibit nonlinear time-variant behavior, which makes them difficult to model. In addition, the problems of sensor design, placement, and fabrication require a great deal of human input and previous knowledge. Drawing inspiration from the human perceptive system, we created a synthetic analog. Our synthetic system builds models using a redundant and unstructured sensor topology embedded in a soft actuator, a vision-based motion capture system for ground truth, and a general machine learning approach. This allows us to model an unknown soft actuated system. We demonstrate that the proposed approach is able to model the kinematics of a soft continuum actuator in real time while being robust to sensor nonlinearities and drift. In addition, we show how the same system can estimate the applied forces while interacting with external objects. The role of action in perception is also presented. This approach enables the development of force and deformation models for soft robotic systems, which can be useful for a variety of applications, including human-robot interaction, soft orthotics, and wearable robotics.","",""
37,"A. Murphy, S. Muldoon, D. Baker, Adam Lastowka, Brittany C. Bennett, Muzhi Yang, D. Bassett","Structure, function, and control of the human musculoskeletal network",2018,"","","","",180,"2022-07-13 10:09:04","","10.1371/journal.pbio.2002811","","",,,,,37,9.25,5,7,4,"The human body is a complex organism, the gross mechanical properties of which are enabled by an interconnected musculoskeletal network controlled by the nervous system. The nature of musculoskeletal interconnection facilitates stability, voluntary movement, and robustness to injury. However, a fundamental understanding of this network and its control by neural systems has remained elusive. Here we address this gap in knowledge by utilizing medical databases and mathematical modeling to reveal the organizational structure, predicted function, and neural control of the musculoskeletal system. We constructed a highly simplified whole-body musculoskeletal network in which single muscles connect to multiple bones via both origin and insertion points. We demonstrated that, using this simplified model, a muscle’s role in this network could offer a theoretical prediction of the susceptibility of surrounding components to secondary injury. Finally, we illustrated that sets of muscles cluster into network communities that mimic the organization of control modules in primary motor cortex. This novel formalism for describing interactions between the muscular and skeletal systems serves as a foundation to develop and test therapeutic responses to injury, inspiring future advances in clinical treatments.","",""
6,"R. Hamad, Masashi Kimura, Longzhi Yang, W. L. Woo, Bo Wei","Dilated causal convolution with multi-head self attention for sensor human activity recognition",2021,"","","","",181,"2022-07-13 10:09:04","","10.1007/S00521-021-06007-5","","",,,,,6,6.00,1,5,1,"","",""
12,"Á. Martínez-González, M. Villamizar, Olivier Can'evet, J. Odobez","Efficient Convolutional Neural Networks for Depth-Based Multi-Person Pose Estimation",2019,"","","","",182,"2022-07-13 10:09:04","","10.1109/TCSVT.2019.2952779","","",,,,,12,4.00,3,4,3,"Achieving robust multi-person 2D body landmark localization and pose estimation is essential for human behavior and interaction understanding as encountered for instance in HRI settings. Accurate methods have been proposed recently, but they usually rely on rather deep Convolutional Neural Network (CNN) architecture, thus requiring large computational and training resources. In this paper, we investigate different architectures and methodologies to address these issues and achieve fast and accurate multi-person 2D pose estimation. To foster speed, we propose to work with depth images, whose structure contains sufficient information about body landmarks while being simpler than textured color images and thus potentially requiring less complex CNNs for processing. In this context, we make the following contributions. i) we study several CNN architecture designs combining pose machines relying on the cascade of detectors concept with lightweight and efficient CNN structures; ii) to address the need for large training datasets with high variability, we rely on semi-synthetic data combining multi-person synthetic depth data with real sensor backgrounds; iii) we explore domain adaptation techniques to address the performance gap introduced by testing on real depth images; iv) to increase the accuracy of our fast lightweight CNN models, we investigate knowledge distillation at several architecture levels which effectively enhance performance. Experiments and results on synthetic and real data highlight the impact of our design choices, providing insights into methods addressing standard issues normally faced in practical applications, and resulting in architectures effectively matching our goal in both performance and speed.","",""
0,"Lige Yang, Liping Zheng, Lijuan Zheng","Research on Extraction of Human Information Entity Relationship Based on Improved Capsule Network",2020,"","","","",183,"2022-07-13 10:09:04","","10.1109/IWECAI50956.2020.00015","","",,,,,0,0.00,0,3,2,"Entity relation extraction is to learn the implicit semantic relations among entities from multiple entities of a single sentence. Extracting entity relationships from unstructured text information is a key step in building large-scale knowledge map, optimizing personalized search, machine translation and intelligent Q & A. At present, the more popular depth model of entity relationship extraction has a better effect on the relationship extraction of single entity pair, but the evaluation index data of the model is not high when it is extended to the situation of single sentence multi entity pair and document level complex semantics. In this paper, an improved capsule network model based on dynamic routing rules is introduced, and it is applied to the relationship extraction of multi entity pairs of unstructured human information in the field of literature. The capsule network uses the route iteration method to connect the capsules between different hidden layers, which makes the capsule network establish the position relationship between different features in the routing process. Therefore, the capsule network is more robust to the position and angle changes of the target than other neural networks, so as to avoid the loss of information. In the experiment, we use the improved capsule network model, transformer and CNN model to extract the entity relationship of human information. The experimental results show that the improved capsule network model can achieve high accuracy, recall rate and F1 value in the multi entity pair relation extraction of small language database in the field of literature.","",""
11,"M. Trompf","Neural network development for noise reduction in robust speech recognition",1992,"","","","",184,"2022-07-13 10:09:04","","10.1109/IJCNN.1992.227233","","",,,,,11,0.37,11,1,30,"Speech recognition systems with small and medium vocabulary are used as natural human interfaces in a variety of applications. To make such a system more robust, the development of a neural network based noise reduction module is described. Using standard feedforward networks, several topologies have been tested to learn about the properties of neural noise reduction. For the development of a sufficiently robust nonadaptive system, information about the characteristics of the noise and speech components of the input signal including context information was taken into account. The focus is on the stepwise experiment-oriented improvement of a basic linear neural noise reduction network. The isolated word recognition system and the database used for the experiments are described. Results from different noise reduction networks are given. To test their robustness, simulations with varying input signal characteristics were made and are discussed.<<ETX>>","",""
4,"Q. Song, L. Yin, Y. C. Soh","Robust adaptive identification of nonlinear system using neural network",2000,"","","","",185,"2022-07-13 10:09:04","","10.1111/j.1934-6093.2001.tb00054.x","","",,,,,4,0.18,1,3,22,"It is well-known that disturbances can cause the divergence of neural networks in the identification of nonlinear systems. Sufficient conditions using so-called modified algorithms are available to provide guaranteed convergence for adaptive systems. They are: the dead-zone scheme, adaptive law modification and /spl sigma/-modification. These schemes normally require knowledge of the upper bound of the disturbance. In this paper, a robust weight-tuning algorithm is used to train a multi-layered neural network with an adaptive dead-zone scheme. The proposed robust adaptive algorithm does not require knowledge of either the upper bound of the disturbance or the bound on the norm of the estimate parameter. A complete convergence is provided based on the Lyapunov theorem to deal with the nonlinear system. Simulation results are presented to show the good performance of the algorithm.","",""
33,"V. Nguyen, J. Starzyk, Wooi-Boon Goh, Daniel Jachyra","Neural Network Structure for Spatio-Temporal Long-Term Memory",2012,"","","","",186,"2022-07-13 10:09:04","","10.1109/TNNLS.2012.2191419","","",,,,,33,3.30,8,4,10,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","",""
95,"R. Savitha, S. Sundaram, N. Sundararajan","Metacognitive Learning in a Fully Complex-Valued Radial Basis Function Neural Network",2012,"","","","",187,"2022-07-13 10:09:04","","10.1162/NECO_a_00254","","",,,,,95,9.50,32,3,10,"Recent studies on human learning reveal that self-regulated learning in a metacognitive framework is the best strategy for efficient learning. As the machine learning algorithms are inspired by the principles of human learning, one needs to incorporate the concept of metacognition to develop efficient machine learning algorithms. In this letter we present a metacognitive learning framework that controls the learning process of a fully complex-valued radial basis function network and is referred to as a metacognitive fully complex-valued radial basis function (Mc-FCRBF) network. Mc-FCRBF has two components: a cognitive component containing the FC-RBF network and a metacognitive component, which regulates the learning process of FC-RBF. In every epoch, when a sample is presented to Mc-FCRBF, the metacognitive component decides what to learn, when to learn, and how to learn based on the knowledge acquired by the FC-RBF network and the new information contained in the sample. The Mc-FCRBF learning algorithm is described in detail, and both its approximation and classification abilities are evaluated using a set of benchmark and practical problems. Performance results indicate the superior approximation and classification performance of Mc-FCRBF compared to existing methods in the literature.","",""
92,"Lang Chen, M. L. Ralph, T. Rogers","A unified model of human semantic knowledge and its disorders",2017,"","","","",188,"2022-07-13 10:09:04","","10.1038/s41562-016-0039","","",,,,,92,18.40,31,3,5,"","",""
0,"M. Gregurić, S. Mandzuka, E. Ivanjko","Knowledge Integration by Using Adaptive Neural- fuzzy Networks for Ramp Metering",2018,"","","","",189,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,3,4,"An Adaptive Neuro-Fuzzy Inference System (ANFIS) is a neural network-based fuzzy inference system that includes combination of two soft-computing methods: Artificial Neural Networks (ANN) and fuzzy logic [1] Fuzzy logic has the ability to transform the qualitative aspects of human knowledge and insights into the process of precise quantitative analysis [2]. However, it is very problematic to transform the human thought into a rule based Fuzzy Inference System (FIS), and adequately adjust Membership Functions (MFs) of the mentioned FIS. ANFIS uses ANN’s ability of self-adaptation to the environment through the machine learning process in order to automatically adjust the MFs, and reduce the rate of errors in the determination of rules in FIS [2]. Fuzzy logic based approaches such as FIS are often used for ramp metering. Ramp metering as one of the control methods for urban motorways is formulated as the regulation of the on-ramp flow access rate into the motorway mainstream according to the several inputs. Most ramp metering algorithms based on fuzzy logic require a robust and comprehensive approach for adjusting of the FIS rule base and MFs in a complex non-linear environments such as the urban motorway traffic system.","",""
16,"Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah Hanif, M. Martina, M. Shafique","Is Spiking Secure? A Comparative Study on the Security Vulnerabilities of Spiking and Deep Neural Networks",2019,"","","","",190,"2022-07-13 10:09:04","","10.1109/IJCNN48605.2020.9207297","","",,,,,16,5.33,3,6,3,"Spiking Neural Networks (SNNs) claim to present many advantages in terms of biological plausibility and energy efficiency compared to standard Deep Neural Networks (DNNs). Recent works have shown that DNNs are vulnerable to adversarial attacks, i.e., small perturbations added to the input data can lead to targeted or random misclassifications. In this paper, we aim at investigating the key research question: ""Are SNNs secure?"" Towards this, we perform a comparative study of the security vulnerabilities in SNNs and DNNs w.r.t. the adversarial noise. Afterwards, we propose a novel black-box attack methodology, i.e., without the knowledge of the internal structure of the SNN, which employs a greedy heuristic to automatically generate imperceptible and robust adversarial examples (i.e., attack images) for the given SNN. We perform an in-depth evaluation for a Spiking Deep Belief Network (SDBN) and a DNN having the same number of layers and neurons (to obtain a fair comparison), in order to study the efficiency of our methodology and to understand the differences between SNNs and DNNs w.r.t. the adversarial examples. Our work opens new avenues of research towards the robustness of the SNNs, considering their similarities to the human brain's functionality.","",""
4,"H. A. Lafta, Z. Hassan","A Hybrid System Geno-Fuzzified Neural Network for Mobile Robot Control",2013,"","","","",191,"2022-07-13 10:09:04","","10.9734/BJMCS/2013/4587","","",,,,,4,0.44,2,2,9,"Aims: The goal of mobile robot is build system able to achieve tasks without human intervention in cluttered unknown environments. A main issue of an autonomous mobile robot is the design of an intelligent controller which enables the robot to navigate in a real world environment and avoiding obstacles especially in crowded and changing environment. Study Design: The controller uses genetic, fuzzy and neural to control of mobile robot. Place and Duration of Study: College Science, computer department, between September 2011 and December 2012. Methodology: In this search, fuzzy logic, genetic algorithm, and neural network (soft computing) are used to design an intelligent controller. This is due to the fact that fuzzy if-then rules are well suited for capturing the imprecise nature of human knowledge and reasoning processes. On the other hand, the neural networks are equipped for learning. Genetic algorithm has active role in the generating of fuzzy rules, it is designed to minimize the number of rules to minimum number. It is also helped to improve membership functions. Neural network is trained by using back propagation to increase efficiency of the work in time of arrive and get the shortest path to goal, it is obtained the steer angle of robot to the appropriate direction (avoid obstacles or get target). Results: The efficiency and robust of this work is appeared by using many different unknown environments that have different numbers, sizes and shapes of obstacles. The controller enables robot to avoid obstacles and reach goal with shortest distance (757 pixels) compared with other techniques(fuzzy controller and neuro-fuzzy controller),which owns the largest distance from same start position to the same end position and also less time(14 seconds). Conclusion: Geno – fuzzified – neural controller is efficient with different numbers, shapes, sizes of obstacles in unknown environments.","",""
480,"S. Bosse, D. Maniry, K. Müller, T. Wiegand, W. Samek","Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment",2016,"","","","",192,"2022-07-13 10:09:04","","10.1109/TIP.2017.2760518","","",,,,,480,80.00,96,5,6,"We present a deep neural network-based approach to image quality assessment (IQA). The network is trained end-to-end and comprises ten convolutional layers and five pooling layers for feature extraction, and two fully connected layers for regression, which makes it significantly deeper than related IQA models. Unique features of the proposed architecture are that: 1) with slight adaptations it can be used in a no-reference (NR) as well as in a full-reference (FR) IQA setting and 2) it allows for joint learning of local quality and local weights, i.e., relative importance of local quality to the global quality estimate, in an unified framework. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. We evaluate the proposed approach on the LIVE, CISQ, and TID2013 databases as well as the LIVE In the wild image quality challenge database and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different databases, indicating a high robustness of the learned features.","",""
7,"F. Lareyre, C. Adam, M. Carrier, J. Raffort","Automated Segmentation of the Human Abdominal Vascular System Using a Hybrid Approach Combining Expert System and Supervised Deep Learning",2021,"","","","",193,"2022-07-13 10:09:04","","10.3390/jcm10153347","","",,,,,7,7.00,2,4,1,"Background: Computed tomography angiography (CTA) is one of the most commonly used imaging technique for the management of vascular diseases. Here, we aimed to develop a hybrid method combining a feature-based expert system with a supervised deep learning (DL) algorithm to enable a fully automatic segmentation of the abdominal vascular tree. Methods: We proposed an algorithm based on the hybridization of a data-driven convolutional neural network and a knowledge-based model dedicated to vascular system segmentation. By using two distinct datasets of CTA from patients to evaluate independence to training dataset, the accuracy of the hybrid method for lumen and thrombus segmentation was evaluated compared to the feature-based expert system alone and to the ground truth provided by a human expert. Results: The hybrid approach demonstrated a better accuracy for lumen segmentation compared to the expert system alone (volume similarity: 0.8128 vs. 0.7912, p = 0.0006 and Dice similarity coefficient: 0.8266 vs. 0.7942, p < 0.0001). The accuracy for thrombus segmentation was also enhanced using the hybrid approach (volume similarity: 0.9404 vs. 0.9185, p = 0.0027 and Dice similarity coefficient: 0.8918 vs. 0.8654, p < 0.0001). Conclusions: By enabling a robust and fully automatic segmentation, the method could be used to develop real-time decision support to help in the management of vascular diseases.","",""
9,"Ankeeta R. Patel, M. Joshi","Heart diseases diagnosis using neural network",2013,"","","","",194,"2022-07-13 10:09:04","","10.1109/ICCCNT.2013.6726740","","",,,,,9,1.00,5,2,9,"Neural network based systems have been used in past years in medical diagnosis applications because of their ability to learn human expertise and to utilize this knowledge for segregation. In this paper, neural based system is developed for heart diseases classification. The proposed system transforms sensor inputs to stroke stage classification. Multi layer feed forward network with back propagation learning algorithm is used. With a view to ascertain the efficacy of proposed system, performance is compared to other neural (system) based approaches. Simulation results show robustness of proposed system in all kind of test data given.","",""
0,"Zhiqiang Sui","Robust Scene Estimation for Goal-directed Robotic Manipulation in Unstructured Environments",2020,"","","","",195,"2022-07-13 10:09:04","","","","",,,,,0,0.00,0,1,2,"To make autonomous robots taskable such that they function properly, meet human expectations, and interact fluently with human partners, they must be able to perceive and understand the semantic aspects of their environments. However, the everyday world that humans inhabit is dynamic and unstructured. Many semantic aspects of the unstructured environment are difficult for robots to sense directly due to the limited field-of-view and noisy observations from their onboard sensors. The unstructured environment (e.g. objects in dense clutter) further results in substantial perceptual aliases from state-of-the-art neural networks. Furthermore, robots cannot reply on complete knowledge from the single observation so they have to continuously acquire information necessary to support decision making. In this thesis, we propose three methods that perform robust scene estimation in unstructured environments. We first propose Axiomatic Particle Filter (APF), a pure generative approach, to estimate the distribution over scene graphs, in which each object is a node and inter-object relations are edges. Possible world states are hypothesized to explain the true world state and the only maximal likely state estimate is used for planning. The ambiguity can then be alleviated with further information after a robot manipulation action. However, this approach assumes known object identification which leads to known data association. To avoid this assumption, we propose Sequential Scene Understanding and Manipulation (SUM) to leverage the strength from discriminative learning and generative probabilistic method. SUM considers noisy detections from learning algorithms, performs a greedy data association and addresses this uncertainty through a generative process. To deal with objects in severe occlusions, we propose GeoFusion, a SLAM-based scene estimation method, to fuse noisy measurements from different viewpoints. Geometric consistency is considered at the object-level. It offers a fast and reliable data association process which is robust to perceptual aliases. Meanwhile it enforces proper geometric contact between objects through graph optimization. Chair: Prof. Chad Jenkins Robust Scene Estimation for Goal-directed Robotic Manipulation in Unstructured Environments","",""
1,"Jichang Ma, Hui Xie, K. Song, Hao Liu","A Bayesian Driver Agent Model for Autonomous Vehicles System Based on Knowledge-Aware and Real-Time Data",2021,"","","","",196,"2022-07-13 10:09:04","","10.3390/s21020331","","",,,,,1,1.00,0,4,1,"A key research area in autonomous driving is how to model the driver’s decision-making behavior, due to the fact it is significant for a self-driving vehicles considering their traffic safety and efficiency. However, the uncertain characteristics of vehicle and pedestrian trajectories affect urban roads, which poses severe challenges to the cognitive understanding and decision-making of autonomous vehicle systems in terms of accuracy and robustness. To overcome the abovementioned problems, this paper proposes a Bayesian driver agent (BDA) model which is a vision-based autonomous vehicle system with learning and inference methods inspired by human driver’s cognitive psychology. Different from the end-to-end learning method and traditional rule-based methods, our approach breaks the driving system up into a scene recognition module and a decision inference module. The perception module, which is based on a multi-task learning neural network (CNN), takes a driver’s-view image as its input and predicts the traffic scene’s feature values. The decision module based on dynamic Bayesian network (DBN) then makes an inferred decision using the traffic scene’s feature values. To explore the validity of the Bayesian driver agent model, we performed experiments on a driving simulation platform. The BDA model can extract the scene feature values effectively and predict the probability distribution of the human driver’s decision-making process accurately based on inference. We take the lane changing scenario as an example to verify the model, the intraclass correlation coefficient (ICC) correlation between the BDA model and human driver’s decision process reached 0.984. This work suggests a research in scene perception and autonomous decision-making that may apply to autonomous vehicle system.","",""
5,"Cory Shain, I. Blank, Evelina Fedorenko, E. Gibson, William Schuler","Robust effects of working memory demand during naturalistic language comprehension in language-selective cortex",2021,"","","","",197,"2022-07-13 10:09:04","","10.1101/2021.09.18.460917","","",,,,,5,5.00,1,5,1,"A standard view of human language processing is that comprehenders build richly structured mental representations of natural language utterances, word by word, using computationally costly memory operations supported by domain-general working memory resources. However, three core claims of this view have been questioned, with some prior work arguing that (1) rich word-by-word structure building is not a core function of the language comprehension system, (2) apparent working memory costs are underlyingly driven by word predictability (surprisal), and/or (3) language comprehension relies primarily on domain-general rather than domain-specific working memory resources. In this work, we simultaneously evaluate all three of these claims using naturalistic comprehension in fMRI. In each participant, we functionally localize (a) a language-selective network and (b) a ‘multiple-demand’ network that supports working memory across domains, and we analyze the responses in these two networks of interest during naturalistic story listening with respect to a range of theory-driven predictors of working memory demand under rigorous surprisal controls. Results show robust surprisal-independent effects of word-by-word memory demand in the language network and no effect of working memory demand in the multiple demand network. Our findings thus support the view that language comprehension (1) entails word-by-word structure building using (2) computationally intensive memory operations that are not explained by surprisal. However, these results challenge (3) the domain-generality of the resources that support these operations, instead indicating that working memory operations for language comprehension are carried out by the same neural resources that store linguistic knowledge. Significance Statement This study uses fMRI to investigate signatures of working memory (WM) demand during naturalistic story listening, using a broad range of theoretically motivated estimates of WM demand. Results support a strong effect of WM demand in language-selective brain regions but no effect of WM demand in “multiple demand” regions that have previously been associated with WM in non-linguistic domains. We further show evidence that WM effects in language regions are distinct from effects of word predictability. Our findings support a core role for WM in incremental language processing, using WM resources that are specialized for language.","",""
1,"Aosong Feng, P. Panda","Energy-efficient and Robust Cumulative Training with Net2Net Transformation",2020,"","","","",198,"2022-07-13 10:09:04","","10.1109/IJCNN48605.2020.9207451","","",,,,,1,0.50,1,2,2,"Deep learning has achieved state-of-the-art accuracies on several computer vision tasks. However, the computational and energy requirements associated with training such deep neural networks can be quite high. In this paper, we propose a cumulative training strategy with Net2Net transformation that achieves training computational efficiency without incurring large accuracy loss, in comparison to a model trained from scratch. We achieve this by first training a small network (with lesser parameters) on a small subset of the original dataset, and then gradually expanding the network using Net2Net transformation to train incrementally on larger subsets of the dataset. This incremental training strategy with Net2Net utilizes function-preserving transformations that transfers knowledge from each previous small network to the next larger network, thereby, reducing the overall training complexity. Our experiments demonstrate that compared with training from scratch, cumulative training yields ~2x reduction in computational complexity for training TinyImageNet using VGG19 at iso-accuracy. Besides training efficiency, a key advantage of our cumulative training strategy is that we can perform pruning during Net2Net expansion to obtain a final network with optimal configuration (~0.4x lower inference compute complexity) compared to conventional training from scratch. We also demonstrate that the final network obtained from cumulative training yields better generalization performance and noise robustness. Further, we show that mutual inference from all the networks created with cumulative Net2Net expansion enables improved adversarial input detection.","",""
4,"Ching-Hung Lee, W. Lai","Nonlinear control of benchmark problems using TSK-type fuzzy neural network",2013,"","","","",199,"2022-07-13 10:09:04","","10.1007/s00521-012-1250-5","","",,,,,4,0.44,2,2,9,"","",""
3,"Zachary A. Daniels, Logan Frank, Christopher Menart, M. Raymer, P. Hitzler","A framework for explainable deep neural models using external knowledge graphs",2020,"","","","",200,"2022-07-13 10:09:04","","10.1117/12.2558083","","",,,,,3,1.50,1,5,2,"Deep neural networks (DNNs) have become the gold standard for solving challenging classification problems, especially given complex sensor inputs (e.g., images and video). While DNNs are powerful, they are also brittle, and their inner workings are not fully understood by humans, leading to their use as “black-box” models. DNNs often generalize poorly when provided new data sampled from slightly shifted distributions; DNNs are easily manipulated by adversarial examples; and the decision-making process of DNNs can be difficult for humans to interpret. To address these challenges, we propose integrating DNNs with external sources of semantic knowledge. Large quantities of meaningful, formalized knowledge are available in knowledge graphs and other databases, many of which are publicly obtainable. But at present, these sources are inaccessible to deep neural methods, which can only exploit patterns in the signals they are given to classify. In this work, we conduct experiments on the ADE20K dataset, using scene classification as an example task where combining DNNs with external knowledge graphs can result in more robust and explainable models. We align the atomic concepts present in ADE20K (i.e., objects) to WordNet, a hierarchically-organized lexical database. Using this knowledge graph, we expand the concept categories which can be identified in ADE20K and relate these concepts in a hierarchical manner. The neural architecture we present performs scene classification using these concepts, illuminating a path toward DNNs which can efficiently exploit high-level knowledge in place of excessive quantities of direct sensory input. We hypothesize and experimentally validate that incorporating background knowledge via an external knowledge graph into a deep learning-based model should improve the explainability and robustness of the model.","",""
