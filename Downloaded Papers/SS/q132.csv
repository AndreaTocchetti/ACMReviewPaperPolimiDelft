Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
2,"Lei Gu, R. Wu","Robust Cortical Criticality and Diverse Neural Network Dynamics Resulting from Functional Specification",2020,"","","","",1,"2022-07-13 10:07:43","","10.1101/2020.10.23.352849","","",,,,,2,1.00,1,2,2,"Despite recognized layered structure and increasing evidence for criticality in the cortex, how the specification of input, output and computational layers affects the self-organized criticality has been surprisingly neglected. By constructing heterogeneous structures with a well-accepted model of leaky neurons, we found that the specification can lead to robust criticality almost insensitive to the strength of external stimuli. This naturally unifies the adaptation to strong inputs without extra synaptic plasticity mechanisms. Presence of output neurons constitutes an alternative explanation to subcriticality other than the high frequency inputs. Degree of recurrence is proposed as a network metric to account for the signal termination due to output neurons. Unlike fully recurrent networks where external stimuli always render subcriticality, the dynamics of networks with sufficient feed-forward connections can be driven to criticality and supercriticality. These findings indicate that functional and structural specification and their interplay with external stimuli are of crucial importance for the network dynamics. The robust criticality puts forward networks of the leaky neurons as a promising platform for realizing artificial neural networks that work in the vicinity of critical points.","",""
22,"Zifan Wang, Yilin Yang, Ankit Shrivastava, Varun Rawal, Zihao Ding","Towards Frequency-Based Explanation for Robust CNN",2020,"","","","",2,"2022-07-13 10:07:43","","","","",,,,,22,11.00,4,5,2,"Current explanation techniques towards a transparent Convolutional Neural Network (CNN) mainly focuses on building connections between the human-understandable input features with models' prediction, overlooking an alternative representation of the input, the frequency components decomposition. In this work, we present an analysis of the connection between the distribution of frequency components in the input dataset and the reasoning process the model learns from the data. We further provide quantification analysis about the contribution of different frequency components toward the model's prediction. We show that the vulnerability of the model against tiny distortions is a result of the model is relying on the high-frequency features, the target features of the adversarial (black and white-box) attackers, to make the prediction. We further show that if the model develops stronger association between the low-frequency component with true labels, the model is more robust, which is the explanation of why adversarially trained models are more robust against tiny distortions.","",""
0,"Hongwei Zhang, Can Wang, Yuanqing Xia, Tijin Yan","Information Fusion of Topological Structure and Node Features in Graph Neural Network",2021,"","","","",3,"2022-07-13 10:07:43","","10.23919/CCC52363.2021.9550081","","",,,,,0,0.00,0,4,1,"Graph neural networks(GNNs) have shown great popularity and achieved promising performance on various graph-based tasks in the past years. However, there is little work that explores the information fusion mechanism, which plays an import role in GNNs. Besides, datasets in the real world often have noises, which make the information fusion difficult. In this paper, we give an information-theoretic explanation. Specifically, we focus on how the information from topological structures and node features fuses and how different information contributes to the downstream task. Furthermore, we propose a general framework named M-GCN to express the fusion process in GNNs. Graph embeddings and feature graph are introduced to extract the information from topological structure and node features separately in M-GCN. Extensive experiments are conducted on several benchmark datasets and experimental results show that our proposed models are more robust and outperform state-of-the-art methods.","",""
1,"David Morales, Estefanía Talavera, Beatriz Remeseiro","Playing to distraction: towards a robust training of CNN classifiers through visual explanation techniques",2020,"","","","",4,"2022-07-13 10:07:43","","10.1007/s00521-021-06282-2","","",,,,,1,0.50,0,3,2,"","",""
7,"Laura Rieger, L. K. Hansen","Aggregating explanation methods for stable and robust explainability.",2019,"","","","",5,"2022-07-13 10:07:43","","","","",,,,,7,2.33,4,2,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. We provide evidence that the aggregation is better at identifying important features, than on individual methods. Adversarial attacks on explanations is a recent active research topic. As our second contribution, we present evidence that aggregate explanations are much more robust to attacks than individual explanation methods.","",""
0,"Junho Kim, Seong-Tae Kim, Seong Tae Kim, Y. Ro","Robust Perturbation for Visual Explanation: Cross-Checking Mask Optimization to Avoid Class Distortion",2021,"","","","",6,"2022-07-13 10:07:43","","10.1109/TIP.2021.3130526","","",,,,,0,0.00,0,4,1,"Along with the outstanding performance of the deep neural networks (DNNs), considerable research efforts have been devoted to finding ways to understand the decision of DNNs structures. In the computer vision domain, visualizing the attribution map is one of the most intuitive and understandable ways to achieve human-level interpretation. Among them, perturbation-based visualization can explain the “black box” property of the given network by optimizing perturbation masks that alter the network prediction of the target class the most. However, existing perturbation methods could make unexpected changes to network predictions after applying a perturbation mask to the input image, resulting in a loss of robustness and fidelity of the perturbation mechanisms. In this paper, we define class distortion as the unexpected changes of the network prediction during the perturbation process. To handle that, we propose a novel visual interpretation framework, Robust Perturbation, which shows robustness against the unexpected class distortion during the mask optimization. With a new cross-checking mask optimization strategy, our proposed framework perturbs the target prediction of the network while upholding the non-target predictions, providing more reliable and accurate visual explanations. We evaluate our framework on three different public datasets through extensive experiments. Furthermore, we propose a new metric for class distortion evaluation. In both quantitative and qualitative experiments, tackling the class distortion problem turns out to enhance the quality and fidelity of the visual explanation in comparison with the existing perturbation-based methods.","",""
0,"","AGGREGATING EXPLANATION METHODS FOR NEURAL NETWORKS STABILIZES EXPLANATIONS",2019,"","","","",7,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,0,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. The aggregation is more robust and aligns better with the neural network than any single explanation method.. Second, we propose a new approach to evaluating explanation methods that circumvents the need for manual evaluation and is not reliant on the alignment of neural networks and humans decision processes.","",""
0,"Gu Xiao, Huibin Wang, Jie Shen, Zhe Chen, Zhen Zhang","An Adaptive Hierarchical Concatenated Network With A Robust Loss Function For Image Denoising",2022,"","","","",8,"2022-07-13 10:07:43","","10.1007/s10723-022-09601-6","","",,,,,0,0.00,0,5,1,"","",""
7,"Emanuele La Malfa, A. Zbrzezny, Rhiannon Michelmore, Nicola Paoletti, M. Kwiatkowska","On Guaranteed Optimal Robust Explanations for NLP Models",2021,"","","","",9,"2022-07-13 10:07:43","","10.24963/366","","",,,,,7,7.00,1,5,1,"We build on abduction-based explanations for machine learning and develop a method for computing local explanations for neural network models in natural language processing (NLP). Our explanations comprise a subset of the words of the input text that satisfies two key features: optimality w.r.t. a user-defined cost function, such as the length of explanation, and robustness, in that they ensure prediction invariance for any bounded perturbation in the embedding space of the left-out words. We present two solution algorithms, respectively based on implicit hitting sets and maximum universal subsets, introducing a number of algorithmic improvements to speed up convergence of hard instances. We show how our method can be configured with different perturbation sets in the embedded space and used to detect bias in predictions by enforcing include/exclude constraints on biased terms, as well as to enhance existing heuristic-based NLP explanation frameworks such as Anchors. We evaluate our framework on three widely used sentiment analysis tasks and texts of up to 100 words from SST, Twitter and IMDB datasets, demonstrating the effectiveness of the derived explanations.","",""
4,"Jay Roberts, Theodoros Tsiligkaridis","Controllably Sparse Perturbations of Robust Classifiers for Explaining Predictions and Probing Learned Concepts",2021,"","","","",10,"2022-07-13 10:07:43","","","","",,,,,4,4.00,2,2,1,"Explaining the predictions of a deep neural network (DNN) in image classification is an active area of research. Many methods focus on localizing pixels, or groups of pixels, which maximize a relevance metric for the prediction. Others aim at creating local ""proxy"" explainers which aim to account for an individual prediction of a model. We aim to explore ""why"" a model made a prediction by perturbing inputs to robust classifiers and interpreting the semantically meaningful results. For such an explanation to be useful for humans it is desirable for it to be sparse; however, generating sparse perturbations can computationally expensive and infeasible on high resolution data. Here we introduce controllably sparse explanations that can be efficiently generated on higher resolution data to provide improved counter-factual explanations. Further we use these controllably sparse explanations to probe what the robust classifier has learned. These explanations could provide insight for model developers as well as assist in detecting dataset bias. CCS Concepts • Computing methodologies → Machine learning; Artificial intelligence;","",""
1,"Yuchai Wan, Zhongshu Zheng, Ran Liu, Zheng Zhu, Hongen Zhou, Xun Zhang, Said Boumaraf","A Multi-Scale and Multi-Level Fusion Approach for Deep Learning-Based Liver Lesion Diagnosis in Magnetic Resonance Images with Visual Explanation",2021,"","","","",11,"2022-07-13 10:07:43","","10.3390/life11060582","","",,,,,1,1.00,0,7,1,"Many computer-aided diagnosis methods, especially ones with deep learning strategies, of liver cancers based on medical images have been proposed. However, most of such methods analyze the images under only one scale, and the deep learning models are always unexplainable. In this paper, we propose a deep learning-based multi-scale and multi-level fusing approach of CNNs for liver lesion diagnosis on magnetic resonance images, termed as MMF-CNN. We introduce a multi-scale representation strategy to encode both the local and semi-local complementary information of the images. To take advantage of the complementary information of multi-scale representations, we propose a multi-level fusion method to combine the information of both the feature level and the decision level hierarchically and generate a robust diagnostic classifier based on deep learning. We further explore the explanation of the diagnosis decision of the deep neural network through visualizing the areas of interest of the network. A new scoring method is designed to evaluate whether the attention maps can highlight the relevant radiological features. The explanation and visualization make the decision-making process of the deep neural network transparent for the clinicians. We apply our proposed approach to various state-of-the-art deep learning architectures. The experimental results demonstrate the effectiveness of our approach.","",""
1,"R. Vardhan, Ninghao Liu, Phakpoom Chinprutthiwong, Weijie Fu, Zhen Hu, Xia Hu, G. Gu","ExAD: An Ensemble Approach for Explanation-based Adversarial Detection",2021,"","","","",12,"2022-07-13 10:07:43","","","","",,,,,1,1.00,0,7,1,"Recent research has shown Deep Neural Networks (DNNs) to be vulnerable to adversarial examples that induce desired misclassifications in the models. Such risks impede the application of machine learning in security-sensitive domains. Several defense methods have been proposed against adversarial attacks to detect adversarial examples at test time or to make machine learning models more robust. However, while existing methods are quite effective under blackbox threat model, where the attacker is not aware of the defense, they are relatively ineffective under whitebox threat model, where the attacker has full knowledge of the defense. In this paper, we propose ExAD, a framework to detect adversarial examples using an ensemble of explanation techniques. Each explanation technique in ExAD produces an explanation map identifying the relevance of input variables for the model’s classification. For every class in a dataset, the system includes a detector network, corresponding to each explanation technique, which is trained to distinguish between normal and abnormal explanation maps. At test time, if the explanation map of an input is detected as abnormal by any detector model of the classified class, then we consider the input to be an adversarial example. We evaluate our approach using six state-of-the-art adversarial attacks on three image datasets. Our extensive evaluation shows that our mechanism can effectively detect these attacks under blackbox threat model with limited false-positives. Furthermore, we find that our approach achieves promising results in limiting the success rate of whitebox attacks.","",""
7,"Thorben Funke, Megha Khosla, Avishek Anand","Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks",2021,"","","","",13,"2022-07-13 10:07:43","","","","",,,,,7,7.00,2,3,1,"With the ever-increasing popularity and applications of graph neural networks, several proposals have been made to explain and understand the decisions of a graph neural network. Explanations for graph neural networks differ in principle from other input settings. It is important to attribute the decision to input features and other related instances connected by the graph structure. We find that the previous explanation generation approaches that maximize the mutual information between the label distribution produced by the model and the explanation to be restrictive. Specifically, existing approaches do not enforce explanations to be valid, sparse, or robust to input perturbations. In this paper, we lay down some of the fundamental principles that an explanation method for graph neural networks should follow and introduce a metric RDT-Fidelity as a measure of the explanation’s effectiveness. We propose a novel approach Zorro based on the principles from rate-distortion theory that uses a simple combinatorial procedure to optimize for RDT-Fidelity. Extensive experiments on real and synthetic datasets reveal that Zorro produces sparser, stable, and more faithful explanations than existing graph neural network explanation approaches.","",""
8,"Simón C. Smith, S. Ramamoorthy","Counterfactual Explanation and Causal Inference In Service of Robustness in Robot Control",2020,"","","","",14,"2022-07-13 10:07:43","","10.1109/ICDL-EpiRob48136.2020.9278061","","",,,,,8,4.00,4,2,2,"We propose an architecture for training generative models of counterfactual conditionals of the form, ‘can we modify event A to cause B instead of C?’, motivated by applications in robot control. Using an ‘adversarial training’ paradigm, an image-based deep neural network model is trained to produce small and realistic modifications to an original image in order to cause user-defined effects. These modifications can be used in the design process of image-based robust control - to determine the ability of the controller to return to a working regime by modifications in the input space, rather than by adaptation. In contrast to conventional control design approaches, where robustness is quantified in terms of the ability to reject noise, we explore the space of counterfactuals that might cause a certain requirement to be violated, thus proposing an alternative model that might be more expressive in certain robotics applications. So, we propose the generation of counterfactuals as an approach to explanation of black-box models and the envisioning of potential movement paths in autonomous robotic control. Firstly, we demonstrate this approach in a set of classification tasks, using the well known MNIST and CelebFaces Attributes datasets. Then, addressing multi-dimensional regression, we demonstrate our approach in a reaching task with a physical robot, and in a navigation task with a robot in a digital twin simulation.","",""
0,"Simón C. Smith, S. Ramamoorthy","Counterfactual Explanation and Causal in Service of Robustness in Robot Control",2020,"","","","",15,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,2,2,"We propose an architecture for training generative models of counterfactual conditionals of the form, ‘can we modify event A to cause B instead of C?’, motivated by applications in robot control. Using an ‘adversarial training’ paradigm, an image-based deep neural network model is trained to produce small and realistic modifications to an original image in order to cause user-defined effects. These modifications can be used in the design process of image-based robust control to determine the ability of the controller to return to a working regime by modifications in the input space, rather than by adaptation. In contrast to conventional control design approaches, where robustness is quantified in terms of the ability to reject noise, we explore the space of counterfactuals that might cause a certain requirement to be violated, thus proposing an alternative model that might be more expressive in certain robotics applications. So, we propose the generation of counterfactuals as an approach to explanation of black-box models and the envisioning of potential movement paths in autonomous robotic control. Firstly, we demonstrate this approach in a set of classification tasks, using the well known MNIST and CelebFaces Attributes datasets. Then, addressing multi-dimensional regression, we demonstrate our approach in a reaching task with a physical robot, and in a navigation task with a robot in a digital twin simulation.","",""
0,"Junhee Lee, Hyeonseong Cho, Yun Jang Pyun, Suk‐Ju Kang, H. Nam","Heatmap Assisted Accuracy Score Evaluation Method for Machine-Centric Explainable Deep Neural Networks",2022,"","","","",16,"2022-07-13 10:07:43","","10.1109/access.2022.3184453","","",,,,,0,0.00,0,5,1,"There have existed many studies about the explainable artificial intelligence (XAI) that explains the logic behind the complex deep neural network called a black box. At the same time, researchers have tried to evaluate the explainability performance of various XAIs. However, most previous evaluation methods are human-centric, that is, subjective, where they rely on how much the results of explanation are similar to what people’s decision is based on rather than what features actually affect the decision in the model. Their XAI selections are also dependent of datasets. Furthermore, they are focusing only on the output variation of a target class. On the other hand, this paper proposes a robust heatmap assisted accuracy score (HAAS) scheme over datasets that helps selecting machine-centric explanation algorithms to show what actually leads to the decision of a given classification network. The proposed method modifies the input image with the heatmap scores obtained by a given explanation algorithm and then puts the resultant heatmap assisted (HA) images into the network to estimate the accuracy change. The resultant metric (<inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula>) is computed as a ratio of accuracies of the given network over HA and original images. The proposed evaluation scheme is verified in the image classification models of LeNet-5 for MNIST and VGG-16 for CIFAR-10, STL-10, and ILSVRC2012 over totally 11 XAI algorithms of saliency map, deconvolution, and 9 layer-wise relevance propagation (LRP) configurations. Consequently, for LRP1 and LRP3, MINST showed largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> values of 1.0088 and 1.0079, CIFAR-10 achieved 1.1160 and 1.1254, STL-10 had 1.0906 and 1.0918, and ILSVRC2012 got 1.3207 and 1.3469. While LRP1 consists of <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for input, convolutional, and fully-connected layers, LRP3 adopts a bounded-rule for an input layer and the same <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for other layers as LRP1. The consistency of evaluation results of HAAS and AOPC has been compared by means of Kullback-Leibler divergence, ensuring that HAAS is the more robust evaluation method than AOPC independently of datasets since HAAS has much lower average divergence of 0.0251 than AOPC of 0.3048. In addition, the validity of the proposed HAAS scheme is further investigated through the inverted HA test that employs inverted HA images made up with inverted heatmap scores and estimates the accuracy degradation caused by applying them to the network. The XAI algorithms with largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> results experience biggest accuracy degradation in the inverted HA test.","",""
0,"Nuno Calaim, F. Dehmelt, P. J. Gonçalves, Christian K. Machens","The geometry of robustness in spiking neural networks.",2022,"","","","",17,"2022-07-13 10:07:43","","10.7554/eLife.73276","","",,,,,0,0.00,0,4,1,"Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate howneural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons; subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a 'bounding box'. Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synapticweights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we showthat functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks-low-dimensional representations, heterogeneity of tuning, and precise negative feedback-may be key to understanding the robustness of neural systems at the circuit level.","",""
7,"Laura Rieger, L. K. Hansen","Aggregating explainability methods for neural networks stabilizes explanations",2019,"","","","",18,"2022-07-13 10:07:43","","","","",,,,,7,2.33,4,2,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. In fact, most works rely on manually assessing the explanation to evaluate the quality of a method. This injects uncertainty in the explanation process along several dimensions: Which explanation method to apply? Who should we ask to evaluate it and which criteria should be used for the evaluation? Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. Our findings show that the aggregation is more robust, well-aligned with human explanations and can attribute relevance to a broader set of features (completeness). Second, we propose a novel way of evaluating explanation methods that circumvents the need for manual evaluation and is not reliant on the alignment of neural networks and humans decision processes.","",""
1,"Klemen Pečnik, V. Todorovic, M. Bošnjak, M. Čemažar, I. Kononenko, G. Serša, J. Plavec","The General Explanation Method with NMR Spectroscopy Enables the Identification of Metabolite Profiles Specific for Normal and Tumor Cell Lines",2018,"","","","",19,"2022-07-13 10:07:43","","10.1002/cbic.201800392","","",,,,,1,0.25,0,7,4,"Machine learning models in metabolomics, despite their great prediction accuracy, are still not widely adopted owing to the lack of an efficient explanation for their predictions. In this study, we propose the use of the general explanation method to explain the predictions of a machine learning model to gain detailed insight into metabolic differences between biological systems. The method was tested on a dataset of 1H NMR spectra acquired on normal lung and mesothelial cell lines and their tumor counterparts. Initially, the random forests and artificial neural network models were applied to the dataset, and excellent prediction accuracy was achieved. The predictions of the models were explained with the general explanation method, which enabled identification of discriminating metabolic concentration differences between individual cell lines and enabled the construction of their specific metabolic concentration profiles. This intuitive and robust method holds great promise for in‐depth understanding of the mechanisms that underline phenotypes as well as for biomarker discovery in complex diseases.","",""
0,"Kazutaka Uchida, Masayuki Tanaka, M. Okutomi","Extraction of Degradation Parameters for Transparency of an Image Restoration Network",2019,"","","","",20,"2022-07-13 10:07:43","","10.1109/GCCE46687.2019.9015336","","",,,,,0,0.00,0,3,3,"Many image restoration processors based on convolutional neural network (CNN) has been proposed because of its high performance. However, it is well known that restoration by these networks is not robust against perturbations on a degradation model. If restoration fails, it is difficult for users to find the cause because no explanation is given by the network. In this paper, we propose an additional network to extract internal parameters for an image restoration network to supply users explaining information on restoration process. Experimental results show that the proposed network successfully extracts estimated degradation attributes and gives helpful information to assist users to find a root cause of a restoration failure.","",""
9,"Xiaoting Shao, Arseny Skryagin, Wolfgang Stammer, P. Schramowski, K. Kersting","Right for Better Reasons: Training Differentiable Models by Constraining their Influence Functions",2021,"","","","",21,"2022-07-13 10:07:43","","","","",,,,,9,9.00,2,5,1,"Explaining black-box models such as deep neural networks is becoming increasingly important as it helps to boost trust and debugging. Popular forms of explanations map the features to a vector indicating their individual importance to a decision on the instance-level. They can then be used to prevent the model from learning the wrong bias in data possibly due to ambiguity. For instance, Ross et al.’s “right for the right rea- sons” propagates user explanations backwards to the network by formulating differentiable constraints based on input gra- dients. Unfortunately, input gradients as well as many other widely used explanation methods form an approximation of the decision boundary and assume the underlying model to be ﬁxed. Here, we demonstrate how to make use of inﬂuence functions—a well known robust statistic—in the constraints to correct the model’s behaviour more effectively. Our em- pirical evidence demonstrates that this “right for better rea-sons”(RBR) considerably reduces the time to correct the clas- siﬁer at training time and boosts the quality of explanations at inference time compared to input gradients. Besides, we also showcase the effectiveness of RBR in correcting ”Clever Hans”-like behaviour in real, high-dimensional domain.","",""
4,"Adam Ivankay, Ivan Girardi, Chiara Marchiori, P. Frossard","FAR: A General Framework for Attributional Robustness",2020,"","","","",22,"2022-07-13 10:07:43","","","","",,,,,4,2.00,1,4,2,"Attribution maps have gained popularity as tools for explaining neural networks predictions. By assigning an importance value to each input dimension that represents their influence towards the outcome, they give an intuitive explanation of the decision process. However, recent work has discovered vulnerability of these maps to imperceptible, carefully crafted changes in the input that lead to significantly different attributions, rendering them meaningless. By borrowing notions of traditional adversarial training - a method to achieve robust predictions - we propose a novel framework for attributional robustness (FAR) to mitigate this vulnerability. Central assumption is that similar inputs should yield similar attribution maps, while keeping the prediction of the network constant. Specifically, we define a new generic regularization term and training objective that minimizes the maximal dissimilarity of attribution maps in a local neighbourhood of the input. We then show how current state-of-the-art methods can be recovered through principled instantiations of these objectives. Moreover, we propose two new training methods, AAT and AdvAAT, derived from the framework, that directly optimize for robust attributions and predictions. We showcase the effectivity of our training methods by comparing them to current state-of-the-art attributional robustness approaches on widely used vision datasets. Experiments show that they perform better or comparably to current methods in terms of attributional robustness, while being applicable to any attribution method and input data domain. We finally show that our methods mitigate undesired dependencies of attributional robustness and some training and estimation parameters, which seem to critically affect other methods.","",""
1,"Ginevra Carbone, G. Sanguinetti, L. Bortolussi","Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks",2021,"","","","",23,"2022-07-13 10:07:43","","","","",,,,,1,1.00,0,3,1,"—We consider the problem of the stability of saliency- based explanations of Neural Network predictions under adversarial attacks in a classiﬁcation task. Saliency interpretations of deterministic Neural Networks are remarkably brittle even when the attacks fail, i.e. for attacks that do not change the classiﬁcation label. We empirically show that interpretations provided by Bayesian Neural Networks are considerably more stable under adversarial perturbations of the inputs and even under direct attacks to the explanations. By leveraging recent results, we also provide a theoretical explanation of this result in terms of the geometry of the data manifold. Additionally, we discuss the stability of the interpretations of high level representations of the inputs in the internal layers of a Network. Our results demonstrate that Bayesian methods, in addition to being more robust to adversarial attacks, have the potential to provide more stable and interpretable assessments of Neural Network predictions.","",""
0,"Sahana Ramnath, Preksha Nema, Deep Sahni, Mitesh M. Khapra","A Framework for Rationale Extraction for Deep QA models",2021,"","","","",24,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,4,1,"As neural-network-based QA models become deeper and more complex, there is a demand for robust frameworks which can access a model’s rationale for its prediction. Current techniques that provide insights on a model’s working are either dependent on adversarial datasets or are proposing models with explicit explanation generation components. These techniques are time-consuming and challenging to extend to existing models and new datasets. In this work, we use ‘Integrated Gradients’ to extract rationale for existing state-ofthe-art models in the task of Reading Comprehension based Question Answering (RCQA). On detailed analysis and comparison with collected human rationales, we find that though ∼40-80% words of extracted rationale coincide with the human rationale (precision), only 6-19% of human rationale is present in the extracted rationale (recall).","",""
0,"M. Serrurier, F. Mamalet, Thomas Fel, Louis B'ethune, Thibaut Boissin","When adversarial attacks become interpretable counterfactual explanations",2022,"","","","",25,"2022-07-13 10:07:43","","10.48550/arXiv.2206.06854","","",,,,,0,0.00,0,5,1,"We argue that, when learning a 1-Lipschitz neural network with the dual loss of an optimal transportation problem, the gradient of the model is both the direction of the transportation plan and the direction to the closest adversarial attack. Traveling along the gradient to the decision boundary is no more an adversarial attack but becomes a counterfactual explanation, explicitly transporting from one class to the other. Through extensive experiments on XAI metrics, we find that the simple saliency map method, applied on such networks, becomes a reliable explanation, and outperforms the state-of-the-art explanation approaches on unconstrained models. The proposed networks were already known to be certifiably robust, and we prove that they are also explainable with a fast and simple method.","",""
2,"Radoslaw Martin Cichy, A. Khosla, D. Pantazis, A. Oliva","Dynamics of Scene Representations in the Human Brain revealed by MEG and Deep Neural Networks",2015,"","","","",26,"2022-07-13 10:07:43","","","","",,,,,2,0.29,1,4,7,"Human scene recognition is a rapid multistep process evolving over time from single scene image to spatial layout processing. We used multivariate pattern analyses on magnetoencephalography (MEG) data to unravel the time course of this cortical process. Following an early signal for lower-level visual analysis of single scenes at ∼ 100ms, we found a marker of real-world scene size, i.e., spatial layout processing, at ∼ 250ms indexing neural representations robust to changes in unrelated scene properties and viewing conditions. For a quantitative explanation that captures the complexity of scene recognition, we compared MEG data to a deep neural network model trained on scene classification. Representations of scene size emerged intrinsically in the model, and resolved emerging neural scene size representation. Together our data provide a first description of an electrophysiological signal for layout processing in humans, and a novel quantitative model of how spatial layout representations may emerge in the human brain. The supplemental materials are available at: http://brainmodels.csail.mit.edu/scene-size","",""
8,"R. Taheri, R. Javidan, Zahra Pooranian","Adversarial android malware detection for mobile multimedia applications in IoT environments",2020,"","","","",27,"2022-07-13 10:07:43","","10.1007/s11042-020-08804-x","","",,,,,8,4.00,3,3,2,"","",""
0,"Radoslaw Martin Cichy, A. Khosla, D. Pantazis, A. Oliva","Title : Dynamics of scene representations in the human brain revealed by 1 magnetoencephalography and deep neural networks 2 3",2015,"","","","",28,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,4,7,"22. CC-BY-NC-ND 4.0 International license peer-reviewed) is the author/funder. It is made available under a The copyright holder for this preprint (which was not. ABSTRACT 23 24 Human scene recognition is a rapid multistep process evolving over time from single 25 scene image to spatial layout processing. We used multivariate pattern analyses on 26 magnetoencephalography (MEG) data to unravel the time course of this cortical process. 27 Following an early signal for lower-level visual analysis of single scenes at ~100ms, we 28 found a marker of real-world scene size, i.e. spatial layout processing, at ~250ms 29 indexing neural representations robust to changes in unrelated scene properties and 30 viewing conditions. For a quantitative explanation that captures the complexity of scene 31 recognition, we compared MEG data to a deep neural network model trained on scene 32 classification. Representations of scene size emerged intrinsically in the model, and 33 resolved emerging neural scene size representation. Together our data provide a first 34 description of an electrophysiological signal for layout processing in humans, and a novel 35 quantitative model of how spatial layout representations may emerge in the human brain. 36 37 38 39 40 41 KEY WORDS 42 43 Scene perception, spatial layout, magnetoencephalography, deep neural network, 44 representational similarity analysis 45 46. CC-BY-NC-ND 4.0 International license peer-reviewed) is the author/funder. It is made available under a The copyright holder for this preprint (which was not .","",""
8,"Laura Rieger, L. K. Hansen","A simple defense against adversarial attacks on heatmap explanations",2020,"","","","",29,"2022-07-13 10:07:43","","","","",,,,,8,4.00,4,2,2,"With machine learning models being used for more sensitive applications, we rely on interpretability methods to prove that no discriminating attributes were used for classification. A potential concern is the so-called ""fair-washing"" - manipulating a model such that the features used in reality are hidden and more innocuous features are shown to be important instead.  In our work we present an effective defence against such adversarial attacks on neural networks. By a simple aggregation of multiple explanation methods, the network becomes robust against manipulation. This holds even when the attacker has exact knowledge of the model weights and the explanation methods used.","",""
2,"Agnieszka Mikołajczyk, M. Grochowski, Arkadiusz Kwasigroch","Global explanations for discovering bias in data",2020,"","","","",30,"2022-07-13 10:07:43","","","","",,,,,2,1.00,1,3,2,"In the paper, we propose attention-based summarized post-hoc explanations for detection and identification of bias in data. We propose a global explanation and introduce a step-by-step framework on how to detect and test bias. Then, the bias is evaluated with a proposed counterfactual approach to bias insertion. Because removing the unwanted bias is often a complicated and tremendous task, we automatically insert it, instead. We validate our results on the example of the skin lesion dataset. Using the method, we successfully identified and confirmed part of the possible bias-causing artifacts in dermoscopy images. We confirmed that the commonplace black frames in the training dataset images have a strong influence on the Convolutional Neural Network's prediction. After artificially adding a black frame to all images, around 22% of them changed the prediction from benign to malignant. We have shown that bias detection is an important step of making more robust models, and we discuss how to improve them","",""
5,"Nuno Calaim, F. Dehmelt, P. J. Gonçalves, Christian K. Machens","Robustness in spiking networks: a geometric perspective",2020,"","","","",31,"2022-07-13 10:07:43","","10.1101/2020.06.15.148338","","",,,,,5,2.50,1,4,2,"Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate how neural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons’ subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a ‘bounding box.’ Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synaptic weights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we show that functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks—low-dimensional representations, heterogeneity of tuning, and precise negative feedback—may be key to understanding the robustness of neural systems at the circuit level.","",""
44,"R. Abeysuriya, J. Hadida, S. Sotiropoulos, S. Jbabdi, R. Becker, Benjamin A. E. Hunt, M. Brookes, M. Woolrich","A biophysical model of dynamic balancing of excitation and inhibition in fast oscillatory large-scale networks",2018,"","","","",32,"2022-07-13 10:07:43","","10.1371/journal.pcbi.1006007","","",,,,,44,11.00,6,8,4,"Over long timescales, neuronal dynamics can be robust to quite large perturbations, such as changes in white matter connectivity and grey matter structure through processes including learning, aging, development and certain disease processes. One possible explanation is that robust dynamics are facilitated by homeostatic mechanisms that can dynamically rebalance brain networks. In this study, we simulate a cortical brain network using the Wilson-Cowan neural mass model with conduction delays and noise, and use inhibitory synaptic plasticity (ISP) to dynamically achieve a spatially local balance between excitation and inhibition. Using MEG data from 55 subjects we find that ISP enables us to simultaneously achieve high correlation with multiple measures of functional connectivity, including amplitude envelope correlation and phase locking. Further, we find that ISP successfully achieves local E/I balance, and can consistently predict the functional connectivity computed from real MEG data, for a much wider range of model parameters than is possible with a model without ISP.","",""
2,"Shivika Singh, Arun Ravi, S. Gosavi, Disha Gundecha, Akshit Akhoury, Paras Shah, Sahil Joshi, Nishant Gavhane","Analysis and Comparison of Calibration Techniques for COTS Sensors Onboard a Nanosatellite",2019,"","","","",33,"2022-07-13 10:07:43","","10.1109/AERO.2019.8742132","","",,,,,2,0.67,0,8,3,"This paper explains and compares the different methods that could be used to characterize and calibrate COTS sensors onboard a 2U class nanosatellite. Attitude sensors are used in satellite missions for determination of attitude in orbit and then using this information for controlling the satellite for effective payload action. The paper focuses on the two major sensors on board; the Anisotropic Magnetoresistance (AMR) Magnetometer and a Micro-Electro-Mechanical Systems (MEMS) Gyroscope. The COTS sensors tend to have manufacturing defects which lead to internal errors and external factors like temperature adding to the deviation from the true value. A robust explanation of the factors affecting the sensor values and a corresponding functioning of the mathematical model built on the various internal sources of error and external stimulants which affect the output of these sensors is provided. In contrast to mathematical modeling, an offboard neural network uses the method of backpropagation for defining a nonlinear relationship between the raw sensor values and the actual values. The calibrated values obtained from the application of the mathematical error model and the neural network is presented through a series of graphs. Further critical analyses of the plots are done to obtain the best method to calibrate the particular sensor. This systematic calibration aids in improving the attitude estimation and control design of the satellite further leading to enhanced control on payload action. This enables the low-cost COTS sensors to be used in aerospace applications.","",""
0,"S. Saratha, Pei Fen Ng, Velavan Muraly","Application of Higher Order Hopfield Network",2013,"","","","",34,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,3,9,"Neural network and logic integration is the latest trend in Artificial Intelligence. Neural Symbolic Integration is a combination of neural networks’ robust learning capabilities with symbolic knowledge representation, reasoning, and explanation capabilities in ways that retain the strengths of each paradigm. In this paper, an Agent Based Modelling (ABM) was introduced by using Netlogo which carry out higher order horn clauses in Hopfield network. Our interest in this paper is confined largely to an important class of neural networks that perform useful computations through a process of learning. So, from the ABM that designed, we can carry out some computer simulation to verify and test the ABM develop.","",""
11,"Daniel Harborne, C. Willis, Richard J. Tomsett, A. Preece","Integrating learning and reasoning services for explainable information fusion",2018,"","","","",35,"2022-07-13 10:07:43","","","","",,,,,11,2.75,3,4,4,"—We present a distributed information fusion system  able to integrate heterogeneous information processing services  based on machine learning and reasoning approaches. We focus  on higher (semantic) levels of information fusion, and highlight  the requirement for the component services, and the system as  a whole, to generate explanations of its outputs. Using a case  study approach in the domain of traffic monitoring, we introduce  component services based on (i) deep neural network approaches  and (ii) heuristic-based reasoning. We examine methods for  explanation generation in each case, including both transparency  (e.g, saliency maps, reasoning traces) and post-hoc methods  (e.g, explanation in terms of similar examples, identification of  relevant semantic objects). We consider trade-offs in terms of  the classification performance of the services and the kinds of  available explanations, and show how service integration offers  more robust performance and explainability.","",""
3,"Sangchul Hahn, Heeyoul Choi","Gradient Acceleration in Activation Functions",2018,"","","","",36,"2022-07-13 10:07:43","","","","",,,,,3,0.75,2,2,4,"Dropout has been one of standard approaches to train deep neural networks, and it is known to regularize large models to avoid overfitting. The effect of dropout has been explained by avoiding co-adaptation. In this paper, however, we propose a new explanation of why dropout works and propose a new technique to design better activation functions. First, we show that dropout is an optimization technique to push the input towards the saturation area of nonlinear activation function by accelerating gradient information flowing even in the saturation area in backpropagation. Based on this explanation, we propose a new technique for activation functions, gradient acceleration in activation function (GAAF), that accelerates gradients to flow even in the saturation area. Then, input to the activation function can climb onto the saturation area which makes the network more robust because the model converges on a flat region. Experiment results support our explanation of dropout and confirm that the proposed GAAF technique improves performances with expected properties.","",""
91,"J. Shawe-Taylor, N. Cristianini","On the generalization of soft margin algorithms",2002,"","","","",37,"2022-07-13 10:07:43","","10.1109/TIT.2002.802647","","",,,,,91,4.55,46,2,20,"Generalization bounds depending on the margin of a classifier are a relatively new development. They provide an explanation of the performance of state-of-the-art learning systems such as support vector machines (SVMs) and Adaboost. The difficulty with these bounds has been either their lack of robustness or their looseness. The question of whether the generalization of a classifier can be more tightly bounded in terms of a robust measure of the distribution of margin values has remained open for some time. The paper answers this open question in the affirmative and, furthermore, the analysis leads to bounds that motivate the previously heuristic soft margin SVM algorithms as well as justifying the use of the quadratic loss in neural network training algorithms. The results are extended to give bounds for the probability of failing to achieve a target accuracy in regression prediction, with a statistical analysis of ridge regression and Gaussian processes as a special case. The analysis presented in the paper has also lead to new boosting algorithms described elsewhere.","",""
6,"R. Nayak","GYAN: A methodology for rule extraction from artificial neural networks",1999,"","","","",38,"2022-07-13 10:07:43","","","","",,,,,6,0.26,6,1,23,"Artificial neural network (ANN) learning methods provide a robust and non-linear approach to approximating the target function for many classification, regression and clustering problems. ANNs have demonstrated good predictive performance in a wide variety of practical problems. However, there are strong arguments as to why ANNs are not sufficient for the general representation of knowledge. The arguments are the poor comprehensibility of the learned ANN, and the inability to represent explanation structures.    The overall objective of this thesis is to address these issues by: (1) explanation of the decision process in ANNs in the form of symbolic rules (predicate rules with variables); and (2) provision of explanatory capability by mapping the general conceptual knowledge that is learned by the neural networks into a knowledge base to be used in a rule-based reasoning system.    A multi-stage methodology GYAN is developed and evaluated for the task of extracting knowledge from the trained ANNs. The extracted knowledge is represented in the form of restricted first-order logic rules, and subsequently allows user interaction by interfacing with a knowledge based reasoner. The performance of GYAN is demonstrated using a number of real world and artificial data sets. The empirical results demonstrate that: (1) an equivalent symbolic interpretation is derived describing the overall behaviour of the ANN with high accuracy and fidelity, and (2) a concise explanation is given (in terms of rules, facts and predicates activated in a reasoning episode) as to why a particular instance is being classified into a certain category.","",""
0,"S. Sahu, Rakesh Tripathi, Sanjay Kumar","Fundamental Techniques of Soft Computing",2017,"","","","",39,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,3,5,"This Book deals with basics and fundamental concepts and techniques of Soft Computing under the heading of Artificial Neural Network (ANN), Fuzzy Logic (FL) and Genetic Algorithms (GA) or Evolutionary Computing (EC). The subject covers the tools and methods to deal with the problems under uncertainty, imprecision, partial or incomplete information and offers the approximation to achieve the robust, low cost and optimal solution.The major objective of these components are learning or training of pattern, to work with inaccurate and partial truth information for the development of control system and to achieve the optimized solution. The salient features of the book are: i. Soft Computing fundamentals and concepts. ii. Explanation and Study of on various Neural Networks models and algorithms. iii. Description of Fuzzy Sets and Fuzzy Systems. iv. Overview of Genetic Algorithms and its applications. v. Discussions on problems for ANNs, FL and GAs.","",""
0,"A. Chella, R. Pirrone","A multilayer feedforward network for model estimation from range data",2002,"","","","",40,"2022-07-13 10:07:43","","10.1109/IJCNN.2002.1007692","","",,,,,0,0.00,0,2,20,"A novel neural architecture aimed to estimate superquadrics parameters form range data is presented. The network topology is designed to model and compute the inside-outside function of an undeformed superquadric in whatever attitude, starting from the (x,y,z) data triples. The network has been trained using backpropagation, and the weights arrangement, after training, represents a robust estimate of the superquadric parameters. The architectural approach is general, it can be extended to other geometric primitives for part-based object recognition, and performs faster than classical model fitting techniques. Detailed explanation of the theoretical approach, along with some experiments with real data, are reported.","",""
0,"D. Ingole, K. Kulat, M. D. Ingole","Application of Wavelet Analysis in Detection of Fault Diagnosis of Heart",2009,"","","","",41,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,3,13,"The ECG waveform is a non-stationary signal, and its variation can contain indicators of current disease or warnings about impending cardiac diseases. In this paper, we have evaluated wavelet transform (WT) based detector of ECG. Dyadic wavelet transform (DyWT) was used as prototype wavelet, which is robust to time varying & noise. It includes noise purification, sample design of digital ECG. This method can implement ECG report in real time and provide exact explanation for diagnostic decision obtained. We exemplify the performance of the DyWT based PQRST detector by considering problematic ECG signal from MIT-BIH database. From the results we observed that DyWT based detector exhibited superior performance compared to standard techniques. The paper deals with the classification of cardiac rhythms using an artificial neural network (ANN) for the use of fault diagnosis of heart..","",""
5,"G. Szirtes, Z. Palotai, A. Lorincz","Emergence of scale-free properties in Hebbian networks",2003,"","","","",42,"2022-07-13 10:07:43","","","","",,,,,5,0.26,2,3,19,"The fundamental `plasticity' of the nervous system (i.e high adaptability at different structural levels) is primarily based on Hebbian learning mechanisms that modify the synaptic connections. The modifications rely on neural activity and assign a special dynamic behavior to the neural networks. Another striking feature of the nervous system is that spike based information transmission, which is supposed to be robust against noise, is noisy in itself: the variance of the spiking of the individual neurons is surprisingly large which may deteriorate the adequate functioning of the Hebbian mechanisms. In this paper we focus on networks in which Hebbian-like adaptation is induced only by external random noise and study spike-timing dependent synaptic plasticity. We show that such `HebbNets' are able to develop a broad range of network structures, including scale-free small-world networks. The development of such network structures may provide an explanation of the role of noise and its interplay with Hebbian plasticity. We also argue that this model can be seen as a unification of the famous Watts-Strogatz and preferential attachment models of small-world nets.","",""
63,"Nina Pörner, Hinrich Schütze, Benjamin Roth","Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement",2018,"","","","",43,"2022-07-13 10:07:43","","10.18653/v1/P18-1032","","",,,,,63,15.75,21,3,4,"The behavior of deep neural networks (DNNs) is hard to understand. This makes it necessary to explore post hoc explanation methods. We conduct the first comprehensive evaluation of explanation methods for NLP. To this end, we design two novel evaluation paradigms that cover two important classes of NLP problems: small context and large context problems. Both paradigms require no manual annotation and are therefore broadly applicable. We also introduce LIMSSE, an explanation method inspired by LIME that is designed for NLP. We show empirically that LIMSSE, LRP and DeepLIFT are the most effective explanation methods and recommend them for explaining DNNs in NLP.","",""
16,"Ce Zhang, Young-Keun Kim, A. Eskandarian","EEG-inception: an accurate and robust end-to-end neural network for EEG-based motor imagery classification",2021,"","","","",44,"2022-07-13 10:07:43","","10.1088/1741-2552/abed81","","",,,,,16,16.00,5,3,1,"Objective. Classification of electroencephalography (EEG)-based motor imagery (MI) is a crucial non-invasive application in brain–computer interface (BCI) research. This paper proposes a novel convolutional neural network (CNN) architecture for accurate and robust EEG-based MI classification that outperforms the state-of-the-art methods. Approach. The proposed CNN model, namely EEG-inception, is built on the backbone of the inception-time network, which has showed to be highly efficient and accurate for time-series classification. Also, the proposed network is an end-to-end classification, as it takes the raw EEG signals as the input and does not require complex EEG signal-preprocessing. Furthermore, this paper proposes a novel data augmentation method for EEG signals to enhance the accuracy, at least by 3%, and reduce overfitting with limited BCI datasets. Main results. The proposed model outperforms all state-of-the-art methods by achieving the average accuracy of 88.4% and 88.6% on the 2008 BCI Competition IV 2a (four-classes) and 2b datasets (binary-classes), respectively. Furthermore, it takes less than 0.025 s to test a sample suitable for real-time processing. Moreover, the classification standard deviation for nine different subjects achieves the lowest value of 5.5 for the 2b dataset and 7.1 for the 2a dataset, which validates that the proposed method is highly robust. Significance. From the experiment results, it can be inferred that the EEG-inception network exhibits a strong potential as a subject-independent classifier for EEG-based MI tasks.","",""
22,"Hantao Huang, Jingye Zhou, Qingxun Di, Jiawei Zhou, Jiawang Li","Robust neural network–based tracking control and stabilization of a wheeled mobile robot with input saturation",2018,"","","","",45,"2022-07-13 10:07:43","","10.1002/rnc.4396","","",,,,,22,5.50,4,5,4,"This paper presents a robust neural network–based control scheme to deal with the problem of tracking and stabilization simultaneously for a wheeled mobile robot subject to parametric uncertainties, external disturbances, and input saturation. At first, a new error‐state transformation scheme is designed by introducing some auxiliary variables as an additional virtual control signals to reduce the adverse effect caused by the underactuation. These variables can change their structures for different desired trajectories to be tracked. Then, a robust control law is proposed combining with a kinematic controller and a dynamic controller, while a three‐layer neural network system is applied to approximate model uncertainties. Stability analysis via the Lyapunov theory shows that the proposed controller can make tracking errors converge to bounded neighborhoods of the origin. Finally, some simulation results are illustrated to verify the effectiveness of the proposed control strategy.","",""
84,"E. Saad, D. Wunsch","Neural network explanation using inversion",2007,"","","","",46,"2022-07-13 10:07:43","","10.1016/j.neunet.2006.07.005","","",,,,,84,5.60,42,2,15,"","",""
18,"R. Eberhart, R. W. Dobbins","Designing neural network explanation facilities using genetic algorithms",1991,"","","","",47,"2022-07-13 10:07:43","","10.1109/IJCNN.1991.170682","","",,,,,18,0.58,9,2,31,"The authors describe the use of genetic algorithms to provide components of explanation facilities for neural network applications. The genetic algorithm implementation, Genesis, uses a trained backpropagation neural network weight matrix as the genetic algorithm fitness function. Using different combinations of Genesis' run-time options, codebook vectors and decision surfaces are defined for the trained neural network. These vectors and surfaces can then be used as components of a facility that explains how the network is trained, and how it differentiates between classes. Two examples of this methodology are presented and briefly discussed. The first is a network trained to solve the XOR problem. The second is a network trained to diagnose appendicitis.<<ETX>>","",""
11,"H. Suleman, A. Maulud, Z. Man","Reconciliation of outliers in CO2-alkanolamine-H2O datasets by robust neural network winsorization",2017,"","","","",48,"2022-07-13 10:07:43","","10.1007/s00521-016-2213-z","","",,,,,11,2.20,4,3,5,"","",""
40,"Ding Wang, Derong Liu, C. Mu, Yun Zhang","Neural Network Learning and Robust Stabilization of Nonlinear Systems With Dynamic Uncertainties",2018,"","","","",49,"2022-07-13 10:07:43","","10.1109/TNNLS.2017.2749641","","",,,,,40,10.00,10,4,4,"Due to the existence of dynamical uncertainties, it is important to pay attention to the robustness of nonlinear control systems, especially when designing adaptive critic control strategies. In this paper, based on the neural network learning component, the robust stabilization scheme of nonlinear systems with general uncertainties is developed. Through system transformation and employing adaptive critic technique, the approximate optimal controller of the nominal plant can be applied to accomplish robust stabilization for the original uncertain dynamics. The neural network weight vector is very convenient to initialize by virtue of the improved critic learning formulation. Under the action of the approximate optimal control law, the stability issues for the closed-loop form of nominal and uncertain plants are analyzed, respectively. Simulation illustrations via a typical nonlinear system and a practical power system are included to verify the control performance.","",""
40,"Lei Liu, Zhanshan Wang, Huaguang Zhang","Neural-Network-Based Robust Optimal Tracking Control for MIMO Discrete-Time Systems With Unknown Uncertainty Using Adaptive Critic Design",2018,"","","","",50,"2022-07-13 10:07:43","","10.1109/TNNLS.2017.2660070","","",,,,,40,10.00,13,3,4,"This paper is concerned with the robust optimal tracking control strategy for a class of nonlinear multi-input multi-output discrete-time systems with unknown uncertainty via adaptive critic design (ACD) scheme. The main purpose is to establish an adaptive actor-critic control method, so that the cost function in the procedure of dealing with uncertainty is minimum and the closed-loop system is stable. Based on the neural network approximator, an action network is applied to generate the optimal control signal and a critic network is used to approximate the cost function, respectively. In contrast to the previous methods, the main features of this paper are: 1) the ACD scheme is integrated into the controllers to cope with the uncertainty and 2) a novel cost function, which is not in quadric form, is proposed so that the total cost in the design procedure is reduced. It is proved that the optimal control signals and the tracking errors are uniformly ultimately bounded even when the uncertainty exists. Finally, a numerical simulation is developed to show the effectiveness of the present approach.","",""
24,"G. Rajchakit, R. Sriraman","Robust Passivity and Stability Analysis of Uncertain Complex-Valued Impulsive Neural Networks with Time-Varying Delays",2021,"","","","",51,"2022-07-13 10:07:43","","10.1007/s11063-020-10401-w","","",,,,,24,24.00,12,2,1,"","",""
18,"M. Witczak, M. Mrugalski, J. Korbicz","Towards Robust Neural-Network-Based Sensor and Actuator Fault Diagnosis: Application to a Tunnel Furnace",2015,"","","","",52,"2022-07-13 10:07:43","","10.1007/s11063-014-9387-0","","",,,,,18,2.57,6,3,7,"","",""
30,"Ding Wang, Derong Liu, Yun Zhang, Hongyi Li","Neural network robust tracking control with adaptive critic framework for uncertain nonlinear systems",2018,"","","","",53,"2022-07-13 10:07:43","","10.1016/j.neunet.2017.09.005","","",,,,,30,7.50,8,4,4,"","",""
14,"Hui Zhao, Lixiang Li, Haipeng Peng, J. Kurths, Jinghua Xiao, Yixian Yang","Finite-Time Robust Synchronization of Memrisive Neural Network with Perturbation",2017,"","","","",54,"2022-07-13 10:07:43","","10.1007/s11063-017-9664-9","","",,,,,14,2.80,2,6,5,"","",""
13,"K. Sim, Y. Qian, G. Mantena, Lahiru Samarakoon, Souvik Kundu, T. Tan","Adaptation of Deep Neural Network Acoustic Models for Robust Automatic Speech Recognition",2017,"","","","",55,"2022-07-13 10:07:43","","10.1007/978-3-319-64680-0_9","","",,,,,13,2.60,2,6,5,"","",""
24,"S. Tortora, S. Ghidoni, C. Chisari, S. Micera, F. Artoni","Deep learning-based BCI for gait decoding from EEG with LSTM recurrent neural network.",2020,"","","","",56,"2022-07-13 10:07:43","","10.1088/1741-2552/ab9842","","",,,,,24,12.00,5,5,2,"OBJECTIVE Mobile Brain/Body Imaging (MoBI) frameworks allowed the research community to find evidence of cortical involvement at walking initiation and during locomotion. However, the decoding of gait patterns from brain signals remains an open challenge. The aim of this work is to propose and validate a deep learning model to decode gait phases from Electroenchephalography (EEG).   APPROACH A Long-Short Term Memory (LSTM) deep neural network has been trained to deal with time-dependent information within brain signals during locomotion. The EEG signals have been preprocessed by means of Artifacts Subspace Reconstruction (ASR) and Reliable Independent Component Analysis (RELICA) to ensure that classification performance was not affected by movement-related artifacts.   MAIN RESULT The network was evaluated on the dataset of 11 healthy subjects walking on a treadmill. The proposed decoding approach shows a robust reconstruction (AUC>90%) of gait patterns (i.e., swing and stance states) of both legs together, or of each leg independently.   SIGNIFICANCE Our results support for the first time the use of a memory-based deep learning classifier to decode walking activity from non-invasive brain recordings. We suggest that this classifier, exploited in real time, can be a more effective input for devices restoring locomotion in impaired people.","",""
28,"U. Oparaji, R. Sheu, M. Bankhead, J. Austin, E. Patelli","Robust artificial neural network for reliability and sensitivity analyses of complex non-linear systems",2017,"","","","",57,"2022-07-13 10:07:43","","10.1016/j.neunet.2017.09.003","","",,,,,28,5.60,6,5,5,"","",""
36,"T. Roshni, M. Jha, J. Drisya","Neural network modeling for groundwater-level forecasting in coastal aquifers",2020,"","","","",58,"2022-07-13 10:07:43","","10.1007/s00521-020-04722-z","","",,,,,36,18.00,12,3,2,"","",""
37,"C. Pham, Yaonan Wang","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",59,"2022-07-13 10:07:43","","10.1007/s00521-015-1873-4","","",,,,,37,6.17,19,2,6,"","",""
36,"Lin Sun, Jiucheng Xu, Shangwang Liu, Shiguang Zhang, Yuan Li, Chang'an Shen","A robust image watermarking scheme using Arnold transform and BP neural network",2018,"","","","",60,"2022-07-13 10:07:43","","10.1007/s00521-016-2788-4","","",,,,,36,9.00,6,6,4,"","",""
68,"Qiang Yu, Rui Yan, Huajin Tang, K. Tan, Haizhou Li","A Spiking Neural Network System for Robust Sequence Recognition",2016,"","","","",61,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2416771","","",,,,,68,11.33,14,5,6,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.","",""
75,"Qinmin Yang, S. Jagannathan, Youxian Sun","Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems",2015,"","","","",62,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2470175","","",,,,,75,10.71,25,3,7,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.","",""
61,"Zhijun Li, Yuanqing Xia, C. Su, Jun Deng, Jun Fu, W. He","Missile Guidance Law Based on Robust Model Predictive Control Using Neural-Network Optimization",2015,"","","","",63,"2022-07-13 10:07:43","","10.1109/TNNLS.2014.2345734","","",,,,,61,8.71,10,6,7,"In this brief, the utilization of robust model-based predictive control is investigated for the problem of missile interception. Treating the target acceleration as a bounded disturbance, novel guidance law using model predictive control is developed by incorporating missile inside constraints. The combined model predictive approach could be transformed as a constrained quadratic programming (QP) problem, which may be solved using a linear variational inequality-based primal-dual neural network over a finite receding horizon. Online solutions to multiple parametric QP problems are used so that constrained optimal control decisions can be made in real time. Simulation studies are conducted to illustrate the effectiveness and performance of the proposed guidance control law for missile interception.","",""
25,"Guoyang Liu, Weidong Zhou, Minxing Geng","Automatic Seizure Detection Based on S-Transform and Deep Convolutional Neural Network",2020,"","","","",64,"2022-07-13 10:07:43","","10.1142/S0129065719500242","","",,,,,25,12.50,8,3,2,"Automatic seizure detection is significant for the diagnosis of epilepsy and reducing the massive workload of reviewing continuous EEGs. In this work, a novel approach, combining Stockwell transform (S-transform) with deep Convolutional Neural Networks (CNN), is proposed to detect seizure onsets in long-term intracranial EEG recordings. Primarily, raw EEG data is filtered with wavelet decomposition. Then, S-transform is used to obtain a proper time-frequency representation of each EEG segment. After that, a 15-layer deep CNN using dropout and batch normalization serves as a robust feature extractor and classifier. Finally, smoothing and collar technique are applied to the outputs of CNN to improve the detection accuracy and reduce the false detection rate (FDR). The segment-based and event-based evaluation assessments and receiver operating characteristic (ROC) curves are employed for the performance evaluation on a public EEG database containing 21 patients. A segment-based sensitivity of 97.01% and a specificity of 98.12% are yielded. For the event-based assessment, this method achieves a sensitivity of 95.45% with an FDR of 0.36/h.","",""
48,"P. D. Cuong, W. Nan","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",65,"2022-07-13 10:07:43","","10.1007/s00521-015-1873-4","","",,,,,48,8.00,24,2,6,"","",""
3,"Yiya Hao, Abdullah Küçük, Anshuman Ganguly, I. Panahi","Spectral Flux-Based Convolutional Neural Network Architecture for Speech Source Localization and Its Real-Time Implementation",2020,"","","","",66,"2022-07-13 10:07:43","","10.1109/ACCESS.2020.3033533","","",,,,,3,1.50,1,4,2,"In this article, we present a real-time convolutional neural network (CNN)-based Speech source localization (SSL) algorithm that is robust to realistic background acoustic conditions (noise and reverberation). We have implemented and tested the proposed method on a prototype (Raspberry Pi) for real-time operation. We have used the combination of the imaginary-real coefficients of the short-time Fourier transform (STFT) and Spectral Flux (SF) with delay-and-sum (DAS) beamforming as the input feature. We have trained the CNN model using noisy speech recordings collected from different rooms and inference on an unseen room. We provide quantitative comparison with five other previously published SSL algorithms under several realistic noisy conditions, and show significant improvements by incorporating the Spectral Flux (SF) with beamforming as an additional feature to learn temporal variation in speech spectra. We perform real-time inferencing of our CNN model on the prototyped platform with low latency (21 milliseconds (ms) per frame with a frame length of 30 ms) and high accuracy (i.e. 89.68% under Babble noise condition at 5dB SNR). Lastly, we provide a detailed explanation of real-time implementation and on-device performance (including peak power consumption metrics) that sets this work apart from previously published works. This work has several notable implications for improving the audio-processing algorithms for portable battery-operated Smart loudspeakers and hearing improvement (HI) devices.","",""
22,"Masaki Kobayashi","Noise Robust Projection Rule for Hyperbolic Hopfield Neural Networks",2020,"","","","",67,"2022-07-13 10:07:43","","10.1109/TNNLS.2019.2899914","","",,,,,22,11.00,22,1,2,"A complex-valued Hopfield neural network (CHNN) is a multistate Hopfield model. Low noise tolerance is the main disadvantage of CHNNs. The hyperbolic Hopfield neural network (HHNN) is a noise robust multistate Hopfield model. In HHNNs employing the projection rule, noise tolerance rapidly worsened as the number of training patterns increased. This result was caused by the self-loops. The projection rule for CHNNs improves noise tolerance by removing the self-loops, however, that for HHNNs cannot remove them. In this brief, we extended the stability condition for the self-loops of HHNNs and modified the projection rule. Thus, the HHNNs had improved noise tolerance.","",""
25,"Hai Wang, Zhengming Xu, Do Manh Tuan, Jinchuan Zheng, Z. Cao, Linsen Xie","Neural-network-based robust control for steer-by-wire systems with uncertain dynamics",2015,"","","","",68,"2022-07-13 10:07:43","","10.1007/s00521-014-1819-2","","",,,,,25,3.57,4,6,7,"","",""
16,"Xuanqing Liu, Tesi Xiao, Uc Davis, Qin Cao","How Does Noise Help Robustness? Explanation and Exploration under the Neural SDE Framework",2020,"","","","",69,"2022-07-13 10:07:43","","10.1109/cvpr42600.2020.00036","","",,,,,16,8.00,4,4,2,"Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g., dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE), which naturally incorporates various commonly used regularization mechanisms based on random noise injection. For regularization purposes, our framework includes multiple types of noise patterns, such as dropout, additive, and multiplicative noise, which are common in plain neural networks. We provide some theoretical analyses explaining the improved robustness of our models against input perturbations. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.","",""
8,"S. Pontes-Filho, M. Liwicki","Bidirectional Learning for Robust Neural Networks",2018,"","","","",70,"2022-07-13 10:07:43","","10.1109/IJCNN.2019.8852120","","",,,,,8,2.00,4,2,4,"A multilayer perceptron can behave as a generative classifier by applying bidirectional learning (BL). It consists of training an undirected neural network to map input to output and vice-versa; therefore it can produce a classifier in one direction, and a generator in the opposite direction for the same data. The learning process of BL tries to reproduce the neuroplasticity stated in Hebbian theory using only backward propagation of errors. In this paper, two learning techniques are independently introduced which use BL for improving robustness to white noise static and adversarial examples. The first method is bidirectional propagation of errors, which the error propagation occurs in backward and forward directions. Motivated by the fact that its generative model receives as input a constant vector per class, we introduce as a second method the novel hybrid adversarial networks (HAN). Its generative model receives a random vector as input and its training is based on generative adversarial networks (GAN). To assess the performance of BL, we perform experiments using several architectures with fully and convolutional layers, with and without bias. Experimental results show that both methods improve robustness to white noise static and adversarial examples, and even increase accuracy, but have different behavior depending on the architecture and task, being more beneficial to use the one or the other. Nevertheless, HAN using a convolutional architecture with batch normalization presents outstanding robustness, reaching state-of-the-art accuracy on adversarial examples of hand-written digits.","",""
34,"H. Dinh, R. Kamalapurkar, S. Bhasin, W. Dixon","Dynamic neural network-based robust observers for uncertain nonlinear systems",2014,"","","","",71,"2022-07-13 10:07:43","","10.1016/j.neunet.2014.07.009","","",,,,,34,4.25,9,4,8,"","",""
64,"H. C. Liaw, B. Shirinzadeh, Julian Smith","Robust Neural Network Motion Tracking Control of Piezoelectric Actuation Systems for Micro/Nanomanipulation",2009,"","","","",72,"2022-07-13 10:07:43","","10.1109/TNN.2008.2004406","","",,,,,64,4.92,21,3,13,"This paper presents a robust neural network motion tracking control methodology for piezoelectric actuation systems employed in micro/nanomanipulation. This control methodology is proposed for tracking of desired motion trajectories in the presence of unknown system parameters, nonlinearities including the hysteresis effect and external disturbances in the control systems. In this paper, the related control issues are investigated, and a control methodology is established including the neural networks and a sliding control scheme. In particular, the radial basis function (RBF) neural networks are chosen for function approximations. The stability of the closed-loop system, as well as the convergence of the position and velocity tracking errors to zero, is assured by the control methodology in the presence of the aforementioned conditions. An offline learning procedure is also proposed for the improvement of the motion tracking performance. Precise tracking results of the proposed control methodology for a desired motion trajectory are demonstrated in the experimental study. With such a motion tracking capability, the proposed control methodology promises the realization of high-performance piezoelectric actuated micro/nanomanipulation systems.","",""
39,"H. Singh, N. Sukavanam","Stability analysis of robust adaptive hybrid position/force controller for robot manipulators using neural network with uncertainties",2013,"","","","",73,"2022-07-13 10:07:43","","10.1007/s00521-012-0966-6","","",,,,,39,4.33,20,2,9,"","",""
19,"Hassan Ali, Hammad Tariq, Muhammad Abdullah Hanif, Faiq Khalid, Semeen Rehman, Rehan Ahmed, M. Shafique","QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural Network against Adversarial Attacks",2018,"","","","",74,"2022-07-13 10:07:43","","10.1109/IOLTS.2019.8854377","","",,,,,19,4.75,3,7,4,"Adversarial examples have emerged as a significant threat to machine learning algorithms, especially to the convolutional neural networks (CNNs). In this paper, we propose two quantization-based defense mechanisms, Constant Quantization (CQ) and Trainable Quantization (TQ), to increase the robustness of CNNs against adversarial examples. CQ quantizes input pixel intensities based on a “fixed” number of quantization levels, while in TQ, the quantization levels are “iteratively learned during the training phase”, thereby providing a stronger defense mechanism. We apply the proposed techniques on undefended CNNs against different state-of-the-art adversarial attacks from the open-source Cleverhans library. The experimental results demonstrate 50%–96% and 10%–50% increase in the classification accuracy of the perturbed images generated from the MNIST and the CIFAR-10 datasets, respectively, on commonly used CNN (Conv2D(64, 8×8)-Conv2D(128, 6×6)-Conv2D(128, 5×5) - Dense(10) - Softmax()) available in Cleverhans library.","",""
1,"Huijun Wu, Chen Wang, R. Nock, Wei Wang, Jie Yin, Kai Lu, Liming Zhu","SMINT: Toward Interpretable and Robust Model Sharing for Deep Neural Networks",2020,"","","","",75,"2022-07-13 10:07:43","","10.1145/3381833","","",,,,,1,0.50,0,7,2,"Sharing a pre-trained machine learning model, particularly a deep neural network via prediction APIs, is becoming a common practice on machine learning as a service (MLaaS) platforms nowadays. Although deep neural networks (DNN) have shown remarkable successes in many tasks, they are also criticized for the lack of interpretability and transparency. Interpreting a shared DNN model faces two additional challenges compared with interpreting a general model. (1) Limited training data can be disclosed to users. (2) The internal structure of the models may not be available. These two challenges impede the application of most existing interpretability approaches, such as saliency maps or influence functions, for DNN models. Case-based reasoning methods have been used for interpreting decisions; however, how to select and organize the data points under the constraints of shared DNN models is not discussed. Moreover, simply providing cases as explanations may not be sufficient for supporting instance level interpretability. Meanwhile, existing interpretation methods for DNN models generally lack the means to evaluate the reliability of the interpretation. In this article, we propose a framework named Shared Model INTerpreter (SMINT) to address the above limitations. We propose a new data structure called a boundary graph to organize training points to mimic the predictions of DNN models. We integrate local features, such as saliency maps and interpretable input masks, into the data structure to help users to infer the model decision boundaries. We show that the boundary graph is able to address the reliability issues in many local interpretation methods. We further design an algorithm named hidden-layer aware p-test to measure the reliability of the interpretations. Our experiments show that SMINT is able to achieve above 99% fidelity to corresponding DNN models on both MNIST and ImageNet by sharing only a tiny fraction of training data to make these models interpretable. The human pilot study demonstrates that SMINT provides better interpretability compared with existing methods. Moreover, we demonstrate that SMINT is able to assist model tuning for better performance on different user data.","",""
1,"Yuyang Gao, Tong Sun, Guang-ying Bai, Siyi Gu, S. Hong, Liang Zhao","RES: A Robust Framework for Guiding Visual Explanation",2022,"","","","",76,"2022-07-13 10:07:43","","10.1145/3534678.3539419","","",,,,,1,1.00,0,6,1,"Despite the fast progress of explanation techniques in modern Deep Neural Networks (DNNs) where the main focus is handling “how to generate the explanations”, advanced research questions that exam-ine the quality of the explanation itself (e.g., “whether the explanations are accurate”) and improve the explanation quality (e.g., “how to adjust the model to generate more accurate explanations when explanations are inaccurate”) are still relatively under-explored. To guide the model toward better explanations, techniques in explanation supervision—which add supervision signals on the model explanation—have started to show promising effects on improving both the generalizability as and intrinsic interpretability of Deep Neural Networks. However, the research on supervising explanations, especially in vision-based applications represented through saliency maps, is in its early stage due to several inherent challenges: 1) inaccuracy of the human explanation annotation boundary, 2) incompleteness of the human explanation annotation region, and 3) inconsistency of the data distribution between human annotation and model explanation maps. To address the challenges, we propose a generic RES 1 framework for guiding visual explanation by developing a novel objective that handles inaccurate boundary, incomplete region, and inconsistent distribution of human annotations, with a theoretical justification on model generalizability. Extensive experiments on two real-world image datasets demonstrate the effectiveness of the proposed framework on enhancing","",""
22,"Walt Woods, Jack H Chen, C. Teuscher","Adversarial explanations for understanding image classification decisions and improved neural network robustness",2019,"","","","",77,"2022-07-13 10:07:43","","10.1038/s42256-019-0104-6","","",,,,,22,7.33,7,3,3,"","",""
24,"Ç. Aladag, E. Egrioglu, U. Yolcu","Robust multilayer neural network based on median neuron model",2014,"","","","",78,"2022-07-13 10:07:43","","10.1007/s00521-012-1315-5","","",,,,,24,3.00,8,3,8,"","",""
10,"Mohit Bajaj, Lingyang Chu, Zihui Xue, J. Pei, Lanjun Wang, P. C. Lam, Yong Zhang","Robust Counterfactual Explanations on Graph Neural Networks",2021,"","","","",79,"2022-07-13 10:07:43","","","","",,,,,10,10.00,1,7,1,"Massive deployment of Graph Neural Networks (GNNs) in high-stake applications generates a strong demand for explanations that are robust to noise and align well with human intuition. Most existing methods generate explanations by identifying a subgraph of an input graph that has a strong correlation with the prediction. These explanations are not robust to noise because independently optimizing the correlation for a single input can easily overfit noise. Moreover, they do not align well with human intuition because removing an identified subgraph from an input graph does not necessarily change the prediction result. In this paper, we propose a novel method to generate robust counterfactual explanations on GNNs by explicitly modelling the common decision logic of GNNs on similar input graphs. Our explanations are naturally robust to noise because they are produced from the common decision boundaries of a GNN that govern the predictions of many similar input graphs. The explanations also align well with human intuition because removing the set of edges identified by an explanation from the input graph changes the prediction significantly. Exhaustive experiments on many public datasets demonstrate the superior performance of our method.","",""
31,"Q. Song, J. Spall, Y. Soh, Jie-ke Ni","Robust Neural Network Tracking Controller Using Simultaneous Perturbation Stochastic Approximation",2008,"","","","",80,"2022-07-13 10:07:43","","10.1109/TNN.2007.912315","","",,,,,31,2.21,8,4,14,"This paper considers the design of robust neural network tracking controllers for nonlinear systems. The neural network is used in the closed-loop system to estimate the nonlinear system function. We introduce the conic sector theory to establish a robust neural control system, with guaranteed boundedness for both the input/output (I/O) signals and the weights of the neural network. The neural network is trained by the simultaneous perturbation stochastic approximation (SPSA) method instead of the standard backpropagation (BP) algorithm. The proposed neural control system guarantees closed-loop stability of the estimation system, and a good tracking performance. The performance improvement of the proposed system over existing systems can be quantified in terms of preventing weight shifts, fast convergence, and robustness against system disturbance.","",""
0,"Zhimin Li, Shusen Liu, Xin Yu, K. Bhavya, Jie Cao, Diffenderfer James Daniel, P. Bremer, Valerio Pascucci","""Understanding Robustness Lottery"": A Comparative Visual Analysis of Neural Network Pruning Approaches",2022,"","","","",81,"2022-07-13 10:07:43","","10.48550/arXiv.2206.07918","","",,,,,0,0.00,0,8,1,"Deep learning approaches have provided state-of-the-art performance in many applications by relying on extremely large and heavily overparameterized neural networks. However, such networks have been shown to be very brittle, not generalize well to new uses cases, and are often difficult if not impossible to deploy on resources limited platforms. Model pruning, i.e., reducing the size of the network, is a widely adopted strategy that can lead to more robust and generalizable network – usually orders of magnitude smaller with the same or even improved performance. While there exist many heuristics for model pruning, our understanding of the pruning process remains limited. Empirical studies show that some heuristics improve performance while others can make models more brittle or have other side effects. This work aims to shed light on how different pruning methods alter the network’s internal feature representation, and the corresponding impact on model performance. To provide a meaningful comparison and characterization of model feature space, we use three geometric metrics that are decomposed from the common adopted classification loss. With these metrics, we design a visualization system to highlight the impact of pruning on model prediction as well as the latent feature embedding. The proposed tool provides an environment for exploring and studying differences among pruning methods and between pruned and original model. By leveraging our visualization, the ML researchers can not only identify samples that are fragile to model pruning and data corruption but also obtain insights and explanations on how some pruned models achieve superior robustness performance.","",""
0,"Kazuki Adachi, Shin'ya Yamaguchi","Learning Robust Convolutional Neural Networks with Relevant Feature Focusing via Explanations",2022,"","","","",82,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,2,1,"Existing image recognition techniques based on convolutional neural networks (CNNs) basically assume that the training and test datasets are sampled from i.i.d distributions. However, this assumption is easily broken in the real world because of the distribution shift that occurs when the cooccurrence relations between objects and backgrounds in input images change. Under this type of distribution shift, CNNs learn to focus on features that are not task-relevant, such as backgrounds from the training data, and degrade their accuracy on the test data. To tackle this problem, we propose relevant feature focusing (ReFF). ReFF detects task-relevant features and regularizes CNNs via explanation outputs (e.g., Grad-CAM). Since ReFF is composed of post-hoc explanation modules, it can be easily applied to off-the-shelf CNNs. Furthermore, ReFF requires no additional inference cost at test time because it is only used for regularization while training. We demonstrate that CNNs trained with ReFF focus on features relevant to the target task and that ReFF improves the test-time accuracy.","",""
4,"Chih-Min Lin, Chin-Hsu Leng, Chun-Fei Hsu, Chiu-Hsiung Chen","Robust neural network control system design for linear ultrasonic motor",2009,"","","","",83,"2022-07-13 10:07:43","","10.1007/s00521-008-0228-9","","",,,,,4,0.31,1,4,13,"","",""
49,"Peng Wu, Jing Liu, Fang Shen","A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes",2020,"","","","",84,"2022-07-13 10:07:43","","10.1109/TNNLS.2019.2933554","","",,,,,49,24.50,16,3,2,"How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations’ diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.","",""
144,"Tong Yang, Ning Sun, He Chen, Yongchun Fang","Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones",2020,"","","","",85,"2022-07-13 10:07:43","","10.1109/TNNLS.2019.2910580","","",,,,,144,72.00,36,4,2,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.","",""
39,"H. Sadr, M. Pedram, M. Teshnehlab","A Robust Sentiment Analysis Method Based on Sequential Combination of Convolutional and Recursive Neural Networks",2019,"","","","",86,"2022-07-13 10:07:43","","10.1007/s11063-019-10049-1","","",,,,,39,13.00,13,3,3,"","",""
5,"Hongjun Wang, Guangrun Wang, Guanbin Li, Liang Lin","CamDrop: A New Explanation of Dropout and A Guided Regularization Method for Deep Neural Networks",2019,"","","","",87,"2022-07-13 10:07:43","","10.1145/3357384.3357999","","",,,,,5,1.67,1,4,3,"To force convolutional networks to explore more discriminative evidence throughout spatial regions, this paper presents a novel CamDrop to improve the conventional dropout in two aspects. First, by considering the intensity of class activation mapping (CAM) all around, CamDrop selectively abandons some specific spatial regions in predominating visual patterns at each iteration. In many classification tasks, CamDrop demonstrates its effectiveness and achieves considerable improvements on robust predictions for adversarial examples. Second, although dropout is a widely adopted technique that has been applied to regularize large models, the improvement in performance always attributes to better preventing DNN from overfitting. Here we give a new explanation of dropout from the perspective of optimization that it makes the upper bound of the magnitude of gradients much tighter, which leads to a more stable behavior of the gradients and effectively avoids neurons falling into the saturation region of the nonlinear activation, even when using high learning rates. Extensive experiments have been performed to prove the above two strengths of CamDrop.","",""
94,"C. Kwan, F. Lewis, D. Dawson","Robust neural-network control of rigid-link electrically driven robots",1998,"","","","",88,"2022-07-13 10:07:43","","10.1109/72.701172","","",,,,,94,3.92,31,3,24,"A robust neural-network (NN) controller is proposed for the motion control of rigid-link electrically driven (RLED) robots. Two-layer NN's are used to approximate two very complicated nonlinear functions. The main advantage of our approach is that the NN weights are tuned on-line, with no off-line learning phase required. Most importantly, we can guarantee the uniformly ultimately bounded (UUB) stability of tracking errors and NN weights. When compared with standard adaptive robot controllers, we do not require lengthy and tedious preliminary analysis to determine a regression matrix. The controller can be regarded as a universal reusable controller because the same controller can be applied to any type of RLED robots without any modifications.","",""
36,"Wei He, Yongkun Sun, Zichen Yan, Chenguang Yang, Zhijun Li, O. Kaynak","Disturbance Observer-Based Neural Network Control of Cooperative Multiple Manipulators With Input Saturation",2020,"","","","",89,"2022-07-13 10:07:43","","10.1109/TNNLS.2019.2923241","","",,,,,36,18.00,6,6,2,"In this paper, the complex problems of internal forces and position control are studied simultaneously and a disturbance observer-based radial basis function neural network (RBFNN) control scheme is proposed to: 1) estimate the unknown parameters accurately; 2) approximate the disturbance experienced by the system due to input saturation; and 3) simultaneously improve the robustness of the system. More specifically, the proposed scheme utilizes disturbance observers, neural network (NN) collaborative control with an adaptive law, and full state feedback. Utilizing Lyapunov stability principles, it is shown that semiglobally uniformly bounded stability is guaranteed for all controlled signals of the closed-loop system. The effectiveness of the proposed controller as predicted by the theoretical analysis is verified by comparative experimental studies.","",""
0,"Pau","Neural network signal understanding for instrumentation",2019,"","","","",90,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,1,3,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
15,"F. Ham, Sungjin Park","A robust neural network classifier for infrasound events using multiple array data",2002,"","","","",91,"2022-07-13 10:07:43","","10.1109/IJCNN.2002.1007556","","",,,,,15,0.75,8,2,20,"An integral part of the Comprehensive Nuclear-Test-Ban Treaty International Monitoring System is an infrasound monitoring network. This network has the capability to detect and verify infrasonic signals-of-interest, e.g., nuclear explosions, from other unwanted infrasound noise sources. The paper presents classification results of infrasonic events using a robust neural network.","",""
92,"Xiaojian Li, Guanghong Yang","Neural-Network-Based Adaptive Decentralized Fault-Tolerant Control for a Class of Interconnected Nonlinear Systems",2018,"","","","",92,"2022-07-13 10:07:43","","10.1109/TNNLS.2016.2616906","","",,,,,92,23.00,46,2,4,"This paper is concerned with the adaptive decentralized fault-tolerant tracking control problem for a class of uncertain interconnected nonlinear systems with unknown strong interconnections. An algebraic graph theory result is introduced to address the considered interconnections. In addition, to achieve the desirable tracking performance, a neural-network-based robust adaptive decentralized fault-tolerant control (FTC) scheme is given to compensate the actuator faults and system uncertainties. Furthermore, via the Lyapunov analysis method, it is proven that all the signals of the resulting closed-loop system are semiglobally bounded, and the tracking errors of each subsystem exponentially converge to a compact set, whose radius is adjustable by choosing different controller design parameters. Finally, the effectiveness and advantages of the proposed FTC approach are illustrated with two simulated examples.","",""
356,"M. Mirman, Timon Gehr, Martin T. Vechev","Differentiable Abstract Interpretation for Provably Robust Neural Networks",2018,"","","","",93,"2022-07-13 10:07:43","","","","",,,,,356,89.00,119,3,4,"We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.","",""
10,"Xiaotong Wang, Chih-Chen Chang, Fang Du","Achieving a More Robust Neural Network Model for Control of a MR Damper by Signal Sensitivity Analysis",2002,"","","","",94,"2022-07-13 10:07:43","","10.1007/s005210200005","","",,,,,10,0.50,3,3,20,"","",""
0,"D. Bzdok, J. Ioannidis","Deep ] neural networks are elaborate regression methods aimed solely at prediction , not estimation or explanation",2019,"","","","",95,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,2,3,"The last decades saw dramatic progress in brain research. These advances were often buttressed by probing single variables to make circumscribed discoveries, typically through null hypothesis significance testing. New ways for generating massive data fueled tension between the traditional methodology, used to infer statistically relevant effects in carefully-chosen variables, and pattern-learning algorithms, used to identify predictive signatures by searching through abundant information. In this article, we detail the antagonistic philosophies behind two quantitative approaches: certifying robust effects in understandable variables, and evaluating how accurately a built model can forecast future outcomes. We discourage choosing analysis tools via categories like ‘statistics’ or ‘machine learning’. Rather, to establish reproducible knowledge about the brain, we advocate prioritizing tools in view of the core motivation of each quantitative analysis: aiming towards mechanistic insight, or optimizing predictive accuracy.","",""
16,"Peng Xu, A. Chan","Fast and robust neural network based wheel bearing fault detection with optimal wavelet features",2002,"","","","",96,"2022-07-13 10:07:43","","10.1109/IJCNN.2002.1007461","","",,,,,16,0.80,8,2,20,"We propose a new design of a neural network based system to detect faulty bearings using acoustic signals in a noisy wayside environment. Statistical features are generated from discrete wavelet transform coefficients, and a genetic algorithm is used to select the optimal features. The false negative rate for detecting a condemnable bearing is as low as 0.1% regardless of the speed, load condition, and bearing type.","",""
14,"Chih-Min Lin, A. Ting, Ming-Chia Li, Te-Yu Chen","Neural-network-based robust adaptive control for a class of nonlinear systems",2011,"","","","",97,"2022-07-13 10:07:43","","10.1007/s00521-011-0561-2","","",,,,,14,1.27,4,4,11,"","",""
12,"Zheng Yan, Jun Wang","Robust model predictive control of nonlinear affine systems based on a two-layer recurrent neural network",2011,"","","","",98,"2022-07-13 10:07:43","","10.1109/IJCNN.2011.6033195","","",,,,,12,1.09,6,2,11,"A robust model predictive control (MPC) method is proposed for nonlinear affine systems with bounded disturbances. The robust MPC technique requires on-line solution of a minimax optimal control problem. The minimax strategy means that worst-case performance with respect to uncertainties is optimized. The minimax optimization problem involved in robust MPC is reformulated to a minimization problem and then is solved by using a two-layer recurrent neural network. Simulation examples are included to illustrate the effectiveness of the proposed method.","",""
619,"Mou Chen, S. Ge, B. How","Robust Adaptive Neural Network Control for a Class of Uncertain MIMO Nonlinear Systems With Input Nonlinearities",2010,"","","","",99,"2022-07-13 10:07:43","","10.1109/TNN.2010.2042611","","",,,,,619,51.58,206,3,12,"In this paper, robust adaptive neural network (NN) control is investigated for a general class of uncertain multiple-input-multiple-output (MIMO) nonlinear systems with unknown control coefficient matrices and input nonlinearities. For nonsymmetric input nonlinearities of saturation and deadzone, variable structure control (VSC) in combination with backstepping and Lyapunov synthesis is proposed for adaptive NN control design with guaranteed stability. In the proposed adaptive NN control, the usual assumption on nonsingularity of NN approximation for unknown control coefficient matrices and boundary assumption between NN approximation error and control input have been eliminated. Command filters are presented to implement physical constraints on the virtual control laws, then the tedious analytic computations of time derivatives of virtual control laws are canceled. It is proved that the proposed robust backstepping control is able to guarantee semiglobal uniform ultimate boundedness of all signals in the closed-loop system. Finally, simulation results are presented to illustrate the effectiveness of the proposed adaptive NN control.","",""
15,"Tianyu Guo, Chang Xu, Shiyi He, Boxin Shi, Chao Xu, D. Tao","Robust Student Network Learning",2018,"","","","",100,"2022-07-13 10:07:43","","10.1109/TNNLS.2019.2929114","","",,,,,15,3.75,3,6,4,"Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher–student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.","",""
27,"Sheng Zhang, W. Zheng","Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment",2018,"","","","",101,"2022-07-13 10:07:43","","10.1109/TNNLS.2017.2761259","","",,,,,27,6.75,14,2,4,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.","",""
29,"S. A. Taqvi, L. Tufa, H. Zabiri, A. Maulud, F. Uddin","Fault detection in distillation column using NARX neural network",2018,"","","","",102,"2022-07-13 10:07:43","","10.1007/s00521-018-3658-z","","",,,,,29,7.25,6,5,4,"","",""
76,"Yong Xu, Qiuqiang Kong, Qiang Huang, Wenwu Wang, Mark D. Plumbley","Convolutional gated recurrent neural network incorporating spatial features for audio tagging",2017,"","","","",103,"2022-07-13 10:07:43","","10.1109/IJCNN.2017.7966291","","",,,,,76,15.20,15,5,5,"Environmental audio tagging is a newly proposed task to predict the presence or absence of a specific audio event in a chunk. Deep neural network (DNN) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene. In this paper, we propose to use a convolutional neural network (CNN) to extract robust features from mel-filter banks (MFBs), spectrograms or even raw waveforms for audio tagging. Gated recurrent unit (GRU) based recurrent neural networks (RNNs) are then cascaded to model the long-term temporal structure of the audio signal. To complement the input information, an auxiliary CNN is designed to learn on the spatial features of stereo recordings. We evaluate our proposed methods on Task 4 (audio tagging) of the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE 2016) challenge. Compared with our recent DNN-based method, the proposed structure can reduce the equal error rate (EER) from 0.13 to 0.11 on the development set. The spatial features can further reduce the EER to 0.10. The performance of the end-to-end learning on raw waveforms is also comparable. Finally, on the evaluation set, we get the state-of-the-art performance with 0.12 EER while the performance of the best existing system is 0.15 EER.","",""
66,"Dechao Chen, Yunong Zhang","Robust Zeroing Neural-Dynamics and Its Time-Varying Disturbances Suppression Model Applied to Mobile Robot Manipulators",2018,"","","","",104,"2022-07-13 10:07:43","","10.1109/TNNLS.2017.2764529","","",,,,,66,16.50,33,2,4,"This paper proposes a novel robust zeroing neural-dynamics (RZND) approach as well as its associated model for solving the inverse kinematics problem of mobile robot manipulators. Unlike existing works based on the assumption that neural network models are free of external disturbances, four common forms of time-varying disturbances suppressed by the proposed RZND model are investigated in this paper. In addition, theoretical analyses on the antidisturbance performance are presented in detail to prove the effectiveness and robustness of the proposed RZND model with time-varying disturbances suppressed for solving the inverse kinematics problem of mobile robot manipulators. That is, the RZND model converges toward the exact solution of the inverse kinematics problem of mobile robot manipulators with bounded or zero-oriented steady-state position error. Moreover, simulation studies and comprehensive comparisons with existing neural network models, e.g., the conventional Zhang neural network model and the gradient-based recurrent neural network model, together with extensive tests with four common forms of time-varying disturbances substantiate the efficacy, robustness, and superiority of the proposed RZND approach as well as its time-varying disturbances suppression model for solving the inverse kinematics problem of mobile robot manipulators.","",""
47,"K. Shojaei","Three-dimensional neural network tracking control of a moving target by underactuated autonomous underwater vehicles",2019,"","","","",105,"2022-07-13 10:07:43","","10.1007/s00521-017-3085-6","","",,,,,47,15.67,47,1,3,"","",""
12,"H. Ninomiya","An Improved Online quasi-Newton method for robust training and its application to microwave neural network models",2010,"","","","",106,"2022-07-13 10:07:43","","10.1109/IJCNN.2010.5596655","","",,,,,12,1.00,12,1,12,"This paper describes a new technique for robust training of feedforward neural networks. The proposed algorithm is employed for the robust neural network training purpose. The quasi-Newton method was studied as one of the most efficient optimization algorithms based on the gradient descent and used as the batch training method of neural networks. On the other hand, the stochastic (online) quasi-Newton method was developed as an algorithm for the machine learning. In this paper the stochastic quasi-Newton training algorithm is improved for robust neural network training. Neural network training for some benchmark problems is presented to demonstrate the proposed algorithm. Furthermore, neural network training for microwave circuit modeling, such as the waveguide and the microstrip examples is presented, demonstrating that the proposed algorithm achieves more accurate models than both the batch and the stochastic quasi-Newton methods.","",""
83,"Juyeon Heo, Sunghwan Joo, Taesup Moon","Fooling Neural Network Interpretations via Adversarial Model Manipulation",2019,"","","","",107,"2022-07-13 10:07:43","","","","",,,,,83,27.67,28,3,3,"We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a model fine-tuning step that aims to radically alter the explanations without hurting the accuracy of the original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating the interpretation results directly in the penalty term of the objective function for fine-tuning, we show that the state-of-the-art saliency map based interpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with our model manipulation. We propose two types of fooling, Passive and Active, and demonstrate such foolings generalize well to the entire validation set as well as transfer to other interpretation methods. Our results are validated by both visually showing the fooled explanations and reporting quantitative metrics that measure the deviations from the original explanations. We claim that the stability of neural network interpretation method with respect to our adversarial model manipulation is an important criterion to check for developing robust and reliable neural network interpretation method.","",""
56,"Xinqiao Zhao, Hongmiao Zhang, Guilin Zhu, Fengxiang You, S. Kuang, Lining Sun","A Multi-Branch 3D Convolutional Neural Network for EEG-Based Motor Imagery Classification",2019,"","","","",108,"2022-07-13 10:07:43","","10.1109/TNSRE.2019.2938295","","",,,,,56,18.67,9,6,3,"One of the challenges in motor imagery (MI) classification tasks is finding an easy-handled electroencephalogram (EEG) representation method which can preserve not only temporal features but also spatial ones. To fully utilize the features on various dimensions of EEG, a novel MI classification framework is first introduced in this paper, including a new 3D representation of EEG, a multi-branch 3D convolutional neural network (3D CNN) and the corresponding classification strategy. The 3D representation is generated by transforming EEG signals into a sequence of 2D array which preserves spatial distribution of sampling electrodes. The multi-branch 3D CNN and classification strategy are designed accordingly for the 3D representation. Experimental evaluation reveals that the proposed framework reaches state-of-the-art classification kappa value level and significantly outperforms other algorithms by 50% decrease in standard deviation of different subjects, which shows good performance and excellent robustness on different subjects. The framework also shows great performance with only nine sampling electrodes, which can significantly enhance its practicality. Moreover, the multi-branch structure exhibits its low latency and a strong ability in mitigating overfitting issues which often occur in MI classification because of the small training dataset.","",""
27,"Mai Viet Thuan, D. C. Huong, Duong Thi Hong","New Results on Robust Finite-Time Passivity for Fractional-Order Neural Networks with Uncertainties",2018,"","","","",109,"2022-07-13 10:07:43","","10.1007/s11063-018-9902-9","","",,,,,27,6.75,9,3,4,"","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",110,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",111,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",112,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
18,"E. Egrioglu, U. Yolcu, E. Bas, Ali Z. Dalar","Median-Pi artificial neural network for forecasting",2019,"","","","",113,"2022-07-13 10:07:43","","10.1007/s00521-017-3002-z","","",,,,,18,6.00,5,4,3,"","",""
52,"L. Arras, Ahmed Osman, K. Müller, W. Samek","Evaluating Recurrent Neural Network Explanations",2019,"","","","",114,"2022-07-13 10:07:43","","10.18653/v1/W19-4813","","",,,,,52,17.33,13,4,3,"Recently, several methods have been proposed to explain the predictions of recurrent neural networks (RNNs), in particular of LSTMs. The goal of these methods is to understand the network’s decisions by assigning to each input variable, e.g., a word, a relevance indicating to which extent it contributed to a particular prediction. In previous works, some of these methods were not yet compared to one another, or were evaluated only qualitatively. We close this gap by systematically and quantitatively comparing these methods in different settings, namely (1) a toy arithmetic task which we use as a sanity check, (2) a five-class sentiment prediction of movie reviews, and besides (3) we explore the usefulness of word relevances to build sentence-level representations. Lastly, using the method that performed best in our experiments, we show how specific linguistic phenomena such as the negation in sentiment analysis reflect in terms of relevance patterns, and how the relevance visualization can help to understand the misclassification of individual samples.","",""
14,"Ann-Kathrin Dombrowski, Christopher J. Anders, K. Müller, P. Kessel","Towards Robust Explanations for Deep Neural Networks",2020,"","","","",115,"2022-07-13 10:07:43","","10.1016/j.patcog.2021.108194","","",,,,,14,7.00,4,4,2,"","",""
23,"Hao Li, S. Misra, Jiabo He","Neural network modeling of in situ fluid-filled pore size distributions in subsurface shale reservoirs under data constraints",2019,"","","","",116,"2022-07-13 10:07:43","","10.1007/s00521-019-04124-w","","",,,,,23,7.67,8,3,3,"","",""
17,"A. A. Khater, Ahmad M. El-Nagar, M. El-Bardini, N. El-Rabaie","Online learning based on adaptive learning rate for a class of recurrent fuzzy neural network",2019,"","","","",117,"2022-07-13 10:07:43","","10.1007/s00521-019-04372-w","","",,,,,17,5.67,4,4,3,"","",""
22,"Arpan Jain, Apoorva Mishra, A. Shukla, R. Tiwari","A Novel Genetically Optimized Convolutional Neural Network for Traffic Sign Recognition: A New Benchmark on Belgium and Chinese Traffic Sign Datasets",2019,"","","","",118,"2022-07-13 10:07:43","","10.1007/s11063-019-09991-x","","",,,,,22,7.33,6,4,3,"","",""
60,"Qingshan Liu, Jun Wang","$L_{1}$ -Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network",2016,"","","","",119,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2481006","","",,,,,60,10.00,30,2,6,"This paper presents several L1 -minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1 -minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1 -minimization algorithms.","",""
116,"Carlo Baldassi, C. Borgs, J. Chayes, Alessandro Ingrosso, C. Lucibello, Luca Saglietti, R. Zecchina","Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes",2016,"","","","",120,"2022-07-13 10:07:43","","10.1073/pnas.1608103113","","",,,,,116,19.33,17,7,6,"Significance Artificial neural networks are some of the most widely used tools in data science. Learning is, in principle, a hard problem in these systems, but in practice heuristic algorithms often find solutions with good generalization properties. We propose an explanation of this good performance in terms of a nonequilibrium statistical physics framework: We show that there are regions of the optimization landscape that are both robust and accessible and that their existence is crucial to achieve good performance on a class of particularly difficult learning problems. Building on these results, we introduce a basic algorithmic scheme that improves existing optimization algorithms and provides a framework for further research on learning in neural networks. In artificial neural networks, learning from data is a computationally demanding task in which a large number of connection weights are iteratively tuned through stochastic-gradient-based heuristic processes over a cost function. It is not well understood how learning occurs in these systems, in particular how they avoid getting trapped in configurations with poor computational performance. Here, we study the difficult case of networks with discrete weights, where the optimization landscape is very rough even for simple architectures, and provide theoretical and numerical evidence of the existence of rare—but extremely dense and accessible—regions of configurations in the network weight space. We define a measure, the robust ensemble (RE), which suppresses trapping by isolated configurations and amplifies the role of these dense regions. We analytically compute the RE in some exactly solvable models and also provide a general algorithmic scheme that is straightforward to implement: define a cost function given by a sum of a finite number of replicas of the original cost function, with a constraint centering the replicas around a driving assignment. To illustrate this, we derive several powerful algorithms, ranging from Markov Chains to message passing to gradient descent processes, where the algorithms target the robust dense states, resulting in substantial improvements in performance. The weak dependence on the number of precision bits of the weights leads us to conjecture that very similar reasoning applies to more conventional neural networks. Analogous algorithmic schemes can also be applied to other optimization problems.","",""
17,"Yali Dong, Huimin Wang","Robust Output Feedback Stabilization for Uncertain Discrete-Time Stochastic Neural Networks with Time-Varying Delay",2019,"","","","",121,"2022-07-13 10:07:43","","10.1007/s11063-019-10077-x","","",,,,,17,5.67,9,2,3,"","",""
14,"P. V. C. Souza, L. Torres, A. J. Guimarães, Vanessa Souza Araújo","Pulsar Detection for Wavelets SODA and Regularized Fuzzy Neural Networks Based on Andneuron and Robust Activation Function",2019,"","","","",122,"2022-07-13 10:07:43","","10.1142/S0218213019500039","","",,,,,14,4.67,4,4,3,"The use of intelligent models may be slow because of the number of samples involved in the problem. The identification of pulsars (stars that emit Earth-catchable signals) involves collecting thousands of signals by professionals of astronomy and their identification may be hampered by the nature of the problem, which requires many dimensions and samples to be analyzed. This paper proposes the use of hybrid models based on concepts of regularized fuzzy neural networks that use the representativeness of input data to define the groupings that make up the neurons of the initial layers of the model. The andneurons are used to aggregate the neurons of the first layer and can create fuzzy rules. The training uses fast extreme learning machine concepts to generate the weights of neurons that use robust activation functions to perform pattern classification. To solve large-scale problems involving the nature of pulsar detection problems, the model proposes a fast and highly accurate approach to address complex issues. In the execution of the tests with the proposed model, experiments were conducted explanation in two databases of pulsars, and the results prove the viability of the fast and interpretable approach in identifying such involved stars.","",""
25,"Michael Green, U. Ekelund, L. Edenbrandt, J. Björk, J. Forberg, M. Ohlsson","Exploring new possibilities for case-based explanation of artificial neural network ensembles",2009,"","","","",123,"2022-07-13 10:07:43","","10.1016/j.neunet.2008.09.014","","",,,,,25,1.92,4,6,13,"","",""
58,"S. Naz, A. I. Umar, Riaz Ahmad, S. Ahmed, S. H. Shirazi, M. I. Razzak","Urdu Nasta’liq text recognition system based on multi-dimensional recurrent neural network and statistical features",2017,"","","","",124,"2022-07-13 10:07:43","","10.1007/s00521-015-2051-4","","",,,,,58,11.60,10,6,5,"","",""
405,"David Alvarez-Melis, T. Jaakkola","Towards Robust Interpretability with Self-Explaining Neural Networks",2018,"","","","",125,"2022-07-13 10:07:43","","","","",,,,,405,101.25,203,2,4,"Most recent work on interpretability of complex machine learning models has focused on estimating a posteriori explanations for previously trained models around specific predictions. Self-explaining models where interpretability plays a key role already during learning have received much less attention. We propose three desiderata for explanations in general – explicitness, faithfulness, and stability – and show that existing methods do not satisfy them. In response, we design self-explaining models in stages, progressively generalizing linear classifiers to complex yet architecturally explicit models. Faithfulness and stability are enforced via regularization specifically tailored to such models. Experimental results across various benchmark datasets show that our framework offers a promising direction for reconciling model complexity and interpretability.","",""
5,"Min Han, Xinying Wang","Robust neural predictor for noisy chaotic time series prediction",2013,"","","","",126,"2022-07-13 10:07:43","","10.1109/IJCNN.2013.6706996","","",,,,,5,0.56,3,2,9,"A robust neural predictor is designed for noisy chaotic time series prediction in this paper. The main idea is based on the consideration of the bounded uncertainty in predictor input, and it is a typical Errors-in-Variables problem. The robust design is based on the linear-in-parameters ESN (Echo State Network) model. By minimizing the worst-case residual induced by the bounded perturbations in the echo state variables, the robust predictor is obtained in coping with the uncertainty in the noisy time series. In the experiment, the classical Mackey-Glass 84-step benchmark prediction task is investigated. The prediction performance is studied for the nominal and robust design of ESN predictors.","",""
22,"Ikbal Eski, Ş. Yıldırım","Neural network-based fuzzy inference system for speed control of heavy duty vehicles with electronic throttle control system",2017,"","","","",127,"2022-07-13 10:07:43","","10.1007/s00521-016-2362-0","","",,,,,22,4.40,11,2,5,"","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",128,"2022-07-13 10:07:43","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
19,"Xuhong Wang, Baihong Jin, Ying Du, Ping Cui, Yupu Yang","One-class graph neural networks for anomaly detection in attributed networks",2020,"","","","",129,"2022-07-13 10:07:43","","10.1007/S00521-021-05924-9","","",,,,,19,9.50,4,5,2,"","",""
64,"Qiang Chen, X. Ren, J. Na, Dong-dong Zheng","Adaptive robust finite-time neural control of uncertain PMSM servo system with nonlinear dead zone",2017,"","","","",130,"2022-07-13 10:07:43","","10.1007/s00521-016-2260-5","","",,,,,64,12.80,16,4,5,"","",""
104,"Liu Yang, Hanxin Chen","Fault diagnosis of gearbox based on RBF-PF and particle swarm optimization wavelet neural network",2019,"","","","",131,"2022-07-13 10:07:43","","10.1007/s00521-018-3525-y","","",,,,,104,34.67,52,2,3,"","",""
158,"C. Hua, X. Guan, P. Shi","Robust Output Feedback Tracking Control for Time-Delay Nonlinear Systems Using Neural Network",2007,"","","","",132,"2022-07-13 10:07:43","","10.1109/TNN.2006.888368","","",,,,,158,10.53,53,3,15,"In this paper, the problem of robust output tracking control for a class of time-delay nonlinear systems is considered. The systems are in the form of triangular structure with unmodeled dynamics. First, we construct an observer whose gain matrix is scheduled via linear matrix inequality approach. For the case that the information of uncertainties bounds is not completely available, we design an observer-based neural network (NN) controller by employing the backstepping method. The resulting closed-loop system is ensured to be stable in the sense of semiglobal boundedness with the help of changing supplying function idea. The observer and the controller designed are both independent of the time delays. Finally, numerical simulations are conducted to verify the effectiveness of the main theoretic results obtained","",""
29,"Q. Song, Jinde Cao","Robust Stability in Cohen–Grossberg Neural Network with both Time-Varying and Distributed Delays",2008,"","","","",133,"2022-07-13 10:07:43","","10.1007/s11063-007-9068-3","","",,,,,29,2.07,15,2,14,"","",""
692,"W. Samek, Alexander Binder, G. Montavon, S. Lapuschkin, K. Müller","Evaluating the Visualization of What a Deep Neural Network Has Learned",2015,"","","","",134,"2022-07-13 10:07:43","","10.1109/TNNLS.2016.2599820","","",,,,,692,98.86,138,5,7,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.","",""
29,"V. Krasnopolsky, M. Fox-Rabinovitz, H. Tolman, A. Belochitski","Neural network approach for robust and fast calculation of physical processes in numerical environmental models: Compound parameterization with a quality control of larger errors",2008,"","","","",135,"2022-07-13 10:07:43","","10.1016/j.neunet.2007.12.019","","",,,,,29,2.07,7,4,14,"","",""
38,"G. Lai, Zhi Liu, Yun Zhang, C. L. Chen","Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier",2016,"","","","",136,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2406812","","",,,,,38,6.33,10,4,6,"This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.","",""
18,"Claudio Ciancio, G. Ambrogio, F. Gagliardi, R. Musmanno","Heuristic techniques to optimize neural network architecture in manufacturing applications",2016,"","","","",137,"2022-07-13 10:07:43","","10.1007/s00521-015-1994-9","","",,,,,18,3.00,5,4,6,"","",""
75,"Vaibhav Gandhi, G. Prasad, D. Coyle, L. Behera, T. McGinnity","Quantum Neural Network-Based EEG Filtering for a Brain–Computer Interface",2014,"","","","",138,"2022-07-13 10:07:43","","10.1109/TNNLS.2013.2274436","","",,,,,75,9.38,15,5,8,"A novel neural information processing architecture inspired by quantum mechanics and incorporating the well-known Schrodinger wave equation is proposed in this paper. The proposed architecture referred to as recurrent quantum neural network (RQNN) can characterize a nonstationary stochastic signal as time-varying wave packets. A robust unsupervised learning algorithm enables the RQNN to effectively capture the statistical behavior of the input signal and facilitates the estimation of signal embedded in noise with unknown characteristics. The results from a number of benchmark tests show that simple signals such as dc, staircase dc, and sinusoidal signals embedded within high noise can be accurately filtered and particle swarm optimization can be employed to select model parameters. The RQNN filtering procedure is applied in a two-class motor imagery-based brain-computer interface where the objective was to filter electroencephalogram (EEG) signals before feature extraction and classification to increase signal separability. A two-step inner-outer fivefold cross-validation approach is utilized to select the algorithm parameters subject-specifically for nine subjects. It is shown that the subject-specific RQNN EEG filtering significantly improves brain-computer interface performance compared to using only the raw EEG or Savitzky-Golay filtered EEG across multiple sessions.","",""
140,"R. Wai, Rajkumar Muthusamy","Fuzzy-Neural-Network Inherited Sliding-Mode Control for Robot Manipulator Including Actuator Dynamics",2013,"","","","",139,"2022-07-13 10:07:43","","10.1109/TNNLS.2012.2228230","","",,,,,140,15.56,70,2,9,"This paper presents the design and analysis of an intelligent control system that inherits the robust properties of sliding-mode control (SMC) for an n-link robot manipulator, including actuator dynamics in order to achieve a high-precision position tracking with a firm robustness. First, the coupled higher order dynamic model of an n-link robot manipulator is briefy introduced. Then, a conventional SMC scheme is developed for the joint position tracking of robot manipulators. Moreover, a fuzzy-neural-network inherited SMC (FNNISMC) scheme is proposed to relax the requirement of detailed system information and deal with chattering control efforts in the SMC system. In the FNNISMC strategy, the FNN framework is designed to mimic the SMC law, and adaptive tuning algorithms for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. Numerical simulations and experimental results of a two-link robot manipulator actuated by DC servo motors are provided to justify the claims of the proposed FNNISMC system, and the superiority of the proposed FNNISMC scheme is also evaluated by quantitative comparison with previous intelligent control schemes.","",""
115,"Yong Xu, R. Lu, P. Shi, Jie Tao, S. Xie","Robust Estimation for Neural Networks With Randomly Occurring Distributed Delays and Markovian Jump Coupling",2018,"","","","",140,"2022-07-13 10:07:43","","10.1109/TNNLS.2016.2636325","","",,,,,115,28.75,23,5,4,"This paper studies the issue of robust state estimation for coupled neural networks with parameter uncertainty and randomly occurring distributed delays, where the polytopic model is employed to describe the parameter uncertainty. A set of Bernoulli processes with different stochastic properties are introduced to model the randomly occurrences of the distributed delays. Novel state estimators based on the local coupling structure are proposed to make full use of the coupling information. The augmented estimation error system is obtained based on the Kronecker product. A new Lyapunov function, which depends both on the polytopic uncertainty and the coupling information, is introduced to reduce the conservatism. Sufficient conditions, which guarantee the stochastic stability and the  $l_{2}-l_\infty $  performance of the augmented estimation error system, are established. Then, the estimator gains are further obtained on the basis of these conditions. Finally, a numerical example is used to prove the effectiveness of the results.","",""
75,"Vu Thi Yen, Yaonan Wang, C. Pham","Recurrent fuzzy wavelet neural networks based on robust adaptive sliding mode control for industrial robot manipulators",2019,"","","","",141,"2022-07-13 10:07:43","","10.1007/s00521-018-3520-3","","",,,,,75,25.00,25,3,3,"","",""
93,"W. Yeh","New Parameter-Free Simplified Swarm Optimization for Artificial Neural Network Training and its Application in the Prediction of Time Series",2013,"","","","",142,"2022-07-13 10:07:43","","10.1109/TNNLS.2012.2232678","","",,,,,93,10.33,93,1,9,"A new soft computing method called the parameter-free simplified swarm optimization (SSO)-based artificial neural network (ANN), or improved SSO for short, is proposed to adjust the weights in ANNs. The method is a modification of the SSO, and seeks to overcome some of the drawbacks of SSO. In the experiments, the iSSO is compared with five other famous soft computing methods, including the backpropagation algorithm, the genetic algorithm, the particle swarm optimization (PSO) algorithm, cooperative random learning PSO, and the SSO, and its performance is tested on five famous time-series benchmark data to adjust the weights of two ANN models (multilayer perceptron and single multiplicative neuron model). The experimental results demonstrate that iSSO is robust and more efficient than the other five algorithms.","",""
0,"Fei Wang","The Evaluation of Public Opinion in the Internet Using Optimized Neural Network and Genetic Algorithm",2016,"","","","",143,"2022-07-13 10:07:43","","10.14257/ASTL.2016.121.11","","",,,,,0,0.00,0,1,6,"Over the past era of time, with the bursting interaction and propagation of the Internet information, collecting emerging plenty of internet information and fining out the hot topic of network public opinion becomes a hotspot research branch. In the paper, we propose a novel model and prototype aiming at evaluating internet public opinions based on neural network (NN). Firstly, a novel evaluation indicator system is proposed and designed based on the characteristics analysis of internet public opinions. Later, we propose a novel evaluation model for the public opinion analysis, the detailed steps are discussed. Finally, we conduct experiment to test the robustness and effectiveness of our proposed methodology with detailed explanation.","",""
65,"S. Thrun, Tom Michael Mitchell","Integrating Inductive Neural Network Learning and Explanation-Based Learning",1993,"","","","",144,"2022-07-13 10:07:43","","","","",,,,,65,2.24,33,2,29,"Many researchers have noted the importance of combining inductive and analytical learning, yet we still lack combined learning methods that are effective in practice. We present here a learning method that combines explanation-based learning from a previously learned approximate domain theory, together with inductive learning from observations. This method, called explanation-based neural network learning (EBNN), is based on a neural network representation of domain knowledge. Explanations are constructed by chaining together inferences from multiple neural networks. In contrast with symbolic approaches to explanation-based learning which extract weakest preconditions from the explanation, EBNN extracts the derivatives of the target concept with respect to the training example features. These derivatives summarize the dependencies within the explanation, and are used to bias the inductive learning of the target concept. Experimental results on a simulated robot control task show that EBNN requires significantly fewer training examples than standard inductive learning. Furthermore, the method is shown to be robust to errors in the domain theory, operating effectively over a broad spectrum from very strong to very weak domain theories.","",""
32,"R. Eberhart","The role of genetic algorithms in neural network query-based learning and explanation facilities",1992,"","","","",145,"2022-07-13 10:07:43","","10.1109/COGANN.1992.273940","","",,,,,32,1.07,32,1,30,"Genetic algorithms are used as a means of achieving neural network inversion. Neural network inversion allows a user to find one or more neural network input patterns which yield a specific output. The input patterns obtained from the genetic algorithm can use in training partially-trained networks, as well as in the building of neural network system explanation facilities.<<ETX>>","",""
33,"S. Pierce, Y. Ben-Haim, K. Worden, G. Manson","Evaluation of Neural Network Robust Reliability Using Information-Gap Theory",2006,"","","","",146,"2022-07-13 10:07:43","","10.1109/TNN.2006.880363","","",,,,,33,2.06,8,4,16,"A novel technique for the evaluation of neural network robustness against uncertainty using a nonprobabilistic approach is presented. Conventional optimization techniques were employed to train multilayer perceptron (MLP) networks, which were then probed with an uncertainty analysis using an information-gap model to quantify the network response to uncertainty in the input data. It is demonstrated that the best performing network on data with low uncertainty is not in general the optimal network on data with a higher degree of input uncertainty. Using the concepts of information-gap theory, this paper develops a theoretical framework for information-gap uncertainty applied to neural networks, and explores the practical application of the procedure to three sample cases. The first consists of a simple two-dimensional (2-D) classification network operating on a known Gaussian distribution, the second a nine-lass vibration classification problem from an aircraft wing, and the third a two-class example from a database of breast cancer incidence","",""
52,"Zhixia Ding, Z. Zeng, Leimin Wang","Robust Finite-Time Stabilization of Fractional-Order Neural Networks With Discontinuous and Continuous Activation Functions Under Uncertainty",2018,"","","","",147,"2022-07-13 10:07:43","","10.1109/TNNLS.2017.2675442","","",,,,,52,13.00,17,3,4,"This paper is concerned with robust finite-time stabilization for a class of fractional-order neural networks (FNNs) with two types of activation functions (i.e., discontinuous and continuous activation function) under uncertainty. It is worth noting that there exist few results about FNNs with discontinuous activation functions, which is mainly because classical solutions and theories of differential equations cannot be applied in this case. Especially, there is no relevant finite-time stabilization research for such system, and this paper makes up for the gap. The existence of global solution under the framework of Filippov for such system is guaranteed by limiting discontinuous activation functions. According to set-valued analysis and Kakutani’s fixed point theorem, we obtain the existence of equilibrium point. In particular, based on differential inclusion theory and fractional Lyapunov stability theory, several new sufficient conditions are given to ensure finite-time stabilization via a novel discontinuous controller, and the upper bound of the settling time for stabilization is estimated. In addition, we analyze the finite-time stabilization of FNNs with Lipschitz-continuous activation functions under uncertainty. The results of this paper improve corresponding ones of integer-order neural networks with discontinuous and continuous activation functions. Finally, three numerical examples are given to show the effectiveness of the theoretical results.","",""
33,"G. Rovithakis","Robust redesign of a neural network controller in the presence of unmodeled dynamics",2004,"","","","",148,"2022-07-13 10:07:43","","10.1109/TNN.2004.837782","","",,,,,33,1.83,33,1,18,"This work presents a neural network control redesign, which achieves robust stabilization in the presence of unmodeled dynamics restricted to be input to output practically stable (IOpS), without requiring any prior knowledge on any bounding function. Moreover, the state of the unmodeled dynamics is permitted to go unbounded provided that the nominal system state and/or the control input also go unbounded. The neural network controller is equipped with a resetting strategy to deal with the problem of possible division by zero, which may appear since we consider unknown input vector fields with unknown signs. The uniform ultimate boundedness of the system output to an arbitrarily small set, plus the boundedness of all other signals in the closed-loop is guaranteed.","",""
15,"J. Hopfield","Understanding Emergent Dynamics: Using a Collective Activity Coordinate of a Neural Network to Recognize Time-Varying Patterns",2015,"","","","",149,"2022-07-13 10:07:43","","10.1162/NECO_a_00768","","",,,,,15,2.14,15,1,7,"Abstract In higher animals, complex and robust behaviors are produced by the microscopic details of large structured ensembles of neurons. I describe how the emergent computational dynamics of a biologically based neural network generates a robust natural solution to the problem of categorizing time-varying stimulus patterns such as spoken words or animal stereotypical behaviors. The recognition of these patterns is made difficult by their substantial variation in cadence and duration. The neural circuit behaviors used are similar to those associated with brain neural integrators. In the larger context described here, this kind of circuit becomes a building block of an entirely different computational algorithm for solving complex problems. While the network behavior is simulated in detail, a collective view is essential to understanding the results. A closed equation of motion for the collective variable describes an algorithm that quantitatively accounts for many aspects of the emergent network computation. The feedback connections and ongoing activity in the network shape the collective dynamics onto a reduced dimensionality manifold of activity space, which defines the algorithm and computation actually performed. The external inputs are weak and are not the dominant drivers of network activity.","",""
7,"Guangyao Chen, Peixi Peng, Li Ma, Jia Li, Lin Du, Yonghong Tian","Amplitude-Phase Recombination: Rethinking Robustness of Convolutional Neural Networks in Frequency Domain",2021,"","","","",150,"2022-07-13 10:07:43","","10.1109/iccv48922.2021.00051","","",,,,,7,7.00,1,6,1,"Recently, the generalization behavior of Convolutional Neural Networks (CNN) is gradually transparent through explanation techniques with the frequency components decomposition. However, the importance of the phase spectrum of the image for a robust vision system is still ignored. In this paper, we notice that the CNN tends to converge at the local optimum which is closely related to the high-frequency components of the training images, while the amplitude spectrum is easily disturbed such as noises or common corruptions. In contrast, more empirical studies found that humans rely on more phase components to achieve robust recognition. This observation leads to more explanations of the CNN’s generalization behaviors in both robustness to common perturbations and out-of-distribution detection, and motivates a new perspective on data augmentation designed by re-combing the phase spectrum of the current image and the amplitude spectrum of the distracter image. That is, the generated samples force the CNN to pay more attention to the structured information from phase components and keep robust to the variation of the amplitude. Experiments on several image datasets indicate that the proposed method achieves state-of-the-art performances on multiple generalizations and calibration tasks, including adaptability for common corruptions and surface variations, out-of-distribution detection, and adversarial attack. The code is released on github/iCGY96/APR.","",""
41,"M. Matsugu, Katsuhiko Mori, Mie Ishii, Y. Mitarai","Convolutional spiking neural network model for robust face detection",2002,"","","","",151,"2022-07-13 10:07:43","","10.1109/ICONIP.2002.1198140","","",,,,,41,2.05,10,4,20,"We propose a convolutional spiking neural network (CSNN) model with population coding for robust face detection. The basic structure of the network includes hierarchically alternating layers for feature detection and feature pooling. The proposed model implements hierarchical template matching by temporal integration of structured pulse packet. The packet signal represents some intermediate or complex visual feature (e.g., a pair of line segments, corners, eye, nose, etc.) that constitutes a face model. The output pulse of a feature pooling neuron represents some local feature (e.g., line segments). Introducing a population coding scheme in the CSNN architecture, we show how the biologically inspired model attains invariance to changes in size and position of face and ensures the efficiency of face detection.","",""
37,"Weiwei Zhang, Y. Murphey, Tianyu Wang, Q. Xu","Driver yawning detection based on deep convolutional neural learning and robust nose tracking",2015,"","","","",152,"2022-07-13 10:07:43","","10.1109/IJCNN.2015.7280566","","",,,,,37,5.29,9,4,7,"Driver yawning detection is one of the key technologies used in driver fatigue monitoring systems. Real-time driver yawning detection is a very challenging problem due to the dynamics in driver's movements and lighting conditions. In this paper, we present a yawning detection system that consists of a face detector, a nose detector, a nose tracker and a yawning detector. Deep learning algorithms are developed for detecting driver face area and nose location. A nose tracking algorithm that combines Kalman filter with a dedicated open-source TLD (Track-Learning-Detection) tracker is developed to generate robust tracking results under dynamic driving conditions. Finally a neural network is developed for yawning detection based on the features including nose tracking confidence value, gradient features around corners of mouth and face motion features. Experiments are conducted on real-world driving data, and results show that the deep convolutional networks can generate a satisfactory classification result for detecting driver's face and nose when compared with other pattern classification methods, and the proposed yawning detection system is effective in real-time detection of driver's yawning states.","",""
158,"A. Vemuri, M. Polycarpou","Neural-network-based robust fault diagnosis in robotic systems",1997,"","","","",153,"2022-07-13 10:07:43","","10.1109/72.641464","","",,,,,158,6.32,79,2,25,"Fault diagnosis plays an important role in the operation of modern robotic systems. A number of researchers have proposed fault diagnosis architectures for robotic manipulators using the model-based analytical redundancy approach. One of the key issues in the design of such fault diagnosis schemes is the effect of modeling uncertainties on their performance. This paper investigates the problem of fault diagnosis in rigid-link robotic manipulators with modeling uncertainties. A learning architecture with sigmoidal neural networks is used to monitor the robotic system for any off-nominal behavior due to faults. The robustness and stability properties of the fault diagnosis scheme are rigorously established. Simulation examples are presented to illustrate the ability of the neural-network-based robust fault diagnosis scheme to detect and accommodate faults in a two-link robotic manipulator.","",""
60,"Z. Man, X. Yu, K. Eshraghian, M. Palaniswami","A robust adaptive sliding mode tracking control using an RBF neural network for robotic manipulators",1995,"","","","",154,"2022-07-13 10:07:43","","10.1109/ICNN.1995.487738","","",,,,,60,2.22,15,4,27,"A new robust adaptive sliding mode tracking control scheme using an RBF neural network is proposed for rigid robotic manipulators to achieve robustness and asymptotic error convergence. A key feature of this scheme is that the prior knowledge of the upper bound of the system uncertainties is not required. An adaptive RBF neural network is used to learn the upper bound of system uncertainties. The output of the neural network is then used as a compensator parameter in the sense that the effects of the system uncertainties can be eliminated and asymptotic error convergence can be obtained for the closed loop robotic control system.","",""
92,"N. Punn, Sonali Agarwal","Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray images using fine-tuned deep neural networks",2020,"","","","",155,"2022-07-13 10:07:43","","10.1007/s10489-020-01900-3","","",,,,,92,46.00,46,2,2,"","",""
24,"T. Chuah, B. Sharif, O. Hinton","Robust CDMA multiuser detection using a neural-network approach",2002,"","","","",156,"2022-07-13 10:07:43","","10.1109/TNN.2002.804310","","",,,,,24,1.20,8,3,20,"Abstract-Recently, a robust version of the linear decorrelating detector (LDD) based on the Huber's M-estimation technique has been proposed. In this paper, we first demonstrate the use of a three-layer recurrent neural network (RNN) to implement the LDD without requiring matrix inversion. The key idea is based on minimizing an appropriate computational energy function iteratively. Second, it will be shown that the M-decorrelating detector (MDD) can be implemented by simply incorporating sigmoidal neurons in the first layer of the RNN. A proof of the redundancy of the matrix inversion process is provided and the computational saving in realistic network is highlighted. Third, we illustrate how further performance gain could be achieved for the subspace-based blind MDD by using robust estimates of the signal subspace components in the initial stage. The impulsive noise is modeled using non-Gaussian alpha-stable distributions, which do not include a Gaussian component but facilitate the use of the recently proposed geometric signal-to-noise ratio (G-SNR). The characteristics and performance of the proposed neural-network detectors are investigated by computer simulation.","",""
20,"Ke-wei Ding, N. Huang","Global Robust Exponential Stability of Interval General BAM Neural Network with Delays",2006,"","","","",157,"2022-07-13 10:07:43","","10.1007/s11063-005-5090-5","","",,,,,20,1.25,10,2,16,"","",""
149,"Songwu Lu, T. Başar","Robust nonlinear system identification using neural-network models",1998,"","","","",158,"2022-07-13 10:07:43","","10.1109/72.668883","","",,,,,149,6.21,75,2,24,"We study the problem of identification for nonlinear systems in the presence of unknown driving noise, using both feedforward multilayer neural network and radial basis function network models. Our objective is to resolve the difficulty associated with the persistency of excitation condition inherent to the standard schemes in the neural identification literature. This difficulty is circumvented here by a novel formulation and by using a new class of identification algorithms recently obtained by Didinsky et al. We show how these algorithms can be exploited to successfully identify the nonlinearity in the system using neural-network models. By embedding the original problem in one with noise-perturbed state measurements, we present a class of identifiers (under L1 and L2 cost criteria) which secure a good approximant for the system nonlinearity provided that some global optimization technique is used. In this respect, many available learning algorithms in the current neural-network literature, e.g., the backpropagation scheme and the genetic algorithms-based scheme, with slight modifications, can ensure the identification of the system nonlinearity. Subsequently, we address the same problem under a third, worst case L(infinity) criterion for an RBF modeling. We present a neural-network version of an H(infinity)-based identification algorithm from Didinsky et al and show how, along with an appropriate choice of control input to enhance excitation, under both full-state-derivative information (FSDI) and noise-perturbed full-state-information (NPFSI), it leads to satisfaction of a relevant persistency of excitation condition, and thereby to robust identification of the nonlinearity. Results from several simulation studies have been included to demonstrate the effectiveness of these algorithms.","",""
490,"M. Matsugu, Katsuhiko Mori, Y. Mitari, Yuji Kaneda","Subject independent facial expression recognition with robust face detection using a convolutional neural network",2003,"","","","",159,"2022-07-13 10:07:43","","10.1016/S0893-6080(03)00115-1","","",,,,,490,25.79,123,4,19,"","",""
147,"K. Liano","Robust error measure for supervised neural network learning with outliers",1996,"","","","",160,"2022-07-13 10:07:43","","10.1109/72.478411","","",,,,,147,5.65,147,1,26,"Most supervised neural networks (NNs) are trained by minimizing the mean squared error (MSE) of the training set. In the presence of outliers, the resulting NN model can differ significantly from the underlying system that generates the data. Two different approaches are used to study the mechanism by which outliers affect the resulting models: influence function and maximum likelihood. The mean log squared error (MLSE) is proposed as the error criteria that can be easily adapted by most supervised learning algorithms. Simulation results indicate that the proposed method is robust against outliers.","",""
112,"Zheng Yan, Jun Wang","Robust Model Predictive Control of Nonlinear Systems With Unmodeled Dynamics and Bounded Uncertainties Based on Neural Networks",2014,"","","","",161,"2022-07-13 10:07:43","","10.1109/TNNLS.2013.2275948","","",,,,,112,14.00,56,2,8,"This paper presents a neural network approach to robust model predictive control (MPC) for constrained discrete-time nonlinear systems with unmodeled dynamics affected by bounded uncertainties. The exact nonlinear model of underlying process is not precisely known, but a partially known nominal model is available. This partially known nonlinear model is first decomposed to an affine term plus an unknown high-order term via Jacobian linearization. The linearization residue combined with unmodeled dynamics is then modeled using an extreme learning machine via supervised learning. The minimax methodology is exploited to deal with bounded uncertainties. The minimax optimization problem is reformulated as a convex minimization problem and is iteratively solved by a two-layer recurrent neural network. The proposed neurodynamic approach to nonlinear MPC improves the computational efficiency and sheds a light for real-time implementability of MPC technology. Simulation results are provided to substantiate the effectiveness and characteristics of the proposed approach.","",""
12,"E. Voudouri-Maniati, L. Kurz, J. Kowalski","A neural-network approach to nonparametric and robust classification procedures",1997,"","","","",162,"2022-07-13 10:07:43","","10.1109/72.557667","","",,,,,12,0.48,4,3,25,"In this paper algorithms of neural-network type are introduced for solving estimation and classification problems when assumptions about independence, Gaussianity, and stationarity of the observation samples are no longer valid. Specifically, the asymptotic normality of several nonparametric classification tests is demonstrated and their implementation using a neural-network approach is presented. Initially, the neural nets train themselves via learning samples for nominal noise and alternative hypotheses distributions resulting in near optimum performance in a particular stochastic environment. In other than the nominal environments, however, high efficiency is maintained by adapting the optimum nonlinearities to changing conditions during operation via parallel networks, without disturbing the classification process. Furthermore, the superiority in performance of the proposed networks over more traditional neural nets is demonstrated in an application involving pattern recognition.","",""
54,"M. Pezeshki, Sekouba Kaba, Y. Bengio, Aaron C. Courville, Doina Precup, Guillaume Lajoie","Gradient Starvation: A Learning Proclivity in Neural Networks",2020,"","","","",163,"2022-07-13 10:07:43","","","","",,,,,54,27.00,9,6,2,"We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments.","",""
1,"Eduardo Ulises Moya-Sánchez, S. Xambó-Descamps, Abraham Sánchez Pérez, Sebastián Salazar-Colores, Ulises Cort'es","A Trainable Monogenic ConvNet Layer Robust in Front of Large Contrast Changes in Image Classification",2021,"","","","",164,"2022-07-13 10:07:43","","10.1109/access.2021.3128552","","",,,,,1,1.00,0,5,1,"At present, Convolutional Neural Networks (ConvNets) achieve remarkable performance in image classification tasks. However, current ConvNets cannot guarantee the capabilities of mammalian visual systems such as invariance to contrast and illumination changes. Some ideas for overcoming the illumination and contrast variations must usually be tuned manually and tend to fail when tested with other types of data degradation. In this context, a new bio-inspired entry layer is presented in this work, M6, which detects low-level geometric features (lines, edges, and orientations) similar to those patterns detected by the V1 visual cortex. This new trainable layer is capable of dealing with image classification tasks even with large contrast variations. The explanation for this behavior is due to the use of monogenic signal geometry, which represents each pixel value in a 3D space using quaternions, a fact that confers a degree of explainability to the networks. The M6 was compared to conventional convolutional layer (C) and a deterministic quaternion local phase layer (Q9). The experimental setup is designed to evaluate the robustness of this M6 enriched ConvNet model and includes three architectures, four datasets, and three types of contrast degradation (including non-uniform haze degradations). The numerical results reveal that the models with M6 are the most robust in front of any kind of contrast variations. This amounts to a significant enhancement of the C models, which usually have reasonably good performance only when the same training and test degradation are used, except for the case of maximum degradation. Moreover, the Structural Similarity Index Measure (SSIM) and Peak Signal to Noise Ratio (PSNR) are used to analyze and explain the robustness effect of the M6 feature maps under any kind of contrast degradations.","",""
47,"A. Tavanaei, A. Maida","Multi-layer unsupervised learning in a spiking convolutional neural network",2017,"","","","",165,"2022-07-13 10:07:43","","10.1109/IJCNN.2017.7966099","","",,,,,47,9.40,24,2,5,"Spiking neural networks (SNNs) have advantages over traditional, non-spiking networks with respect to biorealism, potential for low-power hardware implementations, and theoretical computing power. However, in practice, spiking networks with multi-layer learning have proven difficult to train. This paper explores a novel, bio-inspired spiking convolutional neural network (CNN) that is trained in a greedy, layer-wise fashion. The spiking CNN consists of a convolutional/pooling layer followed by a feature discovery layer, both of which undergo bio-inspired learning. Kernels for the convolutional layer are trained using a sparse, spiking auto-encoder representing primary visual features. The feature discovery layer uses a probabilistic spike-timing-dependent plasticity (STDP) learning rule. This layer represents complex visual features using WTA-thresholded, leaky, integrate-and-fire (LIF) neurons. The new model is evaluated on the MNIST digit dataset using clean and noisy images. Intermediate results show that the convolutional layer is stack-admissible, enabling it to support a multi-layer learning architecture. The recognition performance for clean images is above 98%. This performance is accounted for by the independent and informative visual features extracted in a hierarchy of convolutional and feature discovery layers. The performance loss for recognizing the noisy images is in the range 0.1% to 8.5%. This level of performance loss indicates that the network is robust to additive noise.","",""
0,"D. Elton","Common Pitfalls When Explaining AI and Why Mechanistic Explanation Is a Hard Problem",2021,"","","","",166,"2022-07-13 10:07:43","","10.1007/978-981-16-2377-6_38","","",,,,,0,0.00,0,1,1,"","",""
122,"D. Tomandl, Andreas Schober","A Modified General Regression Neural Network (MGRNN) with new, efficient training algorithms as a robust 'black box'-tool for data analysis",2001,"","","","",167,"2022-07-13 10:07:43","","10.1016/S0893-6080(01)00051-X","","",,,,,122,5.81,61,2,21,"","",""
80,"Q. Song, Qinqin Yu, Zhenjiang Zhao, Yurong Liu, F. Alsaadi","Boundedness and global robust stability analysis of delayed complex-valued neural networks with interval parameter uncertainties",2018,"","","","",168,"2022-07-13 10:07:43","","10.1016/j.neunet.2018.03.008","","",,,,,80,20.00,16,5,4,"","",""
1,"Mirtha Lucas, Miguel A. Lerma, J. Furst, D. Raicu","Robust Heatmap Template Generation for COVID-19 Biomarker Detection",2021,"","","","",169,"2022-07-13 10:07:43","","10.4108/EAI.24-2-2021.168729","","",,,,,1,1.00,0,4,1,"INTRODUCTION: Detecting and identifying patterns in chest X-ray images of Covid-19 patients are important tasks for understanding the disease and for making differential diagnosis. OBJECTIVES: The purpose of this work is to develop a technique for detecting biomarkers of four possible conditions in chest X-rays, and study the patterns arising from the location of biomarkers. METHODS: We use transfer learning applied to a pretrained VGG19 neural network to build a model capable of detecting the four conditions in chest X-rays. For biomarkers detection we use Grad-CAM. Patterns in the biomarkers are found by using classical eigenfaces approach. RESULTS: The discovered patterns are consistent across images from a given class of disease, and they are robust with respect to changes in dataset. CONCLUSION: The identified patterns can serve as biomarkers for a given disease in chest X-ray images, and constitute explanations of how the deep learning model makes classification decisions. Received on 16 December 2020; accepted on 21 February 2021; published on 24 February 2021","",""
34,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, Semeen Rehman, M. Shafique","Robust Machine Learning Systems: Reliability and Security for Deep Neural Networks",2018,"","","","",170,"2022-07-13 10:07:43","","10.1109/IOLTS.2018.8474192","","",,,,,34,8.50,7,5,4,"Machine learning is commonly being used in almost all the areas that involve advanced data analytics and intelligent control. From applications like Natural Language Processing (NLP) to autonomous driving are based upon machine learning algorithms. An increasing trend is observed in the use of Deep Neural Networks (DNNs) for such applications. While the slight inaccuracy in applications like NLP does not have any severe consequences, it is not the same for other safety-critical applications, like autonomous driving and smart healthcare, where a small error can lead to catastrophic effects. Apart from high-accuracy DNN algorithms, there is a significant need for robust machine learning systems and hardware architectures that can generate reliable and trustworthy results in the presence of hardware-level faults while also preserving security and privacy. This paper provides an overview of the challenges being faced in ensuring reliable and secure execution of DNNs. To address the challenges, we present several techniques for analyzing and mitigating the reliability and security threats in machine learning systems.","",""
86,"Zitong Yang, Yaodong Yu, Chong You, J. Steinhardt, Yi Ma","Rethinking Bias-Variance Trade-off for Generalization of Neural Networks",2020,"","","","",171,"2022-07-13 10:07:43","","","","",,,,,86,43.00,17,5,2,"The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation for this by measuring the bias and variance of neural networks: while the bias is monotonically decreasing as in the classical theory, the variance is unimodal or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent curve observed in recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.","",""
20,"Youshen Xia, Jun Wang","Robust Regression Estimation Based on Low-Dimensional Recurrent Neural Networks",2018,"","","","",172,"2022-07-13 10:07:43","","10.1109/TNNLS.2018.2814824","","",,,,,20,5.00,10,2,4,"The robust Huber’s M-estimator is widely used in signal and image processing, classification, and regression. From an optimization point of view, Huber’s M-estimation problem is often formulated as a large-sized quadratic programming (QP) problem in view of its nonsmooth cost function. This paper presents a generalized regression estimator which minimizes a reduced-sized QP problem. The generalized regression estimator may be viewed as a significant generalization of several robust regression estimators including Huber’s M-estimator. The performance of the generalized regression estimator is analyzed in terms of robustness and approximation accuracy. Furthermore, two low-dimensional recurrent neural networks (RNNs) are introduced for robust estimation. The two RNNs have low model complexity and enhanced computational efficiency. Finally, the experimental results of two examples and an application to image restoration are presented to substantiate superior performance of the proposed method over conventional algorithms for robust regression estimation in terms of approximation accuracy and convergence rate.","",""
40,"A. Pratap, R. Raja, C. Sowmiya, O. Bagdasar, Jinde Cao, G. Rajchakit","Robust generalized Mittag-Leffler synchronization of fractional order neural networks with discontinuous activation and impulses",2018,"","","","",173,"2022-07-13 10:07:43","","10.1016/j.neunet.2018.03.012","","",,,,,40,10.00,7,6,4,"","",""
0,"Thi-Thu-Huong Le, Hyoeun Kang, Howon Kim","Robust Adversarial Attack Against Explainable Deep Classification Models Based on Adversarial Images With Different Patch Sizes and Perturbation Ratios",2021,"","","","",174,"2022-07-13 10:07:43","","10.1109/ACCESS.2021.3115764","","",,,,,0,0.00,0,3,1,"In recent years, adversarial attack methods have been deceived rather easily on deep neural networks (DNNs). In practice, adversarial patches cause misclassification that can be extremely effective. However, many existing adversarial patches are used for attacking DNNs, and only a few of them apply to both the DNN and its explanation model. In this paper, we present different adversarial patches that misguide the prediction of DNN models and change the cause of prediction results of interpretation models, such as gradient-weighted class activation mapping. The proposed adversarial patches have appropriate location and perturbation ratios, which comprise visible or less visible adversarial patches. In addition, image patches within small arrays are localized without covering or overlapping with any of the main objects in a natural image. In particular, we generate two adversarial patches that cover only 3% and 1.5% of the pixels in the original image, while they do not cover the main objects in the natural image. Our experiments are performed using four pre-trained DNN models and the ImageNet dataset. We also examine the inaccurate results of the interpretation models through mask and heatmap visualization. The proposed adversarial attack method could be a reference for developing robust network interpretation models that are more reliable for the decision-making process of pre-trained DNN models.","",""
0,"Joe Hays, S. Ramamoorthy, Christian Tetzlaff","Editorial: Robust Artificial Intelligence for Neurorobotics",2021,"","","","",175,"2022-07-13 10:07:43","","10.3389/fnbot.2021.809903","","",,,,,0,0.00,0,3,1,"Neural computing is a powerful paradigm that has revolutionized machine learning. Building from early roots in the study of adaptive behavior and attempts to understand information processing in parallel and distributed neural architectures, modern neural networks have convincingly demonstrated successes in numerous areas—transforming the practice of computer vision, natural language processing, and even computational biology. Applications in robotics bring stringent constraints on size, weight and power constraints (SWaP), which challenge the developers of these technologies in new ways. Indeed, these requirements take us back to the roots of the field of neural computing, forcing us to ask how it could be that the human brain achieves with as little as 12 watts of power what seems to require entire server farms with state of the art computational and numerical methods. Likewise, even lowly insects demonstrate a degree of adaptivity and resilience that still defy easy explanation or computational replication. In this Research Topic, we have compiled the latest research addressing several aspects of these broadly defined challenge questions. As illustrated in Figure 1, the articles are organized into four prevailing themes: Sense, Think, Act, and Tools.","",""
14,"Jin Wang, C. Lim, D. Creighton, A. Khosravi, S. Nahavandi, J. Ugon, P. Vamplew, A. Stranieri, Laura Martin, Anton Freischmidt","Patient admission prediction using a pruned fuzzy min–max neural network with rule extraction",2015,"","","","",176,"2022-07-13 10:07:43","","10.1007/s00521-014-1631-z","","",,,,,14,2.00,1,10,7,"","",""
181,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","Continuous Online Sequence Learning with an Unsupervised Neural Network Model",2015,"","","","",177,"2022-07-13 10:07:43","","10.1162/NECO_a_00893","","",,,,,181,25.86,45,4,7,"Abstract The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.","",""
31,"Y. Nakamura, O. Hasegawa","Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data",2017,"","","","",178,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2489225","","",,,,,31,6.20,16,2,5,"With the ongoing development and expansion of communication networks and sensors, massive amounts of data are continuously generated in real time from real environments. Beforehand, prediction of a distribution underlying such data is difficult; furthermore, the data include substantial amounts of noise. These factors make it difficult to estimate probability densities. To handle these issues and massive amounts of data, we propose a nonparametric density estimator that rapidly learns data online and has high robustness. Our approach is an extension of both kernel density estimation (KDE) and a self-organizing incremental neural network (SOINN); therefore, we call our approach KDESOINN. An SOINN provides a clustering method that learns about the given data as networks of prototype of data; more specifically, an SOINN can learn the distribution underlying the given data. Using this information, KDESOINN estimates the probability density function. The results of our experiments show that KDESOINN outperforms or achieves performance comparable to the current state-of-the-art approaches in terms of robustness, learning time, and accuracy.","",""
58,"S. Arik","New Criteria for Global Robust Stability of Delayed Neural Networks With Norm-Bounded Uncertainties",2014,"","","","",179,"2022-07-13 10:07:43","","10.1109/TNNLS.2013.2287279","","",,,,,58,7.25,58,1,8,"In this paper, we study the global asymptotic robust stability of delayed neural networks with norm-bounded uncertainties. By employing the Lyapunov stability theory and homeomorphic mapping theorem, we derive some new types of sufficient conditions ensuring the existence, uniqueness, and global asymptotic stability of the equilibrium point for the class of neural networks with discrete time delays under parameter uncertainties and with respect to continuous and slope-bounded activation functions. An important aspect of our results is their low computational complexity, as the reported results can be verified by checking some properties of symmetric matrices associated with the uncertainty sets of the network parameters. The obtained results are shown to be generalizations of some of the previously published corresponding results. Some comparative numerical examples are also constructed to compare our results with some closely related existing literature results.","",""
5,"Mohammed Bany Muhammad, M. Yeasin","Eigen-CAM: Visual Explanations for Deep Convolutional Neural Networks",2021,"","","","",180,"2022-07-13 10:07:43","","10.1007/s42979-021-00449-3","","",,,,,5,5.00,3,2,1,"","",""
90,"Jen-Tzung Chien, Y. Ku","Bayesian Recurrent Neural Network for Language Modeling",2016,"","","","",181,"2022-07-13 10:07:43","","10.1109/TNNLS.2015.2499302","","",,,,,90,15.00,45,2,6,"A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.","",""
130,"David Sussillo, P. Nuyujukian, Joline M. Fan, J. Kao, S. Stavisky, S. Ryu, K. Shenoy","A recurrent neural network for closed-loop intracortical brain-machine interface decoders.",2012,"","","","",182,"2022-07-13 10:07:43","","10.1088/1741-2560/9/2/026027","","",,,,,130,13.00,19,7,10,"Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships in time series data with complex temporal dependences. In this paper, we explore the ability of a simplified type of RNN, one with limited modifications to the internal weights called an echostate network (ESN), to effectively and continuously decode monkey reaches during a standard center-out reach task using a cortical brain-machine interface (BMI) in a closed loop. We demonstrate that the RNN, an ESN implementation termed a FORCE decoder (from first order reduced and controlled error learning), learns the task quickly and significantly outperforms the current state-of-the-art method, the velocity Kalman filter (VKF), using the measure of target acquire time. We also demonstrate that the FORCE decoder generalizes to a more difficult task by successfully operating the BMI in a randomized point-to-point task. The FORCE decoder is also robust as measured by the success rate over extended sessions. Finally, we show that decoded cursor dynamics are more like naturalistic hand movements than those of the VKF. Taken together, these results suggest that RNNs in general, and the FORCE decoder in particular, are powerful tools for BMI decoder applications.","",""
17,"Bin Hu, Shigang Yue, Zhuhong Zhang","A Rotational Motion Perception Neural Network Based on Asymmetric Spatiotemporal Visual Information Processing",2017,"","","","",183,"2022-07-13 10:07:43","","10.1109/TNNLS.2016.2592969","","",,,,,17,3.40,6,3,5,"All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts—presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.","",""
3,"Stefani Karp, Ezra Winston, Yuanzhi Li, Aarti Singh","Local Signal Adaptivity: Provable Feature Learning in Neural Networks Beyond Kernels",2021,"","","","",184,"2022-07-13 10:07:43","","","","",,,,,3,3.00,1,4,1,"Neural networks have been shown to outperform kernel methods in practice (including neural tangent kernels). Most theoretical explanations of this performance gap focus on learning a complex hypothesis class; in some cases, it is unclear whether this hypothesis class captures realistic data. In this work, we propose a related, but alternative, explanation for this performance gap in the image classification setting, based on finding a sparse signal in the presence of noise. Specifically, we prove that, for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent simultaneously learns to threshold out the noise and find the signal. On the other hand, the corresponding neural tangent kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. We supplement our theoretical results by demonstrating this phenomenon empirically: in CIFAR-10 and MNIST images with various backgrounds, as the background noise increases in intensity, a CNN’s performance stays relatively robust, whereas its corresponding neural tangent kernel sees a notable drop in performance. We therefore propose the local signal adaptivity (LSA) phenomenon as one explanation for the superiority of neural networks over kernel methods.","",""
0,"Lei Gu, R. Wu","Robust cortical criticality and diverse dynamics resulting from functional specification.",2021,"","","","",185,"2022-07-13 10:07:43","","10.1103/PhysRevE.103.042407","","",,,,,0,0.00,0,2,1,"Despite the recognition of the layered structure and evident criticality in the cortex, how the specification of input, output, and computational layers affects the self-organized criticality has not been much explored. By constructing heterogeneous structures with a well-accepted model of leaky neurons, we find that the specification can lead to robust criticality rather insensitive to the strength of external stimuli. This naturally unifies the adaptation to strong inputs without extra synaptic plasticity mechanisms. Low degree of recurrence constitutes an alternative explanation to subcriticality other than the high-frequency inputs. Unlike fully recurrent networks where external stimuli always render subcriticality, the dynamics of networks with sufficient feedforward connections can be driven to criticality and supercriticality. These findings indicate that functional and structural specification and their interplay with external stimuli are of crucial importance for the network dynamics. The robust criticality puts forward networks of the leaky neurons as promising platforms for realizing artificial neural networks that work in the vicinity of critical points.","",""
9,"Xupeng Miao, Nezihe Merve Gürel, Wentao Zhang, Zhichao Han, Bo Li, Wei Min, Susie Xi Rao, Hansheng Ren, Yinan Shan, Yingxia Shao, Yujie Wang, Fan Wu, H. Xue, Yaming Yang, Zitao Zhang, Yang Zhao, Shuai Zhang, Yujing Wang, B. Cui, Ce Zhang","DeGNN: Improving Graph Neural Networks with Graph Decomposition",2021,"","","","",186,"2022-07-13 10:07:43","","10.1145/3447548.3467312","","",,,,,9,9.00,1,20,1,"Mining from graph-structured data is an integral component of graph data management. A recent trending technique, graph convolutional network (GCN), has gained momentum in the graph mining field, and plays an essential part in numerous graph-related tasks. Although the emerging GCN optimization techniques bring improvements to specific scenarios, they perform diversely in different applications and introduce many trial-and-error costs for practitioners. Moreover, existing GCN models often suffer from oversmoothing problem. Besides, the entanglement of various graph patterns could lead to non-robustness and harm the final performance of GCNs. In this work, we propose a simple yet efficient graph decomposition approach to improve the performance of general graph neural networks. We first empirically study existing graph decomposition methods and propose an automatic connectivity-ware graph decomposition algorithm, DeGNN. To provide a theoretical explanation, we then characterize GCN from the information-theoretic perspective and show that under certain conditions, the mutual information between the output after l layers and the input of GCN converges to 0 exponentially with respect to l. On the other hand, we show that graph decomposition can potentially weaken the condition of such convergence rate, alleviating the information loss when GCN becomes deeper. Extensive experiments on various academic benchmarks and real-world production datasets demonstrate that graph decomposition generally boosts the performance of GNN models. Moreover, our proposed solution DeGNN achieves state-of-the-art performances on almost all these tasks.","",""
12,"Laura Rieger, L. K. Hansen","IROF: a low resource evaluation metric for explanation methods",2020,"","","","",187,"2022-07-13 10:07:43","","","","",,,,,12,6.00,6,2,2,"The adoption of machine learning in health care hinges on the transparency of the used algorithms, necessitating the need for explanation methods. However, despite a growing literature on explaining neural networks, no consensus has been reached on how to evaluate those explanation methods. We propose IROF, a new approach to evaluating explanation methods that circumvents the need for manual evaluation. Compared to other recent work, our approach requires several orders of magnitude less computational resources and no human input, making it accessible to lower resource groups and robust to human bias.","",""
96,"An‐Min Zou, K. Kumar","Neural Network-Based Distributed Attitude Coordination Control for Spacecraft Formation Flying With Input Saturation",2012,"","","","",188,"2022-07-13 10:07:43","","10.1109/TNNLS.2012.2196710","","",,,,,96,9.60,48,2,10,"This brief considers the attitude coordination control problem for spacecraft formation flying when only a subset of the group members has access to the common reference attitude. A quaternion-based distributed attitude coordination control scheme is proposed with consideration of the input saturation and with the aid of the sliding-mode observer, separation principle theorem, Chebyshev neural networks, smooth projection algorithm, and robust control technique. Using graph theory and a Lyapunov-based approach, it is shown that the distributed controller can guarantee the attitude of all spacecraft to converge to a common time-varying reference attitude when the reference attitude is available only to a portion of the group of spacecraft. Numerical simulations are presented to demonstrate the performance of the proposed distributed controller.","",""
14,"Jianming Lian, Jianghai Hu, S. Żak","Variable Neural Adaptive Robust Control: A Switched System Approach",2015,"","","","",189,"2022-07-13 10:07:43","","10.1109/TNNLS.2014.2327853","","",,,,,14,2.00,5,3,7,"Variable neural adaptive robust control strategies are proposed for the output tracking control of a class of multiinput multioutput uncertain systems. The controllers incorporate a novel variable-structure radial basis function (RBF) network as the self-organizing approximator for unknown system dynamics. It can determine the network structure online dynamically by adding or removing RBFs according to the tracking performance. The structure variation is systematically considered in the stability analysis of the closed-loop system using a switched system approach with the piecewise quadratic Lyapunov function. The performance of the proposed variable neural adaptive robust controllers is illustrated with simulations.","",""
32,"Weijia Shi, Andy Shih, Adnan Darwiche, Arthur Choi","On Tractable Representations of Binary Neural Networks",2020,"","","","",190,"2022-07-13 10:07:43","","10.24963/kr.2020/91","","",,,,,32,16.00,8,4,2,"We consider the compilation of a binary neural network's decision function into tractable representations such as Ordered Binary Decision Diagrams (OBDDs) and Sentential Decision Diagrams (SDDs). Obtaining this function as an OBDD/SDD facilitates the explanation and formal verification of a neural network's behavior. First, we consider the task of verifying the robustness of a neural network, and show how we can compute the expected robustness of a neural network, given an OBDD/SDD representation of it. Next, we consider a more efficient approach for compiling neural networks, based on a pseudo-polynomial time algorithm for compiling a neuron. We then provide a case study in a handwritten digits dataset, highlighting how two neural networks trained from the same dataset can have very high accuracies, yet have very different levels of robustness. Finally, in experiments, we show that it is feasible to obtain compact representations of neural networks as SDDs.","",""
0,"Md Ashfaq Ahmed, S. Venugopal, R. Jung","Engaging biological oscillators through second messenger pathways permits emergence of a robust gastric slow-wave during peristalsis.",2021,"","","","",191,"2022-07-13 10:07:43","","10.1371/journal.pcbi.1009644","","",,,,,0,0.00,0,3,1,"Peristalsis, the coordinated contraction-relaxation of the muscles of the stomach is important for normal gastric motility and is impaired in motility disorders. Coordinated electrical depolarizations that originate and propagate within a network of interconnected layers of interstitial cells of Cajal (ICC) and smooth muscle (SM) cells of the stomach wall as a slow-wave, underly peristalsis. Normally, the gastric slow-wave oscillates with a single period and uniform rostrocaudal lag, exhibiting network entrainment. Understanding of the integrative role of neurotransmission and intercellular coupling in the propagation of an entrained gastric slow-wave, important for understanding motility disorders, however, remains incomplete. Using a computational framework constituted of a novel gastric motility network (GMN) model we address the hypothesis that engaging biological oscillators (i.e., ICCs) by constitutive gap junction coupling mechanisms and enteric neural innervation activated signals can confer a robust entrained gastric slow-wave. We demonstrate that while a decreasing enteric neural innervation gradient that modulates the intracellular IP3 concentration in the ICCs can guide the aboral slow-wave propagation essential for peristalsis, engaging ICCs by recruiting the exchange of second messengers (inositol trisphosphate (IP3) and Ca2+) ensures a robust entrained longitudinal slow-wave, even in the presence of biological variability in electrical coupling strengths. Our GMN with the distinct intercellular coupling in conjunction with the intracellular feedback pathways and a rostrocaudal enteric neural innervation gradient allows gastric slow waves to oscillate with a moderate range of frequencies and to propagate with a broad range of velocities, thus preventing decoupling observed in motility disorders. Overall, the findings provide a mechanistic explanation for the emergence of decoupled slow waves associated with motility impairments of the stomach, offer directions for future experiments and theoretical work, and can potentially aid in the design of new interventional pharmacological and neuromodulation device treatments for addressing gastric motility disorders.","",""
0,"Md Ashfaq Ahmed, S. Venugopal, R. Jung","Engaging biological oscillators through second messenger pathways permits emergence of a robust gastric slow-wave during peristalsis",2021,"","","","",192,"2022-07-13 10:07:43","","10.1371/journal.pcbi.1009644","","",,,,,0,0.00,0,3,1,"Peristalsis, the coordinated contraction - relaxation of the muscles of the stomach is important for normal gastric motility and is impaired in motility disorders. Coordinated electrical depolarizations that originate and propagate within a network of interconnected layers of interstitial cells of Cajal (ICC) and smooth muscle (SM) cells of the stomach wall as a slow-wave, underly peristalsis. Normally, the gastric slow-wave oscillates with a single period and uniform rostrocaudal lag, exhibiting network entrainment. Understanding of the integrative role of neurotransmission and intercellular coupling in the propagation of an entrained gastric slow-wave, important for understanding motility disorders, however, remains incomplete. Using a computational framework constituted of a novel gastric motility network (GMN) model we address the hypothesis that engaging biological oscillators (i.e., ICCs) by constitutive gap junction coupling mechanisms and enteric neural stimulus activated signals can confer a robust entrained gastric slow-wave. We demonstrate that while a decreasing enteric neural stimulus gradient that modulates the intracellular IP3 concentration in the ICCs can guide the aboral slow-wave propagation essential for peristalsis, engaging ICCs by recruiting the exchange of second messengers (inositol trisphosphate (IP3) and Ca2+) ensures a robust entrained longitudinal slow-wave, even in the presence of biological variability in coupling strengths. Our GMN with the distinct intercellular coupling in conjunction with the intracellular feedback pathways and a rostrocaudal enteric neural stimulus gradient allows gastric slow waves to oscillate with a moderate range of frequencies and to propagate with a broad range of velocities, thus preventing decoupling observed in motility disorders. Overall, the findings provide a mechanistic explanation for the emergence of decoupled slow waves associated with motility impairments of the stomach, offer directions for future experiments and theoretical work, and can potentially aid in the design of new interventional pharmacological and neuromodulation device treatments for addressing gastric motility disorders. Author Summary The coordinated contraction and relaxation of the muscles of the stomach, known as peristalsis is important for normal gastric motility and primarily governed by electrical depolarizations that originate and propagate within a network of interconnected layers of interstitial cells of Cajal (ICCs) and smooth muscle cells of the stomach wall as a slow-wave. Under normal conditions, a gastric slow-wave oscillates with a single period and uniform rostrocaudal lag, exhibiting network entrainment. However, the understanding of intrinsic and extrinsic mechanisms that ensure propagation of a robust entrained slow-wave remains incomplete. Here, using a computational framework, we show that in conjunction with an enteric neural stimulus gradient along the rostrocaudal ICC chain, and intercellular electrical coupling, the intercellular exchange of inositol trisphosphate between ICCs prevents decoupling by extending the longitudinal entrainment range along the stomach wall, even when variability in intercellular coupling exists. The findings from our study indicate ways that ensure the rostrocaudal spread of a robust gastric slow-wave and provide a mechanistic explanation for the emergence of decoupled slow waves associated with motility impairments of the stomach.","",""
36,"E. Magosso, Cristiano Cuppini, M. Ursino","A Neural Network Model of Ventriloquism Effect and Aftereffect",2012,"","","","",193,"2022-07-13 10:07:43","","10.1371/journal.pone.0042503","","",,,,,36,3.60,12,3,10,"Presenting simultaneous but spatially discrepant visual and auditory stimuli induces a perceptual translocation of the sound towards the visual input, the ventriloquism effect. General explanation is that vision tends to dominate over audition because of its higher spatial reliability. The underlying neural mechanisms remain unclear. We address this question via a biologically inspired neural network. The model contains two layers of unimodal visual and auditory neurons, with visual neurons having higher spatial resolution than auditory ones. Neurons within each layer communicate via lateral intra-layer synapses; neurons across layers are connected via inter-layer connections. The network accounts for the ventriloquism effect, ascribing it to a positive feedback between the visual and auditory neurons, triggered by residual auditory activity at the position of the visual stimulus. Main results are: i) the less localized stimulus is strongly biased toward the most localized stimulus and not vice versa; ii) amount of the ventriloquism effect changes with visual-auditory spatial disparity; iii) ventriloquism is a robust behavior of the network with respect to parameter value changes. Moreover, the model implements Hebbian rules for potentiation and depression of lateral synapses, to explain ventriloquism aftereffect (that is, the enduring sound shift after exposure to spatially disparate audio-visual stimuli). By adaptively changing the weights of lateral synapses during cross-modal stimulation, the model produces post-adaptive shifts of auditory localization that agree with in-vivo observations. The model demonstrates that two unimodal layers reciprocally interconnected may explain ventriloquism effect and aftereffect, even without the presence of any convergent multimodal area. The proposed study may provide advancement in understanding neural architecture and mechanisms at the basis of visual-auditory integration in the spatial realm.","",""
106,"Xiaofeng Chen, Zhongshan Li, Q. Song, Jin Hu, Yuanshun Tan","Robust stability analysis of quaternion-valued neural networks with time delays and parameter uncertainties",2017,"","","","",194,"2022-07-13 10:07:43","","10.1016/j.neunet.2017.04.006","","",,,,,106,21.20,21,5,5,"","",""
114,"Xiaoshuai Ding, Jinde Cao, A. Alsaedi, F. Alsaadi, T. Hayat","Robust fixed-time synchronization for uncertain complex-valued neural networks with discontinuous activation functions",2017,"","","","",195,"2022-07-13 10:07:43","","10.1016/j.neunet.2017.03.006","","",,,,,114,22.80,23,5,5,"","",""
0,"Wanli Liu, Chen Li, Hongzan Sun, Weiming Hu, Hao Chen, Changhao Sun, M. Grzegorzek","Is Image Size Important? A Robustness Comparison of Deep Learning Methods for Multi-scale Cell Image Classification Tasks: from Convolutional Neural Networks to Visual Transformers",2021,"","","","",196,"2022-07-13 10:07:43","","","","",,,,,0,0.00,0,7,1,"Cervical cancer is a very common and fatal cancer in women, but it can be prevented through early examination and treatment. Cytopathology images are often used to screen for cancer. Then, because of the possibility of artificial errors due to the large number of this method, the computer-aided diagnosis system based on deep learning is developed. The image input required by the deep learning method is usually consistent, but the size of the clinical medical image is inconsistent. The internal information is lost after resizing the image directly, so it is unreasonable. A lot of research is to directly resize the image, and the results are still robust. In order to find a reasonable explanation, 22 deep learning models are used to process images of different scales, and experiments are conducted on the SIPaKMeD dataset. The conclusion is that the deep learning method is very robust to the size changes of images. This conclusion is also validated on the Herlev dataset.","",""
9,"Federico Baldassarre, Kevin Smith, J. Sullivan, Hossein Azizpour","Explanation-based Weakly-supervised Learning of Visual Relations with Graph Networks",2020,"","","","",197,"2022-07-13 10:07:43","","10.1007/978-3-030-58604-1_37","","",,,,,9,4.50,2,4,2,"","",""
31,"Jiahui Li, Hongli Dong, Zidong Wang, Nan Hou, F. Alsaadi","On passivity and robust passivity for discrete-time stochastic neural networks with randomly occurring mixed time delays",2017,"","","","",198,"2022-07-13 10:07:43","","10.1007/s00521-017-2980-1","","",,,,,31,6.20,6,5,5,"","",""
88,"Zhuanzhe Zhao, Qingsong Xu, M. Jia","Improved shuffled frog leaping algorithm-based BP neural network and its application in bearing early fault diagnosis",2016,"","","","",199,"2022-07-13 10:07:43","","10.1007/s00521-015-1850-y","","",,,,,88,14.67,29,3,6,"","",""
33,"V. Nguyen, J. Starzyk, Wooi-Boon Goh, Daniel Jachyra","Neural Network Structure for Spatio-Temporal Long-Term Memory",2012,"","","","",200,"2022-07-13 10:07:43","","10.1109/TNNLS.2012.2191419","","",,,,,33,3.30,8,4,10,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","",""
