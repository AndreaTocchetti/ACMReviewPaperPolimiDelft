Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
1,"B. Soni, Prachi Mathur, Angshuman Bora","In Depth Analysis, Applications and Future Issues of Artificial Neural Network",2020,"","","","",1,"2022-07-13 09:26:17","","10.1007/978-3-030-52067-0_7","","",,,,,1,0.50,0,3,2,"","",""
0,"J. Qiu, Xinlei Yan, W. Wang, Wei Wei, Kai Fang","Skeleton-Based Abnormal Behavior Detection Using Secure Partitioned Convolutional Neural Network Model.",2021,"","","","",2,"2022-07-13 09:26:17","","10.1109/JBHI.2021.3137334","","",,,,,0,0.00,0,5,1,"The abnormal behavior detection is the vital for evaluation of daily-life health status of the patient with cognitive impairment. Previous studies about abnormal behavior detection indicate that convolution neural network (CNN)-based computer vision owns the high robustness and accuracy for detection. However, executing CNN model on the cloud possible incurs a privacy disclosure problem during data transmission, and the high computation overhead makes difficult to execute the model on edge-end IoT devices with a well real-time performance. In this paper, we realize a skeleton-based abnormal behavior detection, and propose a secure partitioned CNN model (SP-CNN) to extract human skeleton keypoints and achieve safely collaborative computing by deploying different CNN model layers on the cloud and the IoT device. Because, the data outputted from the IoT device are processed by the several CNN layers instead of transmitting the sensitive video data, objectively it reduces the risk of privacy disclosure. Moreover, we also design an encryption method based on channel state information (CSI) to guarantee the sensitive data security. At last, we apply SP-CNN in abnormal behavior detection to evaluate its effectiveness. The experiment results illustrate that the efficiency of the abnormal behavior detection based on SP-CNN is at least 33.2% higher than the state-of-the-art methods, and its detection accuracy arrives to 97.54%.","",""
0,"Ioannis E. Polykretis, Guangzhi Tang, Praveenram Balachandar, K. Michmizos","A Spiking Neural Network Mimics the Oculomotor System to Control a Biomimetic Robotic Head Without Learning on a Neuromorphic Hardware",2022,"","","","",3,"2022-07-13 09:26:17","","10.1109/TMRB.2022.3155278","","",,,,,0,0.00,0,4,1,"Facilitated by the emergence of neuromorphic hardware, neuromorphic algorithms mimic the brain’s asynchronous computation to improve energy efficiency, low latency, and robustness, which are crucial for a wide variety of real-time robotic applications. However, the limited on-chip learning abilities hinder the applicability of neuromorphic computing to real-world robotic tasks. Biomimetism can overcome this limitation by complementing or replacing training with the knowledge of the brain’s connectome associated with the targeted behavior. By drawing inspiration from the human oculomotor network, we designed a spiking neural network (SNN) that tracked visual targets in real-time. We deployed the biomimetic controller on Intel’s Loihi neuromorphic processor to control an in-house robotic head. The robot’s behavior resembled the smooth pursuit and saccadic eye movements observed in humans, while the SNN on Loihi exhibited similar performance to a CPU-run PID controller. Interestingly, this behavior emerged from the SNN without training, which places the biomimetic design as an alternative to the energy- and data-greedy learning-based methods. This work reinforces our on-going efforts to devise energy-efficient autonomous robots that mimic the robustness and versatility of their biological counterparts.","",""
3,"C. Ananth, M. Karthikeyan, N. Mohananthini","Discrete Wavelet Transform Based Multiple Watermarking for Digital Images Using Back-Propagation Neural Network",2019,"","","","",4,"2022-07-13 09:26:17","","10.1007/978-3-030-33846-6_49","","",,,,,3,1.00,1,3,3,"","",""
6,"Hyunkyu Park, Hyosang Lee, Kyungseo Park, Sangwoo Mo, Jung Kim","Deep Neural Network Approach in Electrical Impedance Tomography-based Real-time Soft Tactile Sensor",2019,"","","","",5,"2022-07-13 09:26:17","","10.1109/IROS40897.2019.8968532","","",,,,,6,2.00,1,5,3,"Recently, a whole-body tactile sensing have emerged in robotics for safe human-robot interaction. A key issue in the whole-body tactile sensing is ensuring large-area manufacturability and high durability. To fulfill these requirements, a reconstruction method called electrical impedance tomography (EIT) was adopted in large-area tactile sensing. This method maps voltage measurements to conductivity distribution using only a few number of measurement electrodes. A common approach for the mapping is using a linearized model derived from the Maxwell’s equation. This linearized model shows fast computation time and moderate robustness against measurement noise but reconstruction accuracy is limited. In this paper, we propose a novel nonlinear EIT algorithm through Deep Neural Network (DNN) approach to improve the reconstruction accuracy of EIT-based tactile sensors. The neural network architecture with rectified linear unit (ReLU) function ensured extremely low computational time (0.002 seconds) and nonlinear network structure which provides superior measurement accuracy. The DNN model was trained with dataset synthesized in simulation environment. To achieve the robustness against measurement noise, the training proceeded with additive Gaussian noise that estimated through actual measurement noise. For real sensor application, the trained DNN model was transferred to a conductive fabric-based soft tactile sensor. For validation, the reconstruction error and noise robustness were mainly compared using conventional linearized model and proposed approach in simulation environment. As a demonstration, the tactile sensor equipped with the trained DNN model is presented for a contact force estimation.","",""
0,"Zixi Liu, Yang Feng, Yining Yin, Zhenyu Chen","DeepState: Selecting Test Suites to Enhance the Robustness of Recurrent Neural Networks",2022,"","","","",6,"2022-07-13 09:26:17","","10.1145/3510003.3510231","","",,,,,0,0.00,0,4,1,"Deep Neural Networks (DNN) have achieved tremendous success in various software applications. However, accompanied by outstanding effectiveness, DNN-driven software systems could also exhibit incorrect behaviors and result in some critical accidents and losses. The testing and optimization of DNN-driven software systems rely on a large number of labeled data that often require many human efforts, resulting in high test costs and low efficiency. Although plenty of coverage-based criteria have been proposed to assist in the data selection of convolutional neural networks, it is difficult to apply them on Recurrent Neural Network (RNN) models due to the difference between the working nature. In this paper, we propose a test suite selection tool DeepState towards the particular neural network structures of RNN models for reducing the data labeling and computation cost. DeepState selects data based on a stateful perspective of RNN, which identifies the possibly misclassified test by capturing the state changes of neurons in RNN models. We further design a test selection method to enable testers to obtain a test suite with strong fault detection and model improvement capability from a large dataset. To evaluate DeepState, we conduct an extensive empirical study on popular datasets and prevalent RNN models containing image and text processing tasks. The experimental results demonstrate that DeepState outperforms existing coverage-based techniques in selecting tests regarding effectiveness and the inclusiveness of bug cases. Meanwhile, we observe that the selected data can improve the robustness of RNN models effectively.","",""
2,"Xuechun Wang, Wendong Chen, Yuan Ji, F. Ran","Gesture recognition based on parallel hardware neural network implemented with stochastic logics",2016,"","","","",7,"2022-07-13 09:26:17","","10.1109/ICALIP.2016.7846555","","",,,,,2,0.33,1,4,6,"A new method based on neural network using stochastic computing is presented for the recognition of human gesture. In the current gesture recognition study, most of the technologies require high hardware resources and power consumption. Considering gesture recognition algorithms, the power limitations of their complex systems have encouraged designers toward searching for a reconfigurable architecture, stochastic computing. For different neural networks with complex arithmetic operations, computation on stochastic bit streams costs fewer resources and performs very efficient in operation. The experimental results demonstrate that the stochastic neural network could recognize different hand gesture effectively and take less hardware area. Even more, it has good robustness to the different environments.","",""
0,"J. Conradt","Bayesian Computation in Recurrent Neural Circuits-a Neuro-Control Approach",2017,"","","","",8,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,5,"Over the past years, Bayesian probability theory became a popular tool for modeling human sensorimotor control and behavior. It is commonly used in the creation of optimal controllers due to its robustness in the presence of uncertainty and noise which is also a pervasive property within human sensory measurements and dynamic control tasks like saccadic eye motion. The Hidden Markov Model is an explicit example for a dynamic Bayesian network. The idea of this work is to implement the latter as a state estimator of velocity, location, and movement direction of a moving object within a robotic controller in order to recreate human-like saccadic motion. The visual input is given by a neuromorphic dynamic-vision sensor (DVS). This is fed into the Bayesian network which is built as a recurrent neural model inspired by visual processing in the brain. The motion detection network proves to be robust against noise, detects multiple stimuli, and is able to react to motion perturbations. A winner-takes-all policy, with additional movement cost considerations, then generates output initiating a saccadic movement in order to center the moving stimulus in the foveal area of the visual field. Moreover, further model extensions are addressed which could enable the controller to produce smooth pursuit behavior a more complex eye movement for continuous tracking.","",""
1,"Á. F. Kungl","Robust learning algorithms for spiking and rate-based neural networks",2020,"","","","",9,"2022-07-13 09:26:17","","10.11588/HEIDOK.00028385","","",,,,,1,0.50,1,1,2,"Inspired by the remarkable properties of the human brain, the fields of machine learning, computational neuroscience and neuromorphic engineering have achieved significant synergistic progress in the last decade. Powerful neural network models rooted in machine learning have been proposed as models for neuroscience and for applications in neuromorphic engineering. However, the aspect of robustness is often neglected in these models. Both biological and engineered substrates show diverse imperfections that deteriorate the performance of computation models or even prohibit their implementation. This thesis describes three projects aiming at implementing robust learning with local plasticity rules in neural networks. First, we demonstrate the advantages of neuromorphic computations in a pilot study on a prototype chip. Thereby, we quantify the speed and energy consumption of the system compared to a software simulation and show how on-chip learning contributes to the robustness of learning. Second, we present an implementation of spike-based Bayesian inference on accelerated neuromorphic hardware. The model copes, via learning, with the disruptive effects of the imperfect substrate and benefits from the acceleration. Finally, we present a robust model of deep reinforcement learning using local learning rules. It shows how backpropagation combined with neuromodulation could be implemented in a biologically plausible framework. The results contribute to the pursuit of robust and powerful learning networks for biological and neuromorphic substrates.","",""
2,"S. Tan, Runpei Dong, Kaisheng Ma","Multi-Glimpse Network: A Robust and Efficient Classification Architecture based on Recurrent Downsampled Attention",2021,"","","","",10,"2022-07-13 09:26:17","","","","",,,,,2,2.00,1,3,1,"Most feedforward convolutional neural networks spend roughly the same efforts for each pixel. Yet human visual recognition is an interaction between eye movements and spatial attention, which we will have several glimpses of an object in different regions. Inspired by this observation, we propose an end-to-end trainable M ulti- G limpse N etwork ( MGNet ) which aims to tackle the challenges of high computation and the lack of robustness based on recurrent downsampled attention mechanism. Speciﬁcally, MGNet sequentially selects task-relevant regions of an image to focus on and then adaptively combines all collected information for the ﬁnal prediction. MGNet expresses higher resistance against adversarial attacks and common corruptions with less computation. Also, MGNet is inherently more interpretable as it explicitly informs us where it focuses during each iteration. Our experiments on ImageNet100 demonstrate the potential of recurrent downsampled attention mechanisms to improve a single feedforward manner. For example, MGNet improves 4.76% accuracy on average in common corruptions with only 36.9% computational cost. Moreover, while the baseline incurs an accuracy drop to 7.6%, MGNet manages to maintain 44.2% accuracy in the same PGD attack strength with ResNet-50 backbone. Our code is available at https: //github.com/siahuat0727/MGNet .","",""
1,"Motoki Sakurai, Yosuke Ueno, Masaaki Kondo","Path Planning and Moving Obstacle Avoidance with Neuromorphic Computing",2021,"","","","",11,"2022-07-13 09:26:17","","10.1109/ISR50024.2021.9419537","","",,,,,1,1.00,0,3,1,"Neuromorphic computing has been getting attention because of its potential for fast and low-power computation, robustness, and learning capability. Though traditional machine learning applications are main target of neuromorphic computing, its characteristic of parallel and distributed processing with simple spike-based signals is useful for other types of applications such as a shortest path finding problem (SPFP) on a graph. Prior work discussed approaches for mapping SPFP to a spiking neural network (SNN). In this paper, we propose an SNN algorithm for path planning with moving obstacles. In real world situation, there are many moving obstacles (such as other cars for an autonomous driving car and human for a moving robot) around a target agent which tries to optimize its own path to the goal. Finding an effective path in such an environment is not an easy task since behavior of obstacles is sometimes unknown and there must be a huge number of candidate paths to go. Traditional methods for SPFP with a general CPU may not be effective since it should compare candidate paths and select the most suitable one every time step. We consider two agents with SNN which tries to achieve two goals: “reaching its destination promptly” and “avoiding moving obstacles properly”. Thanks to SNN properties, the agent can learn and estimate how the obstacles move. We compare the proposal approaches with an existing method on a 2D grid graph and the result shows that the proposal agents can select proper paths depending on obstacles' movement.","",""
5,"Rohini Goel, Avinash Sharma, Rajiv Kapoor","State-of-the-Art Object Recognition Techniques: A Comparative Study",2020,"","","","",12,"2022-07-13 09:26:17","","10.1007/978-981-15-0751-9_85","","",,,,,5,2.50,2,3,2,"","",""
28,"Gabriel L. Oliveira, Claas Bollen, W. Burgard, T. Brox","Efficient and robust deep networks for semantic segmentation",2018,"","","","",13,"2022-07-13 09:26:17","","10.1177/0278364917710542","","",,,,,28,7.00,7,4,4,"This paper explores and investigates deep convolutional neural network architectures to increase the efficiency and robustness of semantic segmentation tasks. The proposed solutions are based on up-convolutional networks. We introduce three different architectures in this work. The first architecture, called Part-Net, is designed to tackle the specific problem of human body part segmentation and to provide robustness to overfitting and body part occlusion. The second network, called Fast-Net, is a network specifically designed to provide the smallest computation load without losing representation power. Such an architecture is capable of being run on mobile GPUs. The last architecture, called M-Net, aims to maximize the robustness characteristics of deep semantic segmentation approaches through multiresolution fusion. The networks achieve state-of-the-art performance on the PASCAL Parts dataset and competitive results on the KITTI dataset for road and lane segmentation. Moreover, we introduce a new part segmentation dataset, the Freiburg City dataset, which is designed to bring semantic segmentation to highly realistic robotics scenarios. Additionally, we present results obtained with a ground robot and an unmanned aerial vehicle and a full system to explore the capabilities of human body part segmentation in the context of human–robot interaction.","",""
1,"Shekhar Nayak, D. Shashank, Saurabhchand Bhati, Koilakuntla Bramhendra, K. S. R. Murty","Instantaneous Frequency Features for Noise Robust Speech Recognition",2019,"","","","",14,"2022-07-13 09:26:17","","10.1109/NCC.2019.8732216","","",,,,,1,0.33,0,5,3,"Analytic phase of the speech signal plays an important role in human speech perception, specially in the presence of noise. Generally, phase information is ignored in most of the recent speech recognition systems. In this paper, we illustrate the importance of analytic phase of the speech signal for noise robust automatic speech recognition. To avoid phase wrapping problem involved in the computation of analytic phase, features are extracted from instantaneous frequency (IF) which is time derivative of analytic phase. Deep neural network (DNN) based acoustic models are trained on clean speech using features extracted from the IF of speech signals. Robustness of IF features in combination with mel-frequency cepstral coefficients (MFCCs) was evaluated in varied noisy conditions. System combination using minimum Bayes risk decoding of IF features with MFCCs delivered absolute improvements of upto 13% over MFCC features alone for DNN based systems under noisy conditions. The impact of the system combination of magnitude and phase based features on different phonetic classes was studied under noisy conditions and was found to model both voiced and unvoiced phonetic classes efficiently.","",""
0,"Liyuan Zhao, Zhong-ren Peng","Microsimulation of Land Use Change with Artificial Neural Networks, Cellular Automata, and Multi-Agents Model",2011,"","","","",15,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,2,11,"This paper presents a methodology through employing artificial neural network (ANN), cellular automata (CA), and multi-agent model for simulating land use change. To facilitate transportation analysis, the model utilizes a series of transition rules defined for each land cell (50*50 meters) to describe both spatial factors and the human decision making behaviors of land use development. Based on the geographic information systems (GIS) data in 1990, the model forecasts all land use types and transportation-related types (LUT) in 2000 with high prediction accuracy of 89.8% and 87.7%, respectively. Compared to ANN with one hidden layer, three hidden layers achieved higher prediction accuracy but required more computation time. Modeling results also show the ANN approach is not effective in smaller sized lands, including lower robustness and lower prediction accuracy. The Agents mode represents policy and human micro decision making. When combined with ANN model, the prediction accuracy is improved and the low robustness for ANN model only is relieved.","",""
34,"Amogh Gudi","Recognizing Semantic Features in Faces using Deep Learning",2015,"","","","",16,"2022-07-13 09:26:17","","","","",,,,,34,4.86,34,1,7,"The human face constantly conveys information, both consciously and subconsciously. However, as basic as it is for humans to visually interpret this information, it is quite a big challenge for machines. Conventional semantic facial feature recognition and analysis techniques are already in use and are based on physiological heuristics, but they suffer from lack of robustness and high computation time. This thesis aims to explore ways for machines to learn to interpret semantic information available in faces in an automated manner without requiring manual design of feature detectors, using the approach of Deep Learning. This thesis provides a study of the effects of various factors and hyper-parameters of deep neural networks in the process of determining an optimal network configuration for the task of semantic facial feature recognition. This thesis explores the effectiveness of the system to recognize the various semantic features (like emotions, age, gender, ethnicity etc.) present in faces. Furthermore, the relation between the effect of high-level concepts on low level features is explored through an analysis of the similarities in low-level descriptors of different semantic features. This thesis also demonstrates a novel idea of using a deep network to generate 3-D Active Appearance Models of faces from real-world 2-D images.  For a more detailed report on this work, please see [arXiv:1512.00743v1].","",""
69,"M. Wöllmer, F. Eyben, A. Graves, Björn Schuller, G. Rigoll","Bidirectional LSTM Networks for Context-Sensitive Keyword Detection in a Cognitive Virtual Agent Framework",2010,"","","","",17,"2022-07-13 09:26:17","","10.1007/s12559-010-9041-8","","",,,,,69,5.75,14,5,12,"","",""
14,"R. Arriaga, David Rutter, M. Cakmak, S. Vempala","Visual Categorization with Random Projection",2015,"","","","",18,"2022-07-13 09:26:17","","10.1162/NECO_a_00769","","",,,,,14,2.00,4,4,7,"Abstract Humans learn categories of complex objects quickly and from a few examples. Random projection has been suggested as a means to learn and categorize efficiently. We investigate how random projection affects categorization by humans and by very simple neural networks on the same stimuli and categorization tasks, and how this relates to the robustness of categories. We find that (1) drastic reduction in stimulus complexity via random projection does not degrade performance in categorization tasks by either humans or simple neural networks, (2) human accuracy and neural network accuracy are remarkably correlated, even at the level of individual stimuli, and (3) the performance of both is strongly indicated by a natural notion of category robustness.","",""
0,"Kang Li, Quan Guo, Jixiang Guo","Novel algorithms for reducing bladder volume estimation error caused by scanning positions",2017,"","","","",19,"2022-07-13 09:26:17","","10.1080/00207160.2016.1184260","","",,,,,0,0.00,0,3,5,"ABSTRACT Bladder volume is an important and useful indicator to accurately diagnosis urinary diseases. Using the mechanical probe with single vibration source to estimate bladder volume is low-priced and portable. It also contains fast computation speed and low requirements to operators. However, the bladder volume estimated by this kind of probe will be influenced by improper scanning positions. To address this problem, we propose two localization approaches. One is based on geometry method, which has fast computation speed and high accuracy. The other one is based on neural network method, which contains high robustness and stable experiment results. After applying these two approaches to the standard phantom environment and human environment, we get a conclusion that the proposed approaches can effectively decrease the bladder volume estimation error caused by improper scanning positions.","",""
1,"Horng-Chang Yang","Multiresolution neural networks for image edge detection and restoration",1994,"","","","",20,"2022-07-13 09:26:17","","","","",,,,,1,0.04,1,1,28,"One of the methods for building an automatic visual system is to borrow the properties of the human visual system (HVS). Artificial neural networks are based on this doctrine and they have been applied to image processing and computer vision. This work focused on the plausibility of using a class of Hopfield neural networks for edge detection and image restoration.    To this end, a quadratic energy minimization framework is presented. Central to this framework are relaxation operations, which can be implemented using the class of Hopfield neural networks. The role of the uncertainty principle in vision is described, which imposes a limit on the simultaneous localisation in both class and position space. It is shown how a multiresolution approach allows the trade off between position and class resolution and ensures both robustness in noise and efficiency of computation. As edge detection and image restoration are ill-posed, some a priori knowledge is needed to regularize these problems. A multiresolution network is proposed to tackle the uncertainty problem and the regularization of these ill-posed image processing problems. For edge detection, orientation information is used to construct a compatibility function for the strength of the links of the proposed Hopfield neural network.    Edge detection 'results are presented for a number of synthetic and natural images which show that the iterative network gives robust results at low signal-to-noise ratios (0 dB) and is at least as good as many previous methods at capturing complex region shapes. For restoration, mean square error is used as the quadratic energy function of the Hopfield neural network. The results of the edge detection are used for adaptive restoration. Also shown are the results of restoration using the proposed iterative network framework.","",""
34,"M. Lappe","Functional Consequences of an Integration of Motion and Stereopsis in Area MT of Monkey Extrastriate Visual Cortex",1996,"","","","",21,"2022-07-13 09:26:17","","10.1162/neco.1996.8.7.1449","","",,,,,34,1.31,34,1,26,"Experimental evidence from neurophysiological recordings in the middle temporal (MT) area of the macaque monkey suggests that motion-selective cells can use disparity information to separate motion signals that originate from different depths. This finding of a cross-talk between different visual channels has implications for the understanding of the processing of motion in the primate visual system and especially for behavioral tasks requiring the determination of global motion. In this paper, the consequences for the analysis of optic flow fields are explored. A network model is presented that effectively uses the disparity sensitivity of MT-like neurons for the reduction of noise in optic flow fields. Simulations reproduce the recent psychophysical finding that the robustness of the human optic flow processing system is improved by stereoscopic depth information, but that the use of this information depends on the structure of the visual environment.","",""
6,"L. Zadeh, Y. Badr, A. Abraham, Yukio Ohsawa, R. Chbeir, F. Ferri, Mario Koeppen, D. Laurent","Proceedings of the 5th international conference on Soft computing as transdisciplinary science and technology",2008,"","","","",22,"2022-07-13 09:26:17","","","","",,,,,6,0.43,1,8,14,"Soft Computing (SC) has an evolving collection of methodologies, which is aimed to exploit tolerance for imprecision uncertainty, and partial truth to achieve robustness, tractability, and low cost. SC provides attractive opportunity to represent the ambiguity in human thinking with real life uncertainty. Fuzzy logic (FL), Neural Networks (NN), and Evolutionary Computation (EC) were the core methodologies of soft computing. Later chaos computing, fractal theory, wavelet transformation, cellular automaton, percolation models, and immune network theory were added to enhance soft computing. However, they should not be viewed as competing with each other, but synergistic and complementary, instead. SC was actually the combination or fusion of each methodology which yielded new computational capabilities (hybrid systems). Soft computing is currently causing a paradigm shift (breakthrough) in science and technology.    The stage for the Fifth IEEE/ACM International Conference on Soft Computing as Transdisciplinary Science and Technology (CSTST'08) has been set. This edition is dedicated to commemorate the memory of Professor Yasuhiko Dote, Founding Chair of WSTST series of meetings. In essence, CSTST'08 is built on the success of the previous four events held in Muroran, Japan namely the IEEE International Workshop on Neuro Fuzzy Control, in 1993; IEEE International Workshop on Soft Computing in Industry, in 1996, the IEEE International Workshop on Soft Computing in Industry, in 1999 and International Workshop on Soft Computing as Transdisciplinary Science and Technology (WSTST'2005). CSTST'08 is hosted by University of Cergy Pontoise, France and is technically co-sponsored by IEEE Systems Man and Cybernetics Society, ACM SIGAPP (French Chapter), IEEE French Section, World Federation on Soft Computing, European Society for Fuzzy Logic, Technology and International Fuzzy Systems Association, and AFIHM - French Association of Human Computer Interaction. On behalf of the CSTST'08 program committee, we wish to extend a very warm welcome to this edition in Cergy-Pontoise/Paris, France. The conference program committee has organized an exciting and invigorating program comprising presentations from distinguished experts in the field, and important and wide-ranging contributions on state-of-the-art research that provide new insights into current cutting edge results on ""Soft Computing as Transdisciplinary Science and Technology"".    This year, we received over 212 regular submissions and we are really gratified by the international diversity of this conference: authors of submitted work hail from no less than 30 countries including Vietnam, Egypt, Bulgaria, Turkey, Russia, Netherlands, Austria, Malaysia, Sweden, Croatia, Kuwait, Cyprus, Belgium, Estonia, Latvia, Lebanon, Macedonia, Singapore, Argentina, United Arab Emirates, Thailand, Ukraine, Hungary, Ireland, Czech, Republic, Spain, Norway, Taiwan, Canada, Libya, Romania, Mexico, Greece, Brazil, Pakistan, Germany, Australia, Tunisia, India, United States of America, Italy, Korea, Poland, Algeria, Japan, United Kingdom, Iran, China, Portugal, and France. The technical program of CSTST'08 conference comprises of 62 papers. The conference program committee had a very challenging task of choosing high quality submissions. Each paper was peer reviewed by at least three or more independent referees of the program committee and the papers were selected based on the referee recommendations. The papers offer stimulating insights into emerging intelligent technologies and their applications in Internet security, chance discovery, humanized computational intelligence, web intelligence, data mining, image processing, swarm intelligence, optimization and so on.","",""
0,"Aires da Conceição, S. Degadwala","Convolutional Neural Network Computation for Autonomous Vehicle",2020,"","","","",23,"2022-07-13 09:26:17","","10.32628/cseit2062112","","",,,,,0,0.00,0,2,2,"Self-driving vehicle is a vehicle that can drive by itself it means without human interaction. This system shows how the computer can learn and the over the art of driving using machine learning techniques. This technique includes line lane tracker, robust feature extraction and convolutional neural network.","",""
16,"Xiao Qi, L. G. Brown, D. Foran, J. Nosher, I. Hacihaliloglu","Chest X-ray image phase features for improved diagnosis of COVID-19 using convolutional neural network",2020,"","","","",24,"2022-07-13 09:26:17","","10.1007/s11548-020-02305-w","","",,,,,16,8.00,3,5,2,"","",""
12,"Deepak Baby, Arthur Van Den Broucke, S. Verhulst","A convolutional neural-network model of human cochlear mechanics and filter tuning for real-time applications",2020,"","","","",25,"2022-07-13 09:26:17","","10.1038/s42256-020-00286-8","","",,,,,12,6.00,4,3,2,"","",""
1,"M. Mohammadi, Arman Garousi","A Fast and Simple Face Detection Algorithm Using Neural Network and Its Implementation on FPGA",2021,"","","","",26,"2022-07-13 09:26:17","","10.54380/ijrdetv10i102","","",,,,,1,1.00,1,2,1,"Face recognition is one of the interesting types of biometric which determines the presence or absence of human faces in the picture. In this paper, a face recognition system is presented that benefits from an optimized architecture based on the MLP neural network. The proposed method considerably improves the speed and the accuracy of detection compared to traditional architectures of neural network. To reduce the overall computation, neural network is organized so that to be able to rule out the majority of the non-image areas located in the image’s background before applying the main algorithm. An important advantage of this new architecture is its homogeneous structure that makes it suitable for optimized implementation on a hardware platform. In this work, FPGA is used as the platform for implementation of the proposed algorithms. The implementation was done considering Taylor expansion of the activation functions. The performance of the proposed method and the implemented system was evaluated on the BioID dataset. Accomplishment of the proposed method is high precision while reducing training time and total calculations, together with appropriate robustness. Finally, a comparison with other face recognition methods has been done to show the performance of the presented system. The comparison result shows that the proposed system outperforms the other mentioned methods.","",""
0,"S. Farooq, Simranjit Kaur, Satnam Singh Dub","Analysis of Genetic Algorithm Optimized Neural Network System for Human Gait Recognition",2021,"","","","",27,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,1,"This paper explores a gait recognition method with binary silhouette-based input images and Genetic Algorithm Optimized Artificial Neural Network (GA-NN) classification. The performance of the recognition method depends significantly on the quality of the extracted binary silhouettes. A fuzzy correlogram based method is employed for background subtraction and Frame Difference Energy Image (FDEI) reconstruction is performed to make the recognition method robust to partial incompleteness of silhouettes. Feature extraction process uses extracted features directly for classification while the indirect method maps the higher-dimensional features into a lower-dimensional space by means of a Frame-to-Exemplar-Distance (FED) vector. The FED uses the distance measure between pre-determined exemplars and the feature vectors of the current frame as an identification criterion. The extracted features are fed to the GA optimizer for feature fitness evaluation and NN-based classifier which models human gait to compute similarity scores and carry out identification. This work achieves an overall accuracy for all database datasets with difference in recognition time as the dataset sample bulk increases and the GA optimization and ANN trains and learns itself from increased number of samples. As expected, the results using this approach are better, owing to a basic trade-off between complexity and efficiency. The approach is computationally more extensive with a better overall performance, while the indirect approach tends to be computationally less intensive at the cost of recognition performance. Also this approach is less vulnerable to noise and distortion compared to the indirect approach. Surprisingly, the results obtained by using the FED vector show that in this case, the overall performance is actually slightly lesser in the case of FDEI reconstruction as compared to the use of direct binary silhouettes. It is also seen that the recognition performance depends to a certain extent on the specific gait sequences. The algorithms used in this work produce relatively better results in the case of CASIA Dataset-A.","",""
1,"Subash C. Pakhrin, Kiyoko F. Aoki-Kinoshita, Doina Caragea, Dukka B Kc","DeepNGlyPred: A Deep Neural Network-Based Approach for Human N-Linked Glycosylation Site Prediction",2021,"","","","",28,"2022-07-13 09:26:17","","10.3390/molecules26237314","","",,,,,1,1.00,0,4,1,"Protein N-linked glycosylation is a post-translational modification that plays an important role in a myriad of biological processes. Computational prediction approaches serve as complementary methods for the characterization of glycosylation sites. Most of the existing predictors for N-linked glycosylation utilize the information that the glycosylation site occurs at the N-X-[S/T] sequon, where X is any amino acid except proline. Not all N-X-[S/T] sequons are glycosylated, thus the N-X-[S/T] sequon is a necessary but not sufficient determinant for protein glycosylation. In that regard, computational prediction of N-linked glycosylation sites confined to N-X-[S/T] sequons is an important problem. Here, we report DeepNGlyPred a deep learning-based approach that encodes the positive and negative sequences in the human proteome dataset (extracted from N-GlycositeAtlas) using sequence-based features (gapped-dipeptide), predicted structural features, and evolutionary information. DeepNGlyPred produces SN, SP, MCC, and ACC of 88.62%, 73.92%, 0.60, and 79.41%, respectively on N-GlyDE independent test set, which is better than the compared approaches. These results demonstrate that DeepNGlyPred is a robust computational technique to predict N-Linked glycosylation sites confined to N-X-[S/T] sequon. DeepNGlyPred will be a useful resource for the glycobiology community.","",""
3,"Hussein Hassan-Harrirou, Ce Zhang, T. Lemmin","RosENet: Improving binding affinity prediction by leveraging molecular mechanics energies with a 3D Convolutional Neural Network",2020,"","","","",29,"2022-07-13 09:26:17","","10.1101/2020.05.12.090191","","",,,,,3,1.50,1,3,2,"The worldwide increase and proliferation of drug resistant microbes, coupled with the lag in new drug development represents a major threat to human health. In order to reduce the time and cost for exploring the chemical search space, drug discovery increasingly relies on computational biology approaches. One key step in these approaches is the need for the rapid and accurate prediction of the binding affinity for potential leads. Here, we present RosENet (Rosetta Energy Neural Network), a three-dimensional (3D) Convolutional Neural Network (CNN), which combines voxelized molecular mechanics energies and molecular descriptors for predicting the absolute binding affinity of protein – ligand complexes. By leveraging the physico-chemical properties captured by the molecular force field, our model achieved a Root Mean Square Error (RMSE) of 1.26 on the PDBBind v2016 core set. We also explored some limitations and the robustness of the PDBBind dataset and our approach, on nearly 500 structures, including structures determined by Nuclear Magnetic Resonance and virtual screening experiments. Our study demonstrated that molecular mechanics energies can be voxelized and used to help improve the predictive power of the CNNs. In the future, our framework can be extended to features extracted from other biophysical and biochemical models, such as molecular dynamics simulations. Availability https://github.com/DS3Lab/RosENet","",""
6,"Gang Liu, Jing Wang","A Polynomial Neural Network with Controllable Precision and Human-Readable Topology for Prediction and System Identification",2020,"","","","",30,"2022-07-13 09:26:17","","","","",,,,,6,3.00,3,2,2,"Although artificial neural networks (ANNs) are successful, there is still a concern among many over their ""black box"" nature. Why do they work? Could we design a ""transparent"" network? This paper presents a controllable and readable polynomial neural network (CR-PNN) for approximation, prediction, and system identification. CR-PNN is simple enough to be described as one ""small"" formula, so that we can control the approximation precision and explain the internal structure of the network. CR-PNN, in fact, essentially is the fascinating Taylor expansion in the form of network. The number of layers represents precision. Derivatives in Taylor expansion are exactly imitated by error back-propagation algorithm. Firstly, we demonstrated that CR-PNN shows excellent analysis performance to the ""black box"" system through ten synthetic data with noise. Also, the results were compared with synthetic data to substantiate its search easily towards the global optimum. Secondly, it was verified, by ten real-world applications, that CR-PNN brought better generalization capability relative to the typical ANNs that approximate depended on the nonlinear activation function. Finally, 200,000 repeated experiments, with 4898 samples, demonstrated that CR-PNN is five times more efficient than typical ANN for one epoch and ten times more efficient than typical ANN for one forward-propagation. In short, compared with the traditional neural networks, the novelties and advantages of CR-PNN include readability of the internal structure, easy to find global optimal solution, lower computational complexity, and likely better robustness to real-world approximation. (We're strong believers in Open Source, and provide CR-PNN code for others. GitHub: this https URL)","",""
3,"Carla Sendra-Balcells, R. Salvador, J. Pedro, M. Biagi, Charlène Aubinet, B. Manor, A. Thibaut, S. Laureys, K. Lekadir, G. Ruffini","Convolutional neural network MRI segmentation for fast and robust optimization of transcranial electrical current stimulation of the human brain",2020,"","","","",31,"2022-07-13 09:26:17","","10.1101/2020.01.29.924985","","",,,,,3,1.50,0,10,2,"The segmentation of structural MRI data is an essential step for deriving geometrical information about brain tissues. One important application is in transcranial direct current stimulation (e.g., tDCS), a non-invasive neuromodulatory technique where head modeling is required to determine the electric field (E-field) generated in the cortex to predict and optimize its effects. Here we propose a deep learning-based model (StarNEt) to automatize white matter (WM) and gray matter (GM) segmentation and compare its performance with FreeSurfer, an established tool. Since good definition of sulci and gyri in the cortical surface is an important requirement for E-field calculation, StarNEt is specifically designed to output masks at a higher resolution than that of the original input T1w-MRI. StarNEt uses a residual network as the encoder (ResNet) and a fully convolutional neural network with U-net skip connections as the decoder to segment an MRI slice by slice. Slice vertical location is provided as an extra input. The model was trained on scans from 425 patients in the open-access ADNI+IXI datasets, and using FreeSurfer segmentation as ground truth. Model performance was evaluated using the Dice Coefficient (DC) in a separate subset (N=105) of ADNI+IXI and in two extra testing sets not involved in training. In addition, FreeSurfer and StarNEt were compared to manual segmentations of the MRBrainS18 dataset, also unseen by the model. To study performance in real use cases, first, we created electrical head models derived from the FreeSurfer and StarNEt segmentations and used them for montage optimization with a common target region using a standard algorithm (Stimweaver) and second, we used StarNEt to successfully segment the brains of minimally conscious state (MCS) patients having suffered from brain trauma, a scenario where FreeSurfer typically fails. Our results indicate that StarNEt matches FreeSurfer performance on the trained tasks while reducing computation time from several hours to a few seconds, and with the potential to evolve into an effective technique even when patients present large brain abnormalities.","",""
0,"Yinqian Sun, Yi Zeng, Tielin Zhang","Quantum Superposition Spiking Neural Network",2020,"","","","",32,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,2,"Quantum brain as a novel hypothesis states that some non-trivial mechanisms in quantum computation, such as superposition and entanglement, may have important influence for the formation of brain functions. Inspired by this idea, we propose Quantum Superposition Spiking Neural Network (QS-SNN), which introduce quantum superposition to spiking neural network models to handel challenges which are hard for other state-of-the-art machine learning models. For human brain, grasping the main information no matter how the background changes is necessary to interact efficiently with diverse environments. As an example, it is easy for human to recognize the digits whether it is white character with black background or inversely black character with white background. While if the current machine learning models are trained with one of the cases (e.g. white character with black background), it will be nearly impossible for them to recognize the color inverted version. To handel this challenge, we propose two-compartment spiking neural network with superposition states encoding, which is inspired by quantum information theory and spatial-temporal spiking property from neuron information encoding in the brain. Typical network structures like fully-connected ANN, VGG, ResNet and DenseNet are challenged with the same task. We train these networks on original image dataset and then invert the background color to test their generalization. Result shows that artificial neural network can not deal with this condition while the quantum superposition spiking neural network(QS-SNN) which we proposed in this paper recognizes the color-inverse image successfully. Further the QS-SNN shows its robustness when noises are added on inputs.","",""
8,"Yang Lou, Yaodong He, Lin Wang, Guanrong Chen","Predicting Network Controllability Robustness: A Convolutional Neural Network Approach",2019,"","","","",33,"2022-07-13 09:26:17","","10.1109/TCYB.2020.3013251","","",,,,,8,2.67,2,4,3,"Network controllability measures how well a networked system can be controlled to a target state, and its robustness reflects how well the system can maintain the controllability against malicious attacks by means of node removals or edge removals. The measure of network controllability is quantified by the number of external control inputs needed to recover or to retain the controllability after the occurrence of an unexpected attack. The measure of the network controllability robustness, on the other hand, is quantified by a sequence of values that record the remaining controllability of the network after a sequence of attacks. Traditionally, the controllability robustness is determined by attack simulations, which is computationally time consuming. In this article, a method to predict the controllability robustness based on machine learning using a convolutional neural network (CNN) is proposed, motivated by the observations that: 1) there is no clear correlation between the topological features and the controllability robustness of a general network; 2) the adjacency matrix of a network can be regarded as a grayscale image; and 3) the CNN technique has proved successful in image processing without human intervention. Under the new framework, a fairly large number of training data generated by simulations are used to train a CNN for predicting the controllability robustness according to the input network-adjacency matrices, without performing conventional attack simulations. Extensive experimental studies were carried out, which demonstrate that the proposed framework for predicting controllability robustness of different network configurations is accurate and reliable with very low overheads.","",""
1,"Muhammad Abdullah Hanif, M. Shafique","Dependable Deep Learning: Towards Cost-Efficient Resilience of Deep Neural Network Accelerators against Soft Errors and Permanent Faults",2020,"","","","",34,"2022-07-13 09:26:17","","10.1109/IOLTS50870.2020.9159734","","",,,,,1,0.50,1,2,2,"Deep Learning has enabled machines to learn computational models (i.e., Deep Neural Networks – DNNs) that can perform certain complex tasks with claims to be close to human-level precision. This state-of-the-art performance offered by DNNs in many Artificial Intelligence (AI) applications has paved their way to being used in several safety-critical applications where even a single failure can lead to catastrophic results. Therefore, improving the robustness of these models to hardware-induced faults (such as soft errors, aging, and manufacturing defects) is of significant importance to avoid any disastrous event. Traditional redundancy-based fault mitigation techniques cannot be employed in a wide of applications due to their high overheads, which, when coupled with the compute-intensive nature of DNNs, lead to undesirable resource consumption. In this article, we present an overview of different low-cost fault-mitigation techniques that exploit the intrinsic characteristics of DNNs to limit their overheads. We discuss how each technique can contribute to the overall resilience of a DNN-based system, and how they can be integrated together to offer resilience against multiple diverse hardware-induced reliability threats. Towards the end, we highlight several key future directions that are envisioned to help in achieving highly dependable DL-based systems.","",""
12,"Linqin Cai, Xiaoling Liu, Fuli Chen, Min Xiang","Robust human action recognition based on depth motion maps and improved convolutional neural network",2018,"","","","",35,"2022-07-13 09:26:17","","10.1117/1.JEI.27.5.051218","","",,,,,12,3.00,3,4,4,"Abstract. Human action recognition has been widely used in various fields of computer vision, pattern recognition, and human–computer interaction and has attracted substantial attention. Combining deep learning and depth information, this paper proposed a method of human action recognition based on improved convolutional neural networks (CNN). First, we use the depth motion maps to extract the depth sequence features and obtain three projected maps corresponding to front, side, and the top views. On this basis, an improved CNN is constructed to realize the recognition of human action, which uses three-dimensional (3-D) input and two-dimensional process identification to speed up the computation and reduce the complexity of recognition process. We evaluate our approach on two public 3-D action datasets: MSR Action3D dataset and UT-Kinect dataset, and our private CTP Action3D dataset built using Kinect to collect data. The experimental results show that the proposed methods of human action recognition achieve higher average recognition rate of 91.3% on MSR Action3D dataset, 97.98% on UT-Kinect dataset, and the average recognition rate is 93.8% on our CTP Action3D dataset. Furthermore, the trained model on one depth video sequence dataset can be easily generalized to different datasets without changing network parameters.","",""
2,"Yue-Huan Wang, Zenan Li, Jingwei Xu, Ping Yu, Xiaoxing Ma","Fast Robustness Prediction for Deep Neural Network",2019,"","","","",36,"2022-07-13 09:26:17","","10.1145/3361242.3361243","","",,,,,2,0.67,0,5,3,"Deep neural networks (DNNs) have achieved impressive performance in many difficult tasks. However, DNN models are essentially uninterpretable to humans, and unfortunately prone to adversarial attacks, which hinders their adoption in security and safety-critical scenarios. The robustness of a DNN model, which measures its stableness against adversarial attacks, becomes an important topic in both the machine learning and the software engineering communities. Analytical evaluation of DNN robustness is difficult due to the high-dimensionality of inputs, the huge amount of parameters, and the nonlinear network structure. In practice, the degree of robustness of DNNs is empirically approximated with adversarial searching, which is computationally expensive and cannot be applied in resource constrained settings such as embedded computing. In this paper, we propose to predict the robustness of a DNN model for each input with another DNN model, which takes the output of neurons of the former model as input. We train a regression model to encode the connections between output of the penultimate layer of a DNN model and its robustness. With this trained model, the robustness for an input can be predicted instantaneously. Experiments with MNIST and CIFAR10 datasets and LeNet, VGG and ResNet DNN models were conducted to evaluate the efficacy of the proposed approach. The results indicated that our approach achieved 0.05-0.21 mean absolute errors and significantly outperformed confidence and surprise adequacy-based approaches.","",""
0,"Minghua Zhao, Min Yuan, Yaning Yang, Steven Xu","CPGL: Prediction of compound-protein interaction by integrating graph attention network with long short-term memory neural network",2022,"","","","",37,"2022-07-13 09:26:17","","10.1101/2022.04.19.488691","","",,,,,0,0.00,0,4,1,"Recent advancements of artificial intelligence based on deep learning algorithms have made it possible to computationally predict compound-protein interaction (CPI) without conducting laboratory experiments. In this manuscript, we integrated a graph attention network (GAT) for compounds and a long short-term memory neural network (LSTM) for proteins, used end-to-end representation learning for both compounds and proteins, and proposed a deep learning algorithm, CPGL (CPI with GAT and LSTM) to optimize the feature extraction from compounds and proteins and to improve the model robustness and generalizability. CPGL demonstrated an excellent predictive performance and outperforms recently reported deep learning models. Based on 3 public CPI datasets, C.elegans, Human and BindingDB, CPGL represented 1 - 5% improvement compared to existing deep-learning models. Our method also achieves excellent results on datasets with imbalanced positive and negative proportions constructed based on the above two datasets. More importantly, using 2 label reversal datasets, GPCR and Kinase, CPGL showed superior performance compared to other existing deep learning models. The AUC were substantially improved by 15% to 50% on the Kinase dataset, indicative of the robustness and generalizability of CPGL.","",""
0,"Jing Yuan, P. Barmpoutis, T. Stathaki","Pedestrian Detection Using Integrated Aggregate Channel Features and Multitask Cascaded Convolutional Neural-Network-Based Face Detectors",2022,"","","","",38,"2022-07-13 09:26:17","","10.3390/s22093568","","",,,,,0,0.00,0,3,1,"Pedestrian detection is a challenging task, mainly owing to the numerous appearances of human bodies. Modern detectors extract representative features via the deep neural network; however, they usually require a large training set and high-performance GPUs. For these cases, we propose a novel human detection approach that integrates a pretrained face detector based on multitask cascaded convolutional neural networks and a traditional pedestrian detector based on aggregate channel features via a score combination module. The proposed detector is a promising approach that can be used to handle pedestrian detection with limited datasets and computational resources. The proposed detector is investigated comprehensively in terms of parameter choices to optimize its performance. The robustness of the proposed detector in terms of the training set, test set, and threshold is observed via tests and cross dataset validations on various pedestrian datasets, including the INRIA, part of the ETHZ, and the Caltech and Citypersons datasets. Experiments have proved that this integrated detector yields a significant increase in recall and a decrease in the log average miss rate compared with sole use of the traditional pedestrian detector. At the same time, the proposed method achieves a comparable performance to FRCNN on the INRIA test set compared with sole use of the Aggregated Channel Features detector.","",""
0,"","Arrhythmia detection and classification using convolutional neural network",2021,"","","","",39,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,0,1,"Healthcare and Life Sciences are among severely researched domains. With the introduction of computing paradigms and possibility of leveraging computational techniques have opened new research avenues. Heart is one among the most researched organs and the reason being trivial. With the advent of computational paradigms researchers explored ways to measure the electrical activity of the heartbeat which is known as electrocardiogram (ECG). Since then ECG has become one of the most important as well as primary tests to diagnose any irregularities in the functioning of the heart. The availability of the ECG data and possibility of employing deep learning models and their robustness has made researchers venture into leveraging them to elevate the accuracy of the ECG Analysis. To date there exists no end-to-end evaluation model based on deep learning techniques. In our present work, we identify different classes of cardiac rhythm by leveraging single-lead ECG. Our results show a significant improvement in ROC (approx. 0.97). Furthermore, our results demonstrate that we can classify a wide spectrum of arrhythmias using Deep Learning Techniques which are comparable to that of cardiologists. This approach can be used to minimize the component of human misdiagnose and help improve the quality of cardiac care.","",""
248,"Lukas Schott, Jonas Rauber, M. Bethge, Wieland Brendel","Towards the first adversarially robust neural network model on MNIST",2018,"","","","",40,"2022-07-13 09:26:17","","","","",,,,,248,62.00,62,4,4,"Despite much effort, deep neural networks remain highly susceptible to tiny input perturbations and even for MNIST, one of the most common toy datasets in computer vision, no neural network model exists for which adversarial perturbations are large and make semantic sense to humans. We show that even the widely recognized and by far most successful defense by Madry et al. (1) overfits on the L-infinity metric (it's highly susceptible to L2 and L0 perturbations), (2) classifies unrecognizable images with high certainty, (3) performs not much better than simple input binarization and (4) features adversarial perturbations that make little sense to humans. These results suggest that MNIST is far from being solved in terms of adversarial robustness. We present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. We derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness on MNIST against L0, L2 and L-infinity perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class.","",""
0,"","Neural Network Training Using Genetic Algorithms Series In Machine Perception And Artificial Intelligence",2021,"","","","",41,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,0,1,"Knowledge-Based Intelligent Information and Engineering Systems 2Nature-inspired Methods in Chemometrics: Genetic Algorithms and Artificial Neural NetworksParallel Implementations of Backpropagation Neural Networks on TransputersEvolutionary Algorithms and Neural NetworksTraining Neural Networks Using Hybrids with Genetic AlgorithmsNeural Network Training Using Genetic AlgorithmsGene Expression ProgrammingTraining a Neural Network with a Genetic AlgorithmMethods and Applications of Artificial IntelligenceClassification and Learning Using Genetic AlgorithmsPractical Computer Vision Applications Using Deep Learning with CNNsIntelligent Hybrid SystemsNeurogenetic LearningAdvances in Neural Networks ISNN 2007Hybrid Intelligent SystemsEncyclopedia of Computer Science and TechnologyMachine LearningUsing a Genetic Algorithm in Training an Artificial Neural Network to Implement the XOR FunctionGenetic and Evolutionary Computation — GECCO 2004Handbook of Fuzzy ComputationNeural Network Data Analysis Using SimulnetTMArtificial Neural Nets and Genetic AlgorithmsApplied Soft Computing Technologies: The Challenge of ComplexityGenetic Algorithm for Artificial Neural Network Training for the Purpose of Automated Part RecognitionNEURAL NETWORKS, FUZZY LOGIC AND GENETIC ALGORITHMAutomatic Generation of Neural Network Architecture Using Evolutionary ComputationPGANETThe Sixth International Symposium on Neural Networks (ISNN 2009)Evolutionary Machine Learning TechniquesModeling Decisions for Artificial IntelligenceEmpirical Studies on the Utility of Genetic Algorithms for Training and Designing of Neural NetworksTraining Neural Networks Using Genetic AlgorithmsTraining feedforward neural networks using genetic algorithmsMetaheuristic Procedures for Training Neural NetworksArtificial Neural Nets and Genetic AlgorithmsNature-Inspired Computing: Concepts, Methodologies, Tools, and ApplicationsApplications of Evolutionary ComputingArtificial Intelligence and CreativityArtificial Neural Nets and Genetic AlgorithmsDeep Learning Using Genetic Algorithms Creativity is one of the least understood aspects of intelligence and is often seen as `intuitive' and not susceptible to rational enquiry. Recently, however, there has been a resurgence of interest in the area, principally in artificial intelligence and cognitive science, but also in psychology, philosophy, computer science, logic, mathematics, sociology, and architecture and design. This volume brings this work together and provides an overview of this rapidly developing field. It addresses a range of issues. Can computers be creative? Can they help us to understand human creativity? How can artificial intelligence (AI) enhance human creativity? How, in particular, can it contribute to the `sciences of the artificial', such as design? Does the new wave of AI (connectionism, geneticism and artificial life) offer more promise in these areas than classical, symbol-handling AI? What would the implications be for AI and cognitive science if computers could not be creative? These issues are explored in five interrelated parts, each of which is introducted and explained by a leading figure in the field. Prologue (Margaret Boden) Part I: Foundational Issues (Terry Dartnall) Part II: Creativity and Cognition (Graeme S. Halford and Robert Levinson) Part III: Creativity and Connectionism (Chris Thornton) Part IV: Creativity and Design (John Gero) Part V: Human Creativity Enhancement (Ernest Edmonds) Epilogue (Douglas Hofstadter) For researchers in AI, cognitive science, computer science, philosophy, psychology, mathematics, logic, sociology, and architecture and design; and anyone interested in the rapidly growing field of artificial intelligence and creativity.From the contents: Neural networks – theory and applications: NNs (= neural networks) classifier on continuous data domains– quantum associative memory – a new class of neuron-like discrete filters to image processing – modular NNs for improving generalisation properties – presynaptic inhibition modelling for image processing application – NN recognition system for a curvature primal sketch – NN based nonlinear temporalspatial noise rejection system – relaxation rate for improving Hopfield network – Oja's NN and influence of the learning gain on its dynamics Genetic algorithms – theory and applications: transposition: a biological-inspired mechanism to use with GAs (= genetic algorithms) – GA for decision tree induction – optimising decision classifications using GAs – scheduling tasks with intertask communication onto multiprocessors by GAs – design of robust networks with GA – effect of degenerate coding on GAs – multiple traffic signal control using a GA – evolving musical harmonisation – niched-penalty approach for constraint handling in GAs – GA with dynamic population size – GA with dynamic niche clustering for multimodal function optimisation Soft computing and uncertainty: self-adaptation of evolutionary constructed decision trees by information spreading – evolutionary programming of near optimal NNsArtificial neural networks and genetic algorithms both are areas of research","",""
1,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Predicting the Robustness of Undirected Network Controllability",2020,"","","","",42,"2022-07-13 09:26:17","","10.23919/CCC50068.2020.9189097","","",,,,,1,0.50,0,5,2,"Robustness of the network controllability reflects how well a networked system can maintain its controllability against destructive attacks. The measure of the network controllability robustness is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the controllability robustness is determined by attack simulations, which is computationally time consuming. In this paper, an improved method for predicting the controllability robustness of undirected networks is developed based on machine learning using a convolutional neural network. This approach is motivated by the following observations: 1) there is no clear correlation between the topological features and the controllability robustness of a general undirected network, 2) the adjacency matrix of a network can be represented as a gray-scale image, 3) the convolutional neural network technique has proved successful in image processing without human intervention. In the new framework, preprocessing and filtering are embedded, and a sufficiently large number of training datasets generated by simulations are used to train several convolutional neural networks for classification and prediction, respectively. Extensive experimental studies were carried out, which demonstrate that the proposed framework for predicting the controllability robustness of undirected networks is more accurate and reliable than the conventional single convolutional neural network predictor.","",""
0,"Timothy R. Newhouse, Pengpeng Zhang, Jungmin Eun, Masha Elkin, Yizhou Zhao, Rachel Cantrell","A Neural Network Model Informs Total Synthesis of Clovane Sesquiterpenoids",2021,"","","","",43,"2022-07-13 09:26:17","","10.33774/chemrxiv-2021-41d5z","","",,,,,0,0.00,0,6,1,"Efficient syntheses of complex small molecules often involve speculative experimental approaches. The central challenge of such plans is that experimental evaluation of high-risk strategies is resource intensive, as it entails iterative attempts at unsuccessful strategies. Herein, we report a complementary strategy that combines creative human-generated synthetic plans with robust computational prediction of the feasibility of key steps in the proposed synthesis. A neural network model was developed to predict the outcome of a generally disfavored transformation, the 6-endo-trig radical cyclization, and applied to synthetic planning of clovan-2,9-dione, resulting in a 5-step total synthesis that improves on a prior 15-step approach. This work establishes how machine learning can guide multistep syntheses that employ innovative and high-risk human-generated plans.","",""
0,"Sang-kyu Bahn, Bo-Yeong Kang, Chany Lee","A computational study on the optimization of transcranial temporal interfering stimulation with high-definition electrode using unsupervised neural network",2021,"","","","",44,"2022-07-13 09:26:17","","10.1101/2021.11.14.467844","","",,,,,0,0.00,0,3,1,"Transcranial temporal interfering stimulation (tTIS) can focally stimulate deep parts of the brain, which are related to specific functions, by using beats at two high AC frequencies that do not affect the human brain. However, it has limitations in terms of calculation time and precision for optimization because of its complexity and non-linearity. We aimed to propose a method using an unsupervised neural network (USNN) for tTIS to optimize quickly the interfering current value of high-definition electrodes, which can finely stimulate the deep part of the brain, and analyze the performance and characteristics of tTIS. A computational study was conducted using 16 realistic head models. This method generated the strongest stimulation on the target, even when targeting deep areas or multi-target stimulation. The tTIS was robust with target depth compared with transcranial alternating current stimulation, and mis-stimulation could be reduced compared with the case of using two-pair inferential stimulation. Optimization of a target could be performed in 3 min. By proposing the USNN for tTIS, we showed that the electrode currents of tTIS can be optimized quickly and accurately, and the possibility of stimulating the deep part of the brain precisely with transcranial electrical stimulation was confirmed.","",""
0,"Qin Cheng, Ziliang Ren, Jun Cheng, Qieshi Zhang, Hao Yan, Jianming Liu","Skeleton-based Action Recognition with Multi-scale Spatial-temporal Convolutional Neural Network",2021,"","","","",45,"2022-07-13 09:26:17","","10.1109/RCAR52367.2021.9517665","","",,,,,0,0.00,0,6,1,"The skeleton data convey significant information for human action recognition since they can robustly accommodate cluttered background and illumination variation. Early convolutional neural networks (CNN) based method mainly structure the skeleton sequence into pseudo-image and feed it into image classification neural network such as Resnet, which can not capture comprehensive spatial-temporal feature. Recently, graph convolutional networks (GCNs) have obtained superior performance. However, the computational complexity of GCN-based methods is quite high, some works even reach 100 GFLOPs for one action sample. This is contrary to the highly condensed attributes of skeleton data. In this paper, a Multi-scale Spatial-temporal Convolution Neural Network (MSST-Net) is proposed for skeleton-based action recognition. Our MSST-Net abandons complex graph convolutions and takes the implicit complementary advantages across different scales of spatial-temporal representations, which are often ignored in the previous work. On two datasets for action recognition, MSST-Net achieves impressive recognition accuracy with a small amount of calculation.","",""
0,"Apostol T. Vassilev, Munawar Hasan, Honglan Jin","Can You Tell? SSNet - A Biologically-Inspired Neural Network Framework for Sentiment Classifiers",2020,"","","","",46,"2022-07-13 09:26:17","","10.1007/978-3-030-95467-3_27","","",,,,,0,0.00,0,3,2,"","",""
0,"Calvin Chi","HLA Allele Imputation with Multitask Deep Convolutional Neural Network",2021,"","","","",47,"2022-07-13 09:26:17","","10.1101/2021.06.03.447012","","",,,,,0,0.00,0,1,1,"Motivation The Human leukgocyte antigen (HLA) system is a highly polymorphic gene complex encoding the major histocompatibility complex proteins in humans. HLA alleles are of strong epidemiological interest for their large effect sizes in associations with autoimmune diseases, infectious diseases, severe drug reactions, and transplant medicine. Since HLA genotyping can be time-consuming and cost-prohibitive, methods to impute HLA alleles from SNP genotype data have been developed, including HLA Genotype Imputation with Attribute Bagging (HIBAG), HLA*IMP:02, and SNP2HLA. However, limitations of these imputation programs include imputation accuracy, computational runtime, and ability to impute HLA allele haplotypes. Results We present a deep learning framework for HLA allele imputation using a multitask convolutional neural network (CNN) architecture. In this approach, we use phased SNP genotype data flanking ±250 kb from each HLA locus to simultaneously impute HLA allele haplotyes across loci HLA-A, -B, -C, -DQA1, -DQB1, -DPA1, -DPB1, and -DRB1. We start by tokenizing phased genotype sequences into k-mers that serve as input to the model. The CNN architecture starts with a shared embedding layer for learning low-dimensional representations of k-mers, shared convolutional layers for detecting genotype motifs, and branches off into separate densely-connected layers for imputing each HLA loci. We present evidence that the CNN used information from known tag SNPs to impute HLA alleles, and demonstrate the architecture is robust against a selection of hyperparameters. On the T1DGC dataset, our model achieved 97.6% imputation accuracy, which was superior to SNP2HLA’s performance and comparable to HIBAG’s performance. However, unlike HIBAG, our method can impute an entire HLA haplotype sequence instead of imputing one locus at a time. Additionally, by separating the training and inference steps, our imputation program provides user flexibility to reduce usage time. Availability The source code is available at https://github.com/CalvinTChi/HLA_imputation Contact calvin.chi@berkeley.edu","",""
1,"A. Tellaeche, Ignacio Fidalgo Astorquia, Juan Ignacio Vázquez Gómez, S. Saikia","Gesture-Based Human Machine Interaction Using RCNNs in Limited Computation Power Devices",2021,"","","","",48,"2022-07-13 09:26:17","","10.3390/s21248202","","",,,,,1,1.00,0,4,1,"The use of gestures is one of the main forms of human machine interaction (HMI) in many fields, from advanced robotics industrial setups, to multimedia devices at home. Almost every gesture detection system uses computer vision as the fundamental technology, with the already well-known problems of image processing: changes in lighting conditions, partial occlusions, variations in color, among others. To solve all these potential issues, deep learning techniques have been proven to be very effective. This research proposes a hand gesture recognition system based on convolutional neural networks and color images that is robust against environmental variations, has a real time performance in embedded systems, and solves the principal problems presented in the previous paragraph. A new CNN network has been specifically designed with a small architecture in terms of number of layers and total number of neurons to be used in computationally limited devices. The obtained results achieve a percentage of success of 96.92% on average, a better score than those obtained by previous algorithms discussed in the state of the art.","",""
0,"I. T. Toudjeu, J. Tapamo","A 2D Convolutional Neural Network Approach for Human Action Recognition",2019,"","","","",49,"2022-07-13 09:26:17","","10.1109/AFRICON46755.2019.9133840","","",,,,,0,0.00,0,2,3,"Nowadays, deep neural networks are widely used for human action recognition (HAR) due to their ability to operate directly on the raw video inputs by extracting both the spatial and temporal information. Although the 3D convolutional neural networks as deep models have achieved superior performance, they remain computational expensive. In this paper we propose a 2D-CNN approach that learns robust feature representation from temporal information embedded into the motion history images of action videos. The proposed approach is simple and reduces the computational complexity imposed by the 3D-CNN approaches. The KTH database is used to validate our approach and the achieved results are compared favorably against the handcrafted state-of-the-art methods.","",""
7,"Eric Minor, Stian D. Howard, Adam A S Green, M. Glaser, C. Park, N. Clark","End-to-end machine learning for experimental physics: using simulated data to train a neural network for object detection in video microscopy.",2019,"","","","",50,"2022-07-13 09:26:17","","10.1039/c9sm01979k","","",,,,,7,2.33,1,6,3,"We demonstrate a method for training a convolutional neural network with simulated images for usage on real-world experimental data. Modern machine learning methods require large, robust training data sets to generate accurate predictions. Generating these large training sets requires a significant up-front time investment that is often impractical for small-scale applications. Here we demonstrate a 'full-stack' computational solution, where the training data set is generated on-the-fly using a noise injection process to produce simulated data characteristic of the experimental system. We demonstrate the power of this full-stack approach by applying it to the study of topological defect annihilation in systems of liquid crystal freely-suspended films. This specific experimental system requires accurate observations of both the spatial distribution of the defects and the total number of defects, making it an ideal system for testing the robustness of the trained network. The fully trained network was found to be comparable in accuracy to human hand-annotation, with four-orders of magnitude improvement in time efficiency.","",""
1,"Mohammad Mehdi Yadollahi, Farzaneh Shoeleh, S. Dadkhah, A. Ghorbani","Robust Black-box Watermarking for Deep Neural Network using Inverse Document Frequency",2021,"","","","",51,"2022-07-13 09:26:17","","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00100","","",,,,,1,1.00,0,4,1,"Recently, Deep Neural Networks (DNNs), presented exceptional achievement in implementing human-level capabilities for various predicaments, such as Natural Language Processing (NLP), voice recognition, and image processing, etc. Training these models is expensive in terms of computational power and the existence of enough labelled data. Thus, ML-based models such as DNNs establish genuine business value and intellectual property (IP) for their owners. Therefore the trained models need to be protected from any adversary attacks such as illegal redistribution, reproducing, and derivation. Watermarking can be considered as an effective technique for securing a DNN model. However, so far, most of the watermarking algorithms focus on watermarking the DNN by adding noise to an image. To this end, we propose a framework for watermarking a DNN model designed for textual domain. The watermark generation scheme provides a secure watermarking method by combining Term Frequency (TF) and Inverse Document Frequency (IDF) of a particular word. The proposed embedding procedure takes place in the model's training stage, which makes the watermark verification stage straightforward by sending the watermarked document to the trained model. The experimental results show that watermarked models have the same accuracy as the original one, and the proposed framework accurately verifies the ownership of all surrogate models without impairing the performance. The proposed algorithm is robust against well-known attacks such as parameter pruning and brute force attack.","",""
0,"Pedro Vinícius A. B. De Venâncio, T. M. Rezende, A. C. Lisboa, A. V. Barbosa","Fire Detection based on a Two-Dimensional Convolutional Neural Network and Temporal Analysis",2021,"","","","",52,"2022-07-13 09:26:17","","10.1109/LA-CCI48322.2021.9769824","","",,,,,0,0.00,0,4,1,"In the last few years there has been a substantial increase in the success of deep learning, especially with regard to convolutional neural networks for computer vision tasks. These architectures are being widely used in emergency situations, where a fast and accurate response is needed. In environmental monitoring, several works have focused on fire detection, since fires have been increasingly associated with negative consequences such as respiratory diseases, economical losses and the destruction of natural resources. The automatic detection of smoke and fire, however, poses a particularly difficult challenge to computer vision systems, since the variability in the shape, color and texture of these objects makes the process of learning how to detect them much more complicated than for other ordinary objects. As a consequence, the number of false positives may grow high, which is especially problematic for a real-time application that mobilizes human efforts to fight fire. This work presents a robust fire detection tool based on a 2D deep convolutional network capable of suppressing false alarms from clouds, fogs, car lights and other objects that are easily confused with fire and smoke. Our approach integrates an object detector with an object tracker; this makes it possible to analyze the temporal behavior of the object and use that information in the decision process. We also present D-Fire, a public and labeled dataset containing more than 21,000 images, which is used to train and test the proposed system. The experimental results show that the detector reached an mAP@0.50 = 75.91% and that the incorporation of the temporal context resulted in a 60% reduction in the false positive rate at the cost of a 2.86% reduction in true positive rate. In addition, the computational cost added by the proposed approach to the fire detector is negligible, so that real-time detection is still completely feasible.","",""
0,"Takuya Sakuma, Hiroki Matsutani","An Area-Efficient Recurrent Neural Network Core for Unsupervised Time-Series Anomaly Detection",2021,"","","","",53,"2022-07-13 09:26:17","","10.1587/transele.2020lhp0003","","",,,,,0,0.00,0,2,1,"Since most sensor data depend on each other, time-series anomaly detection is one of practical applications of IoT devices. Such tasks are handled by Recurrent Neural Networks (RNNs) with a feedback structure, such as Long Short Term Memory. However, their learning phase based on Stochastic Gradient Descent (SGD) is computationally expensive for such edge devices. This issue is addressed by executing their learning on high-performance server machines, but it introduces a communication overhead and additional power consumption. On the other hand, Recursive Least-Squares Echo State Network (RLS-ESN) is a simple RNN that can be trained at low cost using the least-squares method rather than SGD. In this paper, we propose its area-efficient hardware implementation for edge devices and adapt it to human activity anomaly detection as an example of interdependent time-series sensor data. The model is implemented in Verilog HDL, synthesized with a 45 nm process technology, and evaluated in terms of the anomaly capability, hardware amount, and performance. The evaluation results demonstrate that the RLS-ESN core with a feedback structure is more robust to hyper parameters than an existing Online Sequential Extreme Learning Machine (OS-ELM) core. It consumes only 1.25 times larger hardware amount and 1.11 times longer latency than the existing OS-ELM core. key words: on-device learning, machine learning, anomaly detection","",""
15,"F. Ma, Jingyao Zhang, Wei Liang, Jingyu Xue","Automated Classification of Atrial Fibrillation Using Artificial Neural Network for Wearable Devices",2020,"","","","",54,"2022-07-13 09:26:17","","10.1155/2020/9159158","","",,,,,15,7.50,4,4,2,"Atrial fibrillation (AF), as one of the most common arrhythmia diseases in clinic, is a malignant threat to human health. However, AF is difficult to monitor in real time due to its intermittent nature. Wearable electrocardiogram (ECG) monitoring equipment has flourished in the context of telemedicine due to its real-time monitoring and simple operation in recent years, providing new ideas and methods for the detection of AF. In this paper, we propose a low computational cost classification model for robust detection of AF episodes in ECG signals, using RR intervals of the ECG signals and feeding them into artificial neural network (ANN) for classification, to compensate the defect of the computational complexity in traditional wearable ECG monitoring devices. In addition, we compared our proposed classifier with other popular classifiers. The model was trained and tested on the AF Termination Challenge Database and MIT-BIH Arrhythmia Database. Experimental results achieve the highest sensitivity of 99.3%, specificity of 97.4%, and accuracy of 98.3%, outperforming most of the others in the recent literature. Accordingly, we observe that ANN using RR intervals as an input feature can be a suitable candidate for automatic classification of AF.","",""
0,"Yasmine Benchaib","IMPROVED ARTIFICIAL NEURAL NETWORK FOR EPILEPTIC SEIZURES DETECTION",2021,"","","","",55,"2022-07-13 09:26:17","","10.1142/s0219519421500457","","",,,,,0,0.00,0,1,1,"Electroencephalogram (EEG) is a fundamental and unique tool for exploring human brain activity in general and epileptic mechanism in particular. It offers significant information about epileptic seizures source known as epileptogenic area. However, it is often complicated to detect critical changes in EEG signals by visual examination, since this signal aspect of epileptic persons seems to be normal out of the seizure. Thus, the challenge is to design such a robust and automatic system to detect these unseen changes and use them for diagnosis. In this research, we apply the Artificial Metaplasticity Multi-Layer Perceptron (AMMLP) together with discrete wavelet transform (DWT) to Bonn EEG signals for seizure detection goal. Significant features were then extracted from the well-known EEG brainwaves. Aiming to decrease the computational time and improve classification accuracy, we performed a features ranking and selection employing the Relief algorithm. The obtained AMMLP classification accuracy of 98.97% proved the effctiveness of the applied approach. Our results were compared to recent researches results on the same database, proving to be superior or at least an interesting alternative for seizures detection within EEG signals.","",""
14,"L. Ngo, J. Cha, Jae‐Ho Han","Deep Neural Network Regression for Automated Retinal Layer Segmentation in Optical Coherence Tomography Images",2020,"","","","",56,"2022-07-13 09:26:17","","10.1109/TIP.2019.2931461","","",,,,,14,7.00,5,3,2,"Segmenting the retinal layers in optical coherence tomography (OCT) images helps to quantify the layer information in early diagnosis of retinal diseases, which are the main cause of permanent blindness. Thus, the segmentation process plays a critical role in preventing vision impairment. However, because there is a lack of practical automated techniques, expert ophthalmologists still have to manually segment the retinal layers. In this paper, we propose an automated segmentation method for OCT images based on a feature-learning regression network without human bias. The proposed deep neural network regression takes the intensity, gradient, and adaptive normalized intensity score (ANIS) of an image segment as features for learning, and then predicts the corresponding retinal boundary pixel. Reformulating the segmentation as a regression problem obviates the need for a huge dataset and reduces the complexity significantly, as shown in the analysis of computational complexity given here. In addition, assisted by ANIS, the method operates robustly on OCT images containing intensity variances, low-contrast regions, speckle noise, and blood vessels, yet remains accurate and time-efficient. In the evaluation of the method conducted using 114 images, the processing time was approximately 10.596 s per image for identifying eight boundaries, and the training phase for each boundary line took only 30 s. Further, the Dice similarity coefficient used for assessing accuracy gave a computed value of approximately 0.966. The absolute pixel distance of manual and automatic segmentation using the proposed scheme was 0.612, which is less than a one-pixel difference, on average.","",""
9,"Xiang Zhai, Kui Liu, W. Nash, D. Castineira","Smart Autopilot Drone System for Surface Surveillance and Anomaly Detection via Customizable Deep Neural Network",2020,"","","","",57,"2022-07-13 09:26:17","","10.2523/iptc-20111-ms","","",,,,,9,4.50,2,4,2,"  Copter-based unmanned aerial vehicle (drone) systems are being utilized for surveillance, inspection and security purposes for well sites, gathering centers, pipelines, refineries, and other surface facilities. However, most of the practices largely rely on humans, including drone operation, data transfer, image analysis, etc. In this paper, we present a comprehensive, cloud-enabled, human-free autopilot drone system and its application in field surveillance and anomaly detection powered by customizable deep neural network and computer vision models.  The proposed system consists of customized quadcopter drones equipped with high-definition cameras, thermal imaging and gas sensing devices, autopiloted by cloud-connected onboard computers. A series of advanced algorithms are developed and deployed onboard and over the Cloud for processing and diagnosing the image/thermal/gas sensing data collected by the drones in real-time or near real-time, including accurate 2D geospatial aerial mapping, anomaly detection and classification for events like oil leak, gas leak, facility failure, human activities, etc. Object detection deep learning models are customized and parallelized for low-profile multi-core single board computers.  In our case study, a pre-configured drone flew along the same path twice at a 6-month gap. A robust, iterative image registering algorithm is developed to precisely align and overlay images taken at different days at the same or similar GPS locations, even with significant changes to the environment due to season shift, human activities, camera angles or height variations. Local changes are filtered and selected based on their sizes and magnitudes in the residual images by subtracting pairs of perfectly overlaid scenes. Pre-trained Residual Convolutional Neural network (He et al. 2015) is rapidly re-trained to further classify the type of changes using the techniques of transfer learning and data augmentation. An ROC of 99% was achieved in the multi-task binary classification, wherein the detected changes are divided into positive anomalies (such as oil/gas leak, facility failures, unauthored human activities) and negative (natural/insignificant) signals. Comparing against a support vector machine baseline with a ROC=92%, the ResNet model demonstrates significant, more promising detection accuracy at a faster training time.  This innovative integrated platform is presented that combines physical drone, onboard imaging/sensing devices, cloud connectivity, onboard and back-end control system, deep learning and computer vision architecture for situational awareness of oil & gas fields and the mining industry. It achieves full automation of mass surveillance, data acquisition and storage, diagnostics and asset situational understanding. The system architecture, especially the onboard and cloud computation engines, can be readily transferred and applied to other common drone platforms.","",""
7,"Kudakwashe Zvarevashe, O. Olugbara","Recognition of speech emotion using custom 2D-convolution neural network deep learning algorithm",2020,"","","","",58,"2022-07-13 09:26:17","","10.3233/IDA-194747","","",,,,,7,3.50,4,2,2,"Speech emotion recognition has become the heart of most human computer interaction applications in the modern world. The growing need to develop emotionally intelligent devices has opened up a lot of research opportunities. Most researchers in this field have applied the use of handcrafted features and machine learning techniques in recognising speech emotion. However, these techniques require extra processing steps and handcrafted features are usually not robust. They are computationally intensive because the curse of dimensionality results in low discriminating power. Research has shown that deep learning algorithms are effective for extracting robust and salient features in dataset. In this study, we have developed a custom 2D-convolution neural network that performs both feature extraction and classification of vocal utterances. The neural network has been evaluated against deep multilayer perceptron neural network and deep radial basis function neural network using the Berlin database of emotional speech, Ryerson audio-visual emotional speech database and Surrey audio-visual expressed emotion corpus. The described deep learning algorithm achieves the highest precision, recall and F1-scores when compared to other existing algorithms. It is observed that there may be need to develop customized solutions for different language settings depending on the area of applications.","",""
7,"Hossein Mehnatkesh, A. Alasty, M. Boroushaki, M. Khodsiani, M. Hasheminasab, M. Kermani","Estimation of Water Coverage Ratio in Low Temperature PEM-Fuel Cell Using Deep Neural Network",2020,"","","","",59,"2022-07-13 09:26:17","","10.1109/JSEN.2020.2993181","","",,,,,7,3.50,1,6,2,"Proton exchange membrane fuel cell (PEMFC) is a rich source of renewable energy. A non-destructive prediction method is needed to determine the content of water in the PEMFC. In the gas channel of a transparent PEMFC, water is detected with image processing. This method has a high computational cost and is sensitive to the initial position of the camera and ambient lighting. In this paper, the deep neural network (DNN) has been trained to learn the transparent PEMFC’s labeled images as a way to determine the content of water, limit human interference and employed in a real-time process. This DNN model is a virtual sensor for measuring the water coverage ratio. To produce the label of images, all data are divided into 6 classes based on the percentage of water coverage ratio. Through analyzing the number of each class, the imbalance data is unfolded. To overcome this problem, random oversampling and undersampling techniques are used. The images and the classes are considered as the input and output of the DNN, respectively. Also, the region of water accumulation in the gas channel can be recognized with robustness to the environmental conditions. Final results of 4-41-64-120-99-6 nodes for DNN layers were derived due to GA optimization. Accuracy of 96.77% and 94.23% in train and test data have been achieved. This DNN, processes the images up to 10 times faster than image processing. Also, the region of water accumulation in the gas channel can be recognized.","",""
22,"Haihua Liu, Na Shu, Q. Tang, Wensheng Zhang","Computational Model Based on Neural Network of Visual Cortex for Human Action Recognition",2018,"","","","",60,"2022-07-13 09:26:17","","10.1109/TNNLS.2017.2669522","","",,,,,22,5.50,6,4,4,"In this paper, we propose a bioinspired model for human action recognition through modeling neural mechanisms of information processing in two visual cortical areas: the primary visual cortex (V1) and the middle temporal cortex (MT) dedicated to motion. This model, named V1-MT, is composed of V1 and MT models (layers) corresponding to their cortical areas, which are built with layered spiking neural networks (SNNs). Some neuron properties in V1 and MT, such as direction and speed selectivity, spatiotemporal inseparability, and center surround suppression, are integrated into SNNs. Based on speed and direction selectivity, V1 and MT models contain multiple SNN channels, each of which processes motion information in sequences with spatiotemporal tunings of neurons at a certain speed and different directions. Therefore, we propose two operations, input signal perceiving with 3-D Gabor filters and surround inhibition processing with 3-D differences of Gaussian functions, to perform this task according to the spatiotemporal inseparability and center surround suppression of neurons. Then, neurons are modeled with our simplified integrate-and-fire model and motion information is transformed into spike trains. Afterward, we define a new feature vector: a mean motion map computed from spike trains in all channels to represent human actions. Finally, a support vector machine is trained to classify actions represented by the feature vectors. We conducted extensive experiments on public action databases, and the results show that our model outperforms other bioinspired models and rivals the state-of-the-art approaches.","",""
0,"Apostol T. Vassilev, Munawar Hasan","Can you tell? SSNet - a Sagittal Stratum-inspired Neural Network Framework for Sentiment Analysis",2020,"","","","",61,"2022-07-13 09:26:17","","10.2139/ssrn.3641938","","",,,,,0,0.00,0,2,2,"When people try to understand nuanced language they typically process multiple input sensor modalities to complete this cognitive task. It turns out the human brain has even a specialized neuron formation, called sagittal stratum, to help us understand sarcasm. We use this biological formation as the inspiration for designing a neural network architecture that combines predictions of different models on the same text to construct a robust, accurate and computationally efficient classifier for sentiment analysis. Experimental results on representative benchmark datasets and comparisons to other methods1show the advantages of the new network architecture.","",""
2,"Jagadeesh Basavaiah, C. Patil","HUMAN ACTIVITY DETECTION AND ACTION RECOGNITION IN VIDEOS USING CONVOLUTIONAL NEURAL NETWORKS",2020,"","","","",62,"2022-07-13 09:26:17","","10.32890/JICT2020.19.2.1","","",,,,,2,1.00,1,2,2,"Human activity recognition from video scenes has become a significant area of research in the field of computer vision applications. Action recognition is one of the most challenging problems in the area of video analysis and it finds applications in human-computer interaction, anomalous activity detection, crowd monitoring and patient monitoring. Several approaches have been presented for human activity recognition using machine learning techniques. The main aim of this work is to detect and track human activity, and classify actions for two publicly available video databases. In this work, a novel approach of feature extraction from video sequence by combining Scale Invariant Feature Transform and optical flow computation are used where shape, gradient and orientation features are also incorporated for robust feature formulation. Tracking of human activity in the video is implemented using the Gaussian Mixture Model. Convolutional Neural Network based classification approach is used for database training and testing purposes. The activity recognition performance is evaluated for two public datasets namely Weizmann dataset and Kungliga Tekniska Hogskolan dataset with action recognition accuracy of 98.43% and 94.96%, respectively. Experimental and comparative studies have shown that the proposed approach outperformed state-of the art techniques.","",""
12,"T. D’orazio, G. Attolico, G. Cicirelli, C. Guaragnella","A Neural Network Approach for Human Gesture Recognition with a Kinect Sensor",2014,"","","","",63,"2022-07-13 09:26:17","","10.5220/0004919307410746","","",,,,,12,1.50,3,4,8,"Service robots are expected to be used in many household    in the near future, provided that proper interfaces are developed    for the human robot interaction. Gesture recognition has been    recognized as a natural way for the communication especially for    elder or impaired people. With the developments of new    technologies and the large availability of inexpensive depth    sensors, real time gesture recognition has been faced by using    depth information and avoiding the limitations due to complex    background and lighting situations. In this paper the Kinect    Depth Camera, and the OpenNI framework have been used to obtain    real time tracking of human skeleton. Then, robust and significant    features have been selected to get rid of unrelated features and    decrease the computational costs. These features are fed to a set    of Neural Network Classifiers that recognize ten different    gestures. Several experiments demonstrate that the proposed method    works effectively. Real time tests prove the robustness of    the method for realization of human robot interfaces.","",""
1,"Y. Diao, I. Jelescu","Parameter estimation for WMTI-Watson model of white matter using encoder-decoder recurrent neural network",2022,"","","","",64,"2022-07-13 09:26:17","","10.48550/arXiv.2203.00595","","",,,,,1,1.00,1,2,1,"Biophysical modelling of the diffusion MRI signal provides estimates of specific microstructural tissue properties. Model parameters estimates can be obtained by fitting the model to the measured signal. Although nonlinear optimization such as non-linear least squares (NLLS) is the most widespread method for model estimation, it suffers from local minima, high computational cost and uncertain accuracy. Deep Learning approaches are steadily replacing NL fitting, but come with the limitation that the model needs to be retrained for each acquisition protocol and noise level. The White Matter Tract Integrity (WMTI)Watson model was proposed as an implementation of the Standard Model of diffusion in white matter that estimates model parameters from the diffusion and kurtosis tensors (DKI), thereby overcoming fitting the model signal equation. Here we proposed a deep learning approach based on the encoder-decoder recurrent neural network (RNN) to increase the robustness and accelerate the parameter estimation of WMTI-Watson. We use an embedding approach to render the model insensitive to potential differences in distributions between training data and experimental data. This RNN-based solver thus has the advantage of being highly efficient in computation and more readily translatable to other datasets, irrespective of acquisition protocol and underlying parameter distributions as long as diffusion and kurtosis tensors (or their typical derived scalars) were pre-computed from the data. In this study, we evaluated the performance of NLLS, the RNN-based method and a baseline DL architecture based on multilayer perceptron (MLP) on synthetic and in vivo datasets of rat and human brain. We showed that the proposed RNN-based fitting approach had the advantage of highly reduced computation time over NLLS (from hours to seconds), with similar accuracy and precision but improved robustness, and superior translatability to new datasets over MLP, irrespective of acquisition protocol or species being rat or human.","",""
1,"Joshua Emoto, Y. Hirata","Lightweight Convolutional Neural Network for Image Processing Method for Gaze Estimation and Eye Movement Event Detection",2020,"","","","",65,"2022-07-13 09:26:17","","10.2197/ipsjtbio.13.7","","",,,,,1,0.50,1,2,2,": Advancements in technology have recently made it possible to obtain various types of biometric informa- tion from humans, enabling studies on estimation of human conditions in medicine, automobile safety, marketing, and other areas. These studies have particularly pointed to eye movement as an e ﬀ ective indicator of human conditions, and research on its applications is actively being pursued. The devices now widely used for measuring eye movements are based on the video-oculography (VOG) method, wherein the direction of gaze is estimated by processing eye images obtained through a camera. Applying convolutional neural networks (ConvNet) to the processing of eye images has been shown to enable accurate and robust gaze estimation. Conventional image processing, however, is premised on execution using a personal computer, making it di ﬃ cult to carry out real-time gaze estimation using ConvNet, which involves the use of a large number of parameters, in a small arithmetic unit. Also, detecting eye movement events, such as blinking and saccadic movements, from the inferred gaze direction sequence for particular purposes requires the use of a separate algorithm. We therefore propose a new eye image processing method that batch-processes gaze estimation and event detection from end to end using an independently designed lightweight ConvNet. This paper discusses the structure of the proposed lightweight ConvNet, the methods for learning and evaluation used, and the proposed method’s ability to simultaneously detect gaze direction and event occurrence using a smaller memory and at lower computational complexity than conventional methods.","",""
7,"Mengyuan Gong, Taosheng Liu","Biased Neural Representation of Feature-Based Attention in the Human Frontoparietal Network",2020,"","","","",66,"2022-07-13 09:26:17","","10.1523/JNEUROSCI.0690-20.2020","","",,,,,7,3.50,4,2,2,"Selective attention is a core cognitive function for efficient processing of information. Although it is well known that attention can modulate neural responses in many brain areas, the computational principles underlying attentional modulation remain unclear. Contrary to the prevailing view of a high-dimensional, distributed neural representation, here we show a surprisingly simple, biased neural representation for feature-based attention in a large dataset including five human fMRI studies. Selective attention is a core cognitive function for efficient processing of information. Although it is well known that attention can modulate neural responses in many brain areas, the computational principles underlying attentional modulation remain unclear. Contrary to the prevailing view of a high-dimensional, distributed neural representation, here we show a surprisingly simple, biased neural representation for feature-based attention in a large dataset including five human fMRI studies. We found that when human participants (both sexes) selected one feature from a compound stimulus, voxels in many cortical areas responded consistently higher to one attended feature over the other. This univariate bias was consistent across brain areas within individual subjects. Importantly, this univariate bias showed a progressively stronger magnitude along the cortical hierarchy. In frontoparietal areas, the bias was strongest and contributed largely to pattern-based decoding, whereas early visual areas lacked such a bias. These findings suggest a gradual transition from a more analog to a more abstract representation of attentional priority along the cortical hierarchy. Biased neural responses in high-level areas likely reflect a low-dimensional neural code that can facilitate a robust representation and simple readout of cognitive variables. SIGNIFICANCE STATEMENT It is typically assumed that cognitive variables are represented by distributed population activities. Although this view is rooted in decades of work in the sensory system, it has not been rigorously tested at different levels of cortical hierarchy. Here we show a novel, low-dimensional coding scheme that dominated the representation of feature-based attention in frontoparietal areas. The simplicity of such a biased code may confer a robust representation of cognitive variables, such as attentional selection, working memory, and decision-making.","",""
1,"Jung-Yoon Kim, J. Hwang, E. Park, Hyeon-Uk Nam, Songhee Cheon","Flat-Feet Prediction Based on a Designed Wearable Sensing Shoe and a PCA-Based Deep Neural Network Model",2020,"","","","",67,"2022-07-13 09:26:17","","10.1109/ACCESS.2020.3033826","","",,,,,1,0.50,0,5,2,"Gait is a significant factor that affects human health, and monitoring a person’s gait with sensing devices during daily life can detect abnormal gait events that affect numerous physical health problems. In particular, flat feet can cause changes in alignment conditions of the foot, ankle, leg, pelvis and spine. The primary problem with previous studies of wearable devices for measuring gait have focused on quantitatively monitoring the degree of gait rather than the limited gait ability. The existing method of feeding back the degree of gait or activity does not consider the severity of the subject and is insufficient for qualitative evaluation or training of gait. The significance of this study is development of convenient detecting and long-term tracking tools that can be used by both patients and clinicians for prescreening flat feet and monitoring the progress of flat feet treatment. For wearable devices for flatfoot detection to be most effective, detection systems and algorithms must be accurate, robust, reliable and computationally-efficient. In this paper, we developed an integrated smart wearable gait-monitoring device comprised of three sensors: front force, rear force, and an ankle flex sensor. We propose a new flat feet detection methodology based on a dynamic sensing window and a deep neural network with scaled principal component analysis (PCA). We tested 24 subjects, including both those with healthy gait and flat-feet-affected gait. Our study shows that the proposed sensing devices could be worn comfortably. The proposed deep neural network (DNN) model outperformed the other five classifier algorithms considered, and the area under the curve (AUC) value of the method was 87.1%. This wearable device can thus be easily and simply used both by patients and doctors to monitor the progress of flat feet and prescreen for possible gait problems in daily life.","",""
15,"Ruihao Li, Dongbing Gu, Qiang Liu, Zhiqiang Long, Huosheng Hu","Semantic Scene Mapping with Spatio-temporal Deep Neural Network for Robotic Applications",2018,"","","","",68,"2022-07-13 09:26:17","","10.1007/s12559-017-9526-9","","",,,,,15,3.75,3,5,4,"","",""
0,"Mark Ikechukwu Ogbodo, K. Dang, Abderazek Ben Abdallah","Study of a Multi-modal Neurorobotic Prosthetic Arm Control System based on Recurrent Spiking Neural Network",2022,"","","","",69,"2022-07-13 09:26:17","","10.1051/shsconf/202213903019","","",,,,,0,0.00,0,3,1,"The use of robotic arms in various fields of human endeavor has increased over the years, and with recent advancements in artificial intelligence enabled by deep learning, they are increasingly being employed in medical applications like assistive robots for paralyzed patients with neurological disorders, welfare robots for the elderly, and prosthesis for amputees. However, robot arms tailored towards such applications are resource-constrained. As a result, deep learning with conventional artificial neural network (ANN) which is often run on GPU with high computational complexity and high power consumption cannot be handled by them. Neuromorphic processors, on the other hand, leverage spiking neural network (SNN) which has been shown to be less computationally complex and consume less power, making them suitable for such applications. Also, most robot arms unlike living agents that combine different sensory data to accurately perform a complex task, use uni-modal data which affects their accuracy. Conversely, multi-modal sensory data has been demonstrated to reach high accuracy and can be employed to achieve high accuracy in such robot arms. This paper presents the study of a multi-modal neurorobotic prosthetic arm control system based on recurrent spiking neural network. The robot arm control system uses multi-modal sensory data from visual (camera) and electromyography sensors, together with spike-based data processing on our previously proposed R-NASH neuromorphic processor to achieve robust accurate control of a robot arm with low power. The evaluation result using both uni-modal and multi-modal input data show that the multi-modal input achieves a more robust performance at 87%, compared to the uni-modal.","",""
0,"Xiangyu Fu","GomokuPro: An Implementation of Enhanced Machine Learning Algorithm Utilizing Convolutional Neural Network in Gomoku Strategy and Predictions Model",2022,"","","","",70,"2022-07-13 09:26:17","","10.1109/ICSP54964.2022.9778476","","",,,,,0,0.00,0,1,1,"In this paper, the researcher proposes a machine learning Gomoku model, GomokuPro, which is based on CNN (Convolutional Neural Network) as well as Monte Carlo tree search. The purpose of this research aggregation is to solve the previous problem of artificial intelligence algorithms taking too long to compute in board games. The researchers turned a more multidimensional fractional model into an adaptive model based on a single machine learning strategy previously developed by the researchers and capable of making judgments and predictions based on the following human algorithms. Due to the limitations of the hardware used for testing, the researchers found that the results were not applicable to some specific cases. Although this algorithm significantly reduces the computational effort, it still does not provide robust performance in some cases. The computational effort of convolutional neural networks is also influenced by the type of data. However, most of the time, machine learning models are still able to make master predictions.","",""
0,"U. Cnrs","Neural Network and Wavelet Multiresolution System for Human Being Detection",2017,"","","","",71,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,5,"ABSTRACT Many applications, in robotics, require identification of human being. Using complex methods, based on modelmatching are too computationally expensive and not always justified. We propose a fast and simple method for identification of human being. This method takes profit of the learning capabilities of a neural network. The idea is to train a neural network on some images of persons. In order to reduce the amount of this data (images), we use waveletmultiresolution propriety analysis that allows to bring significant information content of image. This one thus ischaracterised by its approximation at a given resolution. After the training phase, the generalization capabilities of the network allow it to identify no-learned images.We describe here the proposed method, and we present experimental results obtained on a data base of 437 images.Key words: Segmentation - Neural Network -Identification-Image Processing-Wavelet Multiresolution. 1. INTRODUCTION Human is able to localise and identify a human being very quickly, in different situations and with a good reliability.This capability is very robust: this one resists to important image changes due to modification of point of view or lightingconditions, etc....That why, the visual analysis by the humans has fascinated a lot of scientifics like Aristote or Darwin,since centuries. The automatic detection systems are interesting by theory knowledge that they will can bring to us aboutthe visual human system. But they have a lot of practical applications like: perception of autonomous vehicles, controlaccess (banks,..), etc.The connexionist models (neural networks) give a panoply of methods for classification, event detection and signal","",""
1,"Zerui Chen, Yan Huang, Hongyuan Yu, Liang Wang","Learning a Robust Part-Aware Monocular 3D Human Pose Estimator via Neural Architecture Search",2021,"","","","",72,"2022-07-13 09:26:17","","10.1007/s11263-021-01525-0","","",,,,,1,1.00,0,4,1,"","",""
0,"Kian Long Tan, C. Lee, K. Anbananthen, K. Lim","RoBERTa-LSTM: A Hybrid Model for Sentiment Analysis With Transformer and Recurrent Neural Network",2022,"","","","",73,"2022-07-13 09:26:17","","10.1109/access.2022.3152828","","",,,,,0,0.00,0,4,1,"Due to the rapid development of technology, social media has become more and more common in human daily life. Social media is a platform for people to express their feelings, feedback, and opinions. To understand the sentiment context of the text, sentiment analysis plays the role to determine whether the sentiment of the text is positive, negative, neutral or any other personal feeling. Sentiment analysis is prominent from the perspective of business or politics where it highly impacts the strategic decision making. The challenges of sentiment analysis are attributable to the lexical diversity, imbalanced dataset and long-distance dependencies of the texts. In view of this, a data augmentation technique with GloVe word embedding is leveraged to synthesize more lexically diverse samples by similar word vector replacements. The data augmentation also focuses on the oversampling of the minority classes to mitigate the imbalanced dataset problems. Apart from that, the existing sentiment analysis mostly leverages sequence models to encode the long-distance dependencies. Nevertheless, the sequence models require a longer execution time as the processing is done sequentially. On the other hand, the Transformer models require less computation time with parallelized processing. To that end, this paper proposes a hybrid deep learning method that combines the strengths of sequence model and Transformer model while suppressing the limitations of sequence model. Specifically, the proposed model integrates Robustly optimized BERT approach and Long Short-Term Memory for sentiment analysis. The Robustly optimized BERT approach maps the words into a compact meaningful word embedding space while the Long Short-Term Memory model captures the long-distance contextual semantics effectively. The experimental results demonstrate that the proposed hybrid model outshines the state-of-the-art methods by achieving F1-scores of 93%, 91%, and 90% on IMDb dataset, Twitter US Airline Sentiment dataset, and Sentiment140 dataset, respectively.","",""
0,"Jiahui Yu, Hongwei Gao, Qing Gao, Dalin Zhou, Zhaojie Ju","Skeleton-based Human Activity Analysis Using Deep Neural Networks with Adaptive Representation Transformation",2021,"","","","",74,"2022-07-13 09:26:17","","10.1109/ICARM52023.2021.9536067","","",,,,,0,0.00,0,5,1,"Compared with RGB-D-based human action analysis, skeleton-based works reach higher robustness and better performance, which are widely applied in the real world. However, the diversity of action observation perspectives hinders the improvement of recognition accuracy. Most of the existing works solve this problem by increasing the amount of training data, which brings a huge computational cost and cannot improve the robustness of the models. This paper proposes an adaptive model to obtain high-performance representations to improve human action recognition accuracy. First, a skeleton representation transfer scheme is proposed to transform the input skeleton-based body model to the best perspective, in which all parameters can be adaptively learned. This is more robust and cost-effective than hand-crafted features. Next, a re-designed backbone is proposed to train the model with a small computational cost based on the 3D-CNN. In the training process, a data enhancement method is also introduced to enhance robustness. Finally, extensive experimental evaluations are conducted on two benchmarks. The results show that this deep model can effectively and adaptively obtain high-performance skeleton representation and its performance is better than other state-of-the-art methods.","",""
27,"M. Sreenivasa, K. Ayusawa, Yoshihiko Nakamura","Modeling and Identification of a Realistic Spiking Neural Network and Musculoskeletal Model of the Human Arm, and an Application to the Stretch Reflex",2016,"","","","",75,"2022-07-13 09:26:17","","10.1109/TNSRE.2015.2478858","","",,,,,27,4.50,9,3,6,"This study develops a multi-level neuromuscular model consisting of topological pools of spiking motor, sensory and interneurons controlling a bi-muscular model of the human arm. The spiking output of motor neuron pools were used to drive muscle actions and skeletal movement via neuromuscular junctions. Feedback information from muscle spindles were relayed via monosynaptic excitatory and disynaptic inhibitory connections, to simulate spinal afferent pathways. Subject-specific model parameters were identified from human experiments by using inverse dynamics computations and optimization methods. The identified neuromuscular model was used to simulate the biceps stretch reflex and the results were compared to an independent dataset. The proposed model was able to track the recorded data and produce dynamically consistent neural spiking patterns, muscle forces and movement kinematics under varying conditions of external forces and co-contraction levels. This additional layer of detail in neuromuscular models has important relevance to the research communities of rehabilitation and clinical movement analysis by providing a mathematical approach to studying neuromuscular pathology.","",""
11,"Hao Wang, Ruibin Feng, A. Leung, K. Tsang","Lagrange Programming Neural Network Approaches for Robust Time-of-Arrival Localization",2018,"","","","",76,"2022-07-13 09:26:17","","10.1007/s12559-017-9495-z","","",,,,,11,2.75,3,4,4,"","",""
2,"V. Bahrami, A. Kalhor, M. T. Masouleh","Dynamic model estimating and designing controller for the 2-DoF planar robot in interaction with cable-driven robot based on adaptive neural network",2021,"","","","",77,"2022-07-13 09:26:17","","10.3233/JIFS-210180","","",,,,,2,2.00,1,3,1,"This study intends to investigate the dynamic model estimation and the design of an adaptive neural network based controller for a passive planar robot, performing 2-DoF motion pattern which is in interaction with an actuated cable-driven robot. In fact, the main goal of applying this structure is to use a number of light cables to drive serial robot links and track the desired reference model by the robot’s end-effector. The under study system can be used as a rehabilitation setup which is helpful for those with arm disability. In this way, upon applying sliding mode error dynamics, it is necessary to determine a vector that contains the matrices related to the robot dynamics. However, finding these matrices requires the use of computational approaches such as Newton-Euler or Lagrange. In addition, since the purpose of this paper is to express comprehensive methods, so with increasing the number of links and degrees of freedom of the robot, finding the dynamics of the robot becomes more difficult. Therefore, the Adaptive Neural Network (ANN) with specific inputs has been used for estimation unknown matrices of the system and the controller design has been performed based on it. So, the main idea in using an adaptive controller is the fact there is no pre-knowledge for the dynamic modeling of the system since the human arm could have different dynamic properties. Hence, the controller is formed by an ANN and robust term. In this way, the adaptation laws of the parameters are extracted by Lyapunov approach, and as a result, as aforementioned, the asymptotic stability of the whole of the system is guaranteed. Simulation results certify the efficiency of the proposed method. Finally, using the Roots Mean Square Error (RMSE) criteria, it has been revealed that, in the presence of bounded disturbance with different amplitude, adding the robust term to the controller leads to improve the tracking error about 34% and 62%, respectively.","",""
2,"Hanxiao Xu, Da Xu, Naiqian Zhang, Yusen Zhang, Rui Gao","Protein-Protein Interaction Prediction Based on Spectral Radius and General Regression Neural Network.",2021,"","","","",78,"2022-07-13 09:26:17","","10.1021/acs.jproteome.0c00871","","",,,,,2,2.00,0,5,1,"Protein-protein interaction (PPI) not only plays a critical role in cell life activities, but also plays an important role in discovering the mechanism of biological activity, protein function, and disease states. Developing computational methods is of great significance for PPIs prediction since experimental methods are time-consuming and laborious. In this paper, we proposed a PPI prediction algorithm called GRNN-PPI only using the amino acid sequence information based on general regression neural network and two feature extraction methods. Specifically, we designed a new feature extraction method named Mutation Spectral Radius (MSR) to extract evolutionary information by the BLOSUM62 matrix. Meanwhile, we integrated another feature extraction method, autocorrelation description, which can completely extract information on physicochemical properties and protein sequences. The principal component analysis was applied to eliminate noise, and the general regression neural network was adopted as a classifier. The prediction accuracy of the yeast, human, and Helicobacter pylori1 (H. pylori1) data sets were 97.47%, 99.63%, and 99.97%, respectively. In addition, we also conducted experiments on two important PPI networks and six independent data sets. All results were significantly higher than some state-of-the-art methods used for comparison, showing that our method is feasible and robust.","",""
1,"V. Papageorgiou","Brain Tumor Detection Based on Features Extracted and Classified Using a Low-Complexity Neural Network",2021,"","","","",79,"2022-07-13 09:26:17","","10.18280/ts.380302","","",,,,,1,1.00,1,1,1,"Brain tumor detection or brain tumor classification is one of the most challenging problems in modern medicine, where patients suffering from benign or malignant brain tumors are usually characterized by low life expectancy making the necessity of a punctual and accurate diagnosis mandatory. However, even today, this kind of diagnosis is based on manual classification of magnetic resonance imaging (MRI), culminating in inaccurate conclusions especially when they derive from inexperienced doctors. Hence, trusted, automatic classification schemes are essential for the reduction of humans’ death rate due to this major chronic disease. In this article, we propose an automatic classification tool, using a computationally economic convolutional neural network (CNN), for the purposes of a binary problem concerning MRI images depicting the existence or the absence of brain tumors. The proposed model is based on a dataset containing real MRI images of both classes with nearly perfect validation-testing accuracy and low computational complexity, resulting a very fast and reliable training-validation process. During our analysis we compare the diagnostic capacity of three alternative loss functions, validating the appropriateness of cross entropy function, while underlining the capability of an alternative loss function named Jensen-Shannon divergence since our model accomplished nearly excellent testing accuracy, as with cross-entropy. The multiple validation tests applied, enhancing the robustness of the produced results, render this low-complexity CNN structure as an ideal and trustworthy medical aid for the classification of small datasets.","",""
0,"B. Mukunthan","A NEURAL NETWORK APPROACH FOR THE PRECISE PATTERN RECOGNITION OF HUMAN DNA",2012,"","","","",80,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,10,"The primary goal of bio informatics and neural networks solely is to increase our understanding of biological processes and focus on developing and applying computationally intensive techniques (e.g., pattern recognition, data mining, machine learning algorithms, and visualization) to achieve this goal. The neural networks exhibit characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, parallel and high speed information processing. Neural networks learn by examples they can therefore be trained with known examples of a problem to ‘acquire’ knowledge about it. Once appropriately trained, the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. The perfect blend made of bioinformatics and neural networks results in efficient pattern analysis techniques. The conventional techniques and algorithms employed by forensic scientists to assist in the identification of individuals on the basis of their respective DNA profiles involves more computational steps and mathematical formulas that leads to more time and space complexity resulting in complicated and less efficient algorithms which can be shorted out by emerging Artificial Neural Network approach.","",""
3,"A. Giannakidis, K. Kamnitsas, V. Spadotto, J. Keegan, Gillian Smith, B. Glocker, D. Rueckert, S. Ernst, M. Gatzoulis, D. Pennell, S. Babu-Narayan, D. Firmin","Fast Fully Automatic Segmentation of the Severely Abnormal Human Right Ventricle from Cardiovascular Magnetic Resonance Images Using a Multi-Scale 3D Convolutional Neural Network",2016,"","","","",81,"2022-07-13 09:26:17","","10.1109/SITIS.2016.16","","",,,,,3,0.50,0,12,6,"Cardiac magnetic resonance (CMR) is regarded as the reference examination for cardiac morphology in tetralogy of Fallot (ToF) patients allowing images of high spatial resolution and high contrast. The detailed knowledge of the right ventricular anatomy is critical in ToF management. The segmentation of the right ventricle (RV) in CMR images from ToF patients is a challenging task due to the high shape and image quality variability. In this paper we propose a fully automatic deep learning-based framework to segment the RV from CMR anatomical images of the whole heart. We adopt a 3D multi-scale deep convolutional neural network to identify pixels that belong to the RV. Our robust segmentation framework was tested on 26 ToF patients achieving a Dice similarity coefficient of 0.8281±0.1010 with reference to manual annotations performed by expert cardiologists. The proposed technique is also computationally efficient, which may further facilitate its adoption in the clinical routine.","",""
27,"Matthias Kerzel, Moaaz Ali, Hwei Geok Ng, S. Wermter","Haptic material classification with a multi-channel neural network",2017,"","","","",82,"2022-07-13 09:26:17","","10.1109/IJCNN.2017.7965887","","",,,,,27,5.40,7,4,5,"We present a novel approach for haptic material classification based on an adaptation of human haptic exploratory procedures executed by a robot arm with an optical force sensor. A multi-channel neural architecture informed by findings from human haptic perception performs a spectral analysis on vibration and texture data gathered during material exploration and integrates this analysis with information gathered on material compliance. Experimental results show a high classification accuracy on a test set of 32 common household materials. Furthermore, we show that haptic material properties, relevant for robot grasping, can be classified with a simple haptic exploration while actual material classification requires more complex exploration and computation.","",""
0,"Deep LearningTensorFlow","Deep Convolutional Neural Network Based Approach For",2021,"","","","",83,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,1,"Deep Learning for Data AnalyticsDeep Learning for Chest RadiographsBrain Tumor MRI Image Segmentation Using Deep Learning TechniquesEfficient Processing of Deep Neural NetworksMachine Learning and Deep Learning in Real-Time ApplicationsState of the Art in Neural Networks and Their ApplicationsDatabase Systems for Advanced ApplicationsMedical Image Computing and Computer-Assisted Intervention – MICCAI 2016A Guide to Convolutional Neural Networks for Computer VisionEffect of Enhancement on Convolutional Neural Network Based Multi-view Object ClassificationAdvancing Cardiovascular MRI Acquisition Through Deep Convolutional Neural Network-Based LocalizationModelling and Analysis of Active Biopotential Signals in Healthcare, Volume 2Deep Learning-Based Approaches for Sentiment AnalysisIntroduction to Graph Neural NetworksPractical Convolutional Neural Networks2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2)From Natural to Artificial IntelligenceNeural Networks and Deep LearningMultimodal Behavior Analysis in the WildMultimodal Scene UnderstandingAdvances in Machine Learning/Deep Learning-Based TechnologiesDeep LearningDeep Learning Applications with Practical Measured Results in Electronics IndustriesFundamentals of Brain Network AnalysisComputer Vision ECCV 2014 WorkshopsDeep Learning and Convolutional Neural Networks for Medical Image ComputingDeep Learning and Convolutional Neural Networks for Medical Imaging and Clinical InformaticsAdvanced Applied Deep LearningHands-On Convolutional Neural Networks with TensorflowComputer Vision – ECCV 2016A Convolutional Neural Network-based Approach to Personalized 3D Modeling of the Human Body and Its ClassificationDeep Learning in Computer VisionMulti-faceted Deep LearningDeep Learning in Computer Vision2019 IEEE National Aerospace and Electronics Conference (NAECON)Deep Learning Neural NetworksDeep Convolutional Neural Network Architecture for Effective Image AnalysisHybrid Intelligent SystemsNeural Networks: Tricks of the TradeThoracic Image Analysis This book reviews the state of the art in deep learning approaches to high-performance robust disease detection, robust and accurate organ segmentation in medical image computing (radiological and pathological imaging modalities), and the construction and mining of large-scale radiology databases. It particularly focuses on the application of convolutional neural networks, and on recurrent neural networks like LSTM, using numerous practical examples to complement the theory. The book’s chief features are as follows: It highlights how deep neural networks can be used to address new questions and protocols, and to tackle current challenges in medical image computing; presents a comprehensive review of the latest research and literature; and describes a range of different methods that employ deep learning for object or landmark detection tasks in 2D and 3D medical imaging. In addition, the book examines a broad selection of techniques for semantic segmentation using deep learning principles in medical imaging; introduces a novel approach to text and image deep embedding for a large-scale chest xray image database; and discusses how deep learning relational graphs can be used to organize a sizable collection of radiology findings from real clinical practice, allowing semantic similarity-based retrieval. The intended reader of this edited book is a professional engineer, scientist or a graduate student who is able to comprehend general concepts of image processing, computer vision and medical image analysis. They can apply computer science and mathematical principles into problem solving practices. It may be necessary to have a certain level of familiarity with a number of more advanced subjects: image formation and enhancement, image understanding, visual recognition in medical applications, statistical learning, deep neural networks, structured prediction and image segmentation.The eight-volume set comprising LNCS volumes 9905-9912 constitutes the refereed proceedings of the 14th European Conference on Computer Vision, ECCV 2016, held in Amsterdam, The Netherlands, in October 2016. The 415 revised papers presented were carefully reviewed and selected from 1480 submissions. The papers cover all aspects of computer vision and pattern recognition such as 3D computer vision; computational photography, sensing and display; face and gesture; low-level vision and image processing; motion and tracking; optimization methods; physicsbased vision, photometry and shape-from-X; recognition: detection, categorization, indexing, matching; segmentation, grouping and shape representation; statistical methods and learning; video: events, activities and surveillance; applications. They are organized in topical sections on detection, recognition and retrieval; scene understanding; optimization; image and video processing; learning; action activity and tracking; 3D; and 9 poster sessions.This book collects 14 articles from the Special Issue entitled “Deep Learning Applications with Practical Measured Results in Electronics Industries” of Electronics. Topics covered in this Issue include four main parts: (1) environmental information analyses and predictions, (2) unmanned aerial vehicle (UAV) and object tracking applications, (3) measurement and denoising techniques, and (4) recommendation systems and education systems. These authors used and improved deep learning techniques (e.g., ResNet (deep residual network), Faster-RCNN (faster regions with convolutional neural network), LSTM (long short term memory), ConvLSTM (convolutional LSTM), GAN (generative adversarial network), etc.) to analyze and denoise measured data in a variety of applications and services (e.g., wind speed prediction, air quality prediction, underground mine applications, neural audio caption, etc.). Several practical experiments were conducted, and the results indicate that the performance of the presented deep learning methods is improved compared with the performance of conventional machine learning methods.Deep Learning Neural Networks is the fastest growing field in machine learning. It serves as a powerful computational tool for solving prediction, decision, diagnosis, detection and decision problems based on a well-defined computational architecture. It has been successfully applied to a broad field of applications ranging from computer security, speech recognition, image and video recognition to industrial fault detection, medical diagnostics and finance. This comprehensive textbook is the first in the new emerging field. Numerous case studies are succinctly demonstrated in the text. It is intended for use as a one-semester graduate-level university text and as a textbook for research and development establishments in industry, medicine and financial research.In this thesis, we introduce an integrated method to build personalized full body 3D models of people given frontal and profile silhouette images. Several deep convolutional neural network (CNN) architectures have been designed and trained to accurately estimate the positions of a set of anthropometric set of ordered control points on the frontal and profile silhouette images. For the prediction of key points on the frontal silhouette image, the output from four different convolutional neural networks have been fused together to generate the final coordinates. A global CNN is first designed to predict those control points on all parts of the body. This has been reinforced with local deep CNN architectures focused on the prediction of control points on localized areas of the body to improve on the accuracy of predictions. Fusing the global and local predictions yielded an estimate of the coordinates of 56 control points on the frontal image and 26 control points on the side view image of a person. The controlled points are then regularized to reside on the silhouette of the frontal and profile images using a combination of Canny edge detector and shortest distance mapping. The set of regularized control points are then fed into a model-based 3D reconstruction algorithm [1] to yield the corresponding high-resolution 3D model of the person. A database of 800 models from the Caesar dataset were studied, of which 100 were used to train and the other 700 were used for testing and classification of 3D models. Our method achieves an accuracy of 99.7 % in prediction of control points and 3D reconstruction using those points. We also present a classification scheme to allocate a test surface to one of competing base surfaces. The classification is based on computing the error between salient points with identical anthropometric meaning that reside on a nested set of boundaries in the frontal and profile projection image spaces. The method can have a variety of applications ranging from medical imaging, to 3D modeling for recognition, virtual reality, generation of video games, 3D animation, etc.It is our belief that researchers and practitioners acquire, through experience and word-of-mouth, techniques and heuristics that help them successfully apply neural networks to di cult real world problems. Often these \tricks"" are theotically well motivated. Sometimes they are the result of trial and error. However, their most common link is that they are usually hidden in people’s heads or in the back pages of spaceconstrained conference papers. As a result newcomers to the eld waste much time wondering why their networks train so slowly and perform so poorly. This book is an outgrowth of a 1996 NIPS workshop called Tricks of the Trade whose goal was to begin the process of gathering and documenting these tricks. The interest that the workshop generated motivated us to expand our collection and compile it into this book. Although we have no doubt that there are many tricks we have missed, we hope that what we have included will prove to be useful, particularly to those who are relatively new t","",""
15,"Junfeng Jing, Amei Dong, Pengfei Li, Kaibing Zhang","Yarn-dyed fabric defect classification based on convolutional neural network",2017,"","","","",84,"2022-07-13 09:26:17","","10.1117/1.OE.56.9.093104","","",,,,,15,3.00,4,4,5,"Abstract. Considering that manual inspection of the yarn-dyed fabric can be time consuming and inefficient, we propose a yarn-dyed fabric defect classification method by using a convolutional neural network (CNN) based on a modified AlexNet. CNN shows powerful ability in performing feature extraction and fusion by simulating the learning mechanism of human brain. The local response normalization layers in AlexNet are replaced by the batch normalization layers, which can enhance both the computational efficiency and classification accuracy. In the training process of the network, the characteristics of the defect are extracted step by step and the essential features of the image can be obtained from the fusion of the edge details with several convolution operations. Then the max-pooling layers, the dropout layers, and the fully connected layers are employed in the classification model to reduce the computation cost and extract more precise features of the defective fabric. Finally, the results of the defect classification are predicted by the softmax function. The experimental results show promising performance with an acceptable average classification rate and strong robustness on yarn-dyed fabric defect classification.","",""
3,"Yanxi Li, Zhaohui Yang, Yunhe Wang, Chang Xu","Neural Architecture Dilation for Adversarial Robustness",2021,"","","","",85,"2022-07-13 09:26:17","","","","",,,,,3,3.00,1,4,1,"With the tremendous advances in the architecture and scale of convolutional neural networks (CNNs) over the past few decades, they can easily reach or even exceed the performance of humans in certain tasks. However, a recently discovered shortcoming of CNNs is that they are vulnerable to adversarial attacks. Although the adversarial robustness of CNNs can be improved by adversarial training, there is a trade-off between standard accuracy and adversarial robustness. From the neural architecture perspective, this paper aims to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy. Under a minimal computational overhead, the introduction of a dilation architecture is expected to be friendly with the standard performance of the backbone CNN while pursuing adversarial robustness. Theoretical analyses on the standard and adversarial error bounds naturally motivate the proposed neural architecture dilation algorithm. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and adversarial robustness.","",""
1,"J. Constantin, A. Bigand, I. Constantin","Pooling spike neural network for fast rendering in global illumination",2019,"","","","",86,"2022-07-13 09:26:17","","10.1007/s00521-018-3941-z","","",,,,,1,0.33,0,3,3,"","",""
0,"Jiamin Zhou","Spectrome-AI: a Neural Network Framework for Inferring MEG Spectra",2019,"","","","",87,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,3,"Author(s): Zhou, Jiamin | Advisor(s): Raj, Ashish | Abstract: Computational modeling is a tool that allows for biological systems involving large networks to be studied, such as in studying the correlations between structural connectivity and functional connectivity in the human brain. Raj et al. proposed the spectral graph model in 2019 as a linear, low-dimensional alternative to conventional neural field and mass models that are more computationally expensive, especially when optimizing parameters, which is necessary in order to obtain quantitative and qualitative information about functional neural activity. The initial method used for inferring the spectral graph model parameters was Markov chain Monte Carlo (MCMC) sampling, which provided a robust way to estimate what the target parameter distributions were most likely to be. However, MCMC methods are still slow and computationally expensive. In this study, we trained a fully connected neural network on MCMC-simulated magnetoencephalography (MEG) data to perform parameter estimation for the spectral graph model in an accelerated manner. We found that the neural network was able to predict most parameters of interest without much loss in precision while generating the parameters in less than a second. This approach puts us closer to obtaining real time neurophysiological information from functional neuroimaging data for applications in diagnosis, prognosis, and characterization of various neurological diseases.","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",88,"2022-07-13 09:26:17","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
1,"Muhammad Altaf Hussain, U. Rehman, S. Islam, M. F. Sheikh, Amber Javaid","Detection and Classification of Retinal Red Lesions via Regional Spatial Transformations and Neural Network",2019,"","","","",89,"2022-07-13 09:26:17","","10.1145/3330482.3330486","","",,,,,1,0.33,0,5,3,"The worldwide loss in human vision is primarily associated with Diabetic Retinopathy (DR). It occurs due to accelerated levels of blood sugar thereby causing perforation, bulging and leakage of retinal blood vessels (BVs). DR commences with the emergence of small blood spots on the retinal surface known as Microaneurysms (MAs) that are subsequently transformed into heavy blood deposits called Hemorrhages (HGs). This paper proposes an optimized and computationally inexpensive digital image processing (DIP) technique for detection and classification of 'Retinal Red Lesions' (RRLs) i.e. MAs and HGs using green channel of the digital fundus images. The basic essence of the proposed technique revolves around regional spatial transformations detection performed through region based spatial filtering, matching features and neural networks classification. The proposed technique comprises of five main stages i.e. Pre-processing, Regional Spatial Transformations, Optimization, Features extraction and Classification. Speed Up Robust Features (SURF) algorithm has been used for features selection & extraction while Feed-forward Back-propagation Artificial Neural Network (FFBP ANN) has been used for classification. The proposed technique has been successfully applied on commercially available digital fundus image data-set and has yielded 98.4% 'Sensitivity' (SE), 94% 'Specificity' (SP) and 98% 'Accuracy' (AC). The SE, SP and AC have also been compared with other RRLs detection methods and has shown highly promising and encouraging results.","",""
12,"Junfeng Jing, Amei Dong, Pengfei Li","Yarn-dyed fabric defect classification based on convolutional neural network",2017,"","","","",90,"2022-07-13 09:26:17","","10.1117/12.2281978","","",,,,,12,2.40,4,3,5,"Considering that the manual inspection of the yarn-dyed fabric can be time consuming and less efficient, a convolutional neural network (CNN) solution based on the modified AlexNet structure for the classification of the yarn-dyed fabric defect is proposed. CNN has powerful ability of feature extraction and feature fusion which can simulate the learning mechanism of the human brain. In order to enhance computational efficiency and detection accuracy, the local response normalization (LRN) layers in AlexNet are replaced by the batch normalization (BN) layers. In the process of the network training, through several convolution operations, the characteristics of the image are extracted step by step, and the essential features of the image can be obtained from the edge features. And the max pooling layers, the dropout layers, the fully connected layers are also employed in the classification model to reduce the computation cost and acquire more precise features of fabric defect. Finally, the results of the defect classification are predicted by the softmax function. The experimental results show the capability of defect classification via the modified Alexnet model and indicate its robustness.","",""
29,"C. Corbane, V. Syrris, F. Sabo, P. Politis, M. Melchiorri, M. Pesaresi, P. Soille, T. Kemper","Convolutional Neural Networks for Global Human Settlements Mapping from Sentinel-2 Satellite Imagery",2020,"","","","",91,"2022-07-13 09:26:17","","10.1007/S00521-020-05449-7","","",,,,,29,14.50,4,8,2,"","",""
8,"Lorena Guachi, R. Guachi, F. Bini, F. Marinozzi","Automatic Colorectal Segmentation with Convolutional Neural Network",2018,"","","","",92,"2022-07-13 09:26:17","","10.14733/CADCONFP.2018.312-316","","",,,,,8,2.00,2,4,4,"Introduction: In the recent years, modern medicine uses image processing technique, such as image segmentation in Computer Aided Diagnosis System (CAD) in order to reduce the dependence of diagnosis by doctors’ knowledge and experience, as well as to locate the prior tissue lesions timely and effectively [6]. Medical image segmentation uses several imaging modalities (MRI, Computed Tomography (CT), Positron Emission Tomography (PET), X-RAY, Ultrasound). However, it is a challenge yet, due to added noise, artifacts, limitations, and unclear edges [8]. In this way, colon tissues segmentation in human abdominal CT images is the base of analysis and identification of cancer nidus, providing powerful information in a CAD, such as early polyps detection, which can reduce the incidence of colon cancer [3],[6],[14]. Colon segmentation techniques can also be used in colorectal tissues simulations to make preoperative plans and simulations of surgery [4]. Some colon segmentation algorithms are introduced in literature, each one having its own model, computational complexity, and overall quality. Such as Local region based active contours [6], which is based on local statistics of tissue of interest and background, instead of global statistics. In [15], an isotropic volume reconstructed from the CT images is used to extract a thick region encompassing the entire colon, where mean curvature, dimensionless ratio sphericity and minimum polyp size are used as parameters to filter anomalies and reduce false positives. Classifications of multispectral colorectal cancer tissues [5], classify tissues samples using convolutional neural network (CNN) and uses active contours technique to extract colorectal regions corresponding to pathological tissues. Although some works presented in literature have demonstrated how CNN provides effective results to analyze colon images, those works are based on the segmentation image regions containing pathological colorectal tissues [5],[7], and glandular colon structure [10]. On the contrary, the analysis of colon tissues as pre-processing task for applications, as tissues simulations, is our motivation to challenge the use of pixel-wise segmentation with CNN. In order to overcome the problem of misclassifying colon tissue pixels, in this paper, we propose a method for automatic colon tissues segmentation based on spatial features learned with CNN. The proposed method has been compared to three state-of-the-art methods. Preliminary experimental results demonstrate the proposed method achieves a higher robustness in terms of sensitivity and similarity, and reduces the number of misclassified colon tissue pixels.","",""
2,"Mohammed Alawad, Mingjie Lin","Stochastic-based multi-stage streaming realization of deep convolutional neural network",2017,"","","","",93,"2022-07-13 09:26:17","","10.1109/ISQED.2017.7918285","","",,,,,2,0.40,1,2,5,"Large-scale convolutional neural network (CNN), conceptually mimicking the operational principle of visual perception in human brain, has been widely applied to tackle many challenging computer vision and artificial intelligence applications. Unfortunately, despite of its simple architecture, a typically-sized CNN is well known to be computationally intensive. This work presents a novel stochastic-based and scalable hardware architecture and circuit design that computes a large-scale CNN with FPGA. The key idea is to implement all key components of a deep learning CNN, including multi-dimensional convolution, activation, and pooling layers, completely in the probabilistic computing domain in order to achieve high computing robustness, high performance, and low hardware usage. Most importantly, through both theoretical analysis and FPGA hardware implementation, we demonstrate that stochastic-based deep CNN can achieve superior hardware scalability when compared with its conventional deterministic-based FPGA implementation by allowing a stream computing mode and adopting efficient random sample manipulations. Overall, being highly scalable and energy efficient, our stochastic-based convolutional neural network architecture is well-suited for a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images, especially those perception-based computing tasks that are inherently fault-tolerant, while still requiring high energy efficiency.","",""
0,"Srungeer Simha, J. Goudswaard, P. Devarakota, P. Somawanshi","Neural Network Assisted Seismic Velocity Editing",2019,"","","","",94,"2022-07-13 09:26:17","","10.2118/197919-ms","","",,,,,0,0.00,0,4,3,"  Normal Move-Out (NMO) velocity pick editing is the segregation of good and bad picks from an unsupervised auto-picking algorithm. As not all these picks are correct, manual velocity editing is required. This is time consuming, repetitive and typically requires a seismic expert for days to weeks. Automating it would require an algorithm that mimics the domain knowledge and expertise of a seismic processor; a deterministic approach would therefore likely fail. Alternatively, we propose a machine learning algorithm to identify valid time-velocity picks.  The proposed approach is a supervised classification approach which utilizes human interpreted velocity picks (1-5% of all picks) as training data. The algorithm learns to recognize the features of a valid velocity pick from metadata such as semblance energy, depth, areal location etc. and utilizes said understanding to segregate valid picks from invalid ones (multiples etc.) amongst the remaining velocity picks. The algorithm has been trained using synthetic NMO picks created by finite-difference forward modelling CMP data, including multiples, in the Marmousi model and auto-picking the move-out. The ground-truth NMO picks were created directly from the velocity model.  The trained classification neural network shows a very high > 97% accuracy on segregation of valid and invalid NMO velocity picks based on a 5% input data set. Further reduction of the training data set to 1% of velocity picks reduces test accuracy only by an additional 2 percentage points. Training and execution time of the neural network on a dataset of ~ 40000 velocity picks are also extremely fast (< 5 mins). Initial results on RMO picks also show a very similar performance characteristic.  The metadata for all valid picks spans a multi-dimensional feature space, from which the neural network constructs a non-linear selection criterion. A human can either manually QC each pick or perform attribute-based selection using only lower dimensional linear selection criteria. The robustness and speed of the neural network outperforms the manual editing while also reducing cycle time; the resulting velocity models will be superior, leading to improved signal processing and imaging results further in the processing sequence.  Automating velocity picking and editing has been a research objective for many years now, but only since the availability of modern computation and optimization algorithms can we properly deploy this to augment the high-quality modern velocity picking software and significantly decrease turn-around time by automating the picking and QC process.","",""
0,"Meenal Suryakant Vatsaraj, D. Bade","Anomalous Behavior Detection in Crowded Environments Using Classifiers Artificial Neural Network and Support Vector Machine",2017,"","","","",95,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,2,5,"Our propose method focuses to detect and localize anomalous behavior in videos of crowded area means different scenario from dominant pattern. Proposed method consist motion and appearance information therefore different kinds of anomalies can be robustly identified in a wide range of situations. Histogram of oriented gradients can easily captures varying dynamic of crowded environment. Histogram of oriented gradients can also effectively recognize and characterize each frame of each scene. Our method of detecting anomalies using artificial neural network and support vector machine consist both appearance and motion features which extracts this features within spatio temporal domain of moving pixels that ensures robustness to local noise and thus increases accuracy in detection of local anomaly with low computational cost. UCSD dataset which will be used and which consist various situations with varying human crowds as well as traffic data with occlusions when feed to our propose method can achieve significantly higher accuracy probably more for pixel level events detection as compared to any other methods.","",""
0,"Meenal Suryakant Vatsaraj, D. Bade","Anomalous Behaviour Detection in Crowded Environments Using Classifiers Artificial Neural Network and Support Vector Machine",2017,"","","","",96,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,2,5,"Our proposed method focuses to detect and localize anomalous behavior in videos of the crowded area means different scenario from the dominant pattern. Proposed method consist motion and appearance information, therefore, different kinds of anomalies can be robustly identified in a wide range of situations. Histogram of oriented gradients can easily capture the varying dynamic of the crowded environment. Histogram of oriented gradients can also effectively recognize and characterize each frame of each scene. Our method of detecting anomalies using artificial neural network and support vector machine consist both appearance and motion features which extract this features within the spatiotemporal domain of moving pixels that ensures robustness to local noise and thus increases accuracy in detection of a local anomaly with low computational cost. UCSD dataset which will be used and which consist various situations with varying human crowds as well as traffic data with occlusions when feed to our proposed method can achieve significantly higher accuracy probably more for pixel level events detection as compared to any other methods.","",""
0,"Mohammed Alawad, Mingjie Lin","Stochastic-Based Multi-stage Streaming Realization of a Deep Convolutional Neural Network (Abstract Only)",2017,"","","","",97,"2022-07-13 09:26:17","","10.1145/3020078.3021788","","",,,,,0,0.00,0,2,5,"Large-scale convolutional neural network (CNN), conceptually mimicking the operational principle of visual perception in human brain, has been widely applied to tackle many challenging computer vision and artificial intelligence applications. Unfortunately, despite of its simple architecture, a typically sized CNN is well known to be computationally intensive. This work presents a novel stochastic-based and scalable hardware architecture and circuit design that computes a large-scale CNN with FPGA. The key idea is to implement all key components of a deep learning CNN, including multi-dimensional convolution, activation, and pooling layers, completely in the probabilistic computing domain in order to achieve high computing robustness, high performance, and low hardware usage. Most importantly, through both theoretical analysis and FPGA hardware implementation, we demonstrate that stochastic-based deep CNN can achieve superior hardware scalability when compared with its conventional deterministic-based FPGA implementation by allowing a stream computing mode and adopting efficient random sample manipulations. Overall, being highly scalable and energy efficient, our stochastic-based convolutional neural network architecture is well-suited for a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images, especially those perception-based computing tasks that are inherently fault-tolerant, while still requiring high energy efficiency.","",""
27,"Sheng Zhang, W. Zheng","Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment",2018,"","","","",98,"2022-07-13 09:26:17","","10.1109/TNNLS.2017.2761259","","",,,,,27,6.75,14,2,4,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.","",""
39,"Sitong Wu, Z. Gao, Zhi Liu, Jianwen Luo, Heye Zhang, S. Li","Direct Reconstruction of Ultrasound Elastography Using an End-to-End Deep Neural Network",2018,"","","","",99,"2022-07-13 09:26:17","","10.1007/978-3-030-00928-1_43","","",,,,,39,9.75,7,6,4,"","",""
0,"Lee","Improved Methodology for Evaluating Adversarial Robustness in Deep Neural Networks",2020,"","","","",100,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,2,"Deep neural networks are known to be vulnerable to adversarial perturbations, which are often imperceptible to humans but can alter predictions of machine learning systems. Since the exact value of adversarial robustness is difficult to obtain for complex deep neural networks, accuracy of the models against perturbed examples generated by attack methods is empirically used as a proxy to adversarial robustness. However, failure of attack methods to find adversarial perturbations cannot be equated with being robust. In this work, we identify three common cases that lead to overestimation of accuracy against perturbed examples generated by bounded first-order attack methods: 1) the value of cross-entropy loss numerically becoming zero when using standard floating point representation, resulting in non-useful gradients; 2) innately non-differentiable functions in deep neural networks, such as Rectified Linear Unit (ReLU) activation and MaxPool operation, incurring “gradient masking” [2]; and 3) certain regularization methods used during training inducing the model to be less amenable to first-order approximation. We show that these phenomena exist in a wide range of deep neural networks, and that these phenomena are not limited to specific defense methods they have been previously investigated for. For each case, we propose compensation methods that either address sources of inaccurate gradient computation, such as numerical saturation for near zero values and nondifferentiability, or reduce the total number of back-propagations for iterative attacks by approximating second-order information. These compensation methods can be combined with existing attack methods for a more precise empirical evaluation metric. We illustrate the impact of these three phenomena with examples of practical interest, such as benchmarking model capacity and regularization techniques for robustness. Furthermore, we show that the gap between adversarial accuracy and the guaranteed lower bound of robustness can be partially explained by these phenomena. Overall, our work shows that overestimated adversarial accuracy that is not indicative of robustness is prevalent even for conventionally trained deep neural networks, and highlights cautions of using empirical evaluation without guaranteed bounds.","",""
46,"Wen Qi, Hang Su, Chenguang Yang, G. Ferrigno, E. Momi, A. Aliverti","A Fast and Robust Deep Convolutional Neural Networks for Complex Human Activity Recognition Using Smartphone",2019,"","","","",101,"2022-07-13 09:26:17","","10.3390/s19173731","","",,,,,46,15.33,8,6,3,"As a significant role in healthcare and sports applications, human activity recognition (HAR) techniques are capable of monitoring humans’ daily behavior. It has spurred the demand for intelligent sensors and has been giving rise to the explosive growth of wearable and mobile devices. They provide the most availability of human activity data (big data). Powerful algorithms are required to analyze these heterogeneous and high-dimension streaming data efficiently. This paper proposes a novel fast and robust deep convolutional neural network structure (FR-DCNN) for human activity recognition (HAR) using a smartphone. It enhances the effectiveness and extends the information of the collected raw data from the inertial measurement unit (IMU) sensors by integrating a series of signal processing algorithms and a signal selection module. It enables a fast computational method for building the DCNN classifier by adding a data compression module. Experimental results on the sampled 12 complex activities dataset show that the proposed FR-DCNN model is the best method for fast computation and high accuracy recognition. The FR-DCNN model only needs 0.0029 s to predict activity in an online way with 95.27% accuracy. Meanwhile, it only takes 88 s (average) to establish the DCNN classifier on the compressed dataset with less precision loss 94.18%.","",""
8,"Wenjin Zhang, Jiacun Wang, Fangping Lan","Dynamic hand gesture recognition based on short-term sampling neural networks",2021,"","","","",102,"2022-07-13 09:26:17","","10.1109/JAS.2020.1003465","","",,,,,8,8.00,3,3,1,"Hand gestures are a natural way for human-robot interaction. Vision based dynamic hand gesture recognition has become a hot research topic due to its various applications. This paper presents a novel deep learning network for hand gesture recognition. The network integrates several well-proved modules together to learn both short-term and long-term features from video inputs and meanwhile avoid intensive computation. To learn short-term features, each video input is segmented into a fixed number of frame groups. A frame is randomly selected from each group and represented as an RGB image as well as an optical flow snapshot. These two entities are fused and fed into a convolutional neural network ( ConvNet ) for feature extraction. The ConvNets for all groups share parameters. To learn long-term features, outputs from all ConvNets are fed into a long short-term memory ( LSTM ) network, by which a final classification result is predicted. The new model has been tested with two popular hand gesture datasets, namely the Jester dataset and Nvidia dataset. Comparing with other models, our model produced very competitive results. The robustness of the new model has also been proved with an augmented dataset with enhanced diversity of hand gestures.","",""
2,"O. Oyedotun, Abd El Rahman Shabayek, Djamila Aouada, B. Ottersten","Improved Highway Network Block for Training Very Deep Neural Networks",2020,"","","","",103,"2022-07-13 09:26:17","","10.1109/ACCESS.2020.3026423","","",,,,,2,1.00,1,4,2,"Very deep networks are successful in various tasks with reported results surpassing human performance. However, training such very deep networks is not trivial. Typically, the problems of learning the identity function and feature reuse can work together to plague optimization of very deep networks. In this paper, we propose a highway network with gate constraints that addresses the aforementioned problems, and thus alleviates the difficulty of training. Namely, we propose two variants of highway network, HWGC and HWCC, employing feature summation and concatenation respectively. The proposed highway networks, besides being more computationally efficient, are shown to have more interesting learning characteristics such as natural learning of hierarchical and robust representations due to a more effective usage of model depth, fewer gates for successful learning, better generalization capacity and faster convergence than the original highway network. Experimental results show that our models outperform the original highway network and many state-of-the-art models. Importantly, we observe that our second model with feature concatenation and compression consistently outperforms our model with feature summation of similar depth, the original highway network, many state-of-the-art models and even ResNets on four benchmarking datasets which are CIFAR-10, CIFAR-100, Fashion-MNIST, SVHN and imagenet-2012 (ILSVRC) datasets. Furthermore, the second proposed model is more computationally efficient than the state-of-the-art in view of training, inference time and GPU memory resource, which strongly supports real-time applications. Using a similar number of model parameters for the CIFAR-10, CIFAR-100, Fashion-MNIST and SVHN datasets, the significantly shallower proposed model can surpass the performance of ResNet-110 and ResNet-164 that are roughly 6 and 8 times deeper, respectively. Similarly, for the imagenet dataset, the proposed models surpass the performance of ResNet-101 and ResNet-152 that are roughly three times deeper.","",""
67,"Keisuke Sakaguchi, Kevin Duh, Matt Post, Benjamin Van Durme","Robsut Wrod Reocginiton via Semi-Character Recurrent Neural Network",2016,"","","","",104,"2022-07-13 09:26:17","","10.1609/aaai.v31i1.10970","","",,,,,67,11.17,17,4,6,"    Language processing mechanism by humans is generally more robust than computers. The Cmabrigde Uinervtisy (Cambridge University) effect from the psycholinguistics literature has demonstrated such a robust word processing mechanism, where jumbled words (e.g. Cmabrigde / Cambridge) are recognized with little cost. On the other hand, computational models for word recognition (e.g. spelling checkers) perform poorly on data with such noise. Inspired by the findings from the Cmabrigde Uinervtisy effect, we propose a word recognition model based on a semi-character level recurrent neural network (scRNN). In our experiments, we demonstrate that scRNN has significantly more robust performance in word spelling correction (i.e. word recognition) compared to existing spelling checkers and character-based convolutional neural network. Furthermore, we demonstrate that the model is cognitively plausible by replicating a psycholinguistics experiment about human reading difficulty using our model.   ","",""
0,"Hirak J. Kashyap","Brain Inspired Neural Network Models of Visual Motion Perception and Tracking in Dynamic Scenes",2020,"","","","",105,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,2,"Author(s): Kashyap, Hirak Jyoti | Advisor(s): Krichmar, Jeffrey L | Abstract: For self-driving vehicles, aerial drones, and autonomous robots to be successfully deployed in the real-world, they must be able to navigate complex environments and track objects. While Artificial Intelligence and Machine Vision have made significant progress in dynamic scene understanding, they are not yet as robust and computationally efficient as humans or other primates in these tasks. For example, the current state-of-the-art visual tracking methods become inaccurate when applied to random test videos. We suggest that ideas from cortical visual processing can inspire real world solutions for motion perception and tracking that are robust and efficient. In this context, the following contributions are made in this dissertation. First, a method for estimating 6DoF ego-motion and pixel-wise object motion is introduced, based on a learned overcomplete motion field basis set. The method uses motion field constraints for training and a novel differentiable sparsity regularizer to achieve state-of-the-art ego and object-motion performances on benchmark datasets. Second, a Convolutional Neural Network (CNN) that learns hidden neural representations analogous to the response characteristics of dorsal Medial Superior Temporal area (MSTd) neurons for optic flow and object motion is presented. The findings suggest that goal driven training of CNNs might automatically result in the MSTd-like response properties of model neurons. Third, a recurrent neural network model of predictive smooth pursuit eye movements is presented that generates similar pursuit initiation and predictive pursuit behaviors as observed in humans. The model provides the computational mechanisms of formation and rapid update of an internal model of target velocity, commonly attributed to zero lag tracking and smooth pursuit of occluded objects. Finally, a spike based stereo depth algorithm is presented that reconstructs dynamic visual scenes at 400 frames-per-second with one watt of power consumption when implemented using the IBM TrueNorth processor. Taken together, the presented models and implementations provide the computations for motion perception in the dorsal visual pathway in the brain and inform ideas for efficient computational vision systems.","",""
42,"G. Basalyga, E. Salinas","When Response Variability Increases Neural Network Robustness to Synaptic Noise",2005,"","","","",106,"2022-07-13 09:26:17","","10.1162/neco.2006.18.6.1349","","",,,,,42,2.47,21,2,17,"Cortical sensory neurons are known to be highly variable, in the sense that responses evoked by identical stimuli often change dramatically from trial to trial. The origin of this variability is uncertain, but it is usually interpreted as detrimental noise that reduces the computational accuracy of neural circuits. Here we investigate the possibility that such response variability might in fact be beneficial, because it may partially compensate for a decrease in accuracy due to stochastic changes in the synaptic strengths of a network. We study the interplay between two kinds of noise, response (or neuronal) noise and synaptic noise, by analyzing their joint influence on the accuracy of neural networks trained to perform various tasks. We find an interesting, generic interaction: when fluctuations in the synaptic connections are proportional to their strengths (multiplicative noise), a certain amount of response noise in the input neurons can significantly improve network performance, compared to the same network without response noise. Performance is enhanced because response noise and multiplicative synaptic noise are in some ways equivalent. So if the algorithm used to find the optimal synaptic weights can take into account the variability of the model neurons, it can also take into account the variability of the synapses. Thus, the connection patterns generated with response noise are typically more resistant to synaptic degradation than those obtained without response noise. As a consequence of this interplay, if multiplicative synaptic noise is present, it is better to have response noise in the network than not to have it. These results are demonstrated analytically for the most basic network consisting of two input neurons and one output neuron performing a simple classification task, but computer simulations show that the phenomenon persists in a wide range of architectures, including recurrent (attractor) networks and sensorimotor networks that perform coordinate transformations. The results suggest that response variability could play an important dynamic role in networks that continuously learn.","",""
1,"Neziha Jaouedi, Noureddine Boujnah, M. Bouhlel","A novel recurrent neural networks architecture for behavior analysis",2021,"","","","",107,"2022-07-13 09:26:17","","10.34028/iajit/18/2/1","","",,,,,1,1.00,0,3,1,"Behavior analysis is an important yet challenging task on computer vision area. However, human behavior is still a necessity in differents sectors. In fact, in the increase of crimes, everyone needs video surveillance to keep their belongings safe and to automatically detect events by collecting important information for the assistance of security guards. Moreover, the surveillance of human behavior is recently used in medicine fields to quickly detect physical and mental health problems of patients. The complex and the variety presentation of human features in video sequence encourage researches to find the effective presentation. An effective presentation is the most challenging part. It must be invariant to changes of point of view, robust to noise and efficient with a low computation time. In this paper, we propose new model for human behavior analysis which combine transfer learning model and Recurrent Neural Network (RNN). Our model can extract human features from frames using the pre-trained model of Convolutional Neural Network (CNN) the Inception V3. The human features obtained are trained using RNN with Gated Recurrent Unit (GRU). The performance of our proposed architecture is evaluated by three different dataset for human action, UCF Sport, UCF101 and KTH, and achieved good classification accuracy","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",108,"2022-07-13 09:26:17","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
3,"Kaushalya Kumarasinghe, Mahonri Owen, Denise Taylor, N. Kasabov, C. Kit","FaNeuRobot: A Framework for Robot and Prosthetics Control Using the NeuCube Spiking Neural Network Architecture and Finite Automata Theory",2018,"","","","",109,"2022-07-13 09:26:17","","10.1109/ICRA.2018.8460197","","",,,,,3,0.75,1,5,4,"Limb amputation is a global problem. Prosthetic limbs can enhance the quality of life of amputees. To this end, anthropomorphic design and intuitive manipulation are two essential requirements. This paper presents a motor control framework for prosthetic control through Brain-Machine Interface (BMI) using Finite Automata Theory, and NeuCube Evolving Spiking Neural Network (SNN) architecture. Voluntary control of prosthetics requires decoding motor commands from the Central Nervous System of the amputee. Selection of the most suitable biomedical signal depends on many parameters such as level of amputation and muscle atrophy. Non-invasive BMI's have the possibility of supporting a wider range of amputees as it extracts the motor commands from the brain. In this paper, we present a proof of concept study on whether a cognitive computational model that is inspired by the motor control of the human body through muscle synergies combined with an anthropomorphic mechanical design, can result in accurate and robust prosthetic control through a noninvasive BMI. In future, learning of a complex Finite Automata that reflects complex upper limb motor behaviours will be investigated.","",""
84,"T. Kline, P. Korfiatis, Marie E. Edwards, J. Blais, F. Czerwiec, P. Harris, B. King, V. Torres, B. Erickson","Performance of an Artificial Multi-observer Deep Neural Network for Fully Automated Segmentation of Polycystic Kidneys",2017,"","","","",110,"2022-07-13 09:26:17","","10.1007/s10278-017-9978-1","","",,,,,84,16.80,9,9,5,"","",""
0,"H. Wang","Graphene-based neuromorphic computing: Artificial spiking neural networks",2021,"","","","",111,"2022-07-13 09:26:17","","10.4233/UUID:1B81527F-C493-482C-AF9F-CD46ADB32729","","",,,,,0,0.00,0,1,1,"The human brain is a natural high-performance computing systemwith outstanding properties, e.g., ultra-low energy consumption, highly parallel information processing, suitability for solving complex tasks, and robustness. As such, numerous attempts have been made to devise neuromorphic systems able to achieve brain-akin computation abilities, which can aid in understanding the complex human brain functionality and can be utilized to solve complex problems, e.g., pattern recognition and data mining. However, the fact that human brain comprises billions of neurons, which are the fundamental information processing units, and trillions of synapses that interconnect them makes the design and implementation of large-scale brain-inspired computing systems quite a challenging task. Graphene appears to be a promising candidate for scalable neuromorphic implementations as it exhibits a wealth of outstanding properties, e.g., ballistic transport, ultimate thinness, flexibility, and graphene devices are capable of emulating complex nonlinear functions and can be readily tuned to provide various conduction dynamicswhile preserving low energy operation and small footprint. Moreover, graphene is biocompatible, which offers perspectives for graphene-based neuromorphic bio-interfaces. This thesis aims to investigate graphene’s potential to enable scalable and energy effective neuromorphic computing. To this end, we first introduce an atomistic-level simulation model for calculating graphene electronic transport properties, that captures the hysteresis effects induced by interface charges trapping/detrapping phenomena. Second, we propose a generic graphene based synapse, which can be tailored to emulate different synaptic plasticity types by properly modifying its Graphene NanoRibbon (GNR) shape and contacts topology, as well as applying external voltages. Subsequently, we introduce a compact graphene-based integrate-and-fire spiking neuron that mimics the basic spiking neuronal dynamics. We further propose a basic SpikingNeuralNetwork (SNN) unit,which can be utilized to implement complex graphene-based SNNstructures. Finally,we introduce a reconfigurable graphene-based SNN architecture and a training methodology for obtaining the initial SNN synaptic weight values. We demonstrate the feasibility of the synaptic weights training methodology and the practical capabilities of the proposedSNNarchitecture by applying them to solve character recognition and edge detection problems. Our experiments clearly indicate that the proposed graphene-based neuromorphic approach enables lowenergy operation at small chip real estate footprint, which are enabling factors for the realization of scalable energy-efficient SNN implementations.","",""
3,"","Focus on neural computation and theory",2016,"","","","",112,"2022-07-13 09:26:17","","10.1038/nn.4261","","",,,,,3,0.50,0,0,6,"","",""
0,"Diego Argüello Ron, M. Kamalian-Kopae, S. Turitsyn","Noise-Resistant Optical Implementation of Analogue Neural Networks",2021,"","","","",113,"2022-07-13 09:26:17","","10.1109/CLEO/Europe-EQEC52157.2021.9541571","","",,,,,0,0.00,0,3,1,"Analogue artificial neural networks are widely considered as promising computational models that more closely imitate the information processing capabilities of the human brain compared to digital neural networks. The significant computation power and the much reduced power consumption per operation make the analogue implementation of neural networks very attractive. There is an active research on artificial neural networks (ANNs) implementation using both analogue photonic and electronic hardware [1] – [4] . However, compared to digital realisations the conventional analogue systems are more sensitive to the noise that is inevitably present in practical implementations [2] , [3] . Noise properties in ANNs have been studied both in the electronic and photonic domains. However, photonic ANNs are much less investigated compared to the electronic implementations, for which some training techniques have been proposed to enhance ANNs robustness against noise [1] , [4] .","",""
29,"N. Amoroso, R. Errico, S. Bruno, A. Chincarini, E. Garuccio, F. Sensi, S. Tangaro, A. Tateo, R. Bellotti","Hippocampal unified multi-atlas network (HUMAN): protocol and scale validation of a novel segmentation tool.",2015,"","","","",114,"2022-07-13 09:26:17","","10.1088/0031-9155/60/22/8851","","",,,,,29,4.14,3,9,7,"In this study we present a novel fully automated Hippocampal Unified Multi-Atlas-Networks (HUMAN) algorithm for the segmentation of the hippocampus in structural magnetic resonance imaging. In multi-atlas approaches atlas selection is of crucial importance for the accuracy of the segmentation. Here we present an optimized method based on the definition of a small peri-hippocampal region to target the atlas learning with linear and non-linear embedded manifolds. All atlases were co-registered to a data driven template resulting in a computationally efficient method that requires only one test registration. The optimal atlases identified were used to train dedicated artificial neural networks whose labels were then propagated and fused to obtain the final segmentation. To quantify data heterogeneity and protocol inherent effects, HUMAN was tested on two independent data sets provided by the Alzheimer's Disease Neuroimaging Initiative and the Open Access Series of Imaging Studies. HUMAN is accurate and achieves state-of-the-art performance (Dice[Formula: see text] and Dice[Formula: see text]). It is also a robust method that remains stable when applied to the whole hippocampus or to sub-regions (patches). HUMAN also compares favorably with a basic multi-atlas approach and a benchmark segmentation tool such as FreeSurfer.","",""
0,"Junxiao Xue, Junjin Cheng, Qibin Zhang, Yibo Guo, Aiguo Lu, Jian Li, Xi Wan, Jing Xu","Improved Efficient Convolutional Neural Networks for Complex Scene Mask-Wearing Detection",2021,"","","","",115,"2022-07-13 09:26:17","","10.3724/sp.j.1089.2021.18635","","",,,,,0,0.00,0,8,1,": To solve the problem about low accuracy of mask wear detection under complex lighting and face lean conditions, a method of mask wear detection under intricate environment using efficient convolutional neural network is proposed, which uses pre-training such as hard negative mining to learn more samples of face feature, utilize multi-task convolutional neural networks (MTCNN) to estimate the possibility of face information, and get accurate face location. With attention mechanism in feature pyramid network, enhanc-ing the weight of key points on human face, employing efficient neural network detection will be wore on mask-wearing detection as a simple binary classification problem. Under the environment of TensorFlow platform, not only data training, data preprocessing, but also the contrast experiment with AIZOO method are completed. A data set containing with 816 images is collected, marked and trained. During the data pre-processing, images are set as fixed size to reduce the amount of computation and promote the detection speed. Then, image enhancement algorithm is used to conduct distortion processing to improve the robust-ness of this model. On this basis, MTCNN is used to detect the face information in pictures, modify and normalize all data, then put them into neural network and the trained model to detection. The experimental results show that under complex conditions such as complex lighting and face tilt, the accuracy can reach 83% and 91% respectively, which means can accurately detect whether wearing a mask.","",""
0,"Hafez Ghaemi, Erfan Mirzaei, Mahbod Nouri, S. R. Kheradpisheh","BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks",2021,"","","","",116,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,4,1,". Brain-inspired computation and information processing alongside compatibility with neuromorphic hardware have made spiking neural networks (SNN) a promising method for solving learning tasks in machine learning (ML). Spiking neurons are only one of the requirements for building a bio-plausible learning model. Network architecture and learning rules are other important factors to consider when developing such artiﬁcial agents. In this work, inspired by the human visual pathway and the role of dopamine in learning, we propose a reward-modulated locally connected spiking neural network, BioLCNet, for visual learning tasks. To extract visual features from Poisson-distributed spike trains, we used local ﬁlters that are more analogous to the biological visual system compared to convolutional ﬁlters with weight sharing. In the decoding layer, we applied a spike population-based voting scheme to determine the decision of the network. We employed Spike-timing-dependent plasticity (STDP) for learning the visual features, and its reward-modulated variant (R-STDP) for training the decoder based on the reward or punishment feedback signal. For evaluation, we ﬁrst assessed the robustness of our rewarding mechanism to varying target responses in a classical conditioning experiment. Afterwards, we evaluated the performance of our network on image classiﬁcation tasks of MNIST and XOR MNIST datasets.","",""
3,"Hojin Jang, F. Tong","Convolutional neural networks trained with a developmental sequence of blurry to clear images reveal core differences between face and object processing",2021,"","","","",117,"2022-07-13 09:26:17","","10.1101/2021.05.25.444835","","",,,,,3,3.00,2,2,1,"Although convolutional neural networks (CNNs) provide a promising model for understanding human vision, most CNNs lack robustness to challenging viewing conditions such as image blur, whereas human vision is much more reliable. Might robustness to blur be attributable to vision during infancy, given that acuity is initially poor but improves considerably over the first several months of life? Here, we evaluated the potential consequences of such early experiences by training CNN models on face and object recognition tasks while gradually reducing the amount of blur applied to the training images. For CNNs trained on blurry to clear faces, we observed sustained robustness to blur, consistent with a recent report by Vogelsang and colleagues (2018). By contrast, CNNs trained with blurry to clear objects failed to retain robustness to blur. Further analyses revealed that the spatial frequency tuning of the two CNNs was profoundly different. The blurry to clear face-trained network successfully retained a preference for low spatial frequencies, whereas the blurry to clear object-trained CNN exhibited a progressive shift toward higher spatial frequencies. Our findings provide novel computational evidence showing how face recognition, unlike object recognition, allows for more holistic processing. Moreover, our results suggest that blurry vision during infancy is insufficient to account for the robustness of adult vision to blurry objects.","",""
1,"Enyan Dai, Tianxiang Zhao, Huaisheng Zhu, Jun Xu, Zhimeng Guo, Hui Liu, Jiliang Tang, Suhang Wang","A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability",2022,"","","","",118,"2022-07-13 09:26:17","","10.48550/arXiv.2204.08570","","",,,,,1,1.00,0,8,1,"Graph Neural Networks (GNNs) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, GNNs are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that GNNs can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the GNNs to give the outcome they desire with unnoticeable perturbation on training graph. GNNs trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy GNNs in various aspects are emerging to prevent the harm from GNN models and increase the users’ trust in GNNs. In this paper, we give a comprehensive survey of GNNs in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy GNNs. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness. Neural Networks:","",""
0,"Hai Jiang, Jing Liu, H. Cheng","Short-Term TLE Uncertainty Estimation Using an Artificial Neural Network Model",2018,"","","","",119,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,4,"A growing number of space activities have created an orbital debris environment that poses increasing impact risks to existing space systems and human space flight. Accurate knowledge of orbit propagation errors of space debris is essential for many types of analyses, such as space surveillance network tasking, conjunction analysis etc. Unfortunately, for two-line elements (TLEs) this is not available. In this paper, a new short-term TLE uncertainty estimation method based on an artificial neural network model is proposed. Object properties, orbit type, space environment and prediction time-span are considered as the input of the network, the propagation errors in the direction of downrange, normal and conormald are as the output of the network. In order to assure the chosen orbit for training is not for an object using station keeping, only debris and R/B are used. The network’s efficiency is demonstrated with some objects with high ephemeris data. Overall, the method proves accurate, computationally fast, and robust, and is applicable to any object in the satellite catalogue, especially for those newly launched objects.","",""
3,"Vasco Lopes, Saeid Alirezazadeh, L. A. Alexandre","EPE-NAS: Efficient Performance Estimation Without Training for Neural Architecture Search",2021,"","","","",120,"2022-07-13 09:26:17","","10.1007/978-3-030-86383-8_44","","",,,,,3,3.00,1,3,1,"","",""
15,"Timo Flesch, Keno Juechems, T. Dumbalska, Andrew M. Saxe, C. Summerfield","Rich and lazy learning of task representations in brains and neural networks",2021,"","","","",121,"2022-07-13 09:26:17","","10.1101/2021.04.23.441128","","",,,,,15,15.00,3,5,1,"How do neural populations code for multiple, potentially conflicting tasks? Here, we used computational simulations involving neural networks to define “lazy” and “rich” coding solutions to this multitasking problem, which trade off learning speed for robustness. During lazy learning the input dimensionality is expanded by random projections to the network hidden layer, whereas in rich learning hidden units acquire structured representations that privilege relevant over irrelevant features. For context-dependent decision-making, one rich solution is to project task representations onto low-dimensional and orthogonal manifolds. Using behavioural testing and neuroimaging in humans, and analysis of neural signals from macaque prefrontal cortex, we report evidence for neural coding patterns in biological brains whose dimensionality and neural geometry are consistent with the rich learning regime.","",""
0,"Y. Meng, Yaochu Jin, Jun Yin, Matthew Conforth","An Evolving Gene Regulatory Network based Spiking Neural Network for Online Human Behavior Recognition",,"","","","",122,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,4,,"— Automatically understanding human behaviors online in a video stream under various scenes is a challenging task. The major difficulty of this task lies in how to combine the spatial and temporal features of video sequences together to extract behavior patterns. To tackle this problem, we propose an evolving gene regulatory network (GRN) based BCM (E-GRN-BCM) model, which is a spiking neural network combined with biological cellular phenomenon. Basically, the weight, weight plasticity, and meta-plasticity of the spiking neural network will be regulated by the GRN, and the GRN will also be influenced by the activity of the neurons it resides in, in a closed loop. Furthermore, an efficient evolutionary algorithm, the covariance matrix adaptation evolution strategy (CMA-ES), is used to justify the GRN parameters, which can significantly reduce the computational cost compared to traditional genetic algorithms. Extensive experimental results have demonstrated the efficiency and robustness of the proposed E-GRN-BCM model for online human behavior recognition under various scenes.","",""
20,"Hussein Hassan-Harrirou, Ce Zhang, T. Lemmin","RosENet: Improving Binding Affinity Prediction by Leveraging Molecular Mechanics Energies with an Ensemble of 3D Convolutional Neural Networks",2020,"","","","",123,"2022-07-13 09:26:17","","10.1021/acs.jcim.0c00075","","",,,,,20,10.00,7,3,2,"The worldwide increase and proliferation of drug resistant microbes, coupled with the lag in new drug development represents a major threat to human health. In order to reduce the time and cost for exploring the chemical search space, drug discovery increasingly relies on computational biology approaches. One key step in these approaches is the need for the rapid and accurate prediction of the binding affinity for potential leads. Here, we present RosENet (Rosetta Energy Neural Network), an ensemble of three-dimensional (3D) Convolutional Neural Networks (CNN), which combines voxelized molecular mechanics energies and molecular descriptors for predicting the absolute binding affinity of protein - ligand complexes. By leveraging the physico-chemical properties captured by the molecular force field, our model achieved a Root Mean Square Error (RMSE) of 1.26 on the PDBBind v2016 core set. We also explored some limitations and the robustness of the PDBBind dataset and our approach, on nearly 500 structures, including structures determined by Nuclear Magnetic Resonance and virtual screening experiments. Our study demonstrated that molecular mechanics energies can be voxelized and used to help improve the predictive power of the CNNs. In the future, our framework can be extended to features extracted from other biophysical and biochemical models, such as molecular dynamics simulations.","",""
3,"Dalai Tang, Tiong Yew Tang, János Botzheim, N. Kubota, Toru Yamaguchi","Fuzzy Spiking Neural Network for Abnormality Detection in Cognitive Robot Life Supporting System",2015,"","","","",124,"2022-07-13 09:26:17","","10.1109/SSCI.2015.29","","",,,,,3,0.43,1,5,7,"In aging nation such as Japan, elderly people belong to the vulnerable group that constantly need health care and monitoring for their well-being. Therefore, an early warning system for detecting abnormality in their daily activities could save their life (e.g. Heart attack, stroke and etc.). However, such early warning system must not trigger any false warning signals in order to robustly operate in real world applications. Robot interactions with human are useful to prevent false warning signals from sending out to healthcare worker. Next, the system should be able to detect short-term abnormal and also long-term abnormal behaviors of the elderly people within their normal daily life routine. Therefore, it is important to integrate information ally structured space with cognitive robot to confirm the elderly's abnormal situation with human-robot interactions before sending out warning signals to healthcare workers. In this work, we proposed an evolutionary computation based approach to optimize fuzzy spiking neural network for detecting abnormal activities in the elderly people's daily activities.","",""
0,"Gautam Chakraborty, Mridusmita Sharma, Navajit Saikia, K. K. Sarma","Soft-computation based speech recognition system for Sylheti language",2022,"","","","",125,"2022-07-13 09:26:17","","10.1007/s10772-022-09976-7","","",,,,,0,0.00,0,4,1,"","",""
9,"Zhensong Wei, Chao Wang, Peng Hao, M. Barth","Vision-Based Lane-Changing Behavior Detection Using Deep Residual Neural Network",2019,"","","","",126,"2022-07-13 09:26:17","","10.1109/ITSC.2019.8917158","","",,,,,9,3.00,2,4,3,"Accurate lane localization and lane change detection are crucial in advanced driver assistance systems and autonomous driving systems for safer and more efficient trajectory planning. Conventional localization devices such as Global Positioning System only provide road-level resolution for car navigation, which is incompetent to assist in lane-level decision making. The state of art technique for lane localization is to use Light Detection and Ranging sensors to correct the global localization error and achieve centimeter-level accuracy, but the real-time implementation and popularization for LiDAR is still limited by its computational burden and current cost. As a cost-effective alternative, vision-based lane change detection has been highly regarded for affordable autonomous vehicles to support lane-level localization. A deep learning based computer vision system is developed to detect the lane change behavior using the images captured by a front-view camera mounted on the vehicle and data from the inertial measurement unit for highway driving. Testing results on real-world driving data have shown that the proposed method is robust with real-time working ability and could achieve around 87% lane change detection accuracy. Compared to the average human reaction to visual stimuli, the proposed computer vision system works 9 times faster, which makes it capable of helping make life-saving decisions in time.","",""
0,"Chinonso Paschal Udeh, Luefeng Chen, Min Wu","Facial Emotion Recognition Using Convolution Neural Networks-Based Deep Learning Model",2021,"","","","",127,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,1,"The 7th International Workshop on Advanced Computational Intelligence and Intelligent Informatics (IWACIII2021) Beijing, China, Oct.31-Nov.3, 2021 1 Abstract. With the development of emotion recognition, learning, and analysis, robotics plays a significant role in human perception, attention, memory, decision-making, and social communication, leading to emotion recognition and human-robot interaction (HRI). This research analyzes the interaction between humans and robots using facial expressions and head pose to achieve robustness in understanding emotions by optimizing the traditional deep neural networks to comprehend the coexistence of multi facial information in HRI using convolution neural networks. A hybrid genetic algorithm with stochastic gradient descent is adopted, which has the capacity of inherent, implicit parallelism and better global optimization of the genetic algorithm to find the better weights of the network. The experiment shows the proposal's effectiveness in providing complete emotion recognition through single-modal cooperation of HRI that can interact with humans and machines.","",""
4,"Theodoros Tsiligkaridis, Jay Roberts","Second Order Optimization for Adversarial Robustness and Interpretability",2020,"","","","",128,"2022-07-13 09:26:17","","","","",,,,,4,2.00,2,2,2,"Deep neural networks are easily fooled by small perturbations known as adversarial attacks. Adversarial Training (AT) is a technique aimed at learning features robust to such attacks and is widely regarded as a very effective defense. However, the computational cost of such training can be prohibitive as the network size and input dimensions grow. Inspired by the relationship between robustness and curvature, we propose a novel regularizer which incorporates first and second order information via a quadratic approximation to the adversarial loss. The worst case quadratic loss is approximated via an iterative scheme. It is shown that using only a single iteration in our regularizer achieves stronger robustness than prior gradient and curvature regularization schemes, avoids gradient obfuscation, and, with additional iterations, achieves strong robustness with significantly lower training time than AT. Further, it retains the interesting facet of AT that networks learn features which are well-aligned with human perception. We demonstrate experimentally that our method produces higher quality human-interpretable features than other geometric regularization techniques. These robust features are then used to provide human-friendly explanations to model predictions.","",""
6,"R. Hamad, Masashi Kimura, Longzhi Yang, W. L. Woo, Bo Wei","Dilated causal convolution with multi-head self attention for sensor human activity recognition",2021,"","","","",129,"2022-07-13 09:26:17","","10.1007/S00521-021-06007-5","","",,,,,6,6.00,1,5,1,"","",""
2,"A. Opeyemi, R. Gbenga","Symptomatic and Climatic Based Malaria Threat Detection Using Multilevel Thresholding FeedForward Neural Network",2017,"","","","",130,"2022-07-13 09:26:17","","10.5815/ijitcs.2017.08.05","","",,,,,2,0.40,1,2,5,"Recent worldwide medical research is focusing on new intelligence approaches for diagnosis of various infections. The sporadic occurrence of malaria diseases in human has pushed the need to develop computational approaches for its diagnoses. Most existing conventional malaria models for classification problems examine the dynamics of asymptomatic and morphological characteristics of malaria parasite in the thick blood smear, but this study examine the symptomatic characteristics of malaria parasite combined with effects of climatic factor which is a great determinant of malaria severity. The need to predict the occurrence of malaria disease and its outbreak will be helpful to take appropriate actions by individuals, World Health Organizations and Government Agencies and its devastating impact will be reduced. This paper proposed Feed-Forward Back-Propagation (FF_BP) Neural Network model to determine the rate of malaria transmission. Monthly averages of climatic factors; rainfall, temperature and relative humidity with monthly malaria incidences were used as input variables. An optimum threshold value of 0.7100 with classification accuracy 87.56%, sensitivity 96.67% and specificity 76.67% and mean square error of 0.100 were achieved. While, the model malaria threat detection rate was 87.56%, positive predictive value was 89.23%, negative predictive value was 92.00% and the standard deviation is 2.533. The statistical analysis of Feed-Forward BackPropagation Neural Network model was conducted and its results were compared with other existing models to check its robustness and viability.","",""
0,"J. Constantin, A. Bigand, I. Constantin","Pooling Spike Neural Network for Acceleration of Global Illumination Rendering",2017,"","","","",131,"2022-07-13 09:26:17","","10.1007/978-3-319-59153-7_18","","",,,,,0,0.00,0,3,5,"","",""
9,"Steffen Czolbe, Oswin Krause, Ingemar Cox, C. Igel","A Loss Function for Generative Neural Networks Based on Watson's Perceptual Model",2020,"","","","",132,"2022-07-13 09:26:17","","","","",,,,,9,4.50,2,4,2,"To train Variational Autoencoders (VAEs) to generate realistic imagery requires a loss function that reflects human perception of image similarity. We propose such a loss function based on Watson's perceptual model, which computes a weighted distance in frequency space and accounts for luminance and contrast masking. We extend the model to color images, increase its robustness to translation by using the Fourier Transform, remove artifacts due to splitting the image into blocks, and make it differentiable. In experiments, VAEs trained with the new loss function generated realistic, high-quality image samples. Compared to using the Euclidean distance and the Structural Similarity Index, the images were less blurry; compared to deep neural network based losses, the new approach required less computational resources and generated images with less artifacts.","",""
49,"Jibin Wu, Yansong Chua, Malu Zhang, Haizhou Li, K. Tan","A Spiking Neural Network Framework for Robust Sound Classification",2018,"","","","",133,"2022-07-13 09:26:17","","10.3389/fnins.2018.00836","","",,,,,49,12.25,10,5,4,"Environmental sounds form part of our daily life. With the advancement of deep learning models and the abundance of training data, the performance of automatic sound classification (ASC) systems has improved significantly in recent years. However, the high computational cost, hence high power consumption, remains a major hurdle for large-scale implementation of ASC systems on mobile and wearable devices. Motivated by the observations that humans are highly effective and consume little power whilst analyzing complex audio scenes, we propose a biologically plausible ASC framework, namely SOM-SNN. This framework uses the unsupervised self-organizing map (SOM) for representing frequency contents embedded within the acoustic signals, followed by an event-based spiking neural network (SNN) for spatiotemporal spiking pattern classification. We report experimental results on the RWCP environmental sound and TIDIGITS spoken digits datasets, which demonstrate competitive classification accuracies over other deep learning and SNN-based models. The SOM-SNN framework is also shown to be highly robust to corrupting noise after multi-condition training, whereby the model is trained with noise-corrupted sound samples. Moreover, we discover the early decision making capability of the proposed framework: an accurate classification can be made with an only partial presentation of the input.","",""
0,"Sweety H Meshram, V. Keswani, Nilesh P. Bodne","MECHANICAL SPARE PART INSPECTION USING ARTIFICIAL NEURAL NETWORK",2014,"","","","",134,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,8,"Artificial Neural Network (ANN) is a fast-growing method which has been used in different industries during recent years. The main idea for creating ANN which is a subset of artificial intelligence is to provide a simple model of human brain in order to solve complex scientific and industrial problems. ANNs are high-value and low-cost tools in modelling, simulation, control, condition monitoring, sensor validation and fault diagnosis of different systems. It have high flexibility and robustness in modeling, simulating and diagnosing the behavior of rotating machines even in the presence of inaccurate input data. They can provide high computational speed for complicated tasks that require rapid response such as real-time processing of several simultaneous signals. ANNs can also be used to improve efficiency and productivity of energy in rotating equipment. In the present study develop an efficient system for sorting out various machine components in order to attain very high efficiency. Feature extraction tools are used for feature extraction of the input object. Artificial neural network the popular artificial intelligence technique is used for recognising the wavelet component object. There is also a special error function for increasing the efficiency of the system. Matlab 7.10 is used for the simulation of the object.","",""
2,"M. S. Islam, K. Mamun, Muhammad S. Khan, Hai Deng","Performance Assessment of Artificial Neural Network Classifier for Predicting Movement and Laterality of Deep Brain Local Field Potential",2013,"","","","",135,"2022-07-13 09:26:17","","","","",,,,,2,0.22,1,4,9,"Human voluntary and involuntary movement and subsequent laterality are closely related with neural synchrony of brain which is an indispensable part of Brain Machine Interface (BMI) research. The objective of this study, therefore aimed to decode deep brain local field potentials (LFPs) related to movements and its laterality, left or right sided visually cued movements. Frequency related components were extracted using the wavelet packet transform (WPT). Signal features were computed as the instantaneous power of each component using the Hilbert Transform with defined windows for motor response. Finally, classification was performed for predicting movement (Event vs. Rest) and its laterality (Left vs. Right) state using Feed forward Back propagation based Artificial Neural Network (FBANN). Classification performance was evaluated using 10-fold cross validation technique to identify the robustness. After optimizing parameters, overall average correct classification rate reached to 94.26±4.3% for movement and 85.62 ±8.90% for laterality. Considering the classification accuracy, sensitivity, specificity and the area under the receiver operating characteristic (ROC) curve, FBANN classifier successfully achieved better than chance level. The proposed modality and computational process may promisingly effective and powerful method for improving BMI applications.","",""
31,"S. Kosbatwar","Pattern Association For Character Recognition By Back-Propagation Algorithm Using Neural Network Approach",2012,"","","","",136,"2022-07-13 09:26:17","","10.5121/IJCSES.2012.3112","","",,,,,31,3.10,31,1,10,"The use of artificial neural network in applications can dramatically simplify the code and improve quality of recognition while achieving good performance. Another benefit of using neural network in application is extensibility of the system – ability to recognize more character sets than initially defined. Most of traditional systems are not extensible enough. In this paper recognition of characters is possible by using neural network back propagation algorithm. What is neural network Neural network are simplified models of the biological nervous system and therefore have drawn their motivation from the kind of computing performed by a human brain. An NN in general is a highly interconnected of a large number of processing elements called neurons in an architecture inspired by the brain. An NN can be massively parallel and therefore is said to exhibit parallel distributed processing. Neural Network exhibits characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, and parallel and high speed information processing. Neural network learn by example. They can therefore be trained with known examples of a problem to acquire knowledge about it. Once appropriate trained the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. Neural network adopt various learning mechanism of which supervised learning and unsupervised learning methods have turned out to be very popular. In supervised learning, a teacher is assumed to be present during the learning process, i.e. the network aims to minimize he error between target (desired) output presented by the teacher and the computed output to achieve better performance. However, in unsupervised learning, there is no teacher present to hand over the desired output and the network therefore tries to learn by itself, organizing the input instances of the problem.NN Architecture has been broadly classified as single layer feed forward networks, multilayer feed forward networks and recurrent networks, over the year several other NN.Architecture have evolved .some of the well known NN system include backpropogation network, perceptron, ADALINE ,Boltzmann machine ,adaptive resonance theory, Self-organized feature map, and Hopfield network. Neural Network has been successfully applied to problem in the field of pattern recognition, image processing, data compression, forecasting and optimization to quote a few. International Journal of Computer Science & Engineering Survey (IJCSES) Vol.3, No.1, February 2012 128 Backpropagation algorithm The architecture of the neural network is the one of a basically backpropagation network with only one hidden layer (although it is the same techniques with more layers). The input layer is constituted of 35 neuron (one per input pixel in the matrix, of course)., they are 8 hidden neurons, and 26 output neurons(one per letter) in this problem domain of character recognition. The weight matrix gives the weight factor for each input of each neuron. These matrices are what we can call the memory of the neural network. The learning process is done by adjusting these weight so that for each given input the output is as near as possible of a wanted output (Here the full activation of the output neuron corresponding to the character to be recognized) [1]. The training patterns are applied in some random order one by one, and the weights are adjusted using the backpropagation learning law. Each application of the training set patterns is called a cycle. The patterns have to be applied for several training cycles to obtain the output error to an acceptable low value. Once the network is trained, it can be used to recall the appropriate pattern for a new input pattern. The computation for recall is straightforward, in the sense that the weights and the output functions of the units in different layers are used to compute the activation values and the output signals. The signals from the output layer correspond to the output[2]. Backpropagation learning emerged as the most significant result in the field of artificial neural networks. The backpropagation learning involves propagation of the error backwards from the output layer to the hidden layers in order to determine the update for the weights leading to the units in a hidden layer. The error at the output layer itself is computed using the difference between the desired output and the actual output at each of the output units. The actual output for a given input training pattern is determined by computing the outputs of units for each hidden layer in the forward pass of the input data. The error in the output is propagated backwards only to determine the weight updates [6].","",""
0,"Georgios Ioannides, Ioannis Kourouklides, A. Astolfi","Spatiotemporal dynamics in spiking recurrent neural networks using modified-full-FORCE on EEG signals",2021,"","","","",137,"2022-07-13 09:26:17","","10.1038/s41598-022-06573-1","","",,,,,0,0.00,0,3,1,"","",""
0,"G. I. Parisi","Multimodal Learning of Actions with Deep Neural Network Self-Organization",2017,"","","","",138,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,5,"Perceiving the actions of other people is one of the most important social skills of human beings. We are able to reliably discern a variety of socially relevant information from people’s body motion such as intentions, identity, gender, and affective states. This ability is supported by highly developed visual skills and the integration of additional modalities that in concert contribute to providing a robust perceptual experience. Multimodal integration is a fundamental feature of the brain that together with widely studied biological mechanisms for action perception has served as inspiration for the development of artificial systems. However, computational mechanisms for processing and integrating knowledge reliably from multiple perceptual modalities are still to be fully investigated.  The goal of this thesis is to study and develop artificial learning architectures for action perception. In light of a wide understanding of the brain areas and underlying neural mechanisms for processing biological motion patterns, we propose a series of neural network models for learning multimodal action representations. Consistent with neurophysiological studies evidencing a hierarchy of cortical layers driven by the distribution of the input, we demonstrate how computational models of input-driven self-organization can account for the learning of action features with increasing complexity of representation. For this purpose, we introduce a novel model of recurrent self-organization for learning action features with increasingly large spatiotemporal receptive fields. Visual representations obtained through unsupervised learning are incrementally associated to symbolic action labels for the purpose of action classification.  From a multimodal perspective, we propose a model in which multimodal action representations can develop from neural network organization in terms of associative connectivity patterns between unimodal representations. We report a set of experiments showing that deep self-organizing hierarchies allow to learn statistically significant features of actions, with multimodal representations emerging from co-occurring audiovisual stimuli. We evaluated our neural network architectures on the tasks of human action recognition, body motion assessment, and the detection of abnormal behavior. Finally, we conducted two robot experiments that provide quantitative evidence for the advantages of multimodal integration for triggering sensory-driven motor behavior. The first scenario consists of an assistive task for the detection of falls, whereas in the second experiment we propose audiovisual integration in an interactive reinforcement learning scenario. Together, our results demonstrate that deep neural self-organization can account for robust action perception, yielding state-of-the-art performance also in the presence of sensory uncertainty and conflict.  The research presented in this thesis comprises interdisciplinary aspects of action perception and multimodal integration for the development of efficient neurocognitive architectures. While the brain mechanisms for multimodal perception are still to be fully understood, the proposed neural network architectures may be seen as a basis for modeling higher-level cognitive functions.","",""
0,"Rassa Ghavami Modegh, Ahmadali Salimi, H. Rabiee","LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks",2022,"","","","",139,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,1,"Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. The complex computation behind their reasoning is not sufficiently human-understandable to develop trust. External explainer methods have tried to interpret the network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection while improving the model’s performance. Moreover, several weakly-supervised knowledge injection methodologies are provided to enhance the process of training. We verified our claims by evaluating several LAP-extended models on three different datasets, including Imagenet. The proposed framework offers more valid humanunderstandable and more faithful-to-the-model interpretations than the commonly used white-box explainer methods.","",""
2,"Myung-Gyun Kang, N. Kang","Predictive Model for Drug-Induced Liver Injury Using Deep Neural Networks Based on Substructure Space",2021,"","","","",140,"2022-07-13 09:26:17","","10.3390/molecules26247548","","",,,,,2,2.00,1,2,1,"Drug-induced liver injury (DILI) is a major concern for drug developers, regulators, and clinicians. However, there is no adequate model system to assess drug-associated DILI risk in humans. In the big data era, computational models are expected to play a revolutionary role in this field. This study aimed to develop a deep neural network (DNN)-based model using extended connectivity fingerprints of diameter 4 (ECFP4) to predict DILI risk. Each data set for the predictive model was retrieved and curated from DILIrank, LiverTox, and other literature. The best model was constructed through ten iterations of stratified 10-fold cross-validation, and the applicability domain was defined based on integer ECFP4 bits of the training set which represented substructures. For the robustness test, we employed the concept of the endurance level. The best model showed an accuracy of 0.731, a sensitivity of 0.714, and a specificity of 0.750 on the validation data set in the complete applicability domain. The model was further evaluated with four external data sets and attained an accuracy of 0.867 on 15 drugs with DILI cases reported since 2019. Overall, the results suggested that the ECFP4-based DNN model represents a new tool to identify DILI risk for the evaluation of drug safety.","",""
1,"D. Wamriew, R. Pevzner, E. Maltsev, D. Pissarenko","Deep Neural Networks for Detection and Location of Microseismic Events and Velocity Model Inversion from Microseismic Data Acquired by Distributed Acoustic Sensing Array",2021,"","","","",141,"2022-07-13 09:26:17","","10.3390/s21196627","","",,,,,1,1.00,0,4,1,"Fiber-optic cables have recently gained popularity for use as Distributed Acoustic Sensing (DAS) arrays for borehole microseismic monitoring due to their physical robustness as well as high spatial and temporal resolutions. As a result, the sensors record large amounts of data, making it very difficult to process in real-/semi-real-time using the conventional processing routines. We present a novel approach, based on deep learning, for handling the large amounts of DAS data in real-/semi-real-time. The proposed neural network was trained on synthetic microseismic data contaminated with real-ambient noise from field data and was validated using field DAS microseismic data obtained from a hydraulic fracturing operation. The results indicate that the trained network is capable of detecting and locating microseismic events from DAS data and simultaneously update the velocity model to a high degree of precision. The mean absolute errors in the event locations and the velocity model parameters are 2.04, 0.72, 2.76, 4.19 and 0.97 percent for distance (x), depth (z), P-wave velocity, S-wave velocity and density, respectively. In addition to automation and computational efficiency, deep learning reduces human expert data handling during processing, thus preserving data integrity leading to more accurate and reproducible results.","",""
4,"Derek Y. Chan, D. Morris, T. Polascik, M. Palmeri, K. Nightingale","Deep Convolutional Neural Networks for Displacement Estimation in ARFI Imaging",2021,"","","","",142,"2022-07-13 09:26:17","","10.1109/TUFFC.2021.3068377","","",,,,,4,4.00,1,5,1,"Ultrasound elasticity imaging in soft tissue with acoustic radiation force requires the estimation of displacements, typically on the order of several microns, from serially acquired raw data A-lines. In this work, we implement a fully convolutional neural network (CNN) for ultrasound displacement estimation. We present a novel method for generating ultrasound training data, in which synthetic 3-D displacement volumes with a combination of randomly seeded ellipsoids are created and used to displace scatterers, from which simulated ultrasonic imaging is performed using Field II. Network performance was tested on these virtual displacement volumes, as well as an experimental ARFI phantom data set and a human in vivo prostate ARFI data set. In the simulated data, the proposed neural network performed comparably to Loupas’s algorithm, a conventional phase-based displacement estimation algorithm; the rms error was $0.62~\mu \text{m}$ for the CNN and 0.73 $\mu \text{m}$ for Loupas. Similarly, in the phantom data, the contrast-to-noise ratio (CNR) of a stiff inclusion was 2.27 for the CNN-estimated image and 2.21 for the Loupas-estimated image. Applying the trained network to in vivo data enabled the visualization of prostate cancer and prostate anatomy. The proposed training method provided 26 000 training cases, which allowed robust network training. The CNN had a computation time that was comparable to Loupas’s algorithm; further refinements to the network architecture may provide an improvement in the computation time. We conclude that deep neural network-based displacement estimation from ultrasonic data is feasible, providing comparable performance with respect to both accuracy and speed compared to current standard time-delay estimation approaches.","",""
5,"H. Fang, Yi Zeng, Feifei Zhao","Brain Inspired Sequences Production by Spiking Neural Networks With Reward-Modulated STDP",2021,"","","","",143,"2022-07-13 09:26:17","","10.3389/fncom.2021.612041","","",,,,,5,5.00,2,3,1,"Understanding and producing embedded sequences according to supra-regular grammars in language has always been considered a high-level cognitive function of human beings, named “syntax barrier” between humans and animals. However, some neurologists recently showed that macaques could be trained to produce embedded sequences involving supra-regular grammars through a well-designed experiment paradigm. Via comparing macaques and preschool children's experimental results, they claimed that human uniqueness might only lie in the speed and learning strategy resulting from the chunking mechanism. Inspired by their research, we proposed a Brain-inspired Sequence Production Spiking Neural Network (SP-SNN) to model the same production process, followed by memory and learning mechanisms of the multi-brain region cooperation. After experimental verification, we demonstrated that SP-SNN could also handle embedded sequence production tasks, striding over the “syntax barrier.” SP-SNN used Population-Coding and STDP mechanism to realize working memory, Reward-Modulated STDP mechanism for acquiring supra-regular grammars. Therefore, SP-SNN needs to simultaneously coordinate short-term plasticity (STP) and long-term plasticity (LTP) mechanisms. Besides, we found that the chunking mechanism indeed makes a difference in improving our model's robustness. As far as we know, our work is the first one toward the “syntax barrier” in the SNN field, providing the computational foundation for further study of related underlying animals' neural mechanisms in the future.","",""
15,"J. Hopfield","Understanding Emergent Dynamics: Using a Collective Activity Coordinate of a Neural Network to Recognize Time-Varying Patterns",2015,"","","","",144,"2022-07-13 09:26:17","","10.1162/NECO_a_00768","","",,,,,15,2.14,15,1,7,"Abstract In higher animals, complex and robust behaviors are produced by the microscopic details of large structured ensembles of neurons. I describe how the emergent computational dynamics of a biologically based neural network generates a robust natural solution to the problem of categorizing time-varying stimulus patterns such as spoken words or animal stereotypical behaviors. The recognition of these patterns is made difficult by their substantial variation in cadence and duration. The neural circuit behaviors used are similar to those associated with brain neural integrators. In the larger context described here, this kind of circuit becomes a building block of an entirely different computational algorithm for solving complex problems. While the network behavior is simulated in detail, a collective view is essential to understanding the results. A closed equation of motion for the collective variable describes an algorithm that quantitatively accounts for many aspects of the emergent network computation. The feedback connections and ongoing activity in the network shape the collective dynamics onto a reduced dimensionality manifold of activity space, which defines the algorithm and computation actually performed. The external inputs are weak and are not the dominant drivers of network activity.","",""
0,"Ze Fu, Xiaosha Wang, Xiaoying Wang, Huichao Yang, Jiahuan Wang, Tao Wei, Xuhong Liao, Zhiyuan Liu, Huimin Chen, Y. Bi","Computational mechanisms for neural representation of words",2021,"","","","",145,"2022-07-13 09:26:17","","10.1101/2021.06.27.450093","","",,,,,0,0.00,0,10,1,"A critical way for humans to acquire, represent and communicate information is through language, yet the underlying computation mechanisms through which language contributes to our word meaning representations are poorly understood. We compared three major types of word computation mechanisms from large language corpus (simple co-occurrence, graph-space relations and neural-network-vector-embedding relations) in terms of the association of words’ brain activity patterns, measured by two functional magnetic resonance imaging (fMRI) experiments. Word relations derived from a graph-space representation, and not neural-network-vector-embedding, had unique explanatory power for the neural activity patterns in brain regions that have been shown to be particularly sensitive to language processes, including the anterior temporal lobe (capturing graph-common-neighbors), inferior frontal gyrus, and posterior middle/inferior temporal gyrus (capturing graph-shortest-path). These results were robust across different window sizes and graph sizes and were relatively specific to language inputs. These findings highlight the role of cumulative language inputs in organizing word meaning neural representations and provide a mathematical model to explain how different brain regions capture different types of language-derived information.","",""
0,"M. D. Putro, Duy-Linh Nguyen, K. Jo","A Fast Real-time Facial Expression Classifier Deep Learning-based for Human-robot Interaction",2021,"","","","",146,"2022-07-13 09:26:17","","10.23919/ICCAS52745.2021.9650034","","",,,,,0,0.00,0,3,1,"Human-robot interaction drives the need for vision technology to recognize user expressions. Convolutional Neural Networks (CNN) has been introduced as a robust facial feature extractor and can overcome classification task. However, it is not supported by efficient computation for real-time applications. The work proposes an efficient CNN architecture to recognize human facial expressions that consist of five stages containing a combination of lightweight convolution operations. It introduces the efficient contextual extractor with a partial transfer module to suppress computational compression. This technique is applied to the mid and high-level features by separating the channel-based input features into two parts. Then it applies sequential convolution to only one part and combines it with the previous separated part. A shuffle channel group is used to exchange the information extracted. The structure of the entire network generates less than a million parameters. The CK+ and KDEF datasets are used as training and test sets to evaluate the performance of the proposed architecture. As a result, the proposed classifier obtains an accuracy that is competitive with other methods. In addition, the efficiency of the classifier has strongly suitable for implementation to edge devices by achieving 43 FPS on a Jetson Nano.","",""
14,"Sravanti Addepalli, S. VivekB., Arya Baburaj, Gaurang Sriramanan, R. Venkatesh Babu","Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes",2020,"","","","",147,"2022-07-13 09:26:17","","10.1109/cvpr42600.2020.00110","","",,,,,14,7.00,3,5,2,"As humans, we inherently perceive images based on their predominant features, and ignore noise embedded within lower bit planes. On the contrary, Deep Neural Networks are known to confidently misclassify images corrupted with meticulously crafted perturbations that are nearly imperceptible to the human eye. In this work, we attempt to address this problem by training networks to form coarse impressions based on the information in higher bit planes, and use the lower bit planes only to refine their prediction. We demonstrate that, by imposing consistency on the representations learned across differently quantized images, the adversarial robustness of networks improves significantly when compared to a normally trained model. Present state-of-the-art defenses against adversarial attacks require the networks to be explicitly trained using adversarial samples that are computationally expensive to generate. While such methods that use adversarial training continue to achieve the best results, this work paves the way towards achieving robustness without having to explicitly train on adversarial samples. The proposed approach is therefore faster, and also closer to the natural learning process in humans.","",""
40,"J. Dethier, P. Nuyujukian, S. Ryu, K. Shenoy, K. Boahen","Design and validation of a real-time spiking-neural-network decoder for brain-machine interfaces.",2013,"","","","",148,"2022-07-13 09:26:17","","10.1088/1741-2560/10/3/036008","","",,,,,40,4.44,8,5,9,"OBJECTIVE Cortically-controlled motor prostheses aim to restore functions lost to neurological disease and injury. Several proof of concept demonstrations have shown encouraging results, but barriers to clinical translation still remain. In particular, intracortical prostheses must satisfy stringent power dissipation constraints so as not to damage cortex.   APPROACH One possible solution is to use ultra-low power neuromorphic chips to decode neural signals for these intracortical implants. The first step is to explore in simulation the feasibility of translating decoding algorithms for brain-machine interface (BMI) applications into spiking neural networks (SNNs).   MAIN RESULTS Here we demonstrate the validity of the approach by implementing an existing Kalman-filter-based decoder in a simulated SNN using the Neural Engineering Framework (NEF), a general method for mapping control algorithms onto SNNs. To measure this system's robustness and generalization, we tested it online in closed-loop BMI experiments with two rhesus monkeys. Across both monkeys, a Kalman filter implemented using a 2000-neuron SNN has comparable performance to that of a Kalman filter implemented using standard floating point techniques.   SIGNIFICANCE These results demonstrate the tractability of SNN implementations of statistical signal processing algorithms on different monkeys and for several tasks, suggesting that a SNN decoder, implemented on a neuromorphic chip, may be a feasible computational platform for low-power fully-implanted prostheses. The validation of this closed-loop decoder system and the demonstration of its robustness and generalization hold promise for SNN implementations on an ultra-low power neuromorphic chip using the NEF.","",""
30,"A. Geminiani, C. Casellato, A. Antonietti, E. D’Angelo, A. Pedrocchi","A Multiple-Plasticity Spiking Neural Network Embedded in a Closed-Loop Control System to Model Cerebellar Pathologies",2017,"","","","",149,"2022-07-13 09:26:17","","10.1142/S0129065717500174","","",,,,,30,6.00,6,5,5,"The cerebellum plays a crucial role in sensorimotor control and cerebellar disorders compromise adaptation and learning of motor responses. However, the link between alterations at network level and cerebellar dysfunction is still unclear. In principle, this understanding would benefit of the development of an artificial system embedding the salient neuronal and plastic properties of the cerebellum and operating in closed-loop. To this aim, we have exploited a realistic spiking computational model of the cerebellum to analyze the network correlates of cerebellar impairment. The model was modified to reproduce three different damages of the cerebellar cortex: (i) a loss of the main output neurons (Purkinje Cells), (ii) a lesion to the main cerebellar afferents (Mossy Fibers), and (iii) a damage to a major mechanism of synaptic plasticity (Long Term Depression). The modified network models were challenged with an Eye-Blink Classical Conditioning test, a standard learning paradigm used to evaluate cerebellar impairment, in which the outcome was compared to reference results obtained in human or animal experiments. In all cases, the model reproduced the partial and delayed conditioning typical of the pathologies, indicating that an intact cerebellar cortex functionality is required to accelerate learning by transferring acquired information to the cerebellar nuclei. Interestingly, depending on the type of lesion, the redistribution of synaptic plasticity and response timing varied greatly generating specific adaptation patterns. Thus, not only the present work extends the generalization capabilities of the cerebellar spiking model to pathological cases, but also predicts how changes at the neuronal level are distributed across the network, making it usable to infer cerebellar circuit alterations occurring in cerebellar pathologies.","",""
15,"Lili Su, Chia-Jung Chang, N. Lynch","Spike-Based Winner-Take-All Computation: Fundamental Limits and Order-Optimal Circuits",2019,"","","","",150,"2022-07-13 09:26:17","","10.1162/neco_a_01242","","",,,,,15,5.00,5,3,3,"Winner-take-all (WTA) refers to the neural operation that selects a (typically small) group of neurons from a large neuron pool. It is conjectured to underlie many of the brain's fundamental computational abilities. However, not much is known about the robustness of a spike-based WTA network to the inherent randomness of the input spike trains. In this work, we consider a spike-based k–WTA model wherein n randomly generated input spike trains compete with each other based on their underlying firing rates and k winners are supposed to be selected. We slot the time evenly with each time slot of length 1 ms and model the n input spike trains as n independent Bernoulli processes. We analytically characterize the minimum waiting time needed so that a target minimax decision accuracy (success probability) can be reached. We first derive an information-theoretic lower bound on the waiting time. We show that to guarantee a (minimax) decision error ≤δ (where δ∈(0,1)), the waiting time of any WTA circuit is at least ((1-δ)log(k(n-k)+1)-1)TR,where R⊆(0,1) is a finite set of rates and TR is a difficulty parameter of a WTA task with respect to set R for independent input spike trains. Additionally, TR is independent of δ, n, and k. We then design a simple WTA circuit whose waiting time is Olog1δ+logk(n-k)TR,provided that the local memory of each output neuron is sufficiently long. It turns out that for any fixed δ, this decision time is order-optimal (i.e., it matches the above lower bound up to a multiplicative constant factor) in terms of its scaling in n, k, and TR.","",""
0,"Yaou Zhao, Yuehui Chen, M. Jiang","A novel ensemble of probabilistic neural network for predicting protein-protein interactions",2012,"","","","",151,"2022-07-13 09:26:17","","10.1109/BMEI.2012.6513055","","",,,,,0,0.00,0,3,10,"The knowledge of protein-protein interactions (PPIs) in cells is indispensable for deep understanding the biological process. Although many computational methods have been developed for identification of PPIs, there are still many difficulties due to high computation complexity and noisy data. In this paper, we proposed an ensemble of probabilistic neural network (PNN) to predict PPIs from primary sequence which achieved promising results. The key advantage of the algorithm is that it combines variety of physicochemical property features to construct diverse individual classifiers for ensemble prediction. What makes the method much more attractive is that it not only generated much more diverse and robust individual classifiers, but also contains different interaction physicochemical information which dictated the structure and the function of proteins. Moreover, the PNN is robust to noise and trained easily, it is suitable for dealing with the large scale noisy PPIs data. Experiment results on H. pylori and Human datasets show that our proposed method performs at least 8% higher accuracy than the best of other related works.","",""
2,"F. Khatami, M. Escabí","Spiking network optimized for noise robust word recognition approaches human-level performance and predicts auditory system hierarchy",2018,"","","","",152,"2022-07-13 09:26:17","","10.1101/243915","","",,,,,2,0.50,1,2,4,"The auditory neural code is resilient to acoustic variability and capable of recognizing sounds amongst competing sound sources, yet, the transformations enabling noise robust abilities are largely unknown. We report that a hierarchical spiking neural network (HSNN) trained to maximize word recognition accuracy in noise and multiple talkers approaches human-level performance. Intriguingly, comparisons with data from auditory nerve, midbrain, thalamus and cortex reveals that the organization and nonlinear transformations of the optimal network predict several properties of the ascending auditory pathway including a sequential loss of temporal resolution, increasing sparseness and selectivity. The optimal organizational scheme is critical for noise robustness since an identical network arranged to enable high information transfer does not predict auditory pathway organization and has substantially poorer performance. Furthermore, conventional linear and nonlinear receptive field-based models fail to achieve similar noise robust performance. The findings suggest that the auditory pathway hierarchy and its sequential nonlinear feature extraction computations may form a near optimal code capable of efficiently detecting sounds in noise impoverished conditions. Significance Statement The brain’s ability to recognize sounds in the presence of competing sounds or background noise is essential for everyday hearing tasks. How the brain accomplishes noise resiliency, however, is poorly understood. Using neural recording from the ascending auditory pathway and an auditory spiking network model trained for optimal sound recognition in noise we explore the computational strategies that enable noise robustness. Our results suggest that the hierarchical organization of the auditory pathway and the resulting nonlinear transformations may form a near optimal strategy that is essential for sound recognition in the presence of noise.","",""
0,"Depeng Kong, Geng Yang, Gaoyang Pang, Zhiqiu Ye, Honghao Lv, Zhangwei Yu, Fei Wang, X. Wang, Kaichen Xu, Huayong Yang","Bioinspired Co‐Design of Tactile Sensor and Deep Learning Algorithm for Human–Robot Interaction",2022,"","","","",153,"2022-07-13 09:26:17","","10.1002/aisy.202200050","","",,,,,0,0.00,0,10,1,"Robots equipped with bionic skins for enhancing the robot perception capability are increasingly deployed in wide applications ranging from healthcare to industry. Artificial intelligence algorithms that can provide bionic skins with efficient signal processing functions further accelerate the development of this trend. Inspired by the somatosensory processing hierarchy of humans, the bioinspired co‐design of a tactile sensor and a deep learning‐based algorithm is proposed herein, simplifying the sensor structure while providing computation‐enhanced tactile sensing performance. The soft piezoresistive sensor, based on the carbon black‐coated polyurethane sponge, offers a continuous sensing area. By utilizing a customized deep neural network (DNN), it can detect external tactile stimulus spatially continuously. Besides, a novel data augmentation method is developed based on the sensor's hexagonal structure that has a sixfold rotation symmetry. It can significantly enhance the generalization ability of the DNN model by enriching the collected training data with generated pseudo‐data. The functionality of the sensor and the robustness of the proposed data augmentation strategy are verified by precisely recognizing five touch modalities, illustrating a well‐generalized performance, and providing a promising application prospect in human–robot interaction.","",""
58,"Youshen Xia, Changyin Sun, W. Zheng","Discrete-Time Neural Network for Fast Solving Large Linear $L_{1}$ Estimation Problems and its Application to Image Restoration",2012,"","","","",154,"2022-07-13 09:26:17","","10.1109/TNNLS.2012.2184800","","",,,,,58,5.80,19,3,10,"There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","",""
58,"Zhan Li, M. Hayashibe, C. Fattal, D. Guiraud","Muscle Fatigue Tracking with Evoked EMG via Recurrent Neural Network: Toward Personalized Neuroprosthetics",2014,"","","","",155,"2022-07-13 09:26:17","","10.1109/MCI.2014.2307224","","",,,,,58,7.25,15,4,8,"One of the challenging issues in computational rehabilitation is that there is a large variety of patient situations depending on the type of neurological disorder. Human characteristics are basically subject specific and time variant; for instance, neuromuscular dynamics may vary due to muscle fatigue. To tackle such patient specificity and time-varying characteristics, a robust bio-signal processing and a precise model-based control which can manage the nonlinearity and time variance of the system, would bring break-through and new modality toward computational intelligence (CI) based rehabilitation technology and personalized neuroprosthetics. Functional electrical stimulation (FES) is a useful technique to assist restoring motor capability of spinal cord injured (SCI) patients by delivering electrical pulses to paralyzed muscles. However, muscle fatigue constraints the application of FES as it results in the time-variant muscle response. To perform adaptive closedloop FES control with actual muscle response feedback taken into account, muscular torque is essential to be estimated accurately. However, inadequacy of the implantable torque sensor limits the direct measurement of the time-variant torque at the joint. This motivates the development of methods to estimate muscle torque from bio-signals that can be measured. Evoked electromyogram (eEMG) has been found to be highly correlated with FES-induced torque under various muscle conditions, indicating that it can be used for torque/force prediction. A nonlinear ARX (NARX) type model is preferred to track the relationship between eEMG and stimulated muscular torque. This paper presents a NARX recurrent neural network (NARX-RNN) model for identification/prediction of FES-induced muscular dynamics with eEMG. The NARX-RNN model may possess novelty of robust prediction performance. Due to the difficulty of choosing a proper forgetting factor of Kalman filter for predicting time-variant torque with eEMG, the presented NARX-RNN could be considered as an alternative muscular torque predictor. Data collected from five SCI patients is used to evaluate the proposed NARX-RNN model, and the results show promising estimation performances. In addition, the general importance regarding CI-based motor function modeling is introduced along with its potential impact in the rehabilitation domain. The issue toward personalized neuroprosthetics is discussed in detail with the potential role of CI-based identification and the benefit for motor-impaired patient community.","",""
0,"M. Swarna, N. Sudhakar, N. Vadaparthi","An effective tropical cyclone intensity estimation model using Convolutional Neural Networks",2021,"","","","",156,"2022-07-13 09:26:17","","10.54302/mausam.v72i2.616","","",,,,,0,0.00,0,3,1,"The tropical cyclones in India is a common natural disaster happening every year. As per the statistics, about three cyclones hit India's east coast in the Bay of Bengal, which damaged human lives, crops and property. It is essential to predict the cyclones in advance to prevent and reduce huge damage. The techniques used are based on numerical models that require vast expertise and higher skill sets to achieve better prediction accuracy. The usage of Convolutional Neural Networks shall overcome various issues like domain knowledge, the scope for human errors. Hence, in this paper, we attempted to predict cyclone intensity using Convolutional Neural Networks by proposing a simple and robust architecture for Tropical Cyclone intensity estimation. The results yielded better performance than the state-of-the-art techniques with reduced computation time.","",""
6,"Yang Yu, M. Rashidi, B. Samali, Masoud Mohammadi, T. N. Nguyen, Xinxiu Zhou","Crack detection of concrete structures using deep convolutional neural networks optimized by enhanced chicken swarm algorithm",2022,"","","","",157,"2022-07-13 09:26:17","","10.1177/14759217211053546","","",,,,,6,6.00,1,6,1,"With the rapid increase of ageing infrastructures worldwide, effective and robust inspection techniques are highly demanding to evaluate structural conditions and residual lifetime. The damages on structural surfaces, for example, spalling, crack, rebar buckling and exposure, are important indicators to assess the structural condition. In fact, several state-of-the-art automated inspection techniques using these indicators have been developed to reduce human-conducted onsite inspection activities. However, the efficiency of these techniques is still required to be improved in terms of accuracy and computational cost. In this study, a vision-based crack diagnosis method is developed using deep convolutional neural network (DCNN) and enhanced chicken swarm algorithm (ECSA). A DCNN model is designed with a deep architecture, consisting of six convolutional layers, two pooling layers and three fully connected layers. To enhance the generalisation capacity of trained model, ECSA is introduced to optimize meta-parameters of the DCNN model. The model is trained and tested using image patches cropped from raw images obtained from damaged concrete samples. Finally, a comparative study on different crack detection techniques is conducted to evaluate performance of the proposed method via a group of statistical evaluation indicators.","",""
23,"F. Glang, A. Deshmane, S. Prokudin, F. Martin, K. Herz, T. Lindig, B. Bender, K. Scheffler, M. Zaiss","DeepCEST 3T: Robust MRI parameter determination and uncertainty quantification with neural networks—application to CEST imaging of the human brain at 3T",2019,"","","","",158,"2022-07-13 09:26:17","","10.1002/mrm.28117","","",,,,,23,7.67,3,9,3,"Calculation of sophisticated MR contrasts often requires complex mathematical modeling. Data evaluation is computationally expensive, vulnerable to artifacts, and often sensitive to fit algorithm parameters. In this work, we investigate whether neural networks can provide not only fast model fitting results, but also a quality metric for the predicted values, so called uncertainty quantification, investigated here in the context of multi‐pool Lorentzian fitting of CEST MRI spectra at 3T.","",""
17,"Bin Hu, Shigang Yue, Zhuhong Zhang","A Rotational Motion Perception Neural Network Based on Asymmetric Spatiotemporal Visual Information Processing",2017,"","","","",159,"2022-07-13 09:26:17","","10.1109/TNNLS.2016.2592969","","",,,,,17,3.40,6,3,5,"All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts—presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.","",""
0,"Ziwei Chen, Yiye Wang, Wankou Yang","Video Based Fall Detection Using Human Poses",2021,"","","","",160,"2022-07-13 09:26:17","","10.1007/978-981-16-9709-8_19","","",,,,,0,0.00,0,3,1,"","",""
53,"R. Tripathi, Sunil Patel, V. Kumari, P. Chakraborty, P. Varadwaj","DeepLNC, a long non-coding RNA prediction tool using deep neural network",2016,"","","","",161,"2022-07-13 09:26:17","","10.1007/s13721-016-0129-2","","",,,,,53,8.83,11,5,6,"","",""
1,"Manh-Quan Bui, Viet-Hang Duong, Tzu-Chiang Tai, Jia-Ching Wang","Depth Human Action Recognition Based on Convolution Neural Networks and Principal Component Analysis",2018,"","","","",162,"2022-07-13 09:26:17","","10.1109/ICIP.2018.8451232","","",,,,,1,0.25,0,4,4,"In this work, we address human action recognition problem under viewpoint variation. The proposed model is formulated by wisely combining convolution neural network (CNN) model with principle component analysis (PCA). In this context, we pass real depth videos through a CNN model in a frame-wise manner. The view invariant features are extracted by employing convolution layers as mid-outputs and considered as 3D nonnegative tensors. The PCA algorithm is separately imposed on view-invariant high-level space of image and video groups to seek both local and holistic hidden dynamics information. To deal with noisy data and temporal misalignment, we utilize the Fourier temporal pyramid to encode temporal and obtain the final descriptors. Our proposed framework supplies a robust discriminative representation with low dimension and computational requirements. We evaluate the proposed method on two standard multiview depth video datasets. The experimental results show that our method has superior performance compared to other approaches.","",""
1,"Gustav Müller-Franzes, T. Nolte, Malin Ciba, Justus Schock, Firas Khader, A. Prescher, L. M. Wilms, C. Kuhl, S. Nebelung, D. Truhn","Fast, Accurate, and Robust T2 Mapping of Articular Cartilage by Neural Networks",2022,"","","","",163,"2022-07-13 09:26:17","","10.3390/diagnostics12030688","","",,,,,1,1.00,0,10,1,"For T2 mapping, the underlying mono-exponential signal decay is traditionally quantified by non-linear Least-Squares Estimation (LSE) curve fitting, which is prone to outliers and computationally expensive. This study aimed to validate a fully connected neural network (NN) to estimate T2 relaxation times and to assess its performance versus LSE fitting methods. To this end, the NN was trained and tested in silico on a synthetic dataset of 75 million signal decays. Its quantification error was comparatively evaluated against three LSE methods, i.e., traditional methods without any modification, with an offset, and one with noise correction. Following in-situ acquisition of T2 maps in seven human cadaveric knee joint specimens at high and low signal-to-noise ratios, the NN and LSE methods were used to estimate the T2 relaxation times of the manually segmented patellofemoral cartilage. In-silico modeling at low signal-to-noise ratio indicated significantly lower quantification error for the NN (by medians of 6–33%) than for the LSE methods (p < 0.001). These results were confirmed by the in-situ measurements (medians of 10–35%). T2 quantification by the NN took only 4 s, which was faster than the LSE methods (28–43 s). In conclusion, NNs provide fast, accurate, and robust quantification of T2 relaxation times.","",""
0,"Sergey Bochkanov","On sparse connectivity, adversarial robustness, and a novel model of the artificial neuron",2020,"","","","",164,"2022-07-13 09:26:17","","10.1007/978-3-030-66096-3_25","","",,,,,0,0.00,0,1,2,"","",""
0,"Liu Yuezhang, Bo Li, Qifeng Chen","Evaluating adversarial robustness in simulated cerebellum",2020,"","","","",165,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,3,2,"It is well known that artificial neural networks are vulnerable to adversarial examples, in which great efforts have been made to improve the robustness. However, such examples are usually imperceptible to humans, thus their effect on biological neural circuits is largely unknown. This paper will investigate the adversarial robustness in a simulated cerebellum, a well-studied supervised learning system in computational neuroscience. Specifically, we propose to study three unique characteristics revealed in the cerebellum: (i) network width; (ii) long-term depression on the parallel fiber-Purkinje cell synapses; (iii) sparse connectivity in the granule layer, and hypothesize that they will be beneficial for improving robustness. To the best of our knowledge, this is the first attempt to examine the adversarial robustness in simulated cerebellum models. We wish to remark that both of the positive and negative results are indeed meaningful -- if the answer is in the affirmative, engineering insights are gained from the biological model into designing more robust learning systems; otherwise, neuroscientists are encouraged to fool the biological system in experiments with adversarial attacks -- which makes the project especially suitable for a pre-registration study.","",""
17,"Á. F. Kungl, Sebastian Schmitt, Johann Klähn, Paul Müller, A. Baumbach, D. Dold, Alexander Kugele, Eric Müller, Christoph Koke, Mitja Kleider, Christian Mauch, O. Breitwieser, Luziwei Leng, Nico Gürtler, M. Güttler, D. Husmann, Kai Husmann, Andreas Hartel, V. Karasenko, A. Grübl, J. Schemmel, K. Meier, M. Petrovici","Accelerated Physical Emulation of Bayesian Inference in Spiking Neural Networks",2018,"","","","",166,"2022-07-13 09:26:17","","10.3389/fnins.2019.01201","","",,,,,17,4.25,2,23,4,"The massively parallel nature of biological information processing plays an important role due to its superiority in comparison to human-engineered computing devices. In particular, it may hold the key to overcoming the von Neumann bottleneck that limits contemporary computer architectures. Physical-model neuromorphic devices seek to replicate not only this inherent parallelism, but also aspects of its microscopic dynamics in analog circuits emulating neurons and synapses. However, these machines require network models that are not only adept at solving particular tasks, but that can also cope with the inherent imperfections of analog substrates. We present a spiking network model that performs Bayesian inference through sampling on the BrainScaleS neuromorphic platform, where we use it for generative and discriminative computations on visual data. By illustrating its functionality on this platform, we implicitly demonstrate its robustness to various substrate-specific distortive effects, as well as its accelerated capability for computation. These results showcase the advantages of brain-inspired physical computation and provide important building blocks for large-scale neuromorphic applications.","",""
12,"Á. Martínez-González, M. Villamizar, Olivier Can'evet, J. Odobez","Efficient Convolutional Neural Networks for Depth-Based Multi-Person Pose Estimation",2019,"","","","",167,"2022-07-13 09:26:17","","10.1109/TCSVT.2019.2952779","","",,,,,12,4.00,3,4,3,"Achieving robust multi-person 2D body landmark localization and pose estimation is essential for human behavior and interaction understanding as encountered for instance in HRI settings. Accurate methods have been proposed recently, but they usually rely on rather deep Convolutional Neural Network (CNN) architecture, thus requiring large computational and training resources. In this paper, we investigate different architectures and methodologies to address these issues and achieve fast and accurate multi-person 2D pose estimation. To foster speed, we propose to work with depth images, whose structure contains sufficient information about body landmarks while being simpler than textured color images and thus potentially requiring less complex CNNs for processing. In this context, we make the following contributions. i) we study several CNN architecture designs combining pose machines relying on the cascade of detectors concept with lightweight and efficient CNN structures; ii) to address the need for large training datasets with high variability, we rely on semi-synthetic data combining multi-person synthetic depth data with real sensor backgrounds; iii) we explore domain adaptation techniques to address the performance gap introduced by testing on real depth images; iv) to increase the accuracy of our fast lightweight CNN models, we investigate knowledge distillation at several architecture levels which effectively enhance performance. Experiments and results on synthetic and real data highlight the impact of our design choices, providing insights into methods addressing standard issues normally faced in practical applications, and resulting in architectures effectively matching our goal in both performance and speed.","",""
19,"He Xu, Chang Shu-juan","An Adaptive Image Watermarking Algorithm Based on Neural Network",2011,"","","","",168,"2022-07-13 09:26:17","","10.1109/ICICTA.2011.386","","",,,,,19,1.73,10,2,11,"According to the characteristic of Human Visual System and the association memory ability of neural network, an adaptive image watermarking algorithm based on neural network is proposed. The watermarking signal is embedded in higher frequency, which is in the lower frequency of original image by DWT joined with DCT. The ability of attracting is improved by pretreatment and re-treatment of image scrambling and Hop field network. Experimental results show that the embedded digital watermarking is invisible and robust enough against common image processing such as JPEG compression, noises, filter and shearing.","",""
0,"Zheyuan Wang, M. Gombolay","Stochastic Resource Optimization over Heterogeneous Graph Neural Networks for Failure-Predictive Maintenance Scheduling",2022,"","","","",169,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,2,1,"Resource optimization for predictive maintenance is a challenging computational problem that requires inferring and reasoning over stochastic failure models and dynamically allocating repair resources. Predictive maintenance scheduling is typically performed with a combination of ad hoc, handcrafted heuristics with manual scheduling corrections by human domain experts, which is a labor-intensive process that is hard to scale. In this paper, we develop an innovative heterogeneous graph neural network to automatically learn an end-to-end resource scheduling policy. Our approach is fully graph-based with the addition of state summary and decision value nodes that provides a computationally lightweight and nonparametric means to perform dynamic scheduling. We augment our policy optimization procedure to enable robust learning in highly stochastic environments for which typical actor-critic reinforcement learning methods are ill-suited. In consultation with aerospace industry partners, we develop a virtual predictive-maintenance environment for a heterogeneous fleet of aircraft, called AirME. Our approach sets a new state-of-the-art by outperforming conventional, hand-crafted heuristics and baseline learning methods across problem sizes and various objective functions.","",""
68,"Qiang Yu, Rui Yan, Huajin Tang, K. Tan, Haizhou Li","A Spiking Neural Network System for Robust Sequence Recognition",2016,"","","","",170,"2022-07-13 09:26:17","","10.1109/TNNLS.2015.2416771","","",,,,,68,11.33,14,5,6,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.","",""
33,"V. Nguyen, J. Starzyk, Wooi-Boon Goh, Daniel Jachyra","Neural Network Structure for Spatio-Temporal Long-Term Memory",2012,"","","","",171,"2022-07-13 09:26:17","","10.1109/TNNLS.2012.2191419","","",,,,,33,3.30,8,4,10,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","",""
2723,"S. Lawrence, C. Lee Giles, A. Tsoi, A. Back","Face recognition: a convolutional neural-network approach",1997,"","","","",172,"2022-07-13 09:26:17","","10.1109/72.554195","","",,,,,2723,108.92,681,4,25,"We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.","",""
16,"Tamas Jantvik, L. Gustafsson, A. Paplinski","A Self-Organized Artificial Neural Network Architecture for Sensory Integration with Applications to Letter-Phoneme Integration",2011,"","","","",173,"2022-07-13 09:26:17","","10.1162/NECO_a_00149","","",,,,,16,1.45,5,3,11,"The multimodal self-organizing network (MMSON), an artificial neural network architecture carrying out sensory integration, is presented here. The architecture is designed using neurophysiological findings and imaging studies that pertain to sensory integration and consists of interconnected lattices of artificial neurons. In this artificial neural architecture, the degree of recognition of stimuli, that is, the perceived reliability of stimuli in the various subnetworks, is included in the computation. The MMSON's behavior is compared to aspects of brain function that deal with sensory integration. According to human behavioral studies, integration of signals from sensory receptors of different modalities enhances perception of objects and events and also reduces time to detection. In neocortex, integration takes place in bimodal and multimodal association areas and result, not only in feedback-mediated enhanced unimodal perception and shortened reaction time, but also in robust bimodal or multimodal percepts. Simulation data from the presented artificial neural network architecture show that it replicates these important psychological and neuroscientific characteristics of sensory integration.","",""
1,"S. Jaiswal, G. Nandi","Hyperparameters optimization for Deep Learning based emotion prediction for Human Robot Interaction",2020,"","","","",174,"2022-07-13 09:26:17","","","","",,,,,1,0.50,1,2,2,"To enable humanoid robots to share our social space we need to develop technology for easy interaction with the robots using multiple modes such as speech, gestures and share our emotions with them. We have targeted this research towards addressing the core issue of emotion recognition problem which would require less computation resources and much lesser number of network hyperparameters which will be more adaptive to be computed on low resourced social robots for real time communication. More specifically, here we have proposed an Inception module based Convolutional Neural Network Architecture which has achieved improved accuracy of upto 6% improvement over the existing network architecture for emotion classification when combinedly tested over multiple datasets when tried over humanoid robots in real - time. Our proposed model is reducing the trainable Hyperparameters to an extent of 94% as compared to vanilla CNN model which clearly indicates that it can be used in real time based application such as human robot interaction. Rigorous experiments have been performed to validate our methodology which is sufficiently robust and could achieve high level of accuracy. Finally, the model is implemented in a humanoid robot, NAO in real time and robustness of the model is evaluated.","",""
0,"Jing Huang","Knowledge graph representation learning and graph neural networks for language understanding",2022,"","","","",175,"2022-07-13 09:26:17","","10.1145/3534540.3534710","","",,,,,0,0.00,0,1,1,"As AI technologies become mature in natural language processing, speech recognition and computer vision, ""intelligent"" user interfaces emerge to handle complex and diverse tasks that require human-like knowledge and reasoning capability. In Part 1, I will present our recent work on knowledge graph representation learning using Graph Neural Networks (GNNs): the first approach is called orthogonal transform embedding (OTE), which integrates graph context into the embedding distance scoring function and improves prediction accuracy on complex relations such as the difficult N-to-1, 1-to-N and N-to-N cases; the second approach is called multi-hop attention GNN (MAGNA), a principled way to incorporate multi-hop context information into every layer of attention computation. MAGNA uses a diffusion prior on attention values, to efficiently account for all paths between the pair of disconnected nodes. Experimental results on knowledge graph completion as well as node classification benchmarks show that MAGNA achieves state-of-the-art results. In Part 2, I will present how we take advantage of GNNs for language understanding and reasoning tasks. We show that combined with large pre-trained language models and knowledge graph embeddings, GNNs are proven effective in multi-hop reading comprehension across documents, improving time sensitivity for question answering over temporal knowledge graphs, and constructing robust syntactic information for aspect-level sentiment analysis.","",""
0,"T. P. Moreira, M. C. Santana, L. A. Passos, J. Papa, K. Costa","An End-to-End Approach for Seam Carving Detection using Deep Neural Networks",2022,"","","","",176,"2022-07-13 09:26:17","","10.48550/arXiv.2203.02728","","",,,,,0,0.00,0,5,1,"Seam carving is a computational method capable of resizing images for both reduction and expansion based on its content, instead of the image geometry. Although the technique is mostly employed to deal with redundant information, i.e., regions composed of pixels with similar intensity, it can also be used for tampering images by inserting or removing relevant objects. Therefore, detecting such a process is of extreme importance regarding the image security domain. However, recognizing seam-carved images does not represent a straightforward task even for human eyes, and robust computation tools capable of identifying such alterations are very desirable. In this paper, we propose an end-to-end approach to cope with the problem of automatic seam carving detection that can obtain state-of-the-art results. Experiments conducted over public and private datasets with several tampering configurations evidence the suitability of the proposed model.","",""
0,"S. Cawley","Hardware spiking neural network and remote FPGA lab",2013,"","","","",177,"2022-07-13 09:26:17","","","","",,,,,0,0.00,0,1,9,"College of Engineering and Informatics Electrical & Electronic Engineering Doctor of Philosophy Hardware Spiking Neural Network and Remote FPGA Lab by Seamus Cawley The automatic design of intelligent systems has been inspired by biology, specifically the operation of the human brain. Researchers hope to exploit and replicate the brain’s ability to adapt and self repair in order to develop robust and error tolerant embedded hardware computational devices. Spiking Neural Networks (SNNs) emulate neural behaviour observed in biology. This thesis describes the successful development of a Networkon-Chip based hardware SNN(EMBRACE-FPGA) and the supporting GA-based SNN training and application implementation tools (SNNDevSys). Hardware SNNs can be configured for multiple applications through programming of neuron spike firing threshold potentials, synaptic weights and the hardware SNN interconnection topology. This thesis describes the hardware SNN architecture and prototype and its application to a range of benchmark control and classification problems. This work has contributed to ongoing EMBRACE-FPGA architecture development within the Bio-Inspired and Reconfigurable Computing research group to improve practical hardware SNN scalability. Phase II of this thesis describes the development of the Remote FPGA Laboratory (RFL). In recent years there has been a growing interest in the development of webbased e-learning systems. The RFL is a web-based distance learning application which enables the teaching of digital systems design using real FPGA devices through a standard web browser. The RFL allows users to configure and interact with FPGA devices via the Internet as part of a combined training and evaluation framework. The system has been designed as an interactive learning tool, which aims to increase student interaction and understanding through a learn-by-doing approach. The system enables better understanding of the operation of digital systems through animation of internal signals, real-time timing diagrams and single-stepping of hardware circuits.","",""
22,"Hongru Zhu, Peng Tang, A. Yuille","Robustness of Object Recognition under Extreme Occlusion in Humans and Computational Models",2019,"","","","",178,"2022-07-13 09:26:17","","","","",,,,,22,7.33,7,3,3,"Most objects in the visual world are partially occluded, but humans can recognize them without difficulty. However, it remains unknown whether object recognition models like convolutional neural networks (CNNs) can handle real-world occlusion. It is also a question whether efforts to make these models robust to constant mask occlusion are effective for real-world occlusion. We test both humans and the above-mentioned computational models in a challenging task of object recognition under extreme occlusion, where target objects are heavily occluded by irrelevant real objects in real backgrounds. Our results show that human vision is very robust to extreme occlusion while CNNs are not, even with modifications to handle constant mask occlusion. This implies that the ability to handle constant mask occlusion does not entail robustness to real-world occlusion. As a comparison, we propose another computational model that utilizes object parts/subparts in a compositional manner to build robustness to occlusion. This performs significantly better than CNN-based models on our task with error patterns similar to humans. These findings suggest that testing under extreme occlusion can better reveal the robustness of visual recognition, and that the principle of composition can encourage such robustness.","",""
0,"Shome S. Das","A data-set and a method for pointing direction estimation from depth images for human-robot interaction and VR applications",2021,"","","","",179,"2022-07-13 09:26:17","","10.1109/ICRA48506.2021.9561143","","",,,,,0,0.00,0,1,1,"3D pointing devices are indispensable in virtual reality (hereafter VR) and human-robot interaction scenarios. Existing devices are cumbersome or non-immersive or have a limited volume of operation. Hand gesture-based interfaces do not suffer from these problems and can be used for 3D pointing purposes. However, there is a lack of robust, accurate hand gesture-based pointing techniques which can be attributed to the non-existence of large and accurate data-set for the same. To overcome this barrier, we propose a data-set consisting of depth images with a large number (107000) of samples collected from 11 subjects, with accurate ground-truth and adequate variation in the orientation and distance of the hand w.r.t. the camera. We propose a 3D convolutional neural network based technique that works on the proposed data-set and achieves an accuracy of 94.49% for an angle error threshold of 10 degrees. The proposed data-set may be used for developing more accurate, robust, less computationally expensive methods.","",""
0,"Wei Li, Han Zhang, Qing Zhao, Jian Liu, Yanbin Yin","Adversarial Dual-Channel Variational Graph Autoencoder for Synthetic Lethality Prediction in Human Cancers",2021,"","","","",180,"2022-07-13 09:26:17","","10.1109/BIBM52615.2021.9669763","","",,,,,0,0.00,0,5,1,"Synthetic Lethality (SL) is a type of vital gene interaction that can lead to various human diseases including cancers. Therefore, SL gene pair prediction can aid in the prevention and treatment of cancer. A number of computational approaches, especially Graph Neural Network (GNN) based methods, have been proposed for this link prediction problem on the graph. However, these GNN-based methods only consider embedding as deterministic vectors and do not take data distribution into account. Here we propose an Adversarial Dual-Channel Variational Graph Autoencoder based on semi-implicit variational inference for SL prediction in human cancers. We consider node embedding as a random variable that has an explicit Gaussian distribution. Then we design a dual-channel GCN encoder to inject stochasticity into the distribution parameters and allow latent embedding to exceed the Gaussian distribution. This hierarchical scheme leads to a more flexible posterior of latent embedding and enhances the model representation capacity. To further obtain a robust and stable representation, an adversarial module is devised for variance regularization. Experimental results compared with other state-of-the-art methods confirm the effectiveness of our proposed method. Moreover, we conduct a case study to demonstrate that our model can be very useful to predict novel SL pairs.","",""
0,"Edwin Kwadwo Tenagyei, Zongbo Hao, Kwadwo Kusi, K. Sarpong","Robust Real-Time Human Action Detection through the Fusion of 3D and 2D CNN",2021,"","","","",181,"2022-07-13 09:26:17","","10.1109/PRML52754.2021.9520696","","",,,,,0,0.00,0,4,1,"Recent approaches for human action detection often rely on appearance and optical flow networks for frame-level detections before linking them to form action tubes. However, they achieve unsatisfactory performance in real-time due to their huge computational complexity and large parameter usage during training. In this paper, we design and implement a unified end-to-end convolutional neural network (CNN) architecture that consists of two branches, extracting both spatial and temporal information concurrently before predicting bounding boxes and action probabilities from video clips. We also design a novel mechanism that exploits the inter-channel dependencies for an effective fusion of features from the branches. Specifically, we propose a Channel Fusion and Relation-Global Attention (CFRGA) module to aggregate the two features smoothly and model their inter-channel dependencies by considering their global scope structural relation information when inferring attention. We conduct experiments on the untrimmed video dataset, UCF101-24, and achieved impressive results in frame-mAP and video-mAP. The experimental results show that our channel fusion and relation-global attention module contributes to its good performance.","",""
0,"M. Younis, Masood Salik, S. T. Gul, Abdul Aleem","Automatic Human Facial Affect Classification Using Computational Intelligence Techniques",2021,"","","","",182,"2022-07-13 09:26:17","","10.1109/MAJICC53071.2021.9526237","","",,,,,0,0.00,0,4,1,"Automatic and robust emotion recognition is of prime concern while designing affect-sensitive machines for human-computer interaction to fully understand the emotional context implicated. This paper presents the development of a Decision Tree (DT) based scheme for the automatic classification of elementary human facial emotions. In order to implement affect classification algorithms, this research employs the Cohn-Kanade dataset based on facial features. Action units are mapped to emotion labels using the Facial Action Coding System (FACS); these labels serve as targets for supervised learning. The proposed scheme is validated through simulation, and results are compared to the existing techniques like Back Propagation Neural Network (BPNN) and Support Vector Machine (SVM). The presented results substantiate that the classification scheme suggested in this paper performs extensively superior than other alternatives in terms of accuracy with minimal computational efforts. Hence, DT based affect classification algorithm is an excellent alternative for applications comprising emotion recognition.","",""
11,"J. Bouvrie, J. Slotine","Synchronization and Redundancy: Implications for Robustness of Neural Learning and Decision Making",2010,"","","","",183,"2022-07-13 09:26:17","","10.1162/NECO_a_00183","","",,,,,11,0.92,6,2,12,"Learning and decision making in the brain are key processes critical to survival, and yet are processes implemented by nonideal biological building blocks that can impose significant error. We explore quantitatively how the brain might cope with this inherent source of error by taking advantage of two ubiquitous mechanisms, redundancy and synchronization. In particular we consider a neural process whose goal is to learn a decision function by implementing a nonlinear gradient dynamics. The dynamics, however, are assumed to be corrupted by perturbations modeling the error, which might be incurred due to limitations of the biology, intrinsic neuronal noise, and imperfect measurements. We show that error, and the associated uncertainty surrounding a learned solution, can be controlled in large part by trading off synchronization strength among multiple redundant neural systems against the noise amplitude. The impact of the coupling between such redundant systems is quantified by the spectrum of the network Laplacian, and we discuss the role of network topology in synchronization and in reducing the effect of noise. We discuss range of situations in which the mechanisms we model arise in brain science and draw attention to experimental evidence suggesting that cortical circuits capable of implementing the computations of interest here can be found on several scales. Finally, simulations comparing theoretical bounds to the relevant empirical quantities show that the theoretical estimates we derive can be tight.","",""
0,"Yiming Li, Min Zeng, Yifan Wu, Yaohang Li, Min Li","Accurate Prediction of Human Essential Proteins Using Ensemble Deep Learning.",2021,"","","","",184,"2022-07-13 09:26:17","","10.1109/TCBB.2021.3122294","","",,,,,0,0.00,0,5,1,"Essential proteins are considered the foundation of life as they are indispensable for the survival of living organisms. Computational methods for essential protein discovery provide a fast way to identify essential proteins. But most of them heavily rely on various biological information, especially protein-protein interaction networks, which limits their practical applications. With the rapid development of high-throughput sequencing technology, sequencing data has become the most accessible biological data. However, using only protein sequence information to predict essential proteins has limited accuracy. In this paper, we propose EP-EDL, an ensemble deep learning model using only protein sequence information to predict human essential proteins. EP-EDL integrates multiple classifiers to alleviate the class imbalance problem and to improve prediction accuracy and robustness. In each base classifier, we employ multi-scale text convolutional neural networks to extract useful features from protein sequence feature matrices with evolutionary information. Our computational results show that EP-EDL outperforms the state-of-the-art sequence-based methods. Furthermore, EP-EDL provides a more practical and flexible way for biologists to accurately predict essential proteins. The source code and datasets can be downloaded from https://github.com/CSUBioGroup/EP-EDL.","",""
30,"M. Goubran, Emmanuel E. Ntiri, H. Akhavein, M. Holmes, S. Nestor, J. Ramirez, S. Adamo, M. Ozzoude, C. Scott, Fuqiang Gao, Anne L. Martel, W. Swardfager, M. Masellis, R. Swartz, B. MacIntosh, S. Black","Hippocampal segmentation for brains with extensive atrophy using three‐dimensional convolutional neural networks",2019,"","","","",185,"2022-07-13 09:26:17","","10.1002/hbm.24811","","",,,,,30,10.00,3,16,3,"Hippocampal volumetry is a critical biomarker of aging and dementia, and it is widely used as a predictor of cognitive performance; however, automated hippocampal segmentation methods are limited because the algorithms are (a) not publicly available, (b) subject to error with significant brain atrophy, cerebrovascular disease and lesions, and/or (c) computationally expensive or require parameter tuning. In this study, we trained a 3D convolutional neural network using 259 bilateral manually delineated segmentations collected from three studies, acquired at multiple sites on different scanners with variable protocols. Our training dataset consisted of elderly cases difficult to segment due to extensive atrophy, vascular disease, and lesions. Our algorithm, (HippMapp3r), was validated against four other publicly available state‐of‐the‐art techniques (HippoDeep, FreeSurfer, SBHV, volBrain, and FIRST). HippMapp3r outperformed the other techniques on all three metrics, generating an average Dice of 0.89 and a correlation coefficient of 0.95. It was two orders of magnitude faster than some of the tested techniques. Further validation was performed on 200 subjects from two other disease populations (frontotemporal dementia and vascular cognitive impairment), highlighting our method's low outlier rate. We finally tested the methods on real and simulated “clinical adversarial” cases to study their robustness to corrupt, low‐quality scans. The pipeline and models are available at: https://hippmapp3r.readthedocs.ioto facilitate the study of the hippocampus in large multisite studies.","",""
1,"Leonard E. van Dyck, W. Gruber","Seeing Eye-to-Eye? A Comparison of Object Recognition Performance in Humans and Deep Convolutional Neural Networks under Image Manipulation",2020,"","","","",186,"2022-07-13 09:26:17","","","","",,,,,1,0.50,1,2,2,"For a considerable time, deep convolutional neural networks (DCNNs) have reached human benchmark performance in object recognition. On that account, computational neuroscience and the field of machine learning have started to attribute numerous similarities and differences to artificial and biological vision. This study aims towards a behavioral comparison of visual core object recognition between humans and feedforward neural networks in a classification learning paradigm on an ImageNet data set. For this purpose, human participants (n = 65) competed in an online experiment against different feedforward DCNNs. The designed approach based on a typical learning process of seven different monkey categories included a training and validation phase with natural examples, as well as a testing phase with novel shape and color manipulations. Analyses of accuracy revealed that humans not only outperform DCNNs on all conditions, but also display significantly greater robustness towards shape and most notably color alterations. Furthermore, a precise examination of behavioral patterns highlights these findings by revealing independent classification errors between the groups. The obtained results endorse an implementation of recurrent circuits similar to the primate ventral stream in artificial vision models as a way to achieve adequate object generalization abilities across unexperienced manipulations.","",""
4,"G. Narasimhulu, Dr. S. A. K. Jilani","Back Propagation Neural Network based Gait Recognition",2012,"","","","",187,"2022-07-13 09:26:17","","","","",,,,,4,0.40,2,2,10,"We describe a new method for recognizing humans by their gait using back propagation neural network(BPNN), BPNN algorithm is used to recognize humans by their gait patterns. Automatic gait recognition using Fourier descriptors and independent component analysis (ICA) for the purpose of human identification at a distance. Firstly, a simple background generation algorithm is introduced to subtract the moving figures accurately and to obtain binary human silhouettes. Secondly, these silhouettes are described with Fourier descriptors and converted into associated onedimension signals. Then ICA is applied to get the independent components of the signals. For reducing the computational cost, a fast and robust fixed-point algorithm for calculating ICs is adopted and a criterion how to select ICs is put forward. Lastly, the nearest neighbour (NN), support vector machine (SVM) and back propagation neural network (BPNN) classifiers are chosen for recognition and this method is tested on the small UMD gait database and the NLPR gait database. Gait recognition aims essentially to address this problem by identifying people based on the way they walk [1]. Gait recognition has 3 steps. The first step is pre-processing, the second step is feature extraction and the third one is classification. This paper focuses on the classification step that is essential to increase the CCR (Correct Classification Rate). Multilayer Perceptron (MLP) is used in this work. In this paper we apply MLP NN for 11 views in our database and compare the CCR values for these views. In experiments, higher gait recognition performances have been achieved.","",""
1324,"Jiawei Su, Danilo Vasconcellos Vargas, K. Sakurai","One Pixel Attack for Fooling Deep Neural Networks",2017,"","","","",188,"2022-07-13 09:26:17","","10.1109/TEVC.2019.2890858","","",,,,,1324,264.80,441,3,5,"Recent research has revealed that the output of deep neural networks (DNNs) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97% of the natural images in Kaggle CIFAR-10 test dataset and 16.04% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03% and 22.91% confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness.","",""
3,"H. Wahid","Neural network-based metamodelling approach for estimation of air pollutant profiles",2013,"","","","",189,"2022-07-13 09:26:17","","","","",,,,,3,0.33,3,1,9,"The air quality system is a system characterised by non-linear, complex relationships. Among existing air pollutants, the ozone (O3), known as a secondary pollutant gas, involves the most complex chemical reactions in its formation, whereby a number of factors can affect its concentration level. To assess the ozone concentration in a region, a measurement method can be implemented, albeit only at certain points in the region. Thus, a more complicated task is to define the spatial distribution of the ozone level across the region, in which the deterministic air quality model is often used by the authority. Nevertheless, simulation by using a deterministic model typically needs high computational requirements due to the nonlinear nature of chemical reactions involved in the model formulation, which is also subject to uncertainties. In the context of ozone as an air pollutant, the determination of the background ozone level (BOL), independent from human activities, is also important as it could represent one of reliable references to human health risk assessment. The concept of BOL may be easily understood, but practically, it is hard to distinguish between natural and anthropogenic effects. Apart from existing approaches to the BOL determination, a new quantisation method is presented in this work, by evaluating the relationship of ozone versus nitric oxide (O3-NO) to estimate the BOL value, mainly by using night-time and early morning measurement data collected at the monitoring stations. In this thesis, to deal with the challenging problem of air pollutant profile estimation, a metamodel approach is suggested to adequately approximate intrinsically nonlinear and complex input-output relationships with significantly less computation. The intrinsic characteristics of the underlying physics are not assumed to be known, while the system’s input and output behaviours remain essential. A considerable number of metamodels approach have been proposed in the literature, e.g. splines, neural networks, kriging and support vector machine. Here, the radial basis function neural network (RBFNN) is concerned as it is known to offer good estimation performance on accuracy, robustness, versatility, sample size, efficiency, and","",""
267,"Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh","Towards Robust Neural Networks via Random Self-ensemble",2017,"","","","",190,"2022-07-13 09:26:17","","10.1007/978-3-030-01234-2_23","","",,,,,267,53.40,67,4,5,"","",""
1,"Zhouning Du, H. Mukaidani","Linear dynamical systems approach for human action recognition with dual-stream deep features",2021,"","","","",191,"2022-07-13 09:26:17","","10.1007/S10489-021-02367-6","","",,,,,1,1.00,1,2,1,"","",""
18,"Francesco Donnarumma, R. Prevete, F. Chersi, G. Pezzulo","A Programmer-Interpreter Neural Network Architecture for Prefrontal Cognitive Control",2015,"","","","",192,"2022-07-13 09:26:17","","10.1142/S0129065715500173","","",,,,,18,2.57,5,4,7,"There is wide consensus that the prefrontal cortex (PFC) is able to exert cognitive control on behavior by biasing processing toward task-relevant information and by modulating response selection. This idea is typically framed in terms of top-down influences within a cortical control hierarchy, where prefrontal-basal ganglia loops gate multiple input-output channels, which in turn can activate or sequence motor primitives expressed in (pre-)motor cortices. Here we advance a new hypothesis, based on the notion of programmability and an interpreter-programmer computational scheme, on how the PFC can flexibly bias the selection of sensorimotor patterns depending on internal goal and task contexts. In this approach, multiple elementary behaviors representing motor primitives are expressed by a single multi-purpose neural network, which is seen as a reusable area of ""recycled"" neurons (interpreter). The PFC thus acts as a ""programmer"" that, without modifying the network connectivity, feeds the interpreter networks with specific input parameters encoding the programs (corresponding to network structures) to be interpreted by the (pre-)motor areas. Our architecture is validated in a standard test for executive function: the 1-2-AX task. Our results show that this computational framework provides a robust, scalable and flexible scheme that can be iterated at different hierarchical layers, supporting the realization of multiple goals. We discuss the plausibility of the ""programmer-interpreter"" scheme to explain the functioning of prefrontal-(pre)motor cortical hierarchies.","",""
3,"Haoqiang Guo, Lu Peng, Jian Zhang, Fang Qi, Lide Duan","Hardware Accelerator for Adversarial Attacks on Deep Learning Neural Networks",2019,"","","","",193,"2022-07-13 09:26:17","","10.1109/IGSC48788.2019.8957192","","",,,,,3,1.00,1,5,3,"Recent studies identify that Deep learning Neural Networks (DNNs) are vulnerable to subtle perturbations, which are not perceptible to human visual system but can fool the DNN models and lead to wrong outputs. A class of adversarial attack network algorithms has been proposed to generate robust physical perturbations under different circumstance. These algorithms are the first efforts to move forward secure deep learning by providing an avenue to train future defense networks, however, the intrinsic complexity of them prevents their broader usage.In this paper, we propose the first hardware accelerator for adversarial attacks based on memristor crossbar arrays. Our design significantly improves the throughput of a visual adversarial perturbation system, which can further improve the robustness and security of future deep learning systems. Based on the algorithm uniqueness, we propose four implementations for the adversarial attack accelerator (A3) to improve the throughput, energy efficiency, and computational efficiency.","",""
1,"N. Saleem, Bie Hong-xia, F. Zafar, Amjad Ali","Pedestrians Detection and Part-Based Tracking by Adaptive Segmentation, Neural Network and Kalman Filter",2012,"","","","",194,"2022-07-13 09:26:17","","10.4156/JDCTA.VOL6.ISSUE23.84","","",,,,,1,0.10,0,4,10,"Abstract In this paper authors have proposed a robust pedestrian tracking algorithm for stationary surveillance videos by combining the multiple adaptive segmentation, computationally efficient feature set, Neural Network and Kalman Filter. In the proposed method, human detection has been performed by the use of an adaptive moving average background model with supportive secondary model, which accurately works in changing environment. The parts-based human model has been used with novel and robust feature set for efficient parts-based human recognition. These features are concise, invariant to pose changes and deformation. Pedestrian recognition has been performed by neural network. Visual tracking has been performed by well known Kalman Filter to estimate the target pedestrian position in each next frame. The algorithm is tested on different surveillance videos and results show that proposed pedestrian recognition and tracking method is robust and efficient than similar work done earlier.","",""
12454,"Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun","Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",2015,"","","","",195,"2022-07-13 09:26:17","","10.1109/ICCV.2015.123","","",,,,,12454,1779.14,3114,4,7,"Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.","",""
0,"Fen Zhou, Xuping Tu, Qingdong Wang, Guosong Jiang","Improved GCN Framework for Human Motion Recognition",2022,"","","","",196,"2022-07-13 09:26:17","","10.1155/2022/2721618","","",,,,,0,0.00,0,4,1,"Human recognition models based on spatial-temporal graph convolutional neural networks have been gradually developed, and we present an improved spatial-temporal graph convolutional neural network to solve the problems of the high number of parameters and low accuracy of this type of model. The method mainly draws on the inception structure. First, the tensor rotation is added to the graph convolution layer to realize the conversion between graph node dimension and channel dimension and enhance the model’s ability to capture global information for small-scale tasks. Then the inception temporal convolution layer is added to build a multiscale temporal convolution filter to perceive temporal information under different time domains hierarchically from 4-time dimensions. It overcomes the shortcomings of temporal graph convolutional networks in the field of joint relevance of hidden layers and compensates for the information omission of small-scale graph tasks. It also limits the volume of parameters, decreases the arithmetic power, and speeds up the computation. In our experiments, we verify our model on the public dataset NTU RGB + D. Our method reduces the number of the model parameters by 50% and achieves an accuracy of 90% in the CS evaluation system and 94% in the CV evaluation system. The results show that our method not only has high recognition accuracy and good robustness in human behavior recognition applications but also has a small number of model parameters, which can effectively reduce the computational cost.","",""
0,"V. Ayzenberg, Stella F. Lourenco","Perception of an object’s global shape is best described by a model of skeletal structure in human infants",2022,"","","","",197,"2022-07-13 09:26:17","","10.7554/eLife.74943","","",,,,,0,0.00,0,2,1,"Categorization of everyday objects requires that humans form representations of shape that are tolerant to variations among exemplars. Yet, how such invariant shape representations develop remains poorly understood. By comparing human infants (6–12 months; N=82) to computational models of vision using comparable procedures, we shed light on the origins and mechanisms underlying object perception. Following habituation to a never-before-seen object, infants classified other novel objects across variations in their component parts. Comparisons to several computational models of vision, including models of high-level and low-level vision, revealed that infants’ performance was best described by a model of shape based on the skeletal structure. Interestingly, infants outperformed a range of artificial neural network models, selected for their massive object experience and biological plausibility, under the same conditions. Altogether, these findings suggest that robust representations of shape can be formed with little language or object experience by relying on the perceptually invariant skeletal structure.","",""
7,"Congzhentao Huang, Shuai Jiang, Yang Li, Ziyue Zhang, Jason M. Traish, Chen Deng, S. Ferguson, R. Xu","End-to-end Dynamic Matching Network for Multi-view Multi-person 3D Pose Estimation",2020,"","","","",198,"2022-07-13 09:26:17","","10.1007/978-3-030-58604-1_29","","",,,,,7,3.50,1,8,2,"","",""
5,"Kshitij Dwivedi, Radoslaw Martin Cichy, G. Roig","Unraveling Representations in Scene-selective Brain Regions Using Scene-Parsing Deep Neural Networks",2020,"","","","",199,"2022-07-13 09:26:17","","10.1162/jocn_a_01624","","",,,,,5,2.50,2,3,2,"Abstract Visual scene perception is mediated by a set of cortical regions that respond preferentially to images of scenes, including the occipital place area (OPA) and parahippocampal place area (PPA). However, the differential contribution of OPA and PPA to scene perception remains an open research question. In this study, we take a deep neural network (DNN)-based computational approach to investigate the differences in OPA and PPA function. In a first step, we search for a computational model that predicts fMRI responses to scenes in OPA and PPA well. We find that DNNs trained to predict scene components (e.g., wall, ceiling, floor) explain higher variance uniquely in OPA and PPA than a DNN trained to predict scene category (e.g., bathroom, kitchen, office). This result is robust across several DNN architectures. On this basis, we then determine whether particular scene components predicted by DNNs differentially account for unique variance in OPA and PPA. We find that variance in OPA responses uniquely explained by the navigation-related floor component is higher compared to the variance explained by the wall and ceiling components. In contrast, PPA responses are better explained by the combination of wall and floor, that is, scene components that together contain the structure and texture of the scene. This differential sensitivity to scene components suggests differential functions of OPA and PPA in scene processing. Moreover, our results further highlight the potential of the proposed computational approach as a general tool in the investigation of the neural basis of human scene perception.","",""
1,"Zihan Pan, Malu Zhang, Jibin Wu, Jiadong Wang, Haizhou Li","Multi-Tone Phase Coding of Interaural Time Difference for Sound Source Localization With Spiking Neural Networks",2021,"","","","",200,"2022-07-13 09:26:17","","10.1109/TASLP.2021.3100684","","",,,,,1,1.00,0,5,1,"Mammals exhibit remarkable capability of detecting and localizing sound sources in complex acoustic environments by using binaural cues in the spiking manner. Emulating the auditory process for sound source localization (SSL) by mammals, we propose a computational model for accurate and robust SSL under the neuromorphic spiking neural network (SNN) framework. The center of this model is a Multi-Tone Phase Coding (MTPC) scheme, which encodes the interaural time difference (ITD) between binaural pure tones into discriminative spike patterns that can be directly classified by SNNs. As such, SSL can be implemented as an event-driven task on highly efficient, neuromorphic parallel processors. We evaluate the proposed computational model on a directional audio dataset recorded from a microphone array in a realistic acoustic environment with background noise, obstruction, reflection, and other interferences. We report superior localization capability with a mean absolute error (MAE) of $1.02^\circ$ or 100% classification accuracy with an angle resolution of $5^\circ$, which surpasses other SNN-based biologically plausible neuromorphic approaches by a relatively large margin and on par with human performance in similar tasks. This study opens up many application opportunities in human-robot interaction where energy efficiency is crucial. As a case study, we successfully deploy the proposed SSL system in a robotic platform to track the speaker and orient the robot's attention.","",""
