Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
3,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantitative comparison of Drosophila behavior annotations by human observers and a machine learning algorithm",2020,"","","","",1,"2022-07-13 10:07:14","","10.1101/2020.06.16.153130","","",,,,,3,1.50,1,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications. Significance Statement Accurate quantification of animal behaviors is fundamental to neuroscience. Here, we quantitatively assess how human choices influence the performance of automated classifiers trained by a machine-learning algorithm. We found that human decisions about the computational tracking method, the training images, and the images used for performance evaluation impact both the classifier outputs and how human observers interpret the results. These factors are sometimes overlooked but are critical, especially because animal behavior is itself inherently variable. Automated quantification of animal behavior is becoming increasingly prevalent: our results provide a model for bridging the gap between traditional human annotations and computer-based annotations. Systematic assessment of human choices is important for developing behavior classifiers that perform robustly in a variety of experimental conditions.","",""
2,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantifying influence of human choice on the automated detection of Drosophila behavior by a supervised machine learning algorithm",2020,"","","","",2,"2022-07-13 10:07:14","","10.1371/journal.pone.0241696","","",,,,,2,1.00,0,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications.","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",3,"2022-07-13 10:07:14","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
10,"Krupal P. Jethava, Jonathan A Fine, Yingqi Chen, Ahad Hossain, G. Chopra","Accelerated Reactivity Mechanism and Interpretable Machine Learning Model of N-Sulfonylimines toward Fast Multicomponent Reactions.",2020,"","","","",4,"2022-07-13 10:07:14","","10.26434/chemrxiv.12116163.v1","","",,,,,10,5.00,2,5,2,"We introduce chemical reactivity flowcharts to help chemists interpret reaction outcomes using statistically robust machine learning models trained on a small number of reactions. We developed fast N-sulfonylimine multicomponent reactions for understanding reactivity and to generate training data. Accelerated reactivity mechanisms were investigated using density functional theory. Intuitive chemical features learned by the model accurately predicted heterogeneous reactivity of N-sulfonylimine with different carboxylic acids. Validation of the predictions shows that reaction outcome interpretation is useful for human chemists.","",""
10,"Alan Le Goallec, B. Tierney, Jacob M. Luber, Evan M. Cofer, A. Kostic, C. Patel","A systematic machine learning and data type comparison yields metagenomic predictors of infant age, sex, breastfeeding, antibiotic usage, country of origin, and delivery type",2020,"","","","",5,"2022-07-13 10:07:14","","10.1371/journal.pcbi.1007895","","",,,,,10,5.00,2,6,2,"The microbiome is a new frontier for building predictors of human phenotypes. However, machine learning in the microbiome is fraught with issues of reproducibility, driven in large part by the wide range of analytic models and metagenomic data types available. We aimed to build robust metagenomic predictors of host phenotype by comparing prediction performances and biological interpretation across 8 machine learning methods and 4 different types of metagenomic data. Using 1,570 samples from 300 infants, we fit 7,865 models for 6 host phenotypes. We demonstrate the dependence of accuracy on algorithm choice and feature definition in microbiome data and propose a framework for building microbiome-derived indicators of host phenotype. We additionally identify biological features predictive of age, sex, breastfeeding status, historical antibiotic usage, country of origin, and delivery type. Our complete results can be viewed at http://apps.chiragjpgroup.org/ubiome_predictions/.","",""
0,"David A. Hindin","Artificial Intelligence and Machine Learning: Implications for Surgery",2020,"","","","",6,"2022-07-13 10:07:14","","10.1007/978-3-030-49100-0_23","","",,,,,0,0.00,0,1,2,"","",""
40,"Yue Zhao, M. K. Hryniewicki, Francesca Cheng, Boyang Fu, Xiaoyu Zhu","Employee Turnover Prediction with Machine Learning: A Reliable Approach",2018,"","","","",7,"2022-07-13 10:07:14","","10.1007/978-3-030-01057-7_56","","",,,,,40,10.00,8,5,4,"","",""
16,"Ramyar Saeedi, S. Norgaard, A. Gebremedhin","A closed-loop deep learning architecture for robust activity recognition using wearable sensors",2017,"","","","",8,"2022-07-13 10:07:14","","10.1109/BigData.2017.8257960","","",,,,,16,3.20,5,3,5,"Human activity recognition (HAR) plays a central role in health-care, fitness and sport applications because of its potential to enable context-aware human monitoring. With the increase in popularity of wearable devices, we are witnessing a large influx in availability of human activity data. For effective analysis and interpretation of these heterogeneous and high-volume streaming data, we need powerful algorithms. In particular, there is a strong need for developing algorithms for robust classification of human activity data that specifically address challenges associated with dynamic environments (e.g. different users, signal heterogeneity). We use the term robust here in two, orthogonal senses: 1) leveraging related data in such a way that knowledge is transferred to a new context; and 2) actively reconfiguring machine learning algorithms such that they can be applied in a new context. In this paper, we propose an architecture that combines an active learning approach with a novel deep network. Our deep neural network exploits both Convolutional and Long Short-Term Memory (LSTM) layers in order to learn hierarchical representation of features and capture time dependencies from raw-data. The active learning process allows us to choose the best instances for fine-tuning the deep network to the new setting in which the system operates (i.e. a new subject). We demonstrate the efficacy of the architecture using real data of human activity. We show that the accuracy of activity recognition reaches over 90% by annotating less than 20% of unlabeled data.","",""
0,"Joey Wang","F3-C,E: Machine Learning & Sensor Management for High Throughput Screening",2013,"","","","",9,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,1,9,"This project is investigating the development of automated explosive detection and classification algorithms for high throughput screening. This is critical both in portal systems, where high throughput requires significant automated decision support, and in stand-off systems where the proliferation of multimodal data can overwhelm human interpretation. The project’s fundamental assumption is that it is too slow or costly to collect full sensor data on every object of interest, either for training, or during real-time operation. As a consequence, there are several important problems to address. In training, one needs to select which data will be used to train the decision algorithms in order to achieve robust performance. This is a problem known as active learning. In the real-time phase, one needs to use a hierarchy of sensing and classification strategies, based on relatively inexpensive early warning sensors, and adaptively select subsequent sensor measurements in order to arrive rapidly at an accurate classification decision. The longrange impact of this research will be the development of adaptive, high throughput screening algorithms for different combinations of sensing modalities that exhibit improved sensitivity/specificity.","",""
1,"K. Katahira, Yoshihiko Kunisato, Yuichi Yamashita, Shinsuke Suzuki","Commentary: A robust data-driven approach identifies four personality types across four large data sets",2020,"","","","",10,"2022-07-13 10:07:14","","10.3389/fdata.2020.00008","","",,,,,1,0.50,0,4,2,"What kinds of personalities do humans have? Can these personalities be classified into several discrete types? These issues have been of considerable concern as they could potentially provide deeper understanding of the nature of human individuality and mental disorders. Recently, Gerlach et al. (2018) addressed these issues by applying established machine-learning techniques to big data (more than 1.5 million respondents in total). They found four “meaningful clusters” in personality dimensions, suggesting the existence of at least four personality types. Here, we propose an alternative interpretation of their result: a skewed distribution with no cluster structures in personality space can erroneously lead to the seemingly meaningful clusters.","",""
0,"Jing Qian","F 3C , E : Machine Learning & Sensor Management for High Throughput Screening",2012,"","","","",11,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,1,10,"This project is investigating the development of automated explosive detection and classification algorithms for high throughput screening. This is critical both in portal systems, where high throughput requires significant automated decision support, and in stand-off systems where the proliferation of multimodal data can overwhelm human interpretation. The project’s fundamental assumption is that it is too slow or costly to collect full sensor data on every object of interest, either for training, or during real-time operation. As a consequence, there are several important problems to address. In training, one needs to select which data will be used to train the decision algorithms in order to achieve robust performance. This is a problem known as active learning. In the real-time phase, one needs to use a hierarchy of sensing and classification strategies, based on relatively inexpensive early warning sensors, and adaptively select subsequent sensor measurements in order to arrive rapidly at an accurate classification decision. The long range impact of this research will be the development of adaptive, high throughput screening algorithms for different combinations of sensing modalities that exhibit improved sensitivity/specificity.","",""
2,"Weishen Pan, Changshui Zhang","The Definitions of Interpretability and Learning of Interpretable Models",2021,"","","","",12,"2022-07-13 10:07:14","","","","",,,,,2,2.00,1,2,1,"As machine learning algorithms getting adopted in an ever-increasing number of applications, interpretation has emerged as a crucial desideratum. In this paper, we propose a mathematical definition for the humaninterpretable model. In particular, we define interpretability between two information process systems. If a prediction model is interpretable by a human recognition system based on the above interpretability definition, the prediction model is defined as a completely human-interpretable model. We further design a practical framework to train a completely human-interpretable model by user interactions. Experiments on image datasets show the advantages of our proposed model in two aspects: 1) The completely human-interpretable model can provide an entire decisionmaking process that is human-understandable; 2) The completely humaninterpretable model is more robust against adversarial attacks.","",""
0,"P. Lendvai, Antal van den Bosch, E. Krahmer, S. Canisius","Tilburg University Memory-based Robust Interpretation of Recognised Speech",,"","","","",13,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,4,,"We describe a series of experiments in which memorybased machine learning techniques are used for the interpretation of spoken user input in human-machine interactions. In these experiments, the task is to determine the dialogue act of the user input and the type of information slots the user fills, on the basis of a variety of features representing the spoken input (speech measurements and word recognition information) as well as its context (the interaction history). In the first experiment, we perform this task using the complete word graph output of the automatic speech recogniser. This yields an overall accuracy of 76.2%, with an F-score of 91.3 on dialogue act classification and an F-score of 87.7 on filled slot types. In the second experiment, we investigate the usefulness of two approaches to filtering out possibly non-contributing word recognition information from the speech recogniser output: (i) filtering out disfluencies, and (ii) keeping only syntactic chunk heads.","",""
13,"P. Lendvai, Antal van den Bosch, E. Krahmer, S. Canisius","Memory-based Robust Interpretation of Recognised Speech",2004,"","","","",14,"2022-07-13 10:07:14","","","","",,,,,13,0.72,3,4,18,"We describe a series of experiments in which memorybased machine learning techniques are used for the interpretation of spoken user input in human-machine interactions. In these experiments, the task is to determine the dialogue act of the user input and the type of information slots the user lls, on the basis of a variety of features representing the spoken input (speech measurements and word recognition information) as well as its context (the interaction history). In the rst experiment, we perform this task using the complete word graph output of the automatic speech recogniser. This yields an overall accuracy of 76.2%, with an F-score of 91.3 on dialogue act classication and an F-score of 87.7 on lled slot types. In the second experiment, we investigate the usefulness of two approaches to ltering out possibly non-contributing word recognition information from the speech recogniser output: (i) ltering out disuencies, and (ii) keeping only syntactic chunk heads.","",""
21,"Xiaochao Yang, Chuang-Wen You, Hong Lu, Mu Lin, N. Lane, A. Campbell","Visage: A Face Interpretation Engine for Smartphone Applications",2012,"","","","",15,"2022-07-13 10:07:14","","10.1007/978-3-642-36632-1_9","","",,,,,21,2.10,4,6,10,"","",""
0,"Max Berniker, Kiran D. Bhattacharyya, Kristen C. Brown, A. Jarc","A Probabilistic Approach to Surgical Tasks and Skill Metrics",2021,"","","","",16,"2022-07-13 10:07:14","","10.1109/TBME.2021.3139538","","",,,,,0,0.00,0,4,1,"Identifying and quantifying the activities that compose surgery is essential for effective interventions, computer-aided analyses and the advancement of surgical data science. For example, recent studies have shown that objective metrics (referred to as objective performance indicators, OPIs) computed during key surgical tasks correlate with surgeon skill and clinical outcomes. Unambiguous identification of these surgical tasks can be particularly challenging for both human annotators and algorithms. Each surgical procedure has multiple approaches, each surgeon has their own level of skill, and the initiation and termination of surgical tasks can be subject to interpretation. As such, human annotators and machine learning models face the same basic problem, accurately identifying the boundaries of surgical tasks despite variable and unstructured information. For use in surgeon feedback, OPIs should also be robust to the variability and diversity in this data. To mitigate this difficulty, we propose a probabilistic approach to surgical task identification and calculation of OPIs. Rather than relying on tasks that are identified by hard temporal boundaries, we demonstrate an approach that relies on distributions of start and stop times, for a probabilistic interpretation of when the task was performed. We first use hypothetical data to outline how this approach is superior to other conventional approaches. Then we present similar analyses on surgical data. We find that when surgical tasks are identified by their individual probabilities, the resulting OPIs are less sensitive to noise in the identification of the start and stop times. These results suggest that this probabilistic approach holds promise for the future of surgical data science.","",""
50,"E. Cahan, T. Hernandez-Boussard, Sonoo Thadaney-Israni, D. Rubin","Putting the data before the algorithm in big data addressing personalized healthcare",2019,"","","","",17,"2022-07-13 10:07:14","","10.1038/s41746-019-0157-2","","",,,,,50,16.67,13,4,3,"","",""
0,"F. Wallhoff, A. Bannat, J. Gast, T. Rehrl, S. Schwärzler, G. Rigoll, M. Wimmer, C. Mayer, B. Radig","Recognition of Head Gestures in Multimodal Human-Machine Dialogs",2008,"","","","",18,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,9,14,"This paper presents a system for human-machine communication that is able to participate in a simple dialog. Spoken language and head gestures are integrated to pass information between the interacting partners. Head gestures are extracted by image interpretation algorithms basing on machine learning techniques. Our experimental evaluation proofs the capability of the system to recognize head gestures from camera images in a robust way. The system works in real-time and will be presented publicly.","",""
1,"Dan Oneață","Robust and efficient models for action recognition and localization",2015,"","","","",19,"2022-07-13 10:07:14","","","","",,,,,1,0.14,1,1,7,"Video interpretation and understanding is one of the long-term research goals in computer vision. Realistic videos such as movies present a variety of challenging machine learning problems, such as action classification/action retrieval, human tracking, human/object interaction classification, etc. Recently robust visual descriptors for video classification have been developed, and have shown that it is possible to learn visual classifiers in realistic difficult settings. However, in order to deploy visual recognition systems on large-scale in practice it becomes important to address the scalability of the techniques. The main goal is this thesis is to develop scalable methods for video content analysis (eg for ranking, or classification).","",""
1,"F. Fabiano, A. D. Palù","An ASP Approach for Arteries Classification in CT-scans",2020,"","","","",20,"2022-07-13 10:07:14","","10.1093/logcom/exab087","","",,,,,1,0.50,1,2,2,"Automated segmentation of CT scans is the first step in the pipeline for the interpretation and identification of potential pathologies in human organs. Several methods based on Machine Learning are currently available, even if their precision is still outperformed by medical doctors. In this field there are some intrinsic limitations to ML approaches, such as the cost and time to acquire high quality annotated scans for training; a considerably high variability of organs morphology due to age, health conditions, genetics; acquisition noise. This paper outlines a new methodology based on Answer Set Programming, which returns reliable, easy-to-program and explainable interpretations. In particular, we focus on the CT scan analysis and retrieval of tree-like structure, corresponding to main blood vessels (arteries) arrangement. The structure is compared to the knowledge base of vessels contained in anatomy text-books. The mapping of vessels names is computed by an ASP program. This preliminary step produces a robust input to a reasoner for the multi-organ labeling and localization problem.","",""
21,"Monzurul Islam, A. Dinh, K. Wahid","Automated Diabetic Retinopathy Detection Using Bag of Words Approach",2017,"","","","",21,"2022-07-13 10:07:14","","10.4236/JBISE.2017.105B010","","",,,,,21,4.20,7,3,5,"Imaging and computer vision systems offer the ability to study quantitatively on human physiology. On contrary, manual interpretation requires tremendous amount of work, expertise and excessive processing time. This work presents an algorithm that integrates image processing and machine learning to diagnose diabetic retinopathy from retinal fundus images. This automated method classifies diabetic retinopathy (or absence thereof) based on a dataset collected from some publicly available database such as DRIDB0, DRIDB1, MESSIDOR, STARE and HRF. Our approach utilizes bag of words model with Speeded Up Robust Features and demonstrate classification over 180 fundus images containing lesions (hard exudates, soft exudates, microaneurysms, and haemorrhages) and non-lesions with an accuracy of 94.4%, precision of 94%, recall and f1-score of 94% and AUC of 95%. Thus, the proposed approach presents a path toward precise and automated diabetic retinopathy diagnosis on a massive scale.","",""
2,"Jonathan Howell, Mats Rooth, M. Wagner","Acoustic Classification of Focus: On the Web and in the Lab",2017,"","","","",22,"2022-07-13 10:07:14","","10.5334/LABPHON.8","","",,,,,2,0.40,1,3,5,"We present a new methodological approach which combines both naturally-occurring speech harvested on the web and speech data elicited in the laboratory. This proof-of-concept study examines the phenomenon of focus sensitivity in English, in which the interpretation of particular grammatical constructions (e.g., the comparative) is sensitive to the location of prosodic prominence. Machine learning algorithms (support vector machines and linear discriminant analysis) and human perception experiments are used to cross-validate the web-harvested and lab-elicited speech. Results confirm the theoretical predictions for location of prominence in comparative clauses and the advantages using both web-harvested and lab-elicited speech. The most robust acoustic classifiers include paradigmatic (i.e., un-normalized), non-intonational acoustic measures (duration and relative formant frequencies from single segments). These acoustic cues are also significant predictors of human listeners’ classification, offering new evidence in the debate whether prominence is mainly encoded by pitch or by other cues, and the role that utterance-normalization plays when looking at non-pitch cues such as duration.","",""
8,"J. Serrà, Tan Hakan Özaslan, J. Arcos","Note Onset Deviations as Musical Piece Signatures",2013,"","","","",23,"2022-07-13 10:07:14","","10.1371/journal.pone.0069268","","",,,,,8,0.89,3,3,9,"A competent interpretation of a musical composition presents several non-explicit departures from the written score. Timing variations are perhaps the most important ones: they are fundamental for expressive performance and a key ingredient for conferring a human-like quality to machine-based music renditions. However, the nature of such variations is still an open research question, with diverse theories that indicate a multi-dimensional phenomenon. In the present study, we consider event-shift timing variations and show that sequences of note onset deviations are robust and reliable predictors of the musical piece being played, irrespective of the performer. In fact, our results suggest that only a few consecutive onset deviations are already enough to identify a musical composition with statistically significant accuracy. We consider a mid-size collection of commercial recordings of classical guitar pieces and follow a quantitative approach based on the combination of standard statistical tools and machine learning techniques with the semi-automatic estimation of onset deviations. Besides the reported results, we believe that the considered materials and the methodology followed widen the testing ground for studying musical timing and could open new perspectives in related research fields.","",""
0,"Pujitha Gunaratne, Sujitha Martin, Eshed Ohn-Bar, R. Satzoda, M. Trivedi","Automated Drive Analysis of Naturalistic Driving Studies with Looking-out Video",2014,"","","","",24,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,5,8,"Problem Large volumes of data from multiple sensors are captured in Naturalistic Driving Studies (NDS) such as in the Strategic Highway Research Program 2 (SHRP2). In order to extract and characterize distraction events leading to crashes and near-crashes, visual data from multiple cameras coupled with other sensory data are analyzed by human data reductionists. This not only requires tremendous human effort and time, it is also subject to human error and interpretation. The research aims at developing novel computer vision and machine learning techniques, which analyze the visual data of the surrounding environment outside the vehicle, and the interactions and movements of the driver and passengers inside the vehicle. In this paper, we present research methods and results for automated drive analysis using looking out videos. Our ongoing research is focused on robust and efficient algorithms for looking-in videos as well.","",""
4,"Megat Norulazmi Megat Mohamed Noor, S. Jusoh","Handling imbalance visualized pattern dataset for yield prediction",2008,"","","","",25,"2022-07-13 10:07:14","","10.1109/ITSIM.2008.4631657","","",,,,,4,0.29,2,2,14,"The prediction of the yield outcome in a non close loop manufacturing process can be achieved by visualizing the historical data pattern generated from the inspection machine, transform the data pattern and map it into machine learning algorithm for training, in order to automatically generate a prediction model without the visual interpretation needs to be done by human. Anyhow, the nature of manufacturing process dataset for the bad yield outcome is highly skewed where the majority class of good yield extremely outnumbers the minority class of bad yield. Comparison between the undersampling, over- sampling and SMOTE + VDM sampling technique indicates that the combination of SMOTE + VDM and undersampled dataset produced a robust classifier performance capable of handling better with different batches of prediction test data sets. Furtherance, suitable distance function for SMOTE is needed to improve class recall and minimize overfitting whilst different approach on the majority class sampling is required to improve the class precision due to information loss by the undersampling.","",""
1,"Y. Xiang, B. Chaib-draa","Advances in artificial intelligence : 16th Conference of the Canadian Society for Computational Studies of Intelligence, AI 2003, Halifax, Canada, June 11-13, 2003 : proceedings",2003,"","","","",26,"2022-07-13 10:07:14","","","","",,,,,1,0.05,1,2,19,"Experiences Building a Distributed Sensor Network.- Artificial Intelligence and Human Brain Imaging.- Machine Learning Methods for Computational Proteomics and Beyond.- The Structure Model Interpretation of Wright's NESS Test.- Answer Formulation for Question-Answering.- Patttern-Based AI Scripting Using ScriptEase.- Enumerating the Preconditions of Agent Message Types.- Monadic Memoization towards Correctness-Preserving Reduction of Search.- Searching Solutions in the Crypto-arithmetic Problems: An Adaptive Parallel Genetic Algorithm Approach.- Stochastic Local Search for Multiprocessor Scheduling for Minimum Total Tardiness.- A Graph Based Backtracking Algorithm for Solving General CSPs.- Iterated Robust Tabu Search for MAX-SAT.- Scaling and Probabilistic Smoothing: Dynamic Local Search for Unweighted MAX-SAT.- A Comparison of Consistency Propagation Algorithms in Constraint Optimization.- Discovering Temporal/Causal Rules: A Comparison of Methods.- Selective Transfer of Task Knowledge Using Stochastic Noise.- Efficient Mining of Indirect Associations Using HI-Mine.- Case Authoring from Text and Historical Experiences.- Session Boundary Detection for Association Rule Learning Using n-Gram Language Models.- Negotiating Exchanges of Private Information for Web Service Eligibility.- Post-supervised Template Induction for Dynamic Web Sources.- Summarizing Web Sites Automatically.- Cycle-Cutset Sampling for Bayesian Networks.- Learning First-Order Bayesian Networks.- AUC: A Better Measure than Accuracy in Comparing Learning Algorithms.- Model-Based Least-Squares Policy Evaluation.- DIAGAL: A Tool for Analyzing and Modelling Commitment-Based Dialogues between Agents.- Situation Event Logic for Early Validation of Multi-Agent Systems.- Understanding ""Not-Understood"": Towards an Ontology of Error Conditions for Agent Communication.- An Improved Ant Colony Optimisation Algorithm for the 2D HP Protein Folding Problem.- Hybrid Randomised Neighbourhoods Improve Stochastic Local Search for DNA Code Design.- A Strategy for Improved Satisfaction of Selling Software Agents in E-Commerce.- Pre-negotiations over Services - A Framework for Evaluation.- Formal Theory for Describing Action Concepts in Terminological Knowledge Bases.- Improving User-Perceived QoS in Mobile Ad Hoc Networks Using Decision Rules Induction.- Risk Neutral Calibration of Classifiers.- Search Bound Strategies for Rule Mining by Iterative Deepening.- Methods for Mining Frequent Sequential Patterns.- Learning by Discovering Conflicts.- Enhancing Caching in Distributed Databases Using Intelligent Polytree Representations.- Feature Selection Strategies for Text Categorization.- Learning General Graphplan Memos through Static Domain Analysis.- Classification Automaton and Its Construction Using Learning.- A Genetic K-means Clustering Algorithm Applied to Gene Expression Data.- Explanation-Oriented Association Mining Using a Combination of Unsupervised and Supervised Learning Algorithms.- Motion Recognition from Video Sequences.- Noun Sense Disambiguation with WordNet for Software Design Retrieval.- Not as Easy as It Seems: Automating the Construction of Lexical Chains Using Roget's Thesaurus.- The Importance of Fine-Grained Cue Phrases in Scientific Citations.- Fuzzy C-Means Clustering of Web Users for Educational Sites.- Re-using Web Information for Building Flexible Domain Knowledge.- A New Inference Axiom for Probabilistic Conditional Independence.- Probabilistic Reasoning for Meal Planning in Intelligent Fridges.- Probabilistic Reasoning in Bayesian Networks: A Relational Database Approach.- Fundamental Issue of Naive Bayes.- The Virtual Driving Instructor Creating Awareness in a Multiagent System.- Multi-attribute Exchange Market: Theory and Experiments.- Agent-Based Online Trading System.- On the Applicability of L-systems and Iterated Function Systems for Grammatical Synthesis of 3D Models.- An Unsupervised Clustering Algorithm for Intrusion Detection.- Dueling CSP Representations: Local Search in the Primal versus Dual Constraint Graph.- A Quick Look at Methods for Mining Long Subsequences.- Back to the Future: Changing the Direction of Time to Discover Causality.- Learning Coordination in RoboCupRescue.- Accent Classification Using Support Vector Machine and Hidden Markov Model.- A Neural Network Based Approach to the Artificial Aging of Facial Images.- Adaptive Negotiation for Agent Based Distributed Manufacturing Scheduling.- Multi-agent System Architecture for Tracking Moving Objects.","",""
1,"H. Freeman","Studies in Pattern Recognition: A Memorial to the Late Professor King-Sun Fu",1997,"","","","",27,"2022-07-13 10:07:14","","10.1142/3250","","",,,,,1,0.04,1,1,25,"Pattern category assignment by neural networks and nearest neighbours rule - a synopsis and a characterization, A. Mitiche and J.K. Aggarwal pattern recognition - an approach to turn machine translation concepts into creation and reality, J.T. Tou learning in navigation - goal finding in graphs, P. Cucka et al subset least squares method for robust speech and image processing, R.L. Kashyap and J.-N. Liaw shape recognition by human-like trial and error random processes, M. Nagao 3-D face modelling and its applications, T.S. Huang and L.-A. Tang dimension reduction, feature extraction and interpretation of data with network computing, Y.-H. Pao characteristic-view modelling of curved-surface solids, S. Chen and H. Freeman propagating covariance in computer vision, R.M. Haralick shape description by a syntactic pyramidal approach, S. Levialdi and L. Cinque genetic selection and neural modelling of piecewise linear-classifiers, J. Sklansky and M. Vriesenga.","",""
22,"J. Phillip, Kyu-Sang Han, Wei-Chiang Chen, D. Wirtz, Pei-Hsun Wu","A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei.",2021,"","","","",28,"2022-07-13 10:07:14","","10.1038/s41596-020-00432-x","","",,,,,22,22.00,4,5,1,"","",""
2,"Md Nafis Ul Alam, U. F. Chowdhury","Short k-mer abundance profiles yield robust machine learning features and accurate classifiers for RNA viruses",2020,"","","","",29,"2022-07-13 10:07:14","","10.1371/journal.pone.0239381","","",,,,,2,1.00,1,2,2,"High throughout sequencing technologies have greatly enabled the study of genomics, transcriptomics and metagenomics. Automated annotation and classification of the vast amounts of generated sequence data has become paramount for facilitating biological sciences. Genomes of viruses can be radically different from all life, both in terms of molecular structure and primary sequence. Alignment-based and profile-based searches are commonly employed for characterization of assembled viral contigs from high-throughput sequencing data. Recent attempts have highlighted the use of machine learning models for the task but these models rely entirely on DNA genomes and owing to the intrinsic genomic complexity of viruses, RNA viruses have gone completely overlooked. Here, we present a novel short k-mer based sequence scoring method that generates robust sequence information for training machine learning classifiers. We trained 18 classifiers for the task of distinguishing viral RNA from human transcripts. We challenged our models with very stringent testing protocols across different species and evaluated performance against BLASTn, BLASTx and HMMER3 searches. For clean sequence data retrieved from curated databases, our models display near perfect accuracy, outperforming all similar attempts previously reported. On de-novo assemblies of raw RNA-Seq data from cells subjected to Ebola virus, the area under the ROC curve varied from 0.6 to 0.86 depending on the software used for assembly. Our classifier was able to properly classify the majority of the false hits generated by BLAST and HMMER3 searches on the same data. The outstanding performance metrics of our model lays the groundwork for robust machine learning methods for the automated annotation of sequence data. Author Summary In this age of high-throughput sequencing, proper classification of copious amounts of sequence data remains to be a daunting challenge. Presently, sequence alignment methods are immediately assigned to the task. Owing to the selection forces of nature, there is considerable homology even between the sequences of different species which draws ambiguity to the results of alignment-based searches. Machine Learning methods are becoming more reliable for characterizing sequence data, but virus genomes are more variable than all forms of life and viruses with RNA-based genomes have gone overlooked in previous machine learning attempts. We designed a novel short k-mer based scoring criteria whereby a large number of highly robust numerical feature sets can be derived from sequence data. These features were able to accurately distinguish virus RNA from human transcripts with performance scores better than all previous reports. Our models were able to generalize well to distant species of viruses and mouse transcripts. The model correctly classifies the majority of false hits generated by current standard alignment tools. These findings strongly imply that this k-mer score based computational pipeline forges a highly informative, rich set of numerical machine learning features and similar pipelines can greatly advance the field of computational biology.","",""
13,"Nareen O. M. Salim, A. Abdulazeez","Human Diseases Detection Based On Machine Learning Algorithms: A Review",2021,"","","","",30,"2022-07-13 10:07:14","","10.5281/ZENODO.4467510","","",,,,,13,13.00,7,2,1,"One of the most significant subjects of society is human healthcare. It is looking for the best one and robust disease diagnosis to get the care they need as soon as possible. Other fields, such as statistics and computer science, are needed for the health aspect of searching since this recognition is often complicated. The task of following new approaches is challenging these disciplines, moving beyond the conventional ones. The actual number of new techniques makes it possible to provide a broad overview that avoids particular aspects. To this end, we suggest a systematic analysis of human diseases related to machine learning. This research concentrates on existing techniques related to machine learning growth applied to the diagnosis of human illnesses in the medical field to discover exciting trends, make unimportant predictions, and help decision-making. This paper analyzes unique machine learning algorithms used for healthcare applications to create adequate decision support. This paper intends to reduce the research gap in creating a realistic decision support system for medical applications.","",""
5,"Haohan Wang, Zeyi Huang, Hanlin Zhang, Eric P. Xing","Toward Learning Human-aligned Cross-domain Robust Models by Countering Misaligned Features",2021,"","","","",31,"2022-07-13 10:07:14","","","","",,,,,5,5.00,1,4,1,"Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective as-suming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available here.","",""
23,"J. Zhang, Kang Liu, Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, T. Theocharides, Alessandro Artussi, M. Shafique, S. Garg","Building Robust Machine Learning Systems: Current Progress, Research Challenges, and Opportunities",2019,"","","","",32,"2022-07-13 10:07:14","","10.1145/3316781.3323472","","",,,,,23,7.67,3,9,3,"Machine learning, in particular deep learning, is being used in almost all the aspects of life to facilitate humans, specifically in mobile and Internet of Things (IoT)-based applications. Due to its state-of-the-art performance, deep learning is also being employed in safety-critical applications, for instance, autonomous vehicles. Reliability and security are two of the key required characteristics for these applications because of the impact they can have on human's life. Towards this, in this paper, we highlight the current progress, challenges and research opportunities in the domain of robust systems for machine learning-based applications.","",""
39,"Yiyue Luo, Yunzhu Li, Pratyusha Sharma, Wan Shou, Kui Wu, Michael Foshey, Beichen Li, Tomás Palacios, A. Torralba, W. Matusik","Learning human–environment interactions using conformal tactile textiles",2021,"","","","",33,"2022-07-13 10:07:14","","10.1038/S41928-021-00558-0","","",,,,,39,39.00,4,10,1,"","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",34,"2022-07-13 10:07:14","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
43,"A. Abrol, Z. Fu, Mustafa S. Salman, Rogers F. Silva, Y. Du, S. Plis, V. Calhoun","Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning",2021,"","","","",35,"2022-07-13 10:07:14","","10.1038/s41467-020-20655-6","","",,,,,43,43.00,6,7,1,"","",""
26,"W. Gou, Chu-wen Ling, Yan He, Zengliang Jiang, Yuanqing Fu, Fengzhe Xu, Z. Miao, Ting-yu Sun, Jie-sheng Lin, Hui-lian Zhu, Hongwei Zhou, Yu-ming Chen, Ju-Sheng Zheng","Interpretable Machine Learning Framework Reveals Robust Gut Microbiome Features Associated With Type 2 Diabetes",2020,"","","","",36,"2022-07-13 10:07:14","","10.2337/dc20-1536","","",,,,,26,13.00,3,13,2,"OBJECTIVE To identify the core gut microbial features associated with type 2 diabetes risk and potential demographic, adiposity, and dietary factors associated with these features. RESEARCH DESIGN AND METHODS We used an interpretable machine learning framework to identify the type 2 diabetes–related gut microbiome features in the cross-sectional analyses of three Chinese cohorts: one discovery cohort (n = 1,832, 270 cases of type 2 diabetes) and two validation cohorts (cohort 1: n = 203, 48 cases; cohort 2: n = 7,009, 608 cases). We constructed a microbiome risk score (MRS) with the identified features. We examined the prospective association of the MRS with glucose increment in 249 participants without type 2 diabetes and assessed the correlation between the MRS and host blood metabolites (n = 1,016). We transferred human fecal samples with different MRS levels to germ-free mice to confirm the MRS–type 2 diabetes relationship. We then examined the prospective association of demographic, adiposity, and dietary factors with the MRS (n = 1,832). RESULTS The MRS (including 14 microbial features) consistently associated with type 2 diabetes, with risk ratio for per 1-unit change in MRS 1.28 (95% CI 1.23–1.33), 1.23 (1.13–1.34), and 1.12 (1.06–1.18) across three cohorts. The MRS was positively associated with future glucose increment (P < 0.05) and was correlated with a variety of gut microbiota–derived blood metabolites. Animal study further confirmed the MRS–type 2 diabetes relationship. Body fat distribution was found to be a key factor modulating the gut microbiome–type 2 diabetes relationship. CONCLUSIONS Our results reveal a core set of gut microbiome features associated with type 2 diabetes risk and future glucose increment.","",""
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",37,"2022-07-13 10:07:14","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
7,"Jarrett Blair, M. D. Weiser, M. Kaspari, Matthew Miller, C. Siler, K. Marshall","Robust and simplified machine learning identification of pitfall trap‐collected ground beetles at the continental scale",2020,"","","","",38,"2022-07-13 10:07:14","","10.1002/ece3.6905","","",,,,,7,3.50,1,6,2,"Abstract Insect populations are changing rapidly, and monitoring these changes is essential for understanding the causes and consequences of such shifts. However, large‐scale insect identification projects are time‐consuming and expensive when done solely by human identifiers. Machine learning offers a possible solution to help collect insect data quickly and efficiently. Here, we outline a methodology for training classification models to identify pitfall trap‐collected insects from image data and then apply the method to identify ground beetles (Carabidae). All beetles were collected by the National Ecological Observatory Network (NEON), a continental scale ecological monitoring project with sites across the United States. We describe the procedures for image collection, image data extraction, data preparation, and model training, and compare the performance of five machine learning algorithms and two classification methods (hierarchical vs. single‐level) identifying ground beetles from the species to subfamily level. All models were trained using pre‐extracted feature vectors, not raw image data. Our methodology allows for data to be extracted from multiple individuals within the same image thus enhancing time efficiency, utilizes relatively simple models that allow for direct assessment of model performance, and can be performed on relatively small datasets. The best performing algorithm, linear discriminant analysis (LDA), reached an accuracy of 84.6% at the species level when naively identifying species, which was further increased to >95% when classifications were limited by known local species pools. Model performance was negatively correlated with taxonomic specificity, with the LDA model reaching an accuracy of ~99% at the subfamily level. When classifying carabid species not included in the training dataset at higher taxonomic levels species, the models performed significantly better than if classifications were made randomly. We also observed greater performance when classifications were made using the hierarchical classification method compared to the single‐level classification method at higher taxonomic levels. The general methodology outlined here serves as a proof‐of‐concept for classifying pitfall trap‐collected organisms using machine learning algorithms, and the image data extraction methodology may be used for nonmachine learning uses. We propose that integration of machine learning in large‐scale identification pipelines will increase efficiency and lead to a greater flow of insect macroecological data, with the potential to be expanded for use with other noninsect taxa.","",""
19,"Nuria Caballé-Cervigón, J. Castillo-Sequera, J. Gómez-Pulido, J. Gómez-Pulido, M. Polo-Luque","Machine Learning Applied to Diagnosis of Human Diseases: A Systematic Review",2020,"","","","",39,"2022-07-13 10:07:14","","10.3390/app10155135","","",,,,,19,9.50,4,5,2,"Human healthcare is one of the most important topics for society. It tries to find the correct effective and robust disease detection as soon as possible to patients receipt the appropriate cares. Because this detection is often a difficult task, it becomes necessary medicine field searches support from other fields such as statistics and computer science. These disciplines are facing the challenge of exploring new techniques, going beyond the traditional ones. The large number of techniques that are emerging makes it necessary to provide a comprehensive overview that avoids very particular aspects. To this end, we propose a systematic review dealing with the Machine Learning applied to the diagnosis of human diseases. This review focuses on modern techniques related to the development of Machine Learning applied to diagnosis of human diseases in the medical field, in order to discover interesting patterns, making non-trivial predictions and useful in decision-making. In this way, this work can help researchers to discover and, if necessary, determine the applicability of the machine learning techniques in their particular specialties. We provide some examples of the algorithms used in medicine, analysing some trends that are focused on the goal searched, the algorithm used, and the area of applications. We detail the advantages and disadvantages of each technique to help choose the most appropriate in each real-life situation, as several authors have reported. The authors searched Scopus, Journal Citation Reports (JCR), Google Scholar, and MedLine databases from the last decades (from 1980s approximately) up to the present, with English language restrictions, for studies according to the objectives mentioned above. Based on a protocol for data extraction defined and evaluated by all authors using PRISMA methodology, 141 papers were included in this advanced review.","",""
7,"J. Bayley, C. Messenger, G. Woan","Robust machine learning algorithm to search for continuous gravitational waves",2020,"","","","",40,"2022-07-13 10:07:14","","10.1103/physrevd.102.083024","","",,,,,7,3.50,2,3,2,"Many continuous gravitational wave searches are affected by instrumental spectral lines that could be confused with a continuous astrophysical signal. Several techniques have been developed to limit the effect of these lines by penalizing signals that appear in only a single detector. We have developed a general method, using a convolutional neural network, to reduce the impact of instrumental artifacts on searches that use the SOAP algorithm Bayley et al. [Phys. Rev. D 100, 023006 (2019)]. The method can identify features in corresponding frequency bands of each detector and classify these bands as containing a signal, an instrumental line, or noise. We tested the method against four different datasets: Gaussian noise with time gaps, data from the final run of Initial LIGO (S6) with signals added, the reference S6 mock data challenge dataset Walsh et al. [Phys. Rev. D 94, 124010 (2016)] and signals injected into data from the second advanced LIGO observing run (O2). Using the S6 mock data challenge dataset and at a 1% false alarm probability we showed that at 95% efficiency a fully automated SOAP search has a sensitivity corresponding to a coherent signal-to-noise ratio of 110, equivalent to a sensitivity depth of $10\text{ }\text{ }{\mathrm{Hz}}^{\ensuremath{-}1/2}$, making this automated search competitive with other searches requiring significantly more computing resources and human intervention.","",""
179,"S. Michie, James Thomas, M. Johnston, Pol Mac Aonghusa, J. Shawe-Taylor, M. Kelly, L. Deleris, Ailbhe N. Finnerty, M. Marques, E. Norris, A. O'Mara-Eves, R. West","The Human Behaviour-Change Project: harnessing the power of artificial intelligence and machine learning for evidence synthesis and interpretation",2017,"","","","",41,"2022-07-13 10:07:14","","10.1186/s13012-017-0641-5","","",,,,,179,35.80,18,12,5,"","",""
19,"J. Mallick, S. AlQadhi, Swapan Talukdar, Majed Alsubih, Mohd. Ahmed, R. A. Khan, N. Kahla, Saud M. Abutayeh","Risk Assessment of Resources Exposed to Rainfall Induced Landslide with the Development of GIS and RS Based Ensemble Metaheuristic Machine Learning Algorithms",2021,"","","","",42,"2022-07-13 10:07:14","","10.3390/SU13020457","","",,,,,19,19.00,2,8,1,"Disastrous natural hazards, such as landslides, floods, and forest fires cause a serious threat to natural resources, assets and human lives. Consequently, landslide risk assessment has become requisite for managing the resources in future. This study was designed to develop four ensemble metaheuristic machine learning algorithms, such as grey wolf optimized based artificial neural network (GW-ANN), grey wolf optimized based random forest (GW-RF), particle swarm optimization optimized based ANN (PSO-ANN), and PSO optimized based RF for modeling rainfall-induced landslide susceptibility (LS) in Aqabat Al-Sulbat, Asir region, Saudi Arabia, which observes landslide frequently. To obtain very high precision and robust prediction from machine learning algorithms, the grey wolf and PSO optimization algorithms were integrated to develop new ensemble machine learning techniques. Subsequently, LS maps produced by training dataset were validated using the receiver operating characteristics (ROC) curve based on the testing dataset. Based on the area under curve (AUC) value of ROC curve, the best method for LS modeling was selected. We developed ROC curve-based sensitivity analysis to investigate the influence of the parameters for LS modeling. The Gumble extreme value distribution was employed to estimate the rainfall at 2, 5, 10, 20, 50, and 100 year return periods. Then, the landslide hazard maps were prepared at different return periods by integrating the best LS model and estimated rainfall at different return periods. The theory of danger pixels was employed to prepare a final risk assessment of the resources, which have been exposed to the landslide. The results showed that 27–42 and 6–15 km2 were predicted as the very high and high LS zones using four ensemble metaheuristic machine learning algorithms. Based on the area under curve (AUC) of ROC, GR-ANN (AUC-0.905) appeared as the best model for LS modeling. The areas under high and very high landslide hazard were gradually increased over the progression of time (26 km2 at the 2 year return period and 40 km2 at the 100 year return period for the high landslide hazard zone, and 6 km2 at the 2 year return period and 20 km2 at the 100 year return period for the very high landslide hazard zone). Similarly, the areas of danger pixel also increased gradually from the 2 to 100 year return periods (37 km2 to 62 km2). Various natural resources, such as scrubland, built up, and sparse vegetation, were identified under risk zone due to landslide hazards. In addition, these resources would be exposed extensively to landslides over the advancement of return periods. Therefore, the outcome of the present study will help planners and scientists to propose high precision management plans for protecting natural resources, which have been exposed to landslides.","",""
24,"V. Croce, G. Caroti, L. D. Luca, K. Jacquot, A. Piemonte, P. Véron","From the Semantic Point Cloud to Heritage-Building Information Modeling: A Semiautomatic Approach Exploiting Machine Learning",2021,"","","","",43,"2022-07-13 10:07:14","","10.3390/rs13030461","","",,,,,24,24.00,4,6,1,"This work presents a semi-automatic approach to the 3D reconstruction of HeritageBuilding Information Models from point clouds based on machine learning techniques. The use of digital information systems leveraging on three-dimensional (3D) representations in architectural heritage documentation and analysis is ever increasing. For the creation of such repositories, realitybased surveying techniques, such as photogrammetry and laser scanning, allow the fast collection of reliable digital replicas of the study objects in the form of point clouds. Besides, their output is raw and unstructured, and the transition to intelligible and semantic 3D representations is still a scarcely automated and time-consuming process requiring considerable human intervention. More refined methods for 3D data interpretation of heritage point clouds are therefore sought after. In tackling these issues, the proposed approach relies on (i) the application of machine learning techniques to semantically label 3D heritage data by identification of relevant geometric, radiometric and intensity features, and (ii) the use of the annotated data to streamline the construction of Heritage-Building Information Modeling (H-BIM) systems, where purely geometric information derived from surveying is associated with semantic descriptors on heritage documentation and management. The “GrandDucal Cloister” dataset, related to the emblematic case study of the Pisa Charterhouse, is discussed.","",""
15,"Vivek Kumar, D. Recupero, Daniele Riboni, Rim Helaoui","Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification From Clinical Notes",2021,"","","","",44,"2022-07-13 10:07:14","","10.1109/ACCESS.2020.3043221","","",,,,,15,15.00,4,4,1,"The past decade has seen an explosion of the amount of digital information generated within the healthcare domain. Digital data exist in the form of images, video, speech, transcripts, electronic health records, clinical records, and free-text. Analysis and interpretation of healthcare data is a daunting task, and it demands a great deal of time, resources, and human effort. In this paper, we focus on the problem of co-morbidity recognition from patient’s clinical records. To this aim, we employ both classical machine learning and deep learning approaches. We use word embeddings and bag-of-words representations, coupled with feature selection techniques. The goal of our work is to develop a classification system to identify whether a certain health condition occurs for a patient by studying his/her past clinical records. In more detail, we have used pre-trained word2vec, domain-trained, GloVe, fastText, and universal sentence encoder embeddings to tackle the classification of sixteen morbidity conditions within clinical records. We have compared the outcomes of classical machine learning and deep learning approaches with the employed feature representation methods and feature selection methods. We present a comprehensive discussion of the performances and behaviour of the employed classical machine learning and deep learning approaches. Finally, we have also used ensemble learning techniques over a large number of combinations of classifiers to improve the single model performance. For our experiments, we used the n2c2 natural language processing research dataset, released by Harvard Medical School. The dataset is in the form of clinical notes that contain patient discharge summaries. Given the unbalancedness of the data and their small size, the experimental results indicate the advantage of the ensemble learning technique with respect to single classifier models. In particular, the ensemble learning technique has slightly improved the performances of single classification models but has greatly reduced the variance of predictions stabilizing the accuracies (i.e., the lower standard deviation in comparison with single classifiers). In real-life scenarios, our work can be employed to identify with high accuracy morbidity conditions of patients by feeding our tool with their current clinical notes. Moreover, other domains where classification is a common problem might benefit from our approach as well.","",""
4,"Ninghao Liu, Mengnan Du, Xia Hu","Adversarial Machine Learning: An Interpretation Perspective",2020,"","","","",45,"2022-07-13 10:07:14","","","","",,,,,4,2.00,1,3,2,"Recent years have witnessed the significant advances of machine learning in a wide spectrum of applications. However, machine learning models, especially deep neural networks, have been recently found to be vulnerable to carefully-crafted input called adversarial samples. The difference between normal and adversarial samples is almost imperceptible to human. Many work have been proposed to study adversarial attack and defense in different scenarios. An intriguing and crucial aspect among those work is to understand the essential cause of model vulnerability, which requires in-depth exploration of another concept in machine learning models, i.e., interpretability. Interpretable machine learning tries to extract human-understandable terms for the working mechanism of models, which also receives a lot of attention from both academia and industry. Recently, an increasing number of work start to incorporate interpretation into the exploration of adversarial robustness. Furthermore, we observe that many previous work of adversarial attacking, although did not mention it explicitly, can be regarded as natural extension of interpretation. In this paper, we review recent work on adversarial attack and defense, particularly, from the perspective of machine learning interpretation. We categorize interpretation into two types, according to whether it focuses on raw features or model components. For each type of interpretation, we elaborate on how it could be used in attacks, or defense against adversaries. After that, we briefly illustrate other possible correlations between the two domains. Finally, we discuss the challenges and future directions along tackling adversary issues with interpretation.","",""
13,"Tharindu Kaluarachchi, Andrew Reis, Suranga Nanayakkara","A Review of Recent Deep Learning Approaches in Human-Centered Machine Learning",2021,"","","","",46,"2022-07-13 10:07:14","","10.3390/s21072514","","",,,,,13,13.00,4,3,1,"After Deep Learning (DL) regained popularity recently, the Artificial Intelligence (AI) or Machine Learning (ML) field is undergoing rapid growth concerning research and real-world application development. Deep Learning has generated complexities in algorithms, and researchers and users have raised concerns regarding the usability and adoptability of Deep Learning systems. These concerns, coupled with the increasing human-AI interactions, have created the emerging field that is Human-Centered Machine Learning (HCML). We present this review paper as an overview and analysis of existing work in HCML related to DL. Firstly, we collaborated with field domain experts to develop a working definition for HCML. Secondly, through a systematic literature review, we analyze and classify 162 publications that fall within HCML. Our classification is based on aspects including contribution type, application area, and focused human categories. Finally, we analyze the topology of the HCML landscape by identifying research gaps, highlighting conflicting interpretations, addressing current challenges, and presenting future HCML research opportunities.","",""
16,"Md. Mokhlesur Rahman, K. Paul, Md. Amjad Hossain, G. Ali, Md. Shahinoor Rahman, J. Thill","Machine Learning on the COVID-19 Pandemic, Human Mobility and Air Quality: A Review",2021,"","","","",47,"2022-07-13 10:07:14","","10.1109/ACCESS.2021.3079121","","",,,,,16,16.00,3,6,1,"The ongoing COVID-19 global pandemic is touching every facet of human lives (e.g., public health, education, economy, transportation, and the environment). This novel pandemic and non-pharmaceutical interventions of lockdown and confinement implemented citywide, regionally or nationally are affecting virus transmission, people’s travel patterns, and air quality. Many studies have been conducted to predict the diffusion of the COVID-19 disease, assess the impacts of the pandemic on human mobility and on air quality, and assess the impacts of lockdown measures on viral spread with a range of Machine Learning (ML) techniques. This literature review aims to analyze the results from past research to understand the interactions among the COVID-19 pandemic, lockdown measures, human mobility, and air quality. The critical review of prior studies indicates that urban form, people’s socioeconomic and physical conditions, social cohesion, and social distancing measures significantly affect human mobility and COVID-19 viral transmission. During the COVID-19 pandemic, many people are inclined to use private transportation for necessary travel to mitigate coronavirus-related health problems. This review study also noticed that COVID-19 related lockdown measures significantly improve air quality by reducing the concentration of air pollutants, which in turn improves the COVID-19 situation by reducing respiratory-related sickness and deaths. It is argued that ML is a powerful, effective, and robust analytic paradigm to handle complex and wicked problems such as a global pandemic. This study also explores the spatio-temporal aspects of lockdown and confinement measures on coronavirus diffusion, human mobility, and air quality. Additionally, we discuss policy implications, which will be helpful for policy makers to take prompt actions to moderate the severity of the pandemic and improve urban environments by adopting data-driven analytic methods.","",""
18,"M. A. Khan, Seifedine Kadry, P. Parwekar, Robertas Damaševičius, A. Mehmood, J. Khan, S. R. Naqvi","Human gait analysis for osteoarthritis prediction: a framework of deep learning and kernel extreme learning machine",2021,"","","","",48,"2022-07-13 10:07:14","","10.1007/S40747-020-00244-2","","",,,,,18,18.00,3,7,1,"","",""
13,"Xinlei Mi, Baiming Zou, F. Zou, J. Hu","Permutation-based identification of important biomarkers for complex diseases via machine learning models",2021,"","","","",49,"2022-07-13 10:07:14","","10.1038/s41467-021-22756-2","","",,,,,13,13.00,3,4,1,"","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",50,"2022-07-13 10:07:14","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
75,"M. Prosperi, Yi Guo, M. Sperrin, J. Koopman, Jae Min, Xing He, S. Rich, Mo Wang, I. Buchan, J. Bian","Causal inference and counterfactual prediction in machine learning for actionable healthcare",2020,"","","","",51,"2022-07-13 10:07:14","","10.1038/s42256-020-0197-y","","",,,,,75,37.50,8,10,2,"","",""
12,"Atik Mahabub","A robust voting approach for diabetes prediction using traditional machine learning techniques",2019,"","","","",52,"2022-07-13 10:07:14","","10.1007/s42452-019-1759-7","","",,,,,12,4.00,12,1,3,"","",""
5,"Xiaohua Li, Yu Chen, K. Zeng","Integration of machine learning and human learning for training optimization in robust linear regression",2016,"","","","",53,"2022-07-13 10:07:14","","10.1109/ICASSP.2016.7472150","","",,,,,5,0.83,2,3,6,"In this paper machine learning and human learning are applied jointly to optimize the training of linear regression. Human learning is exploited to label extra training data so as to resolve problems such as insufficient training and over-fitting. Considering the inevitable human errors in labeling, two machine learning algorithms are developed which optimize the selection of the extra training data and detect human errors during linear regression. The first algorithm assumes sparse human errors and implements a sparse optimization within a sequential active learning procedure. The second algorithm deals with non-sparse human errors. By exploiting the IRT (item response theory) to model the distribution of human errors, it reconstructs the training data set so that the human labeling errors become sparse. Simulations are conducted to show that the two algorithms are effective in resolving the insufficient training and human labeling error problems.","",""
29,"Muhammet Fatih Aslan, Akif Durdu, K. Sabanci","Human action recognition with bag of visual words using different machine learning methods and hyperparameter optimization",2019,"","","","",54,"2022-07-13 10:07:14","","10.1007/s00521-019-04365-9","","",,,,,29,9.67,10,3,3,"","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",55,"2022-07-13 10:07:14","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",56,"2022-07-13 10:07:14","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
9,"J. Harrison, J. Gilbertson, M. Hanna, N. Olson, J. Seheult, James M. Sorace, M. Stram","Introduction to Artificial Intelligence and Machine Learning for Pathology.",2021,"","","","",57,"2022-07-13 10:07:14","","10.5858/arpa.2020-0541-CP","","",,,,,9,9.00,1,7,1,"CONTEXT.— Recent developments in machine learning have stimulated intense interest in software that may augment or replace human experts. Machine learning may impact pathology practice by offering new capabilities in analysis, interpretation, and outcomes prediction using images and other data. The principles of operation and management of machine learning systems are unfamiliar to pathologists, who anticipate a need for additional education to be effective as expert users and managers of the new tools.   OBJECTIVE.— To provide a background on machine learning for practicing pathologists, including an overview of algorithms, model development, and performance evaluation; to examine the current status of machine learning in pathology and consider possible roles and requirements for pathologists in local deployment and management of machine learning systems; and to highlight existing challenges and gaps in deployment methodology and regulation.   DATA SOURCES.— Sources include the biomedical and engineering literature, white papers from professional organizations, government reports, electronic resources, and authors' experience in machine learning. References were chosen when possible for accessibility to practicing pathologists without specialized training in mathematics, statistics, or software development.   CONCLUSIONS.— Machine learning offers an array of techniques that in recent published results show substantial promise. Data suggest that human experts working with machine learning tools outperform humans or machines separately, but the optimal form for this combination in pathology has not been established. Significant questions related to the generalizability of machine learning systems, local site verification, and performance monitoring remain to be resolved before a consensus on best practices and a regulatory environment can be established.","",""
9,"Kamalaker Dadi, G. Varoquaux, J. Houenou, D. Bzdok, B. Thirion, D. Engemann","Population modeling with machine learning can enhance measures of mental health",2021,"","","","",58,"2022-07-13 10:07:14","","10.1101/2020.08.25.266536","","",,,,,9,9.00,2,6,1,"Background Biological aging is revealed by physical measures, e.g., DNA probes or brain scans. Instead, individual differences in mental function are explained by psychological constructs, e.g., intelligence or neuroticism. These constructs are typically assessed by tailored neuropsychological tests that build on expert judgement and require careful interpretation. Could machine learning on large samples from the general population be used to build proxy measures of these constructs that do not require human intervention? Results Here, we built proxy measures by applying machine learning on multimodal MR images and rich sociodemographic information from the largest biomedical cohort to date: the UK Biobank. Objective model comparisons revealed that all proxies captured the target constructs and were as useful, and sometimes more useful than the original measures for characterizing real-world health behavior (sleep, exercise, tobacco, alcohol consumption). We observed this complementarity of proxy measures and original measures when modeling from brain signals or sociodemographic data, capturing multiple health-related constructs. Conclusions Population modeling with machine learning can derive measures of mental health from brain signals and questionnaire data, which may complement or even substitute for psychometric assessments in clinical populations. Key Points We applied machine learning on more than 10.000 individuals from the general population to define empirical approximations of health-related psychological measures that do not require human judgment. We found that machine-learning enriched the given psychological measures via approximation from brain and sociodemographic data: Resulting proxy measures related as well or better to real-world health behavior than the original measures. Model comparisons showed that sociodemographic information contributed most to characterizing psychological traits beyond aging.","",""
0,"P. O. Fernandes, J. Martins, E. D. de Melo, R. B. de Oliveira, T. Kronenberger, V. Maltarollo","Quantitative structure-activity relationship and machine learning studies of 2-thiazolylhydrazone derivatives with anti-Cryptococcus neoformans activity.",2021,"","","","",59,"2022-07-13 10:07:14","","10.1080/07391102.2021.1935321","","",,,,,0,0.00,0,6,1,"Cryptococcus neoformans is a fungus responsible for infections in humans with a significant number of cases in immunosuppressed patients, mainly in underdeveloped countries. In this context, the thiazolylhydrazones are a promising class of compounds with activity against C. neoformans. The understanding of the structure-activity relationship of these derivatives could lead to the design of robust compounds that could be promising drug candidates for fungal infections. Specifically, modern techniques such as 4D-QSAR and machine learning methods were employed in this work to generate two QSAR models (one 2D and one 4D) with high predictive power (r2 for the test set equals to 0.934 and 0.831, respectively), and one random forest classification model was reported with Matthews correlation coefficient equals to 1 and 0.62 for internal and external validations, respectively. The physicochemical interpretation of selected models, indicated the importance of aliphatic substituents at the hydrazone moiety to antifungal activity, corroborating experimental data.Communicated by Ramaswamy H. Sarma.","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",60,"2022-07-13 10:07:14","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
9,"T. Botari, Rafael Izbicki, A. Carvalho","Local Interpretation Methods to Machine Learning Using the Domain of the Feature Space",2019,"","","","",61,"2022-07-13 10:07:14","","10.1007/978-3-030-43823-4_21","","",,,,,9,3.00,3,3,3,"","",""
11,"A. Abrol, Z. Fu, Mustafa S. Salman, Rogers F. Silva, Y. Du, S. Plis, V. Calhoun","Hype versus hope: Deep learning encodes more predictive and robust brain imaging representations than standard machine learning",2020,"","","","",62,"2022-07-13 10:07:14","","10.1101/2020.04.14.041582","","",,,,,11,5.50,2,7,2,"Previous successes of deep learning (DL) approaches on several complex tasks have hugely inflated expectations of their power to learn subtle properties of complex brain imaging data, and scale to large datasets. Perhaps as a reaction to this inflation, recent critical commentaries unfavorably compare DL with standard machine learning (SML) approaches for the analysis of brain imaging data. Yet, their conclusions are based on pre-engineered features which deprives DL of its main advantage: representation learning. Here we evaluate this and show the importance of representation learning for DL performance on brain imaging data. We report our findings from a large-scale systematic comparison of SML approaches versus DL profiled in a ten-way age and gender-based classification task on 12,314 structural MRI images. Results show that DL methods, if implemented and trained following the prevalent DL practices, have the potential to substantially improve compared to SML approaches. We also show that DL approaches scale particularly well presenting a lower asymptotic complexity in relative computational time, despite being more complex. Our analysis reveals that the performance improvement saturates as the training sample size grows, but shows significantly higher performance throughout. We also show evidence that the superior performance of DL is primarily due to the excellent representation learning capabilities and that SML methods can perform equally well when operating on representations produced by the trained DL models. Finally, we demonstrate that DL embeddings span a comprehensible projection spectrum and that DL consistently localizes discriminative brain biomarkers, providing an example of the robustness of prediction relevance estimates. Our findings highlight the presence of non-linearities in brain imaging data that DL frameworks can exploit to generate superior predictive representations for characterizing the human brain, even with currently available data sizes.","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",63,"2022-07-13 10:07:14","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
87,"Kate Crawford, T. Paglen","Excavating AI: the politics of images in machine learning training sets",2021,"","","","",64,"2022-07-13 10:07:14","","10.1007/S00146-021-01162-8","","",,,,,87,87.00,44,2,1,"","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",65,"2022-07-13 10:07:14","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
3,"H. Castañé, G. Baiges-Gaya, A. Hernández-Aguilera, E. Rodríguez-Tomàs, S. Fernández-Arroyo, P. Herrero, A. Delpino-Rius, N. Canela, J. Menéndez, J. Camps, J. Joven","Coupling Machine Learning and Lipidomics as a Tool to Investigate Metabolic Dysfunction-Associated Fatty Liver Disease. A General Overview",2021,"","","","",66,"2022-07-13 10:07:14","","10.3390/biom11030473","","",,,,,3,3.00,0,11,1,"Hepatic biopsy is the gold standard for staging nonalcoholic fatty liver disease (NAFLD). Unfortunately, accessing the liver is invasive, requires a multidisciplinary team and is too expensive to be conducted on large segments of the population. NAFLD starts quietly and can progress until liver damage is irreversible. Given this complex situation, the search for noninvasive alternatives is clinically important. A hallmark of NAFLD progression is the dysregulation in lipid metabolism. In this context, recent advances in the area of machine learning have increased the interest in evaluating whether multi-omics data analysis performed on peripheral blood can enhance human interpretation. In the present review, we show how the use of machine learning can identify sets of lipids as predictive biomarkers of NAFLD progression. This approach could potentially help clinicians to improve the diagnosis accuracy and predict the future risk of the disease. While NAFLD has no effective treatment yet, the key to slowing the progression of the disease may lie in predictive robust biomarkers. Hence, to detect this disease as soon as possible, the use of computational science can help us to make a more accurate and reliable diagnosis. We aimed to provide a general overview for all readers interested in implementing these methods.","",""
4,"S. Nomm, Alejandro Guerra-Manzanares, Hayretdin Bahsi","Towards the Integration of a Post-Hoc Interpretation Step into the Machine Learning Workflow for IoT Botnet Detection",2019,"","","","",67,"2022-07-13 10:07:14","","10.1109/ICMLA.2019.00193","","",,,,,4,1.33,1,3,3,"The analysis of the interplay between the feature selection and the post-hoc local interpretation steps in a machine learning workflow followed for IoT botnet detection constitutes the research scope of the present paper. While the application of machine learning-based techniques has become a trend in cyber security, the main focus has been almost on detection accuracy. However, providing the relevant explanation for a detection decision is a vital requirement in a tiered incident handling processes of the contemporary security operations centers. Moreover, the design of intrusion detection systems in IoT networks has to take the limitations of the computational resources into consideration. Therefore, resource limitations in addition to human element of incident handling necessitate considering feature selection and interpretability at the same time in machine learning workflows. In this paper, first, we analyzed the selection of features and its implication on the data accuracy. Second, we investigated the impact of feature selection on the explanations generated at the post-hoc interpretation phase. We utilized a filter method, Fisher's Score and Local Interpretable Model-Agnostic Explanation (LIME) at feature selection and post-hoc interpretation phases, respectively. To evaluate the quality of explanations, we proposed a metric that reflects the need of the security analysts. It is demonstrated that the application of both steps for the particular case of IoT botnet detection may result in highly accurate and interpretable learning models induced by fewer features. Our metric enables us to evaluate the detection accuracy and interpretability in an integrated way.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",68,"2022-07-13 10:07:14","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
0,"G. Truda","Quantified Sleep: Machine learning techniques for observational n-of-1 studies",2021,"","","","",69,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,1,1,"This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features. The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. “Markov unfolding” is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal β-parameters, and using the SHAP framework, which can explain any “black box” model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",70,"2022-07-13 10:07:14","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
1,"Riqiang Gao, Mirza S. Khan, Yucheng Tang, Kaiwen Xu, S. Deppen, Yuankai Huo, K. Sandler, P. Massion, B. Landman","Technical Report: Quality Assessment Tool for Machine Learning with Clinical CT",2021,"","","","",71,"2022-07-13 10:07:14","","","","",,,,,1,1.00,0,9,1,"Image Quality Assessment (IQA) is important for scientific inquiry, especially in medical imaging and machine learning. Potential data quality issues can be exacerbated when human-based workflows use limited views of the data that may obscure digital artifacts. In practice, multiple factors such as network issues, accelerated acquisitions, motion artifacts, and imaging protocol design can impede the interpretation of image collections. The medical image processing community has developed a wide variety of tools for the inspection and validation of imaging data. Yet, IQA of computed tomography (CT) remains an under-recognized challenge, and no user-friendly tool is commonly available to address these potential issues. Here, we create and illustrate a pipeline specifically designed to identify and resolve issues encountered with large-scale data mining of clinically acquired CT data. Using the widely studied National Lung Screening Trial (NLST), we have identified approximately 4% of image volumes with quality concerns out of 17,392 scans. To assess robustness, we applied the proposed pipeline to our internal datasets where we find our tool is generalizable to clinically acquired medical images. In conclusion, the tool has been useful and time-saving for research study of clinical data, and the code and tutorials are publicly available at https://github.com/MASILab/QA_tool.","",""
1,"J. Ani, Mirajul Islam, Nushrat Jahan Ria, Sharmin Akter, Abu Kaisar Mohammad Masum","Estimating Gender Based On Bengali Conventional Full Name With Various Machine Learning Techniques",2021,"","","","",72,"2022-07-13 10:07:14","","10.1109/ICCCNT51525.2021.9579927","","",,,,,1,1.00,0,5,1,"For finding patterns in data, machine learning models are being trained. Gender relations psychology looks for social norms like inter dimensionality, beliefs, social experience and self-perception, and self-respect. Training on gender based text NLP models unknowingly become acquainted with unusual patterns. In this paper, we represent gender recognition by using Bengali conventional full names. We present a review and interpretation of gender classification based on individual names in this correspondence. These days, NLP has demonstrated excellent execution in identifying human gender. In the field of knowledge, gender classification is a demonstrative binary classification phenomenon. We've used a total of seven algorithms in this research. We were added to the dataset with details regarding which features are currently used for prediction along with that it determines how these features are affected by data preprocessing model initialization and architecture selection. Our research compares those classifiers, examines the impact of pretraining moreover, assesses the robustness of the alignment preprocessing through the confusion matrix.. The proposed Neural Network outperforms most approaches and is much more reliable than other models. This model has the best weighted precision of all the models, with such a 73.04 % accuracy score.","",""
0,"Ahmed Reda Ali, M. Jaya, E. A. Jones","Machine Learning Strategies for Accurate Log Prediction in Reservoir Characterization: Self-Calibrating Versus Domain-Knowledge",2021,"","","","",73,"2022-07-13 10:07:14","","10.2118/205602-ms","","",,,,,0,0.00,0,3,1,"  Petrophysical evaluation is a crucial task for reservoir characterization but it is often complicated, time-consuming and associated with uncertainties. Moreover, this job is subjective and ambiguous depending on the petrophysicist's experience. Utilizing the flourishing Artificial Intelligence (AI)/Machine Learning (ML) is a way to build an automating process with minimal human intervention, improving consistency and efficiency of well log prediction and interpretation. Nowadays, the argument is whether AI-ML should base on a statistically self-calibrating or knowledge-based prediction framework! In this study, we develop a petrophysically knowledge-based AI-ML workflow that upscale sparsely-sampled core porosity and permeability into continuous curves along the entire well interval.  AI-ML focuses on making predictions from analyzing data by learning and identifying patterns. The accuracy of the self-calibrating statistical models is heavily dependent on the volume of training data. The proposed AI-ML workflow uses raw well logs (gamma-ray, neutron and density) to predict porosity and permeability over the well interval using sparsely core data. The challenge in building the AI-ML model is the number of data points used for training showed an imbalance in the relative sampling of plugs, i.e. the number of core data (used as target variable) is less than 10%. Ensemble learning and stacking ML approaches are used to obtain maximum predictive performance of self-calibrating learning strategy.  Alternatively, a new petrophysical workflow is established to debrief the domain experience in the feature selection that is used as an important weight in the regression problem. This helps ML model to learn more accurately by discovering hidden relationships between independent and target variables. This workflow is the inference engine of the AI-ML model to extract relevant domain-knowledge within the system that leads to more accurate predictions.  The proposed knowledge-driven ML strategy achieved a prediction accuracy of R2 score = 87% (Correlation Coefficient (CC) of 96%). This is a significant improvement by R2 = 57% (CC = 62%) compared to the best performing self-calibrating ML models. The predicted properties are upscaled automatically to predict uncored intervals, improving data coverage and property population in reservoir models leading to the improvement of the model robustness. The high prediction accuracy demonstrates the potential of knowledge-driven AI-ML strategy in predicting rock properties under data sparsity and limitations and saving significant cost and time.  This paper describes an AI-ML workflow that predicts high-resolution continuous porosity and permeability logs from imbalanced and sparse core plug data. The method successfully incorporates new type petrophysical facies weight as a feature augmentation engine for ML domain-knowledge framework. The workflow consisted of petrophysical treatment of raw data includes log quality control, preconditioning, processing, features augmentation and labelling, followed by feature selection to impersonate domain experience.","",""
5,"S. Satapathy, D. Loganathan","A Study of Human Sleep Stage Classification Based on Dual Channels of EEG Signal Using Machine Learning Techniques",2021,"","","","",74,"2022-07-13 10:07:14","","10.1007/s42979-021-00528-5","","",,,,,5,5.00,3,2,1,"","",""
21,"Aurélien Appriou, A. Cichocki, F. Lotte","Towards Robust Neuroadaptive HCI: Exploring Modern Machine Learning Methods to Estimate Mental Workload From EEG Signals",2018,"","","","",75,"2022-07-13 10:07:14","","10.1145/3170427.3188617","","",,,,,21,5.25,7,3,4,"Estimating mental workload from brain signals such as Electroencephalography (EEG) has proven very promising in multiple Human-Computer Interaction (HCI) applications, e.g., to design games or educational applications with adaptive difficulty, or to assess how cognitively difficult to use an interface can be. However, current EEG-based workload estimation may not be robust enough for some practical applications. Indeed, the currently obtained workload classification accuracies are relatively low, making the resulting estimations not fully trustable. This paper thus studies promising modern machine learning algorithms, including Riemannian geometry-based methods and Deep Learning, to estimate workload from EEG signals. We study them with both user-specific and user-independent calibration, to go towards calibration-free systems. Our results suggested that a shallow Convolutional Neural Network obtained the best performance in both conditions, outperforming state-of-the-art methods on the used data sets. This suggests that Deep Learning can bring new possibilities in HCI.","",""
21,"Shantani Kannan, K. Subbaram, Sheeza Ali, H. Kannan","The Role of Artificial Intelligence and Machine Learning Techniques: Race for COVID-19 Vaccine",2020,"","","","",76,"2022-07-13 10:07:14","","10.5812/archcid.103232","","",,,,,21,10.50,5,4,2,"Context: In the healthcare system, Artificial Intelligence (AI) is emerging as a productive tool. There are instances where AI has done marvels in the diagnosis of various health conditions and the interpretation of complex medical disorders. Although AI is far from human intelligence, it can be used as an effective tool to study the SARS-CoV-2 and its capabilities, virulence, and genome. The progress of the pandemic can be tracked, and the patients can be monitored, thereby speeding up the research for the treatment of COVID-19. In this review article, we highlighted the importance of AI and Machine learning (ML) techniques that can speed up the path to the discovery of a possible cure for COVID-19. We also deal with the interactions between viromics and AI, which can hopefully find a solution to this pandemic. Evidence Acquisition: A review of different articles was conducted using the following databases: MEDLINE/PubMed, SCOPUS, Web of Science, ScienceDirect, and Google Scholar for recent studies regarding the use of AI, seeking the spread of different infectious diseases using relevant MeSH subheadings. Results: After a thorough screening of different articles, 30 articles were considered, and key information was obtained from them. Finally, the scope was broadened to obtain more information. Our findings indicated that AI/ML is a promising approach to drug development. Conclusions: The field of AI has enormous potential to predict the changes that may take place in the environment. If this technology is applied to situations of a pandemic such as COVID-19, breakthroughs could potentially pave the way for new vaccines and antiviral drugs.","",""
0,"S. Chujfi, C. Meinel","Machine Learning and Human Cognition Combined to Enhance Knowledge Discovery Fidelity",2019,"","","","",77,"2022-07-13 10:07:14","","10.1109/CogMI48466.2019.00010","","",,,,,0,0.00,0,2,3,"The objective of this work is knowledge discovery in large-scale audio files by performing a Cognitive Analysis – CA –, where the knowledge is extracted from transcribed customer service conversations taking into consideration individual cognitive styles to mimic the human cognitive process and maximize the correct meaning interpretation information in a given context. We make the following three contributions: (i) integrate a Cyber Cognitive Identity model – CCI – that states the cognitive profile an individual has for interacting in cyberspace, which yields superior fidelity to identify the meaning of spoken sentences following Sternberg's Thinking Style Inventory (TSI). In particular it guides an analysis grounded in peers' cognitive styles to index words by dimension; (ii) a novel method that extends the Latent Dirichlet Allocation (LDA) approach to a multidimensional partially supervised machine learning model with the help of the psychological activation theory Adaptive Control of Thought – ACT; (iii) an improvement of the Exploratory Data Analysis – EDA–suggested by De Mast and Trip, envisioned as an extended approach to obtain high-fidelity data where topics of a three-dimensional corpus are clustered according to cognitive categorizations. Using speech-to-text software, we transcribed and evaluated 27 500 calls from 206 German-speaking teleworkers combining these three complementary methods and achieved significant fidelity to generate a hypothesis based on individuals' cognitive affinities.","",""
18,"S. Moazemi, Z. Khurshid, A. Erle, S. Lütje, M. Essler, T. Schultz, R. Bundschuh","Machine Learning Facilitates Hotspot Classification in PSMA-PET/CT with Nuclear Medicine Specialist Accuracy",2020,"","","","",78,"2022-07-13 10:07:14","","10.3390/diagnostics10090622","","",,,,,18,9.00,3,7,2,"Gallium-68 prostate-specific membrane antigen positron emission tomography (68Ga-PSMA-PET) is a highly sensitive method to detect prostate cancer (PC) metastases. Visual discrimination between malignant and physiologic/unspecific tracer accumulation by a nuclear medicine (NM) specialist is essential for image interpretation. In the future, automated machine learning (ML)-based tools will assist physicians in image analysis. The aim of this work was to develop a tool for analysis of 68Ga-PSMA-PET images and to compare its efficacy to that of human readers. Five different ML methods were compared and tested on multiple positron emission tomography/computed tomography (PET/CT) data-sets. Forty textural features extracted from both PET- and low-dose CT data were analyzed. In total, 2419 hotspots from 72 patients were included. Comparing results from human readers to those of ML-based analyses, up to 98% area under the curve (AUC), 94% sensitivity (SE), and 89% specificity (SP) were achieved. Interestingly, textural features assessed in native low-dose CT increased the accuracy significantly. Thus, ML based on 68Ga-PSMA-PET/CT radiomics features can classify hotspots with high precision, comparable to that of experienced NM physicians. Additionally, the superiority of multimodal ML-based analysis considering all PET and low-dose CT features was shown. Morphological features seemed to be of special additional importance even though they were extracted from native low-dose CTs.","",""
20,"Taylor Faucett, J. Thaler, D. Whiteson","Mapping machine-learned physics into a human-readable space",2020,"","","","",79,"2022-07-13 10:07:14","","10.1103/PHYSREVD.103.036020","","",,,,,20,10.00,7,3,2,"We present a technique for translating a black-box machine-learned classifier operating on a high-dimensional input space into a small set of human-interpretable observables that can be combined to make the same classification decisions. We iteratively select these observables from a large space of high-level discriminants by finding those with the highest decision similarity relative to the black box, quantified via a metric we introduce that evaluates the relative ordering of pairs of inputs. Successive iterations focus only on the subset of input pairs that are misordered by the current set of observables. This method enables simplification of the machine-learning strategy, interpretation of the results in terms of well-understood physical concepts, validation of the physical model, and the potential for new insights into the nature of the problem itself. As a demonstration, we apply our approach to the benchmark task of jet classification in collider physics, where a convolutional neural network acting on calorimeter jet images outperforms a set of six well-known jet substructure observables. Our method maps the convolutional neural network into a set of observables called energy flow polynomials, and it closes the performance gap by identifying a class of observables with an interesting physical interpretation that has been previously overlooked in the jet substructure literature.","",""
6,"Matthew Norton, Akiko Takeda, Alexander Mafusalov","Optimistic Robust Optimization With Applications To Machine Learning",2017,"","","","",80,"2022-07-13 10:07:14","","","","",,,,,6,1.20,2,3,5,"Robust Optimization has traditionally taken a pessimistic, or worst-case viewpoint of uncertainty which is motivated by a desire to find sets of optimal policies that maintain feasibility under a variety of operating conditions. In this paper, we explore an optimistic, or best-case view of uncertainty and show that it can be a fruitful approach. We show that these techniques can be used to address a wide variety of problems. First, we apply our methods in the context of robust linear programming, providing a method for reducing conservatism in intuitive ways that encode economically realistic modeling assumptions. Second, we look at problems in machine learning and find that this approach is strongly connected to the existing literature. Specifically, we provide a new interpretation for popular sparsity inducing non-convex regularization schemes. Additionally, we show that successful approaches for dealing with outliers and noise can be interpreted as optimistic robust optimization problems. Although many of the problems resulting from our approach are non-convex, we find that DCA or DCA-like optimization approaches can be intuitive and efficient.","",""
13,"Alexander M Zolotarev, B. Hansen, Ekaterina A. Ivanova, Katelynn M. Helfrich, Ning Li, P. Janssen, P. Mohler, N. Mokadam, B. Whitson, M. Fedorov, J. Hummel, D. Dylov, V. Fedorov","Optical Mapping-Validated Machine Learning Improves Atrial Fibrillation Driver Detection by Multi-Electrode Mapping",2020,"","","","",81,"2022-07-13 10:07:14","","10.1161/CIRCEP.119.008249","","",,,,,13,6.50,1,13,2,"Supplemental Digital Content is available in the text. Background: Atrial fibrillation (AF) can be maintained by localized intramural reentrant drivers. However, AF driver detection by clinical surface-only multielectrode mapping (MEM) has relied on subjective interpretation of activation maps. We hypothesized that application of machine learning to electrogram frequency spectra may accurately automate driver detection by MEM and add some objectivity to the interpretation of MEM findings. Methods: Temporally and spatially stable single AF drivers were mapped simultaneously in explanted human atria (n=11) by subsurface near-infrared optical mapping (NIOM; 0.3 mm2 resolution) and 64-electrode MEM (higher density or lower density with 3 and 9 mm2 resolution, respectively). Unipolar MEM and NIOM recordings were processed by Fourier transform analysis into 28 407 total Fourier spectra. Thirty-five features for machine learning were extracted from each Fourier spectrum. Results: Targeted driver ablation and NIOM activation maps efficiently defined the center and periphery of AF driver preferential tracks and provided validated annotations for driver versus nondriver electrodes in MEM arrays. Compared with analysis of single electrogram frequency features, averaging the features from each of the 8 neighboring electrodes, significantly improved classification of AF driver electrograms. The classification metrics increased when less strict annotation, including driver periphery electrodes, were added to driver center annotation. Notably, f1-score for the binary classification of higher-density catheter data set was significantly higher than that of lower-density catheter (0.81±0.02 versus 0.66±0.04, P<0.05). The trained algorithm correctly highlighted 86% of driver regions with higher density but only 80% with lower-density MEM arrays (81% for lower-density+higher-density arrays together). Conclusions: The machine learning model pretrained on Fourier spectrum features allows efficient classification of electrograms recordings as AF driver or nondriver compared with the NIOM gold-standard. Future application of NIOM-validated machine learning approach may improve the accuracy of AF driver detection for targeted ablation treatment in patients.","",""
12,"Boris Kovalerchuk, M. Ahmad, Ankur Teredesai Department of Computer Science, Central Washington University, U. C. O. Science, Systems, University of Washington Tacoma, Usa Kensci Inc., Usa","Survey of explainable machine learning with visual and granular methods beyond quasi-explanations",2020,"","","","",82,"2022-07-13 10:07:14","","10.1007/978-3-030-64949-4_8","","",,,,,12,6.00,1,9,2,"","",""
36,"Rachelly Normand, Wenfei Du, Mayan Briller, R. Gaujoux, E. Starosvetsky, Amit Ziv-Kenet, Gali Shalev-Malul, R. Tibshirani, S. Shen-Orr","Found In Translation: a machine learning model for mouse-to-human inference",2018,"","","","",83,"2022-07-13 10:07:14","","10.1038/s41592-018-0214-9","","",,,,,36,9.00,4,9,4,"","",""
2,"A. Smart, Larry James, B. Hutchinson, Simone Wu, Shannon Vallor","Why Reliabilism Is not Enough: Epistemic and Moral Justification in Machine Learning",2020,"","","","",84,"2022-07-13 10:07:14","","10.1145/3375627.3375866","","",,,,,2,1.00,0,5,2,"In this paper we argue that standard calls for explainability that focus on the epistemic inscrutability of black-box machine learning models may be misplaced. If we presume, for the sake of this paper, that machine learning can be a source of knowledge, then it makes sense to wonder what kind of \em justification it involves. How do we rationalize on the one hand the seeming justificatory black box with the observed wide adoption of machine learning? We argue that, in general, people implicitly adoptreliabilism regarding machine learning. Reliabilism is an epistemological theory of epistemic justification according to which a belief is warranted if it has been produced by a reliable process or method \citegoldman2012reliabilism. We argue that, in cases where model deployments require \em moral justification, reliabilism is not sufficient, and instead justifying deployment requires establishing robust human processes as a moral ""wrapper'' around machine outputs. We then suggest that, in certain high-stakes domains with moral consequences, reliabilism does not provide another kind of necessary justification---moral justification. Finally, we offer cautions relevant to the (implicit or explicit) adoption of the reliabilist interpretation of machine learning.","",""
10,"T. Mizoguchi, S. Kiyohara","Machine learning approaches for ELNES/XANES.",2020,"","","","",85,"2022-07-13 10:07:14","","10.1093/jmicro/dfz109","","",,,,,10,5.00,5,2,2,"Materials characterization is indispensable for materials development. In particular, spectroscopy provides atomic configuration, chemical bonding and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material. Despite its importance, the interpretation of spectra using human-driven methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the rapid increase in experimental spectral data. To overcome the limitations of such methods, we develop new data-driven approaches based on machine learning. Specifically, we use hierarchical clustering, a decision tree and a feedforward neural network to investigate the electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as local measurement of material functions.","",""
17,"Xuesi Ma, Baohang Xi, Yi Zhang, Lijuan Zhu, Xin Sui, Geng Tian, Jialiang Yang","A Machine Learning-based Diagnosis of Thyroid Cancer Using Thyroid Nodules Ultrasound Images",2020,"","","","",86,"2022-07-13 10:07:14","","10.2174/1574893614666191017091959","","",,,,,17,8.50,2,7,2,"  Ultrasound test is one of the routine tests for the diagnosis of thyroid cancer. The diagnosis accuracy depends largely on the correct interpretation of ultrasound images of thyroid nodules. However, human eye-based image recognition is usually subjective and sometimes error-prone especially for less experienced doctors, which presents a need for computeraided diagnostic systems.    To our best knowledge, there is no well-maintained ultrasound image database for the Chinese population. In addition, though there are several computational methods for image-based thyroid cancer detection, a comparison among them is missing. Finally, the effects of features like the choice of distance measures have not been assessed. The study aims to give the improvement of these limitations and proposes a highly accurate image-based thyroid cancer diagnosis system, which can better assist doctors in the diagnosis of thyroid cancer.    We first establish a novel thyroid nodule ultrasound image database consisting of 508 images collected from the Third Hospital of Hebei Medical University in China. The clinical information for the patients is also collected from the hospital, where 415 patients are diagnosed to be benign and 93 are malignant by doctors following a standard diagnosis procedure. We develop and apply five machine learning methods to the dataset including deep neural network, support vector machine, the center clustering method, k-nearest neighbor, and logistic regression.    Experimental results show that deep neural network outperforms other diagnosis methods with an average cross-validation accuracy of 0.87 in 10 runs. Meanwhile, we also explore the performance of four image distance measures including the Euclidean distance, the Manhattan distance, the Chebyshev distance, and the Minkowski distance, among which the Chebyshev distance is the best. The resource can be directly used to aid doctors in thyroid cancer diagnosis and treatment.    The paper establishes a novel thyroid nodule ultrasound image database and develops a high accurate image-based thyroid cancer diagnosis system which can better assist doctors in the diagnosis of thyroid cancer. ","",""
506,"W. James Murdoch, Chandan Singh, Karl Kumbier, R. Abbasi-Asl, Bin Yu","Definitions, methods, and applications in interpretable machine learning",2019,"","","","",87,"2022-07-13 10:07:14","","10.1073/pnas.1900654116","","",,,,,506,168.67,101,5,3,"Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.","",""
24,"Bethany Signal, B. Gloss, M. Dinger, T. Mercer","Machine learning annotation of human branchpoints",2018,"","","","",88,"2022-07-13 10:07:14","","10.1093/bioinformatics/btx688","","",,,,,24,6.00,6,4,4,"Motivation: The branchpoint element is required for the first lariat‐forming reaction in splicing. However current catalogues of human branchpoints remain incomplete due to the difficulty in experimentally identifying these splicing elements. To address this limitation, we have developed a machine‐learning algorithm—branchpointer—to identify branchpoint elements solely from gene annotations and genomic sequence. Results: Using branchpointer, we annotate branchpoint elements in 85% of human gene introns with sensitivity (61.8%) and specificity (97.8%). In addition to annotation, branchpointer can evaluate the impact of SNPs on branchpoint architecture to inform functional interpretation of genetic variants. Branchpointer identifies all published deleterious branchpoint mutations annotated in clinical variant databases, and finds thousands of additional clinical and common genetic variants with similar predicted effects. This genome‐wide annotation of branchpoints provides a reference for the genetic analysis of splicing, and the interpretation of noncoding variation. Availability and implementation: Branchpointer is written and implemented in the statistical programming language R and is freely available under a BSD license as a package through Bioconductor. Contact: b.signal@garvan.org.au or t.mercer@garvan.org Supplementary information: Supplementary data are available at Bioinformatics online.","",""
0,"T. Mizoguchi, S. Kiyohara","Chapter 17. Machine Learning for Core-loss Spectrum",2020,"","","","",89,"2022-07-13 10:07:14","","10.1039/9781839160233-00424","","",,,,,0,0.00,0,2,2,"Characterization is indispensable for developing functional materials and molecules. In particular, spectroscopy provides atomic configuration, chemical bonding, and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material and molecule. Despite its importance, the interpretation of spectra using “human-driven” methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the increase in experimental data. To overcome the limitations of “human-driven” methods, new data-driven approaches based on machine learning were developed. In this chapter, we review our machine learning method for spectral analysis. Hierarchical clustering, a decision tree, and a feedforward neural network were combined to investigate the core loss spectroscopy, namely electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as the local measurement of material functions.","",""
0,"Adhideb Ghosh, A. Navarini","Biological function polarity prediction of missense variants using machine learning",2020,"","","","",90,"2022-07-13 10:07:14","","10.1101/2020.04.03.023440","","",,,,,0,0.00,0,2,2,"Functional interpretation is crucial when facing on average 20,000 missense variants per human exome, as the great majority are not associated with any underlying disease. In silico bioinformatics tools can predict the deleteriousness of variants or assess their functional impact by assigning scores, but they cannot predict whether the variant in question results in gain or loss of function at the protein level. Here, we show that machine learning can effectively predict this biological function polarity of missense variants. The new method adapts weighted gradient boosting machine approach on a set of damaging variants (1,288 loss of function and 218 gain of function variants) as annotated by the tools SIFT, PolyPhen2 and CADD. Area under the ROC curve of 0.85 illustrates high discriminative power of the classifier. Predictive performance of the classifier remains consistent against an independent set of damaging variants as highlighted by the area under the ROC curve of 0.83. This new approach may help to guide biological experiments on the clinical relevance of damaging genetic variants. Author summary Missense variant occurs when a single genetic alteration in DNA takes place and as a result a new amino acid is translated into the protein. This amino acid change can inactivate the existing protein function causing loss-of-function or produce a new function causing gain-of-function. Therefore, it is very important to interpret these functional consequences of missense variants as they often turn out to be disease causing. Each individual’s genome sequence has thousands of missense variants, out of which very few are actually associated with any underlying disease. Various computational tools have been developed to predict whether missense variants are damaging or not, but none of them can actually predict whether the damaging missense variants cause gain-of-function or loss-of-function. We have developed a new ensemble classifier to predict this biological function polarity at the protein level. The classifier combines the prediction scores of three existing bioinformatics tools and applies machine learning to make effective predictions. We have validated our classifier against an independent data set to show its high predictive power and robustness. The predictions made by our machine learning tool can be used as indicators of biological function polarity, but with further evidence on pathogenicity.","",""
0,"Jia Qi Lim, N. Alias, F. Johar","Supervised Classification of Normal and Tumorous Brain MR Images Using Machine Learning Schemes",2020,"","","","",91,"2022-07-13 10:07:14","","10.20944/preprints202007.0688.v1","","",,,,,0,0.00,0,3,2,"Manual interpretation of these huge amounts of image volumes are susceptible to inter-reader variability and human error. Thus, accurate automated CAD scheme is highly desirable in clinical pathological diagnosis. In this research, plethora of machine learning paradigms (e.g. feature extraction, dimensionality reduction and supervised classification methods) were explored, evaluated, compared and analyzed to identify the optimal pathway for brain MR images (normal vs neoplastic) binary classification task. External validation dataset was used to test the generalizability of the optimal predictive models implemented. Relevant and informative features were selected to construct cross-validated decision tree and eventually simple rule set was built based on the decision tree. The experimental results show that almost all pattern recognition paradigms achieve high accuracy with careful selection of number of attributes. LDA+ELM with 55 features are the optimal pipelines which achieve perfect classification when training and test data are of same source; and achieving (accuracy=97.5%, AUC=0.989, sensitivity=95% and specificity=100%) under balanced test dataset; (accuracy=99.5%, AUC=0.988, sensitivity=95% and specificity=100%). Cross-validated decision tree model also shows comparable performance: accuracy=98.8%, AUC=99.1%, sensitivity=99.6% and specificity=98.2%. Three highly relevant and robust attributes are visualized and selected for construction of decision tree models and finally a rule sets are read directly off the decision tree. This rule sets can potentially serve as fast and accurate classification algorithm.","",""
122,"Daniel R. Schrider, A. Kern","S/HIC: Robust Identification of Soft and Hard Sweeps Using Machine Learning",2015,"","","","",92,"2022-07-13 10:07:14","","10.1371/journal.pgen.1005928","","",,,,,122,17.43,61,2,7,"Detecting the targets of adaptive natural selection from whole genome sequencing data is a central problem for population genetics. However, to date most methods have shown sub-optimal performance under realistic demographic scenarios. Moreover, over the past decade there has been a renewed interest in determining the importance of selection from standing variation in adaptation of natural populations, yet very few methods for inferring this model of adaptation at the genome scale have been introduced. Here we introduce a new method, S/HIC, which uses supervised machine learning to precisely infer the location of both hard and soft selective sweeps. We show that S/HIC has unrivaled accuracy for detecting sweeps under demographic histories that are relevant to human populations, and distinguishing sweeps from linked as well as neutrally evolving regions. Moreover we show that S/HIC is uniquely robust among its competitors to model misspecification. Thus even if the true demographic model of a population differs catastrophically from that specified by the user, S/HIC still retains impressive discriminatory power. Finally we apply S/HIC to the case of resequencing data from human chromosome 18 in a European population sample and demonstrate that we can reliably recover selective sweeps that have been identified earlier using less specific and sensitive methods.","",""
4,"Barry McDermott, A. Elahi, A. Santorelli, M. O’halloran, J. Avery, E. Porter","Multi-frequency symmetry difference electrical impedance tomography with machine learning for human stroke diagnosis.",2020,"","","","",93,"2022-07-13 10:07:14","","10.1088/1361-6579/ab9e54","","",,,,,4,2.00,1,6,2,"OBJECTIVE Multi-Frequency Symmetry Difference Electrical Impedance Tomography (MFSD-EIT) can robustly detect and identify unilateral perturbations in symmetric scenes. Here, an investigation is performed to assess if the algorithm can be successfully applied to identify the aetiology of stroke with the aid of machine learning.   METHODS Anatomically realistic four-layer Finite Element Method models of the head based on stroke patient images are developed and used to generate EIT data over a 5 Hz - 100 Hz frequency range with and without bleed and clot lesions present. Reconstruction generates conductivity maps of each head at each frequency. Application of a quantitative metric assessing changes in symmetry across the sagittal plane of the reconstructed image and over the frequency range allows lesion detection and identification. The algorithm is applied to both simulated and human (n=34 subjects) data. A classification algorithm is applied to the metric value in order to differentiate between normal, haemorrhage and clot values.   RESULTS An average accuracy of 85% is achieved when MFSD-EIT with Support Vector Machines (SVM) classification is used to identify and differentiate bleed from clot in human data, with 77% accuracy when differentiating normal from stroke in human data.   CONCLUSION Applying a classification algorithm to metrics derived from MFSD-EIT images is a novel and promising technique for detection and identification of perturbations in static scenes.   SIGNIFICANCE The MFSD-EIT algorithm used with machine learning gives promising results of lesion detection and identification in challenging conditions like stroke. The results imply feasible translation to human patients.","",""
7,"May Me Me Hlaing, Nang Saing Moon Kham","Defining News Authenticity on Social Media Using Machine Learning Approach",2020,"","","","",94,"2022-07-13 10:07:14","","10.1109/ICCA49400.2020.9022837","","",,,,,7,3.50,4,2,2,"Social network and online news media are becoming popular in today’s era. Due to low cost, easy access and rapid diffusion, social media platform becomes a source to distribute false information. Fake news propagation on social media can cause serious negative effects on human society especially in politic, reputation and finance. So, automatic fake news detection plays a vital role to robust news media platform on social network. Defining news authenticity is insufficient based on news content only. It also needs to analyze social features of news. In this paper, we propose an approach to detect fake news on social media that covers both news content and social context. We use synonym-based feature extraction method and three different classifiers based on multidimensional dataset. Experimental result shows the effective as an accuracy way to define news authenticity on online news media.","",""
27,"Dezhen Xiong, Daohui Zhang, Xingang Zhao, Yiwen Zhao","Deep Learning for EMG-based Human-Machine Interaction: A Review",2021,"","","","",95,"2022-07-13 10:07:14","","10.1109/JAS.2021.1003865","","",,,,,27,27.00,7,4,1,"Electromyography (EMG) has already been broadly used in human-machine interaction (HMI) applications. Determining how to decode the information inside EMG signals robustly and accurately is a key problem for which we urgently need a solution. Recently, many EMG pattern recognition tasks have been addressed using deep learning methods. In this paper, we analyze recent papers and present a literature review describing the role that deep learning plays in EMG-based HMI. An overview of typical network structures and processing schemes will be provided. Recent progress in typical tasks such as movement classification, joint angle prediction, and force/torque estimation will be introduced. New issues, including multimodal sensing, inter-subject/inter-session, and robustness toward disturbances will be discussed. We attempt to provide a comprehensive analysis of current research by discussing the advantages, challenges, and opportunities brought by deep learning. We hope that deep learning can aid in eliminating factors that hinder the development of EMG-based HMI systems. Furthermore, possible future directions will be presented to pave the way for future research.","",""
166,"M. Alber, A. Buganza Tepole, W. R. Cannon, S. De, S. Dura-Bernal, K. Garikipati, G. Karniadakis, W. Lytton, P. Perdikaris, L. Petzold, E. Kuhl","Integrating machine learning and multiscale modeling—perspectives, challenges, and opportunities in the biological, biomedical, and behavioral sciences",2019,"","","","",96,"2022-07-13 10:07:14","","10.1038/s41746-019-0193-y","","",,,,,166,55.33,17,11,3,"","",""
27,"Johannes H. Uhl, S. Leyk, Yao-Yi Chiang, Weiwei Duan, Craig A. Knoblock","Extracting Human Settlement Footprint from Historical Topographic Map Series Using Context-Based Machine Learning",2017,"","","","",97,"2022-07-13 10:07:14","","10.1049/CP.2017.0144","","",,,,,27,5.40,5,5,5,"Information extraction from historical maps represents a persistent challenge due to inferior graphical quality and large data volume in digital map archives, which can hold thousands of digitized map sheets. In this paper, we describe an approach to extract human settlement symbols in United States Geological Survey (USGS) historical topographic maps using contemporary building data as the contextual spatial layer. The presence of a building in the contemporary layer indicates a high probability that the same building can be found at that location on the historical map. We describe the design of an automatic sampling approach using these contemporary data to collect thousands of graphical examples for the symbol of interest. These graphical examples are then used for robust learning to then carry out feature extraction in the entire map. We employ a Convolutional Neural Network (LeNet) for the recognition task. Results are promising and will guide the next steps in this research to provide an unsupervised approach to extracting features from historical maps.","",""
20,"Pouria Asadi, M. Gindy, Marco A. Alvarez","A Machine Learning Based Approach for Automatic Rebar Detection and Quantification of Deterioration in Concrete Bridge Deck Ground Penetrating Radar B-scan Images",2019,"","","","",98,"2022-07-13 10:07:14","","10.1007/S12205-019-2012-Z","","",,,,,20,6.67,7,3,3,"","",""
57,"A. Chelli, M. Pätzold","A Machine Learning Approach for Fall Detection and Daily Living Activity Recognition",2019,"","","","",99,"2022-07-13 10:07:14","","10.1109/ACCESS.2019.2906693","","",,,,,57,19.00,29,2,3,"The number of older people in western countries is constantly increasing. Most of them prefer to live independently and are susceptible to fall incidents. Falls often lead to serious or even fatal injuries which are the leading cause of death for elderlies. To address this problem, it is essential to develop robust fall detection systems. In this context, we develop a machine learning framework for fall detection and daily living activity recognition. We use acceleration and angular velocity data from two public databases to recognize seven different activities, including falls and activities of daily living. From the acceleration and angular velocity data, we extract time- and frequency-domain features and provide them to a classification algorithm. In this paper, we test the performance of four algorithms for classifying human activities. These algorithms are the artificial neural network (ANN),  $K$ -nearest neighbors (KNN), quadratic support vector machine (QSVM), and ensemble bagged tree (EBT). New features that improve the performance of the classifier are extracted from the power spectral density of the acceleration. In the first step, only the acceleration data are used for activity recognition. Our results reveal that the KNN, ANN, QSVM, and EBT algorithms could achieve overall accuracy of 81.2%, 87.8%, 93.2%, and 94.1%, respectively. The accuracy of fall detection reaches 97.2% and 99.1% without any false alarms for the QSVM and EBT algorithms, respectively. In a second step, we extract features from the autocorrelation function and the power spectral density of both the acceleration and the angular velocity data, which improves the classification accuracy. By using the proposed features, we could achieve overall accuracy of 85.8%, 91.8%, 96.1%, and 97.7% for the KNN, ANN, QSVM, and EBT algorithms, respectively. The accuracy of fall detection reaches 100% for both the QSVM and EBT algorithms without any false alarm, which is the best achievable performance.","",""
13,"M. Grassia, M. Domenico, G. Mangioni","Machine learning dismantling and early-warning signals of disintegration in complex systems",2021,"","","","",100,"2022-07-13 10:07:14","","10.1038/s41467-021-25485-8","","",,,,,13,13.00,4,3,1,"","",""
38,"G. Caravagna, Timon Heide, Marc J. Williams, L. Zapata, D. Nichol, K. Chkhaidze, W. Cross, G. Cresswell, B. Werner, A. Acar, L. Chesler, C. Barnes, G. Sanguinetti, T. Graham, A. Sottoriva","Subclonal reconstruction of tumors using machine learning and population genetics",2020,"","","","",101,"2022-07-13 10:07:14","","10.1038/s41588-020-0675-5","","",,,,,38,19.00,4,15,2,"","",""
37,"M. Abdar, V. N. Wijayaningrum, Sadiq Hussain, R. Alizadehsani, Pawel Plawiak, U. Acharya, V. Makarenkov","IAPSO-AIRS: A novel improved machine learning-based system for wart disease treatment",2019,"","","","",102,"2022-07-13 10:07:14","","10.1007/s10916-019-1343-0","","",,,,,37,12.33,5,7,3,"","",""
103,"Baibhab Chatterjee, D. Das, Shovan Maity, Shreyas Sen","RF-PUF: Enhancing IoT Security Through Authentication of Wireless Nodes Using In-Situ Machine Learning",2018,"","","","",103,"2022-07-13 10:07:14","","10.1109/JIOT.2018.2849324","","",,,,,103,25.75,26,4,4,"Traditional authentication in radio-frequency (RF) systems enable secure data communication within a network through techniques such as digital signatures and hash-based message authentication codes (HMAC), which suffer from key-recovery attacks. State-of-the-art Internet of Things networks such as Nest also use open authentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery forgery (CSRF), which shows that these techniques may not prevent an adversary from copying or modeling the secret IDs or encryption keys using invasive, side channel, learning or software attacks. Physical unclonable functions (PUFs), on the other hand, can exploit manufacturing process variations to uniquely identify silicon chips which makes a PUF-based system extremely robust and secure at low cost, as it is practically impossible to replicate the same silicon characteristics across dies. Taking inspiration from human communication, which utilizes inherent variations in the voice signatures to identify a certain speaker, we present RF-PUF: a deep neural network-based framework that allows real-time authentication of wireless nodes, using the effects of inherent process variation on RF properties of the wireless transmitters (Tx), detected through in-situ machine learning at the receiver (Rx) end. The proposed method utilizes the already-existing asymmetric RF communication framework and does not require any additional circuitry for PUF generation or feature extraction. The burden of device identification is completely shifted to the gateway Rx, similar to the operation of a human listener’s brain. Simulation results involving the process variations in a standard 65-nm technology node, and features such as local oscillator offset and  ${I}$ – ${Q}$  imbalance detected with a neural network having 50 neurons in the hidden layer indicate that the framework can distinguish up to 4800 Tx(s) with an accuracy of 99.9% [≈99% for 10000 Tx(s)] under varying channel conditions, and without the need for traditional preambles. The proposed scheme can be used as a stand-alone security feature, or as a part of traditional multifactor authentication.","",""
46,"M. Umehara, H. Stein, D. Guevarra, P. F. Newhouse, D. Boyd, J. Gregoire","Analyzing machine learning models to accelerate generation of fundamental materials insights",2019,"","","","",104,"2022-07-13 10:07:14","","10.1038/s41524-019-0172-5","","",,,,,46,15.33,8,6,3,"","",""
62,"Shi Feng, Jordan L. Boyd-Graber","What can AI do for me?: evaluating machine learning interpretations in cooperative play",2018,"","","","",105,"2022-07-13 10:07:14","","10.1145/3301275.3302265","","",,,,,62,15.50,31,2,4,"Machine learning is an important tool for decision making, but its ethical and responsible application requires rigorous vetting of its interpretability and utility: an understudied problem, particularly for natural language processing models. We propose an evaluation of interpretation on a real task with real human users, where the effectiveness of interpretation is measured by how much it improves human performance. We design a grounded, realistic human-computer cooperative setting using a question answering task, Quizbowl. We recruit both trivia experts and novices to play this game with computer as their teammate, who communicates its prediction via three different interpretations. We also provide design guidance for natural language processing human-in-the-loop settings.","",""
24,"V. M","Melanoma Skin Cancer Detection using Image Processing and Machine Learning",2019,"","","","",106,"2022-07-13 10:07:14","","10.31142/IJTSRD23936","","",,,,,24,8.00,24,1,3,"Copyright © 2019 by author(s) and International Journal of Trend in Scientific Research and Development Journal. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0) (http://creativecommons.org/licenses/ by/4.0) ABSTRACT Dermatological Diseases are one of the biggest medical issues in 21st century due to its highly complex and expensive diagnosis with difficulties and subjectivity of human interpretation. In cases of fatal diseases like Melanoma diagnosis in early stages play a vital role in determining the probability of getting cured. We believe that the application of automated methods will help in early diagnosis especially with the set of images with variety of diagnosis. Hence, in this article we present a completely automated system of dermatological disease recognition through lesion images, a machine intervention in contrast to conventional medical personnel-based detection. Our model is designed into three phases compromising of data collection and augmentation, designing model and finally prediction. We have used multiple AI algorithms like Convolutional Neural Network and Support Vector Machine and amalgamated it with image processing tools to form a better structure, leading to higher accuracy of 85%.","",""
74,"Monika A. Myszczynska, P. Ojamies, Alix M. B. Lacoste, Daniel Neil, Amir Saffari, R. Mead, G. Hautbergue, J. Holbrook, L. Ferraiuolo","Applications of machine learning to diagnosis and treatment of neurodegenerative diseases",2020,"","","","",107,"2022-07-13 10:07:14","","10.1038/s41582-020-0377-8","","",,,,,74,37.00,8,9,2,"","",""
23,"Martin G. Seneviratne, N. Shah, Larry Chu","Bridging the implementation gap of machine learning in healthcare",2019,"","","","",108,"2022-07-13 10:07:14","","10.1136/bmjinnov-2019-000359","","",,,,,23,7.67,8,3,3,"Applications of machine learning on clinical data are now attaining levels of performance that match or exceed human clinicians.1–3 Fields involving image interpretation—radiology, pathology and dermatology—have led the charge due to the power of convolutional neural networks, the existence of standard data formats and large data repositories. We have also seen powerful diagnostic and predictive algorithms built using a range of other data, including electronic health records (EHR), -omics, monitoring signals, insurance claims and patient-generated data.4 The looming extinction of doctors has captured the public imagination, with editorials such as ‘The AI Doctor Will See You Now’.5 The prevailing view among experts is more balanced: that doctors who use artificial intelligence (AI) will replace those who do not.6  Amid such inflated expectations, the elephant in the room is the implementation gap of machine learning in healthcare.7 8 Very few of these algorithms ever make it to the bedside; and even the most technology-literate academic medical centres are not routinely using AI in clinical workflows. A recent systematic review of deep learning applications using EHR data highlighted the need to focus on the last mile of implementation: ‘for direct clinical impact, deployment and automation of deep learning models must be considered’.9 The typical life-cycle of an algorithm remains: train on historical data, publish a good receiver-operator curve and then collect dust in the ‘model graveyard’.  This begs the question: if model performance is so …","",""
9,"Shanwen Sun, Benzhi Dong, Q. Zou","Revisiting genome-wide association studies from statistical modelling to machine learning",2020,"","","","",109,"2022-07-13 10:07:14","","10.1093/bib/bbaa263","","",,,,,9,4.50,3,3,2,"Over the last decade, genome-wide association studies (GWAS) have discovered thousands of genetic variants underlying complex human diseases and agriculturally important traits. These findings have been utilized to dissect the biological basis of diseases, to develop new drugs, to advance precision medicine and to boost breeding. However, the potential of GWAS is still underexploited due to methodological limitations. Many challenges have emerged, including detecting epistasis and single-nucleotide polymorphisms (SNPs) with small effects and distinguishing causal variants from other SNPs associated through linkage disequilibrium. These issues have motivated advancements in GWAS analyses in two contrasting cultures-statistical modelling and machine learning. In this review, we systematically present the basic concepts and the benefits and limitations in both methods. We further discuss recent efforts to mitigate their weaknesses. Additionally, we summarize the state-of-the-art tools for detecting the missed signals, ultrarare mutations and gene-gene interactions and for prioritizing SNPs. Our work can offer both theoretical and practical guidelines for performing GWAS analyses and for developing further new robust methods to fully exploit the potential of GWAS.","",""
17,"Luke E K Achenie, A. Scarpa, R. Factor, Tao Wang, D. Robins, D. S. McCrickard","A Machine Learning Strategy for Autism Screening in Toddlers.",2019,"","","","",110,"2022-07-13 10:07:14","","10.1097/DBP.0000000000000668","","",,,,,17,5.67,3,6,3,"OBJECTIVE Autism spectrum disorder (ASD) screening can improve prognosis via early diagnosis and intervention, but lack of time and training can deter pediatric screening. The Modified Checklist for Autism in Toddlers, Revised (M-CHAT-R) is a widely used screener but requires follow-up questions and error-prone human scoring and interpretation. We consider an automated machine learning (ML) method for overcoming barriers to ASD screening, specifically using the feedforward neural network (fNN).   METHODS The fNN technique was applied using archival M-CHAT-R data of 14,995 toddlers (age 16-30 months, 46.51% male). The 20 M-CHAT-R items were inputs, and ASD diagnosis after follow-up and diagnostic evaluation (i.e., ASD or not ASD) was the output. The sample was divided into subgroups by race (i.e., white and black), sex (i.e., boys and girls), and maternal education (i.e., below and above 15 years of education completed) to examine subgroup differences. Each subgroup was evaluated for best-performing fNN models.   RESULTS For the total sample, best results yielded 99.72% correct classification using 18 items. Best results yielded 99.92% correct classification using 14 items for white toddlers and 99.79% correct classification using 18 items for black toddlers. In boys, best results yielded 99.64% correct classification using 18 items, whereas best results yielded 99.95% correct classification using 18 items in girls. For the case when maternal education is 15 years or less (i.e., associate degree and below), best results were 99.75% correct classification when using 16 items. Results were essentially the same when maternal education was 16 years or more (i.e., above associate degree); that is, 99.70% correct classification was obtained using 16 items.   CONCLUSION The ML method was comparable to the M-CHAT-R with follow-up items in accuracy of ASD diagnosis while using fewer items. Therefore, ML may be a beneficial tool in implementing automatic, efficient scoring that negates the need for labor-intensive follow-up and circumvents human error, providing an advantage over previous screening methods.","",""
14,"B. Ansell, B. Pope, P. Georgeson, Samantha J. Emery-Corbin, A. Jex","Annotation of the Giardia proteome through structure-based homology and machine learning",2018,"","","","",111,"2022-07-13 10:07:14","","10.1093/gigascience/giy150","","",,,,,14,3.50,3,5,4,"Abstract Background Large-scale computational prediction of protein structures represents a cost-effective alternative to empirical structure determination with particular promise for non-model organisms and neglected pathogens. Conventional sequence-based tools are insufficient to annotate the genomes of such divergent biological systems. Conversely, protein structure tolerates substantial variation in primary amino acid sequence and is thus a robust indicator of biochemical function. Structural proteomics is poised to become a standard part of pathogen genomics research; however, informatic methods are now required to assign confidence in large volumes of predicted structures. Aims Our aim was to predict the proteome of a neglected human pathogen, Giardia duodenalis, and stratify predicted structures into high- and lower-confidence categories using a variety of metrics in isolation and combination. Methods We used the I-TASSER suite to predict structural models for ∼5,000 proteins encoded in G. duodenalis and identify their closest empirically-determined structural homologues in the Protein Data Bank. Models were assigned to high- or lower-confidence categories depending on the presence of matching protein family (Pfam) domains in query and reference peptides. Metrics output from the suite and derived metrics were assessed for their ability to predict the high-confidence category individually, and in combination through development of a random forest classifier. Results We identified 1,095 high-confidence models including 212 hypothetical proteins. Amino acid identity between query and reference peptides was the greatest individual predictor of high-confidence status; however, the random forest classifier outperformed any metric in isolation (area under the receiver operating characteristic curve = 0.976) and identified a subset of 305 high-confidence-like models, corresponding to false-positive predictions. High-confidence models exhibited greater transcriptional abundance, and the classifier generalized across species, indicating the broad utility of this approach for automatically stratifying predicted structures. Additional structure-based clustering was used to cross-check confidence predictions in an expanded family of Nek kinases. Several high-confidence-like proteins yielded substantial new insight into mechanisms of redox balance in G. duodenalis—a system central to the efficacy of limited anti-giardial drugs. Conclusion Structural proteomics combined with machine learning can aid genome annotation for genetically divergent organisms, including human pathogens, and stratify predicted structures to promote efficient allocation of limited resources for experimental investigation.","",""
5,"J. Dukart, S. Weis, S. Genon, S. Eickhoff","Towards increasing the clinical applicability of machine learning biomarkers in psychiatry.",2021,"","","","",112,"2022-07-13 10:07:14","","10.1038/s41562-021-01085-w","","",,,,,5,5.00,1,4,1,"","",""
48,"Clemens Stachl, F. Pargent, S. Hilbert, Gabriella M. Harari, Ramona Schoedel, Sumer S. Vaid, S. Gosling, M. Bühner","Personality Research and Assessment in the Era of Machine Learning",2019,"","","","",113,"2022-07-13 10:07:14","","10.1002/per.2257","","",,,,,48,16.00,6,8,3,"The increasing availability of high–dimensional, fine–grained data about human behaviour, gathered from mobile sensing studies and in the form of digital footprints, is poised to drastically alter the way personality psychologists perform research and undertake personality assessment. These new kinds and quantities of data raise important questions about how to analyse the data and interpret the results appropriately. Machine learning models are well suited to these kinds of data, allowing researchers to model highly complex relationships and to evaluate the generalizability and robustness of their results using resampling methods. The correct usage of machine learning models requires specialized methodological training that considers issues specific to this type of modelling. Here, we first provide a brief overview of past studies using machine learning in personality psychology. Second, we illustrate the main challenges that researchers face when building, interpreting, and validating machine learning models. Third, we discuss the evaluation of personality scales, derived using machine learning methods. Fourth, we highlight some key issues that arise from the use of latent variables in the modelling process. We conclude with an outlook on the future role of machine learning models in personality research and assessment.","",""
36,"Dingding Wang, Jiaqing Mo, Gang Zhou, Liang Xu, Yajun Liu","An efficient mixture of deep and machine learning models for COVID-19 diagnosis in chest X-ray images",2020,"","","","",114,"2022-07-13 10:07:14","","10.1371/journal.pone.0242535","","",,,,,36,18.00,7,5,2,"A newly emerged coronavirus (COVID-19) seriously threatens human life and health worldwide. In coping and fighting against COVID-19, the most critical step is to effectively screen and diagnose infected patients. Among them, chest X-ray imaging technology is a valuable imaging diagnosis method. The use of computer-aided diagnosis to screen X-ray images of COVID-19 cases can provide experts with auxiliary diagnosis suggestions, which can reduce the burden of experts to a certain extent. In this study, we first used conventional transfer learning methods, using five pre-trained deep learning models, which the Xception model showed a relatively ideal effect, and the diagnostic accuracy reached 96.75%. In order to further improve the diagnostic accuracy, we propose an efficient diagnostic method that uses a combination of deep features and machine learning classification. It implements an end-to-end diagnostic model. The proposed method was tested on two datasets and performed exceptionally well on both of them. We first evaluated the model on 1102 chest X-ray images. The experimental results show that the diagnostic accuracy of Xception + SVM is as high as 99.33%. Compared with the baseline Xception model, the diagnostic accuracy is improved by 2.58%. The sensitivity, specificity and AUC of this model reached 99.27%, 99.38% and 99.32%, respectively. To further illustrate the robustness of our method, we also tested our proposed model on another dataset. Finally also achieved good results. Compared with related research, our proposed method has higher classification accuracy and efficient diagnostic performance. Overall, the proposed method substantially advances the current radiology based methodology, it can be very helpful tool for clinical practitioners and radiologists to aid them in diagnosis and follow-up of COVID-19 cases.","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",115,"2022-07-13 10:07:14","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
0,"Andreea Chiorean, K. Farncombe, Sean Delong, Veronica Andric, S. Ansar, Clarissa Chan, Kaitlin A. Clark, Arpad M. Danos, Yizhuo Gao, R. Giles, A. Goldenberg, P. Jani, Kilannin Krysiak, Lynzey Kujan, Samantha Macpherson, E. Maher, L. McCoy, Yasser Salama, Jason Saliba, Lana M. Sheta, M. Griffith, O. Griffith, L. Erdman, A. Ramani, Raymond H. Kim","Large scale genotype- and phenotype-driven machine learning in Von Hippel-Lindau disease.",2022,"","","","",116,"2022-07-13 10:07:14","","10.1002/humu.24392","","",,,,,0,0.00,0,25,1,"Von Hippel-Lindau (VHL) disease is a hereditary cancer syndrome where individuals are predisposed to tumor development in the brain, adrenal gland, kidney and other organs. It is caused by pathogenic variants in the VHL tumor suppressor gene. Standardized disease information has been difficult to collect due to the rarity and diversity of VHL patients. Over 4100 unique articles published until October 2019 were screened for germline genotype-phenotype data. Patient data was translated into standardized descriptions using Human Genome Variation Society (HGVS) gene variant nomenclature and Human Phenotype Ontology (HPO) terms and has been manually curated into an open-access knowledgebase called Clinical Interpretation of Variants in Cancer (CIViC). In total, 634 unique VHL variants, 2882 patients and 1991 families from 427 papers were captured. We identified relationship trends between phenotype and genotype data using classic statistical methods and spectral clustering unsupervised learning. Our analyses reveal earlier onset of pheochromocytoma/paraganglioma and retinal angiomas, phenotype co-occurrences and genotype-phenotype correlations including hot-spots. It confirms existing VHL associations and can be used to identify new patterns and associations in VHL disease. Our database serves as an aggregate knowledge translation tool to facilitate sharing information about the pathogenicity of VHL variants. This article is protected by copyright. All rights reserved.","",""
8,"Jo-Hsuan Wu, T. Y. A. Liu, W. Hsu, J. Ho, Chien-Chang Lee","Performance and Limitation of Machine Learning Algorithms for Diabetic Retinopathy Screening: Meta-analysis",2021,"","","","",117,"2022-07-13 10:07:14","","10.2196/23863","","",,,,,8,8.00,2,5,1,"Background Diabetic retinopathy (DR), whose standard diagnosis is performed by human experts, has high prevalence and requires a more efficient screening method. Although machine learning (ML)–based automated DR diagnosis has gained attention due to recent approval of IDx-DR, performance of this tool has not been examined systematically, and the best ML technique for use in a real-world setting has not been discussed. Objective The aim of this study was to systematically examine the overall diagnostic accuracy of ML in diagnosing DR of different categories based on color fundus photographs and to determine the state-of-the-art ML approach. Methods Published studies in PubMed and EMBASE were searched from inception to June 2020. Studies were screened for relevant outcomes, publication types, and data sufficiency, and a total of 60 out of 2128 (2.82%) studies were retrieved after study selection. Extraction of data was performed by 2 authors according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), and the quality assessment was performed according to the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2). Meta-analysis of diagnostic accuracy was pooled using a bivariate random effects model. The main outcomes included diagnostic accuracy, sensitivity, and specificity of ML in diagnosing DR based on color fundus photographs, as well as the performances of different major types of ML algorithms. Results The primary meta-analysis included 60 color fundus photograph studies (445,175 interpretations). Overall, ML demonstrated high accuracy in diagnosing DR of various categories, with a pooled area under the receiver operating characteristic (AUROC) ranging from 0.97 (95% CI 0.96-0.99) to 0.99 (95% CI 0.98-1.00). The performance of ML in detecting more-than-mild DR was robust (sensitivity 0.95; AUROC 0.97), and by subgroup analyses, we observed that robust performance of ML was not limited to benchmark data sets (sensitivity 0.92; AUROC 0.96) but could be generalized to images collected in clinical practice (sensitivity 0.97; AUROC 0.97). Neural network was the most widely used method, and the subgroup analysis revealed a pooled AUROC of 0.98 (95% CI 0.96-0.99) for studies that used neural networks to diagnose more-than-mild DR. Conclusions This meta-analysis demonstrated high diagnostic accuracy of ML algorithms in detecting DR on color fundus photographs, suggesting that state-of-the-art, ML-based DR screening algorithms are likely ready for clinical applications. However, a significant portion of the earlier published studies had methodology flaws, such as the lack of external validation and presence of spectrum bias. The results of these studies should be interpreted with caution.","",""
5,"Xueqin Pang, C. Forrest, Félice Lê-Scherban, A. Masino","Understanding Early Childhood Obesity via Interpretation of Machine Learning Model Predictions",2019,"","","","",118,"2022-07-13 10:07:14","","10.1109/ICMLA.2019.00235","","",,,,,5,1.67,1,4,3,"Obesity, as an independent risk factor for increased morbidity and mortality throughout the lifecycle, is a major health issue in the United States. Pediatric obesity is a strong risk factor for adult obesity, as it tends to be stable and tracks into adulthood. Therefore, prevention of childhood obesity is urgently required for reduction in obesity prevalence and obesity related comorbidities. In this paper, the general pediatric obesity development pattern and the onset time period of early childhood obesity was identified via analysis of approximately 11 million pediatric clinical encounters of 860,510 unique individuals. XGBoost model was developed to predict at age 2 years if individuals would develop obesity in early childhood. The model is generalized to both males and females, and achieved an AUC of 81% (± 0.1%). Obesity associated risk factors were further analyzed via interpretation of the XGBoost model predictions. Besides known predictive factors such as weight, height, race, and ethnicity, new factors such as body temperature and respiratory rate were also identified. As body temperature and respiratory rate are related to human metabolism, novel physiologic mechanisms that cause these associations might be discovered in future research. We decomposed model recall to different age ranges when obesity incidence occurred. The model recall for individuals with obesity incidence between 24–36 months was 97.63%, while recall for obesity incidence between 72–84 months was 48.96%, suggesting obesity is less predictable further in the future. Since obesity is largely affected by evolving factors such as life style, diet, and living environment, it is possible that obesity prevention may be achieved via changes in adjustable factors.","",""
6,"P. Washington, O. Mutlu, É. Leblanc, A. Kline, C. Hou, B. Chrisman, N. Stockham, K. Paskov, C. Voss, N. Haber, D. Wall","Using Crowdsourcing to Train Facial Emotion Machine Learning Models with Ambiguous Labels",2021,"","","","",119,"2022-07-13 10:07:14","","","","",,,,,6,6.00,1,11,1,"Current emotion detection classifiers predict discrete emotions. However, literature in psychology has documented that compound and ambiguous facial expressions are often evoked by humans. As a stride towards development of machine learning models that more accurately reflect compound and ambiguous emotions, we replace traditional one-hot encoded label representations with a crowd's distribution of labels. We center our study on the Child Affective Facial Expression (CAFE) dataset, a gold standard dataset of pediatric facial expressions which includes 100 human labels per image. We first acquire crowdsourced labels for 207 emotions from CAFE and demonstrate that the consensus labels from the crowd tend to match the consensus from the original CAFE raters, validating the utility of crowdsourcing. We then train two versions of a ResNet-152 classifier on CAFE images with two types of labels (1) traditional one-hot encoding and (2) vector labels representing the crowd distribution of responses. We compare the resulting output distributions of the two classifiers. While the traditional F1-score for the one-hot encoding classifier is much higher (94.33% vs. 78.68%), the output probability vector of the crowd-trained classifier much more closely resembles the distribution of human labels (t=3.2827, p=0.0014). For many applications of affective computing, reporting an emotion probability distribution that more closely resembles human interpretation can be more important than traditional machine learning metrics. This work is a first step for engineers of interactive systems to account for machine learning cases with ambiguous classes and we hope it will generate a discussion about machine learning with ambiguous labels and leveraging crowdsourcing as a potential solution.","",""
11,"P. Poudel, A. Illanes, E. Ataide, N. Esmaeili, Sathish Balakrishnan, M. Friebe","Thyroid Ultrasound Texture Classification Using Autoregressive Features in Conjunction With Machine Learning Approaches",2019,"","","","",120,"2022-07-13 10:07:14","","10.1109/ACCESS.2019.2923547","","",,,,,11,3.67,2,6,3,"The thyroid is one of the largest endocrine glands in the human body, which is involved in several body mechanisms like controlling protein synthesis, use of energy sources, and controlling the body’s sensitivity to other hormones. Thyroid segmentation and volume reconstruction are hence essential to diagnose thyroid related diseases as most of these diseases involve a change in the shape and size of the thyroid over time. Classification of thyroid texture is the first step toward the segmentation of the thyroid. The classification of texture in thyroid Ultrasound (US) images is not an easy task as it suffers from low image contrast, presence of speckle noise, and non-homogeneous texture distribution inside the thyroid region. Hence, a robust algorithmic approach is required to accurately classify thyroid texture. In this paper, we propose three machine learning based approaches: Support Vector Machine; Artificial Neural Network; and Random Forest Classifier to classify thyroid texture. The computation of features for training these classifiers is based on a novel approach recently proposed by our team, where autoregressive modeling was applied on a signal version of the 2D thyroid US images to compute 30 spectral energy-based features for classifying the thyroid and non-thyroid textures. Our approach differs from the methods proposed in the literature as they use image-based features to characterize thyroid tissues. We obtained an accuracy of around 90% with all the three methods.","",""
9,"S. Aich, Sabyasachi Chakraborty, J. Sim, Dong-Jin Jang, Hee-Cheol Kim","The Design of an Automated System for the Analysis of the Activity and Emotional Patterns of Dogs with Wearable Sensors Using Machine Learning",2019,"","","","",121,"2022-07-13 10:07:14","","10.3390/app9224938","","",,,,,9,3.00,2,5,3,"The safety and welfare of companion animals such as dogs has become a large challenge in the last few years. To assess the well-being of a dog, it is very important for human beings to understand the activity pattern of the dog, and its emotional behavior. A wearable, sensor-based system is suitable for such ends, as it will be able to monitor the dogs in real-time. However, the question remains unanswered as to what kind of data should be used to detect the activity patterns and emotional patterns, as does another: what should be the location of the sensors for the collection of data and how should we automate the system? Yet these questions remain unanswered, because to date, there is no such system that can address the above-mentioned concerns. The main purpose of this study was (1) to develop a system that can detect the activities and emotions based on the accelerometer and gyroscope signals and (2) to automate the system with robust machine learning techniques for implementing it for real-time situations. Therefore, we propose a system which is based on the data collected from 10 dogs, including nine breeds of various sizes and ages, and both genders. We used machine learning classification techniques for automating the detection and evaluation process. The ground truth fetched for the evaluation process was carried out by taking video recording data in frame per second and the wearable sensors data were collected in parallel with the video recordings. Evaluation of the system was performed using an ANN (artificial neural network), random forest, SVM (support vector machine), KNN (k nearest neighbors), and a naïve Bayes classifier. The robustness of our system was evaluated by taking independent training and validation sets. We achieved an accuracy of 96.58% while detecting the activity and 92.87% while detecting emotional behavior, respectively. This system will help the owners of dogs to track their behavior and emotions in real-life situations for various breeds in different scenarios.","",""
16,"Hyunki Lee, S. Madar, Santusht Sairam, Tejas G. Puranik, A. Payan, Michelle Kirby, Olivia J. Pinon, D. Mavris","Critical Parameter Identification for Safety Events in Commercial Aviation Using Machine Learning",2020,"","","","",122,"2022-07-13 10:07:14","","10.3390/aerospace7060073","","",,,,,16,8.00,2,8,2,"In recent years, there has been a rapid growth in the application of data science techniques that leverage aviation data collected from commercial airline operations to improve safety. This paper presents the application of machine learning to improve the understanding of risk factors during flight and their causal chains. With increasing complexity and volume of operations, rapid accumulation and analysis of this safety-related data has the potential to maintain and even lower the low global accident rates in aviation. This paper presents the development of an analytical methodology called Safety Analysis of Flight Events (SAFE) that synthesizes data cleaning, correlation analysis, classification-based supervised learning, and data visualization schema to streamline the isolation of critical parameters and the elimination of tangential factors for safety events in aviation. The SAFE methodology outlines a robust and repeatable framework that is applicable across heterogeneous data sets containing multiple aircraft, airport of operations, and phases of flight. It is demonstrated on Flight Operations Quality Assurance (FOQA) data from a commercial airline through use cases related to three safety events, namely Tire Speed Event, Roll Event, and Landing Distance Event. The application of the SAFE methodology yields a ranked list of critical parameters in line with subject-matter expert conceptions of these events for all three use cases. The work concludes by raising important issues about the compatibility levels of machine learning and human conceptualization of incidents and their precursors, and provides initial guidance for their reconciliation.","",""
15,"O. Pianykh, Steven Guitron, Darren Parke, Chengzhao Zhang, P. Pandharipande, J. Brink, D. Rosenthal","Improving healthcare operations management with machine learning",2020,"","","","",123,"2022-07-13 10:07:14","","10.1038/s42256-020-0176-3","","",,,,,15,7.50,2,7,2,"","",""
9,"R. Roelofs","Measuring Generalization and Overfitting in Machine Learning",2019,"","","","",124,"2022-07-13 10:07:14","","","","",,,,,9,3.00,9,1,3,"Author(s): Roelofs, Rebecca | Advisor(s): Recht, Benjamin; Demmel, James | Abstract: Due to the prevalence of machine learning algorithms and the potential for their decisions to profoundly impact billions of human lives, it is crucial that they are robust, reliable, and understandable. This thesis examines key theoretical pillars of machine learning surrounding generalization and overfitting, and tests the extent to which empirical behavior matches existing theory. We develop novel methods for measuring overfitting and generalization, and we characterize how reproducible observed behavior is across differences in optimization algorithm, dataset, task, evaluation metric, and domain.First, we examine how optimization algorithms bias machine learning models towards solutions with varying generalization properties. We show that adaptive gradient methods empirically find solutions with inferior generalization behavior compared to those found by stochastic gradient descent. We then construct an example using a simple overparameterized model that corroborates the algorithms’ empirical behavior on neural networks. Next, we study the extent to which machine learning models have overfit to commonly reused datasets in both academic benchmarks and machine learning competitions. We build new test sets for the CIFAR-10 and ImageNet datasets and evaluate a broad range of classification models on the new datasets. All models experience a drop in accuracy, which indicates that current accuracy numbers are susceptible to even minute natural variations in the data distribution. Surprisingly, despite several years of adaptively selecting the models to perform well on these competitive benchmarks, we find no evidence of overfitting. We then analyze data from the machine learning platform Kaggle and find little evidence of substantial overfitting in ML competitions. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.Overall, our work suggests that the true concern for robust machine learning is distribution shift rather than overfitting, and designing models that still work reliably in dynamic environments is a challenging but necessary undertaking.","",""
24,"Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Tizian Thieringer, M. Bethge, F. Wichmann, Wieland Brendel","Partial success in closing the gap between human and machine vision",2021,"","","","",125,"2022-07-13 10:07:14","","","","",,,,,24,24.00,3,7,1,"A few years ago, the first CNN surpassed human performance on ImageNet. However, it soon became clear that machines lack robustness on more challenging test cases, a major obstacle towards deploying machines “in the wild” and towards obtaining better computational models of human visual perception. Here we ask: Are we making progress in closing the gap between human and machine vision? To answer this question, we tested human observers on a broad range of out-ofdistribution (OOD) datasets, recording 85,120 psychophysical trials across 90 participants. We then investigated a range of promising machine learning developments that crucially deviate from standard supervised CNNs along three axes: objective function (self-supervised, adversarially trained, CLIP language-image training), architecture (e.g. vision transformers), and dataset size (ranging from 1M to 1B). Our findings are threefold. (1.) The longstanding distortion robustness gap between humans and CNNs is closing, with the best models now exceeding human feedforward performance on most of the investigated OOD datasets. (2.) There is still a substantial image-level consistency gap, meaning that humans make different errors than models. In contrast, most models systematically agree in their categorisation errors, even substantially different ones like contrastive self-supervised vs. standard supervised models. (3.) In many cases, human-to-model consistency improves when training dataset size is increased by one to three orders of magnitude. Our results give reason for cautious optimism: While there is still much room for improvement, the behavioural difference between human and machine vision is narrowing. In order to measure future progress, 17 OOD datasets with image-level human behavioural data and evaluation code are provided as a toolbox and benchmark at https://github.com/bethgelab/model-vs-human/.","",""
27,"E. Mekov, M. Miravitlles, R. Petkov","Artificial intelligence and machine learning in respiratory medicine",2020,"","","","",126,"2022-07-13 10:07:14","","10.1080/17476348.2020.1743181","","",,,,,27,13.50,9,3,2,"ABSTRACT Introduction The application of artificial intelligence (AI) and machine learning (ML) in medicine and in particular in respiratory medicine is an increasingly relevant topic. Areas covered We aimed to identify and describe the studies published on the use of AI and ML in the field of respiratory diseases. The string ‘(((pulmonary) OR respiratory)) AND ((artificial intelligence) OR machine learning)’ was used in PubMed as a search strategy. The majority of studies identified corresponded to the area of chronic obstructive pulmonary disease (COPD), in particular to COPD and chest computed tomography scans, interpretation of pulmonary function tests, exacerbations and treatment. Another field of interest is the application of AI and ML to the diagnosis of interstitial lung disease, and a few other studies were identified on the fields of mechanical ventilation, interpretation of images on chest X-ray and diagnosis of bronchial asthma. Expert opinion ML may help to make clinical decisions but will not replace the physician completely. Human errors in medicine are associated with large financial losses, and many of them could be prevented with the help of AI and ML. AI is particularly useful in the absence of conclusive evidence of decision-making.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",127,"2022-07-13 10:07:14","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
51,"Zhen Wang, H. Di, M. Shafiq, Yazeed Alaudah, G. AlRegib","Successful leveraging of image processing and machine learning in seismic structural interpretation: A review",2018,"","","","",128,"2022-07-13 10:07:14","","10.1190/TLE37060451.1","","",,,,,51,12.75,10,5,4,"As a process that identifies geologic structures of interest such as faults, salt domes, or elements of petroleum systems in general, seismic structural interpretation depends heavily on the domain knowledge and experience of interpreters as well as visual cues of geologic structures, such as texture and geometry. With the dramatic increase in size of seismic data acquired for hydrocarbon exploration, structural interpretation has become more time consuming and labor intensive. By treating seismic data as images rather than signal traces, researchers have been able to utilize advanced image-processing and machine-learning techniques to assist interpretation directly. In this paper, we mainly focus on the interpretation of two important geologic structures, faults and salt domes, and summarize interpretation workflows based on typical or advanced image-processing and machine-learning algorithms. In recent years, increasing computational power and the massive amount of available data have led to the rise of deep learning. Deep-learning models that simulate the human brain's biological neural networks can achieve state-of-the-art accuracy and even exceed human-level performance on numerous applications. The convolutional neural network — a form of deep-learning model that is effective in analyzing visual imagery — has been applied in fault and salt dome interpretation. At the end of this review, we provide insight and discussion on the future of structural interpretation.","",""
9,"Robert G. de Luna, E. Dadios, A. Bandala, R. R. Vicerra","Size Classification of Tomato Fruit Using Thresholding, Machine Learning, and Deep Learning Techniques",2019,"","","","",129,"2022-07-13 10:07:14","","10.17503/agrivita.v41i3.2435","","",,,,,9,3.00,2,4,3,"The size of tomato fruits is closely related to the market segment and price. Manual sorting in tomato is very dependent on human interpretation and thus, very prone to error.  The study presents thresholding, machine learning, and deep learning techniques in classifying the tomato as small, medium, and large based from a single tomato fruit image implemented using Open CV libraries and Python programming. Tomato images with different sizes are gathered where features like area, perimeter, and enclosed circle radius are extracted. The experiment shows that using thresholding, a classification accuracy of 85.83%, 65.83%, and 80% was achieved for area, perimeter, and enclosed circle radius, respectively. For machine learning, the training accuracy rates were recorded as 94.00%-95.00% for SVM, 97.50-92.50% for KNN and 90.33-92.50% for ANN. Comparison of models revealed that SVM is the most model without over fitting. The deep learning approach, regardless of the algorithm, produced low performances with 82.31%-78.21%-55.97% training-validation-testing accuracy for VGG16, 48.17%-41.44%-37.64% for InceptionV3, and 56.05%-44.96%-22.78% for ResNet50 models. Comparative analysis showed that machine learning technique bested the performance of the thresholding and deep learning techniques in classifying the tomato fruit size in terms of accuracy performance.","",""
4,"M. Tong","Using Machine Learning to Predict Core Sizes of High-Efficiency Turbofan Engines",2019,"","","","",130,"2022-07-13 10:07:14","","10.1115/1.4044770","","",,,,,4,1.33,4,1,3,"  With the rise in big data and analytics, machine learning is transforming many industries. It is being increasingly employed to solve a wide range of complex problems, producing autonomous systems that support human decision-making. For the aircraft engine industry, machine learning of historical and existing engine data could provide insights that help drive for better engine design. This work explored the application of machine learning to engine preliminary design. Engine core-size prediction was chosen for the first study because of its relative simplicity in terms of number of input variables required (only three). Specifically, machine-learning predictive tools were developed for turbofan engine core-size prediction, using publicly available data of two hundred manufactured engines and engines that were studied previously in NASA aeronautics projects. The prediction results of these models show that, by bringing together big data, robust machine-learning algorithms and data science, a machine learning-based predictive model can be an effective tool for turbofan engine core-size prediction. The promising results of this first study paves the way for further exploration of the use of machine learning for aircraft engine preliminary design.","",""
9,"Manuel B. Garcia, Shaneth C. Ambat, Rossana Adao","Tomayto, Tomahto: A Machine Learning Approach for Tomato Ripening Stage Identification Using Pixel-Based Color Image Classification",2019,"","","","",131,"2022-07-13 10:07:14","","10.1109/HNICEM48295.2019.9072892","","",,,,,9,3.00,3,3,3,"The main enterprise of the Philippine agriculture sector is crop cultivation where tomato is deliberated as one of the major crops in the country. With the abundance on tomato production, ripeness classification becomes fairly laborious and challenging, not to mention the subjective visual interpretation of human graders grounded from practical experience that is easily influenced by the environment and prone to error. Thus, this study proposes an automatic tomato ripeness identification using Support Vector Machine (SVM) classifier and CIELab color space via a machine learning approach. Dataset used for modeling and validation experiment in a 5-fold cross-validation strategy was composed of 900 images assembled from a farm and various image search engines. Divided into six classes that represent tomato ripening stages, experimental results showed that the proposed method was successful with 83.39% accuracy in ripeness classification detection. With this machine learning approach and combination of image processing techniques, the agriculture industry could benefit by automating the ripeness estimation which then could save tomatoes from damage.","",""
10,"M. Vishwanath, Salar Jafarlou, Ikhwan Shin, M. Lim, N. Dutt, A. Rahmani, H. Cao","Investigation of Machine Learning Approaches for Traumatic Brain Injury Classification via EEG Assessment in Mice",2020,"","","","",132,"2022-07-13 10:07:14","","10.3390/s20072027","","",,,,,10,5.00,1,7,2,"Due to the difficulties and complications in the quantitative assessment of traumatic brain injury (TBI) and its increasing relevance in today’s world, robust detection of TBI has become more significant than ever. In this work, we investigate several machine learning approaches to assess their performance in classifying electroencephalogram (EEG) data of TBI in a mouse model. Algorithms such as decision trees (DT), random forest (RF), neural network (NN), support vector machine (SVM), K-nearest neighbors (KNN) and convolutional neural network (CNN) were analyzed based on their performance to classify mild TBI (mTBI) data from those of the control group in wake stages for different epoch lengths. Average power in different frequency sub-bands and alpha:theta power ratio in EEG were used as input features for machine learning approaches. Results in this mouse model were promising, suggesting similar approaches may be applicable to detect TBI in humans in practical scenarios.","",""
33,"A. Samarakoon, K. Barros, Y. Li, M. Eisenbach, Qiang Zhang, F. Ye, V. Sharma, Z. Dun, Haidong Zhou, S. A. Grigera, C. Batista, D. Tennant","Machine-learning-assisted insight into spin ice Dy2Ti2O7",2019,"","","","",133,"2022-07-13 10:07:14","","10.1038/s41467-020-14660-y","","",,,,,33,11.00,3,12,3,"","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",134,"2022-07-13 10:07:14","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
1,"C. He, M. Mahfouf, Luis A. Torres-Salomao","An Adaptive General Type-2 Fuzzy Logic Approach for Psychophysiological State Modeling in Real-Time Human–Machine Interfaces",2021,"","","","",135,"2022-07-13 10:07:14","","10.1109/THMS.2020.3027531","","",,,,,1,1.00,0,3,1,"In this article, a new type-2 fuzzy-based modeling approach is proposed to assess human operators’ psychophysiological states for both safety and reliability of human–machine interface systems. Such a new modeling technique combines type-2 fuzzy sets with state tracking to update the rule base through a Bayesian process. These new configurations successfully lead to an adaptive, robust, and transparent computational framework that can be utilized to identify dynamic (i.e., real time) features without prior training. The proposed framework is validated on mental arithmetic cognitive real-time experiments with ten participants. It is found that the proposed framework outperforms other paradigms (i.e., an adaptive neuro-fuzzy inference system and an adaptive general type-2 fuzzy c-means modeling approach) in terms of disturbance rejection and learning capabilities. The proposed framework achieved the best performance compared to other models that have been presented in the related literature. Therefore, the new framework can be a promising development in human–machine interface systems. It can be further utilized to develop advanced control mechanisms, investigate the origins of human compromised task performance, and identify and remedy psychophysiological breakdown in the early stages.","",""
20,"Georgios Rizos, Björn Schuller","Average Jane, Where Art Thou? – Recent Avenues in Efficient Machine Learning Under Subjectivity Uncertainty",2020,"","","","",136,"2022-07-13 10:07:14","","10.1007/978-3-030-50146-4_4","","",,,,,20,10.00,10,2,2,"","",""
0,"Jianbo Chen","Towards Interpretability and Robustness of Machine Learning Models",2019,"","","","",137,"2022-07-13 10:07:14","","","","",,,,,0,0.00,0,1,3,"Author(s): Chen, Jianbo | Advisor(s): Jordan, Michael I; Wainwright, Martin J | Abstract: Modern machine learning models can be difficult to probe and understand after they have been trained. This is a major problem for the field, with consequences for trustworthiness, diagnostics, debugging, robustness, and a range of other engineering and human interaction issues surrounding the deployment of a model. Another problem of modern machine learning models is their vulnerability to small adversarial perturbations to the input, which incurs a security risk when they are applied to critical areas.In this thesis, we develop systematic and efficient tools for interpreting machine learning models and evaluating their adversarial robustness. Part I focuses on model interpretation. We derive an efficient feature scoring method by exploiting the graph structure in data. We also develop a learning-based method under an information-based framework. As an attempt to leverage prior knowledge about what constitutes a satisfying interpretation in a given domain, we propose a systematic approach to exploiting syntactic constituency structure by leveraging a parse tree for interpretation of models in the setting of linguistic data. Part II focuses on the evaluation of adversarial robustness. We first propose a probabilistic framework for generating adversarial examples on discrete data, and develop two algorithms to implement it. We also introduce a novel attack method in the setting where the attacker has access to model decisions alone. We investigate the robustness of various machine learning models and existing defense mechanisms under the proposed attack method. In Part III, we build a connection between the two fields by developing a method for detecting adversarial examples via tools in model interpretation.","",""
2,"E. Lughofer","Model Explanation and Interpretation Concepts for Stimulating Advanced Human-Machine Interaction with ""Expert-in-the-Loop""",2018,"","","","",138,"2022-07-13 10:07:14","","10.1007/978-3-319-90403-0_10","","",,,,,2,0.50,2,1,4,"","",""
19,"P. Mathur, S. Srivastava, Xiaowei Xu, J. Mehta","Artificial Intelligence, Machine Learning, and Cardiovascular Disease",2020,"","","","",139,"2022-07-13 10:07:14","","10.1177/1179546820927404","","",,,,,19,9.50,5,4,2,"Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.","",""
19,"Johannes Burdack, Fabian Horst, Sven Giesselbach, Ibrahim Hassan, Sabrina Daffner, W. Schöllhorn","Systematic Comparison of the Influence of Different Data Preprocessing Methods on the Performance of Gait Classifications Using Machine Learning",2019,"","","","",140,"2022-07-13 10:07:14","","10.3389/fbioe.2020.00260","","",,,,,19,6.33,3,6,3,"Human movements are characterized by highly non-linear and multi-dimensional interactions within the motor system. Therefore, the future of human movement analysis requires procedures that enhance the classification of movement patterns into relevant groups and support practitioners in their decisions. In this regard, the use of data-driven techniques seems to be particularly suitable to generate classification models. Recently, an increasing emphasis on machine-learning applications has led to a significant contribution, e.g., in increasing the classification performance. In order to ensure the generalizability of the machine-learning models, different data preprocessing steps are usually carried out to process the measured raw data before the classifications. In the past, various methods have been used for each of these preprocessing steps. However, there are hardly any standard procedures or rather systematic comparisons of these different methods and their impact on the classification performance. Therefore, the aim of this analysis is to compare different combinations of commonly applied data preprocessing steps and test their effects on the classification performance of gait patterns. A publicly available dataset on intra-individual changes of gait patterns was used for this analysis. Forty-two healthy participants performed 6 sessions of 15 gait trials for 1 day. For each trial, two force plates recorded the three-dimensional ground reaction forces (GRFs). The data was preprocessed with the following steps: GRF filtering, time derivative, time normalization, data reduction, weight normalization and data scaling. Subsequently, combinations of all methods from each preprocessing step were analyzed by comparing their prediction performance in a six-session classification using Support Vector Machines, Random Forest Classifiers, Multi-Layer Perceptrons, and Convolutional Neural Networks. The results indicate that filtering GRF data and a supervised data reduction (e.g., using Principal Components Analysis) lead to increased prediction performance of the machine-learning classifiers. Interestingly, the weight normalization and the number of data points (above a certain minimum) in the time normalization does not have a substantial effect. In conclusion, the present results provide first domain-specific recommendations for commonly applied data preprocessing methods and might help to build more comparable and more robust classification models based on machine learning that are suitable for a practical application.","",""
40,"E. Kuminski, Joe George, J. Wallin, L. Shamir","Combining human and machine learning for morphological analysis of galaxy images",2014,"","","","",141,"2022-07-13 10:07:14","","10.1086/678977","","",,,,,40,5.00,10,4,8,"The increasing importance of digital sky surveys collecting many millions of galaxy images has reinforced the need for robust methods that can perform morphological analysis of large galaxy image databases. Citizen science initiatives such as Galaxy Zoo showed that large datasets of galaxy images can be analyzed effectively by non-scientist volunteers, but since databases generated by robotic telescopes grow much faster than the processing power of any group of citizen scientists, it is clear that computer analysis is required. Here we propose to use citizen science data for training machine learning systems, and show experimental results demonstrating that machine learning systems can be trained with citizen science data. Our findings show that the performance of machine learning depends on the quality of the data, which can be improved by using samples that have a high degree of agreement between the citizen scientists. The source code of the method is publicly available.","",""
75,"J. Ko, S. Baldassano, Po-Ling Loh, Konrad Paul Kording, B. Litt, D. Issadore","Machine learning to detect signatures of disease in liquid biopsies - a user's guide.",2018,"","","","",142,"2022-07-13 10:07:14","","10.1039/c7lc00955k","","",,,,,75,18.75,13,6,4,"New technologies that measure sparse molecular biomarkers from easily accessible bodily fluids (e.g. blood, urine, and saliva) are revolutionizing disease diagnostics and precision medicine. Microchip devices can measure more disease biomarkers with better sensitivity and specificity each year, but clinical interpretation of these biomarkers remains a challenge. Single biomarkers in 'liquid biopsy' often cannot accurately predict the state of a disease due to heterogeneity in phenotype and disease expression across individuals. To address this challenge, investigators are combining multiplexed measurements of different biomarkers that together define robust signatures for specific disease states. Machine learning is a useful tool to automatically discover and detect these signatures, especially as new technologies output increasing quantities of molecular data. In this paper, we review the state of the field of machine learning applied to molecular diagnostics and provide practical guidance to use this tool effectively and to avoid common pitfalls.","",""
14,"Megha Srivastava, Besmira Nushi, Ece Kamar, S. Shah, E. Horvitz","An Empirical Analysis of Backward Compatibility in Machine Learning Systems",2020,"","","","",143,"2022-07-13 10:07:14","","10.1145/3394486.3403379","","",,,,,14,7.00,3,5,2,"In many applications of machine learning (ML), updates are performed with the goal of enhancing model performance. However, current practices for updating models rely solely on isolated, aggregate performance analyses, overlooking important dependencies, expectations, and needs in real-world deployments. We consider how updates, intended to improve ML models, can introduce new errors that can significantly affect downstream systems and users. For example, updates in models used in cloud-based classification services, such as image recognition, can cause unexpected erroneous behavior in systems that make calls to the services. Prior work has shown the importance of ""backward compatibility"" for maintaining human trust. We study challenges with backward compatibility across different ML architectures and datasets, focusing on common settings including data shifts with structured noise and ML employed in inferential pipelines. Our results show that (i) compatibility issues arise even without data shift due to optimization stochasticity, (ii) training on large-scale noisy datasets often results in significant decreases in backward compatibility even when model accuracy increases, and (iii) distributions of incompatible points align with noise bias, motivating the need for compatibility aware de-noising and robustness methods.","",""
12,"J. Vizcarra, M. Gearing, Michael J. Keiser, J. Glass, B. Dugger, D. Gutman","Validation of machine learning models to detect amyloid pathologies across institutions",2020,"","","","",144,"2022-07-13 10:07:14","","10.1186/s40478-020-00927-4","","",,,,,12,6.00,2,6,2,"","",""
72,"Khanh Nguyen, Hal Daumé, Jordan L. Boyd-Graber","Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback",2017,"","","","",145,"2022-07-13 10:07:14","","10.18653/v1/D17-1153","","",,,,,72,14.40,24,3,5,"Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.","",""
5,"Been Kim","An Introduction on Interpretable Machine Learning",2020,"","","","",146,"2022-07-13 10:07:14","","10.35940/ijitee.g1023.0597s20","","",,,,,5,2.50,5,1,2,"As Artificial Intelligence penetrates all aspects of human life, more and more questions about ethical practices and fair uses arise, which has motivated the research community to look inside and develop methods to interpret these Artificial Intelligence/Machine Learning models. This concept of interpretability can not only help with the ethical questions but also can provide various insights into the working of these machine learning models, which will become crucial in trust-building and understanding how a model makes decisions. Furthermore, in many machine learning applications, the feature of interpretability is the primary value that they offer. However, in practice, many developers select models based on the accuracy score and disregarding the level of interpretability of that model, which can be chaotic as predictions by many high accuracy models are not easily explainable. In this paper, we introduce the concept of Machine Learning Model Interpretability, Interpretable Machine learning, and the methods used for interpretation and explanations.","",""
29,"Kanchan Dabre, S. Dholay","Machine learning model for sign language interpretation using webcam images",2014,"","","","",147,"2022-07-13 10:07:14","","10.1109/CSCITA.2014.6839279","","",,,,,29,3.63,15,2,8,"Human beings interact with each other either using a natural language channel such as words, writing, or by body language (gestures) e.g. hand gestures, head gestures, facial expression, lip motion and so on. As understanding natural language is important, understanding sign language is also very important. The sign language is the basic communication method within hearing disable people. People with hearing disabilities face problems in communicating with other hearing people without a translator. For this reason, the implementation of a system that recognize the sign language would have a significant benefit impact on deaf people social live. In this paper, we have proposed a marker-free, visual Indian Sign Language recognition system using image processing, computer vision and neural network methodologies, to identify the characteristics of the hand in images taken from a video trough web camera. This approach will convert video of daily frequently used full sentences gesture into a text and then convert it into audio. Identification of hand shape from continuous frames will be done by using series of image processing operations. Interpretation of signs and corresponding meaning will be identified by using Haar Cascade Classifier. Finally displayed text will be converted into speech using speech synthesizer.","",""
297,"Andrius Vabalas, E. Gowen, E. Poliakoff, A. Casson","Machine learning algorithm validation with a limited sample size",2019,"","","","",148,"2022-07-13 10:07:14","","10.1371/journal.pone.0224365","","",,,,,297,99.00,74,4,3,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.","",""
1,"Jo-Hsuan Wu, T. Liu, W. Hsu, J. Ho, Chien-Chang Lee","Performance and limitation of machine learning algorithms for diabetic retinopathy screening: A meta-analysis (Preprint)",2020,"","","","",149,"2022-07-13 10:07:14","","10.2196/preprints.23863","","",,,,,1,0.50,0,5,2,"  BACKGROUND  Standardly diagnosed by human experts, the high prevalence of diabetic retinopathy (DR) warrants a more efficient screening method. Although machine learning (ML)-based automated DR diagnosis has gained attention due to recent approval of IDx-DR, performance of this tool has not be examined systematically, and the best ML technique for utilization in real-world setting has not been discussed.       OBJECTIVE  To examine systematically the overall diagnostic accuracy of ML in diagnosing DR of different categories based on color fundus photographs and to determine the state-of-the-art ML approach.      METHODS  Published studies in PubMed and EMBASE were searched from inception to June, 2020. Studies were screened for relevant outcomes, publication types, and data sufficiency, and a total of 60 (2.8%) out of 2128 studies were retrieved after study selection. Extraction of data was performed by 2 authors according to PRISMA, and the quality assessment was performed according to QUADUS-2. Meta-analysis of diagnostic accuracy was pooled using a bivariate random-effects model. The main outcomes included diagnostic accuracy, sensitivity, and specificity of ML in diagnosing DR based on color fundus photographs, as well as the performances of different major types of ML algorithms.      RESULTS  The primary meta-analysis included 60 color fundus photograph studies (445,175 interpretations). Overall, ML demonstrated high accuracy in diagnosing DR of various categories, with a pooled AUROC from 0.97 (95% CI: 0.96, 0.99) to 0.99 (95%CI: 0.98, 1.00). The performance of ML in detecting more-than-mild DR (mtmDR) was robust (Sen: 0.95, AUROC: 0.97), and by subgroup analyses, we observed that robust performance of ML was not limited to benchmark datasets (Sen: 0.92; AUROC: 0.96) but could be generalized to images collected in clinical practice (Sen: 0.97; AUROC: 097). Neural network was the most widely utilized method, and the subgroup analysis revealed a pooled AUROC of 0.98 (95% CI: 0.96, 0.99) for studies that utilized neural networks to diagnose mtmDR.      CONCLUSIONS  This meta-analysis demonstrated high diagnostic accuracy of ML algorithms in detecting diabetic retinopathy on color fundus photographs, suggesting that state-of-the-art, ML-based DR screening algorithms are likely ready for clinical applications. However, a significant portion of the earlier published studies had methodology flaws, such as the lack of external validation and presence of spectrum bias. The results of these studies should be interpreted with caution.      CLINICALTRIAL   ","",""
0,"K. Kelly","Man and the machine rise to the spike‐wave. Commentary on “An automated, machine learning‐based detection algorithm for spike‐wave discharges (SWDs) in a mouse model of absence epilepsy.”",2020,"","","","",150,"2022-07-13 10:07:14","","10.1002/epi4.12428","","",,,,,0,0.00,0,1,2,"Anyone who has spent a considerable amount of time in visual analysis and manual scoring of EEG events of either human or animal long-term EEG recordings fully understands that the process is not entirely a labor of love. Manual review of large volumes of EEG data, whether for detection of ictal discharges, epileptiform activity, or abnormal slowing, is notoriously time-consuming, fatigue-inducing, and frequently inexact. Numerous analytical software programs have been developed over the last several decades to aid visual review of continuous EEG recordings and have contributed significantly to the precision and accuracy of event detection. However, event detection by even the best algorithms remains an imperfect science. The ongoing need to build better analytical “mousetraps” for EEG event capture continues to be a daunting challenge for epileptologists, computer scientists, and basic researchers. Such a challenge was embraced wholeheartedly by Pfammatter and colleagues.1 They built an automated, machine learning-based detection algorithm for spike-wave discharges (SWDs) in the γ2R43Q mouse model, a GABAA receptor knock-in mutation that generates ~6 Hz SWDs (absence epilepsy) in the animal. As many are aware, SWDs in rodent models of acquired epilepsy continue to be an active topic of discussion and interpretation.2 The fundamental uncertainty of this ongoing issue is what is or is not an actual SWD associated with “absence” discharges. The authors of this study recognized the critical importance of rigor in defining SWDs in their model and the associated need to develop robust, automated methods for their detection. They contended that the true definition of SWDs should arise from comparison of rigorously definable events, such as a set of predictor variables, with other known EEG features, such as the sleep-wake cycle, or treatments that alter SWDs, for example, ethosuximide. Their deliberative efforts resulted in a highly integrated system of confidence-based scoring of events along a continuum, in addition to a binary classification (SWD/non-SWD), that reflected physiologically relevant EEG features of normal behavioral states and matched scoring characteristics of human reviewers. Their efforts began with two of the authors manually scoring 24-hour unannotated EEG records outside of the EEG training sets for the presence of SWDs—4 from γ2R43Q mice (RQ) and 1 without the mutation but with the same genetic background (RR)—in order to facilitate the development and performance validation of a 2-stage algorithm. For Stage 1, they constructed a support vector machine (SVM)based algorithm, a learning tool used to analyze data and separate groups of events for classification purposes, after being trained with a set of prescribed labels. Importantly, as the authors describe, the boundaries of the classification space are defined by events assigned as support vectors; the location of each event relative to the nearest support vectors can be used for its classification, and the distance from each event to its nearest support vector can be used as a proxy for confidence in its assigned classification. The algorithm first identified 2500 putative SWDs based on frequencyand","",""
16,"Mitchell J. Feldmann, M. Hardigan, R. Famula, Cindy M. López, A. Tabb, Glenn S. Cole, S. Knapp","Multi-dimensional machine learning approaches for fruit shape phenotyping in strawberry",2020,"","","","",151,"2022-07-13 10:07:14","","10.1093/gigascience/giaa030","","",,,,,16,8.00,2,7,2,"Abstract Background Shape is a critical element of the visual appeal of strawberry fruit and is influenced by both genetic and non-genetic determinants. Current fruit phenotyping approaches for external characteristics in strawberry often rely on the human eye to make categorical assessments. However, fruit shape is an inherently multi-dimensional, continuously variable trait and not adequately described by a single categorical or quantitative feature. Morphometric approaches enable the study of complex, multi-dimensional forms but are often abstract and difficult to interpret. In this study, we developed a mathematical approach for transforming fruit shape classifications from digital images onto an ordinal scale called the Principal Progression of k Clusters (PPKC). We use these human-recognizable shape categories to select quantitative features extracted from multiple morphometric analyses that are best fit for genetic dissection and analysis. Results We transformed images of strawberry fruit into human-recognizable categories using unsupervised machine learning, discovered 4 principal shape categories, and inferred progression using PPKC. We extracted 68 quantitative features from digital images of strawberries using a suite of morphometric analyses and multivariate statistical approaches. These analyses defined informative feature sets that effectively captured quantitative differences between shape classes. Classification accuracy ranged from 68% to 99% for the newly created phenotypic variables for describing a shape. Conclusions Our results demonstrated that strawberry fruit shapes could be robustly quantified, accurately classified, and empirically ordered using image analyses, machine learning, and PPKC. We generated a dictionary of quantitative traits for studying and predicting shape classes and identifying genetic factors underlying phenotypic variability for fruit shape in strawberry. The methods and approaches that we applied in strawberry should apply to other fruits, vegetables, and specialty crops.","",""
2,"Zhiyang Wang, Y. Ou","On stability for learning human control strategy by demonstrations using SVM",2019,"","","","",152,"2022-07-13 10:07:14","","10.1108/aa-11-2018-0236","","",,,,,2,0.67,1,2,3,"This paper aims to deal with the trade-off of the stability and the accuracy in learning human control strategy from demonstrations. With the stability conditions and the estimated stability region, this paper aims to conveniently get rid of the unstable controller or controller with relatively small stability region. With this evaluation, the learning human strategy controller becomes much more robust to perturbations.,In this paper, the criterion to verify the stability and a method to estimate the domain of attraction are provided for the learning controllers trained with support vector machines (SVMs). Conditions are formulated based on the discrete-time system Lyapunov theory to ensure that a closed-form of the learning control system is strongly stable under perturbations (SSUP). Then a Chebychev point based approach is proposed to estimate its domain of attraction.,Some of such learning controllers have been implemented in the vertical balance control of a dynamically stable, statically unstable wheel mobile robot.","",""
16,"H. Salehi, Saptarshi Das, S. Chakrabartty, S. Biswas, R. Burgueño","Damage identification in aircraft structures with self‐powered sensing technology: A machine learning approach",2018,"","","","",153,"2022-07-13 10:07:14","","10.1002/stc.2262","","",,,,,16,4.00,3,5,4,"Progress in self‐powered wireless sensor networks for structural health monitoring (SHM) have motivated the development of power‐efficient data communication protocols. One such approach is the energy‐aware pulse switching architecture, which employs ultrasonic pulses to transmit binary data through the material substrate. However, this technology creates time delays on the generated data due to the power budgets demanded for sensing and communication. The nature of data collected from such protocol thus requires the development of new analysis and interpretation methods. This study presents a robust damage identification strategy for aircraft structures, within the context of data‐driven SHM, using discrete time‐delayed binary data. A novel machine learning framework integrating low‐rank matrix completion, pattern recognition, k‐nearest neighbor, and a data fusion model was developed for damage identification. Performance and accuracy of the proposed data‐driven SHM strategy was investigated and tested for an aircraft horizontal stabilizer wing. Damage states were simulated on a finite element model by reducing stiffness in a region of the stabilizer's skin. The reliability of the proposed strategy with noise‐polluted data was also validated. Further, the effect of variations in harvested energy on the performance of the approach was investigated. Results demonstrate that the developed machine learning framework can effectively detect the presence and location of damage based on time‐delayed binary data from a self‐powered sensor network.","",""
35,"Benjamin Schiller, Johannes Daxenberger, Iryna Gurevych","Stance Detection Benchmark: How Robust Is Your Stance Detection?",2020,"","","","",154,"2022-07-13 10:07:14","","10.1007/S13218-021-00714-W","","",,,,,35,17.50,12,3,2,"","",""
42,"T. Luechtefeld, C. Rowlands, T. Hartung","Big-data and machine learning to revamp computational toxicology and its use in risk assessment.",2018,"","","","",155,"2022-07-13 10:07:14","","10.1039/c8tx00051d","","",,,,,42,10.50,14,3,4,"The creation of large toxicological databases and advances in machine-learning techniques have empowered computational approaches in toxicology. Work with these large databases based on regulatory data has allowed reproducibility assessment of animal models, which highlight weaknesses in traditional in vivo methods. This should lower the bars for the introduction of new approaches and represents a benchmark that is achievable for any alternative method validated against these methods. Quantitative Structure Activity Relationships (QSAR) models for skin sensitization, eye irritation, and other human health hazards based on these big databases, however, also have made apparent some of the challenges facing computational modeling, including validation challenges, model interpretation issues, and model selection issues. A first implementation of machine learning-based predictions termed REACHacross achieved unprecedented sensitivities of >80% with specificities >70% in predicting the six most common acute and topical hazards covering about two thirds of the chemical universe. While this is awaiting formal validation, it demonstrates the new quality introduced by big data and modern data-mining technologies. The rapid increase in the diversity and number of computational models, as well as the data they are based on, create challenges and opportunities for the use of computational methods.","",""
36,"M. Domínguez‐Rodrigo, E. Baquedano","Distinguishing butchery cut marks from crocodile bite marks through machine learning methods",2018,"","","","",156,"2022-07-13 10:07:14","","10.1038/s41598-018-24071-1","","",,,,,36,9.00,18,2,4,"","",""
83,"D. Wilkins, Andrea Grisafi, Yang Yang, K. Lao, Robert A. DiStasio, M. Ceriotti","Accurate molecular polarizabilities with coupled cluster theory and machine learning",2018,"","","","",157,"2022-07-13 10:07:14","","10.1073/pnas.1816132116","","",,,,,83,20.75,14,6,4,"Significance The dipole polarizability of molecules and materials is central to several physical phenomena, modeling techniques, and the interpretation of many experiments. Its accurate evaluation from first principles requires quantum chemistry methods that are often too demanding for routine use. The highly accurate calculations reported herein provide a much-needed benchmark of the accuracy of hybrid density functional theory (DFT) as well as training data for a machine-learning model that can predict the polarizability tensor with an error that is about 50% smaller than DFT. This framework provides an accurate, inexpensive, and transferable strategy for estimating the polarizabilities of molecules containing dozens of atoms, and therefore removes a considerable obstacle to accurate and reliable atomistic-based modeling of matter. The molecular dipole polarizability describes the tendency of a molecule to change its dipole moment in response to an applied electric field. This quantity governs key intra- and intermolecular interactions, such as induction and dispersion; plays a vital role in determining the spectroscopic signatures of molecules; and is an essential ingredient in polarizable force fields. Compared with other ground-state properties, an accurate prediction of the molecular polarizability is considerably more difficult, as this response quantity is quite sensitive to the underlying electronic structure description. In this work, we present highly accurate quantum mechanical calculations of the static dipole polarizability tensors of 7,211 small organic molecules computed using linear response coupled cluster singles and doubles theory (LR-CCSD). Using a symmetry-adapted machine-learning approach, we demonstrate that it is possible to predict the LR-CCSD molecular polarizabilities of these small molecules with an error that is an order of magnitude smaller than that of hybrid density functional theory (DFT) at a negligible computational cost. The resultant model is robust and transferable, yielding molecular polarizabilities for a diverse set of 52 larger molecules (including challenging conjugated systems, carbohydrates, small drugs, amino acids, nucleobases, and hydrocarbon isomers) at an accuracy that exceeds that of hybrid DFT. The atom-centered decomposition implicit in our machine-learning approach offers some insight into the shortcomings of DFT in the prediction of this fundamental quantity of interest.","",""
23,"Muxin Gu, M. Buckley","Semi-supervised machine learning for automated species identification by collagen peptide mass fingerprinting",2018,"","","","",158,"2022-07-13 10:07:14","","10.1186/s12859-018-2221-3","","",,,,,23,5.75,12,2,4,"","",""
20,"Po-Han Chiang, S. Dey","Personalized Effect of Health Behavior on Blood Pressure: Machine Learning Based Prediction and Recommendation",2018,"","","","",159,"2022-07-13 10:07:14","","10.1109/HealthCom.2018.8531109","","",,,,,20,5.00,10,2,4,"Blood pressure (BP) is one of the most important indicator of human health. In this paper, we investigate the relationship between BP and health behavior (e.g. sleep and exercise). Using the data collected from off-the-shelf wearable devices and wireless home BP monitors, we propose a data driven personalized model to predict daily BP level and provide actionable insight into health behavior and daily BP. In the proposed machine learning model using Random Forest (RF), trend and periodicity features of BP time-series are extracted to improve prediction. To further enhance the performance of the prediction model, we propose RF with Feature Selection (RFFS), which performs RF-based feature selection to filter out unnecessary features. Our experimental results demonstrate that the proposed approach is robust to different individuals and has smaller prediction error than existing methods. We also validate the effectiveness of personalized recommendation of health behavior generated by RFFS model.","",""
39,"C. Rosé, Elizabeth A. McLaughlin, Ran Liu, K. Koedinger","Explanatory learner models: Why machine learning (alone) is not the answer",2019,"","","","",160,"2022-07-13 10:07:14","","10.1111/BJET.12858","","",,,,,39,13.00,10,4,3,"Using data to understand learning and improve education has great promise. However, the promise will not be achieved simply by AI and Machine Learning researchers developing innovative models that more accurately predict labeled data. As AI advances, modeling techniques and the models they produce are getting increasingly complex, often involving tens of thousands of parameters or more. Though strides towards interpretation of complex models are being made in core machine learning communities, it remains true in these cases of ""black box"" modeling that research teams may have little possibility to peer inside to try understand how, why, or even whether such models will work when applied beyond the data on which they were built. Rather than relying on AI expertise alone, we suggest that learning engineering teams bring interdisciplinary expertise to bear to develop explanatory learner models that provide interpretable and actionable insights in addition to accurate prediction. We describe examples that illustrate use of different kinds of data (eg, click stream and discourse data) in different course content (eg, math and writing) and toward different goals (eg, improving student models and generating actionable feedback). We recommend learning engineering teams, shared infrastructure and funder incentives toward better explanatory learner model development that advances learning science, produces better pedagogical practices and demonstrably improves student learning. Practitioner NotesWhat is already known about this topic Researchers in learning analytics and educational data mining have been successful in creating innovative models of data that optimize prediction.Some of these models produce scientific or practical insights and fewer have been put into use and demonstrated to enhance student learning.What this paper adds We provide examples of development of explanatory models of learners that not only accurately predict data but also provide scientific insights and yield practical outcomes.In particular, researchers with expertise in cognitive science and math education content use AI‐based data analytics to discover previously unrecognized barriers to geometry student learning. They use model‐derived insights to redesign an online tutoring system and ""close‐the‐loop"" by experimentally demonstrating that the new system produces better student learning than the original.Implications for practice and/or policy We define explanatory learning models and provide an articulation of a process for generating them that involves interdisciplinary teams employing human–computer interaction and learning engineering methods.Based on our experiences, we recommend learning engineering teams, shared infrastructure and funder incentives toward better explanatory learner model development that advances learning science, produces better pedagogical practices and demonstrably improves student learning. [ABSTRACT FROM AUTHOR]","",""
56,"M. Krishnan","Against Interpretability: a Critical Examination of the Interpretability Problem in Machine Learning",2019,"","","","",161,"2022-07-13 10:07:14","","10.1007/S13347-019-00372-9","","",,,,,56,18.67,56,1,3,"","",""
63,"Yanju Zhang, Ruopeng Xie, Jiawei Wang, A. Leier, T. Marquez-Lago, T. Akutsu, Geoffrey I. Webb, K. Chou, Jiangning Song","Computational analysis and prediction of lysine malonylation sites by exploiting informative features in an integrative machine-learning framework",2018,"","","","",162,"2022-07-13 10:07:14","","10.1093/bib/bby079","","",,,,,63,15.75,7,9,4,"As a newly discovered post-translational modification (PTM), lysine malonylation (Kmal) regulates a myriad of cellular processes from prokaryotes to eukaryotes and has important implications in human diseases. Despite its functional significance, computational methods to accurately identify malonylation sites are still lacking and urgently needed. In particular, there is currently no comprehensive analysis and assessment of different features and machine learning (ML) methods that are required for constructing the necessary prediction models. Here, we review, analyze and compare 11 different feature encoding methods, with the goal of extracting key patterns and characteristics from residue sequences of Kmal sites. We identify optimized feature sets, with which four commonly used ML methods (random forest, support vector machines, K-nearest neighbor and logistic regression) and one recently proposed [Light Gradient Boosting Machine (LightGBM)] are trained on data from three species, namely, Escherichia coli, Mus musculus and Homo sapiens, and compared using randomized 10-fold cross-validation tests. We show that integration of the single method-based models through ensemble learning further improves the prediction performance and model robustness on the independent test. When compared to the existing state-of-the-art predictor, MaloPred, the optimal ensemble models were more accurate for all three species (AUC: 0.930, 0.923 and 0.944 for E. coli, M. musculus and H. sapiens, respectively). Using the ensemble models, we developed an accessible online predictor, kmal-sp, available at http://kmalsp.erc.monash.edu/. We hope that this comprehensive survey and the proposed strategy for building more accurate models can serve as a useful guide for inspiring future developments of computational methods for PTM site prediction, expedite the discovery of new malonylation and other PTM types and facilitate hypothesis-driven experimental validation of novel malonylated substrates and malonylation sites.","",""
15,"Jonathan Z. L. Zhao, E. Mucaki, P. Rogan","Predicting ionizing radiation exposure using biochemically-inspired genomic machine learning",2018,"","","","",163,"2022-07-13 10:07:14","","10.12688/f1000research.14048.2","","",,,,,15,3.75,5,3,4,"Background: Gene signatures derived from transcriptomic data using machine learning methods have shown promise for biodosimetry testing. These signatures may not be sufficiently robust for large scale testing, as their performance has not been adequately validated on external, independent datasets. The present study develops human and murine signatures with biochemically-inspired machine learning that are strictly validated using k-fold and traditional approaches. Methods: Gene Expression Omnibus (GEO) datasets of exposed human and murine lymphocytes were preprocessed via nearest neighbor imputation and expression of genes implicated in the literature to be responsive to radiation exposure (n=998) were then ranked by Minimum Redundancy Maximum Relevance (mRMR). Optimal signatures were derived by backward, complete, and forward sequential feature selection using Support Vector Machines (SVM), and validated using k-fold or traditional validation on independent datasets. Results: The best human signatures we derived exhibit k-fold validation accuracies of up to 98% ( DDB2, PRKDC, TPP2, PTPRE, and GADD45A) when validated over 209 samples and traditional validation accuracies of up to 92% ( DDB2, CD8A, TALDO1, PCNA, EIF4G2, LCN2, CDKN1A, PRKCH, ENO1, and PPM1D) when validated over 85 samples. Some human signatures are specific enough to differentiate between chemotherapy and radiotherapy. Certain multi-class murine signatures have sufficient granularity in dose estimation to inform eligibility for cytokine therapy (assuming these signatures could be translated to humans). We compiled a list of the most frequently appearing genes in the top 20 human and mouse signatures. More frequently appearing genes among an ensemble of signatures may indicate greater impact of these genes on the performance of individual signatures. Several genes in the signatures we derived are present in previously proposed signatures. Conclusions: Gene signatures for ionizing radiation exposure derived by machine learning have low error rates in externally validated, independent datasets, and exhibit high specificity and granularity for dose estimation.","",""
66,"R. Cuocolo, Maria Brunella Cipullo, A. Stanzione, L. Ugga, V. Romeo, L. Radice, A. Brunetti, M. Imbriaco","Machine learning applications in prostate cancer magnetic resonance imaging",2019,"","","","",164,"2022-07-13 10:07:14","","10.1186/s41747-019-0109-2","","",,,,,66,22.00,8,8,3,"","",""
62,"Philipp Schmidt, F. Biessmann","Quantifying Interpretability and Trust in Machine Learning Systems",2019,"","","","",165,"2022-07-13 10:07:14","","","","",,,,,62,20.67,31,2,3,"Decisions by Machine Learning (ML) models have become ubiquitous. Trusting these decisions requires understanding how algorithms take them. Hence interpretability methods for ML are an active focus of research. A central problem in this context is that both the quality of interpretability methods as well as trust in ML predictions are difficult to measure. Yet evaluations, comparisons and improvements of trust and interpretability require quantifiable measures. Here we propose a quantitative measure for the quality of interpretability methods. Based on that we derive a quantitative measure of trust in ML decisions. Building on previous work we propose to measure intuitive understanding of algorithmic decisions using the information transfer rate at which humans replicate ML model predictions. We provide empirical evidence from crowdsourcing experiments that the proposed metric robustly differentiates interpretability methods. The proposed metric also demonstrates the value of interpretability for ML assisted human decision making: in our experiments providing explanations more than doubled productivity in annotation tasks. However unbiased human judgement is critical for doctors, judges, policy makers and others. Here we derive a trust metric that identifies when human decisions are overly biased towards ML predictions. Our results complement existing qualitative work on trust and interpretability by quantifiable measures that can serve as objectives for further improving methods in this field of research.","",""
14,"Hanan Hindy, David Brosset, E. Bayne, A. Seeam, X. Bellekens","Improving SIEM for Critical SCADA Water Infrastructures Using Machine Learning",2018,"","","","",166,"2022-07-13 10:07:14","","10.1007/978-3-030-12786-2_1","","",,,,,14,3.50,3,5,4,"","",""
9,"Dina Sikpa, J. Fouquet, R. Lebel, P. Diamandis, M. Richer, M. Lepage","Automated detection and quantification of breast cancer brain metastases in an animal model using democratized machine learning tools",2019,"","","","",167,"2022-07-13 10:07:14","","10.1038/s41598-019-53911-x","","",,,,,9,3.00,2,6,3,"","",""
10,"E. Adabor, G. Acquaah-Mensah","Machine learning approaches to decipher hormone and HER2 receptor status phenotypes in breast cancer",2019,"","","","",168,"2022-07-13 10:07:14","","10.1093/bib/bbx138","","",,,,,10,3.33,5,2,3,"Breast cancer prognosis and administration of therapies are aided by knowledge of hormonal and HER2 receptor status. Breast cancer lacking estrogen receptors, progesterone receptors and HER2 receptors are difficult to treat. Regarding large data repositories such as The Cancer Genome Atlas, available wet-lab methods for establishing the presence of these receptors do not always conclusively cover all available samples. To this end, we introduce median-supplement methods to identify hormonal and HER2 receptor status phenotypes of breast cancer patients using gene expression profiles. In these approaches, supplementary instances based on median patient gene expression are introduced to balance a training set from which we build simple models to identify the receptor expression status of patients. In addition, for the purpose of benchmarking, we examine major machine learning approaches that are also applicable to the problem of finding receptor status in breast cancer. We show that our methods are robust and have high sensitivity with extremely low false-positive rates compared with the well-established methods. A successful application of these methods will permit the simultaneous study of large collections of samples of breast cancer patients as well as save time and cost while standardizing interpretation of outcomes of such studies.","",""
45,"R. Roelofs, Vaishaal Shankar, B. Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, Ludwig Schmidt","A Meta-Analysis of Overfitting in Machine Learning",2019,"","","","",169,"2022-07-13 10:07:14","","","","",,,,,45,15.00,6,7,3,"We conduct the first large meta-analysis of overfitting due to test set reuse in the machine learning community. Our analysis is based on over one hundred machine learning competitions hosted on the Kaggle platform over the course of several years. In each competition, numerous practitioners repeatedly evaluated their progress against a holdout set that forms the basis of a public ranking available throughout the competition. Performance on a separate test set used only once determined the final ranking. By systematically comparing the public ranking with the final ranking, we assess how much participants adapted to the holdout set over the course of a competition. Our study shows, somewhat surprisingly, little evidence of substantial overfitting. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.","",""
41,"Zijian Zhang, Jaspreet Singh, U. Gadiraju, Avishek Anand","Dissonance Between Human and Machine Understanding",2019,"","","","",170,"2022-07-13 10:07:14","","10.1145/3359158","","",,,,,41,13.67,10,4,3,"Complex machine learning models are deployed in several critical domains including healthcare and autonomous vehicles nowadays, albeit as functional blackboxes. Consequently, there has been a recent surge in interpreting decisions of such complex models in order to explain their actions to humans. Models which correspond to human interpretation of a task are more desirable in certain contexts and can help attribute liability, build trust, expose biases and in turn build better models. It is therefore crucial to understand how and which models conform to human understanding of tasks. In this paper we present a large-scale crowdsourcing study that reveals and quantifies the dissonance between human and machine understanding, through the lens of an image classification task. In particular, we seek to answer the following questions: Which (well performing) complex ML models are closer to humans in their use of features to make accurate predictions? How does task difficulty affect the feature selection capability of machines in comparison to humans? Are humans consistently better at selecting features that make image recognition more accurate? Our findings have important implications on human-machine collaboration, considering that a long term goal in the field of artificial intelligence is to make machines capable of learning and reasoning like humans.","",""
37,"Alex Bratt, Jiwon Kim, Meridith P. Pollie, Ashley N Beecy, Nathan H. Tehrani, N. Codella, R. Perez-Johnston, M. Palumbo, Javid Alakbarli, Wayne Colizza, Ian R. Drexler, C. Azevedo, R. Kim, R. Devereux, J. Weinsaft","Machine learning derived segmentation of phase velocity encoded cardiovascular magnetic resonance for fully automated aortic flow quantification",2019,"","","","",171,"2022-07-13 10:07:14","","10.1186/s12968-018-0509-0","","",,,,,37,12.33,4,15,3,"","",""
127,"Sohrab Saeb, L. Lonini, A. Jayaraman, D. Mohr, Konrad Paul Kording","The need to approximate the use-case in clinical machine learning",2017,"","","","",172,"2022-07-13 10:07:14","","10.1093/gigascience/gix019","","",,,,,127,25.40,25,5,5,"Abstract The availability of smartphone and wearable sensor technology is leading to a rapid accumulation of human subject data, and machine learning is emerging as a technique to map those data into clinical predictions. As machine learning algorithms are increasingly used to support clinical decision making, it is vital to reliably quantify their prediction accuracy. Cross-validation (CV) is the standard approach where the accuracy of such algorithms is evaluated on part of the data the algorithm has not seen during training. However, for this procedure to be meaningful, the relationship between the training and the validation set should mimic the relationship between the training set and the dataset expected for the clinical use. Here we compared two popular CV methods: record-wise and subject-wise. While the subject-wise method mirrors the clinically relevant use-case scenario of diagnosis in newly recruited subjects, the record-wise strategy has no such interpretation. Using both a publicly available dataset and a simulation, we found that record-wise CV often massively overestimates the prediction accuracy of the algorithms. We also conducted a systematic review of the relevant literature, and found that this overly optimistic method was used by almost half of the retrieved studies that used accelerometers, wearable sensors, or smartphones to predict clinical outcomes. As we move towards an era of machine learning-based diagnosis and treatment, using proper methods to evaluate their accuracy is crucial, as inaccurate results can mislead both clinicians and data scientists.","",""
30,"D. Yang, Liling Zhu, Yalong Liu, Danhong Wu, B. Ran","A Novel Car-Following Control Model Combining Machine Learning and Kinematics Models for Automated Vehicles",2019,"","","","",173,"2022-07-13 10:07:14","","10.1109/TITS.2018.2854827","","",,,,,30,10.00,6,5,3,"The machine learning-based car-following models are widely adopted to control the longitudinal movements of automated vehicles, such as Google Car and Apple Car, by mimicking the human drivers’ car-following maneuver. However, like human drivers, the models easily produce unsafe maneuvers for automated vehicles and has low robustness, especially in uncommon situations. To improve the machine learning-based car-following models, this paper proposes to combine the machine learning models with the kinematics-based car-following models that can overcome the shortcomings of machine learning models, using an optimal combination prediction method, which is called the combination car-following model in the paper. The selected kinematics-based car-following model is the Gipps model that has an intrinsic crash-avoidance mechanism, and the used machine learning-based models are the Back-Propagation Neural Networks (BPNN) model and Random Forest (RF) model, producing the two CCF models, the Gipps-RF model and Gipps-BPNN model. The real vehicle trajectory data sets are applied to calibrate and validate the proposed models, and simulations are conducted to evaluate the model performances. The results display that the proposed CCF models can enhance safety level and robustness of the car-following control of automated vehicles. Both the two CCF models have better performance than the BPNN and RF car-following models in reducing congestion, stabilizing traffic, and avoiding crashes, especially the Gipps-BPNN model.","",""
31,"Matthew R. Carbone, Shinjae Yoo, M. Topsakal, D. Lu","Classification of local chemical environments from x-ray absorption spectra using supervised machine learning",2019,"","","","",174,"2022-07-13 10:07:14","","10.1103/PhysRevMaterials.3.033604","","",,,,,31,10.33,8,4,3,"X-ray absorption spectroscopy is a premier element-specific technique for materials characterization. Specifically, the x-ray absorption near-edge structure (XANES) encodes important information about the local chemical environment of an absorbing atom, including coordination number, symmetry, and oxidation state. Interpreting XANES spectra is a key step towards understanding the structural and electronic properties of materials, and as such, extracting structural and electronic descriptors from XANES spectra is akin to solving a challenging inverse problem. Existing methods rely on empirical fingerprints, which are often qualitative or semiquantitative and not transferable. In this paper, we present a machine learning-based approach, which is capable of classifying the local coordination environments of the absorbing atom from simulated K-edge XANES spectra. The machine learning classifiers can learn important spectral features in a broad energy range without human bias and once trained, can make predictions on the fly. The robustness and fidelity of the machine learning method are demonstrated by an average 86% accuracy across the wide chemical space of oxides in eight 3d transition-metal families. We found that spectral features beyond the preedge region play an important role in the local structure classification problem especially for the late 3d transition-metal elements.","",""
6,"O. R. Sanchez, Simone Ferlin Oliveira, C. Pelsser, R. Bush","Comparing Machine Learning Algorithms for BGP Anomaly Detection using Graph Features",2019,"","","","",175,"2022-07-13 10:07:14","","10.1145/3359992.3366640","","",,,,,6,2.00,2,4,3,"The Border Gateway Protocol (BGP) coordinates the connectivity and reachability among Autonomous Systems, providing efficient operation of the global Internet. Historically, BGP anomalies have disrupted network connections on a global scale, i.e., detecting them is of great importance. Today, Machine Learning (ML) methods have improved BGP anomaly detection using volume and path features of BGP's update messages, which are often noisy and bursty. In this work, we identified different graph features to detect BGP anomalies, which are arguably more robust than traditional features. We evaluate such features through an extensive comparison of different ML algorithms, i.e., Naive Bayes classifier (NB), Decision Trees (DT), Random Forests (RF), Support Vector Machines (SVM), and Multi-Layer Perceptron (MLP), to specifically detect BGP path leaks. We show that SVM offers a good trade-off between precision and recall. Finally, we provide insights into the graph features' characteristics during the anomalous and non-anomalous interval and provide an interpretation of the ML classifier results.","",""
0,"J. O’Donovan, Ken Kahn, M. MacRae, A. S. Namanda, Rebecca Hamala, Kenneth Kabali, Anne Geniets, A. Lakati, Simon M. Mbae, N. Winters","Analysing 3429 digital supervisory interactions between Community Health Workers in Uganda and Kenya: the development, testing and validation of an open access predictive machine learning web app",2022,"","","","",176,"2022-07-13 10:07:14","","10.1186/s12960-021-00699-5","","",,,,,0,0.00,0,10,1,"","",""
26,"Christina M. Funke, Judy Borowski, Karolina Stosio, Wieland Brendel, Thomas S. A. Wallis, M. Bethge","The Notorious Difficulty of Comparing Human and Machine Perception",2020,"","","","",177,"2022-07-13 10:07:14","","10.32470/ccn.2019.1295-0","","",,,,,26,13.00,4,6,2,"With the rise of machines to human-level performance in complex recognition tasks, a growing amount of work is directed towards comparing information processing in humans and machines. These works have the potential to deepen our understanding of the inner mechanisms of human perception and to improve machine learning. Drawing robust conclusions from comparison studies, however, turns out to be difficult. Here, we highlight common shortcomings that can easily lead to fragile conclusions. First, if a model does achieve high performance on a task similar to humans, its decision-making process is not necessarily human-like. Moreover, further analyses can reveal differences. Second, the performance of neural networks is sensitive to training procedures and architectural details. Thus, generalizing conclusions from specific architectures is difficult. Finally, when comparing humans and machines, equivalent experimental settings are crucial in order to identify innate differences. Addressing these shortcomings alters or refines the conclusions of studies. We show that, despite their ability to solve closed-contour tasks, our neural networks use different decision-making strategies than humans. We further show that there is no fundamental difference between same-different and spatial tasks for common feed-forward neural networks and finally, that neural networks do experience a ""recognition gap"" on minimal recognizable images. All in all, care has to be taken to not impose our human systematic bias when comparing human and machine perception.","",""
15,"G. E. Jergensen, A. McGovern, Ryan Lagerquist, Travis M. Smith","Classifying Convective Storms Using Machine Learning",2019,"","","","",178,"2022-07-13 10:07:14","","10.1175/waf-d-19-0170.1","","",,,,,15,5.00,4,4,3,"  We demonstrate that machine learning (ML) can skillfully classify thunderstorms into three categories: supercell, part of a quasi-linear convective system, or disorganized. These classifications are based on radar data and environmental information obtained through a proximity sounding. We compare the performance of five ML algorithms: logistic regression with the elastic-net penalty, random forests, gradient-boosted forests, and support-vector machines with both a linear and nonlinear kernel. The gradient-boosted forest performs best, with an accuracy of 0.77 ± 0.02 and a Peirce score of 0.58 ± 0.04. The linear support-vector machine performs second best, with values of 0.70 ± 0.02 and 0.55 ± 0.05, respectively. We use two interpretation methods, permutation importance and sequential forward selection, to determine the most important predictors for the ML models. We also use partial-dependence plots to determine how these predictors influence the outcome. A main conclusion is that shape predictors, based on the outline of the storm, appear to be highly important across ML models. The training data, a storm-centered radar scan and modeled proximity sounding, are similar to real-time data. Thus, the models could be used operationally to aid human decision-making by reducing the cognitive load involved in manual storm-mode identification. Also, they could be run on historical data to perform climatological analyses, which could be valuable to both the research and operational communities.","",""
11,"A. Baskar, T. Kumar","Facial Expression Classification Using Machine Learning Approach: A Review",2018,"","","","",179,"2022-07-13 10:07:14","","10.1007/978-981-10-3223-3_32","","",,,,,11,2.75,6,2,4,"","",""
40,"B. Almaslukh, A. Artoli, J. Al-Muhtadi","A Robust Deep Learning Approach for Position-Independent Smartphone-Based Human Activity Recognition",2018,"","","","",180,"2022-07-13 10:07:14","","10.3390/s18113726","","",,,,,40,10.00,13,3,4,"Recently, modern smartphones equipped with a variety of embedded-sensors, such as accelerometers and gyroscopes, have been used as an alternative platform for human activity recognition (HAR), since they are cost-effective, unobtrusive and they facilitate real-time applications. However, the majority of the related works have proposed a position-dependent HAR, i.e., the target subject has to fix the smartphone in a pre-defined position. Few studies have tackled the problem of position-independent HAR. They have tackled the problem either using handcrafted features that are less influenced by the position of the smartphone or by building a position-aware HAR. The performance of these studies still needs more improvement to produce a reliable smartphone-based HAR. Thus, in this paper, we propose a deep convolution neural network model that provides a robust position-independent HAR system. We build and evaluate the performance of the proposed model using the RealWorld HAR public dataset. We find that our deep learning proposed model increases the overall performance compared to the state-of-the-art traditional machine learning method from 84% to 88% for position-independent HAR. In addition, the position detection performance of our model improves superiorly from 89% to 98%. Finally, the recognition time of the proposed model is evaluated in order to validate the applicability of the model for real-time applications.","",""
9,"Natasa Kleanthous, A. Hussain, A. Mason, J. Sneddon, A. Shaw, P. Fergus, C. Chalmers, D. Al-Jumeily","Machine Learning Techniques for Classification of Livestock Behavior",2018,"","","","",181,"2022-07-13 10:07:14","","10.1007/978-3-030-04212-7_26","","",,,,,9,2.25,1,8,4,"","",""
19,"C. Cai, M. Linnenluecke, M. Marrone, Abhay K. Singh","Machine Learning and Expert Judgement: Analyzing Emerging Topics in Accounting and Finance Research in the Asia–Pacific",2019,"","","","",182,"2022-07-13 10:07:14","","10.1111/abac.12179","","",,,,,19,6.33,5,4,3,"In this paper, we focus on the question to what extent machine learning (ML) tools can be used to support systematic literature reviews. We apply a ML approach for topic detection to analyze emerging topics in the literature—our context is accounting and finance research in the Asia–Pacific region. To evaluate the robustness of the approach, we compare findings from the automated ML approach with the results from a manual analysis of the literature. The automated approach uses a keyword algorithm detection mechanism whereby the manual analysis uses common techniques for qualitative data analysis, that is, triangulation between researchers (expert judgement). From our paper, we conclude that both methods have strengths and weaknesses. The automated analysis works well for large corpora of text and provides a very standardized and non‐biased way of analyzing the literature. However, the human researcher is potentially better equipped to evaluate current issues and future trends in the literature. Overall, the best results might be achieved when a variety of tools are used together. [ABSTRACT FROM AUTHOR]","",""
29,"Violeta Mirchevska, M. Luštrek, M. Gams","Combining domain knowledge and machine learning for robust fall detection",2014,"","","","",183,"2022-07-13 10:07:14","","10.1111/exsy.12019","","",,,,,29,3.63,10,3,8,"This paper presents a method for combining domain knowledge and machine learning (CDKML) for classifier generation and online adaptation. The method exploits advantages in domain knowledge and machine learning as complementary information sources. Whereas machine learning may discover patterns in interest domains that are too subtle for humans to detect, domain knowledge may contain information on a domain not present in the available domain dataset. CDKML has three steps. First, prior domain knowledge is enriched with relevant patterns obtained by machine learning to create an initial classifier. Second, genetic algorithms refine the classifier. Third, the classifier is adapted online on the basis of user feedback using the Markov decision process. CDKML was applied in fall detection. Tests showed that the classifiers developed by CDKML have better performance than machine‐learning classifiers generated on a training dataset that does not adequately represent all real‐life cases of the learned concept. The accuracy of the initial classifier was 10 percentage points higher than the best machine‐learning classifier and the refinement added 3 percentage points. The online adaptation improved the accuracy of the refined classifier by an additional 15 percentage points.","",""
12,"Kristoffer Hougaard Madsen, L. Krohne, Xin-Lu Cai, Yi Wang, R. Chan","Perspectives on Machine Learning for Classification of Schizotypy Using fMRI Data.",2018,"","","","",184,"2022-07-13 10:07:14","","10.1093/schbul/sby026","","",,,,,12,3.00,2,5,4,"Functional magnetic resonance imaging is capable of estimating functional activation and connectivity in the human brain, and lately there has been increased interest in the use of these functional modalities combined with machine learning for identification of psychiatric traits. While these methods bear great potential for early diagnosis and better understanding of disease processes, there are wide ranges of processing choices and pitfalls that may severely hamper interpretation and generalization performance unless carefully considered. In this perspective article, we aim to motivate the use of machine learning schizotypy research. To this end, we describe common data processing steps while commenting on best practices and procedures. First, we introduce the important role of schizotypy to motivate the importance of reliable classification, and summarize existing machine learning literature on schizotypy. Then, we describe procedures for extraction of features based on fMRI data, including statistical parametric mapping, parcellation, complex network analysis, and decomposition methods, as well as classification with a special focus on support vector classification and deep learning. We provide more detailed descriptions and software as supplementary material. Finally, we present current challenges in machine learning for classification of schizotypy and comment on future trends and perspectives.","",""
117,"Xiao Chen, Chaoran Li, Derui Wang, S. Wen, Jun Zhang, S. Nepal, Yang Xiang, K. Ren","Android HIV: A Study of Repackaging Malware for Evading Machine-Learning Detection",2018,"","","","",185,"2022-07-13 10:07:14","","10.1109/TIFS.2019.2932228","","",,,,,117,29.25,15,8,4,"Machine learning-based solutions have been successfully employed for the automatic detection of malware on Android. However, machine learning models lack robustness to adversarial examples, which are crafted by adding carefully chosen perturbations to the normal inputs. So far, the adversarial examples can only deceive detectors that rely on syntactic features (e.g., requested permissions, API calls, etc.), and the perturbations can only be implemented by simply modifying application’s manifest. While recent Android malware detectors rely more on semantic features from Dalvik bytecode rather than manifest, existing attacking/defending methods are no longer effective. In this paper, we introduce a new attacking method that generates adversarial examples of Android malware and evades being detected by the current models. To this end, we propose a method of applying optimal perturbations onto Android APK that can successfully deceive the machine learning detectors. We develop an automated tool to generate the adversarial examples without human intervention. In contrast to existing works, the adversarial examples crafted by our method can also deceive recent machine learning-based detectors that rely on semantic features such as control-flow-graph. The perturbations can also be implemented directly onto APK’s Dalvik bytecode rather than Android manifest to evade from recent detectors. We demonstrate our attack on two state-of-the-art Android malware detection schemes, MaMaDroid and Drebin. Our results show that the malware detection rates decreased from 96% to 0% in MaMaDroid, and from 97% to 0% in Drebin, with just a small number of codes to be inserted into the APK.","",""
45,"Geir Thore Berge, Ole-Christoffer Granmo, T. Tveit, Morten Goodwin, Lei Jiao, B. Matheussen","Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization With Medical Applications",2018,"","","","",186,"2022-07-13 10:07:14","","10.1109/ACCESS.2019.2935416","","",,,,,45,11.25,8,6,4,"Medical applications challenge today’s text categorization techniques by demanding both high accuracy and ease-of-interpretation. Although deep learning has provided a leap forward in regard to accuracy, this leap comes at the sacrifice of interpretability. In this paper, we introduce a text categorization approach that leverages the recently introduced Tsetlin Machine to address this accuracy-interpretability challenge. Briefly, we represent the terms of a text as propositional variables. From these variables, we capture categories using simple propositional formulae, such as: IF “rash” AND “reaction” AND “penicillin” THEN Allergy. The Tsetlin Machine learns these formulae from labeled text, utilizing conjunctive clauses to represent the particular facets of each category. Therefore, also the absence of terms (negated features) can be used for categorization purposes. Our empirical comparisons with Naïve Bayes classifiers, decision trees, linear support vector machines (SVMs), random forest, long short-term memory (LSTM) neural networks, and other techniques, are quite conclusive. Using relatively simple propositional formulae, the accuracy of the Tsetlin Machine either outperforms or performs approximately on par with the best evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a clinical dataset containing authentic electronic health records (EHRs). On average, the Tsetlin Machine delivers the best recall and precision scores across the datasets. The main merit of the proposed approach is thus its capacity for producing human-interpretable rules, while at the same time achieving acceptable accuracy. We believe that our novel approach can have a significant impact on a wide range of text analysis applications, providing a promising starting point for deeper natural language understanding with the Tsetlin Machine.","",""
24,"Patrick Nalepka, M. Lamb, Rachel W. Kallen, K. Shockley, A. Chemero, E. Saltzman, M. Richardson","Human social motor solutions for human–machine interaction in dynamical task contexts",2019,"","","","",187,"2022-07-13 10:07:14","","10.1073/pnas.1813164116","","",,,,,24,8.00,3,7,3,"Significance Human–machine interaction (HMI) is becoming ubiquitous within today’s society due to rapid advances in interactive virtual and robotic technologies. Ensuring the real-time coordination necessary for effective HMI, however, requires both identifying the dynamics of natural human multiagent performance and formally modeling those dynamics in ways that can be incorporated into the control structure of artificial agents. Here, we used a dyadic shepherding task to demonstrate that the dynamics of complex human multiagent activity cannot only be effectively modeled by means of simple, environmentally coupled dynamical motor primitives but that such models can be easily incorporated into the control structure of artificial agents to achieve robust, human-level HMI performance. Multiagent activity is commonplace in everyday life and can improve the behavioral efficiency of task performance and learning. Thus, augmenting social contexts with the use of interactive virtual and robotic agents is of great interest across health, sport, and industry domains. However, the effectiveness of human–machine interaction (HMI) to effectively train humans for future social encounters depends on the ability of artificial agents to respond to human coactors in a natural, human-like manner. One way to achieve effective HMI is by developing dynamical models utilizing dynamical motor primitives (DMPs) of human multiagent coordination that not only capture the behavioral dynamics of successful human performance but also, provide a tractable control architecture for computerized agents. Previous research has demonstrated how DMPs can successfully capture human-like dynamics of simple nonsocial, single-actor movements. However, it is unclear whether DMPs can be used to model more complex multiagent task scenarios. This study tested this human-centered approach to HMI using a complex dyadic shepherding task, in which pairs of coacting agents had to work together to corral and contain small herds of virtual sheep. Human–human and human–artificial agent dyads were tested across two different task contexts. The results revealed (i) that the performance of human–human dyads was equivalent to those composed of a human and the artificial agent and (ii) that, using a “Turing-like” methodology, most participants in the HMI condition were unaware that they were working alongside an artificial agent, further validating the isomorphism of human and artificial agent behavior.","",""
16,"Phil Legg, Jim E. Smith, A. Downing","Visual analytics for collaborative human-machine confidence in human-centric active learning tasks",2019,"","","","",188,"2022-07-13 10:07:14","","10.1186/s13673-019-0167-8","","",,,,,16,5.33,5,3,3,"","",""
31,"Amirata Ghorbani, David Ouyang, Abubakar Abid, B. He, Jonathan H. Chen, R. Harrington, D. Liang, E. Ashley, James Y. Zou","Deep learning interpretation of echocardiograms",2020,"","","","",189,"2022-07-13 10:07:14","","10.1038/s41746-019-0216-8","","",,,,,31,15.50,3,9,2,"","",""
8,"Ruichuan Zhang, N. El-Gohary","A Machine Learning Approach for Compliance Checking-Specific Semantic Role Labeling of Building Code Sentences",2018,"","","","",190,"2022-07-13 10:07:14","","10.1007/978-3-030-00220-6_67","","",,,,,8,2.00,4,2,4,"","",""
11,"J. Halotel, V. Demyanov, A. Gardiner","Value of Geologically Derived Features in Machine Learning Facies Classification",2019,"","","","",191,"2022-07-13 10:07:14","","10.1007/s11004-019-09838-0","","",,,,,11,3.67,4,3,3,"","",""
7,"M. Asiedu, Anish K. Simhal, Christopher T Lam, Jenna L. Mueller, Usamah N. Chaudhary, J. W. Schmitt, G. Sapiro, N. Ramanujam","Image processing and machine learning techniques to automate diagnosis of Lugol's iodine cervigrams for a low-cost point-of-care digital colposcope",2018,"","","","",192,"2022-07-13 10:07:14","","10.1117/12.2282792","","",,,,,7,1.75,1,8,4,"The world health organization recommends visual inspection with acetic acid (VIA) and/or Lugol’s Iodine (VILI) for cervical cancer screening in low-resource settings. Human interpretation of diagnostic indicators for visual inspection is qualitative, subjective, and has high inter-observer discordance, which could lead both to adverse outcomes for the patient and unnecessary follow-ups. In this work, we a simple method for automatic feature extraction and classification for Lugol’s Iodine cervigrams acquired with a low-cost, miniature, digital colposcope. Algorithms to preprocess expert physician-labelled cervigrams and to extract simple but powerful color-based features are introduced. The features are used to train a support vector machine model to classify cervigrams based on expert physician labels. The selected framework achieved a sensitivity, specificity, and accuracy of 89.2%, 66.7% and 80.6% with majority diagnosis of the expert physicians in discriminating cervical intraepithelial neoplasia (CIN +) relative to normal tissues. The proposed classifier also achieved an area under the curve of 84 when trained with majority diagnosis of the expert physicians. The results suggest that utilizing simple color-based features may enable unbiased automation of VILI cervigrams, opening the door to a full system of low-cost data acquisition complemented with automatic interpretation.","",""
9,"Brendon Lutnick, B. Ginley, D. Govind, S. McGarry, P. LaViolette, R. Yacoub, Sanjay Jain, J. Tomaszewski, K. Jen, P. Sarder","Iterative annotation to ease neural network training: Specialized machine learning in medical image analysis",2018,"","","","",193,"2022-07-13 10:07:14","","10.1038/s42256-019-0018-3","","",,,,,9,2.25,1,10,4,"","",""
12,"Andrew Pilny, Kelly G. McAninch, A. Slone, Kelsey P. Moore","Using Supervised Machine Learning in Automated Content Analysis: An Example Using Relational Uncertainty",2019,"","","","",194,"2022-07-13 10:07:14","","10.1080/19312458.2019.1650166","","",,,,,12,4.00,3,4,3,"ABSTRACT The goal of this research is to make progress towards using supervised machine learning for automated content analysis dealing with complex interpretations of text. For Step 1, two humans coded a sub-sample of online forum posts for relational uncertainty. For Step 2, we evaluated reliability, in which we trained three different classifiers to learn from those subjective human interpretations. Reliability was established when two different metrics of inter-coder reliability could not distinguish whether a human or a machine coded the text on a separate hold-out set. Finally, in Step 3 we assessed validity. To accomplish this, we administered a survey in which participants described their own relational uncertainty/certainty via text and completed a questionnaire. After classifying the text, the machine’s classifications of the participants’ text positively correlated with the subjects’ own self-reported relational uncertainty and relational satisfaction. We discuss our results in line with areas of computational communication science, content analysis, and interpersonal communication.","",""
21,"M. Yazdani, Bryn C. Taylor, Justine W. Debelius, Weizhong Li, R. Knight, L. Smarr","Using machine learning to identify major shifts in human gut microbiome protein family abundance in disease",2016,"","","","",195,"2022-07-13 10:07:14","","10.1109/BIGDATA.2016.7840731","","",,,,,21,3.50,4,6,6,"Inflammatory Bowel Disease (IBD) is an autoimmune condition that is observed to be associated with major alterations in the gut microbiome taxonomic composition. Here we classify major changes in microbiome protein family abundances between healthy subjects and IBD patients. We use machine learning to analyze results obtained previously from computing relative abundance of ∼10,000 KEGG orthologous protein families in the gut microbiome of a set of healthy individuals and IBD patients. We develop a machine learning pipeline, involving the Kolomogorv-Smirnov test, to identify the 100 most statistically significant entries in the KEGG database. Then we use these 100 as a training set for a Random Forest classifier to determine ∼5% the KEGGs which are best at separating disease and healthy states. Lastly, we developed a Natural Language Processing classifier of the KEGG description files to predict KEGG relative over-or under-abundance. As we expand our analysis from 10,000 KEGG protein families to one million proteins identified in the gut microbiome, scalable methods for quickly identifying such anomalies between health and disease states will be increasingly valuable for biological interpretation of sequence data.","",""
13,"Nicholas Carlini, Ú. Erlingsson, Nicolas Papernot","Distribution Density, Tails, and Outliers in Machine Learning: Metrics and Applications",2019,"","","","",196,"2022-07-13 10:07:14","","","","",,,,,13,4.33,4,3,3,"We develop techniques to quantify the degree to which a given (training or testing) example is an outlier in the underlying distribution. We evaluate five methods to score examples in a dataset by how well-represented the examples are, for different plausible definitions of ""well-represented"", and apply these to four common datasets: MNIST, Fashion-MNIST, CIFAR-10, and ImageNet. Despite being independent approaches, we find all five are highly correlated, suggesting that the notion of being well-represented can be quantified. Among other uses, we find these methods can be combined to identify (a) prototypical examples (that match human expectations); (b) memorized training examples; and, (c) uncommon submodes of the dataset. Further, we show how we can utilize our metrics to determine an improved ordering for curriculum learning, and impact adversarial robustness. We release all metric values on training and test sets we studied.","",""
37,"B. Pham, A. Jaafari, Mohammadtaghi Avand, N. Al‐Ansari, Tran Dinh Du, H. Yen, T. Phong, D. H. Nguyen, H. V. Le, D. Gholami, Indra Prakash, Hoang Thi Thuy, T. T. Tuyen","Performance Evaluation of Machine Learning Methods for Forest Fire Modeling and Prediction",2020,"","","","",197,"2022-07-13 10:07:14","","10.3390/sym12061022","","",,,,,37,18.50,4,13,2,"Predicting and mapping fire susceptibility is a top research priority in fire-prone forests worldwide. This study evaluates the abilities of the Bayes Network (BN), Naive Bayes (NB), Decision Tree (DT), and Multivariate Logistic Regression (MLP) machine learning methods for the prediction and mapping fire susceptibility across the Pu Mat National Park, Nghe An Province, Vietnam. The modeling methodology was formulated based on processing the information from the 57 historical fires and a set of nine spatially explicit explanatory variables, namely elevation, slope degree, aspect, average annual temperate, drought index, river density, land cover, and distance from roads and residential areas. Using the area under the receiver operating characteristic curve (AUC) and seven other performance metrics, the models were validated in terms of their abilities to elucidate the general fire behaviors in the Pu Mat National Park and to predict future fires. Despite a few differences between the AUC values, the BN model with an AUC value of 0.96 was dominant over the other models in predicting future fires. The second best was the DT model (AUC = 0.94), followed by the NB (AUC = 0.939), and MLR (AUC = 0.937) models. Our robust analysis demonstrated that these models are sufficiently robust in response to the training and validation datasets change. Further, the results revealed that moderate to high levels of fire susceptibilities are associated with ~19% of the Pu Mat National Park where human activities are numerous. This study and the resultant susceptibility maps provide a basis for developing more efficient fire-fighting strategies and reorganizing policies in favor of sustainable management of forest resources.","",""
148,"Ken Kubota, Jason A. Chen, M. Little","Machine learning for large‐scale wearable sensor data in Parkinson's disease: Concepts, promises, pitfalls, and futures",2016,"","","","",198,"2022-07-13 10:07:14","","10.1002/mds.26693","","",,,,,148,24.67,49,3,6,"For the treatment and monitoring of Parkinson's disease (PD) to be scientific, a key requirement is that measurement of disease stages and severity is quantitative, reliable, and repeatable. The last 50 years in PD research have been dominated by qualitative, subjective ratings obtained by human interpretation of the presentation of disease signs and symptoms at clinical visits. More recently, “wearable,” sensor‐based, quantitative, objective, and easy‐to‐use systems for quantifying PD signs for large numbers of participants over extended durations have been developed. This technology has the potential to significantly improve both clinical diagnosis and management in PD and the conduct of clinical studies. However, the large‐scale, high‐dimensional character of the data captured by these wearable sensors requires sophisticated signal processing and machine‐learning algorithms to transform it into scientifically and clinically meaningful information. Such algorithms that “learn” from data have shown remarkable success in making accurate predictions for complex problems in which human skill has been required to date, but they are challenging to evaluate and apply without a basic understanding of the underlying logic on which they are based. This article contains a nontechnical tutorial review of relevant machine‐learning algorithms, also describing their limitations and how these can be overcome. It discusses implications of this technology and a practical road map for realizing the full potential of this technology in PD research and practice. © 2016 International Parkinson and Movement Disorder Society","",""
32,"Baifeng Shi, Dinghuai Zhang, Qi Dai, Zhanxing Zhu, Yadong Mu, Jingdong Wang","Informative Dropout for Robust Representation Learning: A Shape-bias Perspective",2020,"","","","",199,"2022-07-13 10:07:14","","","","",,,,,32,16.00,5,6,2,"Convolutional Neural Networks (CNNs) are known to rely more on local texture rather than global shape when making decisions. Recent work also indicates a close relationship between CNN's texture-bias and its robustness against distribution shift, adversarial perturbation, random corruption, etc. In this work, we attempt at improving various kinds of robustness universally by alleviating CNN's texture bias. With inspiration from the human visual system, we propose a light-weight model-agnostic method, namely Informative Dropout (InfoDrop), to improve interpretability and reduce texture bias. Specifically, we discriminate texture from shape based on local self-information in an image, and adopt a Dropout-like algorithm to decorrelate the model output from the local texture. Through extensive experiments, we observe enhanced robustness under various scenarios (domain generalization, few-shot classification, image corruption, and adversarial perturbation). To the best of our knowledge, this work is one of the earliest attempts to improve different kinds of robustness in a unified model, shedding new light on the relationship between shape-bias and robustness, also on new approaches to trustworthy machine learning algorithms. Code is available at this https URL.","",""
8,"Amirmasoud Ghiassi, Taraneh Younesian, Zilong Zhao, R. Birke, V. Schiavoni, L. Chen","Robust (Deep) Learning Framework Against Dirty Labels and Beyond",2019,"","","","",200,"2022-07-13 10:07:14","","10.1109/TPS-ISA48467.2019.00038","","",,,,,8,2.67,1,6,3,"Data is generated with unprecedented speed, due to the flourishing of social media and open platforms. However, due to the lack of scrutinizing, both clean and dirty data are widely spreaded. For instance, there is a significant portion of images tagged with corrupted dirty class labels. Such dirty data sets are not only detrimental to the learning outcomes, e.g., misclassified images into the wrong classes, but also costly. It is pointed out that bad data can cost the U.S. up to a daunting 3 trillion dollars per year. In this paper, we address the following question: how prevailing (deep) machine learning models can be robustly trained given a non-negligible presence of corrupted labeled data. Dirty labels significantly increase the complexity of existing learning problems, as the ground truth of label’s quality are not easily assessed. Here, we advocate to rigorously incorporate human experts into one learning framework where both artificial and human intelligence collaborate. To such an end, we combine three strategies to enhance the robustness for deep and regular machine learning algorithms, namely, (i) data filtering through additional quality model, (ii) data selection via actively learning from expert, and (iii) imitating expert’s correction process. We demonstrate three strategies sequentially with examples and apply them on widely used benchmarks, such as CIFAR10 and CIFAR100. Our initial results show the effectiveness of the proposed strategies in combating dirty labels, e.g., the resulting classification can be up to 50% higher than the state-of-the-art AI-only solutions. Finally, we extend the discussion of robust learning from the trusted data to the trusted execution environment.","",""
