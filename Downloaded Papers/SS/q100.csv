Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",1,"2022-07-13 09:36:21","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",2,"2022-07-13 09:36:21","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
0,"C. Hamel, Mona Hersi, S. Kelly, A. Tricco, S. Straus, G. Wells, B. Pham, B. Hutton","Guidance for using artificial intelligence for title and abstract screening while conducting knowledge syntheses",2021,"","","","",3,"2022-07-13 09:36:21","","10.1186/s12874-021-01451-2","","",,,,,0,0.00,0,8,1,"","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",4,"2022-07-13 09:36:21","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
1,"O. Jenkins, D. Lopresti, M. Mitchell","Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",2020,"","","","",5,"2022-07-13 09:36:21","","","","",,,,,1,0.50,0,3,2,"The history of AI has included several ""waves"" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called ""expert systems"". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed ""statistical learning algorithms"" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by ""deep learning"" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors.  A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.","",""
0,"Khadijeh Karamzadeh, H. Moharrami","Survey of robust artificial intelligence classifier proper for various digital data",2015,"","","","",6,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,2,7,"Artificial intelligence or machine intelligence should be considered as the vast domain of junction of many knowledge, sciences and old and new technics. Today, classification of documents is adopted extensively in information recovery for organizing documents. In the method of document supervised classification some correct information about documents that previously have been classified are available for us and based on these information we classify these documents. Thus, we will examine methods such as: expert systems, artificial neural network, Genetic algorithm and fuzzy logics and so on. In this project we examine documents thematically and then using existing algorithms we predict a theme for a new document.","",""
4,"Shubham Yadav, S. Ganesh, Debanjan Das, U. Venkanna, R. Mahapatra, A. Shrivastava, Prantar Chakrabarti, A. Talukder","Suśruta: Artificial Intelligence and Bayesian Knowledge Network in Health Care - Smartphone Apps for Diagnosis and Differentiation of Anemias with Higher Accuracy at Resource Constrained Point-of-Care Settings",2019,"","","","",7,"2022-07-13 09:36:21","","10.1007/978-3-030-37188-3_10","","",,,,,4,1.33,1,8,3,"","",""
5,"Ayodeji Oseni, Nour Moustafa, H. Janicke, Peng Liu, Z. Tari, A. Vasilakos","Security and Privacy for Artificial Intelligence: Opportunities and Challenges",2021,"","","","",8,"2022-07-13 09:36:21","","","","",,,,,5,5.00,1,6,1,"The increased adoption of Artificial Intelligence (AI) presents an opportunity to solve many socio-economic and environmental challenges; however, this cannot happen without securing AI-enabled technologies. In recent years, most AI models are vulnerable to advanced and sophisticated hacking techniques. This challenge has motivated concerted research efforts into adversarial AI, with the aim of developing robust machine and deep learning models that are resilient to different types of adversarial scenarios. In this paper, we present a holistic cyber security review that demonstrates adversarial attacks against AI applications, including aspects such as adversarial knowledge and capabilities, as well as existing methods for generating adversarial examples and existing cyber defence models. We explain mathematical AI models, especially new variants of reinforcement and federated learning, to demonstrate how attack vectors would exploit vulnerabilities of AI models. We also propose a systematic framework for demonstrating attack techniques against AI applications, and reviewed several cyber defences that would protect the AI applications against those attacks. We also highlight the importance of understanding the adversarial goals and their capabilities, especially the recent attacks against industry applications, to develop adaptive defences that assess to secure AI applications. Finally, we describe the main challenges and future research directions in the domain of security and privacy of AI technologies.","",""
18,"J. Hellwig, Sarah Huggett, Mark Siebert","Data for report ""Artificial Intelligence: How knowledge is created, transferred, and used""",2019,"","","","",9,"2022-07-13 09:36:21","","10.17632/7YDFS62GD6.2","","",,,,,18,6.00,6,3,3,"The growing importance and relevance of artificial intelligence (AI) to humanity is undisputed. However, AI does not seem to have a universally agreed definition, and different sectors of society use very different vocabulary to describe AI. Using AI to define AI, we were able to detect the relevant body of research, further structure it in sub-fields, and give a comprehensive overview of the research landscape.    There are strong regional differences in AI activity:  • China aspires to lead globally in AI and focuses on computer vision. It shows a rapid rise in scholarly output and citation impact. A net brain gain of AI researchers to China also suggests an attractive research environment.  • Europe is the largest producer of AI scholarly output, but appears to be losing academic AI talent. The broad spectrum of AI research in Europe reflects the diversity of European countries, each with their own agenda and specialties.  • AI research in the United States is robust, both in terms of scholarly output and talent retention. The US benefits from a strong corporate sector. The corpus shows less diversity in AI research than Europe but more than China.    A key area of further development in AI research worldwide is on ethical issues pertaining to AI. While a major topic in daily conversation, there is surprisingly little formal research published on AI ethics to date. We believe there is a need for more AI ethics research, which would bring many benefits to the field, its development, and its applications.","",""
0,"Canan Tiftik","Investigation of Human Resources Dimension in Management and Organization Structure of the Effects of Artificial Intelligence",2021,"","","","",10,"2022-07-13 09:36:21","","10.21733/IBAD.833256","","",,,,,0,0.00,0,1,1,"In the competitive time, there has been a great deal of progress in the industry. It is one of the most serious obstacles to the industry in many industries that adopt contemporary technologies to manage continuous development and faster than ordinary jobs. Many of the scientists and researchers recommend using AI tools and digital technologies for industries. Machine language and artificial intelligence are used by many organizations in the human resources unit, where it undertakes an integrated task in recruiting, performance analysis, personnel selection, data collection for employees, providing real-time information and obtaining the right information. Artificial intelligence-based Human Resources (HR) applications have a solid potential to increase employee productivity and support HR experts to become knowledge and trained consultants that increase the success of the employee. HR applications authorized by artificial intelligence have the ability to analyze, predict, diagnose and seek and find more robust and capable resources.","",""
0,"Chengbing Tan, Qun Chen","Application of an artificial intelligence algorithm model of memory retrieval and roaming in sorting Chinese medicinal materials",2021,"","","","",11,"2022-07-13 09:36:21","","10.3233/jcm-215477","","",,,,,0,0.00,0,2,1,"In order to capture autobiographical memory, inspired by the development of human intelligence, a computational AM model for autobiographical memory is proposed in this paper, which is a three-layer network structure, in which the bottom layer encodes the event-specific knowledge comprising 5W1H, and provides retrieval clues to the middle layer, encodes the related events, and the top layer encodes the event set. According to the bottom-up memory search process, the corresponding events and event sets can be identified in the middle layer and the top layer respectively; At the same time, AM model can simulate human memory roaming through the process of rule-based memory retrieval. The computational AM model proposed in this paper not only has robust and flexible memory retrieval, but also has better response performance to noisy memory retrieval cues than the commonly used memory retrieval model based on keyword query method, and can also imitate the roaming phenomenon in memory.","",""
0,"Poona Bahrebar, Leon Denis, Maxim Bonnaerens, Kristof Coddens, J. Dambre, W. Favoreel, I. Khvastunov, A. Munteanu, Hung Nguyen-Duc, S. Schulte, D. Stroobandt, Ramses Valvekens, N. V. D. Broeck, Geert Verbruggen","cREAtIve: reconfigurable embedded artificial intelligence",2021,"","","","",12,"2022-07-13 09:36:21","","10.1145/3457388.3458857","","",,,,,0,0.00,0,14,1,"cREAtIve targets the development of novel highly-adaptable embedded deep learning solutions for automotive and traffic monitoring applications, including position sensor processing, scene interpretation based on LiDAR, and object detection and classification in thermal images for traffic camera systems. These applications share the need for deep learning solutions tailored for deployment on embedded devices with limited resources and featuring high adaptability and robustness to changing environmental conditions. cREAtIve develops knowledge, tools and methods that enable hardware-efficient, adaptable, and robust deep learning.","",""
9,"Kuansong Wang, Gang Yu, Chao Xu, Xiang-He Meng, Jian-hua Zhou, C. Zheng, Z. Deng, L. Shang, Ruijie Liu, S. Su, Xunjian Zhou, Qingling Li, Juanni Li, Jing Wang, K. Ma, J. Qi, Zhenmin Hu, P. Tang, Jeffrey Deng, X. Qiu, Bo Li, W. Shen, R. Quan, Juntao Yang, Lin Huang, Yao Xiao, Zhichun Yang, Zhongming Li, Shengchun Wang, Hongzheng Ren, C. Liang, Wei Guo, Yanchun Li, Heng Xiao, Yong-hong Gu, J. Yun, Dan Huang, Zhigang Song, Xiangshan Fan, Ling Chen, Xiaochu Yan, Zhi Li, Zhongjun Huang, Jufang Huang, Joseph Luttrell, Chaoyang Zhang, Weihua Zhou, Kun Zhang, C. Yi, Hui Shen","Accurate diagnosis of colorectal cancer based on histopathology images using artificial intelligence",2020,"","","","",13,"2022-07-13 09:36:21","","10.1186/s12916-021-01942-5","","",,,,,9,4.50,1,50,2,"","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",14,"2022-07-13 09:36:21","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
6,"Óscar Álvarez-Machancoses, Enrique J DeAndrés Galiana, A. Cernea, J. Fernández de la Viña, J. Fernández-Martínez","On the Role of Artificial Intelligence in Genomics to Enhance Precision Medicine",2020,"","","","",15,"2022-07-13 09:36:21","","10.2147/PGPM.S205082","","",,,,,6,3.00,1,5,2,"Abstract The complexity of orphan diseases, which are those that do not have an effective treatment, together with the high dimensionality of the genetic data used for their analysis and the high degree of uncertainty in the understanding of the mechanisms and genetic pathways which are involved in their development, motivate the use of advanced techniques of artificial intelligence and in-depth knowledge of molecular biology, which is crucial in order to find plausible solutions in drug design, including drug repositioning. Particularly, we show that the use of robust deep sampling methodologies of the altered genetics serves to obtain meaningful results and dramatically decreases the cost of research and development in drug design, influencing very positively the use of precision medicine and the outcomes in patients. The target-centric approach and the use of strong prior hypotheses that are not matched against reality (disease genetic data) are undoubtedly the cause of the high number of drug design failures and attrition rates. Sampling and prediction under uncertain conditions cannot be avoided in the development of precision medicine.","",""
1,"A. Zarzeczny, P. Babyn, S. Adams, Justin Longo","Artificial intelligence-based imaging analytics and lung cancer diagnostics: Considerations for health system leaders",2020,"","","","",16,"2022-07-13 09:36:21","","10.1177/0840470420975062","","",,,,,1,0.50,0,4,2,"Lung cancer is a leading cause of cancer death in Canada, and accurate, early diagnosis are critical to improving clinical outcomes. Artificial Intelligence (AI)-based imaging analytics are a promising healthcare innovation that aim to improve the accuracy and efficiency of lung cancer diagnosis. Maximizing their clinical potential while mitigating their risks and limitations will require focused leadership informed by interdisciplinary expertise and system-wide insight. We convened a knowledge exchange workshop with diverse Saskatchewan health system leaders and stakeholders to explore issues surrounding the use of AI in diagnostic imaging for lung cancer, including implementation opportunities, challenges, and priorities. This technology is anticipated to improve patient outcomes, reduce unnecessary healthcare spending, and increase knowledge. However, health system leaders must also address the needs for robust data, financial investment, effective communication and collaboration between healthcare sectors, privacy and data protections, and continued interdisciplinary research to achieve this technology’s potential benefits.","",""
1,"Alicia Lai","Artificial Intelligence, LLC: Corporate Personhood as Tort Reform",2020,"","","","",17,"2022-07-13 09:36:21","","10.2139/ssrn.3677360","","",,,,,1,0.50,1,1,2,"Our legal system has long tried to fit the square peg of artificial intelligence (AI) technologies into the round hole of the current tort regime, overlooking the inability of traditional liability schemes to address the nuances of how AI technology creates harms. The current tort regime deals out rough justice—using strict liability for some AI products and using the negligence rule for other AI services—both of which are insufficiently tailored to achieve public policy objectives.    Under a strict liability regime where manufacturers are always held liable for the faults of their technology regardless of knowledge or precautionary measures, firms are incentivized to play it safe and stifle innovation. But even with this cautionary stance, the goals of strict liability cannot be met due to the unique nature of AI technology: its mistakes are merely “efficient errors”—they appropriately surpass the human baseline, they are game theory problems intended for a jury, they are necessary to train a robust system, or they are harmless but misclassified.    Under a negligence liability regime where the onus falls entirely on consumers to prove the element of causation, victimized consumers are left without sufficient recourse or compensation. Many critiques have been leveled against the “black-box” nature of algorithms.    This paper proposes a new framework to regulate artificial intelligence technologies: bestowing corporate personhood to AI systems. First, the corporate personality trait of “limited liability” strikes an optimal balance in determining liability—it would both compensate victims (for instance, through obligations to carry insurance and a straightforward burden of causation) while holding manufacturers responsible only when the infraction is egregious (for instance, through veil-piercing). Second, corporate personhood is “divisible”—meaning not all corporate personality traits need to be granted—which circumvents many of the philosophical criticisms of giving AI the complete set of rights of full legal personhood.","",""
0,"S. Prusty, U. K. Jena, Sidhanta Kumar Balabantaray","APPLICATION OF ARTIFICIAL INTELLIGENCE IN FUZZY LOGIC FOR CROP MANAGEMENT IN AGRICULTURE",2020,"","","","",18,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,3,2,"This paper provides a systematic implementation of th e techniques of artificial intelligence for agricultural crop man agement. Agriculture faces many challenges, such as disease a nd infestation of pests, unsuitable soil treatment, inadequate dr ainage and irrigation and many more. Such result in severe crop failure along with environmental hazards caused by excessive chemical use. Several researches were carried out to deal with these issues. With its robust learning capabilities, the fields of artificial intelligence have become a crucial technique for solving various agricultural related problems. Systems are being developed to assist the agricultural experts around the world in finding better solutions. The sector faces numerous challenges to optimize its production, including inadequate soil care, disease and infestation of pests, big data requirements, low output and knowledge gap between farmers and","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",19,"2022-07-13 09:36:21","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",20,"2022-07-13 09:36:21","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
0,"J. Blay, Jurgi Camblong, F. Sigaux","Artificial Intelligence Applied to Oncology",2020,"","","","",21,"2022-07-13 09:36:21","","10.1007/978-3-030-32161-1_24","","",,,,,0,0.00,0,3,2,"","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",22,"2022-07-13 09:36:21","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",23,"2022-07-13 09:36:21","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
1,"Sonal Modak, D. Sehgal, J. Valadi","Applications of Artificial Intelligence and Machine Learning in Viral Biology",2019,"","","","",24,"2022-07-13 09:36:21","","10.1007/978-3-030-29022-1_1","","",,,,,1,0.33,0,3,3,"","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",25,"2022-07-13 09:36:21","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
0,"Chris Yang","Explainable Artificial Intelligence for Predictive Modeling in Healthcare",2022,"","","","",26,"2022-07-13 09:36:21","","10.1007/s41666-022-00114-1","","",,,,,0,0.00,0,1,1,"","",""
0,"Bukhoree Sahoh, Kanjana Haruehansapong, Mallika Kliangkhlao","Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model",2022,"","","","",27,"2022-07-13 09:36:21","","10.1109/access.2022.3155118","","",,,,,0,0.00,0,3,1,"A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.","",""
0,"D. Lange","Robustness of artificial intelligence in the face of novelty",2022,"","","","",28,"2022-07-13 09:36:21","","10.1117/12.2622912","","",,,,,0,0.00,0,1,1,"A critical factor in utilizing agents with Artificial Intelligence (AI) is their robustness to novelty. AI agents include models that are either engineered or trained. Engineered models include knowledge of those aspects of the environment that are known and considered important by the engineers. Learned models form embeddings of aspects of the environment based on connections made through the training data. In operation, however, a rich environment is likely to present challenges not seen in training sets or accounted for in engineered models. Worse still, adversarial environments are subject to change by opponents. A program at the Defense Advanced Research Project Agency (DARPA) seeks to develop the science necessary to develop and evaluate agents that are robust to novelty. This capability will be required, before AI has the role envisioned within mission critical environments.","",""
2,"M. Shahid, G. Abbas, Mohammad Rashid Hussain, M. Asad, U. Farooq, J. Gu, V. Balas, M. Uzair, A. Awan, T. Yazdan","Artificial Intelligence-Based Controller for DC-DC Flyback Converter",2019,"","","","",29,"2022-07-13 09:36:21","","10.3390/app9235108","","",,,,,2,0.67,0,10,3,"This paper presents an intelligent voltage controller designed on the basis of an adaptive neuro-fuzzy inference system (ANFIS) for a flyback converter (FC) working in continuous conduction mode (CCM). The union of fuzzy logic (FL) and adaptive neural networks (ANN) makes ANFIS more robust against model parameters’ uncertainties and perturbations in input voltage or load current. ANFIS inherits the advantages of structured knowledge representation from FL and learning capability from NN. Comparative analysis showed that the ANFIS controller offers not only the superior transient response characteristics, but also excellent steady-state characteristics compared to those of the FL controller (FLC) and proportional–integral–derivative (PID) controllers, thus validating its superiority over these traditional controllers. For this purpose, MATLAB/Simulink environment-based simulation results are presented for validation of the proposed converter compensated system under all operating conditions.","",""
0,"Yaxin Peng, S. Du, T. Zeng","Preface: Special Issue on Optimization Models and Algorithms in Artificial Intelligence",2019,"","","","",30,"2022-07-13 09:36:21","","10.1007/s40305-019-00278-5","","",,,,,0,0.00,0,3,3,"","",""
0,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","Sensible Artificial Intelligence that plays with handicap and targets high scores in 9 × 9",2019,"","","","",31,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
0,"Samiyuru Menik, Lakshmish Ramaswamy","Towards a Robust Knowledge Graph-Enabled Machine Learning Service Description Framework",2021,"","","","",32,"2022-07-13 09:36:21","","10.1109/ICSC50631.2021.00026","","",,,,,0,0.00,0,2,1,"Although machine learning (ML) is widely expected to become a key enabler of innovative applications in a number of important domains, building, deploying and managing robust ML pipelines for diverse domains are very challenging as they require expertise in both the application domain as well as the ML field. Recently, machine learning as a service (MLAAS) is being explored as a paradigm to address these challenges and to democratize artificial intelligence (AI). MLAAS envisions an ecosystem with powerful mechanisms for publishing, searching/discovering, composing and deploying ML models. This paper argues that a semantic-rich and flexible ML service description is indispensable for realizing such an ecosystem. Towards this end, we outline a unique approach that leverages knowledge graphs (KGs) for ML service description. A requirements study highlights the ML services aspects that need to be provisioned in the description framework. This paper presents a novel five-dimensional KG-enabled ML service description framework, which incorporates ML task description, Input-Output (I–O) description, ML-model description, dataset and training description and performance characteristics description. In designing this ML service description framework, we introduce several conceptual structures such as functional specifications with semantically-extended types and compound knowledge graphs for representing ML model architectures.","",""
0,"Zhaohan Xi, Ren Pang, Changjiang Li, S. Ji, Xiapu Luo, Xusheng Xiao, Ting Wang","Towards Robust Reasoning over Knowledge Graphs",2021,"","","","",33,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,7,1,"Answering complex logical queries over large-scale knowledge graphs (KGs) represents an important artificial intelligence task, entailing a range of applications. Recently, knowledge representation learning (KRL) has emerged as the stateof-the-art approach, wherein KG entities and the query are embedded into a latent space such that entities that answer the query are embedded close to the query. Yet, despite its surging popularity, the potential security risks of KRL are largely unexplored, which is concerning, given the increasing use of such capabilities in security-critical domains (e.g., cyber-security and healthcare). This work represents a solid initial step towards bridging this gap. We systematize the potential security threats to KRL according to the underlying attack vectors (e.g., knowledge poisoning and query perturbation) and the adversary’s background knowledge. More importantly, we present ROAR1, a new class of attacks that instantiate a variety of such threats. We demonstrate the practicality of ROAR in two representative use cases (i.e., cyber-threat hunting and drug repurposing). For instance, ROAR attains over 99% attack success rate in misleading the threat intelligence engine to give pre-defined answers for target queries, yet without any impact on nontarget ones. Further, we discuss potential countermeasures against ROAR, including filtering of poisoning facts and robust training with adversarial queries, which leads to several promising research directions.","",""
19,"P. Svenmarck, L. Luotsinen, Mattias Nilsson, J. Schubert","Possibilities and Challenges for Artificial Intelligence in Military Applications",2018,"","","","",34,"2022-07-13 09:36:21","","","","",,,,,19,4.75,5,4,4,"Recent developments in artificial intelligence (AI) have resulted in a breakthrough for many classical AIapplications, such as computer vision, natural language processing, robotics, and data mining. Therefore, there are many efforts to exploit these developments for military applications, such as surveillance, reconnaissance, threat evaluation, underwater mine warfare, cyber security, intelligence analysis, command and control, and education and training. However, despite the possibilities for AI in military applications, there are many challenges to consider. For instance, 1) high risks means that military AI-systems need to be transparent to gain decision maker trust and to facilitate risk analysis; this is a challenge since many AItechniques are black boxes that lack sufficient transparency, 2) military AI-systems need to be robust and reliable; this is a challenge since it has been shown that AI-techniques may be vulnerable to imperceptible manipulations of input data even without any knowledge about the AI-technique that is used, and 3) many AItechniques are based on machine learning that requires large amounts of training data; this is challenge since there is often a lack of sufficient data in military applications. This paper present results from ongoing projects to identity possibilities for AI in military applications, as well as how to address these challenges.","",""
15,"Yun-he Pan","Special issue on artificial intelligence 2.0",2017,"","","","",35,"2022-07-13 09:36:21","","10.1631/FITEE.1710000","","",,,,,15,3.00,15,1,5,"With the ever-growing popularization of the Internet, universal existence of sensors, emergence of big data, development of e-commerce, rise of the information community, and interconnection and fusion of data and knowledge in human society, physical space, and cyberspace, the information environment surrounding artificial intelligence (AI) development has changed profoundly, leading to a new evolutionary stage: AI 2.0. The emergence of new technologies also promotes AI to a new stage (Pan, 2016). The next-generation AI, namely AI 2.0, is a more explainable, robust, open, and general AI with the following attractive merits: It effectively integrates data-driven machine learning approaches (bottom-up) with knowledge-guided methods (top-down). In addition, it can employ data with different modalities (e.g., visual, auditory, and natural language processing) to perform cross-media learning and inference. Furthermore, there will be a step from the pursuit of an intelligent machine to the hybridaugmented intelligence (i.e., high-level man-machine collaboration and fusion). AI 2.0 will also promote crowd-based intelligence and autonomous-intelligent systems. In the next decades, AI2.0 will probably achieve remarkable progress in aforementioned trends, and therefore significantly change our cities, products, services, economics, environments, even how we advance our society. This special issue aims at reporting recent re-thinking of AI 2.0 from aforementioned aspects as well as practical methodologies, efficient implementations, and applications of AI 2.0. The papers in this special issue can be categorized into two groups. The first group consists of six review papers and the second group five research papers. In the first group, Zhuang et al. (2017) reviewed recent emerging theoretical and technological advances of AI in big data settings. The authors concluded that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI. Li W et al. (2017) described the concepts of crowd intelligence, and explained its relationship to the existing related concepts, e.g., crowdsourcing and human computation. In addition, the authors introduced four categories of representative crowd intelligence platforms. Peng et al. (2017) presented approaches, advances, and future directions in cross-media analysis and reasoning. This paper covers cross-media representation, mining, reasoning, and cross-media knowledge evolution. Tian et al. (2017) reviewed the state-of-the-art research of the perception in terms of visual perception, auditory perception, and speech perception. It also covered perceptual information processing and learning engines. Zhang et al. (2017) introduced the trends in the development of intelligent unmanned autonomous systems. It covered unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned Editorial: Frontiers of Information Technology & Electronic Engineering www.zju.edu.cn/jzus; engineering.cae.cn; www.springerlink.com ISSN 2095-9184 (print); ISSN 2095-9230 (online) E-mail: jzus@zju.edu.cn","",""
0,"Lucas B. Miguel, D. Takabayashi, Jose R. Pizani, Tiago Andrade, Brody West","Marvin - Open source artificial intelligence platform",2018,"","","","",36,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,5,4,"Marvin is an open source project that focuses on empowering data science teams to deliver industrial-grade applications supported by a high-scale, low-latency, language agnostic and standardized architecture platform, while simplifying the process of exploration and modeling. Building model-dependent applications in a robust way is not trivial, one is required to have knowledge in advanced areas of sciences like computing, statistics and math. Marvin aims at abstracting the complexities in the creation process of scalable, highly available, interoperable and maintainable predictive software.","",""
8,"P. Mittal, Y. Singh","Development of Intelligent Transportation System for Improving Average Moving and Waiting time with Artificial Intelligence",2016,"","","","",37,"2022-07-13 09:36:21","","10.17485/IJST/2016/V9I3/84156","","",,,,,8,1.33,4,2,6,"Background: Real time traffic control is an important tool of Intelligent Transportation System (ITS). The development of system for controlling the urban traffic dynamically provides not only the safety for traffic, but also saves the time, money and provides polluted free environment. This paper describes the development of dynamic and robust traffic management system based on fuzzy logic approach. Method: Knowledge based system have been extensively adopted as approach for real time decision making system. Findings: As the conventional dynamic controllers were used sensors which are having certain limitations, so these limitations can be overcome by vision sensors i.e. camera. Also image and vision computing plays an important role in monitoring and measuring the traffic density on road. Problems were identified with the current traffic control system at the intersection on road and this necessitated the design and implementation of a new system to solve the congestion problems. Improvements: The performance of the proposed framework is evaluated with LabVIEW and MATLAB test bed. The results of extensive simulations using the proposed approach indicate that the system improves the average moving time and decrease the average waiting time than the controllers with conventional sensors.","",""
20,"FarzinPiltan, MarziehKamgari, SaeedZare, FatemehShahryarZadeh, M. Mansoorzadeh","Design Novel Model Reference Artificial Intelligence Based Methodology to Optimized Fuel Ratio in IC Engine",2013,"","","","",38,"2022-07-13 09:36:21","","10.5815/IJIEEB.2013.02.07","","",,,,,20,2.22,4,5,9,"In this research, model reference fuzzy based control is presented as robust controls for IC engine. The objective of the study is to design controls for IC engines without the knowledge of the boundary of uncertainties and dynamic information by using fuzzy model reference PD p lus mass of air while improve the robustness of the PD p lus mass of air control. A PD plus mass of air provides for eliminate the mass of air and ultimate accuracy in the presence of the bounded disturbance/uncertainties, although this methods also causes some oscillation. The fuzzy PD plus mass of air is proposed as a solution to the problems crated by unstability. Th is method has a good performance in presence of uncertainty.","",""
4,"S. Back, Seongju Lee, Sungho Shin, Yeonguk Yu, Taekyeong Yuk, Saepomi Jong, Seungjun Ryu, Kyoobin Lee","Robust Skin Disease Classification by Distilling Deep Neural Network Ensemble for the Mobile Diagnosis of Herpes Zoster",2021,"","","","",39,"2022-07-13 09:36:21","","10.1109/ACCESS.2021.3054403","","",,,,,4,4.00,1,8,1,"Herpes zoster (HZ) is a common cutaneous disease affecting one out of five people; hence, early diagnosis of HZ is crucial as it can progress to chronic pain syndrome if antiviral treatment is not provided within 72 hr. Mobile diagnosis of HZ with the assistance of artificial intelligence can prevent neuropathic pain while reducing clinicians’ fatigue and diagnosis cost. However, the clinical images captured from daily mobile devices likely contain visual corruptions, such as motion blur and noise, which can easily mislead the automated system. Hence, this paper aims to train a robust and mobile deep neural network (DNN) that can distinguish HZ from other skin diseases using user-submitted images. To enhance robustness while retaining low computational cost, we propose a knowledge distillation from ensemble via curriculum training (KDE-CT) wherein a student network learns from a stronger teacher network progressively. We established skin diseases dataset for HZ diagnosis and evaluated the robustness against 75 types of corruption. A total of 13 different DNNs was evaluated on both clean and corrupted images. The experiment result shows that the proposed KDE-CT significantly improves corruption robustness when compared with other methods. Our trained MobileNetV3-Small achieved more robust performance (93.5% overall accuracy, 67.6 mean corruption error) than the DNN ensemble with smaller computation (549x fewer multiply-and-accumulate operations), which makes it suitable for mobile skin lesion analysis.","",""
1,"M. Moradi, Kathrin Blagec, M. Samwald","Deep learning models are not robust against noise in clinical text",2021,"","","","",40,"2022-07-13 09:36:21","","","","",,,,,1,1.00,0,3,1,"Artificial Intelligence (AI) systems are attracting increasing interest in the medical domain due to their ability to learn complicated tasks that require human intelligence and expert knowledge. AI systems that utilize high-performance Natural Language Processing (NLP) models have achieved state-of-the-art results on a wide variety of clinical text processing benchmarks. They have even outperformed human accuracy on some tasks. However, performance evaluation of such AI systems have been limited to accuracy measures on curated and clean benchmark datasets that may not properly reflect how robustly these systems can operate in real-world situations. In order to address this challenge, we introduce and implement a wide variety of perturbation methods that simulate different types of noise and variability in clinical text data. While noisy samples produced by these perturbation methods can often be understood by humans, they may cause AI systems to make erroneous decisions. Conducting extensive experiments on several clinical text processing tasks, we evaluated the robustness of high-performance NLP models against various types of character-level and word-level noise. The results revealed that the NLP models performance degrades when the input contains small amounts of noise. This study is a significant step towards exposing vulnerabilities of AI models utilized in clinical text processing systems. The proposed perturbation methods can be used in performance evaluation tests to assess how robustly clinical NLP models can operate on noisy data, in real-world settings.","",""
0,"Yufeng Zhang, Zhuoran Yang, Zhaoran Wang","Provably Efficient Actor-Critic for Risk-Sensitive and Robust Adversarial RL: A Linear-Quadratic Case",2021,"","","","",41,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,3,1,"Risk-sensitivity plays a central role in artificial intelligence safety. In this paper, we study the global convergence of the actor-critic algorithm for risk-sensitive reinforcement learning (RSRL) with exponential utility, which remains challenging for policy optimization as it lacks the linearity needed to formulate policy gradient. To bypass such an issue of nonlinearity, we resort to the equivalence between RSRL and robust adversarial reinforcement learning (RARL), which is formulated as a zero-sum Markov game with a hypothetical adversary. In particular, the Nash equilibrium (NE) of such a game yields the optimal policy for RSRL, which is provably robust. We focus on a simple yet fundamental setting known as linear-quadratic (LQ) game. To attain the optimal policy, we develop a nested natural actor-critic algorithm, which provably converges to the NE of the LQ game at a sublinear rate, thus solving both RSRL and RARL. To the best knowledge, the proposed nested actor-critic algorithm appears to be the first model-free policy optimization algorithm that provably attains the optimal policy for RSRL and RARL in the LQ setting, which sheds light on more general settings.","",""
0,"S. K. Opoku","A Robust Mechanism for Categorizing Context-Aware Applications into Generations",2021,"","","","",42,"2022-07-13 09:36:21","","10.24018/ejece.2021.5.6.371","","",,,,,0,0.00,0,1,1,"The hunt to categorize context-aware applications has been a prevalent issue to developers of context-aware applications. The previous categorizations were based on the functions of the applications. These mechanisms yielded limited results since many applications could not be categorized. This paper categorizes applications into four generations based on developmental trends through a literature survey. The first generation applications focused on data acquisition and used hardware sensors. The second generation applications focused on knowledge acquisition and used software sensors, semantic language and ontology-based modelling languages. The third generation applications focused on intelligent reasoning and used mechanisms to handle information uncertainty. The fourth generation applications deprecate cumbersome ruleset implementations and focus on artificial intelligence whilst taking into consideration the effect of the dynamics of users’ background and preference on contextual information. The study demonstrated that when applications, methods or technologies can be categorized over some time, it is better to classify them into generations.","",""
15,"Qianqian Song, Jing Su, Wei Zhang","scGCN is a graph convolutional networks algorithm for knowledge transfer in single cell omics",2021,"","","","",43,"2022-07-13 09:36:21","","10.1038/s41467-021-24172-y","","",,,,,15,15.00,5,3,1,"","",""
2,"B. Dorr, Lucian Galescu, E. Golob, K. Venable, Y. Wilks","Companion-Based Ambient Robust Intelligence (CARING)",2015,"","","","",44,"2022-07-13 09:36:21","","","","",,,,,2,0.29,0,5,7,"We present a Companion-based Ambient Robust INtelliGence (CARING) system, for communication with, and support of, clients with Traumatic brain injury (TBI) or Amyotrophic Lateral Sclerosis (ALS). A central component of this system is an artificial companion, combined with a range of elements for ambient intelligence. The companion acts as a personalized intermediary for multi-party communication between the client, the environment (e.g. a Smart Home), caregivers and health professionals. CARING is based on tightly coupled systems drawing from natural language processing, speech recognition and adaptation, deep language understanding and constraintbased knowledge representation and reasoning. A major innovation of the system is its ability to adapt and accommodate different interfaces associated with different client capabilities and needs. The system will use, as a proxy, different interaction requirements of clients (e.g., Brain-Computer Interfaces) at different stages of ALS progression and with different types of TBI impairments. Ultimately, this technology is expected to improve the quality of life for clients through conversation with a computer.","",""
24,"Sebastian Bader, P. Hitzler, Steffen Hölldobler","The Integration of Connectionism and First-Order Knowledge Representation and Reasoning as a Challenge for Artificial Intelligence",2004,"","","","",45,"2022-07-13 09:36:21","","","","",,,,,24,1.33,8,3,18,"Intelligent systems based on first-order logic on the one hand, and on artificial neural networks (also called connectionist systems) on the other, differ substantially. It would be very desirable to combine the robust neural networking machinery with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. Current state-of-the-art research, however, fails by far to achieve this ultimate goal. As one of the main obstacles to be overcome we perceive the question how symbolic knowledge can be encoded by means of connectionist systems: Satisfactory answers to this will naturally lead the way to knowledge extraction algorithms and to integrated neural-symbolic systems.","",""
3,"Yongyue Wang, Chunhe Xia, Chengxiang Si, Beitong Yao, Tianbo Wang","Robust Reasoning Over Heterogeneous Textual Information for Fact Verification",2020,"","","","",46,"2022-07-13 09:36:21","","10.1109/ACCESS.2020.3019586","","",,,,,3,1.50,1,5,2,"Automatic fact verification (FV) based on artificial intelligence is considered as a promising approach which can be used to identify misinformation distributed on the web. Even though previous FV using deep learning have made great achievements in single dataset (e.g., FEVER), the trained systems are unlikely to be capable of extracting evidence from heterogeneous web-sources and validating claims in accordance with evidence found on the Internet. Nevertheless, the heterogeneity covers abundant semantic information, which will help FV system identify misinformation in a more accurate way. The current work is the first attempt to make the combination of knowledge graph (KG) and graph neural network (GNN) to enhance the robustness of FV systems for heterogeneous information. As a result, it can be generalized to multi-domain datasets after training on a sufficient single one. To make information update and aggregate well on the collaborative graph, the present study proposes a double graph attention network (DGAT) framework which recursively propagates the embeddings from a node’s neighbors to refine the node’s embedding as well as applies an attention mechanism to classify the importance of the neighbors. We train and evaluate our system on FEVER, a single and benchmark dataset for FV, and then re-evaluate our system on UKP Snopes Corpus, a new richly annotated corpus for FV tasks on the basis of heterogeneous web sources. According to experimental results, although DGAT has no excellent advantages in a single dataset, it shows outstanding performance in more realistic and multi-domain datasets. Moreover, the current study also provides a feasible method for deep learning to have the ability to infer heterogeneous information robustly.","",""
0,"A. J. Spiessbach","Task -specific knowledge by itself, however, is not sufficient to achieve robust machine perception in unrestricted, uncontrolled, or noncooperativ e environments. A higher -level",2017,"","","","",47,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,5,"Extending the recent successes demonstrated by artificial intelligence expert system technology to the broader domain of scene analysis necessitates a consequent broadening of the concepts and techniques used in current systems. Simple, single mechanisms must give way to multiple lines of reasoning and multiple levels of description. Meta -level reasoning, which is a recursive application of the basic expert system paradigm, is a promising approach to the problem of coping with the complexity inherent in highly variable, dynamic environments. This paper describes research directed towards incorporating meta level reasoning into context -based scene analysis systems. A multi -layered expert system architecture is outlined that is aimed at providing high -level strategies and dynamic planning capability to the basic image understanding process.","",""
2,"Preet Amol Singh, Neha Bajwa, S. Naman, A. Baldi","A Review on Robust Computational Approaches Based Identification and Authentication of Herbal Raw Drugs",2020,"","","","",48,"2022-07-13 09:36:21","","10.2174/1570180817666200304125520","","",,,,,2,1.00,1,4,2,"  Over the last decade, there has been a sudden rise in the demand for herbal as well as Information and Technology (IT) industry around the world. Identification of plant species has become useful and relevant to all the members of the society including farmers, traders, hikers, etc. Conventional authentication techniques such as morphological characterization, histological methods, and optical microscopy require multiple skills which are tedious, timeconsuming and difficult to learn for non-experts. This creates a hurdle for individuals interested in acquiring knowledge of species. Relying on rapid, economical and computerized approaches to identify and authenticate medicinal plants has become a recent development.    The purpose of this review is to summarize artificial intelligence-based technologies for wider dissemination of common plant-based knowledge such as identification and authentication to common people earlier limited to only experts.    A robust plant identification design enabling automated plant-organ and feature-based identification utilizing pattern recognition and image processing techniques resulting in image retrieval and recognition has been highlighted in this review for all the concerned stakeholders. Attempts have been made to compare conventional authentication methods with advanced computerized techniques to emphasize the advantages and future applications of an automated identification system in countering adulteration and providing fair trade opportunities to farmers.    Major findings suggested that microscopical features such as shape and size of calcium oxalate crystals, trichomes, scleriods, stone cells, fibers, etc. are the essential descriptors for identification and authentication of herbal raw drugs using computational approaches.    This computational design can be successfully employed to address quality issues of medicinal plants. Therefore, computational techniques proved as a milestone in the growth of agriculture and medicinal plant industries. ","",""
11,"S. Tripathi, David Muhr, Manuel Brunner, F. Emmert‐Streib, H. Jodlbauer, M. Dehmer","Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing",2020,"","","","",49,"2022-07-13 09:36:21","","10.3389/frai.2021.576892","","",,,,,11,5.50,2,6,2,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.","",""
1,"Zhaofeng Zhang, Yue Chen, Junshan Zhang","Distributionally Robust Learning Based on Dirichlet Process Prior in Edge Networks",2020,"","","","",50,"2022-07-13 09:36:21","","10.23919/JCIN.2020.9055108","","",,,,,1,0.50,0,3,2,"In order to meet the real-time performance requirements, intelligent decisions in Internet of things applications must take place right here right now at the network edge. Pushing the artificial intelligence frontier to achieve edge intelligence is nontrivial due to the constrained computing resources and limited training data at the network edge. To tackle these challenges, we develop a distributionally robust optimization (DRO)-based edge learning algorithm, where the uncertainty model is constructed to foster the synergy of cloud knowledge and local training. Specifically, the cloud transferred knowledge is in the form of a Dirichlet process prior distribution for the edge model parameters, and the edge device further constructs an uncertainty set centered around the empirical distribution of its local samples. The edge learning DRO problem, subject to these two distributional uncertainty constraints, is recast as a single-layer optimization problem using a duality approach. We then use an Expectation-Maximization algorithm-inspired method to derive a convex relaxation, based on which we devise algorithms to learn the edge model. Furthermore, we illustrate that the meta-learning fast adaptation procedure is equivalent to our proposed Dirichlet process prior-based approach. Finally, extensive experiments are implemented to showcase the performance gain over standard approaches using edge data only.","",""
1,"Chunheng Zhao, Yi Li, Matthew J. Wessner, Chinmay Rathod, P. Pisu","Support-Vector Machine Approach for Robust Fault Diagnosis of Electric Vehicle Permanent Magnet Synchronous Motor",2020,"","","","",51,"2022-07-13 09:36:21","","10.36001/PHMCONF.2020.V12I1.1291","","",,,,,1,0.50,0,5,2,"Permanent magnet synchronous motor (PMSM) is a leading technology for electric vehicles (EVs) and other high-performance industrial applications. These challenging applications demand robust fault diagnosis schemes, but conventional strategies based on models, system knowledge, and signal transformation have limitations that degrade the agility of diagnosing faults. These methods require extremely detailed design and consideration to remain robust against noise and disturbances in the actual application. Recent advancements in artificial intelligence and machine learning have proven to be promising next-generation solutions for fault diagnosis. In this paper, a support-vector machine (SVM) utilizing sparse representation is developed to perform sensor fault diagnosis of a PMSM. A simulation model of the pertinent PMSM drive system for automotive applications is used to generate a set of labelled training example sets that the SVM uses to determine margins between normal and faulty operating conditions. The PMSM model includes input as a torque reference profile and disturbance as a constant road grade, against both of which faults must be detectable. Even with limited training, the SVM classifier developed in this paper is capable of diagnosing faults with a high degree of accuracy, suggesting that such methods are feasible for the demanding fault diagnosis challenge in PMSM.","",""
0,"Zhaofeng Zhang, Yue Chen, Junshan Zhang","Distributionally Robust Edge Learning with Dirichlet Process Prior",2020,"","","","",52,"2022-07-13 09:36:21","","10.1109/ICDCS47774.2020.00016","","",,,,,0,0.00,0,3,2,"In order to meet the real-time performance requirements, intelligent decisions in many IoT applications must take place right here right now at the network edge. The conventional cloud-based learning approach would not be able to keep up with the demands in achieving edge intelligence in these applications. Nevertheless, pushing the artificial intelligence (AI) frontier to achieve edge intelligence is highly nontrivial due to the constrained computing resources and limited training data at the network edge. To tackle these challenges, we develop a distributionally robust optimization (DRO)-based edge learning algorithm, where the uncertainty model is constructed to foster the synergy of cloud knowledge transfer and local training. Specifically, the knowledge transferred from the cloud is in the form of a Dirichlet process prior distribution for the edge model parameters, and the edge device further constructs an uncertainty set centered around the empirical distribution of its local samples to capture the information of local data processing. The edge learning DRO problem, subject to the above two distributional uncertainty constraints, is then recast as an equivalent single-layer optimization problem using a duality approach. We then use an Expectation-Maximization (EM) algorithm-inspired method to derive a convex relaxation, based on which we devise algorithms to learn the edge model parameters. Finally, extensive experiments are implemented to showcase the performance gain over standard learning approaches using local edge data only.","",""
0,"Bharat Khandelwal","FAME-BERT: Stable Meta-learning for Robust Question-Answering",2022,"","","","",53,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,1,"With the increasing importance of conversational AI, search engines, and other interactive systems, Question Answering has become a critical task to advancing the state-of-the-art in Natural Language Understanding systems. An important problem is for these systems to generalize well to new domains with a small amount of training examples - understanding how to build such systems will represent a leap of knowledge in our quest for Artificial General Intelligence, and will allow us to create general-purpose software that adapts on an as-needed basis. To obtain good out-of-domain generalization performance with fewshot learning, we propose our model FAME-BERT ( F inetune- A ugment- M etalearn-E nsemble Distil BERT ). We recognize and underline the benefits of carefully crafted learning rates, data augmentation, and ensembling over our base approach of meta-learning a DistilBERT model. Highlights of our model’s performance include Rank 1 by EM on the validation leaderboard and Top 5 by EM on the test leaderboard. On both validation and test sets, our model outperforms the DistilBERT baseline by a significant margin. Finally, we discuss future directions of research that are likely to further boost model performance.","",""
31,"Shijie Jiang, Yi Zheng, D. Solomatine","Improving AI System Awareness of Geoscience Knowledge: Symbiotic Integration of Physical Approaches and Deep Learning",2020,"","","","",54,"2022-07-13 09:36:21","","10.1029/2020GL088229","","",,,,,31,15.50,10,3,2,"Modeling dynamic geophysical phenomena is at the core of Earth and environmental studies. The geoscientific community relying mainly on physical representations may want to consider much deeper adoption of artificial intelligence (AI) instruments in the context of AI's global success and emergence of big Earth data. A new perspective of using hybrid physics‐AI approaches is a grand vision, but actualizing such approaches remains an open question in geoscience. This study develops a general approach to improving AI geoscientific awareness, wherein physical approaches such as temporal dynamic geoscientific models are included as special recurrent neural layers in a deep learning architecture. The illustrative case of runoff modeling across the conterminous United States demonstrates that the physics‐aware DL model has enhanced prediction accuracy, robust transferability, and good intelligence for inferring unobserved processes. This study represents a firm step toward realizing the vision of tackling Earth system challenges by physics‐AI integration.","",""
2,"Aidan Murphy, Gráinne Murphy, Jorge Amaral, D. M. Dias, Enrique Naredo, C. Ryan","Towards Incorporating Human Knowledge in Fuzzy Pattern Tree Evolution",2021,"","","","",55,"2022-07-13 09:36:21","","10.1007/978-3-030-72812-0_5","","",,,,,2,2.00,0,6,1,"","",""
26,"Giuseppe Futia, Antonio Vetrò","On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI - Three Challenges for Future Research",2020,"","","","",56,"2022-07-13 09:36:21","","10.3390/info11020122","","",,,,,26,13.00,13,2,2,"Deep learning models contributed to reaching unprecedented results in prediction and classification tasks of Artificial Intelligence (AI) systems. However, alongside this notable progress, they do not provide human-understandable insights on how a specific result was achieved. In contexts where the impact of AI on human life is relevant (e.g., recruitment tools, medical diagnoses, etc.), explainability is not only a desirable property, but it is -or, in some cases, it will be soon-a legal requirement. Most of the available approaches to implement eXplainable Artificial Intelligence (XAI) focus on technical solutions usable only by experts able to manipulate the recursive mathematical functions in deep learning algorithms. A complementary approach is represented by symbolic AI, where symbols are elements of a lingua franca between humans and deep learning. In this context, Knowledge Graphs (KGs) and their underlying semantic technologies are the modern implementation of symbolic AI—while being less flexible and robust to noise compared to deep learning models, KGs are natively developed to be explainable. In this paper, we review the main XAI approaches existing in the literature, underlying their strengths and limitations, and we propose neural-symbolic integration as a cornerstone to design an AI which is closer to non-insiders comprehension. Within such a general direction, we identify three specific challenges for future research—knowledge matching, cross-disciplinary explanations and interactive explanations.","",""
150,"C. Yan, Liang Li, Chunjie Zhang, Bingtao Liu, Yongdong Zhang, Qionghai Dai","Cross-Modality Bridging and Knowledge Transferring for Image Understanding",2019,"","","","",57,"2022-07-13 09:36:21","","10.1109/TMM.2019.2903448","","",,,,,150,50.00,25,6,3,"The understanding of web images has been a hot research topic in both artificial intelligence and multimedia content analysis domains. The web images are composed of various complex foregrounds and backgrounds, which makes the design of an accurate and robust learning algorithm a challenging task. To solve the above significant problem, first, we learn a cross-modality bridging dictionary for the deep and complete understanding of a vast quantity of web images. The proposed algorithm leverages the visual features into the semantic concept probability distribution, which can construct a global semantic description for images while preserving the local geometric structure. To discover and model the occurrence patterns between intra- and inter-categories, multi-task learning is introduced for formulating the objective formulation with Capped-$\ell _{1}$ penalty, which can obtain the optimal solution with a higher probability and outperform the traditional convex function-based methods. Second, we propose a knowledge-based concept transferring algorithm to discover the underlying relations of different categories. This distribution probability transferring among categories can bring the more robust global feature representation, and enable the image semantic representation to generalize better as the scenario becomes larger. Experimental comparisons and performance discussion with classical methods on the ImageNet, Caltech-256, SUN397, and Scene15 datasets show the effectiveness of our proposed method at three traditional image understanding tasks.","",""
22,"Xi Lin, Jun Wu, A. Bashir, Jianhua Li, Wu Yang, Jalil Piran","Blockchain-Based Incentive Energy-Knowledge Trading in IoT: Joint Power Transfer and AI Design",2020,"","","","",58,"2022-07-13 09:36:21","","10.1109/jiot.2020.3024246","","",,,,,22,11.00,4,6,2,"Recently, edge artificial intelligence techniques (e.g., federated edge learning) are emerged to unleash the potential of big data from Internet of Things (IoT). By learning knowledge on local devices, data privacy-preserving and quality of service (QoS) are guaranteed. Nevertheless, the dilemma between the limited on-device battery capacities and the high energy demands in learning is not resolved. When the on-device battery is exhausted, the edge learning process will have to be interrupted. In this paper, we propose a novel Wirelessly Powered Edge intelliGence (WPEG) framework, which aims to achieve a stable, robust, and sustainable edge intelligence by energy harvesting (EH) methods. Firstly, we build a permissioned edge blockchain to secure the peer-to-peer (P2P) energy and knowledge sharing in our framework. To maximize edge intelligence efficiency, we then investigate the wirelessly-powered multi-agent edge learning model and design the optimal edge learning strategy. Moreover, by constructing a two-stage Stackelberg game, the underlying energy-knowledge trading incentive mechanisms are also proposed with the optimal economic incentives and power transmission strategies. Finally, simulation results show that our incentive strategies could optimize the utilities of both parties compared with classic schemes, and our optimal learning design could realize the optimal learning efficiency.","",""
16,"S. Ulyanov","Quantum Fast Algorithm Computational Intelligence PT I: SW / HW Smart Toolkit",2019,"","","","",59,"2022-07-13 09:36:21","","10.30564/AIA.V1I1.619","","",,,,,16,5.33,16,1,3,"A new approach to a circuit implementation design of quantum algorithm gates for quantum massive parallel fast computing implementation is presented. The main attention is focused on the development of design method of fast quantum algorithm operators as superposition, entanglement and interference which are in general time-consuming operations due to the number of products that have to be performed. SW & HW support sophisticated smart toolkit of supercomputing accelerator of quantum algorithm simulation is described. The method for performing Grover’s interference without product operations as Benchmark introduced. The background of developed information technology is the ""Quantum / Soft Computing Optimizer"" (QSCOptKBTM) software based on soft and quantum computational intelligence toolkit. Quantum genetic and quantum fuzzy inference algorithm gate design considered. The quantum information technology of imperfect knowledge base self-organization design of fuzzy robust controllers for the guaranteed achievement of intelligent autonomous robot the control goal in unpredicted control situations is described.","",""
0,"A. Sarkar","J ul 2 02 1 QKSA : Quantum Knowledge Seeking Agent motivation , core thesis and baseline framework",2021,"","","","",60,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,1,"In this article we present the motivation and the core thesis towards the implementation of a Quantum Knowledge Seeking Agent (QKSA). QKSA is a general reinforcement learning agent that can be used to model classical and quantum dynamics. It merges ideas from universal artificial general intelligence, constructor theory and genetic programming to build a robust and general framework for testing the capabilities of the agent in a variety of environments. It takes the artificial life (or, animat) path to artificial general intelligence where a population of intelligent agents are instantiated to explore valid ways of modeling the perceptions. The multiplicity and survivability of the agents are defined by the fitness, with respect to the explainability and predictability, of a resource-bounded computational model of the environment. This general learning approach is then employed to model the physics of an environment based on subjective observer states of the agents. A specific case of quantum process tomography as a general modeling principle is presented. The various background ideas and a baseline formalism is discussed in this article which sets the groundwork for the implementations of the QKSA that are currently in active development. Section 2 presents a historic overview of the motivation behind this research In Section 3 we survey some general reinforcement learning models and bio-inspired computing techniques that forms a baseline for the design of the QKSA. Section 4 presents an overview of field of quantum artificial agents and the observer based operational theory that the QKSA aims to learn. In Section 5 and 6 we presents the salient features and a formal definition of our model. In Section 7 we present the task of quantum process tomography (QPT) as a general task to test our framework. In Section 8 we conclude the discussion with suggestive future directions for implementing the QKSA.","",""
0,"A. Sarkar","QKSA: Quantum Knowledge Seeking Agent",2021,"","","","",61,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,1,"In this article we present the motivation and the core thesis towards the implementation of a Quantum Knowledge Seeking Agent (QKSA). QKSA is a general reinforcement learning agent that can be used to model classical and quantum dynamics. It merges ideas from universal artificial general intelligence, constructor theory and genetic programming to build a robust and general framework for testing the capabilities of the agent in a variety of environments. It takes the artificial life (or, animat) path to artificial general intelligence where a population of intelligent agents are instantiated to explore valid ways of modelling the perceptions. The multiplicity and survivability of the agents are defined by the fitness, with respect to the explainability and predictability, of a resource-bounded computational model of the environment. This general learning approach is then employed to model the physics of an environment based on subjective observer states of the agents. A specific case of quantum process tomography as a general modelling principle is presented. The various background ideas and a baseline formalism are discussed in this article which sets the groundwork for the implementations of the QKSA that are currently in active development.","",""
5,"Sutta Sornmayura","Robust FOREX Trading with Deep Q Network (DQN)",2019,"","","","",62,"2022-07-13 09:36:21","","","","",,,,,5,1.67,5,1,3,"Financial trading is one of the most attractive areas in finance. Trading systems development is not an easy task because it requires extensive knowledge in several areas such as quantitative analysis, financial skills, and computer programming. A trading systems expert, as a human, also brings in their own bias when developing the system. There should be another, more effective way to develop the system using artificial intelligence. The aim of this study was to compare the performance of AI agents to the performance of the buy-and-hold strategy and the expert trader. The tested market consisted of 15 years of the Forex data market, from two currency pairs (EURUSD, USDJPY) obtained from Dukascopy Bank SA Switzerland. Both hypotheses were tested with a paired t-Test at the 0.05 significance level. The findings showed that AI can beat the buy & hold strategy with significant superiority, in FOREX for both currency pairs (EURUSD, USDJPY), and that AI can also significantly outperform CTA (experienced trader) for trading in EURUSD. However, the AI could not significantly outperform CTA for USDJPY trading. Limitations, contributions, and further research were recommended.","",""
12,"Xinxin Jiang, Shirui Pan, Guodong Long, Fei Xiong, Jing Jiang, Chengqi Zhang","Cost-Sensitive Parallel Learning Framework for Insurance Intelligence Operation",2019,"","","","",63,"2022-07-13 09:36:21","","10.1109/TIE.2018.2873526","","",,,,,12,4.00,2,6,3,"Recent advancements in artificial intelligence are providing the insurance industry with new opportunities to create tailored solutions and services based on newfound knowledge of consumers, and the execution of enhanced operations and business functions. However, insurance data are heterogeneous, and imbalanced class distribution with low frequency and high dimensions, which presents four major challenges to machine learning in real-world business. Traditional machine learning algorithms can typically apply to standard data sets, which are normally homogeneous and balanced. In this paper, we focus on an efficient cost-sensitive parallel learning framework (CPLF) to enhance insurance operations with a deep learning approach that does not require preprocessing. Our approach comprises a novel, unified, end-to-end cost-sensitive parallel neural network that learns real-world heterogeneous data. A specifically designed cost-sensitive matrix then automatically generates a robust model for learning minority classifications, and the parameters of both the cost-sensitive matrix and the hybrid neural network are alternately but jointly optimized during training. We also study the CPLF-based architecture for a real-world insurance intelligence operation system, and demonstrate fraud detection and policy renewal experiments on this system. The results of comparative experiments on real-world insurance data sets reflecting actual business cases demonstrate the effectiveness of our design.","",""
0,"Y. D. Valle, N. Hampton","APPLICATION OF ARTIFICIAL INTELLIGENCE TO THE PROBLEM OF SELECTING THE APPROPRIATE DIAGNOSTIC FOR CABLE SYSTEMS",2011,"","","","",64,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,2,11,"Cable System Management requires an assessment of the health of the cables system. It is increasingly common for the assessment of aged cable systems to be made through the application of diagnostics measurements. There are a plethora of these techniques and embodiments; such that even an informed user has great difficulty making a rational choice on the most appropriate technique. To aid this decision making a Knowledge Based System has been developed that takes the knowledge of many diverse experts and delivers a robust framework by which rational, reproducible and transparent choices may be made. This paper discusses the development of the system and provides a number of illustrative case studies.","",""
9,"R. Das, Ameya Godbole, S. Dhuliawala, M. Zaheer, A. McCallum","A Simple Approach to Case-Based Reasoning in Knowledge Bases",2020,"","","","",65,"2022-07-13 09:36:21","","10.24432/C52S3K","","",,,,,9,4.50,2,5,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires \emph{no training}, and is reminiscent of case-based reasoning in classical artificial intelligence (AI).  Consider the task of finding a target entity given a source entity and a binary relation.  Our approach finds multiple \textit{graph path patterns} that connect similar source entities through the given relation, and looks for pattern matches starting from the query source.  Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122.  We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
4,"M. Gates, Mukesh Ambani","Non-Parametric Reasoning on Knowledge Bases",2020,"","","","",66,"2022-07-13 09:36:21","","","","",,,,,4,2.00,2,2,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence (AI). Consider the task of finding a target entity given a source entity and a binary relation. Our approach finds multiple graph path patterns that connect similar source entities through the given relation, and looks for pattern matches starting from the query source. Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
7,"Qianqian Song, Jing Su, Wei Zhang","scGCN: a Graph Convolutional Networks Algorithm for Knowledge Transfer in Single Cell Omics",2020,"","","","",67,"2022-07-13 09:36:21","","10.1101/2020.09.13.295535","","",,,,,7,3.50,2,3,2,"Single-cell omics represent the fastest-growing genomics data type in the literature and the public genomics repositories. Leveraging the growing repository of labeled datasets and transferring labels from existing datasets to newly generated datasets will empower the exploration of the single-cell omics. The current label transfer methods have limited performance, largely due to the intrinsic heterogeneity and extrinsic differences between datasets. Here, we present a robust graph-based artificial intelligence model, single-cell Graph Convolutional Network (scGCN), to achieve effective knowledge transfer across disparate datasets. Benchmarked with other label transfer methods on totally 30 single cell omics datasets, scGCN has consistently demonstrated superior accuracy on leveraging cells from different tissues, platforms, and species, as well as cells profiled at different molecular layers. scGCN is implemented as an integrated workflow as a python software, which is available at https://github.com/QSong-github/scGCN.","",""
79,"Stefan Zwicklbauer, C. Seifert, M. Granitzer","Robust and Collective Entity Disambiguation through Semantic Embeddings",2016,"","","","",68,"2022-07-13 09:36:21","","10.1145/2911451.2911535","","",,,,,79,13.17,26,3,6,"Entity disambiguation is the task of mapping ambiguous terms in natural-language text to its entities in a knowledge base. It finds its application in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question & Answering. We propose a new collective, graph-based disambiguation algorithm utilizing semantic entity and document embeddings for robust entity disambiguation. Robust thereby refers to the property of achieving better than state-of-the-art results over a wide range of very different data sets. Our approach is also able to abstain if no appropriate entity can be found for a specific surface form. Our evaluation shows, that our approach achieves significantly (>5%) better results than all other publicly available disambiguation algorithms on 7 of 9 datasets without data set specific tuning. Moreover, we discuss the influence of the quality of the knowledge base on the disambiguation accuracy and indicate that our algorithm achieves better results than non-publicly available state-of-the-art algorithms.","",""
43,"M. El-Melegy, Mohammed H. Essai, A. A. Ali","Robust Training of Artificial Feedforward Neural Networks",2009,"","","","",69,"2022-07-13 09:36:21","","10.1007/978-3-642-01082-8_9","","",,,,,43,3.31,14,3,13,"","",""
73,"Yueting Zhuang, Fei Wu, Chun Chen, Yunhe Pan","Challenges and opportunities: from big data to knowledge in AI 2.0",2017,"","","","",70,"2022-07-13 09:36:21","","10.1631/FITEE.1601883","","",,,,,73,14.60,18,4,5,"In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.","",""
322,"J. Korbicz, J. M. Kóscielny, Z. Kowalczuk, W. Cholewa, Jozef Karbicz","Fault Diagnosis: Models, Artificial Intelligence, Applications",2004,"","","","",71,"2022-07-13 09:36:21","","","","",,,,,322,17.89,64,5,18,"1. Introduction.- 2. Models in the diagnostics of processes.- 3. Process diagnostics methodology.- 4. Methods of signal analysis.- 5. Control theory methods in designing diagnostic systems.- 6. Optimal detection observers based on eigenstructure assignment.- 7. Robust H?-optimal synthesis of FDI systems.- 8. Evolutionary methods in designing diagnostic systems.- 9. Artificial neural networks in fault diagnosis.- 10. Parametric and neural network Wiener and Hammerstein models in fault detection and isolation.- 11. Application of fuzzy logic to diagnostics.- 12. Observers and genetic programming in the identification and fault diagnosis of non-linear dynamic systems.- 13. Genetic algorithms in the multi-objective optimisation of fault detection observers.- 14. Pattern recognition approach to fault diagnostics.- 15. Expert systems in technical diagnostics.- 16. Selected methods of knowledge engineering in systems diagnosis.- 17. Methods of acqusition of diagnostic knowledge.- 18. State monitoring algorithms for complex dynamic systems.- 19. Diagnostics of industrial processes in decentralised structures.- 20. Detection and isolation of manoeuvres in adaptive tracking filtering based on multiple model switching.- 21. Detecting and locating leaks in transmission pipelines.- 22. Models in the diagnostics of processes.- 23. Diagnostic systems.","",""
368,"J. D. Schaffer","Some experiments in machine learning using vector evaluated genetic algorithms (artificial intelligence, optimization, adaptation, pattern recognition)",1984,"","","","",72,"2022-07-13 09:36:21","","","","",,,,,368,9.68,368,1,38,"This dissertation describes experiments conducted to explore the efficacy of using vector-valued feedback with a class of adaptive procedures called genetic algorithms. The software system developed was called VEGA for Vector Evaluated Genetic Algorithm and was first used on multiple objective optimization problems. The principle conclusion of these experiments was that VEGA provided a powerful and robust search technique for complex multiobjective optimization problems of high order when little or no a priori knowledge was available to guide the search. These results were similar to those found by previous researchers using scalar genetic algorithms for scalar optimization problems.  The VEGA technique was then applied to multiclass pattern discrimination tasks. The resulting software system was called LS-2 for Learning System - Two since it followed closely the lead of a scalar-valued learning system called LS-1 developed by Stephen Smith. The experiments revealed that LS-2 was able to evolve high performance production system programs to perform the pattern discrimination tasks it was given. In addition, experiments which varied several of the parameters of LS-2 revealed something of the sensitivity of vector-valued genetic search to the settings of these parameters.  In sum it may be said that the VEGA approach has demonstrated the efficacy of extending the previously demonstrated power of genetic algorithms to vector-valued problems and thereby provides a new approach to machine learning.","",""
2,"M. Ghadi, L. Laouamer, Laurent Nana, A. Pascu","Rough Set Theory Based on Robust Image Watermarking",2018,"","","","",73,"2022-07-13 09:36:21","","10.1007/978-3-319-63754-9_28","","",,,,,2,0.50,1,4,4,"","",""
21,"Donald J. Gemaehlich","An overview of artificial intelligence",1984,"","","","",74,"2022-07-13 09:36:21","","","","",,,,,21,0.55,21,1,38,"The face of science and engineering has been changing with the recent growth in computer architecture. This growth is so important and robust that it is dramatically reshaping relationships among people and organizations and providing a foundation for understanding and learning of intelligent behavior in living and engineered systems. Is this growth beneficial to our society, these are such questions of the general public which are due to the lack of education concerning rapidly advancing technologies. This paper attempts to present an overview of Artificial Intelligence (AI). A generally accepted theory that ―machine will do and think like humans more in the future‖ is the concept behind AI. Brief literature of different aspects by which AI is achieved like expert system, knowledge based systems (knowledge engineering), neural networks, fuzzy logic, Neuro-fuzzy logic and fuzzy expert system, is included in order to have a clear understanding of AI. Along with this the different applications of AI, has been included in this paper. It is concluded that extensive ongoing research in the field of AI gives an idea that in near future a day will come when human beings and machines will merge into cyborgs or cybernetic organisms that are more capable and powerful than either. This idea is called transhumanism. KeywordsArtificial Intelligence; Expert System; Neural Network; Fuzzy Logic; Neuro-fuzzy logic.","",""
0,"C. Ezeofor, Onengiye M. Georgewill","Development of Knowledge Based Smart Home",2019,"","","","",75,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,2,3,"this paper presents the development of Knowledge Based Smart Home. Smart home came to existence the very moment Internet of Things (IoT) Technology was invented. Internet of Things (IoT) has been experimentally proven to work satisfactorily by connecting simple appliances to it and were successfully controlled remotely through the internet.This invention has led to automation of homes, offices, industries, robotics, artificial intelligence etc. and today, more robust systems are being developed. Two basic ways of controlling and monitoring home remotely had been implemented from research. The first is by using GSM phone to control home appliances via sms commands and the second is through web application platform via networked and internet based computers. This work covers both ways and integrated voice recognition as another way of controlling home appliances. In order to accommodate sms based, web based and voice based, knowledge based system is implemented.This system integrates various communication techonologies such as Bluetooth BLE, Wi-Fi, GSM and Voice Recognition for easy communication with smart devices like Android smartphones, tablets, PDA etc. and personal computers. The system is made up of security system, control system and communication system which houses various sensors, actuators, microcontrollers such as raspberry pi 3, ESp 32, STM32, ESP8266-01, LCDs, etc. The graphical user interface (GUI) for mobile and computer web applications is designed using Eclipse and brackets IDEs. Python, java, C++ languages are used to write control codes for both the GUI and the embedded system chips (microcontrollers).The system can also function as an intelligent personal assistant (IPA), thus answering query and performing actions via voice commands using natural language user interface. This is to assist people like elderly, sick and disabled with basic tasks to makes household decisions through stored information in the knowledge base of the system. The system is implemented with the aid of Artificial Intelligence for the effective and efficient management of the home. The complete system was tested successfully.","",""
18,"P. Bock","The Emergence of Artificial Intelligence: Learning to Learn",1985,"","","","",76,"2022-07-13 09:36:21","","10.1609/AIMAG.V6I3.498","","",,,,,18,0.49,18,1,37,"The classical approach to the acquisition of knowledge and reason in artificial intelligence is to program the facts and rules into the machine. Unfortunately, the amount of time required to program the equivalent of human intelligence is prohibitively large. An alternative approach allows an automaton to learn to solve problems through iterative trial-and-error interaction with its environment, much as humans do. To solve a problem posed by the environment, the automaton generates a sequence or collection of responses based on its experience. The environment evaluates the effectiveness of this collection, and reports its evaluation to the automaton. The automaton modifies its strategy accordingly, and then generates a new collection of responses. This process is repeated until the automaton converges to the correct collection of responses. The principles underlying this paradigm, known as collective learning systems theory, are explained and applied to a simple game, demonstrating robust learning and dynamic adaptivity.","",""
172,"E. Muratov, J. Bajorath, R. Sheridan, I. Tetko, D. Filimonov, V. Poroikov, T. Oprea, I. Baskin, A. Varnek, A. Roitberg, O. Isayev, Stefano Curtalolo, D. Fourches, Y. Cohen, Alán Aspuru-Guzik, D. Winkler, D. Agrafiotis, A. Cherkasov, A. Tropsha","QSAR without borders.",2020,"","","","",77,"2022-07-13 09:36:21","","10.1039/d0cs00098a","","",,,,,172,86.00,17,19,2,"Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge.","",""
0,"Qinyun Liu","Solution Generation through Hybrid Intelligence and Creativity based on Investment Portfolio",2018,"","","","",78,"2022-07-13 09:36:21","","10.23940/IJPE.18.07.P29.16411650","","",,,,,0,0.00,0,1,4,"Artificial Intelligence (AI) has been developed to be robust on computing. Learning can be achieved by connecting to heterogeneous data using AI algorithms, such as the Artificial Neural Network. Knowledge can be learned, and rules in the database can be discovered by machines through heuristic algorithms. However, creativity has not been achieved by computers like the human brain by using AI algorithms individually. This research serves to explore a method to achieve creative solution generation by utilizing a relationship between intelligence and creativity, assuming intelligence is the subset of creativity. Under this relationship, the computing can be fulfilled using AI algorithms. The theories of achieving creativity is the guidance of this method.","",""
32,"Y. Mansour, Mariano Schain","Robust domain adaptation",2014,"","","","",79,"2022-07-13 09:36:21","","10.1007/s10472-013-9391-5","","",,,,,32,4.00,16,2,8,"","",""
8,"P. Bock","A perspective on artificial intelligence: Learning to learn",1988,"","","","",80,"2022-07-13 09:36:21","","10.1007/BF02283734","","",,,,,8,0.24,8,1,34,"","",""
36,"Mario Rodríguez-Molins, L. Ingolotti, F. Barber, M. Salido, María R. Sierra, Jorge Puente","A genetic algorithm for robust berth allocation and quay crane assignment",2014,"","","","",81,"2022-07-13 09:36:21","","10.1007/s13748-014-0056-3","","",,,,,36,4.50,6,6,8,"","",""
0,"G. McCalla","Artificial Intelligence and Educational Technology: A Natural Synergy. Extended Abstract.",1994,"","","","",82,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,28,"Educational technology and artificial intelligence (AI) are natural partners in the development of environments to support human learning. Designing systems with the characteristics of a rich learning environment is the long term goal of research in intelligent tutoring systems (ITS). Building these characteristics into a system is extremely difficult: each requires the use of techniques from AI, including knowledge representation, diagnosis and user modeling, planning, machine learning, and natural language understanding. Artificial intelligence techniques are usable now in practical systems. To illustrate this, several working systems that use artificial intelligence and that have been developed in the ARIES Laboratory (University of Saskatchewan, Canada) are discussed. The SCENT advisor can be used to provide robust diagnosis in a wide variety of problem solving domains. The learning by teaching system inverts the usual instructional paradigm: the system acts as an inquisitive learner, thus stimulating the human learner to refine and extend his/her knowledge. G.E.N.I.U.S. takes advantage of the credibility invested in a programming advisor by human learners in order to provide ""ignorance-based"" advice on programming errors. Finally, the VCR Tutor provides help to learners on how to program a video cassette recorder. The general lesson is that AI and educational technology can interact in a natural synergy to the mutual benefit of both. (Contains 11 references.) (MAS) *********************************************************************** Reproductions supplied by EDRS are the best that can be made from the original document. *********************************************************************** Artificial Intelligence and Educational Technology: A Natural Synergy","",""
2,"Moonis Ali, B. Whitehead, U. Gupta, H. Ferber","Identification and interpretation of patterns in rocket engine data: Artificial intelligence and neural network approaches",1995,"","","","",83,"2022-07-13 09:36:21","","","","",,,,,2,0.07,1,4,27,"This paper describes an expert system which is designed to perform automatic data analysis, identify anomalous events, and determine the characteristic features of these events. We have employed both artificial intelligence and neural net approaches in the design of this expert system. The artificial intelligence approach is useful because it provides (1) the use of human experts' knowledge of sensor behavior and faulty engine conditions in interpreting data; (2) the use of engine design knowledge and physical sensor locations in establishing relationships among the events of multiple sensors; (3) the use of stored analysis of past data of faulty engine conditions; and (4) the use of knowledge-based reasoning in distinguishing sensor failure from actual faults. The neural network approach appears promising because neural nets (1) can be trained on extremely noisy data and produce classifications which are more robust under noisy conditions than other classification techniques; (2) avoid the necessity of noise removal by digital filtering and therefore avoid the need to make assumptions about frequency bands or other signal characteristics of anomalous behavior; (3) can, in effect, generate their own feature detectors based on the characteristics of the sensor data used in training; and (4) are inherently parallel and therefore are potentially implementable in special-purpose parallel hardware.","",""
0,"I. Wachsmuth, Claus-Rainer Rollinger, W. Brauer","KI-95: Advances in Artificial Intelligence: 19th Annual German Conference on Artificial Intelligence, Bielefeld, Germany, September 11 - 13, 1995. Proceedings",1995,"","","","",84,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,3,27,"Partially observable Markov decision processes for artificial intelligence.- Robust processing of natural language.- Distinction networks.- The problem of signal and symbol integration: A study of cooperative mobile autonomous agent behaviors.- An extension of explanation-based generalization to negation as failure.- Inducing integrity constraints from knowledge bases.- Dynamic structuring of lexical knowledge in a reusability scenario.- Efficient memory-limited graph search.- Quality-based terminological reasoning for concept learning.- Task acquisition with a description logic reasoner.- Parallelizing description logics.- Automated termination proofs with measure functions.- What is a skeptical proof?.- Default entailment.- Actions that make you change your mind.- Reasoning about action with typical and atypical effects.- Reasoning about action and change: Actions with abnormal effects.- Temporal logic based on characteristic functions.- Computational properties of qualitative spatial reasoning: First results.- An empirically validated model for computing spatial relations.- Integrating vision and language: Towards automatic description of human movements.","",""
1,"Y. Xiang, B. Chaib-draa","Advances in artificial intelligence : 16th Conference of the Canadian Society for Computational Studies of Intelligence, AI 2003, Halifax, Canada, June 11-13, 2003 : proceedings",2003,"","","","",85,"2022-07-13 09:36:21","","","","",,,,,1,0.05,1,2,19,"Experiences Building a Distributed Sensor Network.- Artificial Intelligence and Human Brain Imaging.- Machine Learning Methods for Computational Proteomics and Beyond.- The Structure Model Interpretation of Wright's NESS Test.- Answer Formulation for Question-Answering.- Patttern-Based AI Scripting Using ScriptEase.- Enumerating the Preconditions of Agent Message Types.- Monadic Memoization towards Correctness-Preserving Reduction of Search.- Searching Solutions in the Crypto-arithmetic Problems: An Adaptive Parallel Genetic Algorithm Approach.- Stochastic Local Search for Multiprocessor Scheduling for Minimum Total Tardiness.- A Graph Based Backtracking Algorithm for Solving General CSPs.- Iterated Robust Tabu Search for MAX-SAT.- Scaling and Probabilistic Smoothing: Dynamic Local Search for Unweighted MAX-SAT.- A Comparison of Consistency Propagation Algorithms in Constraint Optimization.- Discovering Temporal/Causal Rules: A Comparison of Methods.- Selective Transfer of Task Knowledge Using Stochastic Noise.- Efficient Mining of Indirect Associations Using HI-Mine.- Case Authoring from Text and Historical Experiences.- Session Boundary Detection for Association Rule Learning Using n-Gram Language Models.- Negotiating Exchanges of Private Information for Web Service Eligibility.- Post-supervised Template Induction for Dynamic Web Sources.- Summarizing Web Sites Automatically.- Cycle-Cutset Sampling for Bayesian Networks.- Learning First-Order Bayesian Networks.- AUC: A Better Measure than Accuracy in Comparing Learning Algorithms.- Model-Based Least-Squares Policy Evaluation.- DIAGAL: A Tool for Analyzing and Modelling Commitment-Based Dialogues between Agents.- Situation Event Logic for Early Validation of Multi-Agent Systems.- Understanding ""Not-Understood"": Towards an Ontology of Error Conditions for Agent Communication.- An Improved Ant Colony Optimisation Algorithm for the 2D HP Protein Folding Problem.- Hybrid Randomised Neighbourhoods Improve Stochastic Local Search for DNA Code Design.- A Strategy for Improved Satisfaction of Selling Software Agents in E-Commerce.- Pre-negotiations over Services - A Framework for Evaluation.- Formal Theory for Describing Action Concepts in Terminological Knowledge Bases.- Improving User-Perceived QoS in Mobile Ad Hoc Networks Using Decision Rules Induction.- Risk Neutral Calibration of Classifiers.- Search Bound Strategies for Rule Mining by Iterative Deepening.- Methods for Mining Frequent Sequential Patterns.- Learning by Discovering Conflicts.- Enhancing Caching in Distributed Databases Using Intelligent Polytree Representations.- Feature Selection Strategies for Text Categorization.- Learning General Graphplan Memos through Static Domain Analysis.- Classification Automaton and Its Construction Using Learning.- A Genetic K-means Clustering Algorithm Applied to Gene Expression Data.- Explanation-Oriented Association Mining Using a Combination of Unsupervised and Supervised Learning Algorithms.- Motion Recognition from Video Sequences.- Noun Sense Disambiguation with WordNet for Software Design Retrieval.- Not as Easy as It Seems: Automating the Construction of Lexical Chains Using Roget's Thesaurus.- The Importance of Fine-Grained Cue Phrases in Scientific Citations.- Fuzzy C-Means Clustering of Web Users for Educational Sites.- Re-using Web Information for Building Flexible Domain Knowledge.- A New Inference Axiom for Probabilistic Conditional Independence.- Probabilistic Reasoning for Meal Planning in Intelligent Fridges.- Probabilistic Reasoning in Bayesian Networks: A Relational Database Approach.- Fundamental Issue of Naive Bayes.- The Virtual Driving Instructor Creating Awareness in a Multiagent System.- Multi-attribute Exchange Market: Theory and Experiments.- Agent-Based Online Trading System.- On the Applicability of L-systems and Iterated Function Systems for Grammatical Synthesis of 3D Models.- An Unsupervised Clustering Algorithm for Intrusion Detection.- Dueling CSP Representations: Local Search in the Primal versus Dual Constraint Graph.- A Quick Look at Methods for Mining Long Subsequences.- Back to the Future: Changing the Direction of Time to Discover Causality.- Learning Coordination in RoboCupRescue.- Accent Classification Using Support Vector Machine and Hidden Markov Model.- A Neural Network Based Approach to the Artificial Aging of Facial Images.- Adaptive Negotiation for Agent Based Distributed Manufacturing Scheduling.- Multi-agent System Architecture for Tracking Moving Objects.","",""
2,"B. Orchard, Chunsheng Yang, Moonis Ali","Innovations in applied artificial intelligence : 17th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2004, Ottawa, Canada, May 17-20, 2004 : proceedings",2004,"","","","",86,"2022-07-13 09:36:21","","","","",,,,,2,0.11,1,3,18,"Invited Contributions.- Applications of Knowledge Discovery.- Spoken Language Communication with Machines: The Long and Winding Road from Research to Business.- Computer Vision.- Motion-Based Stereovision Method with Potential Utility in Robot Navigation.- Object Tracking Using Mean Shift and Active Contours.- Place Recognition System from Long-Term Observations.- Real-Time People Localization and Tracking Through Fixed Stereo Vision.- Face Recognition by Kernel Independent Component Analysis.- Head Detection of the Car Occupant Based on Contour Models and Support Vector Machines.- A Morphological Proposal for Vision-Based Path Planning.- A New Video Surveillance System Employing Occluded Face Detection.- Image Analysis.- Intelligent Vocal Cord Image Analysis for Categorizing Laryngeal Diseases.- Keyword Spotting on Hangul Document Images Using Two-Level Image-to-Image Matching.- Robust Character Segmentation System for Korean Printed Postal Images.- Speech Recognition.- Case Based Reasoning Using Speech Data for Clinical Assessment.- Feature-Table-Based Automatic Question Generation for Tree-Based State Tying: A Practical Implementation.- Speeding Up Dynamic Search Methods in Speech Recognition.- Robotics.- Conscious Robot That Distinguishes Between Self and Others and Implements Imitation Behavior.- Distance-Based Dynamic Interaction of Humanoid Robot with Multiple People.- Movement Prediction from Real-World Images Using a Liquid State Machine.- Robot Competition Using Gesture Based Interface.- Agents.- Agent Support for a Grid-Based High Energy Physics Application.- Feasibility of Multi-agent Simulation for the Trust and Tracing Game.- Multi-agent Support for Distributed Engineering Design.- Reliable Multi-agent Systems with Persistent Publish/Subscribe Messaging.- A Strategy-Proof Mechanism Based on Multiple Auction Support Agents.- Automated Teleoperation of Web-Based Devices Using Semantic Web Services.- Context Awarable Self-configuration System for Distributed Resource Management.- A Decision Support System for Inventory Control Using Planning and Distributed Agents.- Planning.- Controlling Complex Physical Systems Through Planning and Scheduling Integration.- Plan Execution in Dynamic Environments.- Structural Advantages for Ant Colony Optimisation Inherent in Permutation Scheduling Problems.- Incrementally Scheduling with Qualitative Temporal Information.- New Upper Bounds for the Permutation Flowshop Scheduling Problem.- R-Tree Representations of Disaster Areas Based on Probabilistic Estimation.- Human-Computer Interaction and Natural Language Processing.- AI/NLP Technologies Applied to Spacecraft Mission Design.- Automatic Word Spacing in Korean for Small Memory Devices.- Generating Personalized Tourist Map Descriptions.- Haptic Fruition of 3D Virtual Scene by Blind People.- Ontology-Based Natural Language Parser for E-Marketplaces.- Towards Effective Adaptive Information Filtering Using Natural Language Dialogs and Search-Driven Agents.- Towards Minimization of Test Sets for Human-Computer Systems.- Discovering Learning Paths on a Domain Ontology Using Natural Language Interaction.- A Geometric Approach to Automatic Description of Iconic Scenes.- Man-Machine Interface of a Support System for Analyzing Open-Ended Questionnaires.- Reasoning.- A Holistic Approach to Test-Driven Model Checking.- Inferring Definite-Clause Grammars to Express Multivariate Time Series.- Obtaining a Bayesian Map for Data Fusion and Failure Detection Under Uncertainty.- Event Handling Mechanism for Retrieving Spatio-temporal Changes at Various Detailed Level.- Fault Localization Based on Abstract Dependencies.- Freeway Traffic Qualitative Simulation.- LEADSTO: A Language and Environment for Analysis of Dynamics by SimulaTiOn.- Prediction-Based Diagnosis and Loss Prevention Using Model-Based Reasoning.- Machine Learning.- An Algorithm Based on Counterfactuals for Concept Learning in the Semantic Web.- Classification of Ophthalmologic Images Using an Ensemble of Classifiers.- Comparison of Extreme Learning Machine with Support Vector Machine for Text Classification.- Endoscopy Images Classification with Kernel Based Learning Algorithms.- Local Bagging of Decision Stumps.- Methods for Classifying Spot Welding Processes: A Comparative Study of Performance.- Minimum Spanning Trees in Hierarchical Multiclass Support Vector Machines Generation.- One-Class Classifier for HFGWR Ship Detection Using Similarity-Dissimilarity Representation.- Improving the Readability of Decision Trees Using Reduced Complexity Feature Extraction.- Intelligent Bayesian Classifiers in Network Intrusion Detection.- Data Mining.- Analyzing Multi-level Spatial Association Rules Through a Graph-Based Visualization.- Data Mining for Decision Support: An Application in Public Health Care.- A Domain-Independent Approach to Discourse-Level Knowledge Discovery from Texts.- An Efficient Subsequence Matching Method Based on Index Interpolation.- A Meteorological Conceptual Modeling Approach Based on Spatial Data Mining and Knowledge Discovery.- Mining Generalized Association Rules on Biomedical Literature.- Mining Information Extraction Rules from Datasheets Without Linguistic Parsing.- An Ontology-Supported Data Preprocessing Technique for Real-Life Databases.- Genetic Algorithms.- A Fuzzy Genetic Algorithm for Real-World Job Shop Scheduling.- Pareto-Optimal Hardware for Digital Circuits Using SPEA.- Application of a Genetic Algorithm to Nearest Neighbour Classification.- Applying Genetic Algorithms for Production Scheduling and Resource Allocation. Special Case: A Small Size Manufacturing Company.- An Efficient Genetic Algorithm for TSK-Type Neural Fuzzy Identifier Design.- Hardware Architecture for Genetic Algorithms.- Node-Depth Encoding for Evolutionary Algorithms Applied to Multi-vehicle Routing Problem.- Novel Approach to Optimize Quantitative Association Rules by Employing Multi-objective Genetic Algorithm.- Neural Networks.- GMDH-Type Neural Network Modeling in Evolutionary Optimization.- Predicting Construction Litigation Outcome Using Particle Swarm Optimization.- Self-organizing Radial Basis Function Network Modeling for Robot Manipulator.- A SOM Based Approach for Visualization of GSM Network Performance Data.- Using an Artificial Neural Network to Improve Predictions of Water Levels Where Tide Charts Fail.- Canonical Decision Model Construction by Extracting the Mapping Function from Trained Neural Networks.- Detecting Fraud in Mobile Telephony Using Neural Networks.- An Intelligent Medical Image Understanding Method Using Two-Tier Neural Network Ensembles.- Decision Support and Heuristic Search.- The Coordination of Parallel Search with Common Components.- A Decision Support Tool Coupling a Causal Model and a Multi-objective Genetic Algorithm.- Emergent Restructuring of Resources in Ant Colonies: A Swarm-Based Approach to Partitioning.- The Probabilistic Heuristic In Local (PHIL) Search Meta-strategy.- Search on Transportation Network for Location-Based Service.- A Specification Language for Organisational Performance Indicators.- A New Crowded Comparison Operator in Constrained Multiobjective Optimization for Capacitors Sizing and Siting in Electrical Distribution Systems.- A Two-Phase Backbone-Based Search Heuristic for Partial MAX-SAT - An Initial Investigation.- Fuzzy Logic.- An Algorithm for Peer Review Matching Using Student Profiles Based on Fuzzy Classification and Genetic Algorithms.- Pose-Invariant Face Detection Using Edge-Like Blob Map and Fuzzy Logic.- A Fuzzy Logic-Based Approach for Detecting Shifting Patterns in Cross-Cultural Data.- Minimal Knowledge Anonymous User Profiling for Personalized Services.- Knowledge Management.- Formal Goal Generation for Intelligent Control Systems.- MoA: OWL Ontology Merging and Alignment Tool for the Semantic Web.- Optimizing RDF Storage Removing Redundancies: An Algorithm.- Complementing Search Engines with Text Mining.- A Decision Support Approach to Modeling Trust in Networked Organizations.- An Integrated Approach to Rating and Filtering Web Content.- Applications.- Collaborative Case-Based Preference Elicitation.- Complex Knowledge in the Environmental Domain: Building Intelligent Architectures for Water Management.- An Expert System for the Oral Anticoagulation Treatment.- Formal Verification of Control Software: A Case Study.- GRAPE: An Expert Review Assignment Component for Scientific Conference Management Systems.- A Nurse Scheduling System Based on Dynamic Constraint Satisfaction Problem.- A Semi-autonomous Wheelchair with HelpStar.- ST-Modal Logic to Correlate Traffic Alarms on Italian Highways: Project Overview and Example Installations.- Train Rescheduling Algorithm Which Minimizes Passengers' Dissatisfaction.- Case-Based Reasoning for Financial Prediction.- The Generation of Automated Learner Feedback Based on Individual Proficiency Levels.- A Geographical Virtual Laboratory for the Recomposition of Fragments.- A Meta-level Architecture for Strategic Reasoning in Naval Planning.- A Support Method for Qualitative Simulation-Based Learning System.","",""
1,"J. Delgado-Frias, W. Moore","A wafer-scale architecture for artificial intelligence",1989,"","","","",87,"2022-07-13 09:36:21","","10.1109/WAFER.1989.47543","","",,,,,1,0.03,1,2,33,"The architecture presented exploits the advantages of wafer-scale integration technology and has a defect-tolerant scheme to overcome silicon defects. It is in principle a two-dimensional array that is suited to process semantic network knowledge bases. The defect-tolerance approach is based on a combination of hardware redundancy and robust algorithms run on the architecture. The application that is presented here is the scene labeling that is used in computer vision. Due to the robustness of the scene labeling algorithms the machine can tolerate some hardware faults at run time.<<ETX>>","",""
1,"Tom Gedeon, L. Fung","AI 2003 : advances in artificial intelligence : 16th Australian Conference on AI, Perth, Australia, December 3-5, 2003 : proceedings",2003,"","","","",88,"2022-07-13 09:36:21","","","","",,,,,1,0.05,1,2,19,"Keynote Papers.- Discovery of Emerging Patterns and Their Use in Classification.- Robot Soccer: Science or Just Fun and Games?.- On How to Learn from a Stochastic Teacher or a Stochastic Compulsive Liar of Unknown Identity.- Multimedia Analysis and Synthesis.- Ontology.- Modelling Message Handling System.- A New Approach for Concept-Based Web Search.- Representing the Spatial Relations in the Semantic Web Ontologies.- Inductive Construction of Ontologies from Formal Concept Analysis.- Problem Solving.- Dynamic Variable Filtering for Hard Random 3-SAT Problems.- A Proposal of an Efficient Crossover Using Fitness Prediction and Its Application.- A New Hybrid Genetic Algorithm for the Robust Graph Coloring Problem.- Estimating Problem Metrics for SAT Clause Weighting Local Search.- Knowledge Discovery and Data Mining I.- Information Extraction via Path Merging.- Natural Language Agreement Description for Reversible Grammars.- Token Identification Using HMM and PPM Models.- Korean Compound Noun Term Analysis Based on a Chart Parsing Technique.- Knowledge Discovery and Data Milling II.- A Language Modeling Approach to Search Distributed Text Databases.- Combining Multiple Host-Based Detectors Using Decision Tree.- Association Rule Discovery with Unbalanced Class Distributions.- Efficiently Mining Frequent Patterns from Dense Datasets Using a Cluster of Computers.- Expert Systems.- Weighted MCRDR: Deriving Information about Relationships between Classifications in MCRDR.- Fuzzy Cognitive Map Learning Based on Nonlinear Hebbian Rule.- MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes.- Selection of Parameters in Building Fuzzy Decision Trees.- Neural Networks Applications.- Tool Condition Monitoring in Drilling Using Artificial Neural Networks.- Software Verification of Redundancy in Neuro-Evolutionary Robotics.- A Firearm Identification System Based on Neural Network.- Predicting the Australian Stock Market Index Using Neural Networks Exploiting Dynamical Swings and Intermarket Influences.- Belief Revisioii and Theorem Proving.- A Tableaux System for Deontic Interpreted Systems.- Decidability of Propositionally Quantified Logics of Knowledge.- Some Logics of Belief and Disbelief.- Axiomatic Analysis of Negotiation Protocols.- Reasoning and Logic.- A Probabilistic Line Breaking Algorithm.- Semiring-Valued Satisfiability.- A Defeasible Logic of Policy-Based Intention.- Dynamic Agent Ordering in Distributed Constraint Satisfaction Problems.- Machine Learning I.- On Why Discretization Works for Naive-Bayes Classifiers.- Adjusting Dependence Relations for Semi-Lazy TAN Classifiers.- Reduction of Non Deterministic Automata for Hidden Markov Model Based Pattern Recognition Applications.- Unsupervised Learning of Correlated Multivariate Gaussian Mixture Models Using MML.- AI Applications.- Cooperative Learning in Self-Organizing E-Learner Communities Based on a Multi-Agents Mechanism.- The Effects of Material, Tempo and Search Depth on Win-Loss Ratios in Chess.- Using Multiple Classification Ripple Down Rules for Intelligent Tutoring System's Knowledge Acquisition.- Model-Based Reinforcement Learning for Alternating Markov Games.- Neural Networks.- HLabelSOM: Automatic Labelling of Self Organising Maps toward Hierarchical Visualisation for Information Retrieval.- Using Images to Compare Two Constructive Network Techniques.- Pareto Neuro-Ensembles.- Predicting the Distribution of Discrete Spatial Events Using Artificial Neural Networks.- Intelligent Agents.- Learning Action Selection Network of Intelligent Agent.- A Dynamic Self-Organizing E-Learner Communities with Improved Multi-agent Matchmaking Algorithm.- Learning to Survive: Increased Learning Rates by Communication in a Multi-agent System.- An Infrastructure for Agent Collaboration in Open Environments.- Computer Vision.- Fingerprint Images Segmentation Using Two Stages Coarse to Fine Discrimination Technique.- Automatic Fingerprint Center Point Determination by Using Modified Directional Field and Morphology.- Convolutional Neural Networks for Image Processing: An Application in Robot Vision.- Towards Automated Creation of Image Interpretation Systems.- AI & Medical Applications.- Dealing with Decision Costs in CBR in Medical Applications.- A Case Study in Feature Invention for Breast Cancer Diagnosis Using X-Ray Scatter Images.- Effectiveness of A Direct Speech Transform Method Using Inductive Learning from Laryngectomee Speech to Normal Speech.- Machine Learning II.- Robustness for Evaluating Rule's Generalization Capability in Data Mining.- Choosing Learning Algorithms Using Sign Tests with High Replicability.- Evaluating a Nearest-Neighbor Method to Substitute Continuous Missing Values.- Single-Class Classification Augmented with Unlabeled Data: A Symbolic Approach.- Machilie Learning and Language.- C3: A New Learning Scheme to Improve Classification of Rare Category Emails.- A New Approach for Scientific Citation Classification Using Cue Phrases.- Automatic Dialogue Segmentation Using Discourse Chunking.- Artificial Intelligence I.- On Using Prototype Reduction Schemes and Classifier Fusion Strategies to Optimize Kernel-Based Nonlinear Subspace Methods.- Noise Tolerance of EP-Based Classifiers.- Guided Operators for a Hyper-Heuristic Genetic Algorithm.- AI \& Business.- Translating Novelty of Business Model into Terms of Modal Logics.- An eNegotiation Framework.- Teaching Computational Intelligent Techniques with Real-Life Problems in Stock Trading.- Soft Computing.- Finding Optimal Architectures and Weights for ANN: A Combined Hierarchical Approach.- Race Car Chassis Tuning Using Artificial Neural Networks.- Applications of Soft Computing for Musical Instrument Classification.- Nonlinear Time Series Prediction Based on Lyapunov Theory-Based Fuzzy Neural Network and Multiobjective Genetic Algorithm.- A Unified Stochastic Architecture for Spoken Dialogue Systems.- Language Understanding.- Evaluating Corpora for Named Entity Recognition Using Character-Level Features.- Active Learning: Applying RinSCut Thresholding Strategy to Uncertainty Sampling.- The Effect of Evolved Attributes on Classification Algorithms.- Semi-Automatic Construction of Metadata from a Series of Web Documents.- Theory.- Constructive Plausible Logic Is Relatively Consistent.- Heuristic Search Algorithms Based on Symbolic Data Structures.- BN+BN: Behavior Network with Bayesian Network for Intelligent Agent.- Effectiveness of Syntactic Information for Document Classification.- Off-Line Signature Verification and Forgery Detection System Based on Fuzzy Modeling.- Artificial Intelligence II.- Case Study: A Course Advisor Expert System.- Applications of the Ecological Visualization System Using Artificial Neural Network and Mathematical Analysis.- Dynamic Games to Assess Network Value and Performance.- Design and Implementation of an Intelligent Information Infrastructure.- MML Classification of Music Genres.","",""
376,"J. Serrà, Dídac Surís, M. Miron, Alexandros Karatzoglou","Overcoming catastrophic forgetting with hard attention to the task",2018,"","","","",89,"2022-07-13 09:36:21","","","","",,,,,376,94.00,94,4,4,"Catastrophic forgetting occurs when a neural network loses the information learned in a previous task after training on subsequent tasks. This problem remains a hurdle for artificial intelligence systems with sequential learning capabilities. In this paper, we propose a task-based hard attention mechanism that preserves previous tasks' information without affecting the current task's learning. A hard attention mask is learned concurrently to every task, through stochastic gradient descent, and previous masks are exploited to condition such learning. We show that the proposed mechanism is effective for reducing catastrophic forgetting, cutting current rates by 45 to 80%. We also show that it is robust to different hyperparameter choices, and that it offers a number of monitoring capabilities. The approach features the possibility to control both the stability and compactness of the learned knowledge, which we believe makes it also attractive for online learning or network compression applications.","",""
6,"A. Salem, S. Parusheva","Exploiting the knowledge engineering paradigms for designing smart learning systems",2018,"","","","",90,"2022-07-13 09:36:21","","10.15587/1729-4061.2018.128410","","",,,,,6,1.50,3,2,4,"Knowledge engineering (KE) is a subarea of artificial intelligence (AI). Recently, KE paradigms have become more widespread within the fields of smart education and learning. Developing of Smart learning Systems (SLS) is very difficult from the technological perspective and a challenging task. In this paper, three KE paradigms, namely: case-based reasoning, data mining, and intelligent agents are discussed. This article demonstrates how SLS can take advantage of the innovative KE paradigms. Therefore, the paper addresses the pros of such smart computing approaches for the industry of SLS. Moreover, we concentrate our discussion on the challenges faced by knowledge engineers and software developers in developing and deploying efficient and robust SLS. Overall, this study introduces the reader the KE techniques, approaches and algorithms currently in use and the open research issues in designing the smart learning systems.","",""
51,"A. Garcez, L. Lamb","Neurosymbolic AI: The 3rd Wave",2020,"","","","",91,"2022-07-13 09:36:21","","","","",,,,,51,25.50,26,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",92,"2022-07-13 09:36:21","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
0,"Stefan Zwicklbauer","Robust Entity Linking in Heterogeneous Domains",2017,"","","","",93,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,5,"Entity Linking is the task of mapping terms in arbitrary documents to entities in a knowledge base by identifying the correct semantic meaning. It is applied in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question and Answering. Most existing Entity Linking systems were optimized for specific domains (e.g., general domain, biomedical domain), knowledge base types (e.g., DBpedia, Wikipedia), or document structures (e.g., tables) and types (e.g., news articles, tweets). This led to very specialized systems that lack robustness and are only applicable for very specific tasks. In this regard, this work focuses on the research and development of a robust Entity Linking system in terms of domains, knowledge base types, and document structures and types.    To create a robust Entity Linking system, we first analyze the following three crucial components of an Entity Linking algorithm in terms of robustness criteria: (i) the underlying knowledge base, (ii) the entity relatedness measure, and (iii) the textual context matching technique. Based on the analyzed components, our scientific contributions are three-fold. First, we show that a federated approach leveraging knowledge from various knowledge base types can significantly improve robustness in Entity Linking systems. Second, we propose a new state-of-the-art, robust entity relatedness measure for topical coherence computation based on semantic entity embeddings. Third, we present the neural-network-based approach Doc2Vec as a textual context matching technique for robust Entity Linking.    Based on our previous findings and outcomes, our main contribution in this work is DoSeR (Disambiguation of Semantic Resources). DoSeR is a robust, knowledge-base-agnostic Entity Linking framework that extracts relevant entity information from multiple knowledge bases in a fully automatic way. The integrated algorithm represents a collective, graph-based approach that utilizes semantic entity and document embeddings for entity relatedness and textual context matching computation. Our evaluation shows, that DoSeR achieves state-of-the-art results over a wide range of different document structures (e.g., tables), document types (e.g., news documents) and domains (e.g., general domain, biomedical domain). In this context, DoSeR outperforms all other (publicly available) Entity Linking algorithms on most data sets.","",""
11,"Monireh Ebrahimi, Aaron Eberhart, Federico Bianchi, P. Hitzler","Towards bridging the neuro-symbolic gap: deep deductive reasoners",2021,"","","","",94,"2022-07-13 09:36:21","","10.1007/S10489-020-02165-6","","",,,,,11,11.00,3,4,1,"","",""
203,"P. Mirowski, M. Grimes, Mateusz Malinowski, K. Hermann, Keith Anderson, Denis Teplyashin, K. Simonyan, K. Kavukcuoglu, Andrew Zisserman, R. Hadsell","Learning to Navigate in Cities Without a Map",2018,"","","","",95,"2022-07-13 09:36:21","","","","",,,,,203,50.75,20,10,4,"Navigating through unstructured environments is a basic capability of intelligent creatures, and thus is of fundamental interest in the study and development of artificial intelligence. Long-range navigation is a complex cognitive task that relies on developing an internal representation of space, grounded by recognisable landmarks and robust visual processing, that can simultaneously support continuous self-localisation (""I am here"") and a representation of the goal (""I am going there""). Building upon recent research that applies deep reinforcement learning to maze navigation problems, we present an end-to-end deep reinforcement learning approach that can be applied on a city scale. Recognising that successful navigation relies on integration of general policies with locale-specific knowledge, we propose a dual pathway architecture that allows locale-specific features to be encapsulated, while still enabling transfer to multiple cities. We present an interactive navigation environment that uses Google StreetView for its photographic content and worldwide coverage, and demonstrate that our learning method allows agents to learn to navigate multiple cities and to traverse to target destinations that may be kilometres away. The project webpage this http URL contains a video summarising our research and showing the trained agent in diverse city environments and on the transfer task, the form to request the StreetLearn dataset and links to further resources. The StreetLearn environment code is available at this https URL","",""
4,"Fatmah Baothman","An Intelligent Big Data Management System Using Haar Algorithm-Based Nao Agent Multisensory Communication",2021,"","","","",96,"2022-07-13 09:36:21","","10.1155/2021/9977751","","",,,,,4,4.00,4,1,1,"Artificial intelligence (AI) is progressively changing techniques of teaching and learning. In the past, the objective was to provide an intelligent tutoring system without intervention from a human teacher to enhance skills, control, knowledge construction, and intellectual engagement. This paper proposes a definition of AI focusing on enhancing the humanoid agent Nao’s learning capabilities and interactions. The aim is to increase Nao intelligence using big data by activating multisensory perceptions such as visual and auditory stimuli modules and speech-related stimuli, as well as being in various movements. The method is to develop a toolkit by enabling Arabic speech recognition and implementing the Haar algorithm for robust image recognition to improve the capabilities of Nao during interactions with a child in a mixed reality system using big data. The experiment design and testing processes were conducted by implementing an AI principle design, namely, the three-constituent principle. Four experiments were conducted to boost Nao’s intelligence level using 100 children, different environments (class, lab, home, and mixed reality Leap Motion Controller (LMC). An objective function and an operational time cost function are developed to improve Nao’s learning experience in different environments accomplishing the best results in 4.2 seconds for each number recognition. The experiments’ results showed an increase in Nao’s intelligence from 3 to 7 years old compared with a child’s intelligence in learning simple mathematics with the best communication using a kappa ratio value of 90.8%, having a corpus that exceeded 390,000 segments, and scoring 93% of success rate when activating both auditory and vision modules for the agent Nao. The developed toolkit uses Arabic speech recognition and the Haar algorithm in a mixed reality system using big data enabling Nao to achieve a 94% success learning rate at a distance of 0.09 m; when using LMC in mixed reality, the hand sign gestures recorded the highest accuracy of 98.50% using Haar algorithm. The work shows that the current work enabled Nao to gradually achieve a higher learning success rate as the environment changes and multisensory perception increases. This paper also proposes a cutting-edge research work direction for fostering child-robots education in real time.","",""
4,"S. A. Borz","Development of a Modality-Invariant Multi-Layer Perceptron to Predict Operational Events in Motor-Manual Willow Felling Operations",2021,"","","","",97,"2022-07-13 09:36:21","","10.3390/F12040406","","",,,,,4,4.00,4,1,1,"Motor-manual operations are commonly implemented in the traditional and short rotation forestry. Deep knowledge of their performance is needed for various strategic, tactical and operational decisions that rely on large amounts of data. To overcome the limitations of traditional analytical methods, Artificial Intelligence (AI) has been lately used to deal with various types of signals and problems to be solved. However, the reliability of AI models depends largely on the quality of the signals and on the sensing modalities used. Multimodal sensing was found to be suitable in developing AI models able to learn time and location-related data dependencies. For many reasons, such as the uncertainty of preserving the sensing location and the inter- and intra-variability of operational conditions and work behavior, the approach is particularly useful for monitoring motor-manual operations. The main aim of this study was to check if the use of acceleration data sensed at two locations on a brush cutter could provide a robust AI model characterized by invariance to data sensing location. As such, a Multi-Layer Perceptron (MLP) with backpropagation was developed and used to learn and classify operational events from bimodally-collected acceleration data. The data needed for training and testing was collected in the central part of Romania. Data collection modalities were treated by fusion in the training dataset, then four single-modality testing datasets were used to check the performance of the model on a binary classification problem. Fine tuning of the regularization parameters (α term) has led to acceptable testing and generalization errors of the model measured as the binary cross-entropy (log loss). Irrespective of the hyperparameters’ tunning strategy, the classification accuracy (CA) was found to be very high, in many cases approaching 100%. However, the best models were those characterized by α set at 0.0001 and 0.1, for which the CA in the test datasets ranged from 99.1% to 99.9% and from 99.5% to 99.9%, respectively. Hence, data fusion in the training set was found to be a good strategy to build a robust model, able to deal with data collected by single modalities. As such, the developed MLP model not only removes the problem of sensor placement in such applications, but also automatically classifies the events in the time domain, enabling the integration of data collection, handling and analysis in a simple less resource-demanding workflow, and making it a feasible alternative to the traditional approach to the problem.","",""
4,"Usef Paledi, E. Allahkarami, B. Rezai, Mohammad Reza Aslani","Selectivity index and separation efficiency prediction in industrial magnetic separation process using a hybrid neural genetic algorithm",2021,"","","","",98,"2022-07-13 09:36:21","","10.1007/S42452-021-04361-6","","",,,,,4,4.00,1,4,1,"","",""
3,"Sijie Yang, Fei Zhu, Xinghong Ling, QUAN LIU, Peiyao Zhao","Intelligent Health Care: Applications of Deep Learning in Computational Medicine",2021,"","","","",99,"2022-07-13 09:36:21","","10.3389/fgene.2021.607471","","",,,,,3,3.00,1,5,1,"With the progress of medical technology, biomedical field ushered in the era of big data, based on which and driven by artificial intelligence technology, computational medicine has emerged. People need to extract the effective information contained in these big biomedical data to promote the development of precision medicine. Traditionally, the machine learning methods are used to dig out biomedical data to find the features from data, which generally rely on feature engineering and domain knowledge of experts, requiring tremendous time and human resources. Different from traditional approaches, deep learning, as a cutting-edge machine learning branch, can automatically learn complex and robust feature from raw data without the need for feature engineering. The applications of deep learning in medical image, electronic health record, genomics, and drug development are studied, where the suggestion is that deep learning has obvious advantage in making full use of biomedical data and improving medical health level. Deep learning plays an increasingly important role in the field of medical health and has a broad prospect of application. However, the problems and challenges of deep learning in computational medical health still exist, including insufficient data, interpretability, data privacy, and heterogeneity. Analysis and discussion on these problems provide a reference to improve the application of deep learning in medical health.","",""
2,"Vuong Van Pham, E. Fathi, Fatemeh Belyadi","New Hybrid Approach for Developing Automated Machine Learning Workflows: A Real Case Application in Evaluation of Marcellus Shale Gas Production",2021,"","","","",100,"2022-07-13 09:36:21","","10.3390/fuels2030017","","",,,,,2,2.00,1,3,1,"The success of machine learning (ML) techniques implemented in different industries heavily rely on operator expertise and domain knowledge, which is used in manually choosing an algorithm and setting up the specific algorithm parameters for a problem. Due to the manual nature of model selection and parameter tuning, it is impossible to quantify or evaluate the quality of this manual process, which in turn limits the ability to perform comparison studies between different algorithms. In this study, we propose a new hybrid approach for developing machine learning workflows to help automated algorithm selection and hyperparameter optimization. The proposed approach provides a robust, reproducible, and unbiased workflow that can be quantified and validated using different scoring metrics. We have used the most common workflows implemented in the application of artificial intelligence (AI) and ML in engineering problems including grid/random search, Bayesian search and optimization, genetic programming, and compared that with our new hybrid approach that includes the integration of Tree-based Pipeline Optimization Tool (TPOT) and Bayesian optimization. The performance of each workflow is quantified using different scoring metrics such as Pearson correlation (i.e., R2 correlation) and Mean Square Error (i.e., MSE). For this purpose, actual field data obtained from 1567 gas wells in Marcellus Shale, with 121 features from reservoir, drilling, completion, stimulation, and operation is tested using different proposed workflows. A proposed new hybrid workflow is then used to evaluate the type well used for evaluation of Marcellus shale gas production. In conclusion, our automated hybrid approach showed significant improvement in comparison to other proposed workflows using both scoring matrices. The new hybrid approach provides a practical tool that supports the automated model and hyperparameter selection, which is tested using real field data that can be implemented in solving different engineering problems using artificial intelligence and machine learning. The new hybrid model is tested in a real field and compared with conventional type wells developed by field engineers. It is found that the type well of the field is very close to P50 predictions of the field, which shows great success in the completion design of the field performed by field engineers. It also shows that the field average production could have been improved by 8% if shorter cluster spacing and higher proppant loading per cluster were used during the frac jobs.","",""
2,"W. El-Shafai, A. Ali, E. El-Rabaie, N. Soliman, A. Algarni, F. El-Samie","Automated COVID-19 Detection Based on Single-Image Super-Resolution and CNN Models",2022,"","","","",101,"2022-07-13 09:36:21","","10.32604/cmc.2022.018547","","",,,,,2,2.00,0,6,1,"In developing countries, medical diagnosis is expensive and time consuming. Hence, automatic diagnosis can be a good cheap alternative. This task can be performed with artificial intelligence tools such as deep Convolutional Neural Networks (CNNs). These tools can be used on medical images to speed up the diagnosis process and save the efforts of specialists. The deep CNNs allow direct learning from the medical images. However, the accessibility of classified data is still the largest challenge, particularly in the field of medical imaging. Transfer learning can deliver an effective and promising solution by transferring knowledge from universal object detection CNNs to medical image classification. However, because of the inhomogeneity and enormous overlap in intensity between medical images in terms of features in the diagnosis of Pneumonia and COVID-19, transfer learning is not usually a robust solution. Single-Image Super-Resolution (SISR) can facilitate learning to enhance computer vision functions, apart from enhancing perceptual image consistency. Consequently, it helps in showing the main features of images. Motivated by the challenging dilemma of Pneumonia and COVID-19 diagnosis, this paper introduces a hybrid CNN model, namely SIGTra, to generate super-resolution versions of X-ray and CT images. It depends on a Generative Adversarial Network (GAN) for the super-resolution reconstruction problem. Besides, Transfer learning with CNN (TCNN) is adopted for the classification of images. Three different categories of chest X-ray and CT images can be classified with the proposed model. A comparison study is presented between the proposed SIGTra model and the other related CNN models for COVID-19 detection in terms of precision, sensitivity, and accuracy. © 2021 Tech Science Press. All rights reserved.","",""
1,"G. Villa, S. Romagnoli","Registers and biobanks in ICU and anesthesia.",2022,"","","","",102,"2022-07-13 09:36:21","","10.23736/S0375-9393.22.16208-5","","",,,,,1,1.00,1,2,1,"Anesthesia, perioperative and critical care medicine are specific areas where registries, biobanks and big data are gaining a leading role in increasing knowledge and improving patients' care. The adoption of these robust data infrastructures -aimed at bridling, manipulating, aggregating, and linking patients' multiparametric data- supports anesthesiologists and intensive care physicians in several aspects of bedside practice and clinical research. Indeed, registries-integrated calculators may promote the concept of personalized medicine acting as ""sniffers"", electronic alarm systems, or decision support systems. Artificial intelligence applied to large databases or meta-registries may further increase dramatically this functionality, identify associations among thousands of different and only apparently uncorrelated variables. From a research perspective, large datasets are increasingly mined to create observations about medical care beyond prospective randomized clinical trials enrolling thousands of patients, often only presumably homogeneous ore well-balanced. Registries in this context may effectively explore the association between patients' management and patients' outcomes with a negligible impact on ethical issues, limited costs, and easy management. Finally, registries may promote self-evaluation and continuous quality improvement in the field of perioperative and critical care medicine. In a different way, the role of biobanks primarily relies on translational medical research. These allow rapidly creating pools of biological samples available for epidemiological description, pathophysiological definition, and treatment effectiveness verification, basically acting as an accelerator of knowledge production in critical care and perioperative medicine. Nowadays, registries and biobanks are thus routine tools for anesthesiologists and critical care physicians.","",""
1,"Jian Gu, P. Salza, H. Gall","Assemble Foundation Models for Automatic Code Summarization",2022,"","","","",103,"2022-07-13 09:36:21","","","","",,,,,1,1.00,0,3,1,"Automatic code summarization is beneficial to software development and maintenance since it reduces the burden of manual tasks. Currently, artificial intelligence is undergoing a paradigm shift. The foundation models pretrained on massive data and finetuned to downstream tasks surpass specially customized models. This trend inspired us to consider reusing foundation models instead of learning from scratch. Based on this, we propose a flexible and robust approach for automatic code summarization based on neural networks. We assemble available foundation models, such as CodeBERT and GPT-2, into a single model named AdaMo. Moreover, we utilize Gaussian noise as the simulation of contextual information to optimize the latent representation. Furthermore, we introduce two adaptive schemes from the perspective of knowledge transfer, namely continuous pretraining and intermediate finetuning, and design intermediate stage tasks for general sequence-to-sequence learning. Finally, we evaluate AdaMo against a benchmark dataset for code summarization, by comparing it with state-of-the-art models.","",""
150,"Dipendra Jha, Logan T. Ward, Arindam Paul, W. Liao, A. Choudhary, C. Wolverton, Ankit Agrawal","ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition",2018,"","","","",104,"2022-07-13 09:36:21","","10.1038/s41598-018-35934-y","","",,,,,150,37.50,21,7,4,"","",""
1,"A. Ennouni, Noura Ouled Sihamman, M. A. Sabri, A. Aarab","Analysis and Classification of Plant Diseases Based on Deep Learning",2021,"","","","",105,"2022-07-13 09:36:21","","10.1007/978-3-030-73882-2_12","","",,,,,1,1.00,0,4,1,"","",""
1,"Jan Strohschein, A. Fischbach, Andreas Bunte, Heide Faeskorn-Woyke, N. Moriz, T. Bartz-Beielstein","Cognitive Capabilities for the CAAI in Cyber-Physical Production Systems",2020,"","","","",106,"2022-07-13 09:36:21","","10.1007/s00170-021-07248-3","","",,,,,1,0.50,0,6,2,"","",""
1,"J. Lógó, N. Krausz, V. Potó, A. Barsi","QUALITY ASPECTS OF HIGH-DEFINITION MAPS",2021,"","","","",107,"2022-07-13 09:36:21","","10.5194/isprs-archives-xliii-b4-2021-389-2021","","",,,,,1,1.00,0,4,1,"A self-driving vehicle is one of the most expected inventions in the near future. These vehicles are enabled by several technological developments, like artificial intelligence, robust control, vehicular sensors, and high-speed communication. But beyond all these elements, the essential component is the knowledge about reality. Our profession has answered that question with the development of high-definition (abbreviated as HD) maps. Fully automated driving (also called driverless transportation) must be reliable enough to entrust our lives to the car. This fact indicates that the applied technology and the used map must be of high quality. But how can the quality of such a map be expressed? We are looking for the answer in the current paper. Following Carlo Batini’s idea, the general approach is based on the triumvirate of data sources – quality dimensions – life cycle phases. Data sources cover aerial, terrestrial and mobile mapping products with the available highest technological care; furthermore, onboard vehicular sensing extends the corresponding data sets. Lifecycle phases focus on the production (data collection and processing technologies) expanded by conceptualization (pre-production) and data delivery and use (post-production). Quality dimensions are strongly related to the dimensionality of the data; they can be measured by dimension metrics. The first part of the paper summarizes the applied data collection methodologies, emphasizing the output data. This description contains a summary of the processing mechanism – inevitably characterized by quality indicators. The paper aims to give a complete outline for the quality dimensions; we do not limit the resolution and accuracy dimensions, but other significant clusters like completeness or consistency are also discussed. Because the reality changes are enormous in transportation (vehicles, pedestrians, etc., are moving – even at higher speed) and the newly developing HD maps are expected to be live, actuality is a cardinal quality dimension as well. Vehicular technologies like SENSORIS give an excellent option to the equipped vehicles to download and use maps from the cloud and upload their field observations, opening a new way to maintain the map database. The so established crowd-sourced data collection intensely influences the map quality; therefore, this method generates quality-related issues that are also to be analyzed. The second part of the paper is a case study, where a pilot site close to the university campus was selected. In this area, thousands of images were captured and uploaded into the Mapillary database. Artificial intelligence processes were applied for segmenting, classifying, and evaluating the content of the georeferenced imagery. The map database stores various object categories in the area, for example, pedestrian crossings, traffic signs, or trash cans. All extracted objects are available in georeferenced format, enabling spatial analyses to derive numeric quality indicators. The paper presents the complete results of this study.","",""
1,"M. Dahlbeck","AI and Spinoza: a review of law's conceptual treatment of Lethal Autonomous",2020,"","","","",108,"2022-07-13 09:36:21","","10.1007/S00146-020-01014-X","","",,,,,1,0.50,1,1,2,"","",""
0,"Taehoon Lee","Robust Feature Learning with Deep Neural Networks",2016,"","","","",109,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,6,"Recent advances in machine learning continue to bring us closer to artificial intelligence. In particular, deep learning plays a key role in cutting-edge frameworks such as autonomous driving and game playing. Deep learning refers to a class of multi-layered neural networks, which is rapidly evolving as the amount of data increases, prior knowledge builds up, efficient training schemes are being developed, and high-end hardwares are being build. Currently, deep learning is a state-of-the-art technique for most recognition tasks. As deep neural networks learn many parameters, there has been a variety of attempts to obtain reasonable solutions over a wide search space. In this dissertation, three issues in deep learning are discussed and approaches to solve them with regularization techniques are suggested. First, deep neural networks expose the problem of intrinsic blind spots called adversarial perturbations. Thus, we must construct neural networks that resist the directions of adversarial perturbations by introducing an explicit loss term to minimize the differences between the original and adversarial samples. Second, training restricted Boltzmann machines show limited performance when handling minority samples in class-imbalanced datasets. Our approach addresses this limitation and is combined with a new regularization concept for datasets that have categorical features. Lastly, insufficient data handling is required to be more sophisticated when deep networks learn numerous parameters. Given high-dimensional samples, we must augment datasets with adequate prior knowledge to estimate a high-dimensional distribution. Furthermore, this dissertation shows the first application of deep belief networks to identifying junction splicing signals. Junction prediction is one of the major problems in the field of bioinformatics, and is a starting point to understanding the entire gene expression process. In summary, this dissertation proposes a set of deep learning regularization schemes that can learn the meaningful representation underlying large-scale genomic datasets and image datasets. The effectiveness of these methods was confirmed with a number of experimental studies.","",""
21,"Phillip Odom, Tushar Khot, R. Porter, Sriraam Natarajan","Knowledge-Based Probabilistic Logic Learning",2015,"","","","",110,"2022-07-13 09:36:21","","10.1609/aaai.v29i1.9690","","",,,,,21,3.00,5,4,7,"    Advice giving has been long explored in artificial intelligence to build robust learning algorithms. We consider advice giving in relational domains where the noise is systematic. The advice is provided as logical statements that are then explicitly considered by the learning algorithm at every update. Our empirical evidence proves that human advice can effectively accelerate learning in noisy structured domains where so far humans have been merely used as labelers or as designers of initial structure of the model.   ","",""
0,"Ruben Branco, A. Branco, J. Silva, J. Rodrigues","Commonsense Reasoning: \protect \@normalcr how do Neuro-Symbolic and Neuro-only approaches compare?",2021,"","","","",111,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
0,"Ruben Branco, A. Branco, João Silva, J. Rodrigues","Commonsense Reasoning: How do Neuro-Symbolic and Neuro-only Approaches Compare?",2021,"","","","",112,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
0,"Shamim Akhtar, M. Z. Sujod, Syed Sajjad Hussain Rizvi","A Novel Deep Learning Architecture for Data-Driven Energy Efficiency Management (D2EEM) - Systematic Survey",2021,"","","","",113,"2022-07-13 09:36:21","","10.1109/ICEET53442.2021.9659737","","",,,,,0,0.00,0,3,1,"The Energy Management System (EMS) is the cost-effectiveness, robustness, and flexible approach for energy efficiency management (EEM). Data-Driven Energy Efficiency Management (D2EEM) is a recent advancement in EMS. The D2EEM is the blend of data science and artificial intelligence for EEM. Due to the highly tolerant to the performance plateau and unconstraint to the feature extraction, Deep Learning (DL) facilitates handling big data-driven problems of EEM. To the best of the knowledge, the accurate and robust D2EEM is the pressing need. Moreover, the accurate pre-trained DL network for EEM is not available in the recent literature. In this work, a comprehensive study is presented to devise a D2EEM. Moreover, the architecture is suggested in connection to the research gap.","",""
0,"R. Bettker, Pedro Minini, Gabriel Pereira, J. V. C. Assunção","Towards playing AIs for 7 Wonders: main patterns and strategies for 3-player games",2021,"","","","",114,"2022-07-13 09:36:21","","10.1109/SBGames54170.2021.00029","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) in games may be greatly supported by a robust set of patterns, rules, and strategies that contribute to securing a win. In this work, we made a Knowledge Discovery pipeline - involving data selection, association, classification, and clustering - to successfully identify important factors that help to achieve a win in the board game 7 Wonders, focusing on 3-player matches. Our results show strong patterns and main strategies used by the best players in the world. This knowledge narrows the search for a Nash equilibrium for the game, getting us closer to create a top-tier AI.","",""
0,"Weijie Kang, Junjie Xue, Jiyang Xiao, Haizhen Zhu, Jianfeng Li, Changjun Li","Multimode Generative Adversarial Networks for Sequence Data Generation",2021,"","","","",115,"2022-07-13 09:36:21","","10.1088/1742-6596/1827/1/012209","","",,,,,0,0.00,0,6,1,"As a new type of artificial intelligence technology, generative adversarial network (GAN) has good data understanding and generation capabilities, and has a wide range of application prospects in the fields of image and speech. However, due to the lack of prior knowledge, its training process is less robust and prone to occur the pattern ignore. Its development is restricted to a certain extent, and its application scope still needs to be expanded. To solve the above problems, this paper introduces a knowledge confidence multimode GAN (KC-MGAN) algorithm, calculates the confidence of the input data through the reasoning method, and then puts the confidence and the input data into the GAN system to generate new sample data. During the training process, the confidence of the input data is continuously calculated, while the generated data samples are continuously evaluated. The training process will end until the GAN system reaches a stable condition. Finally, this paper takes the generation of UAV flight trajectory data as an example to verify the effectiveness of the proposed method. Some explorations have been made for the application of data generation and GAN’s training mode with the prior knowledge.","",""
0,"F. Ventura, Salvatore Greco, D. Apiletti, T. Cerquitelli","Trusting deep learning natural-language models via local and global explanations",2022,"","","","",116,"2022-07-13 09:36:21","","10.1007/s10115-022-01690-9","","",,,,,0,0.00,0,4,1,"","",""
18,"Y. Jasim","A Manuscript of Knowledge Representation",2015,"","","","",117,"2022-07-13 09:36:21","","","","",,,,,18,2.57,18,1,7,"This paper describes the Knowledge representation and how it is used in artificial intelligence systems such as (Expert Systems, Hybrid intelligence systems, Neural networks, etc.) to construct a robust systems without any bugs and issues, it also depicts the knowledge representation categories (Implicit and Explicit) and types (Rules, Ontology, Frames, Semantic Networks and Logic), who is the person that deals with knowledge to analyze (Knowledge Engineer), how to build a knowledge base to use in systems, and what are the issues that will face the engineer?","",""
0,"Vacslav Glukhov","Reward is not enough: can we liberate AI from the reinforcement learning paradigm?",2022,"","","","",118,"2022-07-13 09:36:21","","10.2139/ssrn.4024901","","",,,,,0,0.00,0,1,1,"I present arguments against the hypothesis put forward by Silver, Singh, Precup, and Sutton [1]: reward maximization is not enough to explain many activities associated with natural and artificial intelligence including knowledge, learning, perception, social intelligence, evolution, language, generalisation and imitation. I show such reductio ad lucrum has its intellectual origins in the political economy of Homo economicus and substantially overlaps with the radical version of behaviourism. I show why the reinforcement learning paradigm, despite its demonstrable usefulness in some practical application, is an incomplete framework for intelligence – natural and artificial. Complexities of intelligent behaviour are not simply second-order complications on top of reward maximisation. This fact has profound implications for the development of practically usable, smart, safe and robust artificially intelligent agents1.","",""
0,"E. Papagiannidis, Ida Merete Enholm, Chirstian Dremel, Patrick Mikalef, J. Krogstie","Toward AI Governance: Identifying Best Practices and Potential Barriers and Outcomes",2022,"","","","",119,"2022-07-13 09:36:21","","10.1007/s10796-022-10251-y","","",,,,,0,0.00,0,5,1,"","",""
0,"M. Salucci, L. Poli, P. Rocca, A. Massa","Learned Global Optimization for Inverse Scattering Problems - Matching Global Search with Computational Efficiency",2021,"","","","",120,"2022-07-13 09:36:21","","10.1109/tap.2021.3139627","","",,,,,0,0.00,0,4,1,"The computationally-efficient solution of fully non-linear microwave inverse scattering problems (ISPs) is addressed. An innovative System-by-Design (SbD) based method is proposed to enable, for the first time to the best of the authors’ knowledge, an effective, robust, and time-efficient exploitation of an evolutionary algorithm (EA) to perform the global minimization of the data-mismatch cost function. According to the SbD paradigm as suitably applied to ISPs, the proposed approach founds on (i) a smart re-formulation of the ISP based on the definition of a minimum-dimensionality and representative set of degrees-of-freedom (DoFs) and on (ii) the artificial-intelligence (AI)-driven integration of a customized global search technique with a digital twin (DT) predictor based on the Gaussian Process (GP) theory. Representative numerical and experimental results are provided to assess the effectiveness and the efficiency of the proposed approach also in comparison with competitive state-of-the-art inversion techniques.","",""
0,"Zhiqiang Zheng","The Classification of Music and Art Genres under the Visual Threshold of Deep Learning",2022,"","","","",121,"2022-07-13 09:36:21","","10.1155/2022/4439738","","",,,,,0,0.00,0,1,1,"Wireless networks are commonly employed for ambient assisted living applications, and artificial intelligence-enabled event detection and classification processes have become familiar. However, music is a kind of time-series data, and it is challenging to design an effective music genre classification (MGC) system due to a large quantity of music data. Robust MGC techniques necessitate a massive amount of data, which is time-consuming, laborious, and requires expert knowledge. Few studies have focused on the design of music representations extracted directly from input waveforms. In recent times, deep learning (DL) models have been widely used due to their characteristics of automatic extracting advanced features and contextual representation from actual music or processed data. This paper aims to develop a novel deep learning-enabled music genre classification (DLE-MGC) technique. The proposed DLE-MGC technique effectively classifies the music genres into multiple classes by using three subprocesses, namely preprocessing, classification, and hyperparameter optimization. At the initial stage, the Pitch to Vector (Pitch2vec) approach is applied as a preprocessing step where the pitches in the input musical instrument digital interface (MIDI) files are transformed into the vector sequences. Besides, the DLE-MGC technique involves the design of a cat swarm optimization (CSO) with bidirectional long-term memory (BiLSTM) model for the classification process. The DBTMPE technique has gained a moderately increased accuracy of 94.27%, and the DLE-MGC technique has accomplished a better accuracy of 95.87%. The performance validation of the DLE-MGC technique was carried out using the Lakh MIDI music dataset, and the comparative results verified the promising performance of the DLE-MGC technique over current methods.","",""
1,"J. Wolff","The SP Theory of Intelligence as a Foundation for the Development of a General, Human-Level Thinking Machine",2016,"","","","",122,"2022-07-13 09:36:21","","","","",,,,,1,0.17,1,1,6,"This paper summarises how the ""SP theory of intelligence"" and its realisation in the ""SP computer model"" simplifies and integrates concepts across artificial intelligence and related areas, and thus provides a promising foundation for the development of a general, human-level thinking machine, in accordance with the main goal of research in artificial general intelligence.  The key to this simplification and integration is the powerful concept of ""multiple alignment"", borrowed and adapted from bioinformatics. This concept has the potential to be the ""double helix"" of intelligence, with as much significance for human-level intelligence as has DNA for biological sciences.  Strengths of the SP system include: versatility in the representation of diverse kinds of knowledge; versatility in aspects of intelligence (including: strengths in unsupervised learning; the processing of natural language; pattern recognition at multiple levels of abstraction that is robust in the face of errors in data; several kinds of reasoning (including: one-step `deductive' reasoning; chains of reasoning; abductive reasoning; reasoning with probabilistic networks and trees; reasoning with 'rules'; nonmonotonic reasoning and reasoning with default values; Bayesian reasoning with 'explaining away'; and more); planning; problem solving; and more); seamless integration of diverse kinds of knowledge and diverse aspects of intelligence in any combination; and potential for application in several areas (including: helping to solve nine problems with big data; helping to develop human-level intelligence in autonomous robots; serving as a database with intelligence and with versatility in the representation and integration of several forms of knowledge; serving as a vehicle for medical knowledge and as an aid to medical diagnosis; and several more).","",""
13,"Konstantinos N. Blazakis, T. Kapetanakis, G. Stavrakakis","Effective Electricity Theft Detection in Power Distribution Grids Using an Adaptive Neuro Fuzzy Inference System",2020,"","","","",123,"2022-07-13 09:36:21","","10.3390/en13123110","","",,,,,13,6.50,4,3,2,"Electric power grids are a crucial infrastructure for the proper operation of any country and must be preserved from various threats. Detection of illegal electricity power consumption is a crucial issue for distribution system operators (DSOs). Minimizing non-technical losses is a challenging task for the smooth operation of electrical power system in order to increase electricity provider’s and nation’s revenue and to enhance the reliability of electrical power grid. The widespread popularity of smart meters enables a large volume of electricity consumption data to be collected and new artificial intelligence technologies could be applied to take advantage of these data to solve the problem of power theft more efficiently. In this study, a robust artificial intelligence algorithm adaptive neuro fuzzy inference system (ANFIS)—with many applications in many various areas—is presented in brief and applied to achieve more effective detection of electric power theft. To the best of our knowledge, there are no studies yet that involve the application of ANFIS for the detection of power theft. The proposed technique is shown that if applied properly it could achieve very high success rates in various cases of fraudulent activities originating from unauthorized energy usage.","",""
32,"Tatjana V. Sibalija, V. Majstorovic, Z. Miljković","An intelligent approach to robust multi-response process design",2011,"","","","",124,"2022-07-13 09:36:21","","10.1080/00207543.2010.511476","","",,,,,32,2.91,11,3,11,"In order to meet strict customer demands in a global highly-complex industrial sector, it is necessary to design manufacturing processes based on a clear understanding of the customer's requirements and usage of a product, by translating this knowledge into the process parameter design. This paper presents an integrative, general and intelligent approach to the multi-response process design, based on Taguchi's method, multivariate statistical methods and artificial intelligence techniques. The proposed model considers process design in a general case where analytical relations and interdependency in a process are unknown, thus making it applicable to various types of processes, and incorporates customer demands for several (possible correlated) characteristics of a product. The implementation of the suggested approach is presented on a study that discusses the design of a thermosonic copper wire bonding process in the semiconductor industry, for assembly of microelectronic devices used in automotive applications. The results confirm the effectiveness of the approach in the presence of different types of correlated product quality characteristics.","",""
4,"Kai Olav Ellefsen","The Evolution of Learning: Balancing adaptivity and stability in artificial agents",2014,"","","","",125,"2022-07-13 09:36:21","","","","",,,,,4,0.50,4,1,8,"A longstanding challenge in artificial intelligence is to create agents that learn, enabling them to interact with and adapt to a complex and changing world. A better understanding of the evolution of learning may help produce robust and adaptive agents, as well as shed light on open questions about the evolution of learning from biology. Evolutionary computation offers the benefits of precise experimental control, repeatability of experiments and rapid generational turnover – enabling experiments to test hypotheses that would be impossible or extremely time demanding to test in natural studies. The evolution of learning is influenced by the balance between the benefits offered by adaptivity and the costs (disadvantages) individuals pay for learning abilities. Such costs include forgetting previous knowledge, dangers of exploration and maintenance of neural structures for learning. This thesis focuses on how evolution regulates learning capacities to reap the benefits of being adaptive, while minimizing the costs of learning. The regulation of learning capacities is studied along three main axes: regulation through individual lifetimes, regulation within a population facing varying environments and regulation across neural modules. The study of learning regulation within individual lifetimes is inspired by the sensitive periods in learning observed in nature: limited periods within individuals’ lives where learning is temporarily facilitated. Experiments herein demonstrate that sensitive periods can emerge to schedule learning in tasks where there are dependencies between the learning of sub-tasks, and further explore how the flexibility of evolved sensitive periods depends on assumptions about which factors regulate plasticity. On the population level, the evolution of learning efforts is known to be highly dependent on the variability of the environment and the reliability of environmental stimuli. Evolving the innate preferences and learning rates of individuals across a wide range of environmental variability demonstrates that environments changing too rapidly or too slowly discourage the evolution of learning. Further experiments show how independently varying the degrees of environmental stability and stimuli reliability leads to a refinement of this model of learning, which also acknowledges the fact that learning may be disruptive or inefficient when stimuli are not reliable. One cost of learning is the risk of losing old information as new information is gained, a problem known as catastrophic forgetting. Evolving individuals facing a task with potential for catastrophic forgetting, it is demonstrated how the addition of an evolutionary cost of neural connections leads to more modular networks, which forget old skills less when learning a new skill. Together, the findings herein demonstrate several ways to handle the so-called stabilityplasticity dilemma: how can an individual be realized which has the flexibility to adapt without risking unstable behaviors and forgetting of old skills? The findings suggest ways in which evolution may have solved this problem in natural learners, and ways to harness the powers of evolution to mitigate this problem in artificial agents.","",""
40,"Andreas Holzinger, Benjamin Haibe-Kains, I. Jurisica","Why imaging data alone is not enough: AI-based integration of imaging, omics, and clinical data",2019,"","","","",126,"2022-07-13 09:36:21","","10.1007/s00259-019-04382-9","","",,,,,40,13.33,13,3,3,"","",""
799,"R. Brachman, H. Levesque","Readings in Knowledge Representation",1985,"","","","",127,"2022-07-13 09:36:21","","","","",,,,,799,21.59,400,2,37,"From the Publisher:  In Artificial Intelligence, it is often said that the representation of knowledge is the key to the design of robust intelligent systems. In one form or another the principles of Knowledge Representation are fundamental to work in natural language processing, computer vision, knowledge-based expert systems, and other areas. The papers reprinted in this volume have been collected to allow the reader with a general technical background in AI to explore the subtleties of this key subarea. These seminal articles, spanning a quarter-century of research, cover the most important ideas and developments in the representation field. The editors introduce each paper, discuss its relevance and context, and provide an extensive bibliography of other work. Readings in Knowledge Representation is intended to serve as a complete sourcebook for the study of this crucial subject.","",""
1,"S. Tran","Propositional Knowledge Representation and Reasoning in Restricted Boltzmann Machines.",2017,"","","","",128,"2022-07-13 09:36:21","","","","",,,,,1,0.20,1,1,5,"While knowledge representation and reasoning are considered the keys for human-level artificial intelligence, connectionist networks have been shown successful in a broad range of applications due to their capacity for robust learning and flexible inference under uncertainty. The idea of representing symbolic knowledge in connectionist networks has been well-received and attracted much attention from research community as this can establish a foundation for integration of scalable learning and sound reasoning. In previous work, there exist a number of approaches that map logical inference rules with feed-forward propagation of artificial neural networks (ANN). However, the discriminative structure of an ANN requires the separation of input/output variables which makes it difficult for general reasoning where any variables should be inferable. Other approaches address this issue by employing generative models such as symmetric connectionist networks, however, they are difficult and convoluted. In this paper we propose a novel method to represent propositional formulas in restricted Boltzmann machines which is less complex, especially in the cases of logical implications and Horn clauses. An integration system is then developed and evaluated in real datasets which shows promising results.","",""
0,"Jerry D. Smith","Robust knowledge bases (abstract)",1986,"","","","",129,"2022-07-13 09:36:21","","10.1145/324634.325098","","",,,,,0,0.00,0,1,36,"Knowledge representation (KR) has emerged as one of the most important and active fields of investigation within artificial intelligence (AI). It is now clear that significant advances in the application of AI principles to real world problems will require sophisticated knowledge representation schemes. A variety of knowledge structures and techniques for knowledge storage and retrieval have been proposed. Many of these representation techniques are practical only when the knowledge base can exist in primary storage and/or when it is reasonably static. However, many future applications of AI will require management of large, very dynamic knowledge bases. This paper takes as an example a sophisticated tutoring system, i.e., one of greater magnitude than those offered in [Sleeman82]. Such a tutoring system can be developed only at great expense; this implies a need to consider multi-user access, which raises questions about concurrency, recovery, networking, etc. Researchers in the database field have begun to address issues such as concurrency, integrity, recovery, and others; problems that will arise in the long-term development of robust knowledge systems. It will not be possible to handle these problems effectively by introducing memory-management features tailored to large primary storage areas [Balkovich85]. Instead, knowledge systems will have to make efficient use of secondary storage. There are other considerations. A very important one deals with procedure and data abstraction. In general, KR schemes used in many hl applications have not provided sufficient separation of procedure and data, nor has abstraction been promoted within each of these. Another consideration in developing large knowledge systems is storage and retrieval efficiency. Efficiency has been an issue with current systems that are heavily dependent on primary storage access; secondary storage-intensive systems will demand greater consideration of efficiency.","",""
6,"P. V. de Campos Souza, A. J. Guimarães, T. S. Rezende, Vinicius Jonathan Silva Araujo, Vanessa Souza Araújo","Detection of Anomalies in Large-Scale Cyberattacks Using Fuzzy Neural Networks",2020,"","","","",130,"2022-07-13 09:36:21","","10.3390/ai1010005","","",,,,,6,3.00,1,5,2,"The fuzzy neural networks are hybrid structures that can act in several contexts of the pattern classification, including the detection of failures and anomalous behaviors. This paper discusses the use of an artificial intelligence model based on the association between fuzzy logic and training of artificial neural networks to recognize anomalies in transactions involved in the context of computer networks and cyberattacks. In addition to verifying the accuracy of the model, fuzzy rules were obtained through knowledge from the massive datasets to form expert systems. The acquired rules allow the creation of intelligent systems in high-level languages with a robust level of identification of anomalies in Internet transactions, and the accuracy of the results of the test confirms that the fuzzy neural networks can act in anomaly detection in high-security attacks in computer networks.","",""
0,"L. Fesq, E. Atkins, L. Khatib, C. Pecheur, P. Cohen, L. Stein, M. Lent, J. Laird, A. Provetti, S. Cao","Robust Autonomy Answer Set Programming : Toward Efficient and Scalable Knowledge",2001,"","","","",131,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,10,21,"quently, each model of the program encodes a solution to the problem itself. For example, an ASP program encoding a planning scenario has as many models as valid plans. This schema is similar to that underlying the application of propositional satisfiability (SAT) algorithms. In fact, the ranges of applicability of these two techniques are similar. Several ASP systems are now available, among them DERES, DLV, SMODELS, and XSB; they support provably correct inferences and are about as fast and scalable as SAT checkers. These exciting results are attracting the attention of researchers from fields such as planThe American Association for Artificial Intelligence, in cooperation with Stanford University’s Department of Computer Science, presented the 2001 Spring Symposium Series on Monday through Wednesday, 26 to 28 March 2001, at Stanford University. The titles of the seven symposia were","",""
6,"Wienand A. Omta, Roy G. van Heesbeen, I. Shen, Jacob de Nobel, D. Robers, Lieke M. van der Velden, R. Medema, A. Siebes, A. Feelders, S. Brinkkemper, J. Klumperman, M. Spruit, Matthieu J. S. Brinkhuis, D. Egan","Combining Supervised and Unsupervised Machine Learning Methods for Phenotypic Functional Genomics Screening",2020,"","","","",132,"2022-07-13 09:36:21","","10.1177/2472555220919345","","",,,,,6,3.00,1,14,2,"There has been an increase in the use of machine learning and artificial intelligence (AI) for the analysis of image-based cellular screens. The accuracy of these analyses, however, is greatly dependent on the quality of the training sets used for building the machine learning models. We propose that unsupervised exploratory methods should first be applied to the data set to gain a better insight into the quality of the data. This improves the selection and labeling of data for creating training sets before the application of machine learning. We demonstrate this using a high-content genome-wide small interfering RNA screen. We perform an unsupervised exploratory data analysis to facilitate the identification of four robust phenotypes, which we subsequently use as a training set for building a high-quality random forest machine learning model to differentiate four phenotypes with an accuracy of 91.1% and a kappa of 0.85. Our approach enhanced our ability to extract new knowledge from the screen when compared with the use of unsupervised methods alone.","",""
24,"D. Miller","The medical AI insurgency: what physicians must know about data to practice with intelligent machines",2019,"","","","",133,"2022-07-13 09:36:21","","10.1038/s41746-019-0138-5","","",,,,,24,8.00,24,1,3,"","",""
14,"Ndapandula Nakashole","Automatic extraction of facts, relations, and entities for web-scale knowledge base population",2012,"","","","",134,"2022-07-13 09:36:21","","10.22028/D291-26412","","",,,,,14,1.40,14,1,10,"Equipping machines with knowledge, through the construction of machinereadable knowledge bases, presents a key asset for semantic search, machine translation, question answering, and other formidable challenges in artificial intelligence. However, human knowledge predominantly resides in books and other natural language text forms. This means that knowledge bases must be extracted and synthesized from natural language text. When the source of text is the Web, extraction methods must cope with ambiguity, noise, scale, and updates. The goal of this dissertation is to develop knowledge base population methods that address the afore mentioned characteristics of Web text. The dissertation makes three contributions. The first contribution is a method for mining high-quality facts at scale, through distributed constraint reasoning and a pattern representation model that is robust against noisy patterns. The second contribution is a method for mining a large comprehensive collection of relation types beyond those commonly found in existing knowledge bases. The third contribution is a method for extracting facts from dynamic Web sources such as news articles and social media where one of the key challenges is the constant emergence of new entities. All methods have been evaluated through experiments involving Web-scale text collections.","",""
3,"Saniat Javid Sohrawardi, Akash Chintha","DeFaking Deepfakes: Understanding Journalists’ Needs for Deepfake Detection",2020,"","","","",135,"2022-07-13 09:36:21","","","","",,,,,3,1.50,2,2,2,"Although the concern over deliberately inaccurate news is not new in media, the emergence of deepfakes—manipulated audio and video generated using artificial intelligence—changes the landscape of the problem. As these manipulations become more convincing, they can be used to place public figures into manufactured scenarios, effectively making it appear that anybody could say anything. Even if the public does not believe these are real, it will generally make video evidence appear less reliable as a source of validation, such that people no long trust anything they see. This increases the pressure on trusted agents in the media to help validate video and audio for the general public. To support this, we propose to develop a robust and an intuitive system to help journalists detect deepfakes. This paper presents a study of the perceptions, current procedures, and expectations of journalists regarding such a tool. We then combine technical knowledge of media forensics and the findings of the study to design a system for detection of deepfake videos that is usable by, and useful for, journalists.","",""
3,"R. Brachman, David Gunning, Murray Burke","Integrated AI Systems",2020,"","","","",136,"2022-07-13 09:36:21","","10.1609/aimag.v41i2.5300","","",,,,,3,1.50,1,3,2,"From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richly-integrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI","",""
3,"Richard Evan Sutanto, Sukho Lee","Real-Time Adversarial Attack Detection with Deep Image Prior Initialized as a High-Level Representation Based Blurring Network",2020,"","","","",137,"2022-07-13 09:36:21","","10.3390/electronics10010052","","",,,,,3,1.50,2,2,2,"Several recent studies have shown that artificial intelligence (AI) systems can malfunction due to intentionally manipulated data coming through normal channels. Such kinds of manipulated data are called adversarial examples. Adversarial examples can pose a major threat to an AI-led society when an attacker uses them as means to attack an AI system, which is called an adversarial attack. Therefore, major IT companies such as Google are now studying ways to build AI systems which are robust against adversarial attacks by developing effective defense methods. However, one of the reasons why it is difficult to establish an effective defense system is due to the fact that it is difficult to know in advance what kind of adversarial attack method the opponent is using. Therefore, in this paper, we propose a method to detect the adversarial noise without knowledge of the kind of adversarial noise used by the attacker. For this end, we propose a blurring network that is trained only with normal images and also use it as an initial condition of the Deep Image Prior (DIP) network. This is in contrast to other neural network based detection methods, which require the use of many adversarial noisy images for the training of the neural network. Experimental results indicate the validity of the proposed method.","",""
2,"C. Lim, C. Abeynayake, M. Sato-Ilic, L. Jain","Special issue: Computational intelligence models for image processing and information reasoning",2013,"","","","",138,"2022-07-13 09:36:21","","10.3233/IFS-2012-0546","","",,,,,2,0.22,1,4,9,"Computational Intelligence CI models comprise robust computing methodologies with a high level of machine learning quotient. CI models, in general, are useful for designing computerized intelligent systems/machines that possess useful characteristics mimicking human behaviors and capabilities in solving complex tasks, e.g., learning, adaptation, and evolution. Examples of some popular CI models include fuzzy systems, artificial neural networks, evolutionary algorithms, multi-agent systems, decision trees, rough set theory, knowledge-based systems, and hybrid of these models. This special issue highlights how different computational intelligence models, coupled with other complementary techniques, can be used to handle problems encountered in image processing and information reasoning.","",""
0,"M. Krupa, Sysiphe Inria, Paris-Rocquencourt, P. Chossat, Neuromath","Storing cycles and robust heteroclinic cycles M 2 project",2012,"","","","",139,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,5,10,"Hopfield neural networks are simple models of information storage and retrieval, used both in the context of artificial intelligence and the brain [1]. Cycling orbits, that is periodic or recurrent solutions that visit multiple nodes of the network, are likely candidates for fragments of encoded information (working memory, cognitive tasks) [2, 3]. We conjecture that such cycles can be found near so-called robust heteroclinic cycles that exist for idealizations of a transformed version of the Hopfield network with voltage variables replaced by firing rate variables [4], [5]. We propose to conduct a numerical and theoretical study of robust heteroclinic cycles in the firing rate Hopfield networks and investigate their relation to the cycling orbits. A good starting point can be some work by Chuan Zhang available in the form of a preprint [6], [7]. The study requires basic knowledge of dynamical systems and their applications in computational biology. Some experience with MATLAB or a similar program is also an asset.","",""
40,"Rafael V. Borges, A. Garcez, L. Lamb","Learning and Representing Temporal Knowledge in Recurrent Networks",2011,"","","","",140,"2022-07-13 09:36:21","","10.1109/TNN.2011.2170180","","",,,,,40,3.64,13,3,11,"The effective integration of knowledge representation, reasoning, and learning in a robust computational model is one of the key challenges of computer science and artificial intelligence. In particular, temporal knowledge and models have been fundamental in describing the behavior of computational systems. However, knowledge acquisition of correct descriptions of a system's desired behavior is a complex task. In this paper, we present a novel neural-computation model capable of representing and learning temporal knowledge in recurrent networks. The model works in an integrated fashion. It enables the effective representation of temporal knowledge, the adaptation of temporal models given a set of desirable system properties, and effective learning from examples, which in turn can lead to temporal knowledge extraction from the corresponding trained networks. The model is sound from a theoretical standpoint, but it has also been tested on a case study in the area of model verification and adaptation. The results contained in this paper indicate that model verification and learning can be integrated within the neural computation paradigm, contributing to the development of predictive temporal knowledge-based systems and offering interpretable results that allow system researchers and engineers to improve their models and specifications. The model has been implemented and is available as part of a neural-symbolic computational toolkit.","",""
2,"A. Garcez, L. Lamb","A I ] 1 0 D ec 2 02 0 Neurosymbolic AI : The 3 rd Wave",2020,"","","","",141,"2022-07-13 09:36:21","","","","",,,,,2,1.00,1,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
2,"Moa De Lucia Dahlbeck","AI and Spinoza: a review of law’s conceptual treatment of Lethal Autonomous",2020,"","","","",142,"2022-07-13 09:36:21","","10.1007/s00146-020-01014-x","","",,,,,2,1.00,2,1,2,"","",""
2,"C. Makris, Michael Angelos Simos","OTNEL: A Distributed Online Deep Learning Semantic Annotation Methodology",2020,"","","","",143,"2022-07-13 09:36:21","","10.3390/bdcc4040031","","",,,,,2,1.00,1,2,2,"Semantic representation of unstructured text is crucial in modern artificial intelligence and information retrieval applications. The semantic information extraction process from an unstructured text fragment to a corresponding representation from a concept ontology is known as named entity disambiguation. In this work, we introduce a distributed, supervised deep learning methodology employing a long short-term memory-based deep learning architecture model for entity linking with Wikipedia. In the context of a frequently changing online world, we introduce and study the domain of online training named entity disambiguation, featuring on-the-fly adaptation to underlying knowledge changes. Our novel methodology evaluates polysemous anchor mentions with sense compatibility based on thematic segmentation of the Wikipedia knowledge graph representation. We aim at both robust performance and high entity-linking accuracy results. The introduced modeling process efficiently addresses conceptualization, formalization, and computational challenges for the online training entity-linking task. The novel online training concept can be exploited for wider adoption, as it is considerably beneficial for targeted topic, online global context consensus for entity disambiguation.","",""
2,"Tong Lin, Yiqiong Shi, Na Shu, Deruo Cheng, Xuenong Hong, Jingsi Song, B. Gwee","Deep Learning-Based Image Analysis Framework for Hardware Assurance of Digital Integrated Circuits",2020,"","","","",144,"2022-07-13 09:36:21","","10.1109/IPFA49335.2020.9261081","","",,,,,2,1.00,0,7,2,"We propose an Artificial Intelligence (AI)/Deep Learning (DL)-based image analysis framework for hardware assurance of digital integrated circuits (ICs). Our aim is to examine and verify various hardware information from analyzing the Scanning Electron Microscope (SEM) images of an IC. In our proposed framework, we apply DL-based methods at all essential steps of the analysis. To the best of our knowledge, this is the first such framework that makes heavy use of DL-based methods at all essential analysis steps. Further, to reduce time and effort required in model re-training, we propose and demonstrate various automated or semi-automated training data preparation methods and demonstrate the effectiveness of using synthetic data to train a model. By applying our proposed framework to analyzing a set of SEM images of a large digital IC, we prove its efficacy. Our DL-based methods are fast, accurate, robust against noise, and can automate tasks that were previously performed mainly manually. Overall, we show that DL-based methods can largely increase the level of automation in hardware assurance of digital ICs and improve its accuracy.","",""
1,"F. Fabiano","Towards a Complete Characterization of Epistemic Reasoning: the Notion of Trust",2020,"","","","",145,"2022-07-13 09:36:21","","","","",,,,,1,0.50,1,1,2,"Designing autonomous agents, that interact with others to perform complex tasks, has always been one of the main objective of the Artificial Intelligence community. For such systems to be employed in complex scenarios, where the information about others is key (e.g., self-driving cars), it is necessary to define robust formalisms that allow each agent to act considering her beliefs on both: i) the state of the world; and ii) the other agents’ perspective of it. The branch of AI that studies such formalisms is known in literature as Multi-Agent Epistemic Planning (MEP). The epistemic action-based language mA, to the best of our knowledge, is the most comprehensive tool to model MEP domains but still lacks concepts that are necessary to reason on real-world scenarios. In this paper we introduce the actions (un)trustworthy announcement and (mis)trustworthy announcement for mA. These actions increase the language’s expressiveness introducing the notion of trust, therefore allowing for a more profound representation of real-world scenarios. In particular, we will provide the characterization, along with some desired properties, of the aforementioned actions’ transition functions. Finally, we will discuss the importance of formalizing the concept of trust in the MEP problem.","",""
16,"Sajjad Shokouhyar, Sudabeh Seifhashemi, S. H. Siadat, M. Ahmadi","Implementing a fuzzy expert system for ensuring information technology supply chain",2018,"","","","",146,"2022-07-13 09:36:21","","10.1111/exsy.12339","","",,,,,16,4.00,4,4,4,"In the business environment, information technology (IT) plays an important role for firms' performance. It provides information flow that makes the supply chain more robust and resilient without undermining its efficiency. Smart systems use artificial intelligence methods for solving problems and facilitating decision‐making through rule‐based deduction. Accordingly, these systems can present specialists' skills and simulate their thinking process. The primary goal of expert systems is to implement knowledge acquisition process by converting knowledge to wisdom. This process is vital for critical decision‐making regarding important issues such as determining necessities of a particular contract. Companies use professional liability insurance of the products and services to ensure the purchasers and prevent potential losses. Although this practice is highly prevalent, there is not any particular procedure for measuring necessities of contracts. The main purpose of this paper is to design a fuzzy expert system for measuring the necessities of professional contracts regarding insurance coverage and improve the supply chain management using IT. This system can measure and report these obligations, considering specifications of each project. Taking into perspective variety of professional services/products, we consider software as a type of professional contracts, extract its important indices and give it to the system as the input. After the necessary stages, the system produces a proper response and presents the generated response to the user. The software of this expert system is web based, and there are four operating layers in its architecture. We implemented this program in MS Visual Studio Framework with C#.NET programming language. Moreover, we implemented MS SQL‐Server Database Management.","",""
0,"Jedrzej Potoniec","Mining Cardinality Restrictions in OWL",2020,"","","","",147,"2022-07-13 09:36:21","","10.2478/fcds-2020-0011","","",,,,,0,0.00,0,1,2,"  We present an approach to mine cardinality restriction axioms from an existing knowledge graph, in order to extend an ontology describing the graph. We compare frequency estimation with kernel density estimation as approaches to obtain the cardinalities in restrictions. We also propose numerous strategies for filtering obtained axioms in order to make them more available for the ontology engineer. We report the results of experimental evaluation on DBpedia 2016-10 and show that using kernel density estimation to compute the cardinalities in cardinality restrictions yields more robust results that using frequency estimation. We also show that while filtering is of limited usability for minimum cardinality restrictions, it is much more important for maximum cardinality restrictions. The presented findings can be used to extend existing ontology engineering tools in order to support ontology construction and enable more efficient creation of knowledge-intensive artificial intelligence systems.","",""
0,"D. Rus","Keynote Lecture - Robotics and AI: Promises and Challenges",2020,"","","","",148,"2022-07-13 09:36:21","","10.1109/iccp51029.2020.9266165","","",,,,,0,0.00,0,1,2,"The digitization of practically everything coupled with the mobile Internet, the automation of knowledge work, and advanced robotics promises a future with democratized use of machines and wide-spread use of customization and data-driven decision making. Advances are happening in three different but overlapping fields: robotics, machine learning, and artificial intelligence. However, the science and engineering of intelligence remains a grand challenge. Where are the gaps we need to address in order to advance toward a future where machines help people reliably with cognitive and physical tasks? In this talk I will discuss recent developments toward enabling robust machine learning and pervasive robotics.","",""
0,"C. Bergin, M. Horgan","Past, present and future of medical education in Ireland",2020,"","","","",149,"2022-07-13 09:36:21","","10.29060/taps.2020-5-2/gp1084","","",,,,,0,0.00,0,2,2,"Medical education and training has evolved over the centuries. Ireland has a long history of leading on aspects of training that remain relevant today, focussing on the apprenticeship model coupled with a robust modern medical education framework. The practice of medicine is changing rapidly driven by expanding knowledge, advances in technology and use of artificial intelligence, demographic shifts and the expectations of patients and society. Medical training and education need to adapt to ensure that our current knowledge and future medical workforce is prepared for modern-day patient-centric practice. Ireland has emerged as a world leader in medical device technology, pharmaceutical research and development and social media technology support which offer the opportunity for the future of medical training. Knowledge, emotional intelligence, critical thinking, compassion, resilience and leadership are key attributes to which we as a profession aspire. There is an opportunity to leverage Ireland’s global position in technology and finance to train our modern-day medical workforce whilst retaining the attributes of the compassionate practice of the art of medicine. This paper explores the past, present and future of medical education and training in Ireland.","",""
0,"Tae-Hyun Chun, Yong Yu","Enhancing CHF Prediction of AECL Look-Up Table Along with Machine Learning",2020,"","","","",150,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,2,2,"A critical heat flux (CHF) is a key safety parameter. For the CHF prediction, artificial neural network has been also applied and showed good performances [1, 2]. However, it is hardly accepted in the nuclear community due to a drawback of ‘Explainability’. A machine learning, as a subset of the artificial intelligence, can play a supplementary role for a more robust domain knowledge-based model. AECL Look-up Table (LUT) is widely used for the CHF prediction in reactor thermal-hydraulic design and safety analyses [3]. This domain knowledge model can predict the CHF by two schemes such as DSM (Direct Substitute Method) and HBM (Heat Balance Method). The uncertainty is much large in the DSM relative to the HBM. But the DSM is practically used in the nuclear engineering since HBM requires iterations to reach the heat balance in the CHF prediction. The purpose of this study is to show a feasibility that a machine learning-aided CHF LUT model enhances considerably the accuracy of the CHF prediction.","",""
0,"Roger Pizarro Milian, Yvette Munro","Credit Transfer, Articulation & The Future of Work: Towards a Federal Strategy",2020,"","","","",151,"2022-07-13 09:36:21","","10.47678/cjhe.vi0.188769","","",,,,,0,0.00,0,2,2,"Some analysts foresee that the rise of automation—triggered by advances in artificial intelligence, robotics, and other novel technologies—will soon unsettle sizable sections of our labour market, prompting the need for mass upskilling and re-skilling. Continuous learning is perceived as the new norm within the future of work. Many believe that solutions to future surges in training demand will require a degree of dexterity not exhibited by traditional postsecondary education (PSE) organizations, and advocate for radical alternatives. However, we outline how basic reforms leading to a more robust articulation and credit transfer system could also improve our PSE system’s ability to handle augmented training demands. In turn, we explore how the Canadian federal government can facilitate these reforms by (a) providing additional incentives for domestic colleges and universities to engage in seamless transfer, and (b) supporting the production of knowledge to inform more strategic forms of pathway articulation.","",""
3,"Sam Devlin","Potential-based reward shaping for knowledge-based, multi-agent reinforcement learning",2013,"","","","",152,"2022-07-13 09:36:21","","","","",,,,,3,0.33,3,1,9,"Reinforcement learning is a robust artificial intelligence solution for agents required to act in an environment, making their own decisions on how to behave. Typically an agent is deployed alone with no prior knowledge, but if given sufficient time, a suitable state representation and an informative reward function is guaranteed to learn how to maximise its long term reward.    Incorporating domain knowledge, typically known by the system designer, can minimise the number of suboptimal behaviours tried and, therefore, speed up the rate of learning. Potential-based reward shaping is a method of providing this knowledge to an agent by additional rewards. Furthermore, if the agent is alone in the environment, it is guaranteed to learn the same behaviour both with and without potential-based reward shaping.    Meanwhile, there has also been a growing interest in deploying not just one agent but many into the same environment. This application can benefit from the potential of both multi-agent systems and reinforcement learning. However, practical use is often limited by the non-stationary environment, exponential increase in state features with every agent added and partial observability.    This thesis documents work combining knowledge-based reinforcement learning and multi-agent reinforcement learning so that the latter can be achieved quicker and, therefore, feasibly applied to complex problem domains.    Experience gained from many empirical studies is gathered to support novel theoretical contributions proving that the pre-existing guarantees of potential-based reward shaping do not apply when used in multi-agent problem domains. Instead multi-agent potential-based reward shaping may cause agents to learn a different behaviour, but this behaviour is guaranteed to be from the same set of behaviours that the agents could have learned without the additional rewards. Therefore, knowledge-based multi-agent reinforcement learning can both reduce the time a group of agents need to learn a suitable behaviour and increase their final performance.","",""
51,"Jun He, Shixi Yang, C. Gan","Unsupervised Fault Diagnosis of a Gear Transmission Chain Using a Deep Belief Network",2017,"","","","",153,"2022-07-13 09:36:21","","10.3390/s17071564","","",,,,,51,10.20,17,3,5,"Artificial intelligence (AI) techniques, which can effectively analyze massive amounts of fault data and automatically provide accurate diagnosis results, have been widely applied to fault diagnosis of rotating machinery. Conventional AI methods are applied using features selected by a human operator, which are manually extracted based on diagnostic techniques and field expertise. However, developing robust features for each diagnostic purpose is often labour-intensive and time-consuming, and the features extracted for one specific task may be unsuitable for others. In this paper, a novel AI method based on a deep belief network (DBN) is proposed for the unsupervised fault diagnosis of a gear transmission chain, and the genetic algorithm is used to optimize the structural parameters of the network. Compared to the conventional AI methods, the proposed method can adaptively exploit robust features related to the faults by unsupervised feature learning, thus requires less prior knowledge about signal processing techniques and diagnostic expertise. Besides, it is more powerful at modelling complex structured data. The effectiveness of the proposed method is validated using datasets from rolling bearings and gearbox. To show the superiority of the proposed method, its performance is compared with two well-known classifiers, i.e., back propagation neural network (BPNN) and support vector machine (SVM). The fault classification accuracies are 99.26% for rolling bearings and 100% for gearbox when using the proposed method, which are much higher than that of the other two methods.","",""
0,"Dinesh Kumar","Knowledge Based Design of Axial Flow Compressor",2015,"","","","",154,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,7,"In the aerospace industry with highly competitive market the time to design and delivery is shortening every day. Pressure on delivering robust product with cost economy is in demand in each development. Even though technology is older, it is new for each customer requirement and highly non-liner to fit one in another place. Gas turbine is considered one of a complex design in the aircraft system. It involves experts to be grouped with designers of various segments to arrive the best output. The time is crucial to achieve a best design and it needs knowledge automation incorporated with CAD/CAE tools. In the present work an innovative idea in the form of Knowledge Based Engineering for axial compressor is proposed, this includes the fundamental design of axial compressor integrated with artificial intelligence in the form of knowledge capturing and programmed with high level language (Visual Basis.Net) and embedded into CATIA v5. This KBE frame work eases out the design and modeling of axial compressor design and produces 3D modeling for further flow simulation with fluid dynamic in Ansys-Fluent. Most of the aerospace components are developed through simulation driven product development and in this case it is established for axial compressor.","",""
9,"Vahid Nourani, Amir Molajou, Hessam Najafi, A. D. Mehr","Emotional ANN (EANN): A New Generation of Neural Networks for Hydrological Modeling in IoT",2019,"","","","",155,"2022-07-13 09:36:21","","10.1007/978-3-030-04110-6_3","","",,,,,9,3.00,2,4,3,"","",""
69,"Gilbert Lim, Yuan Cheng, W. Hsu, M. Lee","Integrated Optic Disc and Cup Segmentation with Deep Learning",2015,"","","","",156,"2022-07-13 09:36:21","","10.1109/ICTAI.2015.36","","",,,,,69,9.86,17,4,7,"Glaucoma is a widespread ocular disorder leading to irreversible loss of vision. Therefore, there is a pressing need for cost-effective screening, such that preventive measures can be taken. This can be achieved with an accurate segmentation of the optic disc and cup from retinal images to obtain the cup-to-disc ratio. We describe a comprehensive solution based on applying convolutional neural networks to feature exaggerated inputs emphasizing disc pallor without blood vessel obstruction, as well as the degree of vessel kinking. The produced raw probability maps then undergo a robust refinement procedure that takes into account prior knowledge about retinal structures. Analysis of these probability maps further allows us to obtain a confidence estimate on the correctness of the segmentation, which can be used to direct the most challenging cases for manual inspection. Tests on two large real-world databases, including the publicly-available MESSIDOR collection, demonstrate the effectiveness of our proposed system.","",""
3,"Neeraj Priyadarshi, F. Azam, A. Sharma, Monika Vardia","An Adaptive Neuro-Fuzzy Inference System-Based Intelligent Grid-Connected Photovoltaic Power Generation",2019,"","","","",157,"2022-07-13 09:36:21","","10.1007/978-981-13-8222-2_1","","",,,,,3,1.00,1,4,3,"","",""
0,"Xiuyi Fan, T. Henderson","Robot Google TM : a Framework for Robot Knowledge Sharing",,"","","","",158,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,2,,"Knowledge representation is a traditional field in artificial intelligence. Researchers have developed various ways to represent and share information among intelligent agents. Agents that share resources, data, information, and knowledge perform better than agents working alone. However, previous research also reveals that sharing knowledge among a large number of entities in an open environment is a problem yet to be solved. Intelligent robots are designed and produced by different manufactures. They have various physical attributes, use different knowledge representations and have different needs. In this research, we pose robot knowledge sharing as an activity to be developed in an open environment the World Wide Web. Just as search engines like Google provide enormous power for information exchange and sharing for humans, we believe a searching mechanism designed for intelligent agents can provide a robust approach for sharing knowledge among robots. We have developed knowledge representation for robots that allows Internet access and a knowledge organization and search indexing engine that performs knowledge retrieval.","",""
151,"Christopher D. Manning, Bill MacCartney","Natural language inference",2009,"","","","",159,"2022-07-13 09:36:21","","","","",,,,,151,11.62,76,2,13,"Inference has been a central topic in artificial intelligence from the start, but while automatic methods for formal deduction have advanced tremendously, comparatively little progress has been made on the problem of natural language inference (NLI), that is, determining whether a natural language hypothesis h can justifiably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression.  This dissertation explores a range of approaches to NLI, beginning with methods which are robust but approximate, and proceeding to progressively more precise approaches.  We first develop a baseline system based on overlap between bags of words. Despite its extreme simplicity, this model achieves surprisingly good results on a standard NLI evaluation, the PASCAL RTE Challenge. However, its effectiveness is limited by its failure to represent semantic structure.  To remedy this lack, we next introduce the Stanford RTE system, which uses typed dependency trees as a proxy for semantic structure, and seeks a low-cost alignment between trees for p and h, using a cost model which incorporates both lexical and structural matching costs. This system is typical of a category of approaches to NLI based on approximate graph matching. We argue, however, that such methods work best when the entailment decision is based, not merely on the degree of alignment, but also on global features of the aligned 〈p, h〉 pair motivated by semantic theory.  Seeking still greater precision, we devote the largest part of the dissertation to developing an approach to NLI based on a model of natural logic. We greatly extend past work in natural logic, which has focused solely on semantic containment and monotonicity, to incorporate both semantic exclusion and implicativity. Our system decomposes an inference problem into a sequence of atomic edits which transforms p into h; predicts a lexical entailment relation for each edit using a statistical classifier; propagates these relations upward through a syntax tree according to semantic properties of intermediate nodes; and composes the resulting entailment relations across the edit sequence.  Finally, we address the problem of alignment for NLI, by developing a model of phrase-based alignment inspired by analogous work in machine translation, including an alignment scoring function, inference algorithms for finding good alignments, and training algorithms for choosing feature weights.","",""
144,"A. Garcez, L. Lamb, D. Gabbay","Neural-Symbolic Cognitive Reasoning",2008,"","","","",160,"2022-07-13 09:36:21","","10.1007/978-3-540-73246-4","","",,,,,144,10.29,48,3,14,"","",""
0,"Av. Ramón López Velarde","NSDann2BS, a Neutron Spectrum Unfolding Code Based on Neural Networks Technology and Two Bonner Spheres",2019,"","","","",161,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,3,"In this work a neutron spectrum unfolding code, based on artificial intelligence technology is presented. The code called “Neutron Spectrometry and Dosimetry with Artificial Neural Networks and two Bonner spheres”, (NSDann2BS), was designed in a graphical user interface under the LabVIEW programming environment. The main features of this code are to use an embedded artificial neural network architecture optimized with the “Robust design of artificial neural networks methodology” and to use two Bonner spheres as the only piece of information. In order to build the code here presented, once the net topology was optimized and properly trained, knowledge stored at synaptic weights was extracted and using a graphical framework build on the LabVIEW programming environment, the NSDann2BS code was designed. This code is friendly, intuitive and easy to use for the end user. The code is freely available upon request to authors. To demonstrate the use of the neural net embedded in the NSDann2BS code, the rate counts of Cf, AmBe and PuBe neutron sources measured with a Bonner spheres system.","",""
0,"Conor Falvey","Bitesize: Exploring the Form, Function, and Future of Online Book Summary Services",2019,"","","","",162,"2022-07-13 09:36:21","","10.5931/DJIM.V15I0.8979","","",,,,,0,0.00,0,1,3,"Popular book summaries are an under-researched family of information objects. Online book summary services offer condensed versions of popular press non-fiction books, especially titles related to management and leadership, for busy readers willing to pay subscription fees. These summaries are intended to be mobile, electronic, quickly-digested alternatives to reading entire books. Summaries can function as tools of learning as well as aids to book discovery. This paper describes the offerings of three online book summary services. It then discusses the implications of such services for information in society. It considers the benefits and drawbacks of the choice to focus these services on popular press nonfiction, which has commercial value and mainstream appeal, rather than other knowledge sources which might be more robust but less desirable to readers. Finally, it examines the ways in which artificial intelligence and natural language processing technologies could transform and disrupt the current system of producing and consuming book summaries.","",""
0,"Edison CONDE PEREZ DOS SANTOS, Carlos A.N., C. Jose, Carlos C. Amorim","HYBRID SEDIMENT TRANSPORT MODEL FOR THE STABILITY ANALYSIS OF THE LINGUADO CHANNEL, STATE OF SANTA CATARINA, BRAZIL",2019,"","","","",163,"2022-07-13 09:36:21","","10.3850/38wc092019-1112","","",,,,,0,0.00,0,4,3,"This study involves an assessment of various artificial intelligence-related techniques which aim to produce a more robust system for sediment transport modeling. The intelligent systems developed in this research are directly applicable to academic knowledge and use data from a report on water circulation assessment in the Linguado Channel and Babitonga Bay - Santa Catarina, Brazil, developed by the Military Institute of Engineering (Instituto Militar de Engenharia - IME). The solution employed for sediment transport was built using an intelligent system from the conception of two hybrid models. The first was a Neuro-Fuzzy (ANFIS) hybrid model for the study of hydrodynamic behavior, aiming to determine flow rate in the channel. The second was a fuzzy genetic model, able to assess sediment transport in the Linguado Channel.","",""
29,"A. Gordon","Commonsense Interpretation of Triangle Behavior",2016,"","","","",164,"2022-07-13 09:36:21","","10.1609/aaai.v30i1.9881","","",,,,,29,4.83,29,1,6,"    The ability to infer intentions, emotions, and other unobservable psychological states from people's behavior is a hallmark of human social cognition, and an essential capability for future Artificial Intelligence systems. The commonsense theories of psychology and sociology necessary for such inferences have been a focus of logic-based knowledge representation research, but have been difficult to employ in robust automated reasoning architectures. In this paper we model behavior interpretation as a process of logical abduction, where the reasoning task is to identify the most probable set of assumptions that logically entail the observable behavior of others, given commonsense theories of psychology and sociology. We evaluate our approach using Triangle-COPA, a benchmark suite of 100 challenge problems based on an early social psychology experiment by Fritz Heider and Marianne Simmel. Commonsense knowledge of actions, social relationships, intentions, and emotions are encoded as defeasible axioms in first-order logic. We identify sets of assumptions that logically entail observed behaviors by backchaining with these axioms to a given depth, and order these sets by their joint probability assuming conditional independence. Our approach solves almost all (91) of the 100 questions in Triangle-COPA, and demonstrates a promising approach to robust behavior interpretation that integrates both logical and probabilistic reasoning.   ","",""
46,"Gilbert Lim, M. Lee, W. Hsu, T. Wong","Transformed Representations for Convolutional Neural Networks in Diabetic Retinopathy Screening",2014,"","","","",165,"2022-07-13 09:36:21","","","","",,,,,46,5.75,12,4,8,"Convolutional neural networks (CNNs) are flexible, biologically-inspired variants of multi-layer perceptrons that have proven themselves to be exceptionally suited to discriminative vision tasks. However, relatively little is known on whether they can be made both more efficient and more accurate, by introducing suitable transformations that exploit general knowledge of the target classes. We demonstrate this functionality through pre-segmentation of input images with a fast and robust but loose segmentation step, to obtain a set of candidate objects. These objects then undergo a spatial transformation into a reduced space, retaining but a compact high-level representation of their appearance. Additional attributes may be abstracted as raw features that are incorporated after the convolutional phase of the network. Finally, we compare its performance against existing approaches on the challenging problem of detecting lesions in retinal images.","",""
0,"Shailaja Keyur Sampat","Technical, Hard and Explainable Question Answering (THE-QA)",2019,"","","","",166,"2022-07-13 09:36:21","","10.24963/IJCAI.2019/916","","",,,,,0,0.00,0,1,3,"The ability of an agent to rationally answer questions about a given task is the key measure of its intelligence. While we have obtained phenomenal performance over various language and vision tasks separately, 'Technical, Hard and Explainable Question Answering' (THE-QA) is a new challenging corpus which addresses them jointly. THE-QA is a question answering task involving diagram understanding and reading comprehension. We plan to establish benchmarks over this new corpus using deep learning models guided by knowledge representation methods. The proposed approach will envisage detailed semantic parsing of technical figures and text, which is robust against diverse formats. It will be aided by knowledge acquisition and reasoning module that categorizes different knowledge types, identify sources to acquire that knowledge and perform reasoning to answer the questions correctly. THE-QA data will present a strong challenge to the community for future research and will bridge the gap between state-of-the-art Artificial Intelligence (AI) and 'Human-level' AI.","",""
5,"Y. Malhotra","AI, Machine Learning & Deep Learning Risk Management & Controls: Beyond Deep Learning and Generative Adversarial Networks: Model Risk Management in AI, Machine Learning & Deep Learning",2018,"","","","",167,"2022-07-13 09:36:21","","10.2139/SSRN.3193693","","",,,,,5,1.25,5,1,4,"The current paper proposes how model risk management in operationalizing machine learning for algorithm deployment can be applied in national C4I and Cyber projects such as Project Maven. It builds upon recent leadership of global Management and Leadership industry executives for AI and Machine Learning Executive Education for MIT Sloan School of Management and the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and invited presentations at Princeton University. After building understanding about why model risk management is most crucial to robust AI, Machine Learning, Deep Learning, and, Neural Networks deployment, it introduces a Knowledge Management Framework for Model Risk Management to advance beyond ‘AI Automation’ to ‘AI Augmentation.’","",""
3,"Rafael V. Borges, A. Garcez, L. Lamb","Representing, Learning and Extracting Temporal Knowledge from Neural Networks: A Case Study",2010,"","","","",168,"2022-07-13 09:36:21","","10.1007/978-3-642-15822-3_13","","",,,,,3,0.25,1,3,12,"","",""
1,"F. Kirchner, Sebastian Bartsch, José DeGea","Experiments on Embodied Cognition: A Bio-Inspired Approach for Robust Biped Locomotion",2007,"","","","",169,"2022-07-13 09:36:21","","10.5772/4883","","",,,,,1,0.07,0,3,15,"Recently, the psychological point of view that grants the body a more significant role in cognition has also gained attention in artificial intelligence. Proponents of this approach would claim that instead of a ‘mind that works on abstract problems’ we have to deal with and understand ‘a body that needs a mind to make it function’ (Wilson, 2002). These ideas differ quite radically from the traditional approach that describes a cognitive process as an abstract information processing task where the real physical connections to the outside world are of only sub-critical importance, sometimes discarded as mere ‘informational encapsulated plug-ins’ (Fodor, 1983). Thus most theories in cognitive psychology have tried to describe the process of human thinking in terms of propositional knowledge. At the same time, artificial intelligence research has been dominated by methods of abstract symbolic processing, even if researchers often used robotic systems to implement them (Nilsson, 1984). Ignoring sensor-motor influences on cognitive ability is in sharp contrast to research by William James (James, 1890) and others (see (Prinz, 1987) for a review) that describe theories of cognition based on motor acts, or a theory of cognitive function emerging from seminal research on sensor-motor abilities by Jean Piaget (Wilson, 2002) and the theory of affordances by (Gibson, 1977). In the 1980s the linguist Lakoff and the philosopher Johnson (Lakoff & Johnson, 1980) put forward the idea of abstract concepts based on metaphors for bodily, physical concepts; around the same time, Brooks (Brooks, 1986) made a major impact on artificial intelligence research by his concepts of behavior based robotics and interaction with the environment without internal representation instead of the sensereason-act cycle. This approach has gained wide attention ever since and there appears to be a growing sense of commitment to the idea that cognitive ability in a system (natural or artificial) has to be studied in the context of its relation to a ‘kinematically competent’ physical body. Among the most competent (in a multi functional sense) physical bodies around are certainly humans, so the study of humanoid robots appears to be a promising field for","",""
11,"Du Zhang","Quantifying Knowledge Base Inconsistency via Fixpoint Semantics",2007,"","","","",170,"2022-07-13 09:36:21","","10.1007/978-3-540-87563-5_9","","",,,,,11,0.73,11,1,15,"","",""
3,"A. Salem","DEVELOPING A WEB-BASED ONTOLOGY FOR E-BUSINESS",2018,"","","","",171,"2022-07-13 09:36:21","","10.7903/IJECS.1654","","",,,,,3,0.75,3,1,4,"Ontological engineering (OE) is a subset of knowledge science. Ontology is a powerful technique for knowledge management and reasoning tasks. Recently, most research of OE is related to developing robust, smart, knowledge-based systems in different domains. Nowadays, e-business, or electronic business, is the integrated execution of all business analytics processes of an enterprise by means of smart computing and informatics. The objective of this study is to develop a web-based ontology for e-business paradigms. In this work, five web-based ontologies were designed for the following: (a) e-business applications; (b) e-business participants; (c) e-business infrastructure; (d) e-business support areas, and (e) fields in e-business. The developed ontologies were implemented in ontology web-based language OWL2 using the Protege smart tool version 5.0.0 editing environment. Keywords: Knowledge Engineering, E-Business, E-Commerce, Web Technology, Ontology, Computer Science, Artificial Intelligence, Smart Computing. To cite this document: Abdel-Badeeh M. Salem and Silvia Parusheva, "" DEVELOPING A WEB-BASED ONTOLOGY FOR E-BUSINESS "", International Journal of Electronic Commerce Studies, Vol.9, No.2, pp.119-132, 2018. Permanent link to this document: http://dx.doi.org/10.7903/ijecs.1654","",""
9,"Joseph B. Kopena, B. T. Loo","OntoNet: Scalable knowledge-based networking",2008,"","","","",172,"2022-07-13 09:36:21","","10.1109/ICDEW.2008.4498312","","",,,,,9,0.64,5,2,14,"Recent years have seen a proliferation of work on the Semantic Web, an initiative to enable intelligent agents to reason about and utilize World Wide Web content and services. Concurrently, the networking community has developed a concept of the knowledge plane, using artificial intelligence to reason about and manage network behavior. These two efforts have progressed independently despite potential synergies. This paper presents early work on OntoNet, a knowledge-based middleware which aims to integrate those visions and provide flexible, scalable knowledge-based networking with ontologies. We focus on supporting multicast messaging in mobile ad-hoc networks using description logic advertisements and requests in a subset of the Web Ontology Language (OWL). We explore a novel hybrid tree- mesh protocol which enables efficient and robust propagation of potentially verbose queries and descriptions. We demonstrate the potential viability of this protocol via simulations in the newly developed NS-3 simulator.","",""
102,"L. Semeniuk, A. Noureldin","Bridging GPS outages using neural network estimates of INS position and velocity errors",2006,"","","","",173,"2022-07-13 09:36:21","","10.1088/0957-0233/17/10/033","","",,,,,102,6.38,51,2,16,"INS and GPS are commonly integrated using a Kalman filter (KF) to provide a robust navigation solution, overcoming situations of GPS satellite signals blockage. This research presents an alternative method of bridging GPS outages requiring no prior knowledge of the INS and GPS sensor characteristics, called the artificial-intelligence-based segmented forward predictor. This method uses radial basis function neural networks to predict INS position and velocity errors during GPS outages, resulting in reliable performance. The performance of the proposed method is examined using real field test data of both navigational and tactical grade INS integrated with GPS. The results have shown that the proposed method outperforms KF, especially during long GPS outages.","",""
34,"D. Kimes, P. Harrison, P. Ratcliffe","A knowledge-based expert system for inferring vegetation characteristics",1991,"","","","",174,"2022-07-13 09:36:21","","10.1080/01431169108955233","","",,,,,34,1.10,11,3,31,"Abstract The overall goal of the research is to develop a robust extraction technique for inferring physical and biological surface properties of vegetation using nadir and/or directional reflectance data as input. A prototype knowledge-based expert system VEG is described that concentrates on extracting spectral hemispherical reflectance using any combination of nadir and/or directional reflectance data as input. VEG is designed to facilitate expansion to handle other inferences regarding vegetation properties such as total hemispherical reflectance, per cent ground cover, leaf area index, biomass, and photosynthetic capacity. This approach is more accurate and robust than conventional extraction techniques developed by the investigator and others. VEG combines methods from remote sensing and Artificial Intelligence (AI), It integrates input spectral measurements with diverse knowledge bases available from the literature, data sets of directional reflectance measurements, and from experts, into an intell...","",""
1,"B. Daniels, W. Ryu, I. Nemenman","Automated, predictive, and interpretable inference of C. elegans escape dynamics",2018,"","","","",175,"2022-07-13 09:36:21","","10.1101/426387","","",,,,,1,0.25,0,3,4,"The roundworm C. elegans exhibits robust escape behavior in response to rapidly rising temperature. The behavior lasts for a few seconds, shows history dependence, involves both sensory and motor systems, and is too complicated to model mechanistically using currently available knowledge. Instead we model the process phenomenologically, and we use the Sir Isaac dynamical inference platform to infer the model in a fully automated fashion directly from experimental data. The inferred model requires incorporation of an unobserved dynamical variable, and is biologically interpretable. The model makes accurate predictions about the dynamics of the worm behavior, and it can be used to characterize the functional logic of the dynamical system underlying the escape response. This work illustrates the power of modern artificial intelligence to aid in discovery of accurate and interpretable models of complex natural systems.","",""
28,"S. M. Gowda, R. Baker, A. Corbett, L. M. Rossi","Towards Automatically Detecting Whether Student Learning is Shallow",2012,"","","","",176,"2022-07-13 09:36:21","","10.1007/s40593-013-0006-4","","",,,,,28,2.80,7,4,10,"","",""
9,"M. Colombo","Why build a virtual brain? Large-scale neural simulations as jump start for cognitive computing",2017,"","","","",177,"2022-07-13 09:36:21","","10.1080/0952813X.2016.1148076","","",,,,,9,1.80,9,1,5,"Abstract Despite the impressive amount of financial resources recently invested in carrying out large-scale brain simulations, it is controversial what the pay-offs are of pursuing this project. One idea is that from designing, building, and running a large-scale neural simulation, scientists acquire knowledge about the computational performance of the simulating system, rather than about the neurobiological system represented in the simulation. It has been claimed that this knowledge may usher in a new era of neuromorphic, cognitive computing systems. This study elucidates this claim and argues that the main challenge this era is facing is not the lack of biological realism. The challenge lies in identifying general neurocomputational principles for the design of artificial systems, which could display the robust flexibility characteristic of biological intelligence.","",""
111,"H. Lieberman, Hugo Liu, P. Singh, Barbara Barry","Beating Common Sense into Interactive Applications",2004,"","","","",178,"2022-07-13 09:36:21","","10.1609/aimag.v25i4.1785","","",,,,,111,6.17,28,4,18,"A long-standing dream of artificial intelligence has been to put commonsense knowledge into computers -- enabling machines to reason about everyday life. Some projects, such as Cyc, have begun to amass large collections of such knowledge. However, it is widely assumed that the use of common sense in interactive applications will remain impractical for years, until these collections can be considered sufficiently complete and commonsense reasoning sufficiently robust. Recently, at the Massachusetts Institute of Technology's Media Laboratory, we have had some success in applying commonsense knowledge in a number of intelligent interface agents, despite the admittedly spotty coverage and unreliable inference of today's commonsense knowledge systems. This article surveys several of these applications and reflects on interface design principles that enable successful use of commonsense knowledge.","",""
1,"L. E. Souza","Flexible Planning Knowledge Acquisition for Industrial Processes",2008,"","","","",179,"2022-07-13 09:36:21","","","","",,,,,1,0.07,1,1,14,"The acquisition of planning knowledge for industrial processes has been shown to be particularly hard in terms of acquiring robust task knowledge from human experts. Furthermore, this knowledge, when acquired, is rather domain dependent and the acquisition effort is very seldom amortized over other applications. In this paper, we report on our work on flexibly representing a functional model of a chemical process in an Artificial Intelligence (AI) planning system. We show the generality and flexibility of our new planning operator representation. Operators are designed for general functions which can be defined for hierarchical levels of functional detail. We present how the planning domain can be used with little or no modification, depending on the level of abstraction, to other engineering systems. This planning domain is fully implemented in a domain-independent AI planning system.","",""
3,"I. Rudas, F. Pereszlenyi, J. Tar, J. Bitó","General principles for design of robust non-linear controllers for AI-, ANN- or fuzzy approach-based realization",1993,"","","","",180,"2022-07-13 09:36:21","","10.1109/IECON.1993.339104","","",,,,,3,0.10,1,4,29,"Development of adaptive and robust controllers for nonlinear coupled systems is inspired by new possibilities of hardware-realization, It concerns each kind of artificial intelligence: ""classical"" knowledge-based systems (KBSs), and artificial neural network- (ANN) and fuzzy set- (FS) based formulations. While common and general roots of these approaches became transparent, in each case complexity of the control rules, number of ANN processor units or fuzzy sets, or complexity of fuzzy rules essentially depend on the generalized coordinates used for describing the system to be controlled. It is pointed out, that in a wide class of control tasks relatively simple kinds of coordinate transformation can be applied to achieve effective simplification of the control rules and reduction of the number of necessary processor units or fuzzy sets. As an example, dynamics of robot arms are considered, where the appropriate coordinate transformation is approximate diagonalization of the inertia matrix of the robot arms. It serves as a satisfactory basis for working out a general method and principles for dealing with the quadratic coupling not eliminated by the diagonalization. It shows strong robustness with respect to the unknown inertia of the manipulated body and easily can be realized by ANN or fuzzy rule-based solutions of very limited number of processor units or fuzzy rules. The method is demonstrated by results of numerical simulation. Effects of imprecise modeling of the mass of the work-piece are considered.<<ETX>>","",""
1,"Thomas Augustin, S. Pöhlmann","On Robust Sequential Analysis - Kiefer-Weiss Optimal Testing under Interval Probability",2001,"","","","",181,"2022-07-13 09:36:21","","10.5282/ubm/epub.1641","","",,,,,1,0.05,1,2,21,"Usual sequential testing procedures often are very sensitive against even small deviations from the `ideal model' underlying the hypotheses. This makes robust procedures highly desirable. To rely on a clearly defined optimality criterion, we incorporate robustness aspects directly into the formulation of the hypotheses considering the problem of sequentially testing between two interval probabilities (imprecise probabilities). We derive the basic form of the Kiefer-Weiss optimal testing procedure and show how it can be calculated by an easy-to-handle optimization problem. These results are based on the reinterpretation of our testing problem as the task to test between nonparametric composite hypotheses, which allows to adopt the framework of Pavlov (1991). From this we obtain a general result applicable to any interval probability field on a finite sample space, making the approach powerful far beyond robustness considerations, for instance for applications in artificial intelligence dealing with imprecise expert knowledge.","",""
87,"I. Grosse, John M. Milton-Benoit, J. Wileden","Ontologies for supporting engineering analysis models",2005,"","","","",182,"2022-07-13 09:36:21","","10.1017/S0890060405050018","","",,,,,87,5.12,29,3,17,"In this paper we lay the foundations for exchanging, adapting, and interoperating engineering analysis models (EAMs). Our primary foundation is based upon the concept that engineering analysis models are knowledge-based abstractions of physical systems, and therefore knowledge sharing is the key to exchanging, adapting, and interoperating EAMs within or across organizations. To enable robust knowledge sharing, we propose a formal set of ontologies for classifying analysis modeling knowledge. To this end, the fundamental concepts that form the basis of all engineering analysis models are identified, described, and typed for implementation into a computational environment. This generic engineering analysis modeling ontology is extended to include distinct analysis subclasses. We discuss extension of the generic engineering analysis modeling class for two common analysis subclasses: continuum-based finite element models and lumped parameter or discrete analysis models. To illustrate how formal ontologies of engineering analysis modeling knowledge might facilitate knowledge exchange and improve reuse, adaptability, and interoperability of analysis models, we have developed a prototype engineering analysis modeling knowledge base, called ON-TEAM, based on our proposed ontologies. An industrial application is used to instantiate the ON-TEAM knowledge base and illustrate how such a system might improve the ability of organizations to efficiently exchange, adapt, and interoperate analysis models within a computer-based engineering environment. We have chosen Java as our implementation language for ON-TEAM so that we can fully exploit object-oriented technology, such as object inspection and the use of metaclasses and metaobjects, to operate on the knowledge base to perform a variety of tasks, such as knowledge inspection, editing, maintenance, model diagnosis, customized report generation of analysis models, model selection, automated customization of the knowledge interface based on the user expertise level, and interoperability assessment of distinct analysis models.","",""
1,"Xiuyi Fan, T. Henderson","RobotShare : a Framework for Robot Knowledge Sharing",2007,"","","","",183,"2022-07-13 09:36:21","","","","",,,,,1,0.07,1,2,15,"Knowledge representation is a traditional field in artificial intelligence. Researchers have developed various ways to represent and share information among intelligent agents. Agents that share resources, data, information, and knowledge perform better than agents working alone. However, previous research also reveals that sharing knowledge among a large number of entities in an open environment is a problem yet to be solved. Intelligent robots are designed and produced by different manufactures. They have various physical attributes, use different knowledge representations and have different needs. In this research, we pose robot knowledge sharing as an activity to be developed in an open environment the World Wide Web. Just as search engines like Google provide enormous power for information exchange and sharing for humans, we believe a searching mechanism designed for intelligent agents can provide a robust approach for sharing knowledge among robots. We have developed knowledge representation for robots that allows Internet access and a knowledge organization and search indexing engine that performs knowledge retrieval.","",""
54,"M. Do, W. Ruml, Rong Zhou","On-line Planning and Scheduling: An Application to Controlling Modular Printers",2008,"","","","",184,"2022-07-13 09:36:21","","10.1613/jair.3184","","",,,,,54,3.86,18,3,14,"This paper summarizes recent work reported at ICAPS on applying artificial intelligence techniques to the control of production printing equipment. Like many other real-world applications, such as mobile robotics, this complex domain requires real-time autonomous decision-making and robust continual operation. To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning. At the heart of our system is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling. For example, our planning-graph-based planning heuristic takes resource contention into account when estimating makespan remaining. We suggest that this general architecture may prove useful as more intelligent systems operate in continual, online settings. Our system has enabled a new product architecture for our industrial partner and has been used to drive several commercial prototypes. When compared with stateof-the-art off-line planners, our system is hundreds of times faster and often finds better plans.","",""
32,"Kiem-Hieu Nguyen, Cheolyoung Ock","Word sense disambiguation as a traveling salesman problem",2013,"","","","",185,"2022-07-13 09:36:21","","10.1007/s10462-011-9288-9","","",,,,,32,3.56,16,2,9,"","",""
15,"Arthur Ieumwananonthachai, B. Wah","Statistical generalization of performance-related heuristics for knowledge-lean applications",1995,"","","","",186,"2022-07-13 09:36:21","","10.1109/TAI.1995.479511","","",,,,,15,0.56,8,2,27,"We present new results on the automated generalization of performance-related heuristics learned for knowledge-lean applications. We study methods to statistically generalize new heuristics learned for some small subsets of a problem space (using methods such as genetics-based learning) to unlearned problem subdomains. Our method uses a new statistical metric called probability of win. By assessing the performance of heuristics in a range-independent and distribution-independent manner, we can compare heuristics across problem subdomains in a consistent manner. To illustrate our approach, we show experimental results on generalizing heuristics learned for sequential circuit testing, VLSI cell placement and routing, and branch-and-bound search. We show that generalization can lead to new and robust heuristics that perform better than the original heuristics across problem instances of different characteristics.","",""
14,"Ee-Peng Lim, V. Cherkassky","Semantic networks and associative databases: two approaches to knowledge representation and reasoning",1992,"","","","",187,"2022-07-13 09:36:21","","10.1109/64.153462","","",,,,,14,0.47,7,2,30,"Two models, one originating from an artificial-intelligence paradigm and the other from database research, that incorporate connectionist techniques into their knowledge representation and reasoning processes are described. The first approach, called evidential reasoning, is based on semantic networks and focuses on solving inheritance and recognition queries using a rich internal structure. The second approach, called the associative relational database, provides a query language to manipulate knowledge stored in simple uniform structures. In addition to solving ordinary information retrieval, associative databases support robust retrieval with imprecise queries, which is impossible in traditional databases. The two modeling techniques are compared.<<ETX>>","",""
62,"C. Lo, Y. Wong, A. Rad","Intelligent system for process supervision and fault diagnosis in dynamic physical systems",2006,"","","","",188,"2022-07-13 09:36:21","","10.1109/TIE.2006.870707","","",,,,,62,3.88,21,3,16,"In recent years, the increasing complexity of process plants and other engineered systems has extended the scope of interest in control engineering, which was previously focused on the development of controllers for specified performance criteria such as stability and precision. Modern industrial systems require a higher demand of system reliability, safety, and low-cost operation, which in turn call for sophisticated and elegant fault-detection and isolation algorithms. This paper develops an intelligent supervisory coordinator (ISC) for process supervision and fault diagnosis in dynamic physical systems. A qualitative bond graph modeling scheme, integrating artificial-intelligence techniques with control engineering, is used to construct the knowledge base of the ISC. A supervisor provided by the ISC utilizes the knowledge in the knowledge base to classify various system behaviors, coordinates different control tasks (e.g., fault diagnosis), and communicates system states to human operators. The ISC provides a robust semiautonomous system to assist human operators in managing dynamic physical systems. The proposed ISC has been successfully applied to supervise a laboratory-scale servo-tank liquid process rig.","",""
11,"V. Clément, M. Thonnat","Handling knowledge in image processing libraries to build automatic systems",1989,"","","","",189,"2022-07-13 09:36:21","","10.1109/MIV.1989.40547","","",,,,,11,0.33,6,2,33,"Automatic vision systems are needed to build industrial applications able to adapt themselves to their environment. To allow the development of such robust applications, the authors propose a software tool named OCAPI, which uses artificial intelligence techniques, to handle knowledge about components of software libraries including their goals and their proper usage. An example of a knowledge base for a pattern recognition problem is presented.<<ETX>>","",""
10,"D. Galar, U. Kumar, Yuan Fuqing","RUL prediction using moving trajectories between SVM hyper planes",2012,"","","","",190,"2022-07-13 09:36:21","","10.1109/RAMS.2012.6175481","","",,,,,10,1.00,3,3,10,"With increasing amounts of data being generated by businesses and researchers, there is a need for fast, accurate and robust algorithms for data analysis. Improvements in database's technology, computing performance and artificial intelligence have contributed to the development of intelligent data analysis. The primary aim of data mining is knowledge discovery, i.e. patterns in the data that lead to better understanding of the data generating process and to useful predictions. The knowledge that becomes available through data mining enables an asset owner to make important decisions about life cycle costs in advance. In maintenance field, CMMS (Computer maintenance management system) and CM (Condition Monitoring) are the most popular software available in the industries. Since first one stores all historical data, maintenance actions, events and ma nufacturer recommendations, second one collects and stores all critical physical parameters (vibration, temperature.) to be monitored in a regular time basis. However, converting these data into useful information is a challenge. The degradation process of a system may be affected by many unknown factors, such as unidentified fault modes, unmeasured operational conditions, engineering variance, environmental conditions, etc. These unknown factors not only complicate the degradation behaviors of the system, but also make it difficult to collect quality data. Due to lack of knowledge and incomplete measurements, certain important con text information (e.g. fault modes, operational conditions) of the collected data will be missing. Therefore, historical data of the system with a large variety of degradation patterns will be mixed together. With such data, learning a global model for Remaining Useful Life (RUL) prediction becomes extremely hard since the end user does not have enough and good-quality data to model properly the system. This has led us to look for advanced RUL prediction techniques beyond the traditional RUL prediction models. The degradation process for many engineering systems, especially mechanical systems, is irreversible unless the condition is recovered by effective maintenance actions. The irreversible degradation process does not necessarily imply that the observed features will exhibit a monotonic progression pattern during degradation. Such progression pattern is sometimes hard to model using parametric methods. Considering a degradation process involving no or limited maintenance, the process may compose of a sequence of irreversible stages (either discrete or continuous) from new to be worn out, which can be implicitly expressed by the trajectory of the measured condition data or features. Therefore, the RUL of the system can be estimated if its future degradation trend can be projected from those historical instances. In this paper, a novel RUL prediction method inspired by feature maps and SVM classifiers is proposed. The historical instances of a system with life-time condition data are used to create a classification by SVM hyper planes. For a test instance of the same system, whose RUL is going to be estimated, degradation speed is evaluated by computing the minimal distance defined based on the degradation trajectories, i.e. the approach of the system to the hyper plane that segregates good and bad condition data at a different time horizon. Therefore, the final RUL of a specific component can be estimated, and global RUL information can then be obtained by aggregating the multiple RUL estimations using a density estimation method. Proposed model develops an effective RUL prediction method that addresses multiple challenges in complex system prognostics, where many parameters are unknown. Similarities between degradation trajectories can be checked in order to enrich existing methodologies in prognostic's applications. Existing CM data for bearings will be used to verify the model.","",""
2,"Monica Ward","ICALL's Relevance to CALL.",2017,"","","","",191,"2022-07-13 09:36:21","","10.14705/rpnet.2017.eurocall2017.735","","",,,,,2,0.40,2,1,5,"The term Intelligent Computer Assisted Language Learning (ICALL) covers many different aspects of CALL that add something extra to a CALL resource. This could be with the use of computational linguistics or Artificial Intelligence (AI). ICALL tends to be not very well understood within the CALL community. There may also be the slight fear factor around ICALL, as it may seem very complicated and hard to understand. There is also the fact that ICALL resources tend to not be widely used in CALL as they may not be sufficiently robust enough for learners or they may not address a specific pedagogical need (Heift & Schulze, 2007). This paper looks at how some (basic) ICALL resources can be used in CALL. There is a need for ICALL and CALL researchers to work together to ensure that both benefit from each other’s knowledge and expertise. ICALL has progressed in recent years and it is important for the ICALL community to raise awareness of what ICALL can bring to the CALL toolbox and to encourage CALL researchers to dip their toes in the ICALL waters.","",""
13,"J. Goldman","Pattern theoretic knowledge discovery",1994,"","","","",192,"2022-07-13 09:36:21","","10.1109/TAI.1994.346400","","",,,,,13,0.46,13,1,28,"Future research directions in knowledge discovery in databases (KDD) include the ability to extract an overlying concept relating useful data. Current limitations involve the search complexity to find that concept and what it means to be ""useful."" The pattern theory research crosses over in a natural way to the aforementioned domain. The goal of this paper is threefold. First, we present a new approach to the problem of learning by discovery and robust pattern finding. Second, we explore the current limitations of a pattern theoretic approach as applied to the general KDD problem. Third, we exhibit its performance with experimental results on binary functions, and we compare those results with C4.5. This new approach to learning demonstrates a powerful method for finding patterns in a robust manner.<<ETX>>","",""
73,"L. Valiant","A neuroidal architecture for cognitive computation",1998,"","","","",193,"2022-07-13 09:36:21","","10.1145/355483.355486","","",,,,,73,3.04,73,1,24,"An architecture is described for designing systems that acquire and ma nipulate large amounts of unsystematized, or so-called commonsense, knowledge. Its aim is to exploit to the full those aspects of computational learning that are known to offer powerful solutions in the acquisition and maintenance of robust knowledge bases. The architecture makes explicit the requirements on the basic computational tasks that are to be performed and is designed to make this computationally tractable even for very large databases. The main claims are that (i) the basic learning and deduction tasks are provably tractable and (ii) tractable learning offers viable approaches to a range of issues that have been previously identified as problematic for artificial intelligence systems that are programmed. Among the issues that learning offers to resolve are robustness to inconsistencies, robustness to incomplete information and resolving among alternatives. Attribute-efficient learning algorithms, which allow learning from few examples in large dimensional systems, are fundamental to the approach. Underpinning the overall architecture is a new principled approach to manipulating relations in learning systems. This approach, of independently quantified arguments, allows propositional learning algorithms to be applied systematically to learning relational concepts in polynomial time and in modular fashion.","",""
1,"C. Voyant, C. Paoli, M. Nivet, G. Notton, A. Fouilloy, F. Motte","Multi-layer Perceptron and Pruning",2017,"","","","",194,"2022-07-13 09:36:21","","","","",,,,,1,0.20,0,6,5,"A Multi-Layer Perceptron (MLP) defines a family of artificial neural networks often used in TS modeling and forecasting. Because of its “black box” aspect, many researchers refuse to use it. Moreover, the optimization (often based on the exhaustive approach where “all” configurations are tested) and learning phases of this artificial intelligence tool (often based on the Levenberg-Marquardt algorithm; LMA) are weaknesses of this approach (exhaustively and local minima). These two tasks must be repeated depending on the knowledge of each new problem studied, making the process, long, laborious and not systematically robust. In this short communication, a pruning process is presented. This method allows, during the training phase, to carry out an inputs selecting method activating (or not) inter-nodes connections in order to verify if forecasting is improved. We propose to use iteratively the popular damped least-squares method to activate inputs and neurons. A first pass is applied to 10% of the learning sample to determine weights significantly different from 0 and delete other. Then a classical batch process based on LMA is used with the new MLP. The validation is done using 25 measured meteorological TS and cross-comparing the prediction results of the classical LMA and the 2-stage LMA.","",""
1,"Nicholas Fung","Toward Real Time Autonomous Robotics Through Integration of Hierarchical Goal Network Planning and Low Level Control Libraries",2017,"","","","",195,"2022-07-13 09:36:21","","","","",,,,,1,0.20,1,1,5,"Automated planning has become an increasingly influential area of research in the realm of artificial intelligence. Task based planning algorithms provide a number of advantages including the ease of human readability when creating mission length plans. However, task based planning algorithms are rarely implement on real world robotic systems because they require additional domain specific knowledge to define tasks and are generally not as flexible as other planning techniques. This paper documents work to integrate a hierarchical goal network planning algorithm with low level path planning. The system utilizes the Goal Decomposition with Landmarks (GoDeL) planner for plan generation at an abstract level and the Searched Based Planning Library (SBPL) for low level control. The system is used to direct a robot through an office setting within a simulation environment. We then discuss incorporating an ”in the now” approach to the GoDeL algorithm to make the system more robust to a dynamic environment. The resulting algorithm is more suited for use in real time applications such as autonomous robotics.","",""
7,"D. Neumann, Tommaso Mansi, L. Itu, B. Georgescu, E. Kayvanpour, F. Sedaghat-Hamedani, J. Haas, H. Katus, B. Meder, S. Steidl, J. Hornegger, D. Comaniciu","Vito - A Generic Agent for Multi-physics Model Personalization: Application to Heart Modeling",2015,"","","","",196,"2022-07-13 09:36:21","","10.1007/978-3-319-24571-3_53","","",,,,,7,1.00,1,12,7,"","",""
81,"B. Werger, M. Matarić","From insect to Internet: Situated control for networked robot teams",2001,"","","","",197,"2022-07-13 09:36:21","","10.1023/A:1016650101473","","",,,,,81,3.86,41,2,21,"","",""
19,"P. Brézillon","From expert systems to context-based intelligent assistant systems: a testimony",2011,"","","","",198,"2022-07-13 09:36:21","","10.1017/S0269888910000366","","",,,,,19,1.73,19,1,11,"Abstract This paper presents a personal interpretation of the evolution of artificial intelligence (AI) systems during these last 25 years. This evolution is presented along five generations of AI systems, namely expert systems, joint cognitive systems, intelligent systems, intelligent assistant systems, and the coming generation of context-based intelligent assistant systems. Our testimony relies on different real-world applications in different domains, especially for the French national power company, the subway companies in Paris and in Rio de Janeiro, in medicine, a platform for e-maintenance, road safety, and open sources. Our main claim is to underline that the next generation of AI systems (context-based intelligent assistant systems) requires a radically different consideration on context and its relations with the users, the task at hand, the situation, and the environment in which the task is accomplish by the user; the observation of users through their behaviors and not a profile library; a robust conceptual framework for modeling and managing context; and a computational tool for representing in a uniform way pieces of knowledge, of reasoning, and of contexts.","",""
0,"Wenqin Wu","Simple Dynamic Coattention Networks",2017,"","","","",199,"2022-07-13 09:36:21","","","","",,,,,0,0.00,0,1,5,"Reading comprehension (RC), or the capability to process document texts and answer questions about them is a difficult task for machines, as human language understanding and real-world knowledge are needed [4]. This can serve a wide range of applications, from simplifying information retrieval processes to building more robust artificial intelligence. Previously, most natural language processing was done with classical probabilistic models. With the recent progress in deep learning, more researchers are switching to using neural networks as they are proven to produce better results.","",""
0,"Xiaomin Wang","A Novel Robot Motion Planning Model Based on Visual Navigation and Fuzzy Control",2017,"","","","",200,"2022-07-13 09:36:21","","10.12783/DTSSEHS/ASSHM2016/8380","","",,,,,0,0.00,0,1,5,"In this paper, we propose the novel robot motion planning model based on the visual navigation and fuzzy control. A robot operating system can be viewed as the mechanical energy converter from the joint space to the global operation space, and the flexibility of the robot system reflects the global transformation ability of the whole system. Fuzzy control technology is a kind of fuzzy science, artificial intelligence, knowledge engineering and other disciplines interdisciplinary fields, the theory of strong science and technology, to achieve this fuzzy control technology theory, known as the fuzzy control theory. Besides this, this paper integrates the visual navigation system to construct the better robust methodology which is meaningful.","",""
