Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
21,"Shibo Zhou, Li Xiaohua, Ying Chen, S. T. Chandrasekaran, A. Sanyal","Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance",2019,"","","","",1,"2022-07-13 10:10:34","","","","",,,,,21,7.00,4,5,3,"Spiking neural network (SNN) is interesting both theoretically and practically because of its strong bio-inspiration nature and potentially outstanding energy efficiency. Unfortunately, its development has fallen far behind the conventional deep neural network (DNN), mainly because of difficult training and lack of widely accepted hardware experiment platforms. In this paper, we show that a deep temporal-coded SNN can be trained easily and directly over the benchmark datasets CIFAR10 and ImageNet, with testing accuracy within 1% of the DNN of equivalent size and architecture. Training becomes similar to DNN thanks to the closed-form solution to the spiking waveform dynamics. Considering that SNNs should be implemented in practical neuromorphic hardwares, we train the deep SNN with weights quantized to 8, 4, 2 bits and with weights perturbed by random noise to demonstrate its robustness in practical applications. In addition, we develop a phase-domain signal processing circuit schematic to implement our spiking neuron with 90% gain of energy efficiency over existing work. This paper demonstrates that the temporal-coded deep SNN is feasible for applications with high performance and high energy efficient.","",""
36,"Shisheng Hu, Yiyang Pei, Paul Pu Liang, Ying-Chang Liang","Deep Neural Network for Robust Modulation Classification Under Uncertain Noise Conditions",2020,"","","","",2,"2022-07-13 10:10:34","","10.1109/TVT.2019.2951594","","",,,,,36,18.00,9,4,2,"Recently, classifying the modulation schemes of signals using deep neural network has received much attention. In this paper, we introduce a general model of deep neural network (DNN)-based modulation classifiers for single-input single-output (SISO) systems. Its feasibility is analyzed using maximum a posteriori probability (MAP) criterion and its robustness to uncertain noise conditions is compared to that of the conventional maximum likelihood (ML)-based classifiers. To reduce the design and training cost of DNN classifiers, a simple but effective pre-processing method is introduced and adopted. Furthermore, featuring multiple recurrent neural network (RNN) layers, the DNN modulation classifier is realized. Simulation results show that the proposed RNN-based classifier is robust to the uncertain noise conditions, and the performance of it approaches to that of the ideal ML classifier with perfect channel and noise information. Moreover, with a much lower complexity, it outperforms the existing ML-based classifiers, specifically, expectation maximization (EM) and expectation conditional maximization (ECM) classifiers which iteratively estimate channel and noise parameters. In addition, the proposed classifier is shown to be invariant to the signal distortion such as frequency offset. Furthermore, the adopted pre-processing method is shown to accelerate the training process of our proposed classifier, thus reducing the training cost. Lastly, the computational complexity of our proposed classifier is analyzed and compared to other traditional ones, which further demonstrates its overall advantage.","",""
53,"Xin Liao, Kaide Li, Xinshan Zhu, K. J. R. Liu","Robust Detection of Image Operator Chain With Two-Stream Convolutional Neural Network",2020,"","","","",3,"2022-07-13 10:10:34","","10.1109/JSTSP.2020.3002391","","",,,,,53,26.50,13,4,2,"Many forensic techniques have recently been developed to determine whether an image has undergone a specific manipulation operation. When multiple consecutive operations are applied to images, forensic analysts not only need to identify the existence of each manipulation operation, but also to distinguish the order of the involved operations. However, image operator chain detection is still a challenging problem. In this paper, an order forensics framework for detecting image operator chain based on convolutional neural network (CNN) is presented. Two-stream CNN architecture is designed to capture both tampering artifact evidence and local noise residual evidence. Specifically, the new CNN-based method is proposed for forensically detecting a chain made of two image operators, which could automatically learn manipulation detection features directly from image data. Further, we empirically investigate the robustness of our proposed method in two practical scenarios: forensic investigators have no access to the operating parameters, and manipulations are applied to a JPEG compressed image. Experimental results show that the proposed framework not only obtains significant detection performance but also can distinguish the order in some cases that previous works were unable to identify.","",""
181,"Mingchen Li, M. Soltanolkotabi, Samet Oymak","Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks",2019,"","","","",4,"2022-07-13 10:10:34","","","","",,,,,181,60.33,60,3,3,"Modern neural networks are typically trained in an over-parameterized regime where the parameters of the model far exceed the size of the training data. Such neural networks in principle have the capacity to (over)fit any set of labels including pure noise. Despite this, somewhat paradoxically, neural network models trained via first-order methods continue to predict well on yet unseen test data. This paper takes a step towards demystifying this phenomena. Under a rich dataset model, we show that gradient descent is provably robust to noise/corruption on a constant fraction of the labels despite overparameterization. In particular, we prove that: (i) In the first few iterations where the updates are still in the vicinity of the initialization gradient descent only fits to the correct labels essentially ignoring the noisy labels. (ii) to start to overfit to the noisy labels network must stray rather far from from the initialization which can only occur after many more iterations. Together, these results show that gradient descent with early stopping is provably robust to label noise and shed light on the empirical robustness of deep networks as well as commonly adopted heuristics to prevent overfitting.","",""
17,"Thi Ngoc Tho Nguyen, W. Gan, R. Ranjan, Douglas L. Jones","Robust Source Counting and DOA Estimation Using Spatial Pseudo-Spectrum and Convolutional Neural Network",2020,"","","","",5,"2022-07-13 10:10:34","","10.1109/TASLP.2020.3019646","","",,,,,17,8.50,4,4,2,"Many signal processing-based methods for sound source direction-of-arrival estimation produce a spatial pseudo-spectrum of which the local maxima strongly indicate the source directions. Due to different levels of noise, reverberation and different number of overlapping sources, the spatial pseudo-spectra are noisy even after smoothing. In addition, the number of sources is often unknown. As a result, selecting the peaks from these spectra is susceptible to error. Convolutional neural network has been successfully applied to many image processing problems in general and direction-of-arrival estimation in particular. In addition, deep learning-based methods for direction-of-arrival estimation show good generalization to different environments. We propose to use a 2D convolutional neural network with multi-task learning to robustly estimate the number of sources and the directions-of-arrival from short-time spatial pseudo-spectra, which have useful directional information from audio input signals. This approach reduces the tendency of the neural network to learn unwanted association between sound classes and directional information, and helps the network generalize to unseen sound classes. The simulation and experimental results show that the proposed methods outperform other directional-of-arrival estimation methods in different levels of noise and reverberation, and different number of sources.","",""
93,"Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh","Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network",2018,"","","","",6,"2022-07-13 10:10:34","","","","",,,,,93,23.25,23,4,4,"We present a new algorithm to train a robust neural network against adversarial attacks. Our algorithm is motivated by the following two ideas. First, although recent work has demonstrated that fusing randomness can improve the robustness of neural networks (Liu 2017), we noticed that adding noise blindly to all the layers is not the optimal way to incorporate randomness. Instead, we model randomness under the framework of Bayesian Neural Network (BNN) to formally learn the posterior distribution of models in a scalable way. Second, we formulate the mini-max problem in BNN to learn the best model distribution under adversarial attacks, leading to an adversarial-trained Bayesian neural net. Experiment results demonstrate that the proposed algorithm achieves state-of-the-art performance under strong attacks. On CIFAR-10 with VGG network, our model leads to 14\% accuracy improvement compared with adversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD attack with $0.035$ distortion, and the gap becomes even larger on a subset of ImageNet.","",""
49,"Jiabao Yu, A. Hu, Guyue Li, Linning Peng","A Robust RF Fingerprinting Approach Using Multisampling Convolutional Neural Network",2019,"","","","",7,"2022-07-13 10:10:34","","10.1109/JIOT.2019.2911347","","",,,,,49,16.33,12,4,3,"With the increasing popularity of the Internet of Things (IoT), device identification, and authentication has become a critical security issue. Recently, radio frequency (RF) fingerprint-based identification schemes have attracted wide attention as they extract the inherent characteristics of hardware circuits which is very hard to forge. However, existing RF fingerprint-based approaches face the problems of unstable region of interest (ROI), high-cost feature design, and incomplete automation. To address these problems, this paper proposes a multisampling convolutional neural network (MSCNN) to extract RF fingerprint from the selected ROI for classifying ZigBee devices. A signal-to-noise ratio (SNR) adaptive ROI selection algorithm is also developed to alleviate the effect of semi-steady behavior of ZigBee devices owing to sleep mode switching. The proposed MSCNN uses multiple downsampling transformations for multiscale feature extraction and classification automatically. To validate and evaluate the performance of our proposed method, we design a testbed consisting of one low-cost universal software radio peripheral (USRP) as the receiver and 54 CC2530 devices as targets for identification. Extensive experiments are conducted to demonstrate the feasibility and reliability of MSCNN both in the line-of-sight (LOS) scenarios and non-LOS (NLOS) scenarios. The classification accuracy is as high as 97% under the LOS scenarios around SNR = 30 dB. Our scheme is robust over a wide range of SNRs under the LOS scenarios as well as under the NLOS scenarios.","",""
33,"Venkata S. Kadimesetty, Sreedevi Gutta, S. Ganapathy, P. Yalavarthy","Convolutional Neural Network-Based Robust Denoising of Low-Dose Computed Tomography Perfusion Maps",2019,"","","","",8,"2022-07-13 10:10:34","","10.1109/TRPMS.2018.2860788","","",,,,,33,11.00,8,4,3,"The low-dose computed tomography (CT) perfusion data has low signal-to-noise ratio resulting in derived perfusion maps being noisy. These low-quality maps typically requires a denoising step to improve their utility in real-time. The existing methods, including state-of-the-art online sparse perfusion deconvolution (SPD), largely relies on the convolutional model that may not be applicable in all cases of brain perfusion. In this paper, a denoising convolutional neural network (DCNN) was proposed that relies only on computed perfusion maps for performing the denoising step. The network was trained with a large number of low-dose digital brain phantom perfusion maps to provide an approximation to the corresponding high-dose perfusion maps. The batch normalization coupled with residual learning makes the trained model invariant to the dynamic range of the input low-dose perfusion maps. The denoising of the raw-data using the convolutional neural network was also attempted here and shown to have limited applicability in the low-dose CT perfusion cases. The digital perfusion phantom as well as in-vivo results indicate that the proposed DCNN applied in the derived map domain provides superior improvement compared to the online SPD with an added advantage of being computationally efficient.","",""
42,"Zhonghui You, Jinmian Ye, Kunming Li, Ping Wang","Adversarial Noise Layer: Regularize Neural Network by Adding Noise",2018,"","","","",9,"2022-07-13 10:10:34","","10.1109/ICIP.2019.8803055","","",,,,,42,10.50,11,4,4,"In this paper, we introduce a novel regularization method called Adversarial Noise Layer (ANL), which are able to significantly improve CNN’s generalization ability by adding carefully crafted noise into the intermediate layer activations. ANL can be easily implemented and integrated with most of the mainstream CNN-based models. We compared the effects of the different types of noise and visually demonstrate that our proposed adversarial noise instruct CNN models to learn to extract cleaner feature maps, which further reduce the risk of over-fitting. We also conclude that models trained with ANL are more robust to the adversarial examples generated by FGSM than the traditional adversarial training approaches.","",""
54,"Ilyas Ozer, Z. Ozer, O. Findik","Noise robust sound event classification with convolutional neural network",2018,"","","","",10,"2022-07-13 10:10:34","","10.1016/j.neucom.2017.07.021","","",,,,,54,13.50,18,3,4,"","",""
29,"Shisheng Hu, Yiyang Pei, Paul Pu Liang, Ying-Chang Liang","Robust Modulation Classification under Uncertain Noise Condition Using Recurrent Neural Network",2018,"","","","",11,"2022-07-13 10:10:34","","10.1109/GLOCOM.2018.8647582","","",,,,,29,7.25,7,4,4,"Modulation classification using deep neural networks has recently received increasing attention due to its capability in learning rich features of data. In this paper, we propose a low- complexity blind data-driven modulation classifier. Our classifier operates robustly over Rayleigh fading channels under uncertain noise conditions modeled using a mixture of three types of noise, namely, white Gaussian noise, white non- Gaussian noise and correlated non-Gaussian noise. The proposed classifier consists of several layers of recurrent neural networks (RNN) which is well-suited for learning representations from time-correlated data. The classifier is trained using the labeled raw signal samples generated under different noise conditions. Simulation results show that the performance of our proposed classifier approaches that of maximum likelihood classifiers with perfect channel knowledge and outperforms existing expectation maximum (EM) and expectation conditional maximum (ECM) classifiers which iteratively estimate channel and noise parameters.","",""
19,"Suwon Shon, Tae-Hyun Oh, James R. Glass","Noise-tolerant Audio-visual Online Person Verification Using an Attention-based Neural Network Fusion",2018,"","","","",12,"2022-07-13 10:10:34","","10.1109/ICASSP.2019.8683477","","",,,,,19,4.75,6,3,4,"In this paper, we present a multi-modal online person verification system using both speech and visual signals. Inspired by neuroscientific findings on the association of voice and face, we propose an attention-based end-to-end neural network that learns multi-sensory association for the task of person verification. The attention mechanism in our proposed network learns to conditionally select a salient modality between speech and facial representations that provides a balance between complementary inputs. By virtue of this capability, the network is robust to missing or corrupted data from either modality. In the VoxCeleb2 dataset, we show that our method performs favorably against competing multi-modal methods. Even for extreme cases of large corruption or missing data on either modality, our method demonstrates robustness over other unimodal methods.","",""
22,"Masaki Kobayashi","Noise Robust Projection Rule for Hyperbolic Hopfield Neural Networks",2020,"","","","",13,"2022-07-13 10:10:34","","10.1109/TNNLS.2019.2899914","","",,,,,22,11.00,22,1,2,"A complex-valued Hopfield neural network (CHNN) is a multistate Hopfield model. Low noise tolerance is the main disadvantage of CHNNs. The hyperbolic Hopfield neural network (HHNN) is a noise robust multistate Hopfield model. In HHNNs employing the projection rule, noise tolerance rapidly worsened as the number of training patterns increased. This result was caused by the self-loops. The projection rule for CHNNs improves noise tolerance by removing the self-loops, however, that for HHNNs cannot remove them. In this brief, we extended the stability condition for the self-loops of HHNNs and modified the projection rule. Thus, the HHNNs had improved noise tolerance.","",""
20,"Qinyu Jiang, F. Chang, Bowen Sheng","Bearing Fault Classification Based on Convolutional Neural Network in Noise Environment",2019,"","","","",14,"2022-07-13 10:10:34","","10.1109/ACCESS.2019.2919126","","",,,,,20,6.67,7,3,3,"Bearing fault diagnosis is an important technique in industrial production as bearings are one of the key components in rotating machines. In bearing fault diagnosis, complex environmental noises will lead to inaccurate results. To address the problem, bearing fault classification methods should be capable of noise resistance and be more robust. In previous studies, researchers mainly focus on noise-free condition, measured signal and signal with simulated noise, many effective approaches have been proposed. But in real-world working condition, strong and complex noises are often leads to inaccurate results. According to the situation, this work focuses on bearing fault classification under the influence of factory noise and the white Gaussian noise. In order to eliminate the noise interference and take the possible connection between signal frames into consideration, this paper presents a new bearing fault classification method based on convolutional neural networks (CNNs). By using the sensitivity to impulse of spectral kurtosis (SK), noises are repressed by the proposed filtering approach based on the SK. Mel-frequency cepstral coefficients (MFCC) and delta cepstrum are extracted as the feature by the reason of satisfactory performance in sound recognition. And in consideration of the connection between frames, a feature arrangement method is presented to transfer feature vectors to feature images, so the advantages of the CNNs in the fields of image processing can be exploited in the proposed method. The proposed method is demonstrated to have strong ability of classification under the interference of factory noise and the Gaussian noise by experiments.","",""
35,"K. Kinoshita, Tsubasa Ochiai, Marc Delcroix, T. Nakatani","Improving Noise Robust Automatic Speech Recognition with Single-Channel Time-Domain Enhancement Network",2020,"","","","",15,"2022-07-13 10:10:34","","10.1109/ICASSP40776.2020.9053266","","",,,,,35,17.50,9,4,2,"With the advent of deep learning, research on noise-robust automatic speech recognition (ASR) has progressed rapidly. However, ASR performance in noisy conditions of single-channel systems remains unsatisfactory. Indeed, most single-channel speech enhancement (SE) methods (denoising) have brought only limited performance gains over state-of-the-art ASR back-end trained on multi-condition training data. Recently, there has been much research on neural network-based SE methods working in the time-domain showing levels of performance never attained before. However, it has not been established whether the high enhancement performance achieved by such time-domain approaches could be translated into ASR. In this paper, we show that a single-channel time-domain denoising approach can significantly improve ASR performance, providing more than 30 % relative word error reduction over a strong ASR back-end on the real evaluation data of the single-channel track of the CHiME-4 dataset. These positive results demonstrate that single-channel noise reduction can still improve ASR performance, which should open the door to more research in that direction.","",""
760,"Giorgio Patrini, A. Rozza, A. Menon, R. Nock, Lizhen Qu","Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach",2016,"","","","",16,"2022-07-13 10:10:34","","10.1109/CVPR.2017.240","","",,,,,760,126.67,152,5,6,"We present a theoretically grounded approach to train deep neural networks, including recurrent networks, subject to class-dependent label noise. We propose two procedures for loss correction that are agnostic to both application domain and network architecture. They simply amount to at most a matrix inversion and multiplication, provided that we know the probability of each class being corrupted into another. We further show how one can estimate these probabilities, adapting a recent technique for noise estimation to the multi-class setting, and thus providing an end-to-end framework. Extensive experiments on MNIST, IMDB, CIFAR-10, CIFAR-100 and a large scale dataset of clothing images employing a diversity of architectures &#x2014; stacking dense, convolutional, pooling, dropout, batch normalization, word embedding, LSTM and residual layers &#x2014; demonstrate the noise robustness of our proposals. Incidentally, we also prove that, when ReLU is the only non-linearity, the loss curvature is immune to class-dependent label noise.","",""
203,"Tian Wang, Yang Chen, Meina Qiao, H. Snoussi","A fast and robust convolutional neural network-based defect detection model in product quality control",2018,"","","","",17,"2022-07-13 10:10:34","","10.1007/S00170-017-0882-0","","",,,,,203,50.75,51,4,4,"","",""
55,"R. Kamaleswaran, Ruhi Mahajan, O. Akbilgic","A robust deep convolutional neural network for the classification of abnormal cardiac rhythm using single lead electrocardiograms of variable length.",2018,"","","","",18,"2022-07-13 10:10:34","","10.1088/1361-6579/aaaa9d","","",,,,,55,13.75,18,3,4,"OBJECTIVE Atrial fibrillation (AF) is a major cause of hospitalization and death in the United States. Moreover, as the average age of individuals increases around the world, early detection and diagnosis of AF become even more pressing. In this paper, we introduce a novel deep learning architecture for the detection of normal sinus rhythm, AF, other abnormal rhythms, and noise.   APPROACH We have demonstrated through a systematic approach many hyperparameters, input sets, and optimization methods that yielded influence in both training time and performance accuracy. We have focused on these properties to identify an optimal 13-layer convolutional neural network (CNN) model which was trained on 8528 short single-lead ECG recordings and evaluated on a test dataset of 3658 recordings.   MAIN RESULTS The proposed CNN architecture achieved a state-of-the-art performance in identifying normal, AF and other rhythms with an average F 1-score of 0.83.   SIGNIFICANCE We have presented a robust deep learning-based architecture that can identify abnormal cardiac rhythms using short single-lead ECG recordings. The proposed architecture is computationally fast and can also be used in real-time cardiac arrhythmia detection applications.","",""
376,"Aritra Ghosh, Himanshu Kumar, P. Sastry","Robust Loss Functions under Label Noise for Deep Neural Networks",2017,"","","","",19,"2022-07-13 10:10:34","","10.1609/aaai.v31i1.10894","","",,,,,376,75.20,125,3,5,"    In many applications of classifier learning, training data suffers from label noise. Deep networks are learned using huge training data where the problem of noisy labels is particularly relevant. The current techniques proposed for learning deep networks under label noise focus on modifying the network architecture and on algorithms for estimating true labels from noisy labels. An alternate approach would be to look for loss functions that are inherently noise-tolerant. For binary classification there exist theoretical results on loss functions that are robust to label noise. In this paper, we provide some sufficient conditions on a loss function so that risk minimization under that loss function would be inherently tolerant to label noise for multiclass classification problems. These results generalize the existing results on noise-tolerant loss functions for binary classification. We study some of the widely used loss functions in deep networks and show that the loss function based on mean absolute value of error is inherently robust to label noise. Thus standard back propagation is enough to learn the true classifier even under label noise. Through experiments, we illustrate the robustness of risk minimization with such loss functions for learning neural networks.   ","",""
22,"Xu-Chen Yang, M. Yung, Xin Wang","Neural-network-designed pulse sequences for robust control of singlet-Triplet qubits",2017,"","","","",20,"2022-07-13 10:10:34","","10.1103/PhysRevA.97.042324","","",,,,,22,4.40,7,3,5,"Composite pulses are essential for universal manipulation of singlet-triplet spin qubits. In the absence of noise, they are required to perform arbitrary single-qubit operations due to the special control constraint of a singlet-triplet qubits; while in a noisy environment, more complicated sequences have been developed to dynamically correct the error. Tailoring these sequences typically requires numerically solving a set of nonlinear equations. Here we demonstrate that these pulse sequences can be generated by a well-trained, double-layer neural network. For sequences designed for the noise-free case, the trained neural network is capable of producing almost exactly the same pulses known in the literature. For more complicated noise-correcting sequences, the neural network produces pulses with slightly different line-shapes, but the robustness against noises remains comparable. These results indicate that the neural network can be a judicious and powerful alternative to existing techniques, in developing pulse sequences for universal fault-tolerant quantum computation.","",""
27,"Sheng Zhang, W. Zheng","Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment",2018,"","","","",21,"2022-07-13 10:10:34","","10.1109/TNNLS.2017.2761259","","",,,,,27,6.75,14,2,4,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.","",""
17,"S. Roy, Sk. Imran Hossain, M. Akhand, K. Murase","A Robust System for Noisy Image Classification Combining Denoising Autoencoder and Convolutional Neural Network",2018,"","","","",22,"2022-07-13 10:10:34","","10.14569/IJACSA.2018.090131","","",,,,,17,4.25,4,4,4,"Image classification, a complex perceptual task with many real life important applications, faces a major challenge in presence of noise. Noise degrades the performance of the classifiers and makes them less suitable in real life scenarios. To solve this issue, several researches have been conducted utilizing denoising autoencoder (DAE) to restore original images from noisy images and then Convolutional Neural Network (CNN) is used for classification. The existing models perform well only when the noise level present in the training set and test set are same or differs only a little. To fit a model in real life applications, it should be independent to level of noise. The aim of this study is to develop a robust image classification system which performs well at regular to massive noise levels. The proposed method first trains a DAE with low-level noise-injected images and a CNN with noiseless native images independently. Then it arranges these two trained models in three different combinational structures: CNN, DAE-CNN, and DAE-DAE-CNN to classify images corrupted with zero, regular and massive noises, accordingly. Final system outcome is chosen by applying the winner-takes-all combination on individual outcomes of the three structures. Although proposed system consists of three DAEs and three CNNs in different structure layers, the DAEs and CNNs are the copy of same DAE and CNN trained initially which makes it computationally efficient as well. In DAE-DAE-CNN, two identical DAEs are arranged in a cascaded structure to make the structure well suited for classifying massive noisy data while the DAE is trained with low noisy image data. The proposed method is tested with MNIST handwritten numeral dataset with different noise levels. Experimental results revealed the effectiveness of the proposed method showing better results than individual structures as well as the other related methods.","",""
631,"S. Gu, Luca Rigazio","Towards Deep Neural Network Architectures Robust to Adversarial Examples",2014,"","","","",23,"2022-07-13 10:10:34","","","","",,,,,631,78.88,316,2,8,"Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. How- ever, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty.","",""
32,"Jung Hwan Lee, Jaekyum Kim, Byeoungdo Kim, D. Yoon, J. Choi","Robust Automatic Modulation Classification Technique for Fading Channels via Deep Neural Network",2017,"","","","",24,"2022-07-13 10:10:34","","10.3390/e19090454","","",,,,,32,6.40,6,5,5,"In this paper, we propose a deep neural network (DNN)-based automatic modulation classification (AMC) for digital communications. While conventional AMC techniques perform well for additive white Gaussian noise (AWGN) channels, classification accuracy degrades for fading channels where the amplitude and phase of channel gain change in time. The key contributions of this paper are in two phases. First, we analyze the effectiveness of a variety of statistical features for AMC task in fading channels. We reveal that the features that are shown to be effective for fading channels are different from those known to be good for AWGN channels. Second, we introduce a new enhanced AMC technique based on DNN method. We use the extensive and diverse set of statistical features found in our study for the DNN-based classifier. The fully connected feedforward network with four hidden layers are trained to classify the modulation class for several fading scenarios. Numerical evaluation shows that the proposed technique offers significant performance gain over the existing AMC methods in fading channels.","",""
158,"Xu Yan, Chaoda Zheng, Zhuguo Li, Sheng Wang, Shuguang Cui","PointASNL: Robust Point Clouds Processing Using Nonlocal Neural Networks With Adaptive Sampling",2020,"","","","",25,"2022-07-13 10:10:34","","10.1109/cvpr42600.2020.00563","","",,,,,158,79.00,32,5,2,"Raw point clouds data inevitably contains outliers or noise through acquisition from 3D sensors or reconstruction algorithms. In this paper, we present a novel end-to-end network for robust point clouds processing, named PointASNL, which can deal with point clouds with noise effectively. The key component in our approach is the adaptive sampling (AS) module. It first re-weights the neighbors around the initial sampled points from farthest point sampling (FPS), and then adaptively adjusts the sampled points beyond the entire point cloud. Our AS module can not only benefit the feature learning of point clouds, but also ease the biased effect of outliers. To further capture the neighbor and long-range dependencies of the sampled point, we proposed a local-nonlocal (L-NL) module inspired by the nonlocal operation. Such L-NL module enables the learning process insensitive to noise. Extensive experiments verify the robustness and superiority of our approach in point clouds processing tasks regardless of synthesis data, indoor data, and outdoor data with or without noise. Specifically, PointASNL achieves state-of-the-art robust performance for classification and segmentation tasks on all datasets, and significantly outperforms previous methods on real-world outdoor SemanticKITTI dataset with considerate noise.","",""
268,"Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh","Towards Robust Neural Networks via Random Self-ensemble",2017,"","","","",26,"2022-07-13 10:10:34","","10.1007/978-3-030-01234-2_23","","",,,,,268,53.60,67,4,5,"","",""
223,"Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, C. Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, N. Chawla","A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data",2018,"","","","",27,"2022-07-13 10:10:34","","10.1609/aaai.v33i01.33011409","","",,,,,223,55.75,22,10,4,"Nowadays, multivariate time series data are increasingly collected in various real world systems, e.g., power plants, wearable devices, etc. Anomaly detection and diagnosis in multivariate time series refer to identifying abnormal status in certain time steps and pinpointing the root causes. Building such a system, however, is challenging since it not only requires to capture the temporal dependency in each time series, but also need encode the inter-correlations between different pairs of time series. In addition, the system should be robust to noise and provide operators with different levels of anomaly scores based upon the severity of different incidents. Despite the fact that a number of unsupervised anomaly detection algorithms have been developed, few of them can jointly address these challenges. In this paper, we propose a Multi-Scale Convolutional Recurrent Encoder-Decoder (MSCRED), to perform anomaly detection and diagnosis in multivariate time series data. Specifically, MSCRED first constructs multi-scale (resolution) signature matrices to characterize multiple levels of the system statuses in different time steps. Subsequently, given the signature matrices, a convolutional encoder is employed to encode the inter-sensor (time series) correlations and an attention based Convolutional Long-Short Term Memory (ConvLSTM) network is developed to capture the temporal patterns. Finally, based upon the feature maps which encode the inter-sensor correlations and temporal information, a convolutional decoder is used to reconstruct the input signature matrices and the residual signature matrices are further utilized to detect and diagnose anomalies. Extensive empirical studies based on a synthetic dataset and a real power plant dataset demonstrate that MSCRED can outperform state-ofthe-art baseline methods.","",""
56,"Aniekan Essien, C. Giannetti","A Deep Learning Model for Smart Manufacturing Using Convolutional LSTM Neural Network Autoencoders",2020,"","","","",28,"2022-07-13 10:10:34","","10.1109/TII.2020.2967556","","",,,,,56,28.00,28,2,2,"Time-series forecasting is applied to many areas of smart factories, including machine health monitoring, predictive maintenance, and production scheduling. In smart factories, machine speed prediction can be used to dynamically adjust production processes based on different system conditions, optimize production throughput, and minimize energy consumption. However, making accurate data-driven machine speed forecasts is challenging. Given the complex nature of industrial manufacturing process data, predictive models that are robust to noise and can capture the temporal and spatial distributions of input time-series signals are prerequisites for accurate forecasting. Motivated by recent deep learning studies in smart manufacturing, in this article, we propose an end-to-end model for multistep machine speed prediction. The model comprises a deep convolutional LSTM encoder–decoder architecture. Extensive empirical analyses using real-world data obtained from a metal packaging plant in the United Kingdom demonstrate the value of the proposed method when compared with the state-of-the-art predictive models.","",""
25,"Y. Qian, T. Tan, Dong Yu","Neural Network Based Multi-Factor Aware Joint Training for Robust Speech Recognition",2016,"","","","",29,"2022-07-13 10:10:34","","10.1109/TASLP.2016.2598308","","",,,,,25,4.17,8,3,6,"Although great progress has been made in automatic speech recognition (ASR), significant performance degradation still exists in noisy environments. In this paper, a novel factor-aware training framework, named neural network-based multifactor aware joint training, is proposed to improve the recognition accuracy for noise robust speech recognition. This approach is a structured model which integrates several different functional modules into one computational deep model. We explore and extract speaker, phone, and environment factor representations using deep neural networks (DNNs), which are integrated into the main ASR DNN to improve classification accuracy. In addition, the hidden activations in the main ASR DNN are used to improve factor extraction, which in turn helps the ASR DNN. All the model parameters, including those in the ASR DNN and factor extraction DNNs, are jointly optimized under the multitask learning framework. Unlike prior traditional techniques for the factor-aware training, our approach requires no explicit separate stages for factor extraction and adaptation. Moreover, the proposed neural network-based multifactor aware joint training can be easily combined with the conventional factor-aware training which uses the explicit factors, such as i-vector, noise energy, and T60 value to obtain additional improvement. The proposed method is evaluated on two main noise robust tasks: the AMI single distant microphone task in which reverberation is the main concern, and the Aurora4 task in which multiple noise types exist. Experiments on both tasks show that the proposed model can significantly reduce word error rate (WER). The best configuration achieved more than 15% relative reduction in WER over the baselines on these two tasks.","",""
41,"S. Sivasankaran, A. Nugraha, E. Vincent, J. A. Morales-Cordovilla, Siddharth Dalmia, I. Illina, A. Liutkus","Robust ASR using neural network based speech enhancement and feature simulation",2015,"","","","",30,"2022-07-13 10:10:34","","10.1109/ASRU.2015.7404834","","",,,,,41,5.86,6,7,7,"We consider the problem of robust automatic speech recognition (ASR) in the context of the CHiME-3 Challenge. The proposed system combines three contributions. First, we propose a deep neural network (DNN) based multichannel speech enhancement technique, where the speech and noise spectra are estimated using a DNN based regressor and the spatial parameters are derived in an expectation-maximization (EM) like fashion. Second, a conditional restricted Boltzmann machine (CRBM) model is trained using the obtained enhanced speech and used to generate simulated training and development datasets. The goal is to increase the similarity between simulated and real data, so as to increase the benefit of multicondition training. Finally, we make some changes to the ASR backend. Our system ranked 4th among 25 entries.","",""
11,"Wenzhe Guo, M. Fouda, A. Eltawil, K. Salama","Neural Coding in Spiking Neural Networks: A Comparative Study for Robust Neuromorphic Systems",2021,"","","","",31,"2022-07-13 10:10:34","","10.3389/fnins.2021.638474","","",,,,,11,11.00,3,4,1,"Various hypotheses of information representation in brain, referred to as neural codes, have been proposed to explain the information transmission between neurons. Neural coding plays an essential role in enabling the brain-inspired spiking neural networks (SNNs) to perform different tasks. To search for the best coding scheme, we performed an extensive comparative study on the impact and performance of four important neural coding schemes, namely, rate coding, time-to-first spike (TTFS) coding, phase coding, and burst coding. The comparative study was carried out using a biological 2-layer SNN trained with an unsupervised spike-timing-dependent plasticity (STDP) algorithm. Various aspects of network performance were considered, including classification accuracy, processing latency, synaptic operations (SOPs), hardware implementation, network compression efficacy, input and synaptic noise resilience, and synaptic fault tolerance. The classification tasks on Modified National Institute of Standards and Technology (MNIST) and Fashion-MNIST datasets were applied in our study. For hardware implementation, area and power consumption were estimated for these coding schemes, and the network compression efficacy was analyzed using pruning and quantization techniques. Different types of input noise and noise variations in the datasets were considered and applied. Furthermore, the robustness of each coding scheme to the non-ideality-induced synaptic noise and fault in analog neuromorphic systems was studied and compared. Our results show that TTFS coding is the best choice in achieving the highest computational performance with very low hardware implementation overhead. TTFS coding requires 4x/7.5x lower processing latency and 3.5x/6.5x fewer SOPs than rate coding during the training/inference process. Phase coding is the most resilient scheme to input noise. Burst coding offers the highest network compression efficacy and the best overall robustness to hardware non-idealities for both training and inference processes. The study presented in this paper reveals the design space created by the choice of each coding scheme, allowing designers to frame each scheme in terms of its strength and weakness given a designs’ constraints and considerations in neuromorphic systems.","",""
472,"F. Weninger, Hakan Erdogan, Shinji Watanabe, E. Vincent, Jonathan Le Roux, J. Hershey, Björn Schuller","Speech Enhancement with LSTM Recurrent Neural Networks and its Application to Noise-Robust ASR",2015,"","","","",32,"2022-07-13 10:10:34","","10.1007/978-3-319-22482-4_11","","",,,,,472,67.43,67,7,7,"","",""
18,"Llewyn Salt, David Howard, G. Indiveri, Yulia Sandamirskaya","Parameter Optimization and Learning in a Spiking Neural Network for UAV Obstacle Avoidance Targeting Neuromorphic Processors",2019,"","","","",33,"2022-07-13 10:10:34","","10.1109/TNNLS.2019.2941506","","",,,,,18,6.00,5,4,3,"The Lobula giant movement detector (LGMD) is an identified neuron of the locust that detects looming objects and triggers the insect’s escape responses. Understanding the neural principles and network structure that leads to these fast and robust responses can facilitate the design of efficient obstacle avoidance strategies for robotic applications. Here, we present a neuromorphic spiking neural network model of the LGMD driven by the output of a neuromorphic dynamic vision sensor (DVS), which incorporates spiking frequency adaptation and synaptic plasticity mechanisms, and which can be mapped onto existing neuromorphic processor chips. However, as the model has a wide range of parameters and the mixed-signal analog-digital circuits used to implement the model are affected by variability and noise, it is necessary to optimize the parameters to produce robust and reliable responses. Here, we propose to use differential evolution (DE) and Bayesian optimization (BO) techniques to optimize the parameter space and investigate the use of self-adaptive DE (SADE) to ameliorate the difficulties of finding appropriate input parameters for the DE technique. We quantify the performance of the methods proposed with a comprehensive comparison of different optimizers applied to the model and demonstrate the validity of the approach proposed using recordings made from a DVS sensor mounted on an unmanned aerial vehicle (UAV).","",""
15,"M. Gogate, K. Dashtipour, P. Bell, A. Hussain","Deep Neural Network Driven Binaural Audio Visual Speech Separation",2020,"","","","",34,"2022-07-13 10:10:34","","10.1109/IJCNN48605.2020.9207517","","",,,,,15,7.50,4,4,2,"The central auditory pathway exploits the auditory signals and visual information sent by both ears and eyes to segregate speech from multiple competing noise sources and help disambiguate phonological ambiguity. In this study, inspired from this unique human ability, we present a deep neural network (DNN) that ingest the binaural sounds received at the two ears as well as the visual frames to selectively suppress the competing noise sources individually at both ears. The model exploits the noisy binaural cues and noise robust visual cues to improve speech intelligibility. The comparative simulation results in terms of objective metrics such as PESQ, STOI, SI-SDR and DBSTOI demonstrate significant performance improvement of the proposed audio-visual (AV) DNN as compared to the audio-only (A-only) variant of the proposed model. Finally, subjective listening tests with the real noisy AV ASPIRE corpus shows the superiority of the proposed AV DNN as compared to state-of-the-art approaches.","",""
23,"Chengzhu Yu, A. Ogawa, Marc Delcroix, T. Yoshioka, T. Nakatani, J. Hansen","Robust i-vector extraction for neural network adaptation in noisy environment",2015,"","","","",35,"2022-07-13 10:10:34","","","","",,,,,23,3.29,4,6,7,"In this study, we explore an i-vector based adaptation of deep neural network (DNN) in noisy environment. We first demonstrate the importance of encapsulating environment and channel variability into i-vectors for DNN adaptation in noisy conditions. To be able to obtain robust i-vector without losing noise and channel variability information, we investigate the use of parallel feature based i-vector extraction for DNN adaptation. Specifically, different types of features are used separately during two different stages of i-vector extraction namely universal background model (UBM) state alignment and i-vector computation. To capture noise and channel-specific feature variation, the conventional MFCC features are still used for i-vector computation. However, much more robust features such as Vector Taylor Series (VTS) enhanced as well as bottleneck features are exploited for UBM state alignment. Experimental results on Aurora-4 show that the parallel feature-based i-vectors yield performance gains of up to 9.2% relative compared to a baseline DNN-HMM system and 3.3% compared to a system using conventional MFCC-based i-vectors.","",""
8,"S. Pontes-Filho, M. Liwicki","Bidirectional Learning for Robust Neural Networks",2018,"","","","",36,"2022-07-13 10:10:34","","10.1109/IJCNN.2019.8852120","","",,,,,8,2.00,4,2,4,"A multilayer perceptron can behave as a generative classifier by applying bidirectional learning (BL). It consists of training an undirected neural network to map input to output and vice-versa; therefore it can produce a classifier in one direction, and a generator in the opposite direction for the same data. The learning process of BL tries to reproduce the neuroplasticity stated in Hebbian theory using only backward propagation of errors. In this paper, two learning techniques are independently introduced which use BL for improving robustness to white noise static and adversarial examples. The first method is bidirectional propagation of errors, which the error propagation occurs in backward and forward directions. Motivated by the fact that its generative model receives as input a constant vector per class, we introduce as a second method the novel hybrid adversarial networks (HAN). Its generative model receives a random vector as input and its training is based on generative adversarial networks (GAN). To assess the performance of BL, we perform experiments using several architectures with fully and convolutional layers, with and without bias. Experimental results show that both methods improve robustness to white noise static and adversarial examples, and even increase accuracy, but have different behavior depending on the architecture and task, being more beneficial to use the one or the other. Nevertheless, HAN using a convolutional architecture with batch normalization presents outstanding robustness, reaching state-of-the-art accuracy on adversarial examples of hand-written digits.","",""
28,"Xiang Cheng, Yunzhe Hao, Jiaming Xu, Bo Xu","LISNN: Improving Spiking Neural Networks with Lateral Interactions for Robust Object Recognition",2020,"","","","",37,"2022-07-13 10:10:34","","10.24963/ijcai.2020/211","","",,,,,28,14.00,7,4,2,"Spiking Neural Network (SNN) is considered more biologically plausible and energy-efficient on emerging neuromorphic hardware. Recently backpropagation algorithm has been utilized for training SNN, which allows SNN to go deeper and achieve higher performance. However, most existing SNN models for object recognition are mainly convolutional structures or fully-connected structures, which only have inter-layer connections, but no intra-layer connections. Inspired by Lateral Interactions in neuroscience, we propose a highperformance and noise-robust Spiking Neural Network (dubbed LISNN). Based on the convolutional SNN, we model the lateral interactions between spatially adjacent neurons and integrate it into the spiking neuron membrane potential formula, then build a multi-layer SNN on a popular deep learning framework, i. e., PyTorch. We utilize the pseudo-derivative method to solve the nondifferentiable problem when applying backpropagation to train LISNN and test LISNN on multiple standard datasets. Experimental results demonstrate that the proposed model can achieve competitive or better performance compared to current state-of-the-art spiking neural networks on MNIST, Fashion-MNIST, and N-MNIST datasets. Besides, thanks to lateral interactions, our model processes stronger noise-robustness than other SNN. Our work brings a biologically plausible mechanism into SNN, hoping that it can help us understand the visual information processing in the brain.","",""
23,"Pulak Purkait, Tat-Jun Chin, I. Reid","NeuRoRA: Neural Robust Rotation Averaging",2019,"","","","",38,"2022-07-13 10:10:34","","10.1007/978-3-030-58586-0_9","","",,,,,23,7.67,8,3,3,"","",""
41,"Sreyas Mohan, Zahra Kadkhodaie, Eero P. Simoncelli, C. Fernandez-Granda","Robust and interpretable blind image denoising via bias-free convolutional neural networks",2019,"","","","",39,"2022-07-13 10:10:34","","","","",,,,,41,13.67,10,4,3,"Deep convolutional networks often append additive constant (""bias"") terms to their convolution operations, enabling a richer repertoire of functional mappings. Biases are also used to facilitate training, by subtracting mean response over batches of training images (a component of ""batch normalization""). Recent state-of-the-art blind denoising methods (e.g., DnCNN) seem to require these terms for their success. Here, however, we show that these networks systematically overfit the noise levels for which they are trained: when deployed at noise levels outside the training range, performance degrades dramatically. In contrast, a bias-free architecture -- obtained by removing the constant terms in every layer of the network, including those used for batch normalization-- generalizes robustly across noise levels, while preserving state-of-the-art performance within the training range. Locally, the bias-free network acts linearly on the noisy image, enabling direct analysis of network behavior via standard linear-algebraic tools. These analyses provide interpretations of network functionality in terms of nonlinear adaptive filtering, and projection onto a union of low-dimensional subspaces, connecting the learning-based method to more traditional denoising methodology.","",""
42,"T. Tan, Y. Qian, Hu Hu, Ying Zhou, W. Ding, Kai Yu","Adaptive Very Deep Convolutional Residual Network for Noise Robust Speech Recognition",2018,"","","","",40,"2022-07-13 10:10:34","","10.1109/TASLP.2018.2825432","","",,,,,42,10.50,7,6,4,"Although great progress has been made in automatic speech recognition, significant performance degradation still exists in noisy environments. Our previous work has demonstrated the superior noise robustness of very deep convolutional neural networks (VDCNN). Based on our work on VDCNNs, this paper proposes a more advanced model referred to as the very deep convolutional residual network (VDCRN). This new model incorporates batch normalization and residual learning, showing more robustness than previous VDCNNs.Then, to alleviate the mismatch between the training and testing conditions, model adaptation and adaptive training are developed and compared for the new VDCRN. This paper focuses on factor aware training (FAT) and cluster adaptive training (CAT). For FAT, a unified framework is explored. For CAT, two schemes are first explored to construct the bases in the canonical model; furthermore, a factorized version of CAT is designed to address multiple nonspeech variabilities in one model. Finally, a complete multipass system is proposed to achieve the best system performance in the noisy scenarios. The proposed new approaches are evaluated on three different tasks: Aurora4 (simulated data with additive noise and channel distortion), CHiME4 (both simulated and real data with additive noise and reverberation), and the AMI meeting transcription task (real data with significant reverberation).The evaluation not only includes different noisy conditions, but also covers both simulated and real noisy data. The experiments show that the new VDCRN is more robust, and the adaptation on this model can further significantly reduce the word error rate (WER). The proposed best architecture obtains consistent and very large improvements on all tasks compared to the baseline VDCNN or long short-term memory. Particularly, on Aurora4 a new milestone 5.67% WER is achieved by only improving acoustic modeling.","",""
60,"Cassia Valentini-Botinhao, Xin Wang, Shinji Takaki, J. Yamagishi","Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks",2016,"","","","",41,"2022-07-13 10:10:34","","10.21437/Interspeech.2016-159","","",,,,,60,10.00,15,4,6,"Quality of text-to-speech voices built from noisy recordings is diminished. In order to improve it we propose the use of a recurrent neural network to enhance acoustic parameters prior to training. We trained a deep recurrent neural network using a parallel database of noisy and clean acoustics parameters as input and output of the network. The database consisted of mul-tiple speakers and diverse noise conditions. We investigated using text-derived features as an additional input of the network. We processed a noisy database of two other speakers using this network and used its output to train an HMM acoustic text-to-synthesis model for each voice. Listening experiment results showed that the voice built with enhanced parameters was ranked signiﬁcantly higher than the ones trained with noisy speech and speech that has been enhanced using a conventional enhancement system. The text-derived features improved results only for the female voice, where it was ranked as highly as a voice trained with clean speech.","",""
135,"Dong Xu, Dongbin Zhao, J. Yi, Xiang-min Tan","Trajectory Tracking Control of Omnidirectional Wheeled Mobile Manipulators: Robust Neural Network-Based Sliding Mode Approach",2009,"","","","",42,"2022-07-13 10:10:34","","10.1109/TSMCB.2008.2009464","","",,,,,135,10.38,34,4,13,"This paper addresses the robust trajectory tracking problem for a redundantly actuated omnidirectional mobile manipulator in the presence of uncertainties and disturbances. The development of control algorithms is based on sliding mode control (SMC) technique. First, a dynamic model is derived based on the practical omnidirectional mobile manipulator system. Then, a SMC scheme, based on the fixed large upper boundedness of the system dynamics (FLUBSMC), is designed to ensure trajectory tracking of the closed-loop system. However, the FLUBSMC scheme has inherent deficiency, which needs computing the upper boundedness of the system dynamics, and may cause high noise amplification and high control cost, particularly for the complex dynamics of the omnidirectional mobile manipulator system. Therefore, a robust neural network (NN)-based sliding mode controller (NNSMC), which uses an NN to identify the unstructured system dynamics directly, is further proposed to overcome the disadvantages of FLUBSMC and reduce the online computing burden of conventional NN adaptive controllers. Using learning ability of NN, NNSMC can coordinately control the omnidirectional mobile platform and the mounted manipulator with different dynamics effectively. The stability of the closed-loop system, the convergence of the NN weight-updating process, and the boundedness of the NN weight estimation errors are all strictly guaranteed. Then, in order to accelerate the NN learning efficiency, a partitioned NN structure is applied. Finally, simulation examples are given to demonstrate the proposed NNSMC approach can guarantee the whole system's convergence to the desired manifold with prescribed performance.","",""
47,"Morten Kolbæk, Z. Tan, J. Jensen","Speech enhancement using Long Short-Term Memory based recurrent Neural Networks for noise robust Speaker Verification",2016,"","","","",43,"2022-07-13 10:10:34","","10.1109/SLT.2016.7846281","","",,,,,47,7.83,16,3,6,"In this paper we propose to use a state-of-the-art Deep Recurrent Neural Network (DRNN) based Speech Enhancement (SE) algorithm for noise robust Speaker Verification (SV). Specifically, we study the performance of an i-vector based SV system, when tested in noisy conditions using a DRNN based SE front-end utilizing a Long Short-Term Memory (LSTM) architecture. We make comparisons to systems using a Non-negative Matrix Factorization (NMF) based front-end, and a Short-Time Spectral Amplitude Minimum Mean Square Error (STSA-MMSE) based front-end, respectively. We show in simulation experiments that a male-speaker and text-independent DRNN based SE front-end, without specific a priori knowledge about the noise type outperforms a text, noise type and speaker dependent NMF based front-end as well as a STSA-MMSE based front-end in terms of Equal Error Rates for a large range of noise types and signal to noise ratios on the RSR2015 speech corpus.","",""
25,"Bingrong Xu, Qingshan Liu, Tingwen Huang","A Discrete-Time Projection Neural Network for Sparse Signal Reconstruction With Application to Face Recognition",2019,"","","","",44,"2022-07-13 10:10:34","","10.1109/TNNLS.2018.2836933","","",,,,,25,8.33,8,3,3,"This paper deals with sparse signal reconstruction by designing a discrete-time projection neural network. Sparse signal reconstruction can be converted into an <inline-formula> <tex-math notation=""LaTeX"">$L_{1}$ </tex-math></inline-formula>-minimization problem, which can also be changed into the unconstrained basis pursuit denoising problem. To solve the <inline-formula> <tex-math notation=""LaTeX"">$L_{1}$ </tex-math></inline-formula>-minimization problem, an iterative algorithm is proposed based on the discrete-time projection neural network, and the global convergence of the algorithm is analyzed by using Lyapunov method. Experiments on sparse signal reconstruction and several popular face data sets are organized to illustrate the effectiveness and performance of the proposed algorithm. The experimental results show that the proposed algorithm is not only robust to different levels of sparsity and amplitude of signals and the noise pixels but also insensitive to the diverse values of scalar weight. Moreover, the value of the step size of the proposed algorithm is close to 1/2, thus a fast convergence rate is potentially possible. Furthermore, the proposed algorithm achieves better classification performance compared with some other algorithms for face recognition.","",""
46,"Giorgio Patrini, A. Rozza, A. Menon, R. Nock, Lizhen Qu","Making Neural Networks Robust to Label Noise: a Loss Correction Approach",2016,"","","","",45,"2022-07-13 10:10:34","","","","",,,,,46,7.67,9,5,6,"We present a theoretically grounded approach to train deep neural networks, including recurrent networks, subject to class-dependent label noise. Our method only performs a correction on the loss function, and is agnostic to both the application domain and network architecture. We propose two procedures for loss correction: they simply amount to at most a matrix inversion and multiplication, provided that we know the probability of each class being corrupted into another. We further show how one can estimate these probabilities, adapting a recent technique for noise estimation to the multi-class setting, and thus providing an end-to-end framework. Extensive experiments on MNIST, IMDB, CIFAR-10, CIFAR-100 employing a diversity of architectures — stacking dense, convolutional, pooling, dropout, batch normalization, word embedding, LSTM and residual layers — demonstrate the noise robustness of our proposals. Incidentally, we also prove that, when ReLU is the only non-linearity, the loss curvature is immune to class-dependent label noise.","",""
19,"Z. Long, Tianyi Wang, Chengwu You, Zhengang Yang, Kejia Wang, Jinsong Liu","Terahertz image super-resolution based on a deep convolutional neural network.",2019,"","","","",46,"2022-07-13 10:10:34","","10.1364/AO.58.002731","","",,,,,19,6.33,3,6,3,"We propose an effective and robust method for terahertz (THz) image super-resolution based on a deep convolutional neural network (CNN). A deep CNN model is designed. It learns an end-to-end mapping between the low- and high-resolution images. Blur kernels with multiple width and noise with multiple levels are taken into the training set so that the network can handle THz images very well. Quantitative comparison of the proposed method and other super-resolution methods on the synthetic THz images indicates that the proposed method performs better than other methods in accuracy and visual improvements. Experimental results on real THz images show that the proposed method significantly improves the quality of THz images with increased resolution and decreased noise, which proves the practicability and exactitude of the proposed method.","",""
472,"Yonatan Belinkov, Yonatan Bisk","Synthetic and Natural Noise Both Break Neural Machine Translation",2017,"","","","",47,"2022-07-13 10:10:34","","","","",,,,,472,94.40,236,2,5,"Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems. Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.","",""
27,"Hong Yu, Z. Tan, Zhanyu Ma, Jun Guo","Adversarial Network Bottleneck Features for Noise Robust Speaker Verification",2017,"","","","",48,"2022-07-13 10:10:34","","10.1109/ICNIDC.2018.8525526","","",,,,,27,5.40,7,4,5,"In this paper, we propose a noise robust bottleneck feature representation which is generated by an adversarial network (AN). The AN includes two cascade connected networks, an encoding network (EN) and a discriminative network (DN). Mel-frequency cepstral coefficients (MFCCs) of clean and noisy speech are used as input to the EN and the output of the EN is used as the noise robust feature. The EN and DN are trained in turn, namely, when training the DN, noise types are selected as the training labels and when training the EN, all labels are set as the same, i.e., the clean speech label, which aims to make the AN features invariant to noise and thus achieve noise robustness. We evaluate the performance of the proposed feature on a Gaussian Mixture Model-Universal Background Model based speaker verification system, and make comparison to MFCC features of speech enhanced by short-time spectral amplitude minimum mean square error (STSA-MMSE) and deep neural network-based speech enhancement (DNN-SE) methods. Experimental results on the RSR2015 database show that the proposed AN bottleneck feature (AN-BN) dramatically outperforms the STSA-MMSE and DNN-SE based MFCCs for different noise types and signal-to-noise ratios. Furthermore, the AN-BN feature is able to improve the speaker verification performance under the clean condition.","",""
29,"Yao Ding, Xiaofeng Zhao, Zhili Zhang, Wei Cai, Nengjun Yang, Y. Zhan","Semi-Supervised Locality Preserving Dense Graph Neural Network With ARMA Filters and Context-Aware Learning for Hyperspectral Image Classification",2021,"","","","",49,"2022-07-13 10:10:34","","10.1109/tgrs.2021.3100578","","",,,,,29,29.00,5,6,1,"The application of graph convolutional networks (GCNs) to hyperspectral image (HSI) classification is a heavily researched topic. However, GCNs are based on spectral filters, which are computationally costly and fail to suppress noise effectively. In addition, the current GCN-based methods are prone to oversmoothing (the representation of each node tends to be congruent) problems. To circumvent these problems, a novel semi-supervised locality-preserving dense graph neural network (GNN) with autoregressive moving average (ARMA) filters and context-aware learning (DARMA-CAL) is proposed for HSI classification. In this work, we introduce the ARMA filter instead of a spectral filter to apply to GNNs. The ARMA filter can better capture the global graph structure and is more robust to noise. More importantly, the ARMA filter can simplify calculations compared with the spectral filter. In addition, we show that the ARMA filter can be approximated by a recursive method. Furthermore, we propose a dense structure, which not only implements the ARMA filter in the structure, but is also locality-preserving. Finally, we design a layerwise context-aware learning mechanism to extract the useful local information generated by each layer of the dense ARMA network. The experimental results on three real HSI datasets show that DARMA-CAL outperforms the compared state-of-the-art methods.","",""
112,"Dongsheng Jiang, W. Dou, L. Vosters, Xiayu Xu, Yue Sun, T. Tan","Denoising of 3D magnetic resonance images with multi-channel residual learning of convolutional neural network",2017,"","","","",50,"2022-07-13 10:10:34","","10.1007/s11604-018-0758-8","","",,,,,112,22.40,19,6,5,"","",""
23,"Kazuki Shimada, Yoshiaki Bando, M. Mimura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara","Unsupervised Speech Enhancement Based on Multichannel NMF-Informed Beamforming for Noise-Robust Automatic Speech Recognition",2019,"","","","",51,"2022-07-13 10:10:34","","10.1109/TASLP.2019.2907015","","",,,,,23,7.67,4,6,3,"This paper describes multichannel speech enhancement for improving automatic speech recognition (ASR) in noisy environments. Recently, the minimum variance distortionless response (MVDR) beamforming has widely been used because it works well if the steering vector of speech and the spatial covariance matrix (SCM) of noise are given. To estimating such spatial information, conventional studies take a supervised approach that classifies each time-frequency (TF) bin into noise or speech by training a deep neural network (DNN). The performance of ASR, however, is degraded in an unknown noisy environment. To solve this problem, we take an unsupervised approach that decomposes each TF bin into the sum of speech and noise by using multichannel nonnegative matrix factorization (MNMF). This enables us to accurately estimate the SCMs of speech and noise not from observed noisy mixtures but from separated speech and noise components. In this paper, we propose online MVDR beamforming by effectively initializing and incrementally updating the parameters of MNMF. Another main contribution is to comprehensively investigate the performances of ASR obtained by various types of spatial filters, i.e., time-invariant and variant versions of MVDR beamformers and those of rank-1 and full-rank multichannel Wiener filters, in combination with MNMF. The experimental results showed that the proposed method outperformed the state-of-the-art DNN-based beamforming method in unknown environments that did not match training data.","",""
49,"Shiba Kuanar, V. Athitsos, N. Pradhan, A. Mishra, K. Rao","Cognitive Analysis of Working Memory Load from Eeg, by a Deep Recurrent Neural Network",2018,"","","","",52,"2022-07-13 10:10:34","","10.1109/ICASSP.2018.8462243","","",,,,,49,12.25,10,5,4,"One of the common modalities for observing mental activity is electroencephalogram (EEG) signals. However, EEG recording is highly susceptible to various sources of noise and to inter subject differences. In order to solve these problems we present a deep recurrent neural network (RNN) architecture to learn robust features and predict the levels of cognitive load from EEG recordings. Using a deep learning approach, we first transform the EEG time series into a sequence of multispectral images which carries spatial information. Next, we train our recurrent hybrid network to learn robust representations from the sequence of frames. The proposed approach preserves spectral, spatial and temporal structures and extracts features which are less sensitive to variations along each dimension. Our results demonstrate cognitive memory load prediction across four different levels with an overall accuracy of 92.5% during the memory task execution and reduce classification error to 7.61% in comparison to other state-of-art techniques.","",""
43,"Yair Dgani, H. Greenspan, J. Goldberger","Training a neural network based on unreliable human annotation of medical images",2018,"","","","",53,"2022-07-13 10:10:34","","10.1109/ISBI.2018.8363518","","",,,,,43,10.75,14,3,4,"Building classification models from clinical data often requires human experts for example labeling. However, it is difficult to obtain a perfect set of labels due to the complexity of the medical data and the large variability between experts. In this study we present a neural-network training strategy that is more robust to unreliable labeling by explicitly modeling the label noise as part of the network architecture. Our method is demonstrated on breast microcalcifications classification into benign and malignant categories, given multi-view mammograms. We show that the proposed training procedure outperforms standard training methods that ignore the existence of label noise.","",""
42,"Bo Li, K. Sim","A Spectral Masking Approach to Noise-Robust Speech Recognition Using Deep Neural Networks",2014,"","","","",54,"2022-07-13 10:10:34","","10.1109/TASLP.2014.2329237","","",,,,,42,5.25,21,2,8,"Improving the noise robustness of automatic speech recognition systems has been a challenging task for many years. Recently, it was found that Deep Neural Networks (DNNs) yield large performance gains over conventional GMM-HMM systems, when used in both hybrid and tandem systems. However, they are still far from the level of human expectations especially under adverse environments. Motivated by the separation-prior-to-recognition process of the human auditory system, we propose a robust spectral masking system where power spectral domain masks are predicted using a DNN trained on the same filter-bank features used for acoustic modeling. To further improve performance, Linear Input Network (LIN) adaptation is applied to both the mask estimator and the acoustic model DNNs. Since the estimation of LINs for the mask estimator requires stereo data, which is not available during testing, we proposed using the LINs estimated for the acoustic model DNNs to adapt the mask estimators. Furthermore, we used the same set of weights obtained from pre-training for the input layers of both the mask estimator and the acoustic model DNNs to ensure a better consistency for sharing LINs. Experimental results on benchmark Aurora2 and Aurora4 tasks demonstrated the effectiveness of our system, which yielded Word Error Rates (WERs) of 4.6% and 11.8% respectively. Furthermore, the simple averaging of posteriors from systems with and without spectral masking can further reduce the WERs to 4.3% on Aurora2 and 11.4% on Aurora4.","",""
54,"Z. Eaton-Rosen, Felix J. S. Bragman, S. Bisdas, S. Ourselin, M. Jorge Cardoso","Towards safe deep learning: accurately quantifying biomarker uncertainty in neural network predictions",2018,"","","","",55,"2022-07-13 10:10:34","","10.1007/978-3-030-00928-1_78","","",,,,,54,13.50,11,5,4,"","",""
140,"F. Palsson, J. Sveinsson, M. Ulfarsson","Multispectral and Hyperspectral Image Fusion Using a 3-D-Convolutional Neural Network",2017,"","","","",56,"2022-07-13 10:10:34","","10.1109/LGRS.2017.2668299","","",,,,,140,28.00,47,3,5,"In this letter, we propose a method using a 3-D convolutional neural network to fuse together multispectral and hyperspectral (HS) images to obtain a high resolution HS image. Dimensionality reduction of the HS image is performed prior to fusion in order to significantly reduce the computational time and make the method more robust to noise. Experiments are performed on a data set simulated using a real HS image. The results obtained show that the proposed approach is very promising when compared with conventional methods. This is especially true when the HS image is corrupted by additive noise.","",""
15,"F. Ham, Sungjin Park","A robust neural network classifier for infrasound events using multiple array data",2002,"","","","",57,"2022-07-13 10:10:34","","10.1109/IJCNN.2002.1007556","","",,,,,15,0.75,8,2,20,"An integral part of the Comprehensive Nuclear-Test-Ban Treaty International Monitoring System is an infrasound monitoring network. This network has the capability to detect and verify infrasonic signals-of-interest, e.g., nuclear explosions, from other unwanted infrasound noise sources. The paper presents classification results of infrasonic events using a robust neural network.","",""
31,"M. Hon, D. Stello, Jie Yu","Deep learning classification in asteroseismology using an improved neural network: results on 15 000 Kepler red giants and applications to K2 and TESS data",2018,"","","","",58,"2022-07-13 10:10:34","","10.1093/mnras/sty483","","",,,,,31,7.75,10,3,4,"Deep learning in the form of 1D convolutional neural networks have previously been shown to be capable of efficiently classifying the evolutionary state of oscillating red giants into red giant branch stars and helium-core burning stars by recognizing visual features in their asteroseismic frequency spectra. We elaborate further on the deep learning method by developing an improved convolutional neural network classifier. To make our method useful for current and future space missions such as K2, TESS and PLATO, we train classifiers that are able to classify the evolutionary states of lower frequency resolution spectra expected from these missions. Additionally, we provide new classifications for 8633 Kepler red giants, out of which 426 have previously not been classified using asteroseismology. This brings the total to 14983 Kepler red giants classified with our new neural network. We also verify that our classifiers are remarkably robust to suboptimal data, including low signal-to-noise and incorrect training truth labels.","",""
315,"Andrew L. Maas, Quoc V. Le, Tyler M. O'Neil, Oriol Vinyals, P. Nguyen, A. Ng","Recurrent Neural Networks for Noise Reduction in Robust ASR",2012,"","","","",59,"2022-07-13 10:10:34","","","","",,,,,315,31.50,53,6,10,"Recent work on deep neural networks as acoustic models for automatic speech recognition (ASR) have demonstrated substantial performance improvements. We introduce a model which uses a deep recurrent auto encoder neural network to denoise input features for robust ASR. The model is trained on stereo (noisy and clean) audio features to predict clean features given noisy input. The model makes no assumptions about how noise affects the signal, nor the existence of distinct noise environments. Instead, the model can learn to model any type of distortion or additive noise given sufficient training data. We demonstrate the model is competitive with existing feature denoising approaches on the Aurora2 task, and outperforms a tandem approach where deep networks are used to predict phoneme posteriors directly.","",""
73,"C. Darken, M. Donahue, L. Gurvits, Eduardo Sontag","Rate of approximation results motivated by robust neural network learning",1993,"","","","",60,"2022-07-13 10:10:34","","10.1145/168304.168357","","",,,,,73,2.52,18,4,29,"The set of functions which a single hidden layer neural network can approximate is increasingly well understood, yet our knowledge of how the approximation error depends upon the number of hidden units, i.e. the rate of approximation, remains relatively primitive. Barron [1991] and Jones [1992] give bounds on the rate of approximation valid for Hilbert spaces. We derive bounds for L spaces, 1 < p < m, recovering the 0(1 /&) bounds of Barron and Jones for the case p = 2. The results were motivated in part by the desire to understand approximation in the more “robust” (resistant to exemplar noise) LP, 1 ~ p <2 norms. Consider the task of approximating a given target function f by a linear combination of n functions from a set S. For example, S may be the set of possible sigmoidal activation functions, {g : ~d ~[% 6 ~d, b E ~, s.t. g(z) = a(a . z + b)}, in which case the approximants are single hidden layer neural networks with a linear output layer. It is known that under very weak conditions on IS (it must be Riemann integrable and nonpolynomial), the linear span of S is dense in the set of continuous functions on compact subsets of ~d (i.e. for all positive c there is a linear combination of functions in S which can approximate any continuous function to within c everywhere on a compact domain) [Leshno et al. 1992]. Consider the important rate of approximation issue, i.e. the rate at which the achievable error reduces as we allow larger subsets of S to be used in const rutting the approximant. In the context of neural networks, this is the question of how the approximation error scales with the number of hidden units in the network. Unfortunately, approximation bounds for target functions ~ arbitrarily located in the linear closure (i.e. the closure of the span) of S are unknown. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ACM COLT ’93 17/931CA, USA @ 1993 ACM 0-89791-61 1-5193 /000710303 . ..$1 .50 Leonid Gurvits Eduardo Sontag Learning Systems Dept. Dept. of Mathematics Siemens Corp. Research Rutgers University 755 College Road East New Brunswick, NJ 08903 Princeton, NJ 08540 sontag@control. rutgers. edu gurvitsrlscr. aiemena. com However, progress haa been made recently by introducing the assumptions that f is in the convex closure of S, and that S is bounded in the relevant norm. This theory depends neither on the continuity of f nor on the form of the functions in S (i.e. the functions in S do not need to be sigmoidal or obey the constraints on ~ listed above), but only on the properties of the function space and some generic properties of S. Definition 1 Let X be a Banach space v.rith norm II ! II. Let S ~ X and f E X. Dejine lllinnS fl[ := inf ‘&W, – f , (1) i=l where the injimum is over all gl, . . . . gn c S and al, ..., an E ~. Also define llconS – fll := inf ~ a~ga f , (2) %=1 where the infimum is over all gl, . . . . g~ E S and al, ..., crn G ~+ U {O} such that ~ ai = 1. That is, lllinnS – fll is the distance of f from the closest span of n functions from S (linear approximation bound), and llconS – fll is the distance off from the closest convex hull of n functions from S (convex approximation bound). Note that [1Iinn S – f II ~ IIco.S f Il. These bounds converge to zero as n ~ co for approximable f and thus represent the convergence rates of the best approximants to the target function. The study of such rates is standard in approximation theory (e.g. [Powell 1981] ), but the cases of interest for neural networks are not among those classically considered. For spaces of square-integrable functions (or more general Hilbert spaces) and bounded sets S, Barron [1991] presented results at this conference to the effect that llco~S – fllz = 0(1/@). Subsequently, under additional conditions on S, he has shown that the same rate obtains for the uniform norm [Barren 1992]. If we consider the procedure of constructing approximants to f incrementally, bv formimz a convex combination of the last approxirna~t with a-single new element convergence rate in Lz is interestingly again 303 of S, the o(l/fi)","",""
28,"M. G. Kibria, H. Rivaz","GLUENet: Ultrasound Elastography Using Convolutional Neural Network",2018,"","","","",61,"2022-07-13 10:10:34","","10.1007/978-3-030-01045-4_3","","",,,,,28,7.00,14,2,4,"","",""
67,"Keisuke Sakaguchi, Kevin Duh, Matt Post, Benjamin Van Durme","Robsut Wrod Reocginiton via Semi-Character Recurrent Neural Network",2016,"","","","",62,"2022-07-13 10:10:34","","10.1609/aaai.v31i1.10970","","",,,,,67,11.17,17,4,6,"    Language processing mechanism by humans is generally more robust than computers. The Cmabrigde Uinervtisy (Cambridge University) effect from the psycholinguistics literature has demonstrated such a robust word processing mechanism, where jumbled words (e.g. Cmabrigde / Cambridge) are recognized with little cost. On the other hand, computational models for word recognition (e.g. spelling checkers) perform poorly on data with such noise. Inspired by the findings from the Cmabrigde Uinervtisy effect, we propose a word recognition model based on a semi-character level recurrent neural network (scRNN). In our experiments, we demonstrate that scRNN has significantly more robust performance in word spelling correction (i.e. word recognition) compared to existing spelling checkers and character-based convolutional neural network. Furthermore, we demonstrate that the model is cognitively plausible by replicating a psycholinguistics experiment about human reading difficulty using our model.   ","",""
19,"Yuzhou Liu, Anshuman Ganguly, K. Kamath, T. Kristjansson","Neural Network Based Time-Frequency Masking and Steering Vector Estimation for Two-Channel Mvdr Beamforming",2018,"","","","",63,"2022-07-13 10:10:34","","10.1109/ICASSP.2018.8462069","","",,,,,19,4.75,5,4,4,"We present a neural network based approach to two-channel beamforming. First, single- and cross-channel spectral features are extracted to form a feature map for each utterance. A large neural network that is the concatenation of a convolution neural network (CNN), long short-term memory recurrent neural network (LSTM-RNN) and deep neural network (DNN) is then employed to estimate frame-level speech and noise masks. Later, these predicted masks are used to compute cross-power spectral density (CPSD) matrices which are used to estimate the minimum variance distortion-less response (MVDR) beamformer coefficients. In the end, a DNN is trained to optimize the phase in the estimated steering vectors to make it robust for reverberant conditions. We compare our methods with two state-of-the-art two-channel speech enhancement systems, i.e., time-frequency masking and masking-based beamforming. Results show the proposed method leads to 21 % relative improvement in word error rate (WER) over other systems.","",""
69,"Sarfaraz Hussein, R. Gillies, K. Cao, Q. Song, U. Bagci","TumorNet: Lung nodule characterization using multi-view Convolutional Neural Network with Gaussian Process",2017,"","","","",64,"2022-07-13 10:10:34","","10.1109/ISBI.2017.7950686","","",,,,,69,13.80,14,5,5,"Characterization of lung nodules as benign or malignant is one of the most important tasks in lung cancer diagnosis, staging and treatment planning. While the variation in the appearance of the nodules remains large, there is a need for a fast and robust computer aided system. In this work, we propose an end-to-end trainable multi-view deep Convolutional Neural Network (CNN) for nodule characterization. First, we use median intensity projection to obtain a 2D patch corresponding to each dimension. The three images are then concatenated to form a tensor, where the images serve as different channels of the input image. In order to increase the number of training samples, we perform data augmentation by scaling, rotating and adding noise to the input image. The trained network is used to extract features from the input image followed by a Gaussian Process (GP) regression to obtain the malignancy score. We also empirically establish the significance of different high level nodule attributes such as calcification, sphericity and others for malignancy determination. These attributes are found to be complementary to the deep multi-view CNN features and a significant improvement over other methods is obtained.","",""
10,"Xiaotong Wang, Chih-Chen Chang, Fang Du","Achieving a More Robust Neural Network Model for Control of a MR Damper by Signal Sensitivity Analysis",2002,"","","","",65,"2022-07-13 10:10:34","","10.1007/s005210200005","","",,,,,10,0.50,3,3,20,"","",""
14,"T. Briegel, Volker Tresp","Robust Neural Network Regression for Offline and Online Learning",1999,"","","","",66,"2022-07-13 10:10:34","","","","",,,,,14,0.61,7,2,23,"We replace the commonly used Gaussian noise model in nonlinear regression by a more flexible noise model based on the Student-t- distribution. The degrees of freedom of the t-distribution can be chosen such that as special cases either the Gaussian distribution or the Cauchy distribution are realized. The latter is commonly used in robust regression. Since the t-distribution can be interpreted as being an infinite mixture of Gaussians, parameters and hyperparameters such as the degrees of freedom of the t-distribution can be learned from the data based on an EM-learning algorithm. We show that modeling using the t-distribution leads to improved predictors on real world data sets. In particular, if outliers are present, the t-distribution is superior to the Gaussian noise model. In effect, by adapting the degrees of freedom, the system can ""learn"" to distinguish between outliers and non-outliers. Especially for online learning tasks, one is interested in avoiding inappropriate weight changes due to measurement outliers to maintain stable online learning capability. We show experimentally that using the t-distribution as a noise model leads to stable online learning algorithms and outperforms state-of-the art online learning methods like the extended Kalman filter algorithm.","",""
22,"M. Klachko, M. Mahmoodi, D. Strukov","Improving Noise Tolerance of Mixed-Signal Neural Networks",2019,"","","","",67,"2022-07-13 10:10:34","","10.1109/IJCNN.2019.8851966","","",,,,,22,7.33,7,3,3,"Mixed-signal hardware accelerators for deep learning achieve orders of magnitude better power efficiency than their digital counterparts. In the ultra-low power consumption regime, limited signal precision inherent to analog computation becomes a challenge. We perform a case study of a 6-layer convolutional neural network running on a mixed-signal accelerator and evaluate its sensitivity to hardware specific noise. We apply various methods to improve noise robustness of the network and demonstrate an effective way to optimize useful signal ranges through adaptive signal clipping. The resulting model is robust enough to achieve 80.2% classification accuracy on CIFAR-10 dataset with just 1.4 mW power budget, while 6 mW budget allows us to achieve 87.1% accuracy, which is within 1% of the software baseline. For comparison, the unoptimized version of the same model achieves only 67.7% accuracy at 1.4 mW and 78.6% at 6 mW.","",""
31,"Kateřina Žmolíková, Marc Delcroix, K. Kinoshita, T. Higuchi, A. Ogawa, T. Nakatani","Learning speaker representation for neural network based multichannel speaker extraction",2017,"","","","",68,"2022-07-13 10:10:34","","10.1109/ASRU.2017.8268910","","",,,,,31,6.20,5,6,5,"Recently, schemes employing deep neural networks (DNNs) for extracting speech from noisy observation have demonstrated great potential for noise robust automatic speech recognition. However, these schemes are not well suited when the interfering noise is another speaker. To enable extracting a target speaker from a mixture of speakers, we have recently proposed to inform the neural network using speaker information extracted from an adaptation utterance from the same speaker. In our previous work, we explored ways how to inform the network about the speaker and found a speaker adaptive layer approach to be suitable for this task. In our experiments, we used speaker features designed for speaker recognition tasks as the additional speaker information, which may not be optimal for the speaker extraction task. In this paper, we propose a usage of a sequence summarizing scheme enabling to learn the speaker representation jointly with the network. Furthermore, we extend the previous experiments to demonstrate the potential of our proposed method as a front-end for speech recognition and explore the effect of additional noise on the performance of the method.","",""
271,"M. Ahmadlou, H. Adeli","Enhanced probabilistic neural network with local decision circles: A robust classifier",2010,"","","","",69,"2022-07-13 10:10:34","","10.3233/ICA-2010-0345","","",,,,,271,22.58,136,2,12,"In recent years the Probabilistic Neural Network (PPN) has been used in a large number of applications due to its simplicity and efficiency. PNN assigns the test data to the class with maximum likelihood compared with other classes. Likelihood of the test data to each training data is computed in the pattern layer through a kernel density estimation using a simple Bayesian rule. The kernel is usually a standard probability distribution function such as a Gaussian function. A spread parameter is used as a global parameter which determines the width of the kernel. The Bayesian rule in the pattern layer estimates the conditional probability of each class given an input vector without considering any probable local densities or heterogeneity in the training data. In this paper, an enhanced and generalized PNN (EPNN) is presented using local decision circles (LDCs) to overcome the aforementioned shortcoming and improve its robustness to noise in the data. Local decision circles enable EPNN to incorporate local information and non-homogeneity existing in the training population. The circle has a radius which limits the contribution of the local decision. In the conventional PNN the spread parameter can be optimized for maximum classification accuracy. In the proposed EPNN two parameters, the spread parameter and the radius of local decision circles, are optimized to maximize the performance of the model. Accuracy and robustness of EPNN are compared with PNN using three different benchmark classification problems, iris data, diabetic data, and breast cancer data, and five different ratios of training data to testing data: 90:10, 80:20, 70:30, 60:40, and 50:50. EPNN provided the most accurate results consistently for all ratios. Robustness of PNN and EPNN is investigated using different values of signal to noise ratio (SNR). Accuracy of EPNN is consistently higher than accuracy of PNN at different levels of SNR and for all ratios of training data to testing data.","",""
710,"Li Xu, Jimmy S. J. Ren, Ce Liu, Jiaya Jia","Deep Convolutional Neural Network for Image Deconvolution",2014,"","","","",70,"2022-07-13 10:10:34","","","","",,,,,710,88.75,178,4,8,"Many fundamental image-related problems involve deconvolution operators. Real blur degradation seldom complies with an ideal linear convolution model due to camera noise, saturation, image compression, to name a few. Instead of perfectly modeling outliers, which is rather challenging from a generative model perspective, we develop a deep convolutional neural network to capture the characteristics of degradation. We note directly applying existing deep neural networks does not produce reasonable results. Our solution is to establish the connection between traditional optimization-based schemes and a neural network architecture where a novel, separable structure is introduced as a reliable support for robust deconvolution against artifacts. Our network contains two submodules, both trained in a supervised manner with proper initialization. They yield decent performance on non-blind image deconvolution compared to previous generative-model based methods.","",""
88,"M. Alsmadi, K. Omar, S. Noah, Ibrahim Almarashdeh","Fish Recognition Based on Robust Features Extraction from Size and Shape Measurements Using Neural Network",2010,"","","","",71,"2022-07-13 10:10:34","","10.3844/JCSSP.2010.1088.1094","","",,,,,88,7.33,22,4,12,"Problem statement: Image recognition is a challenging problem researchers had been research into this area for so long especially in the recent years, due to distortion, noise, segmentation errors, overlap and occlusion of objects in digital images. In our study, there are many fields concern with pattern recognition, for example, fingerprint verification, face recognition, iris discrimination, chromosome shape discrimination, optical character recognition, texture discrimination and speech recognition, the subject of pattern recognition appears. A system for recognizing isolated pattern of interest may be as an approach for dealing with such application. Scientists and engineers with interests in image processing and pattern recognition have developed various approaches to deal with digital image recognition problems such as, neural network, contour matching and statistics. Approach: In this study, our aim was to recognize an isolated pattern of interest in the image based on the combination between robust features extraction. Where depend on size and shape measurements, that were extracted by measuring the distance and geometrical measurements. Results: We presented a system prototype for dealing with such problem. The system started by acquiring an image containing pattern of fish, then the image features extraction is performed relying on size and shape measurements. Our system has been applied on 20 different fish families, each family has a different number of fish types and our sample consists of distinct 350 of fish images. These images were divided into two datasets: 257 training images and 93 testing images. An overall accuracy was obtained using the neural network associated with the back-propagation algorithm was 86% on the test dataset used. Conclusion: We developed a classifier for fish images recognition. We efficiently have chosen a features extraction method to fit our demands. Our classifier successfully design and implement a decision which performed efficiently without any problems. Eventually, the classifier is able to categorize the given fish into its cluster and categorize the clustered fish into its poison or non-poison fish and categorizes the poison and non-poison fish into its family.","",""
84,"S. Radzi, M. Khalil-Hani, R. Bakhteri","Finger-vein biometric identification using convolutional neural network",2016,"","","","",72,"2022-07-13 10:10:34","","10.3906/ELK-1311-43","","",,,,,84,14.00,28,3,6,"A novel approach using a convolutional neural network (CNN) for finger-vein biometric identification is presented in this paper. Unlike existing biometric techniques such as fingerprint and face, vein patterns are inside the body, making them virtually impossible to replicate. This also makes finger-vein biometrics a more secure alternative without being susceptible to forgery, damage, or change with time. In conventional finger-vein recognition methods, complex image processing is required to remove noise and extract and enhance the features before the image classification can be performed in order to achieve high performance accuracy. In this regard, a significant advantage of the CNN over conventional approaches is its ability to simultaneously extract features, reduce data dimensionality, and classify in one network structure. In addition, the method requires only minimal image preprocessing since the CNN is robust to noise and small misalignments of the acquired images. In this paper, a reduced-complexity four-layer CNN with fused convolutional-subsampling architecture is proposed for finger-vein recognition. For network training, we have modified and applied the stochastic diagonal Levenberg{Marquardt algorithm, which results in a faster convergence time. The proposed CNN is tested on a finger-vein database developed in-house that contains 50 subjects with 10 samples from each finger. An identification rate of 100.00% is achieved, with an 80/20 percent ratio for separation of training and test samples, respectively. An additional number of subjects have also been tested, in which for 81 subjects an accuracy of 99.38% is achieved.","",""
16,"Qunting Yang, Tieniu Gao, Li Fan","A novel robust watermarking scheme based on neural network",2010,"","","","",73,"2022-07-13 10:10:34","","10.1109/ICISS.2010.5655017","","",,,,,16,1.33,5,3,12,"A color image oblivious watermarking scheme based on neural network and discrete wavelet transform (DWT) is proposed in this paper. Three identical watermarks and some different expanded bit streams are adaptively embedded into the low frequency sub-bands generated from three channels for a color image, respectively. Due to the adaptive learning capabilities of neural network, the expanded bit streams could be used to train back propagation (BP) neural networks to represent the relationship among the neighbor wavelet coefficients. Based on the trained neural networks, three watermarking results can be extracted and then are voted to decide the final watermark. Extensive experiments illustrate that the new scheme possesses good robustness against different attacks including noise addition, shearing, scaling, luminance and distortion. And what's more, the scheme has excellent performance in term of imperceptibility and resistance to JPEG compression.","",""
42,"Tianyi Liu, Xinsong Zhang, Wanhao Zhou, Weijia Jia","Neural Relation Extraction via Inner-Sentence Noise Reduction and Transfer Learning",2018,"","","","",74,"2022-07-13 10:10:34","","10.18653/v1/D18-1243","","",,,,,42,10.50,11,4,4,"Extracting relations is critical for knowledge base completion and construction in which distant supervised methods are widely used to extract relational facts automatically with the existing knowledge bases. However, the automatically constructed datasets comprise amounts of low-quality sentences containing noisy words, which is neglected by current distant supervised methods resulting in unacceptable precisions. To mitigate this problem, we propose a novel word-level distant supervised approach for relation extraction. We first build Sub-Tree Parse(STP) to remove noisy words that are irrelevant to relations. Then we construct a neural network inputting the sub-tree while applying the entity-wise attention to identify the important semantic features of relational words in each instance. To make our model more robust against noisy words, we initialize our network with a priori knowledge learned from the relevant task of entity classification by transfer learning. We conduct extensive experiments using the corpora of New York Times(NYT) and Freebase. Experiments show that our approach is effective and improves the area of Precision/Recall(PR) from 0.35 to 0.39 over the state-of-the-art work.","",""
35,"Guiguang Ding, Yuchen Guo, Kai Chen, Chaoqun Chu, J. Han, Qionghai Dai","DECODE: Deep Confidence Network for Robust Image Classification",2019,"","","","",75,"2022-07-13 10:10:34","","10.1109/TIP.2019.2902115","","",,,,,35,11.67,6,6,3,"Recent years have witnessed the success of deep convolutional neural networks for image classification and many related tasks. It should be pointed out that the existing training strategies assume that there is a clean dataset for model learning. In elaborately constructed benchmark datasets, deep network has yielded promising performance under the assumption. However, in real-world applications, it is burdensome and expensive to collect sufficient clean training samples. On the other hand, collecting noisy labeled samples is very economical and practical, especially with the rapidly increasing amount of visual data in the web. Unfortunately, the accuracy of current deep models may drop dramatically even with 5%–10% label noise. Therefore, enabling label noise resistant classification has become a crucial issue in the data driven deep learning approaches. In this paper, we propose a DEep COnfiDEnce network (DECODE) to address this issue. In particular, based on the distribution of mislabeled data, we adopt a confidence evaluation module that is able to determine the confidence that a sample is mislabeled. With the confidence, we further use a weighting strategy to assign different weights to different samples so that the model pays less attention to low confidence data, which is more likely to be noise. In this way, the deep model is more robust to label noise. DECODE is designed to be general, such that it can be easily combined with existing studies. We conduct extensive experiments on several datasets, and the results validate that DECODE can improve the accuracy of deep models trained with noisy data.","",""
13,"A. Alanís, A. M. Peinado, José A. González, A. Gómez","A Deep Identity Representation for Noise Robust Spoofing Detection",2018,"","","","",76,"2022-07-13 10:10:34","","10.21437/Interspeech.2018-1909","","",,,,,13,3.25,3,4,4,"The issue of the spoofing attacks which may affect automatic speaker verification systems (ASVs) has recently received an increased attention, so that a number of countermeasures have been developed for detecting high technology attacks such as speech synthesis and voice conversion. However, the performance of anti-spoofing systems degrades significantly in noisy conditions. To address this issue, we propose a deep learning framework to extract spoofing identity vectors, as well as the use of soft missing-data masks. The proposed feature extraction employs a convolutional neural network (CNN) plus a recurrent neural network (RNN) in order to provide a single deep feature vector per utterance. Thus, the CNN is treated as a convolutional feature extractor that operates at the frame level. On top of the CNN outputs, the RNN is employed to obtain a single spoofing identity representation of the whole utterance. Experimental evaluation is carried out on both a clean and a noisy version of the ASVSpoof2015 corpus. The experimental results show that our proposals clearly outperforms other methods recently proposed such as the popular CQCC+GMM system or other similar deep feature systems for both seen and unseen noisy conditions.","",""
29,"J. Kopf, Xuejian Rong, Jia-Bin Huang","Robust Consistent Video Depth Estimation",2020,"","","","",77,"2022-07-13 10:10:34","","10.1109/CVPR46437.2021.00166","","",,,,,29,14.50,10,3,2,"We present an algorithm for estimating consistent dense depth maps and camera poses from a monocular video. We integrate a learning-based depth prior, in the form of a convolutional neural network trained for single-image depth estimation, with geometric optimization, to estimate a smooth camera trajectory as well as detailed and stable depth reconstruction. Our algorithm combines two complementary techniques: (1) flexible deformation-splines for low-frequency large-scale alignment and (2) geometry-aware depth filtering for high-frequency alignment of fine depth details. In contrast to prior approaches, our method does not require camera poses as input and achieves robust reconstruction for challenging hand-held cell phone captures containing a significant amount of noise, shake, motion blur, and rolling shutter deformations. Our method quantitatively outperforms state-of-the-arts on the Sintel benchmark for both depth and pose estimations and attains favorable qualitative results across diverse wild datasets.","",""
1409,"David Snyder, D. Garcia-Romero, Gregory Sell, Daniel Povey, S. Khudanpur","X-Vectors: Robust DNN Embeddings for Speaker Recognition",2018,"","","","",78,"2022-07-13 10:10:34","","10.1109/ICASSP.2018.8461375","","",,,,,1409,352.25,282,5,4,"In this paper, we use data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition. The DNN, which is trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings that we call x-vectors. Prior studies have found that embeddings leverage large-scale training datasets better than i-vectors. However, it can be challenging to collect substantial quantities of labeled data for training. We use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness. The x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese. We find that while augmentation is beneficial in the PLDA classifier, it is not helpful in the i-vector extractor. However, the x-vector DNN effectively exploits data augmentation, due to its supervised training. As a result, the x-vectors achieve superior performance on the evaluation datasets.","",""
90,"Christopher A. Metzler, Philip Schniter, A. Veeraraghavan, Richard Baraniuk","prDeep: Robust Phase Retrieval with a Flexible Deep Network",2018,"","","","",79,"2022-07-13 10:10:34","","","","",,,,,90,22.50,23,4,4,"Phase retrieval algorithms have become an important component in many modern computational imaging systems. For instance, in the context of ptychography and speckle correlation imaging, they enable imaging past the diffraction limit and through scattering media, respectively. Unfortunately, traditional phase retrieval algorithms struggle in the presence of noise. Progress has been made recently on more robust algorithms using signal priors, but at the expense of limiting the range of supported measurement models (e.g., to Gaussian or coded diffraction patterns). In this work we leverage the regularization-by-denoising framework and a convolutional neural network denoiser to create prDeep, a new phase retrieval algorithm that is both robust and broadly applicable. We test and validate prDeep in simulation to demonstrate that it is robust to noise and can handle a variety of system models.  A MatConvNet implementation of prDeep is available at this https URL.","",""
67,"A. Narayanan, Deliang Wang","Improving Robustness of Deep Neural Network Acoustic Models via Speech Separation and Joint Adaptive Training",2015,"","","","",80,"2022-07-13 10:10:34","","10.1109/TASLP.2014.2372314","","",,,,,67,9.57,34,2,7,"Although deep neural network (DNN) acoustic models are known to be inherently noise robust, especially with matched training and testing data, the use of speech separation as a frontend and for deriving alternative feature representations has been shown to improve performance in challenging environments. We first present a supervised speech separation system that significantly improves automatic speech recognition (ASR) performance in realistic noise conditions. The system performs separation via ratio time-frequency masking; the ideal ratio mask (IRM) is estimated using DNNs. We then propose a framework that unifies separation and acoustic modeling via joint adaptive training. Since the modules for acoustic modeling and speech separation are implemented using DNNs, unification is done by introducing additional hidden layers with fixed weights and appropriate network architecture. On the CHiME-2 medium-large vocabulary ASR task, and with log mel spectral features as input to the acoustic model, an independently trained ratio masking frontend improves word error rates by 10.9% (relative) compared to the noisy baseline. In comparison, the jointly trained system improves performance by 14.4%. We also experiment with alternative feature representations to augment the standard log mel features, like the noise and speech estimates obtained from the separation module, and the standard feature set used for IRM estimation. Our best system obtains a word error rate of 15.4% (absolute), an improvement of 4.6 percentage points over the next best result on this corpus.","",""
22,"T. V. Pham, Chien T. Tang, M. Stadtschnitzer","Using Artificial Neural Network for Robust Voice Activity Detection Under Adverse Conditions",2009,"","","","",81,"2022-07-13 10:10:34","","10.1109/RIVF.2009.5174662","","",,,,,22,1.69,7,3,13,"We present an approach to model-based voice activity detection (VAD) for harsh environments. By using mel-frequency cepstral coefficients feature extracted from clean and noisy speech samples, an artificial neural network is trained optimally in order to provide a reliable model. There are three main aspects to this study: First, in addition to the developed model, recent state-of-the-art VAD methods are analyzed extensively. Second, we present an optimization procedure of neural network training, including evaluation of trained network performance with proper measures. Third, a large assortment of empirical results on the noisy TIMIT and SNOW corpuses including different types of noise at different signal-to-noise ratios is provided. We evaluate the built VAD model on the noisy corpuses and compare against the state-of-the-art VAD methods such as the ITU-T Rec. G. 729 Annex B, the ETSI AFE ES 202 050, and recently promising VAD algorithms. Results show that: (i) the proposed neural network classifier employing MFCC feature provides robustly high scores under different noisy conditions; (ii) the invented model is superior to other VAD methods in terms of various classification measures; (iii) the robustness of the developed VAD algorithm is still hold in the case of testing it with the completely mismatched environment.","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",82,"2022-07-13 10:10:34","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
11,"M. Trompf","Neural network development for noise reduction in robust speech recognition",1992,"","","","",83,"2022-07-13 10:10:34","","10.1109/IJCNN.1992.227233","","",,,,,11,0.37,11,1,30,"Speech recognition systems with small and medium vocabulary are used as natural human interfaces in a variety of applications. To make such a system more robust, the development of a neural network based noise reduction module is described. Using standard feedforward networks, several topologies have been tested to learn about the properties of neural noise reduction. For the development of a sufficiently robust nonadaptive system, information about the characteristics of the noise and speech components of the input signal including context information was taken into account. The focus is on the stepwise experiment-oriented improvement of a basic linear neural noise reduction network. The isolated word recognition system and the database used for the experiments are described. Results from different noise reduction networks are given. To test their robustness, simulations with varying input signal characteristics were made and are discussed.<<ETX>>","",""
207,"I. Mcloughlin, Haomin Zhang, Zhipeng Xie, Yan Song, Wei Xiao","Robust Sound Event Classification Using Deep Neural Networks",2015,"","","","",84,"2022-07-13 10:10:34","","10.1109/TASLP.2015.2389618","","",,,,,207,29.57,41,5,7,"The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.","",""
34,"Wonseok Jeon, Wooyoung Jeong, Kyungchan Son, Hyunseok Yang","Speckle noise reduction for digital holographic images using multi-scale convolutional neural networks.",2018,"","","","",85,"2022-07-13 10:10:34","","10.1364/OL.43.004240","","",,,,,34,8.50,9,4,4,"In this Letter, we propose a fast speckle noise reduction method with only a single reconstructed image based on convolutional neural networks. The proposed network has multi-sized kernels that can capture the speckle noise component effectively from digital holographic images. For robust noise reduction performance, the network is trained with a large noisy image dataset that has object-dependent noise and a wide range of noise levels. The experimental results show the fast, robust, and outstanding speckle noise reduction performance of the proposed approach.","",""
35,"S. Kale, Dr. Sanjay Vasant Dudul","Intelligent Noise Removal from EMG Signal Using Focused Time-Lagged Recurrent Neural Network",2009,"","","","",86,"2022-07-13 10:10:34","","10.1155/2009/129761","","",,,,,35,2.69,18,2,13,"Electromyography (EMG) signals can be used for clinical/biomedical application and modern human computer interaction. EMG signals acquire noise while traveling through tissue, inherent noise in electronics equipment, ambient noise, and so forth. ANN approach is studied for reduction of noise in EMG signal. In this paper, it is shown that Focused Time-Lagged Recurrent Neural Network (FTLRNN) can elegantly solve to reduce the noise from EMG signal. After rigorous computer simulations, authors developed an optimal FTLRNN model, which removes the noise from the EMG signal. Results show that the proposed optimal FTLRNN model has an MSE (Mean Square Error) as low as 0.000067 and 0.000048, correlation coefficient as high as 0.99950 and 0.99939 for noise signal and EMG signal, respectively, when validated on the test dataset. It is also noticed that the output of the estimated FTLRNN model closely follows the real one. This network is indeed robust as EMG signal tolerates the noise variance from 0.1 to 0.4 for uniform noise and 0.30 for Gaussian noise. It is clear that the training of the network is independent of specific partitioning of dataset. It is seen that the performance of the proposed FTLRNN model clearly outperforms the best Multilayer perceptron (MLP) and Radial Basis Function NN (RBF) models. The simple NN model such as the FTLRNN with single-hidden layer can be employed to remove noise from EMG signal.","",""
7,"H. Sørensen","Noise-robust speech recognition using a cepstral noise reduction neural network architecture",1991,"","","","",87,"2022-07-13 10:10:34","","10.1109/IJCNN.1991.155436","","",,,,,7,0.23,7,1,31,"The problem of speech recognition in the presence of interfering nonstationary noise is addressed. A method for noise reduction in the cepstral domain based on a universal approximator is proposed and tested on a large database of isolated words contaminated with nonstationary F-16 jet cockpit noise. The speech recognition system consists of a concatenation of an auditory preprocessing module, the cepstral noise reduction network (CNR network), and a neural network classifier. The proposed architecture performs a nonlinear autoassociative mapping in the cepstral domain between a set of noisy cepstral coefficients from the preprocessing module and a set of noise-free cepstral coefficients. The output from the CNR network is input to the neural network classifier, in which the output functions are approximations to the Bayes optimal discriminant functions. Noise reduction is possible in the preprocessing module and in the classifier, essentially making the system a three-stage noise reduction system. The average recognition rate on a test database was improved up to 65% when the CNR network was added to the speech recognition system.<<ETX>>","",""
51,"Yadollah Yaghoobzadeh, Heike Adel, Hinrich Schütze","Noise Mitigation for Neural Entity Typing and Relation Extraction",2016,"","","","",88,"2022-07-13 10:10:34","","10.18653/V1/E17-1111","","",,,,,51,8.50,17,3,6,"In this paper, we address two different types of noise in information extraction models: noise from distant supervision and noise from pipeline input features. Our target tasks are entity typing and relation extraction. For the first noise type, we introduce multi-instance multi-label learning algorithms using neural network models, and apply them to fine-grained entity typing for the first time. Our model outperforms the state-of-the-art supervised approach which uses global embeddings of entities. For the second noise type, we propose ways to improve the integration of noisy entity type predictions into relation extraction. Our experiments show that probabilistic predictions are more robust than discrete predictions and that joint training of the two tasks performs best.","",""
83,"P. Merolla, R. Appuswamy, J. Arthur, Steven K. Esser, D. Modha","Deep neural networks are robust to weight binarization and other non-linear distortions",2016,"","","","",89,"2022-07-13 10:10:34","","","","",,,,,83,13.83,17,5,6,"Recent results show that deep neural networks achieve excellent performance even when, during training, weights are quantized and projected to a binary representation. Here, we show that this is just the tip of the iceberg: these same networks, during testing, also exhibit a remarkable robustness to distortions beyond quantization, including additive and multiplicative noise, and a class of non-linear projections where binarization is just a special case. To quantify this robustness, we show that one such network achieves 11% test error on CIFAR-10 even with 0.68 effective bits per weight. Furthermore, we find that a common training heuristic--namely, projecting quantized weights during backpropagation--can be altered (or even removed) and networks still achieve a base level of robustness during testing. Specifically, training with weight projections other than quantization also works, as does simply clipping the weights, both of which have never been reported before. We confirm our results for CIFAR-10 and ImageNet datasets. Finally, drawing from these ideas, we propose a stochastic projection rule that leads to a new state of the art network with 7.64% test error on CIFAR-10 using no data augmentation.","",""
198,"Kerstin Beer, Dmytro Bondarenko, Terry Farrelly, T. Osborne, Robert Salzmann, Daniel Scheiermann, Ramona Wolf","Training deep quantum neural networks",2020,"","","","",90,"2022-07-13 10:10:34","","10.1038/s41467-020-14454-2","","",,,,,198,99.00,28,7,2,"","",""
988,"Anish Athalye, Logan Engstrom, Andrew Ilyas, K. Kwok","Synthesizing Robust Adversarial Examples",2017,"","","","",91,"2022-07-13 10:10:34","","","","",,,,,988,197.60,247,4,5,"Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world.","",""
51,"Chang Qiao, Di Li, Yuting Guo, Chong Liu, Tao Jiang, Qionghai Dai, Dong Li","Evaluation and development of deep neural networks for image super-resolution in optical microscopy.",2021,"","","","",92,"2022-07-13 10:10:34","","10.1038/s41592-020-01048-5","","",,,,,51,51.00,7,7,1,"","",""
30,"Junjie Chen, Songling Huang, Wei Zhao","Three-dimensional defect inversion from magnetic flux leakage signals using iterative neural network",2015,"","","","",93,"2022-07-13 10:10:34","","10.1049/IET-SMT.2014.0173","","",,,,,30,4.29,10,3,7,"Defect inversion is of special interest to magnetic flux leakage (MFL) inspection in industry. This study proposes an iterative neural network to reconstruct three-dimensional defect profiles from three-axial MFL signals in pipeline inspection. A radial basis function neural network is utilised as the forward model to predict the MFL signals given a defect profile, and the defect profile gets updated based on a combination of gradient descent and simulated annealing in the iterative inversion procedure. Accuracy of the proposed inversion procedure is demonstrated in estimating the profile of different defects in steel pipes. Experimental result based on three-axial simulated MFL data also shows that the proposed inversion approach is robust even in presence of reasonable noise.","",""
72,"Kun Han, Deliang Wang","Neural Network Based Pitch Tracking in Very Noisy Speech",2014,"","","","",94,"2022-07-13 10:10:34","","10.1109/TASLP.2014.2363410","","",,,,,72,9.00,36,2,8,"Pitch determination is a fundamental problem in speech processing, which has been studied for decades. However, it is challenging to determinate pitch in strong noise because the harmonic structure is corrupted. In this paper, we estimate pitch using supervised learning, where the probabilistic pitch states are directly learned from noisy speech data. We investigate two alternative neural networks modeling pitch state distribution given observations. The first one is a feedforward deep neural network (DNN), which is trained on static frame-level acoustic features. The second one is a recurrent deep neural network (RNN) which is trained on sequential frame-level features and capable of learning temporal dynamics. Both DNNs and RNNs produce accurate probabilistic outputs of pitch states, which are then connected into pitch contours by Viterbi decoding. Our systematic evaluation shows that the proposed pitch tracking algorithms are robust to different noise conditions and can even be applied to reverberant speech. The proposed approach also significantly outperforms other state-of-the-art pitch tracking algorithms.","",""
75,"Vaibhav Gandhi, G. Prasad, D. Coyle, L. Behera, T. McGinnity","Quantum Neural Network-Based EEG Filtering for a Brain–Computer Interface",2014,"","","","",95,"2022-07-13 10:10:34","","10.1109/TNNLS.2013.2274436","","",,,,,75,9.38,15,5,8,"A novel neural information processing architecture inspired by quantum mechanics and incorporating the well-known Schrodinger wave equation is proposed in this paper. The proposed architecture referred to as recurrent quantum neural network (RQNN) can characterize a nonstationary stochastic signal as time-varying wave packets. A robust unsupervised learning algorithm enables the RQNN to effectively capture the statistical behavior of the input signal and facilitates the estimation of signal embedded in noise with unknown characteristics. The results from a number of benchmark tests show that simple signals such as dc, staircase dc, and sinusoidal signals embedded within high noise can be accurately filtered and particle swarm optimization can be employed to select model parameters. The RQNN filtering procedure is applied in a two-class motor imagery-based brain-computer interface where the objective was to filter electroencephalogram (EEG) signals before feature extraction and classification to increase signal separability. A two-step inner-outer fivefold cross-validation approach is utilized to select the algorithm parameters subject-specifically for nine subjects. It is shown that the subject-specific RQNN EEG filtering significantly improves brain-computer interface performance compared to using only the raw EEG or Savitzky-Golay filtered EEG across multiple sessions.","",""
26,"Suyoun Kim, B. Raj, I. Lane","Environmental Noise Embeddings for Robust Speech Recognition",2016,"","","","",96,"2022-07-13 10:10:34","","","","",,,,,26,4.33,9,3,6,"We propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model. A deep neural network is used to predict the acoustic environment in which the system in being used. The discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model. Through a series of experiments on Resource Management, CHiME-3 task, and Aurora4, we show that the proposed approach significantly improves speech recognition accuracy in noisy and highly reverberant environments, outperforming multi-condition training, noise-aware training, i-vector framework, and multi-task learning on both in-domain noise and unseen noise.","",""
67,"Runchun Wang, Gregory Cohen, K. M. Stiefel, T. Hamilton, J. Tapson, A. van Schaik","An FPGA Implementation of a Polychronous Spiking Neural Network with Delay Adaptation",2013,"","","","",97,"2022-07-13 10:10:34","","10.3389/fnins.2013.00014","","",,,,,67,7.44,11,6,9,"We present an FPGA implementation of a re-configurable, polychronous spiking neural network with a large capacity for spatial-temporal patterns. The proposed neural network generates delay paths de novo, so that only connections that actually appear in the training patterns will be created. This allows the proposed network to use all the axons (variables) to store information. Spike Timing Dependent Delay Plasticity is used to fine-tune and add dynamics to the network. We use a time multiplexing approach allowing us to achieve 4096 (4k) neurons and up to 1.15 million programmable delay axons on a Virtex 6 FPGA. Test results show that the proposed neural network is capable of successfully recalling more than 95% of all spikes for 96% of the stored patterns. The tests also show that the neural network is robust to noise from random input spikes.","",""
255,"R. Laje, D. Buonomano","ROBUST TIMING AND MOTOR PATTERNS BY TAMING CHAOS IN RECURRENT NEURAL NETWORKS",2013,"","","","",98,"2022-07-13 10:10:34","","10.1038/nn.3405","","",,,,,255,28.33,128,2,9,"","",""
101,"A. Narayanan, Deliang Wang","Joint noise adaptive training for robust automatic speech recognition",2014,"","","","",99,"2022-07-13 10:10:34","","10.1109/ICASSP.2014.6854051","","",,,,,101,12.63,51,2,8,"We explore time-frequency masking to improve noise robust automatic speech recognition. Apart from its use as a frontend, we use it for providing smooth estimates of speech and noise which are then passed as additional features to a deep neural network (DNN) based acoustic model. Such a system improves performance on the Aurora-4 dataset by 10.5% (relative) compared to the previous best published results. By formulating separation as a supervised mask estimation problem, we develop a unified DNN framework that jointly improves separation and acoustic modeling. Our final system outperforms the previous best system on CHiME-2 corpus by 22.1% (relative).","",""
33,"A. R. Trivedi, S. Datta, S. Mukhopadhyay","Application of Silicon-Germanium Source Tunnel-FET to Enable Ultralow Power Cellular Neural Network-Based Associative Memory",2014,"","","","",100,"2022-07-13 10:10:34","","10.1109/TED.2014.2357777","","",,,,,33,4.13,11,3,8,"This paper studies the application of tunnel FET (TFET) in designing a low power and robust cellular neural network (CNN)-based associative memory (AM). The lower leakage, steeper switching slope, and higher output resistance of TFET are exploited in designing an ultralow-power TFET-based operational transconductance amplifier (OTA). A TFET-OTA is utilized as a programmable synaptic weight multiplier for CNN. The ultralow-power of TFET-OTA enables a higher connectivity network even at a lower power, and thereby improves the memory capacity and input pattern noise tolerance of CNN-AM for low power applications. The TFET-based higher connectivity CNN also exploits the unique characteristics of TFET to improve the throughput efficiency of CNN-AM.","",""
150,"F. Bianchi, Daniele Grattarola, L. Livi, C. Alippi","Graph Neural Networks With Convolutional ARMA Filters",2019,"","","","",101,"2022-07-13 10:10:34","","10.1109/TPAMI.2021.3054830","","",,,,,150,50.00,38,4,3,"Popular graph neural networks implement convolution operations on graphs based on polynomial spectral filters. In this paper, we propose a novel graph convolutional layer inspired by the auto-regressive moving average (ARMA) filter that, compared to polynomial ones, provides a more flexible frequency response, is more robust to noise, and better captures the global graph structure. We propose a graph neural network implementation of the ARMA filter with a recursive and distributed formulation, obtaining a convolutional layer that is efficient to train, localized in the node space, and can be transferred to new graphs at test time. We perform a spectral analysis to study the filtering effect of the proposed ARMA layer and report experiments on four downstream tasks: semi-supervised node classification, graph signal classification, graph classification, and graph regression. Results show that the proposed ARMA layer brings significant improvements over graph neural networks based on polynomial filters.","",""
192,"Forest Agostinelli, Michael R. Anderson, Honglak Lee","Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising",2013,"","","","",102,"2022-07-13 10:10:34","","","","",,,,,192,21.33,64,3,9,"Stacked sparse denoising autoencoders (SSDAs) have recently been shown to be successful at removing noise from corrupted images. However, like most denoising techniques, the SSDA is not robust to variation in noise types beyond what it has seen during training. To address this limitation, we present the adaptive multi-column stacked sparse denoising autoencoder (AMC-SSDA), a novel technique of combining multiple SSDAs by (1) computing optimal column weights via solving a nonlinear optimization program and (2) training a separate network to predict the optimal weights. We eliminate the need to determine the type of noise, let alone its statistics, at test time and even show that the system can be robust to noise not seen in the training set. We show that state-of-the-art denoising performance can be achieved with a single system on a variety of different noise types. Additionally, we demonstrate the efficacy of AMC-SSDA as a preprocessing (denoising) algorithm by achieving strong classification performance on corrupted MNIST digits.","",""
23,"Jürgen T. Geiger, J. Gemmeke, Björn Schuller, G. Rigoll","Investigating NMF speech enhancement for neural network based acoustic models",2014,"","","","",103,"2022-07-13 10:10:34","","","","",,,,,23,2.88,6,4,8,"In the light of the improvements that were made in the last years with neural network-based acoustic models, it is an interesting question whether these models are also suited for noise-robust recognition. This has not yet been fully explored, although first experiments confirm this question. Furthermore, preprocessing techniques that improve the robustness should be re-evaluated with these new models. In this work, we present experimental results to address these questions. Acoustic models based on Gaussian mixture models (GMMs), deep neural networks (DNNs), and long short-term memory (LSTM) recurrent neural networks (which have an improved ability to exploit context) are evaluated for their robustness after clean or multi-condition training. In addition, the influence of non-negative matrix factorization (NMF) for speech enhancement is investigated. Experiments are performed with the Aurora-4 database and the results show that DNNs perform slightly better than LSTMs and, as expected, both beat GMMs. Furthermore, speech enhancement is capable of improving the DNN result.","",""
20,"Zeyan Oo, Yuta Kawakami, Longbiao Wang, S. Nakagawa, Xiong Xiao, M. Iwahashi","DNN-Based Amplitude and Phase Feature Enhancement for Noise Robust Speaker Identification",2016,"","","","",104,"2022-07-13 10:10:34","","10.21437/Interspeech.2016-717","","",,,,,20,3.33,3,6,6,"The importance of the phase information of speech signal is gathering attention. Many researches indicate system combination of the amplitude and phase features is effective for improving speaker recognition performance under noisy environments. On the other hand, speech enhancement approach is taken usually to reduce the influence of noises. However, this approach only enhances the amplitude spectrum, therefor noisy phase spectrum is used for reconstructing the estimated signal. Recent years, DNN based feature enhancement is studied intensively for robust speech processing. This approach is expected to be effective also for phase-based feature. In this paper, we propose feature space enhancement of amplitude and phase features using deep neural network (DNN) for speaker identification. We used mel-frequency cepstral coefficients as an amplitude feature, and modified group delay cepstral coefficients as a phase feature. Simultaneous enhancement of amplitude and phase based feature was effective, and it achieved about 24% relative error reduction comparing with individual feature enhancement.","",""
55,"Félix G. Harvey, Mike Yurick, Derek Nowrouzezahrai, C. Pal","Robust motion in-betweening",2020,"","","","",105,"2022-07-13 10:10:34","","10.1145/3386569.3392480","","",,,,,55,27.50,14,4,2,"In this work we present a novel, robust transition generation technique that can serve as a new tool for 3D animators, based on adversarial recurrent neural networks. The system synthesises high-quality motions that use temporally-sparse keyframes as animation constraints. This is reminiscent of the job of in-betweening in traditional animation pipelines, in which an animator draws motion frames between provided keyframes. We first show that a state-of-the-art motion prediction model cannot be easily converted into a robust transition generator when only adding conditioning information about future keyframes. To solve this problem, we then propose two novel additive embedding modifiers that are applied at each timestep to latent representations encoded inside the network's architecture. One modifier is a time-to-arrival embedding that allows variations of the transition length with a single model. The other is a scheduled target noise vector that allows the system to be robust to target distortions and to sample different transitions given fixed keyframes. To qualitatively evaluate our method, we present a custom MotionBuilder plugin that uses our trained model to perform in-betweening in production scenarios. To quantitatively evaluate performance on transitions and generalizations to longer time horizons, we present well-defined in-betweening benchmarks on a subset of the widely used Human3.6M dataset and on LaFAN1, a novel high quality motion capture dataset that is more appropriate for transition generation. We are releasing this new dataset along with this work, with accompanying code for reproducing our baseline results.","",""
78,"F. Porikli, Tekin Kocak","Robust License Plate Detection Using Covariance Descriptor in a Neural Network Framework",2006,"","","","",106,"2022-07-13 10:10:34","","10.1109/AVSS.2006.100","","",,,,,78,4.88,39,2,16,"We present a license plate detection algorithm that employs a novel image descriptor. Instead of using conventional gradient filters and intensity histograms, we compute a covariance matrix of low-level pixel-wise features within a given image window. Unlike the existing approaches, this matrix effectively captures both statistical and spatial properties within the window. We normalize the covariance matrix using local variance scores and restructure the unique coefficients into a feature vector form. Then, we feed these coefficients into a multi-layer neural network. Since no explicit similarity or distance computation is required in this framework, we are able to keep the computational load of the detection process low. To further accelerate the covariance matrix extraction process, we adapt an integral image based data propagation technique. Our extensive analysis shows that the detection process is robust against noise, illumination distortions, and rotation. In addition, the presented method does not require careful fine tuning of the decision boundaries.","",""
18,"S. Bianco, Luigi Celona, R. Schettini","Robust smile detection using convolutional neural networks",2016,"","","","",107,"2022-07-13 10:10:34","","10.1117/1.JEI.25.6.063002","","",,,,,18,3.00,6,3,6,"Abstract. We present a fully automated approach for smile detection. Faces are detected using a multiview face detector and aligned and scaled using automatically detected eye locations. Then, we use a convolutional neural network (CNN) to determine whether it is a smiling face or not. To this end, we investigate different shallow CNN architectures that can be trained even when the amount of learning data is limited. We evaluate our complete processing pipeline on the largest publicly available image database for smile detection in an uncontrolled scenario. We investigate the robustness of the method to different kinds of geometric transformations (rotation, translation, and scaling) due to imprecise face localization, and to several kinds of distortions (compression, noise, and blur). To the best of our knowledge, this is the first time that this type of investigation has been performed for smile detection. Experimental results show that our proposal outperforms state-of-the-art methods on both high- and low-quality images.","",""
66,"Jürgen T. Geiger, Zixing Zhang, F. Weninger, Björn Schuller, G. Rigoll","Robust speech recognition using long short-term memory recurrent neural networks for hybrid acoustic modelling",2014,"","","","",108,"2022-07-13 10:10:34","","","","",,,,,66,8.25,13,5,8,"One method to achieve robust speech recognition in adverse conditions including noise and reverberation is to employ acoustic modelling techniques involving neural networks. Using long short-term memory (LSTM) recurrent neural networks proved to be efficient for this task in a setup for phoneme prediction in a multi-stream GMM-HMM framework. These networks exploit a self-learnt amount of temporal context, which makes them especially suited for a noisy speech recognition task. One shortcoming of this approach is the necessity of a GMM acoustic model in the multi-stream framework. Furthermore, potential modelling power of the network is lost when predicting phonemes, compared to the classical hybrid setup where the network predicts HMM states. In this work, we propose to use LSTM networks in a hybrid HMM setup, in order to overcome these drawbacks. Experiments are performed using the medium-vocabulary recognition track of the 2nd CHiME challenge, containing speech utterances in a reverberant and noisy environment. A comparison of different network topologies for phoneme or state prediction used either in the hybrid or double-stream setup shows that state prediction networks perform better than networks predicting phonemes, leading to stateof-the-art results for this database.","",""
23,"Zhishun Wang, Zhenya He, Jiande D. Z. Chen","Robust time delay estimation of bioelectric signals using least absolute deviation neural network",2005,"","","","",109,"2022-07-13 10:10:34","","10.1109/TBME.2004.843287","","",,,,,23,1.35,8,3,17,"The time delay estimation (TDE) is an important issue in modern signal processing and it has found extensive applications in the spatial propagation feature extraction of biomedical signals as well. Due to the extreme complexity and variability of the underlying systems, biomedical signals are usually nonstationary, unstable and even chaotic. Furthermore, due to the limitations of the measurement environments, biomedical signals are often noise-contaminated. Therefore, the TDE of biomedical signals is a challenging issue. A new TDE algorithm based on the least absolute deviation neural network (LADNN) and its application experiments are presented in this paper. The LADNN is the neural implementation of the least absolute deviation (LAD) optimization model, also called unconstrained minimum L/sub 1/-norm model, with a theoretically proven global convergence. In the proposed LADNN-based TDE algorithm, a given signal is modeled using the moving average (MA) model. The MA parameters are estimated by using the LADNN and the time delay corresponds to the time index at which the MA coefficients have a peak. Due to the excellent features of L/sub 1/-norm model superior to L/sub p/-norm (p>1) models in non-Gaussian noise environments or even in chaos, especially for signals that contain sharp transitions (such as biomedical signals with spiky series or motion artifacts) or chaotic dynamic processes, the LADNN-based TDE is more robust than the existing TDE algorithms based on wavelet-domain correlation and those based on higher-order spectra (HOS). Unlike these conventional methods, especially the current state-of-the-art HOS-based TDE, the LADNN-based method is free of the assumption that the signal is non-Gaussian and the noises are Gaussian and, thus, it is more applicable in real situations. Simulation experiments under three different noise environments, Gaussian, non-Gaussian and chaotic, are conducted to compare the proposed TDE method with the existing HOS-based method. Real application experiment is conducted to extract time delay information between every two adjacent channels of gastric myoelectrical activity (GMA) to assess the spatial propagation characteristics of GMA during different phases of the migrating myoelectrical complex (MMC).","",""
72,"Zizhao Zhang, Han Zhang, Sercan Ö. Arik, Honglak Lee, Tomas Pfister","Distilling Effective Supervision From Severe Label Noise",2019,"","","","",110,"2022-07-13 10:10:34","","10.1109/CVPR42600.2020.00931","","",,,,,72,24.00,14,5,3,"Collecting large-scale data with clean labels for supervised training of neural networks is practically challenging. Although noisy labels are usually cheap to acquire, existing methods suffer a lot from label noise. This paper targets at the challenge of robust training at high label noise regimes. The key insight to achieve this goal is to wisely leverage a small trusted set to estimate exemplar weights and pseudo labels for noisy data in order to reuse them for supervised training. We present a holistic framework to train deep neural networks in a way that is highly invulnerable to label noise. Our method sets the new state of the art on various types of label noise and achieves excellent performance on large-scale datasets with real-world label noise. For instance, on CIFAR100 with a 40% uniform noise ratio and only 10 trusted labeled data per class, our method achieves 80.2% classification accuracy, where the error rate is only 1.4% higher than a neural network trained without label noise. Moreover, increasing the noise ratio to 80%, our method still maintains a high accuracy of 75.5%, compared to the previous best accuracy 48.2%.","",""
44,"V. Mitra, Weiqi Wang, H. Franco, Yun Lei, C. Bartels, M. Graciarena","Evaluating robust features on deep neural networks for speech recognition in noisy and channel mismatched conditions",2014,"","","","",111,"2022-07-13 10:10:34","","","","",,,,,44,5.50,7,6,8,"Deep Neural Network (DNN) based acoustic models have shown significant improvement over their Gaussian Mixture Model (GMM) counterparts in the last few years. While several studies exist that evaluate the performance of GMM systems under noisy and channel degraded conditions, noise robustness studies on DNN systems have been far fewer. In this work we present a study exploring both conventional DNNs and deep Convolutional Neural Networks (CNN) for noiseand channel-degraded speech recognition tasks using the Aurora4 dataset. We compare the baseline mel-filterbank energies with noise-robust features that we have proposed earlier and show that the use of robust features helps to improve the performance of DNNs or CNNs compared to melfilterbank energies. We also show that vocal tract length normalization has a positive role in improving the performance of the robust acoustic features. Finally, we show that by combining multiple systems together we can achieve even further improvement in recognition accuracy.","",""
22,"R. Monasson, S. Rosay","Crosstalk and transitions between multiple spatial maps in an attractor neural network model of the hippocampus: phase diagram.",2013,"","","","",112,"2022-07-13 10:10:34","","10.1103/PhysRevE.87.062813","","",,,,,22,2.44,11,2,9,"We study the stable phases of an attractor neural network model, with binary units, for hippocampal place cells encoding one-dimensional (1D) or 2D spatial maps or environments. Different maps correspond to random allocations (permutations) of the place fields. Based on replica calculations we show that, below critical levels for the noise in the neural response and for the number of environments, the network activity is spatially localized in one environment. For high noise and loads the network activity extends over space, either uniformly or with spatial heterogeneities due to the crosstalk between the maps, and memory of environments is lost. Remarkably the spatially localized regime is very robust against the neural noise until it reaches its critical level. Numerical simulations are in excellent quantitative agreement with our theoretical predictions.","",""
15,"Lijie Zhao, T. Chai","Wastewater BOD Forecasting Model for Optimal Operation Using Robust Time-Delay Neural Network",2005,"","","","",113,"2022-07-13 10:10:34","","10.1007/11427469_163","","",,,,,15,0.88,8,2,17,"","",""
38,"M. Sakawa, S. Ushiro, K. Kato, K. Ohtsuka","Cooling load prediction in a district heating and cooling system through simplified robust filter and multi-layered neural network",1999,"","","","",114,"2022-07-13 10:10:34","","10.1109/ICSMC.1999.823364","","",,,,,38,1.65,10,4,23,"The cooling load is a heat value of the cold water used for air conditioning in a district heating and cooling system. Cooling load prediction in such a system is one of key techniques needed for its smooth and economical operation. Unfortunately, since actual cooling load data usually involves measurement noise, outliers and missing data, for several reasons, a prediction method considering the effect of the outliers and missing data is desirable. In this paper, a new prediction method using a simplified robust filter with improved numerical stability and a three-layered neural network is proposed.","",""
149,"Songwu Lu, T. Başar","Robust nonlinear system identification using neural-network models",1998,"","","","",115,"2022-07-13 10:10:34","","10.1109/72.668883","","",,,,,149,6.21,75,2,24,"We study the problem of identification for nonlinear systems in the presence of unknown driving noise, using both feedforward multilayer neural network and radial basis function network models. Our objective is to resolve the difficulty associated with the persistency of excitation condition inherent to the standard schemes in the neural identification literature. This difficulty is circumvented here by a novel formulation and by using a new class of identification algorithms recently obtained by Didinsky et al. We show how these algorithms can be exploited to successfully identify the nonlinearity in the system using neural-network models. By embedding the original problem in one with noise-perturbed state measurements, we present a class of identifiers (under L1 and L2 cost criteria) which secure a good approximant for the system nonlinearity provided that some global optimization technique is used. In this respect, many available learning algorithms in the current neural-network literature, e.g., the backpropagation scheme and the genetic algorithms-based scheme, with slight modifications, can ensure the identification of the system nonlinearity. Subsequently, we address the same problem under a third, worst case L(infinity) criterion for an RBF modeling. We present a neural-network version of an H(infinity)-based identification algorithm from Didinsky et al and show how, along with an appropriate choice of control input to enhance excitation, under both full-state-derivative information (FSDI) and noise-perturbed full-state-information (NPFSI), it leads to satisfaction of a relevant persistency of excitation condition, and thereby to robust identification of the nonlinearity. Results from several simulation studies have been included to demonstrate the effectiveness of these algorithms.","",""
24,"T. Chuah, B. Sharif, O. Hinton","Robust CDMA multiuser detection using a neural-network approach",2002,"","","","",116,"2022-07-13 10:10:34","","10.1109/TNN.2002.804310","","",,,,,24,1.20,8,3,20,"Abstract-Recently, a robust version of the linear decorrelating detector (LDD) based on the Huber's M-estimation technique has been proposed. In this paper, we first demonstrate the use of a three-layer recurrent neural network (RNN) to implement the LDD without requiring matrix inversion. The key idea is based on minimizing an appropriate computational energy function iteratively. Second, it will be shown that the M-decorrelating detector (MDD) can be implemented by simply incorporating sigmoidal neurons in the first layer of the RNN. A proof of the redundancy of the matrix inversion process is provided and the computational saving in realistic network is highlighted. Third, we illustrate how further performance gain could be achieved for the subspace-based blind MDD by using robust estimates of the signal subspace components in the initial stage. The impulsive noise is modeled using non-Gaussian alpha-stable distributions, which do not include a Gaussian component but facilitate the use of the recently proposed geometric signal-to-noise ratio (G-SNR). The characteristics and performance of the proposed neural-network detectors are investigated by computer simulation.","",""
13,"A. Jalalvand, W. D. Neve, R. Walle, J. Martens","Towards using Reservoir Computing Networks for noise-robust image recognition",2016,"","","","",117,"2022-07-13 10:10:34","","10.1109/IJCNN.2016.7727398","","",,,,,13,2.17,3,4,6,"Reservoir Computing Network (RCN) is a special type of the single layer recurrent neural networks, in which the input and the recurrent connections are randomly generated and only the output weights are trained. Besides the ability to process temporal information, the key points of RCN are easy training and robustness against noise. Recently, we introduced a simple strategy to tune the parameters of RCN resulted in an effective and noise-robust RCN-based model for speech recognition. The aim of this work is to extend that study to the field of image processing. In particular, we investigate the potential of RCNs in achieving a competitive performance on the well-known MNIST dataset by following the aforementioned parameter optimizing strategy. Moreover, we achieve good noise robust recognition by utilizing such a network to denoise images and supplying them to a recognizer that is solely trained on clean images. The conducted experiments demonstrate that the proposed RCN-based handwritten digit recognizer achieves an error rate of 0.81 percent on the clean test data of the MNIST benchmark and that the proposed RCN-based denoiser can effectively reduce the error rate on the various types of noise.","",""
12,"E. Voudouri-Maniati, L. Kurz, J. Kowalski","A neural-network approach to nonparametric and robust classification procedures",1997,"","","","",118,"2022-07-13 10:10:34","","10.1109/72.557667","","",,,,,12,0.48,4,3,25,"In this paper algorithms of neural-network type are introduced for solving estimation and classification problems when assumptions about independence, Gaussianity, and stationarity of the observation samples are no longer valid. Specifically, the asymptotic normality of several nonparametric classification tests is demonstrated and their implementation using a neural-network approach is presented. Initially, the neural nets train themselves via learning samples for nominal noise and alternative hypotheses distributions resulting in near optimum performance in a particular stochastic environment. In other than the nominal environments, however, high efficiency is maintained by adapting the optimum nonlinearities to changing conditions during operation via parallel networks, without disturbing the classification process. Furthermore, the superiority in performance of the proposed networks over more traditional neural nets is demonstrated in an application involving pattern recognition.","",""
18,"Andrew L. Maas, Tyler M. O'Neil, Awni Y. Hannun, A. Ng","RECURRENT NEURAL NETWORK FEATURE ENHANCEMENT: THE 2nd CHIME CHALLENGE",2013,"","","","",119,"2022-07-13 10:10:34","","","","",,,,,18,2.00,5,4,9,"We apply a machine learning approach to improve noisy acoustic features for robust speech recognition. Specifically, we train a deep, recurrent neural network to map noisecorrupted input features to their corresponding clean versions. We introduce several improvements to previously proposed neural network feature enhancement architectures. The model does not include assumptions about the specific noise and distortions present in CHiME data, but does assume noisy and clean stereo pairs are available for training. When used with the standard recognizer on the small vocabulary task (track 1), our approach demonstrates substantial improvements over the challenge baseline.","",""
32,"Jürgen T. Geiger, F. Weninger, J. Gemmeke, M. Wöllmer, Björn Schuller, G. Rigoll","Memory-Enhanced Neural Networks and NMF for Robust ASR",2014,"","","","",120,"2022-07-13 10:10:34","","10.1109/TASLP.2014.2318514","","",,,,,32,4.00,5,6,8,"In this article we address the problem of distant speech recognition for reverberant noisy environments. Speech enhancement methods, e. g., using non-negative matrix factorization (NMF), are succesful in improving the robustness of ASR systems. Furthermore, discriminative training and feature transformations are employed to increase the robustness of traditional systems using Gaussian mixture models (GMM). On the other hand, acoustic models based on deep neural networks (DNN) were recently shown to outperform GMMs. In this work, we combine a state-of-the art GMM system with a deep Long Short-Term Memory (LSTM) recurrent neural network in a double-stream architecture. Such networks use memory cells in the hidden units, enabling them to learn long-range temporal context, and thus increasing the robustness against noise and reverberation. The network is trained to predict frame-wise phoneme estimates, which are converted into observation likelihoods to be used as an acoustic model. It is of particular interest whether the LSTM system is capable of improving a robust state-of-the-art GMM system, which is confirmed in the experimental results. In addition, we investigate the efficiency of NMF for speech enhancement on the front-end side. Experiments are conducted on the medium-vocabulary task of the 2nd `CHiME' Speech Separation and Recognition Challenge, which includes reverberation and highly variable noise. Experimental results show that the average word error rate of the challenge baseline is reduced by 64% relative. The best challenge entry, a noise-robust state-of-the-art recognition system, is outperformed by 25% relative.","",""
16,"T. Kondo, A. Ishiguro, S. Tokura, Y. Uchikawa, P. Eggenberger","Realization of robust controllers in evolutionary robotics: a dynamically-rearranging neural network approach",1999,"","","","",121,"2022-07-13 10:10:34","","10.1109/CEC.1999.781948","","",,,,,16,0.70,3,5,23,"The evolutionary robotics approach has been attracting a lot of attention in the field of robotics and artificial life. In this approach, neural networks are widely used to construct controllers for autonomous mobile agents, since they intrinsically have generalization, noise-tolerant abilities and so on. However, there are still open questions: (1) the gap between simulated and real environments, (2) the evolutionary and learning phase are completely separated, and (3) the conflict between stability and evolvability/adaptability. In this paper, we try to overcome these problems by incorporating the concept of dynamic rearrangement function of biological neural networks with the use of neuromodulators. Simulation results show that the proposed approach is highly promising.","",""
18,"Young-Sang Kim, B. Yum, Min Kim","Robust design of artificial neural network for roll force prediction in hot strip mill",2001,"","","","",122,"2022-07-13 10:10:34","","10.1109/IJCNN.2001.938817","","",,,,,18,0.86,6,3,21,"In the steel industry, a vast amount of data are gathered and stored in databases. These data usually exhibit high correlations, nonlinear relationships and low signal to noise ratios. Artificial neural networks (ANN) are known to be very useful for such data. However, selecting a suitable set of ANN parameter values is difficult even for an experienced user. This article proposes an experimental approach for determining ANN parameters in a robust manner for predicting the roll force in a hot strip mill process. Four design variables and two noise variables are included in the experiment, a full factorial design is adopted for the design matrix to estimate all main and two factor interaction effects, and the signal-to-noise (SN) ratio is used as a performance measure for achieving robustness. In the second experiment, only a fraction of the full factorial design is used as the design matrix and the results are compared with those from the full factorial experiment in terms of prediction accuracy. Experimental results show that the learning rate is the most significant parameter in terms of the SN ratio. The proposed method has a general applicability and can be used to alleviate the burden of selecting appropriate ANN parameter values.","",""
154,"Oriol Vinyals, Suman V. Ravuri, Daniel Povey","Revisiting Recurrent Neural Networks for robust ASR",2012,"","","","",123,"2022-07-13 10:10:34","","10.1109/ICASSP.2012.6288816","","",,,,,154,15.40,51,3,10,"In this paper, we show how new training principles and optimization techniques for neural networks can be used for different network structures. In particular, we revisit the Recurrent Neural Network (RNN), which explicitly models the Markovian dynamics of a set of observations through a non-linear function with a much larger hidden state space than traditional sequence models such as an HMM. We apply pretraining principles used for Deep Neural Networks (DNNs) and second-order optimization techniques to train an RNN. Moreover, we explore its application in the Aurora2 speech recognition task under mismatched noise conditions using a Tandem approach. We observe top performance on clean speech, and under high noise conditions, compared to multi-layer perceptrons (MLPs) and DNNs, with the added benefit of being a “deeper” model than an MLP but more compact than a DNN.","",""
19,"Kou-Yuan Huang","Neural network for robust recognition of seismic patterns",2001,"","","","",124,"2022-07-13 10:10:34","","10.1109/IJCNN.2001.938843","","",,,,,19,0.90,19,1,21,"The multilayer perceptron is trained as a classifier and is applied to the recognition of seismic patterns. The principle of training the multilayer perceptron is described. Three classes of seismic patterns are analyzed in the experiment. Bright spot, pinch-out, and horizontal reflection patterns. Seven moments that are invariant to translation, rotation, and scale, are employed for feature generation of each seismic pattern. The training set includes noise-free, low-noise, and misclassified seismic patterns. The test set includes seismic patterns with various noise levels. The multilayer perceptron is initially trained with the training set of noise-free and low-noise seismic patterns. After convergence of the training, the network is applied to the classification of the test set of noisy seismic patterns. Some misclassified patterns with higher noise level are added to the training set for retraining. From experiments, the multilayer perceptron is shown to have the capability of robust recognition of seismic patterns.","",""
236,"Eric Arazo Sanchez, Diego Ortego, Paul Albert, N. O'Connor, Kevin McGuinness","Unsupervised label noise modeling and loss correction",2019,"","","","",125,"2022-07-13 10:10:34","","","","",,,,,236,78.67,47,5,3,"Despite being robust to small amounts of label noise, convolutional neural networks trained with stochastic gradient methods have been shown to easily fit random labels. When there are a mixture of correct and mislabelled targets, networks  tend to fit the former before the latter. This suggests using a suitable two-component mixture model as an unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled. Specifically, we propose a beta mixture to estimate this probability and correct the loss by relying on the network prediction (the so-called bootstrapping loss). We further adapt mixup augmentation to drive our approach a step further. Experiments on CIFAR-10/100 and TinyImageNet demonstrate a robustness to label noise that substantially outperforms recent state-of-the-art. Source code is available at https://git.io/fjsvE and Appendix at https://arxiv.org/abs/1904.11238.","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",126,"2022-07-13 10:10:34","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
18,"Florent Bocquelet, T. Hueber, Laurent Girin, P. Badin, B. Yvert","Robust articulatory speech synthesis using deep neural networks for BCI applications",2014,"","","","",127,"2022-07-13 10:10:34","","","","",,,,,18,2.25,4,5,8,"Brain-Computer Interfaces (BCIs) usually propose typing strategies to restore communication for paralyzed and aphasic people. A more natural way would be to use speech BCI directly controlling a speech synthesizer. Toward this goal, a prerequisite is the development a synthesizer that should i) produce intelligible speech, ii) run in real time, iii) depend on as few parameters as possible, and iv) be robust to error fluctuations on the control parameters. In this context, we describe here an articulatory-to-acoustic mapping approach based on deep neural network (DNN) trained on electromagnetic articulography (EMA) data recorded synchronously with produced speech sounds. On this corpus, the DNN-based model provided a speech synthesis quality (as assessed by automatic speech recognition and behavioral testing) comparable to a state-of-the-art Gaussian mixture model (GMM), yet showing higher robustness when noise was added to the EMA coordinates. Moreover, to envision BCI applications, this robustness was also assessed when the space covered by the 12 original articulatory parameters was reduced to 7 parameters using deep auto-encoders (DAE). Given that this method can be implemented in real time, DNN-based articulatory speech synthesis seems a good candidate for speech BCI applications. Index Terms: articulatory speech synthesis, brain computer interface (BCI), deep neural networks, deep auto-encoder, EMA, noise robustness, dimensionality reduction","",""
25,"H. Toutounji, G. Pipa","Spatiotemporal Computations of an Excitable and Plastic Brain: Neuronal Plasticity Leads to Noise-Robust and Noise-Constructive Computations",2014,"","","","",128,"2022-07-13 10:10:34","","10.1371/journal.pcbi.1003512","","",,,,,25,3.13,13,2,8,"It is a long-established fact that neuronal plasticity occupies the central role in generating neural function and computation. Nevertheless, no unifying account exists of how neurons in a recurrent cortical network learn to compute on temporally and spatially extended stimuli. However, these stimuli constitute the norm, rather than the exception, of the brain's input. Here, we introduce a geometric theory of learning spatiotemporal computations through neuronal plasticity. To that end, we rigorously formulate the problem of neural representations as a relation in space between stimulus-induced neural activity and the asymptotic dynamics of excitable cortical networks. Backed up by computer simulations and numerical analysis, we show that two canonical and widely spread forms of neuronal plasticity, that is, spike-timing-dependent synaptic plasticity and intrinsic plasticity, are both necessary for creating neural representations, such that these computations become realizable. Interestingly, the effects of these forms of plasticity on the emerging neural code relate to properties necessary for both combating and utilizing noise. The neural dynamics also exhibits features of the most likely stimulus in the network's spontaneous activity. These properties of the spatiotemporal neural code resulting from plasticity, having their grounding in nature, further consolidate the biological relevance of our findings.","",""
45,"F. Weninger, M. Wöllmer, Jürgen T. Geiger, Björn Schuller, J. Gemmeke, Antti Hurmalainen, T. Virtanen, G. Rigoll","Non-negative matrix factorization for highly noise-robust ASR: To enhance or to recognize?",2012,"","","","",129,"2022-07-13 10:10:34","","10.1109/ICASSP.2012.6288963","","",,,,,45,4.50,6,8,10,"This paper proposes a multi-stream speech recognition system that combines information from three complementary analysis methods in order to improve automatic speech recognition in highly noisy and reverberant environments, as featured in the 2011 PASCAL CHiME Challenge. We integrate word predictions by a bidirectional Long Short-Term Memory recurrent neural network and non-negative sparse classification (NSC) into a multi-stream Hidden Markov Model using convolutive non-negative matrix factorization (NMF) for speech enhancement. Our results suggest that NMF-based enhancement and NSC are complementary despite their overlap in methodology, reaching up to 91.9% average keyword accuracy on the Challenge test set at signal-to-noise ratios from -6 to 9 dB-the best result reported so far on these data.","",""
90,"Kaiqiang Wang, Ying Li, Qian Kemao, Jianglei Di, Jianlin Zhao","One-step robust deep learning phase unwrapping.",2019,"","","","",130,"2022-07-13 10:10:34","","10.1364/OE.27.015100","","",,,,,90,30.00,18,5,3,"Phase unwrapping is an important but challenging issue in phase measurement. Even with the research efforts of a few decades, unfortunately, the problem remains not well solved, especially when heavy noise and aliasing (undersampling) are present. We propose a database generation method for phase-type objects and a one-step deep learning phase unwrapping method. With a trained deep neural network, the unseen phase fields of living mouse osteoblasts and dynamic candle flame are successfully unwrapped, demonstrating that the complicated nonlinear phase unwrapping task can be directly fulfilled in one step by a single deep neural network. Excellent anti-noise and anti-aliasing performances outperforming classical methods are highlighted in this paper.","",""
17,"J. Schwabedal, A. Neiman, A. Shilnikov","Robust design of polyrhythmic neural circuits.",2014,"","","","",131,"2022-07-13 10:10:34","","10.1103/PHYSREVE.90.022715","","",,,,,17,2.13,6,3,8,"Neural circuit motifs producing coexistent rhythmic patterns are treated as building blocks of multifunctional neuronal networks. We study the robustness of such a motif of inhibitory model neurons to reliably sustain bursting polyrhythms under random perturbations. Without noise, the exponential stability of each of the coexisting rhythms increases with strengthened synaptic coupling, thus indicating an increased robustness. Conversely, after adding noise we find that noise-induced rhythm switching intensifies if the coupling strength is increased beyond a critical value, indicating a decreased robustness. We analyze this stochastic arrhythmia and develop a generic description of its dynamic mechanism. Based on our mechanistic insight, we show how physiological parameters of neuronal dynamics and network coupling can be balanced to enhance rhythm robustness against noise. Our findings are applicable to a broad class of relaxation-oscillator networks, including Fitzhugh-Nagumo and other Hodgkin-Huxley-type networks.","",""
120,"Soumitro Chakrabarty, E. Habets","Multi-Speaker DOA Estimation Using Deep Convolutional Networks Trained With Noise Signals",2018,"","","","",132,"2022-07-13 10:10:34","","10.1109/JSTSP.2019.2901664","","",,,,,120,30.00,60,2,4,"Supervised learning-based methods for source localization, being data driven, can be adapted to different acoustic conditions via training and have been shown to be robust to adverse acoustic environments. In this paper, a convolutional neural network (CNN) based supervised learning method for estimating the direction of arrival (DOA) of multiple speakers is proposed. Multi-speaker DOA estimation is formulated as a multi-class multi-label classification problem, where the assignment of each DOA label to the input feature is treated as a separate binary classification problem. The phase component of the short-time Fourier transform (STFT) coefficients of the received microphone signals are directly fed into the CNN, and the features for DOA estimation are learnt during training. Utilizing the assumption of disjoint speaker activity in the STFT domain, a novel method is proposed to train the CNN with synthesized noise signals. Through experimental evaluation with both simulated and measured acoustic impulse responses, the ability of the proposed DOA estimation approach to adapt to unseen acoustic conditions and its robustness to unseen noise type is demonstrated. Through additional empirical investigation, it is also shown that with an array of M microphone our proposed framework yields the best localization performance with M-1 convolution layers. The ability of the proposed method to accurately localize speakers in a dynamic acoustic scenario with varying number of sources is also shown.","",""
17,"Runzhong Wang, Junchi Yan, Xiaokang Yang","Combinatorial Learning of Robust Deep Graph Matching: an Embedding based Approach.",2020,"","","","",133,"2022-07-13 10:10:34","","10.1109/tpami.2020.3005590","","",,,,,17,8.50,6,3,2,"Graph matching aims to establish node correspondence between two graphs, which has been a fundamental problem for its NP-complete nature. One practical consideration is the effective modeling of the affinity function in the presence of noise, such that the mathematically optimal matching result is also physically meaningful. This paper resorts to deep neural networks to learn the node and edge feature, as well as the affinity model for graph matching in an end-to-end fashion. The learning is supervised by combinatorial permutation loss over nodes. Specifically, the parameters belong to convolutional neural networks for image feature extraction, graph neural networks for node embedding that convert the structural (beyond second-order) information into node-wise features that leads to a linear assignment problem, as well as the affinity kernel between two graphs. Our approach enjoys flexibility in that the permutation loss is agnostic to the number of nodes, and the embedding model is shared among nodes such that the network can deal with varying numbers of nodes for both training and inference. Moreover, our network is class-agnostic. Experimental results on extensive benchmarks show its state-of-the-art performance. It bears some generalization capability across categories and datasets, and is capable for robust matching against outliers.","",""
536,"Andreas Eitel, Jost Tobias Springenberg, Luciano Spinello, Martin A. Riedmiller, W. Burgard","Multimodal deep learning for robust RGB-D object recognition",2015,"","","","",134,"2022-07-13 10:10:34","","10.1109/IROS.2015.7353446","","",,,,,536,76.57,107,5,7,"Robust object recognition is a crucial ingredient of many, if not all, real-world robotics applications. This paper leverages recent progress on Convolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture for object recognition. Our architecture is composed of two separate CNN processing streams - one for each modality - which are consecutively combined with a late fusion network. We focus on learning with imperfect sensor data, a typical problem in real-world robotics tasks. For accurate learning, we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs. The first, an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets. The second, a data augmentation scheme for robust learning with depth images by corrupting them with realistic noise patterns. We present state-of-the-art results on the RGB-D object dataset [15] and show recognition in challenging RGB-D real-world noisy settings.","",""
3685,"Djork-Arné Clevert, Thomas Unterthiner, S. Hochreiter","Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)",2015,"","","","",135,"2022-07-13 10:10:34","","","","",,,,,3685,526.43,1228,3,7,"We introduce the ""exponential linear unit"" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network.","",""
60,"Huaxia Wang, Chun-Nam Yu","A Direct Approach to Robust Deep Learning Using Adversarial Networks",2019,"","","","",136,"2022-07-13 10:10:34","","","","",,,,,60,20.00,30,2,3,"Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans. Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs. Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network (GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent.","",""
13,"Jisoo Lee, Sae-Young Chung","Robust Training with Ensemble Consensus",2019,"","","","",137,"2022-07-13 10:10:34","","","","",,,,,13,4.33,7,2,3,"Since deep neural networks are over-parametrized, they may memorize noisy examples. We address such memorizing issue under the existence of annotation noise. From the fact that deep neural networks cannot generalize neighborhoods of the features acquired via memorization, we find that noisy examples do not consistently incur small losses on the network in the presence of perturbation. Based on this, we propose a novel training method called Learning with Ensemble Consensus (LEC) whose goal is to prevent overfitting noisy examples by eliminating them identified via consensus of an ensemble of perturbed networks. One of the proposed LECs, LTEC outperforms the current state-of-the-art methods on MNIST, CIFAR-10, and CIFAR-100 despite its efficient memory.","",""
47,"Artem Molchanov, Tao Chen, Wolfgang Hönig, James A. Preiss, Nora Ayanian, G. Sukhatme","Sim-to-(Multi)-Real: Transfer of Low-Level Robust Control Policies to Multiple Quadrotors",2019,"","","","",138,"2022-07-13 10:10:34","","10.1109/IROS40897.2019.8967695","","",,,,,47,15.67,8,6,3,"Quadrotor stabilizing controllers often require careful, model-specific tuning for safe operation. We use reinforcement learning to train policies in simulation that transfer remarkably well to multiple different physical quadrotors. Our policies are low-level, i.e., we map the rotorcrafts’ state directly to the motor outputs. The trained control policies are very robust to external disturbances and can withstand harsh initial conditions such as throws. We show how different training methodologies (change of the cost function, modeling of noise, use of domain randomization) might affect flight performance. To the best of our knowledge, this is the first work that demonstrates that a simple neural network can learn a robust stabilizing low-level quadrotor controller (without the use of a stabilizing PD controller) that is shown to generalize to multiple quadrotors. The video of our experiments can be found at https://sites.google.com/view/sim-to-multi-quad.","",""
173,"M. Efe","Neural Network Assisted Computationally Simple PI$^\lambda$D$^\mu$ Control of a Quadrotor UAV",2011,"","","","",139,"2022-07-13 10:10:34","","10.1109/TII.2011.2123906","","",,,,,173,15.73,173,1,11,"The applications of Unmanned Aerial Vehicles (UAVs) require robust control schemes that can alleviate disturbances such as model mismatch, wind disturbances, measurement noise, and the effects of changing electrical variables, e.g., the loss in the battery voltage. Proportional Integral and Derivative (PID) type controller with noninteger order derivative and integration is proposed as a remedy. This paper demonstrates that a neural network can be trained to provide the coefficients of a Finite Impulse Response (FIR) type approximator, that approximates to the response of a given analog PIλDμ controller having time varying action coefficients and differintegration orders. The results obtained show that the neural network aided FIR type controller is very successful in driving the vehicle to prescribed trajectories accurately. The response of the proposed scheme is highly similar to the response of the target PIλDμ controller and the computational burden of the proposed scheme is very low.","",""
682,"Scott E. Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, D. Erhan, Andrew Rabinovich","Training Deep Neural Networks on Noisy Labels with Bootstrapping",2014,"","","","",140,"2022-07-13 10:10:34","","","","",,,,,682,85.25,114,6,8,"Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-the- art results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.","",""
18,"Kun Han, Deliang Wang","Neural networks for supervised pitch tracking in noise",2014,"","","","",141,"2022-07-13 10:10:34","","10.1109/ICASSP.2014.6853845","","",,,,,18,2.25,9,2,8,"Determination of pitch in noise is challenging because of corrupted harmonic structure. In this paper, we extract pitch using supervised learning, where probabilistic pitch states are directly learned from noisy speech. We investigate two alternative neural networks modeling the pitch states given observations. The first one is the feedforward deep neural network (DNN), which is trained on static frame-level features. The second one is the recurrent deep neural network (RNN) capable of learning the temporal dynamics trained on sequential frame-level features. Both DNNs and RNNs produce accurate probabilistic outputs of pitch states, which are then connected into pitch contours by Viterbi decoding. Our systematic evaluation shows that the proposed pitch tracking approaches are robust to different noise conditions and significantly outperform current state-of-the-art pitch tracking techniques.","",""
17,"Ying Zhu, Grace Li Zhang, Tianchen Wang, Bing Li, Yiyu Shi, Tsung-Yi Ho, Ulf Schlichtmann","Statistical Training for Neuromorphic Computing using Memristor-based Crossbars Considering Process Variations and Noise",2020,"","","","",142,"2022-07-13 10:10:34","","10.23919/DATE48585.2020.9116244","","",,,,,17,8.50,2,7,2,"Memristor-based crossbars are an attractive platform to accelerate neuromorphic computing. However, process variations during manufacturing and noise in memristors cause significant accuracy loss if not addressed. In this paper, we propose to model process variations and noise as correlated random variables and incorporate them into the cost function during training. Consequently, the weights after this statistical training become more robust and together with global variation compensation provide a stable inference accuracy. Simulation results demonstrate that the mean value and the standard deviation of the inference accuracy can be improved significantly, by even up to 54% and 31%, respectively, in a two-layer fully connected neural network.","",""
170,"Ron Banner, Itay Hubara, Elad Hoffer, Daniel Soudry","Scalable Methods for 8-bit Training of Neural Networks",2018,"","","","",143,"2022-07-13 10:10:34","","","","",,,,,170,42.50,43,4,4,"Quantized Neural Networks (QNNs) are often used to improve network efficiency during the inference phase, i.e. after the network has been trained. Extensive research in the field suggests many different quantization schemes. Still, the number of bits required, as well as the best quantization scheme, are yet unknown. Our theoretical analysis suggests that most of the training process is robust to substantial precision reduction, and points to only a few specific operations that require higher precision. Armed with this knowledge, we quantize the model parameters, activations and layer gradients to 8-bit, leaving at a higher precision only the final step in the computation of the weight gradients. Additionally, as QNNs require batch-normalization to be trained at high precision, we introduce Range Batch-Normalization (BN) which has significantly higher tolerance to quantization noise and improved computational complexity. Our simulations show that Range BN is equivalent to the traditional batch norm if a precise scale adjustment, which can be approximated analytically, is applied. To the best of the authors' knowledge, this work is the first to quantize the weights, activations, as well as a substantial volume of the gradients stream, in all layers (including batch normalization) to 8-bit while showing state-of-the-art results over the ImageNet-1K dataset.","",""
11,"Chuteng Zhou, Prad Kadambi, Matthew Mattina, P. Whatmough","Noisy Machines: Understanding Noisy Neural Networks and Enhancing Robustness to Analog Hardware Errors Using Distillation",2020,"","","","",144,"2022-07-13 10:10:34","","","","",,,,,11,5.50,3,4,2,"The success of deep learning has brought forth a wave of interest in computer hardware design to better meet the high demands of neural network inference. In particular, analog computing hardware has been heavily motivated specifically for accelerating neural networks, based on either electronic, optical or photonic devices, which may well achieve lower power consumption than conventional digital electronics. However, these proposed analog accelerators suffer from the intrinsic noise generated by their physical components, which makes it challenging to achieve high accuracy on deep neural networks. Hence, for successful deployment on analog accelerators, it is essential to be able to train deep neural networks to be robust to random continuous noise in the network weights, which is a somewhat new challenge in machine learning. In this paper, we advance the understanding of noisy neural networks. We outline how a noisy neural network has reduced learning capacity as a result of loss of mutual information between its input and output. To combat this, we propose using knowledge distillation combined with noise injection during training to achieve more noise robust networks, which is demonstrated experimentally across different networks and datasets, including ImageNet. Our method achieves models with as much as two times greater noise tolerance compared with the previous best attempts, which is a significant step towards making analog hardware practical for deep learning.","",""
38,"Teng Zhang, Shaowei Jiang, Zixin Zhao, Krishna Dixit, Xiaofei Zhou, J. Hou, Yongbing Zhang, C. Yan","Rapid and robust two-dimensional phase unwrapping via deep learning.",2019,"","","","",145,"2022-07-13 10:10:34","","10.1364/OE.27.023173","","",,,,,38,12.67,5,8,3,"Two-dimensional phase unwrapping algorithms are widely used in optical metrology and measurements. The high noise from interference measurements, however, often leads to the failure of conventional phase unwrapping algorithms. In this paper, we propose a deep convolutional neural network (DCNN) based method to perform rapid and robust two-dimensional phase unwrapping. In our approach, we employ a DCNN architecture, DeepLabV3+, with noise suppression and strong feature representation capabilities. The employed DCNN is first used to perform semantic segmentation to obtain the segmentation result of the wrapped phase map. We then combine the wrapped phase map with the segmentation result to generate the unwrapped phase. We benchmarked our results by comparing them with well-established methods. The reported approach out-performed the conventional path-dependent and path-independent algorithms. We also tested the robustness of the reported approach using interference measurements from optical metrology setups. Our results, again, clearly out-performed the conventional phase unwrap algorithms. The reported approach may find applications in optical metrology and microscopy imaging.","",""
469,"P. Bashivan, I. Rish, M. Yeasin, N. Codella","Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks",2015,"","","","",146,"2022-07-13 10:10:34","","","","",,,,,469,67.00,117,4,7,"One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter- and intra-subject differences, as well as to inherent noise associated with such data. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification to learn robust representations from the sequence of images. The proposed approach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.","",""
39,"Yi Lu, Hong Guo, L. Feldkamp","Robust neural learning from unbalanced data samples",1998,"","","","",147,"2022-07-13 10:10:34","","10.1109/IJCNN.1998.687133","","",,,,,39,1.63,13,3,24,"This paper describes the result of our study on neural learning to solve the classification problem in which the data is unbalanced and noisy. Our study was conducted on three different neural network architectures, multilayered back propagation, radial basis function, and fuzzy ARTMAP with training methods including duplicating minority class samples and the Snowball technique. Three major issues are addressed: neural learning from unbalanced data samples, neural learning from noise data, and making intentional biased decisions. The application considered in this study is classifying good(pass)/bad(fail) vehicles. Experiments are conducted on data samples downloaded directly from test sites of automobile assembly.","",""
38,"Donghan Lee, Jeong-ho Kim, Dae-woo Lee","Robust Concrete Crack Detection Using Deep Learning-Based Semantic Segmentation",2019,"","","","",148,"2022-07-13 10:10:34","","10.1007/S42405-018-0120-5","","",,,,,38,12.67,13,3,3,"","",""
38,"T. Guo, Lianping Wu, Cunjun Wang, Zili Xu","Damage detection in a novel deep-learning framework: a robust method for feature extraction",2020,"","","","",149,"2022-07-13 10:10:34","","10.1177/1475921719846051","","",,,,,38,19.00,10,4,2,"Extracting damage features precisely while overcoming the adverse interferences of measurement noise and incomplete data is a problem demanding prompt solution in structural health monitoring (SHM). In this article, we present a deep-learning-based method that can extract the damage features from mode shapes without utilizing any hand-engineered feature or prior knowledge. To meet various requirements of the damage scenarios, we use convolutional neural network (CNN) algorithm and design a new network architecture: a multi-scale module, which helps in extracting features at various scales that can reduce the interference of contaminated data; stacked residual learning modules, which help in accelerating the network convergence; and a global average pooling layer, which helps in reducing the consumption of computing resources and obtaining a regression performance. An extensive evaluation of the proposed method is conducted by using datasets based on numerical simulations, along with two datasets based on laboratory measurements. The transferring parameter methodology is introduced to reduce retraining requirement without any decreases in precision. Furthermore, we plot the feature vectors of each layer to discuss the damage features learned at these layers and additionally provide the basis for explaining the working principle of the neural network. The results show that our proposed method has accuracy improvements of at least 10% over other network architectures.","",""
72,"Jinchi Huang, Lie Qu, Rongfei Jia, Binqiang Zhao","O2U-Net: A Simple Noisy Label Detection Approach for Deep Neural Networks",2019,"","","","",150,"2022-07-13 10:10:34","","10.1109/ICCV.2019.00342","","",,,,,72,24.00,18,4,3,"This paper proposes a novel noisy label detection approach, named O2U-net, for deep neural networks without human annotations. Different from prior work which requires specifically designed noise-robust loss functions or networks, O2U-net is easy to implement but effective. It only requires adjusting the hyper-parameters of the deep network to make its status transfer from overfitting to underfitting (O2U) cyclically. The losses of each sample are recorded during iterations. The higher the normalized average loss of a sample, the higher the probability of being noisy labels. O2U-net is naturally compatible with active learning and other human annotation approaches. This introduces extra flexibility for learning with noisy labels. We conduct sufficient experiments on multiple datasets in various settings. The experimental results prove the state-of-the-art of O2S-net.","",""
16,"Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah Hanif, M. Martina, M. Shafique","Is Spiking Secure? A Comparative Study on the Security Vulnerabilities of Spiking and Deep Neural Networks",2019,"","","","",151,"2022-07-13 10:10:34","","10.1109/IJCNN48605.2020.9207297","","",,,,,16,5.33,3,6,3,"Spiking Neural Networks (SNNs) claim to present many advantages in terms of biological plausibility and energy efficiency compared to standard Deep Neural Networks (DNNs). Recent works have shown that DNNs are vulnerable to adversarial attacks, i.e., small perturbations added to the input data can lead to targeted or random misclassifications. In this paper, we aim at investigating the key research question: ""Are SNNs secure?"" Towards this, we perform a comparative study of the security vulnerabilities in SNNs and DNNs w.r.t. the adversarial noise. Afterwards, we propose a novel black-box attack methodology, i.e., without the knowledge of the internal structure of the SNN, which employs a greedy heuristic to automatically generate imperceptible and robust adversarial examples (i.e., attack images) for the given SNN. We perform an in-depth evaluation for a Spiking Deep Belief Network (SDBN) and a DNN having the same number of layers and neurons (to obtain a fair comparison), in order to study the efficiency of our methodology and to understand the differences between SNNs and DNNs w.r.t. the adversarial examples. Our work opens new avenues of research towards the robustness of the SNNs, considering their similarities to the human brain's functionality.","",""
38,"Vincent Lostanlen, J. Salamon, A. Farnsworth, S. Kelling, J. Bello","Robust sound event detection in bioacoustic sensor networks",2019,"","","","",152,"2022-07-13 10:10:34","","10.1371/journal.pone.0214168","","",,,,,38,12.67,8,5,3,"Bioacoustic sensors, sometimes known as autonomous recording units (ARUs), can record sounds of wildlife over long periods of time in scalable and minimally invasive ways. Deriving per-species abundance estimates from these sensors requires detection, classification, and quantification of animal vocalizations as individual acoustic events. Yet, variability in ambient noise, both over time and across sensors, hinders the reliability of current automated systems for sound event detection (SED), such as convolutional neural networks (CNN) in the time-frequency domain. In this article, we develop, benchmark, and combine several machine listening techniques to improve the generalizability of SED models across heterogeneous acoustic environments. As a case study, we consider the problem of detecting avian flight calls from a ten-hour recording of nocturnal bird migration, recorded by a network of six ARUs in the presence of heterogeneous background noise. Starting from a CNN yielding state-of-the-art accuracy on this task, we introduce two noise adaptation techniques, respectively integrating short-term (60 ms) and long-term (30 min) context. First, we apply per-channel energy normalization (PCEN) in the time-frequency domain, which applies short-term automatic gain control to every subband in the mel-frequency spectrogram. Secondly, we replace the last dense layer in the network by a context-adaptive neural network (CA-NN) layer, i.e. an affine layer whose weights are dynamically adapted at prediction time by an auxiliary network taking long-term summary statistics of spectrotemporal features as input. We show that PCEN reduces temporal overfitting across dawn vs. dusk audio clips whereas context adaptation on PCEN-based summary statistics reduces spatial overfitting across sensor locations. Moreover, combining them yields state-of-the-art results that are unmatched by artificial data augmentation alone. We release a pre-trained version of our best performing system under the name of BirdVoxDetect, a ready-to-use detector of avian flight calls in field recordings.","",""
49,"Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan, Sewoong Oh, P. Viswanath","LEARN Codes: Inventing Low-Latency Codes via Recurrent Neural Networks",2018,"","","","",153,"2022-07-13 10:10:34","","10.1109/ICC.2019.8761286","","",,,,,49,12.25,8,6,4,"Designing channel codes under low latency constraints is one of the most demanding requirements in 5G standards. However, sharp characterizations of the performances of traditional codes are only available in the large block lengths limit. Code designs are guided by those asymptotic analyses and require large block lengths and long latency to achieve the desired error rate. Furthermore, when the codes designed for one channel (e.g. Additive White Gaussian Noise (AWGN) channel) are used for another (e.g. non-AWGN channels), heuristics are necessary to achieve any non trivial performance — thereby severely lacking in robustness as well as adaptivity. Obtained by jointly designing recurrent neural network (RNN) based encoder and decoder, we propose an end-to-end learned neural code which outperforms canonical convolutional code under block settings. With this gained experience of designing a novel neural block code, we propose a new class of codes under low latency constraint — Low-latency Efficient Adaptive Robust Neural (LEARN) codes, which outperform the state-of-the-art low latency codes as well as exhibit robustness and adaptivity properties. LEARN codes show the potential of designing new versatile and universal codes for future communications via tools of modern deep learning coupled with communication engineering insights.","",""
19,"Zihan Wang, Z. Ren, Chunyu He, Peng Zhang, Yue Hu","Robust Embedding with Multi-Level Structures for Link Prediction",2019,"","","","",154,"2022-07-13 10:10:34","","10.24963/ijcai.2019/728","","",,,,,19,6.33,4,5,3,"Knowledge Graph (KG) embedding has become crucial for the task of link prediction. Recent work applies encoder-decoder models to tackle this problem, where an encoder is formulated as a graph neural network (GNN) and a decoder is represented by an embedding method. These approaches enforce embedding techniques with structure information. Unfortunately, existing GNN-based frameworks still confront 3 severe problems: low representational power, stacking in a flat way, and poor robustness to noise. In this work, we propose a novel multi-level graph neural network (M-GNN) to address the above challenges. We first identify an injective aggregate scheme and design a powerful GNN layer using multi-layer perceptrons (MLPs). Then, we define graph coarsening schemes for various kinds of relations, and stack GNN layers on a series of coarsened graphs, so as to model hierarchical structures. Furthermore, attention mechanisms are adopted so that our approach can make predictions accurately even on the noisy knowledge graph. Results on WN18 and FB15k datasets show that our approach is effective in the standard link prediction task, significantly and consistently outperforming competitive baselines. Furthermore, robustness analysis on FB15k-237 dataset demonstrates that our proposed M-GNN is highly robust to sparsity and noise. ","",""
32,"T. Chuah, B. Sharif, O. Hinton","Robust adaptive spread-spectrum receiver with neural net preprocessing in non-Gaussian noise",2001,"","","","",155,"2022-07-13 10:10:34","","10.1109/72.925557","","",,,,,32,1.52,11,3,21,"Multiuser communications channels based on code division multiple access (CDMA) technique exhibit non-Gaussian statistics due to the presence of highly structured multiple access interference (MAI) and impulsive ambient noise. Linear adaptive interference suppression techniques are attractive for mitigating MAI under Gaussian noise. However, the Gaussian noise hypothesis has been found inadequate in many wireless channels characterized by impulsive disturbance. Linear finite impulse response (FIR) filters adapted with linear algorithms are limited by their structural formulation as a simple linear combiner with a hyperplanar decision boundary, which are extremely vulnerable to impulsive interference. This raises the issues of devising robust reception algorithms accounting at the design stage the non-Gaussian behavior of the interference. We propose a multiuser receiver that involves an adaptive nonlinear preprocessing front-end based on a multilayer perceptron neural network, which acts as a mechanism to reduce the influence of impulsive noise followed by a postprocessing stage using linear adaptive filters for MAI suppression. Theoretical arguments supported by promising simulation results suggest that the proposed receiver, which combines the relative merits of both nonlinear and linear signal processing, presents an effective approach for joint suppression of MAI and non-Gaussian ambient noise.","",""
64,"Mark D. Skowronski, J. Harris","Noise-Robust Automatic Speech Recognition Using a Predictive Echo State Network",2007,"","","","",156,"2022-07-13 10:10:34","","10.1109/TASL.2007.896669","","",,,,,64,4.27,32,2,15,"Artificial neural networks have been shown to perform well in automatic speech recognition (ASR) tasks, although their complexity and excessive computational costs have limited their use. Recently, a recurrent neural network with simplified training, the echo state network (ESN), was introduced by Jaeger and shown to outperform conventional methods in time series prediction experiments. We created the predictive ESN classifier by combining the ESN with a state machine framework. In small-vocabulary ASR experiments, we compared the noise-robust performance of the predictive ESN classifier with a hidden Markov model (HMM) as a function of model size and signal-to-noise ratio (SNR). The predictive ESN classifier outperformed an HMM by 8-dB SNR, and both models achieved maximum noise-robust accuracy for architectures with more states and fewer kernels per state. Using ten trials of random sets of training/validation/test speakers, accuracy for the predictive ESN classifier, averaged between 0 and 20 dB SNR, was 81plusmn3%, compared to 61plusmn2% for an HMM. The closed-form regression training for the ESN significantly reduced the computational cost of the network, and the reservoir of the ESN created a high-dimensional representation of the input with memory which led to increased noise-robust classification.","",""
22,"L. Barbier, G. Chollet","Robust speech parameters extraction for word recognition in noise using neural networks",1991,"","","","",157,"2022-07-13 10:10:34","","10.1109/ICASSP.1991.150298","","",,,,,22,0.71,11,2,31,"An attempt was made to enhance the performance of a DTW (dynamic time warping) speech recognizer by preprocessing speech parameters using a neural network transformation. A multilayer perceptron trained with speech utterances of a single speaker has been used in front of a DTW recognizer. Results show an improvement of about 15% in the recognition rate in all cases, even with a speaker that was not used for training. If the network is not completely speaker independent, a dynamic adaptation to the speaker could be performed.<<ETX>>","",""
69,"V. Mitra, Hosung Nam, C. Espy-Wilson, E. Saltzman, L. Goldstein","Articulatory Information for Noise Robust Speech Recognition",2011,"","","","",158,"2022-07-13 10:10:34","","10.1109/TASL.2010.2103058","","",,,,,69,6.27,14,5,11,"Prior research has shown that articulatory information, if extracted properly from the speech signal, can improve the performance of automatic speech recognition systems. However, such information is not readily available in the signal. The challenge posed by the estimation of articulatory information from speech acoustics has led to a new line of research known as “acoustic-to-articulatory inversion” or “speech-inversion.” While most of the research in this area has focused on estimating articulatory information more accurately, few have explored ways to apply this information in speech recognition tasks. In this paper, we first estimated articulatory information in the form of vocal tract constriction variables (abbreviated as TVs) from the Aurora-2 speech corpus using a neural network based speech-inversion model. Word recognition tasks were then performed for both noisy and clean speech using articulatory information in conjunction with traditional acoustic features. Our results indicate that incorporating TVs can significantly improve word recognition rates when used in conjunction with traditional acoustic features.","",""
15,"Mark D. Skowronski, J. Harris","Noise-robust automatic speech recognition using a discriminative echo state network",2007,"","","","",159,"2022-07-13 10:10:34","","10.1109/ISCAS.2007.378015","","",,,,,15,1.00,8,2,15,"The echo state network (ESN) is a recurrent neural network proposed by Herbert Jaeger with a simplified training routine. Previously, we have demonstrated the noise-robust performance of the predictive ESN classifier in automatic speech recognition experiments in which the network was trained to predict the next frame of speech features. Classification performance was limited because the predictive models lacked discriminability, so we changed the model output to a one-of-many output encoding scheme and trained the model discriminatively. Performance was compared to a hidden Markov model (HMM) in small-vocabulary ASR experiments with additive noise. Accuracy of 50% was achieved by a discriminative ESN classifier at -8.5 dB SNR, compared to 0.4 dB SNR for a predictive ESN classifier and 6.6 dB SNR for an HMM. With discriminative training, a larger reservoir was employed for the discriminative ESN classifier compared to the predictive ESN classifier which resulted a larger memory depth and more noise-robust performance.","",""
18,"A. Omidvar, H. Shahhoseini","Intelligent IP traffic matrix estimation by neural network and genetic algorithm",2011,"","","","",160,"2022-07-13 10:10:34","","10.1109/WISP.2011.6051689","","",,,,,18,1.64,9,2,11,"Rapid growth of computer network scales has made traffic matrix estimation essential in network management. It can be used in load balancing, traffic detecting and so on. Since traffic should be considered temporally and spatially, prediction is complicated. Tracking dynamic changes of traffic, reducing estimation errors and increasing robustness to noise are factors which should be considered in estimation. In this paper, we propose a novel method to estimate traffic matrix. This approach combines artificial neural network and evolutionary algorithms. It uses autoregressive model with exogenous inputs (ARX) joined with genetic algorithm (GA) which we call it ARXGEN. GA is used in gaining optimized weights and biases. To evaluate our method, we did our simulations on Abilene data. Results prove that it can well track dynamic nature of traffic and has lower estimation errors. It is also more robust to noise.","",""
130,"Ding Liu, Zhaowen Wang, B. Wen, Jianchao Yang, Wei Han, Thomas S. Huang","Robust Single Image Super-Resolution via Deep Networks With Sparse Prior",2016,"","","","",161,"2022-07-13 10:10:34","","10.1109/TIP.2016.2564643","","",,,,,130,21.67,22,6,6,"Single image super-resolution (SR) is an ill-posed problem, which tries to recover a high-resolution image from its low-resolution observation. To regularize the solution of the problem, previous methods have focused on designing good priors for natural images, such as sparse representation, or directly learning the priors from a large data set with models, such as deep neural networks. In this paper, we argue that domain expertise from the conventional sparse coding model can be combined with the key ingredients of deep learning to achieve further improved results. We demonstrate that a sparse coding model particularly designed for SR can be incarnated as a neural network with the merit of end-to-end optimization over training data. The network has a cascaded structure, which boosts the SR performance for both fixed and incremental scaling factors. The proposed training and testing schemes can be extended for robust handling of images with additional degradation, such as noise and blurring. A subjective assessment is conducted and analyzed in order to thoroughly evaluate various SR techniques. Our proposed model is tested on a wide range of images, and it significantly outperforms the existing state-of-the-art methods for various scaling factors both quantitatively and perceptually.","",""
135,"Hanxi Li, Yi Li, F. Porikli","DeepTrack: Learning Discriminative Feature Representations Online for Robust Visual Tracking",2015,"","","","",162,"2022-07-13 10:10:34","","10.1109/TIP.2015.2510583","","",,,,,135,19.29,45,3,7,"Deep neural networks, albeit their great success on feature learning in various computer vision tasks, are usually considered as impractical for online visual tracking, because they require very long training time and a large number of training samples. In this paper, we present an efficient and very robust tracking algorithm using a single convolutional neural network (CNN) for learning effective feature representations of the target object in a purely online manner. Our contributions are multifold. First, we introduce a novel truncated structural loss function that maintains as many training samples as possible and reduces the risk of tracking error accumulation. Second, we enhance the ordinary stochastic gradient descent approach in CNN training with a robust sample selection mechanism. The sampling mechanism randomly generates positive and negative samples from different temporal distributions, which are generated by taking the temporal relations and label noise into account. Finally, a lazy yet effective updating scheme is designed for CNN training. Equipped with this novel updating algorithm, the CNN model is robust to some long-existing difficulties in visual tracking, such as occlusion or incorrect detections, without loss of the effective adaption for significant appearance changes. In the experiment, our CNN tracker outperforms all compared state-of-the-art methods on two recently proposed benchmarks, which in total involve over 60 video sequences. The remarkable performance improvement over the existing trackers illustrates the superiority of the feature representations, which are learned purely online via the proposed deep learning framework.","",""
25,"Ishan Jindal, Daniel Pressel, Brian Lester, M. Nokleby","An Effective Label Noise Model for DNN Text Classification",2019,"","","","",163,"2022-07-13 10:10:34","","10.18653/v1/N19-1328","","",,,,,25,8.33,6,4,3,"Because large, human-annotated datasets suffer from labeling errors, it is crucial to be able to train deep neural networks in the presence of label noise. While training image classification models with label noise have received much attention, training text classification models have not. In this paper, we propose an approach to training deep networks that is robust to label noise. This approach introduces a non-linear processing layer (noise model) that models the statistics of the label noise into a convolutional neural network (CNN) architecture. The noise model and the CNN weights are learned jointly from noisy training data, which prevents the model from overfitting to erroneous labels. Through extensive experiments on several text classification datasets, we show that this approach enables the CNN to learn better sentence representations and is robust even to extreme label noise. We find that proper initialization and regularization of this noise model is critical. Further, by contrast to results focusing on large batch sizes for mitigating label noise for image classification, we find that altering the batch size does not have much effect on classification performance.","",""
44,"Sining Sun, Ching-feng Yeh, Mari Ostendorf, M. Hwang, Lei Xie","Training Augmentation with Adversarial Examples for Robust Speech Recognition",2018,"","","","",164,"2022-07-13 10:10:34","","10.21437/Interspeech.2018-1247","","",,,,,44,11.00,9,5,4,"This paper explores the use of adversarial examples in training speech recognition systems to increase robustness of deep neural network acoustic models. During training, the fast gradient sign method is used to generate adversarial examples augmenting the original training data. Different from conventional data augmentation based on data transformations, the examples are dynamically generated based on current acoustic model parameters. We assess the impact of adversarial data augmentation in experiments on the Aurora-4 and CHiME-4 single-channel tasks, showing improved robustness against noise and channel variation. Further improvement is obtained when combining adversarial examples with teacher/student training, leading to a 23% relative word error rate reduction on Aurora-4.","",""
18,"Mihailo Isakov, V. Gadepally, K. Gettings, M. Kinsy","Survey of Attacks and Defenses on Edge-Deployed Neural Networks",2019,"","","","",165,"2022-07-13 10:10:34","","10.1109/HPEC.2019.8916519","","",,,,,18,6.00,5,4,3,"Deep Neural Network (DNN) workloads are quickly moving from datacenters onto edge devices, for latency, privacy, or energy reasons. While datacenter networks can be protected using conventional cybersecurity measures, edge neural networks bring a host of new security challenges. Unlike classic IoT applications, edge neural networks are typically very compute and memory intensive, their execution is data-independent, and they are robust to noise and faults. Neural network models may be very expensive to develop, and can potentially reveal information about the private data they were trained on, requiring special care in distribution. The hidden states and outputs of the network can also be used in reconstructing user inputs, potentially violating users’ privacy. Furthermore, neural networks are vulnerable to adversarial attacks, which may cause misclassifications and violate the integrity of the output. These properties add challenges when securing edge-deployed DNNs, requiring new considerations, threat models, priorities, and approaches in securely and privately deploying DNNs to the edge. In this work, we cover the landscape of attacks on, and defenses, of neural networks deployed in edge devices and provide a taxonomy of attacks and defenses targeting edge DNNs.","",""
25,"A. Rusiecki","Trimmed categorical cross‐entropy for deep learning with label noise",2019,"","","","",166,"2022-07-13 10:10:34","","10.1049/EL.2018.7980","","",,,,,25,8.33,25,1,3,"Deep learning methods are nowadays considered as state-of-the-art approach in many sophisticated problems, such as computer vision, speech understanding or natural language processing. However, their performance relies on the quality of large annotated datasets. If the data are not well-annotated and label noise occur, such data-driven models become less reliable. In this Letter, the authors present very simple way to make the training process robust to noisy labels. Without changing network architecture and learning algorithm, the authors apply modified error measure that improves network generalisation when trained with label noise. Preliminary results obtained for deep convolutional neural networks, trained with novel trimmed categorical cross-entropy loss function, revealed its improved robustness for several levels of label noise.","",""
72,"C. Modarres, N. Astorga, E. Droguett, V. Meruane","Convolutional neural networks for automated damage recognition and damage type identification",2018,"","","","",167,"2022-07-13 10:10:34","","10.1002/stc.2230","","",,,,,72,18.00,18,4,4,"Recurring expenses associated with preventative maintenance and inspection produce operational inefficiencies and unnecessary spending. Human inspectors may submit inaccurate damage assessments and physically inaccessible locations, like underground mining structures, and pose additional logistical challenges. Automated systems and computer vision can significantly reduce these challenges and streamline preventative maintenance and inspection. The authors propose a convolutional neural network (CNN)‐based approach to identify the presence and type of structural damage. CNN is a deep feed‐forward artificial neural network that utilizes learnable convolutional filters to identify distinguishing patterns present in images. CNN is invariant to image scale, location, and noise, which makes it robust to classify damage of different sizes or shapes. The proposed approach is validated with synthetic data of a composite sandwich panel with debonding damage, and crack damage recognition is demonstrated on real concrete bridge crack images. CNN outperforms several other machine learning algorithms in completing the same task. The authors conclude that CNN is an effective tool for the detection and type identification of damage.","",""
181,"H. Talebi, K. Khorasani, S. Tafazoli","A Recurrent Neural-Network-Based Sensor and Actuator Fault Detection and Isolation for Nonlinear Systems With Application to the Satellite's Attitude Control Subsystem",2009,"","","","",168,"2022-07-13 10:10:34","","10.1109/TNN.2008.2004373","","",,,,,181,13.92,60,3,13,"This paper presents a robust fault detection and isolation (FDI) scheme for a general class of nonlinear systems using a neural-network-based observer strategy. Both actuator and sensor faults are considered. The nonlinear system considered is subject to both state and sensor uncertainties and disturbances. Two recurrent neural networks are employed to identify general unknown actuator and sensor faults, respectively. The neural network weights are updated according to a modified backpropagation scheme. Unlike many previous methods developed in the literature, our proposed FDI scheme does not rely on availability of full state measurements. The stability of the overall FDI scheme in presence of unknown sensor and actuator faults as well as plant and sensor noise and uncertainties is shown by using the Lyapunov's direct method. The stability analysis developed requires no restrictive assumptions on the system and/or the FDI algorithm. Magnetorquer-type actuators and magnetometer-type sensors that are commonly employed in the attitude control subsystem (ACS) of low-Earth orbit (LEO) satellites for attitude determination and control are considered in our case studies. The effectiveness and capabilities of our proposed fault diagnosis strategy are demonstrated and validated through extensive simulation studies.","",""
127,"Hanxi Li, Yi Li, F. Porikli","DeepTrack: Learning Discriminative Feature Representations Online for Robust Visual Tracking.",2016,"","","","",169,"2022-07-13 10:10:34","","10.1109/TIP.2015.2510583","","",,,,,127,21.17,42,3,6,"Deep neural networks, albeit their great success on feature learning in various computer vision tasks, are usually considered as impractical for online visual tracking, because they require very long training time and a large number of training samples. In this paper, we present an efficient and very robust tracking algorithm using a single convolutional neural network (CNN) for learning effective feature representations of the target object in a purely online manner. Our contributions are multifold. First, we introduce a novel truncated structural loss function that maintains as many training samples as possible and reduces the risk of tracking error accumulation. Second, we enhance the ordinary stochastic gradient descent approach in CNN training with a robust sample selection mechanism. The sampling mechanism randomly generates positive and negative samples from different temporal distributions, which are generated by taking the temporal relations and label noise into account. Finally, a lazy yet effective updating scheme is designed for CNN training. Equipped with this novel updating algorithm, the CNN model is robust to some long-existing difficulties in visual tracking, such as occlusion or incorrect detections, without loss of the effective adaption for significant appearance changes. In the experiment, our CNN tracker outperforms all compared state-of-the-art methods on two recently proposed benchmarks, which in total involve over 60 video sequences. The remarkable performance improvement over the existing trackers illustrates the superiority of the feature representations, which are learned purely online via the proposed deep learning framework.","",""
75,"Guotai Wang, Wenqi Li, S. Ourselin, Tom Kamiel Magda Vercauteren","Automatic Brain Tumor Segmentation using Convolutional Neural Networks with Test-Time Augmentation",2018,"","","","",170,"2022-07-13 10:10:34","","10.1007/978-3-030-11726-9_6","","",,,,,75,18.75,19,4,4,"","",""
107,"Ding Liu, Zhaowen Wang, B. Wen, Jianchao Yang, Wei Han, Thomas S. Huang","Robust Single Image Super-Resolution via Deep Networks With Sparse Prior.",2016,"","","","",171,"2022-07-13 10:10:34","","10.1109/TIP.2016.2564643","","",,,,,107,17.83,18,6,6,"Single image super-resolution (SR) is an ill-posed problem, which tries to recover a high-resolution image from its low-resolution observation. To regularize the solution of the problem, previous methods have focused on designing good priors for natural images, such as sparse representation, or directly learning the priors from a large data set with models, such as deep neural networks. In this paper, we argue that domain expertise from the conventional sparse coding model can be combined with the key ingredients of deep learning to achieve further improved results. We demonstrate that a sparse coding model particularly designed for SR can be incarnated as a neural network with the merit of end-to-end optimization over training data. The network has a cascaded structure, which boosts the SR performance for both fixed and incremental scaling factors. The proposed training and testing schemes can be extended for robust handling of images with additional degradation, such as noise and blurring. A subjective assessment is conducted and analyzed in order to thoroughly evaluate various SR techniques. Our proposed model is tested on a wide range of images, and it significantly outperforms the existing state-of-the-art methods for various scaling factors both quantitatively and perceptually.","",""
38,"Gin-Der Wu, Chin-Teng Lin","A recurrent neural fuzzy network for word boundary detection in variable noise-level environments",2001,"","","","",172,"2022-07-13 10:10:34","","10.1109/3477.907566","","",,,,,38,1.81,19,2,21,"This paper discusses the problem of automatic word boundary detection in the presence of variable-level background noise. Commonly used robust word boundary detection algorithms always assume that the background noise level is fixed. In fact, the background noise level may vary during the procedure of recording. This is the major reason that most robust word boundary detection algorithms cannot work well in the condition of variable background noise level. In order to solve this problem, we first propose a refined time-frequency (RTF) parameter for extracting both the time and frequency features of noisy speech signals. The RTF parameter extends the (time-frequency) TF parameter proposed by Junqua et al. from single band to multiband spectrum analysis, where the frequency bands help to make the distinction between speech signal and noise clear. The RTF parameter can extract useful frequency information. Based on this RTF parameter, we further propose a new word boundary detection algorithm by using a recurrent self-organizing neural fuzzy inference network (RSONFIN). Since RSONPIN can process the temporal relations, the proposed RTF-based RSONFIN algorithm can find the variation of the background noise level and detect correct word boundaries in the condition of variable background noise level. As compared to normal neural networks, the RSONFIN can always find itself an economic network size with high-learning speed. Due to the self-learning ability of RSONFIN, this RTF-based RSONFIN algorithm avoids the need for empirically determining ambiguous decision rules in normal word boundary detection algorithms. Experimental results show that this new algorithm achieves higher recognition rate than the TF-based algorithm which has been shown to outperform several commonly used word boundary detection algorithms by about 12% in variable background noise level condition, It also reduces the recognition error rate due to endpoint detection to about 23%, compared to an average of 47% obtained by the TF-based algorithm in the same condition.","",""
20,"S. Furao, O. Hasegawa","Self-Organizing Incremental Neural Network and Its Application",2010,"","","","",173,"2022-07-13 10:10:34","","10.1007/978-3-642-15825-4_74","","",,,,,20,1.67,10,2,12,"","",""
56,"Akihito Sudo, Akihiro Sato, O. Hasegawa","Associative Memory for Online Learning in Noisy Environments Using Self-Organizing Incremental Neural Network",2009,"","","","",174,"2022-07-13 10:10:34","","10.1109/TNN.2009.2014374","","",,,,,56,4.31,19,3,13,"Associative memory operating in a real environment must perform well in online incremental learning and be robust to noisy data because noisy associative patterns are presented sequentially in a real environment. We propose a novel associative memory that satisfies these requirements. Using the proposed method, new associative pairs that are presented sequentially can be learned accurately without forgetting previously learned patterns. The memory size of the proposed method increases adaptively with learning patterns. Therefore, it suffers neither redundancy nor insufficiency of memory size, even in an environment in which the maximum number of associative pairs to be presented is unknown before learning. Noisy inputs in real environments are classifiable into two types: noise-added original patterns and faultily presented random patterns. The proposed method deals with two types of noise. To our knowledge, no conventional associative memory addresses noise of both types. The proposed associative memory performs as a bidirectional one-to-many or many-to-one associative memory and deals not only with bipolar data, but also with real-valued data. Results demonstrate that the proposed method's features are important for application to an intelligent robot operating in a real environment. The originality of our work consists of two points: employing a growing self-organizing network for an associative memory, and discussing what features are necessary for an associative memory for an intelligent robot and proposing an associative memory that satisfies those requirements.","",""
116,"S. Mousavi, Weiqiang Zhu, Y. Sheng, G. Beroza","CRED: A Deep Residual Network of Convolutional and Recurrent Units for Earthquake Signal Detection",2018,"","","","",175,"2022-07-13 10:10:34","","10.1038/s41598-019-45748-1","","",,,,,116,29.00,29,4,4,"","",""
98,"Zhong-Qiu Wang, Deliang Wang","A Joint Training Framework for Robust Automatic Speech Recognition",2016,"","","","",176,"2022-07-13 10:10:34","","10.1109/TASLP.2016.2528171","","",,,,,98,16.33,49,2,6,"Robustness against noise and reverberation is critical for ASR systems deployed in real-world environments. In robust ASR, corrupted speech is normally enhanced using speech separation or enhancement algorithms before recognition. This paper presents a novel joint training framework for speech separation and recognition. The key idea is to concatenate a deep neural network (DNN) based speech separation frontend and a DNN-based acoustic model to build a larger neural network, and jointly adjust the weights in each module. This way, the separation frontend is able to provide enhanced speech desired by the acoustic model and the acoustic model can guide the separation frontend to produce more discriminative enhancement. In addition, we apply sequence training to the jointly trained DNN so that the linguistic information contained in the acoustic and language models can be back-propagated to influence the separation frontend at the training stage. To further improve the robustness, we add more noise- and reverberation-robust features for acoustic modeling. At the test stage, utterance-level unsupervised adaptation is performed to adapt the jointly trained network by learning a linear transformation of the input of the separation frontend. The resulting sequence-discriminative jointly-trained multistream system with run-time adaptation achieves 10.63% average word error rate (WER) on the test set of the reverberant and noisy CHiME-2 dataset (task-2), which represents the best performance on this dataset and a 22.75% error reduction over the best existing method.","",""
44,"Yanhong Zhang","Blind watermark algorithm based on HVS and RBF neural network in DWT domain",2009,"","","","",177,"2022-07-13 10:10:34","","","","",,,,,44,3.38,44,1,13,"This paper proposes a new blind watermarking scheme based on discrete wavelet transform(DWT) domain. The method uses the HVS model, and radial basis function neural networks(RBF). RBF will be implemented while embedding and extracting watermark. The human visual system (HVS) model is used to determine the watermark insertion strength. The neural networks almost exactly recover the watermarking signals from the watermarked images after training and learning. The experimental results show that the watermark proposed in this paper is invisible (the PSNR is higher than 41) and is robust in the case of against some normal at tacks such as JPEG compression, additive noise and filtering, etc.","",""
47,"Björn Schuller, F. Weninger, M. Wöllmer, Yang Sun, G. Rigoll","Non-negative matrix factorization as noise-robust feature extractor for speech recognition",2010,"","","","",178,"2022-07-13 10:10:34","","10.1109/ICASSP.2010.5495567","","",,,,,47,3.92,9,5,12,"We introduce a novel approach for noise-robust feature extraction in speech recognition, based on non-negative matrix factorization (NMF). While NMF has previously been used for speech denoising and speaker separation, we directly extract time-varying features from the NMF output. To this end we extend basic unsupervised NMF to a hybrid supervised/unsupervised algorithm. We present a Dynamic Bayesian Network (DBN) architecture that can exploit these features in a Tandem manner together with the maximum likelihood phoneme estimate of a bidirectional long short-term memory (BLSTM) recurrent neural network. We show that addition of NMF features to spelling recognition systems can increase word accuracy by up to 7% absolute in a noisy car environment.","",""
45,"Peng Xu, Denilson Barbosa","Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss",2018,"","","","",179,"2022-07-13 10:10:34","","10.18653/v1/N18-1002","","",,,,,45,11.25,23,2,4,"The task of Fine-grained Entity Type Classification (FETC) consists of assigning types from a hierarchy to entity mentions in text. Existing methods rely on distant supervision and are thus susceptible to noisy labels that can be out-of-context or overly-specific for the training sentence. Previous methods that attempt to address these issues do so with heuristics or with the help of hand-crafted features. Instead, we propose an end-to-end solution with a neural network model that uses a variant of cross-entropy loss function to handle out-of-context labels, and hierarchical loss normalization to cope with overly-specific ones. Also, previous work solve FETC a multi-label classification followed by ad-hoc post-processing. In contrast, our solution is more elegant: we use public word embeddings to train a single-label that jointly learns representations for entity mentions and their context. We show experimentally that our approach is robust against noise and consistently outperforms the state-of-the-art on established benchmarks for the task.","",""
29,"Zhong-Qiu Wang, Deliang Wang","On Spatial Features for Supervised Speech Separation and its Application to Beamforming and Robust ASR",2018,"","","","",180,"2022-07-13 10:10:34","","10.1109/ICASSP.2018.8461816","","",,,,,29,7.25,15,2,4,"This study integrates complementary spectral and spatial information to elevate deep learning based time-frequency masking and acoustic beamforming. Coherence and directional features are designed as additional input features for deep neural network training to remove diffuse noise and other directional interferences pervasive in real-world recordings. The diffuse and directional features are designed to be relatively invariant to the underlying target direction, number of microphones and microphone geometry. The estimated masks are then utilized to compute steering vectors and spatial covariance matrices for beamforming and robust ASR. Experiments on the CHiME-4 dataset demonstrate the effectiveness of the proposed approach.","",""
63,"Zhong Meng, Shinji Watanabe, J. Hershey, Hakan Erdogan","Deep long short-term memory adaptive beamforming networks for multichannel robust speech recognition",2017,"","","","",181,"2022-07-13 10:10:34","","10.1109/ICASSP.2017.7952160","","",,,,,63,12.60,16,4,5,"Far-field speech recognition in noisy and reverberant conditions remains a challenging problem despite recent deep learning breakthroughs. This problem is commonly addressed by acquiring a speech signal from multiple microphones and performing beamforming over them. In this paper, we propose to use a recurrent neural network with long short-term memory (LSTM) architecture to adaptively estimate real-time beamforming filter coefficients to cope with non-stationary environmental noise and dynamic nature of source and microphones positions which results in a set of timevarying room impulse responses. The LSTM adaptive beamformer is jointly trained with a deep LSTM acoustic model to predict senone labels. Further, we use hidden units in the deep LSTM acoustic model to assist in predicting the beamforming filter coefficients. The proposed system achieves 7.97% absolute gain over baseline systems with no beamforming on CHiME-3 real evaluation set.","",""
10,"Yinxue Zhang, Xuemin Tian, Xiaogang Deng, Yuping Cao","Seismic denoising based on modified BP neural network",2010,"","","","",182,"2022-07-13 10:10:34","","10.1109/ICNC.2010.5584501","","",,,,,10,0.83,3,4,12,"A new method for seismic random noise reduction based on robust function and back propagation (BP) neural network is proposed in this paper. This method introduces BP neural network utilizing least mean log squares (LMLS) error function or least trimmed squares (LTS) estimator instead of least mean squares (LMS) error function as its error function. The proposed method can diminish the influence of random noise on the accuracy of BP neural network model and improve the denoising capability of neural network, obviously. Experimental results demonstrate that the proposed new method can reduce random noise on seismic data and preserve in-phase axes more effectively than some traditional denoising methods and generic BP neural network model.","",""
53,"Xueliang Zhang, Zhongqiu Wang, Deliang Wang","A speech enhancement algorithm by iterating single- and multi-microphone processing and its application to robust ASR",2017,"","","","",183,"2022-07-13 10:10:34","","10.1109/ICASSP.2017.7952161","","",,,,,53,10.60,18,3,5,"We propose a speech enhancement algorithm based on single- and multi-microphone processing techniques. The core of the algorithm estimates a time-frequency mask which represents the target speech and use masking-based beamforming to enhance corrupted speech. Specifically, in single-microphone processing, the received signals of a microphone array are treated as individual signals and we estimate a mask for the signal of each microphone using a deep neural network (DNN). With these masks, in multi-microphone processing, we calculate a spatial covariance matrix of noise and steering vector for beamforming. In addition, we propose a masking-based post-filter to further suppress the noise in the output of beamforming. Then, the enhanced speech is sent back to DNN for mask re-estimation. When these steps are iterated for a few times, we obtain the final enhanced speech. The proposed algorithm is evaluated as a frontend for automatic speech recognition (ASR) and achieves a 5.05% average word error rate (WER) on the real environment test set of CHiME-3, outperforming the current best algorithm by 13.34%.","",""
40,"Vanika Singhal, H. Aggarwal, Snigdha Tariyal, A. Majumdar","Discriminative Robust Deep Dictionary Learning for Hyperspectral Image Classification",2017,"","","","",184,"2022-07-13 10:10:34","","10.1109/TGRS.2017.2704590","","",,,,,40,8.00,10,4,5,"This paper proposes a new framework for deep learning that has been particularly tailored for hyperspectral image classification. We learn multiple levels of dictionaries in a robust fashion. The last layer is discriminative that learns a linear classifier. The training proceeds greedily; at a time, a single level of dictionary is learned and the coefficients used to train the next level. The coefficients from the final level are used for classification. Robustness is incorporated by minimizing the absolute deviations instead of the more popular Euclidean norm. The inbuilt robustness helps combat mixed noise (Gaussian and sparse) present in hyperspectral images. Results show that our proposed techniques outperform all other deep learning methods—deep belief network, stacked autoencoder, and convolutional neural network. The experiments have been carried out on both benchmark deep learning data sets (MNIST, CIFAR-10, and Street View House Numbers) as well as on real hyperspectral imaging data sets.","",""
14,"C. Hillar, N. Tran","Robust Exponential Memory in Hopfield Networks",2014,"","","","",185,"2022-07-13 10:10:34","","10.1186/s13408-017-0056-2","","",,,,,14,1.75,7,2,8,"","",""
128,"Zhuo Chen, Shinji Watanabe, Hakan Erdogan, J. Hershey","Speech enhancement and recognition using multi-task learning of long short-term memory recurrent neural networks",2015,"","","","",186,"2022-07-13 10:10:34","","","","",,,,,128,18.29,32,4,7,"Long Short-Term Memory (LSTM) recurrent neural network has  proven effective in modeling speech and has achieved outstanding  performance in both speech enhancement (SE) and automatic  speech recognition (ASR). To further improve the performance of  noise-robust speech recognition, a combination of speech enhancement  and recognition was shown to be promising in earlier work.  This paper aims to explore options for consistent integration of SE  and ASR using LSTM networks. Since SE and ASR have different  objective criteria, it is not clear what kind of integration would  finally lead to the best word error rate for noise-robust ASR tasks.  In this work, several integration architectures are proposed and  tested, including: (1) a pipeline architecture of LSTM-based SE and  ASR with sequence training, (2) an alternating estimation architecture,  and (3) a multi-task hybrid LSTM network architecture.  The proposed models were evaluated on the 2nd CHiME speech  separation and recognition challenge task, and show significant  improvements relative to prior results.","",""
232,"R. Laje, D. Buonomano","Complexity without chaos: Plasticity within random recurrent networks generates robust timing and motor control",2012,"","","","",187,"2022-07-13 10:10:34","","10.1038/nn.3405","","",,,,,232,23.20,116,2,10,"","",""
30,"Jorge Chang, Deliang Wang","Robust speaker recognition based on DNN/i-vectors and speech separation",2017,"","","","",188,"2022-07-13 10:10:34","","10.1109/ICASSP.2017.7953191","","",,,,,30,6.00,15,2,5,"Recent research shows that the i-vector framework for speaker recognition can significantly benefit from phonetic information. A common approach is to use a deep neural network (DNN) trained for automatic speech recognition to generate a universal background model (UBM). Studies in this area have been done in relatively clean conditions. However, strong background noise is known to severely reduce speaker recognition performance. This study investigates a phonetically-aware i-vector system in noisy conditions. We propose a front-end to tackle the noise problem by performing speech separation and examine its performance for both verification and identification tasks. The proposed separation system trains a DNN to estimate the ideal ratio mask of the noisy speech. The separated speech is then used to extract enhanced features for the i-vector framework. We compare the proposed system against a multi-condition trained baseline and a traditional GMM-UBM i-vector system. Our proposed system provides an absolute average improvement of 8% in identification accuracy and 1.2% in equal error rate.","",""
433,"S. Shen, W. Sandham, M. Granat, A. Sterr","MRI fuzzy segmentation of brain tissue using neighborhood attraction with neural-network optimization",2005,"","","","",189,"2022-07-13 10:10:34","","10.1109/TITB.2005.847500","","",,,,,433,25.47,108,4,17,"Image segmentation is an indispensable process in the visualization of human tissues, particularly during clinical analysis of magnetic resonance (MR) images. Unfortunately, MR images always contain a significant amount of noise caused by operator performance, equipment, and the environment, which can lead to serious inaccuracies with segmentation. A robust segmentation technique based on an extension to the traditional fuzzy c-means (FCM) clustering algorithm is proposed in this paper. A neighborhood attraction, which is dependent on the relative location and features of neighboring pixels, is shown to improve the segmentation performance dramatically. The degree of attraction is optimized by a neural-network model. Simulated and real brain MR images with different noise levels are segmented to demonstrate the superiority of the proposed technique compared to other FCM-based methods. This segmentation method is a key component of an MR image-based classification system for brain tumors, currently being developed.","",""
34,"Beijia Zhang, K. O'Neill, J. Kong, T. Grzegorczyk","Support Vector Machine and Neural Network Classification of Metallic Objects Using Coefficients of the Spheroidal MQS Response Modes",2008,"","","","",190,"2022-07-13 10:10:34","","10.1109/TGRS.2007.907972","","",,,,,34,2.43,9,4,14,"Two different supervised learning algorithms, support vector machine (SVM) and neural networks (NN), are applied in classifying metallic objects according to size using the expansion coefficients of their magneto-quasistatic response in the spheroidal coordinate system. The classified objects include homogeneous spheroids and composite metallic assemblages meant to resemble unexploded ordnance. An analytical model is used to generate the necessary training data for each learning method. SVM and NN are shown to be successful in classifying three different types of objects on the basis of size. They are capable of fast classification, making them suitable for real-time application. Furthermore, both methods are robust and have a good tolerance of 20-dB SNR additive Gaussian noise. SVM shows promise in dealing with noise due to uncertainty in the object's position and orientation.","",""
23,"M. Nentwig, Paolo Mercorelli","Throttle valve control using an inverse local linear model tree based on a fuzzy neural network",2008,"","","","",191,"2022-07-13 10:10:34","","10.1109/UKRICIS.2008.4798943","","",,,,,23,1.64,12,2,14,"A robust throttle valve control has always been an attractive problem since throttle by wire systems were established in the mid-nineties. Often in control strategy, a feedforward controller is adopted in which an inverse model is used. Mathematical inversions of models imply a high order of differentiation of the state variables and consequently noise effects. In general, neural networks are a very effective and popular tool mostly used for modeling. The inversion of a neural network produces real possibilities to involve the networks in the control problem schemes. This paper presents a control strategy based upon an inversion of a feed forward trained local linear model tree. The local linear model tree is realized through a fuzzy neural network. Simulated results from real data measurements are presented in which two control loops are explicitly compared.","",""
19,"Jegor Uglov, L. Jakaite, V. Schetinin, C. Maple","Comparing Robustness of Pairwise and Multiclass Neural-Network Systems for Face Recognition",2007,"","","","",192,"2022-07-13 10:10:34","","10.1155/2008/468693","","",,,,,19,1.27,5,4,15,"Noise, corruptions, and variations in face images can seriously hurt the performance of face-recognition systems. To make these systems robust to noise and corruptions in image data, multiclass neural networks capable of learning from noisy data have been suggested. However on large face datasets such systems cannot provide the robustness at a high level. In this paper, we explore a pairwise neural-network system as an alternative approach to improve the robustness of face recognition. In our experiments, the pairwise recognition system is shown to outperform the multiclass-recognition system in terms of the predictive accuracy on the test face images.","",""
20,"C. Maha, E. Maher, B. A. Chokri","A blind audio watermarking scheme based on neural network and psychoacoustic model with error correcting code in wavelet domain",2008,"","","","",193,"2022-07-13 10:10:34","","10.1109/ISCCSP.2008.4537396","","",,,,,20,1.43,7,3,14,"Audio watermarking is a method that embeds inaudible information into digital audio data. This paper proposes an audio watermarking technique for protecting audio copyrights based on human psychoacoustic model (HPM), discrete wavelet transform (DWT), neural network (NN) and error correcting code. Our technique exploits frequency perceptual masking studied in HPM to guarantee that the embedded watermark is inaudible. To assure watermark embedding and extraction, neural network is used to memorize the relationships between a Wavelet central sample and its neighbors. To increase robustness of the scheme, the watermark is refined by the Hamming error correcting code while the encoded mark is embedded as new watermark in the transformed audio signal. Our audio watermarking algorithm is robust to common audio signal manipulations like MP3 compression, noise addition, silence addition, bit per sample conversion, noise reduction, dynamic changes and Notch filtering. Furthermore, it allows blind retrieval of embedded watermark which does not need the original audio and makes the watermark perceptually inaudible.","",""
39,"A. Shahina, B. Yegnanarayana","Mapping Speech Spectra from Throat Microphone to Close-Speaking Microphone: A Neural Network Approach",2007,"","","","",194,"2022-07-13 10:10:34","","10.1155/2007/87219","","",,,,,39,2.60,20,2,15,"Speech recorded from a throat microphone is robust to the surrounding noise, but sounds unnatural unlike the speech recorded from a close-speaking microphone. This paper addresses the issue of improving the perceptual quality of the throat microphone speech by mapping the speech spectra from the throat microphone to the close-speaking microphone. A neural network model is used to capture the speaker-dependent functional relationship between the feature vectors (cepstral coefficients) of the two speech signals. A method is proposed to ensure the stability of the all-pole synthesis filter. Objective evaluations indicate the effectiveness of the proposed mapping scheme. The advantage of this method is that the model gives a smooth estimate of the spectra of the close-speaking microphone speech. No distortions are perceived in the reconstructed speech. This mapping technique is also used for bandwidth extension of telephone speech.","",""
45,"S. Barai, A. Dikshit, Sameer Sharma","Neural Network Models for Air Quality Prediction: A Comparative Study",2007,"","","","",195,"2022-07-13 10:10:34","","10.1007/978-3-540-70706-6_27","","",,,,,45,3.00,15,3,15,"","",""
49,"Takaaki Hori, Zhuo Chen, Hakan Erdogan, J. Hershey, Jonathan Le Roux, V. Mitra, Shinji Watanabe","The MERL/SRI system for the 3RD CHiME challenge using beamforming, robust feature extraction, and advanced speech recognition",2015,"","","","",196,"2022-07-13 10:10:34","","10.1109/ASRU.2015.7404833","","",,,,,49,7.00,7,7,7,"This paper introduces the MERL/SRI system designed for the 3rd CHiME speech separation and recognition challenge (CHiME-3). Our proposed system takes advantage of recurrent neural networks (RNNs) throughout the model from the front speech enhancement to the language modeling. Two different types of beamforming are used to combine multi-microphone signals to obtain a single higher quality signal. Beamformed signal is further processed by a single-channel bi-directional long short-term memory (LSTM) enhancement network which is used to extract stacked mel-frequency cepstral coefficients (MFCC) features. In addition, two proposed noise-robust feature extraction methods are used with the beamformed signal. The features are used for decoding in speech recognition systems with deep neural network (DNN) based acoustic models and large-scale RNN language models to achieve high recognition accuracy in noisy environments. Our training methodology includes data augmentation and speaker adaptive training, whereas at test time model combination is used to improve generalization. Results on the CHiME-3 benchmark show that the full cadre of techniques substantially reduced the word error rate (WER). Combining hypotheses from different robust-feature systems ultimately achieved 9.10% WER for the real test data, a 72.4% reduction relative to the baseline of 32.99% WER.","",""
92,"Xiaojia Zhao, Yuxuan Wang, Deliang Wang","Robust Speaker Identification in Noisy and Reverberant Conditions",2014,"","","","",197,"2022-07-13 10:10:34","","10.1109/TASLP.2014.2308398","","",,,,,92,11.50,31,3,8,"Robustness of speaker recognition systems is crucial for real-world applications, which typically contain both additive noise and room reverberation. However, the combined effects of additive noise and convolutive reverberation have been rarely studied in speaker identification (SID). This paper addresses this issue in two phases. We first remove background noise through binary masking using a deep neural network classifier. Then we perform robust SID with speaker models trained in selected reverberant conditions, on the basis of bounded marginalization and direct masking. Evaluation results show that the proposed system substantially improves SID performance over related systems in a wide range of reverberation time and signal-to-noise ratios.","",""
28,"R. Gandhiraj, P. S. Sathidevi","Auditory-Based Wavelet Packet Filterbank for Speech Recognition Using Neural Network",2007,"","","","",198,"2022-07-13 10:10:34","","10.1109/ADCOM.2007.47","","",,,,,28,1.87,14,2,15,"A major problem of most speech recognition systems is their unsatisfactory robustness in noise. Human inner ear based `feature extraction' leads to very robust speech understanding in noise. This `Model of Auditory Periphery' is acting as front-end model of this speech recognition process. This paper describes two quantitative models for signal processing in auditory system (i) Gamma Tone Filter Bank (GTFB) and (ii) Wavelet Packet (WP) as front- ends for robust speech recognition. The auditory feature vectors had been used to train neural network. The classification of the feature vectors was done by the neural network using Back Propagation (BP) algorithm. The system performance was measured by recognition rate with various signal-to- noise ratios over -10 to 10 dB. The proposed system's performance was compared with various types of front-ends and recognition methods such as auditory features with Hidden Markov Model (HMM) & Layered Neural Network (LRNN), auditory features with Mel Frequency Cepstral Coefficient (MFCC) & LRNN and vocal tract model: MFCC & HMM, Dynamic time warping (DTW). The performances of proposed models with gamma tone filter bank and wavelet packet as front-ends were also compared. It had been identified that proposed system with wavelet packet as front-end and Back Propagation Neural Network (BPNN) as the recognition method is having good recognition rate over -10 to 10 dB. Both speaker independent and speaker dependent recognition systems had been designed, implemented and tested. Key words: auditory-based, speech recognition, wavelet packet, neural network","",""
33,"Meiguang Jin, S. Roth, P. Favaro","Noise-Blind Image Deblurring",2017,"","","","",199,"2022-07-13 10:10:34","","10.1109/CVPR.2017.408","","",,,,,33,6.60,11,3,5,"We present a novel approach to noise-blind deblurring, the problem of deblurring an image with known blur, but unknown noise level. We introduce an efficient and robust solution based on a Bayesian framework using a smooth generalization of the 0-1 loss. A novel bound allows the calculation of very high-dimensional integrals in closed form. It avoids the degeneracy of Maximum a-Posteriori (MAP) estimates and leads to an effective noise-adaptive scheme. Moreover, we drastically accelerate our algorithm by using Majorization Minimization (MM) without introducing any approximation or boundary artifacts. We further speed up convergence by turning our algorithm into a neural network termed GradNet, which is highly parallelizable and can be efficiently trained. We demonstrate that our noise-blind formulation can be integrated with different priors and significantly improves existing deblurring algorithms in the noise-blind and in the known-noise case. Furthermore, GradNet leads to state-of-the-art performance across different noise levels, while retaining high computational efficiency.","",""
21,"D. Khairnar, S. Merchant, U. Desai","Radial basis function neural network for pulse radar detection",2007,"","","","",200,"2022-07-13 10:10:34","","10.1049/IET-RSN:20050023","","",,,,,21,1.40,7,3,15,"A new approach using a radial basis function network (RBFN) for pulse compression is proposed. In the study, networks using 13-element Barker code, 35-element Barker code and 21-bit optimal sequences have been implemented. In training these networks, the RBFN-based learning algorithm was used. Simulation results show that RBFN approach has significant improvement in error convergence speed (very low training error), superior signal-to-sidelobe ratios, good noise rejection performance, improved misalignment performance, good range resolution ability and improved Doppler shift performance compared to other neural network approaches such as back-propagation, extended Kalman filter and autocorrelation function based learning algorithms. The proposed neural network approach provides a robust mean for pulse radar tracking.","",""
