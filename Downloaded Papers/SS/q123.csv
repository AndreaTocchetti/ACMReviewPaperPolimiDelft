Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
106,"Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, V. Larivière, A. Beygelzimer, Florence d'Alché-Buc, E. Fox, H. Larochelle","Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)",2020,"","","","",1,"2022-07-13 10:06:04","","","","",,,,,106,53.00,13,8,2,"One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.","",""
8,"K. Ambrosen, Martin W. Skjerbæk, Jonathan Foldager, Martin C. Axelsen, N. Bak, L. Arvastson, S. Christensen, L. B. Johansen, J. Raghava, B. Oranje, E. Rostrup, M. Nielsen, M. Osler, B. Fagerlund, C. Pantelis, B. Kinon, B. Glenthøj, L. K. Hansen, B. Ebdrup","A machine-learning framework for robust and reliable prediction of short- and long-term treatment response in initially antipsychotic-naïve schizophrenia patients based on multimodal neuropsychiatric data",2020,"","","","",2,"2022-07-13 10:06:04","","10.1038/s41398-020-00962-8","","",,,,,8,4.00,1,19,2,"","",""
92,"Martin Rozycki, T. Satterthwaite, N. Koutsouleris, G. Erus, J. Doshi, D. Wolf, Yong Fan, R. Gur, R. Gur, E. Meisenzahl, C. Zhuo, Hong Yin, Hao Yan, W. Yue, Dai Zhang, C. Davatzikos","Multisite Machine Learning Analysis Provides a Robust Structural Imaging Signature of Schizophrenia Detectable Across Diverse Patient Populations and Within Individuals",2018,"","","","",3,"2022-07-13 10:06:04","","10.1093/schbul/sbx137","","",,,,,92,23.00,9,16,4,"Past work on relatively small, single-site studies using regional volumetry, and more recently machine learning methods, has shown that widespread structural brain abnormalities are prominent in schizophrenia. However, to be clinically useful, structural imaging biomarkers must integrate high-dimensional data and provide reproducible results across clinical populations and on an individual person basis. Using advanced multi-variate analysis tools and pooled data from case-control imaging studies conducted at 5 sites (941 adult participants, including 440 patients with schizophrenia), a neuroanatomical signature of patients with schizophrenia was found, and its robustness and reproducibility across sites, populations, and scanners, was established for single-patient classification. Analyses were conducted at multiple scales, including regional volumes, voxelwise measures, and complex distributed patterns. Single-subject classification was tested for single-site, pooled-site, and leave-site-out generalizability. Regional and voxelwise analyses revealed a pattern of widespread reduced regional gray matter volume, particularly in the medial prefrontal, temporolimbic and peri-Sylvian cortex, along with ventricular and pallidum enlargement. Multivariate classification using pooled data achieved a cross-validated prediction accuracy of 76% (AUC = 0.84). Critically, the leave-site-out validation of the detected schizophrenia signature showed accuracy/AUC range of 72-77%/0.73-0.91, suggesting a robust generalizability across sites and patient cohorts. Finally, individualized patient classifications displayed significant correlations with clinical measures of negative, but not positive, symptoms. Taken together, these results emphasize the potential for structural neuroimaging data to provide a robust and reproducible imaging signature of schizophrenia. A web-accessible portal is offered to allow the community to obtain individualized classifications of magnetic resonance imaging scans using the methods described herein.","",""
0,"S. Al-Zaiti, Alaa A. Alghwiri, Xiao Hu, G. Clermont, A. Peace, P. Macfarlane, R. Bond","A clinician’s guide to understanding and critically appraising machine learning studies: a checklist for Ruling Out Bias Using Standard Tools in Machine Learning (ROBUST-ML)",2022,"","","","",4,"2022-07-13 10:06:04","","10.1093/ehjdh/ztac016","","",,,,,0,0.00,0,7,1,"  Developing functional machine learning (ML)-based models to address unmet clinical needs requires unique considerations for optimal clinical utility. Recent debates about the rigours, transparency, explainability, and reproducibility of ML models, terms which are defined in this article, have raised concerns about their clinical utility and suitability for integration in current evidence-based practice paradigms. This featured article focuses on increasing the literacy of ML among clinicians by providing them with the knowledge and tools needed to understand and critically appraise clinical studies focused on ML. A checklist is provided for evaluating the rigour and reproducibility of the four ML building blocks: data curation, feature engineering, model development, and clinical deployment. Checklists like this are important for quality assurance and to ensure that ML studies are rigourously and confidently reviewed by clinicians and are guided by domain knowledge of the setting in which the findings will be applied. Bridging the gap between clinicians, healthcare scientists, and ML engineers can address many shortcomings and pitfalls of ML-based solutions and their potential deployment at the bedside.","",""
0,"F. Moiseev, Artem Lukoianov, N. Durasov","Machine Learning Course, Project 2 Unsupervised Object Segmentation by Redrawing: reproducibility challenge",2019,"","","","",5,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,3,"Semantic Segmentation is one of the core tasks in the area of Computer Vision and in most cases, it’s solved in a supervised manner. This approach demands huge datasets of pixellevel labeled data consisted of image-mask pairs which often are unavailable. In this work we provide an ablation study for the ReDO paper [1] where authors use GAN based segmentation model for Unsupervised Semantic Segmentation task: after prediction of object mask input image is redrawn by generator guided by predicted mask, then generated images are fed to discriminator to align them to the original dataset. However, the proposed approach has one significant shortcoming – the network collapses in ∼ 35% cases. We suggest a modification of this approach based on mask regularization which shows the same performance but is more robust. In the final part, we study the ability of the network to produce meaningful embeddings and show that it contains enough information to be used in semi-supervised classification problems.","",""
20,"L. Pan, Caixia Cheng, U. Haberkorn, A. Dimitrakopoulou-Strauss","Machine learning-based kinetic modeling: a robust and reproducible solution for quantitative analysis of dynamic PET data.",2017,"","","","",6,"2022-07-13 10:06:04","","10.1088/1361-6560/aa6244","","",,,,,20,4.00,5,4,5,"A variety of compartment models are used for the quantitative analysis of dynamic positron emission tomography (PET) data. Traditionally, these models use an iterative fitting (IF) method to find the least squares between the measured and calculated values over time, which may encounter some problems such as the overfitting of model parameters and a lack of reproducibility, especially when handling noisy data or error data. In this paper, a machine learning (ML) based kinetic modeling method is introduced, which can fully utilize a historical reference database to build a moderate kinetic model directly dealing with noisy data but not trying to smooth the noise in the image. Also, due to the database, the presented method is capable of automatically adjusting the models using a multi-thread grid parameter searching technique. Furthermore, a candidate competition concept is proposed to combine the advantages of the ML and IF modeling methods, which could find a balance between fitting to historical data and to the unseen target curve. The machine learning based method provides a robust and reproducible solution that is user-independent for VOI-based and pixel-wise quantitative analysis of dynamic PET data.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",7,"2022-07-13 10:06:04","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
0,"Ziyu Ning, Shuang Yu, Yanqiao Zhao, Xiaoming Sun, Haibin Wu, Xiaoyang Yu","Identification of miRNA-Mediated Subpathways as Prostate Cancer Biomarkers Based on Topological Inference in a Machine Learning Process Using Integrated Gene and miRNA Expression Data",2021,"","","","",8,"2022-07-13 10:06:04","","10.3389/fgene.2021.656526","","",,,,,0,0.00,0,6,1,"Accurately identifying classification biomarkers for distinguishing between normal and cancer samples is challenging. Additionally, the reproducibility of single-molecule biomarkers is limited by the existence of heterogeneous patient subgroups and differences in the sequencing techniques used to collect patient data. In this study, we developed a method to identify robust biomarkers (i.e., miRNA-mediated subpathways) associated with prostate cancer based on normal prostate samples and cancer samples from a dataset from The Cancer Genome Atlas (TCGA; n = 546) and datasets from the Gene Expression Omnibus (GEO) database (n = 139 and n = 90, with the latter being a cell line dataset). We also obtained 10 other cancer datasets to evaluate the performance of the method. We propose a multi-omics data integration strategy for identifying classification biomarkers using a machine learning method that involves reassigning topological weights to the genes using a directed random walk (DRW)-based method. A global directed pathway network (GDPN) was constructed based on the significantly differentially expressed target genes of the significantly differentially expressed miRNAs, which allowed us to identify the robust biomarkers in the form of miRNA-mediated subpathways (miRNAs). The activity value of each miRNA-mediated subpathway was calculated by integrating multiple types of data, which included the expression of the miRNA and the miRNAs’ target genes and GDPN topological information. Finally, we identified the high-frequency miRNA-mediated subpathways involved in prostate cancer using a support vector machine (SVM) model. The results demonstrated that we obtained robust biomarkers of prostate cancer, which could classify prostate cancer and normal samples. Our method outperformed seven other methods, and many of the identified biomarkers were associated with known clinical treatments.","",""
10,"Alan Le Goallec, B. Tierney, Jacob M. Luber, Evan M. Cofer, A. Kostic, C. Patel","A systematic machine learning and data type comparison yields metagenomic predictors of infant age, sex, breastfeeding, antibiotic usage, country of origin, and delivery type",2020,"","","","",9,"2022-07-13 10:06:04","","10.1371/journal.pcbi.1007895","","",,,,,10,5.00,2,6,2,"The microbiome is a new frontier for building predictors of human phenotypes. However, machine learning in the microbiome is fraught with issues of reproducibility, driven in large part by the wide range of analytic models and metagenomic data types available. We aimed to build robust metagenomic predictors of host phenotype by comparing prediction performances and biological interpretation across 8 machine learning methods and 4 different types of metagenomic data. Using 1,570 samples from 300 infants, we fit 7,865 models for 6 host phenotypes. We demonstrate the dependence of accuracy on algorithm choice and feature definition in microbiome data and propose a framework for building microbiome-derived indicators of host phenotype. We additionally identify biological features predictive of age, sex, breastfeeding status, historical antibiotic usage, country of origin, and delivery type. Our complete results can be viewed at http://apps.chiragjpgroup.org/ubiome_predictions/.","",""
1,"M. Hoeren, D. Zontar, A. Tavakolian, M. Berger, S. Ehret, Temirlan Mussagaliyev, C. Brecher","Performance comparison between model-based and machine learning approaches for the automated active alignment of FAC-lenses",2020,"","","","",10,"2022-07-13 10:06:04","","10.1117/12.2546607","","",,,,,1,0.50,0,7,2,"Due to their short focal lengths, FAC lenses significantly influence the performance of high-power diode laser systems. In addition to the shape, coating and surface quality, high demands are placed on the assembly accuracy for these microoptical components. In order to optimally align and position the lenses despite varying properties (e.g. focal length), active alignment strategies are used. The automation of the active alignment process for production offers enormous potential. Compared to manual processes, the reproducibility and accuracy of the alignment is increased. For the automation of the active alignment process, a deep understanding of the system behaviour is necessary. To control a diversity of variants cost-effectively and robust, new approaches must be taken into account. Concepts of AI or machine learning are great for this kind of generalization and adoption and they have many advantages for the active alignment of systems like DOEs or free-form-optics, with a complex system behaviour. In this publication, we want to compare the performance of a classically model-based algorithm and a machine learning approach for the automated active alignment of FAC-lenses. The model-based algorithm uses a physical model of the metrology system (including the FAC to be aligned) to estimate a misalignment in 4-DOF. The machine learning algorithm consist of a deep neuronal network which was trained with image data.","",""
23,"P. Mondal, Xue Liu, T. Fatoyinbo, D. Lagomasino","Evaluating Combinations of Sentinel-2 Data and Machine-Learning Algorithms for Mangrove Mapping in West Africa",2019,"","","","",11,"2022-07-13 10:06:04","","10.3390/rs11242928","","",,,,,23,7.67,6,4,3,"Creating a national baseline for natural resources, such as mangrove forests, and monitoring them regularly often requires a consistent and robust methodology. With freely available satellite data archives and cloud computing resources, it is now more accessible to conduct such large-scale monitoring and assessment. Yet, few studies examine the reproducibility of such mangrove monitoring frameworks, especially in terms of generating consistent spatial extent. Our objective was to evaluate a combination of image processing approaches to classify mangrove forests along the coast of Senegal and The Gambia. We used freely available global satellite data (Sentinel-2), and cloud computing platform (Google Earth Engine) to run two machine learning algorithms, random forest (RF), and classification and regression trees (CART). We calibrated and validated the algorithms using 800 reference points collected using high-resolution images. We further re-ran 10 iterations for each algorithm, utilizing unique subsets of the initial training data. While all iterations resulted in thematic mangrove maps with over 90% accuracy, the mangrove extent ranges between 827–2807 km2 for Senegal and 245–1271 km2 for The Gambia with one outlier for each country. We further report “Places of Agreement” (PoA) to identify areas where all iterations for both methods agree (506.6 km2 and 129.6 km2 for Senegal and The Gambia, respectively), thus have a high confidence in predicting mangrove extent. While we acknowledge the timeand cost-effectiveness of such methods for the landscape managers, we recommend utilizing them with utmost caution, as well as post-classification on-the-ground checks, especially for decision making.","",""
0,"","Machine learning based alignment of mass spectrometry data for improved clinical biomarker discovery",2022,"","","","",12,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,0,1,"Challenges: To date, although few algorithms have been proposed to do so, there does not exist any generic methodological framework allowing for the alignment of several samples, in order to subsequently provide a robust identification transfer between samples. An innovation in this direction will therefore strongly impact the reproducibility of MS-based molecular profiling, and subsequently, clinical research tools.","",""
2,"Chris Emmery, Ákos Kádár, Travis J. Wiltshire, Andrew T. Hendrickson","Towards Replication in Computational Cognitive Modeling: a Machine Learning Perspective",2019,"","","","",13,"2022-07-13 10:06:04","","10.1007/S42113-019-00055-W","","",,,,,2,0.67,1,4,3,"","",""
0,"Samuel J Bell, Onno P. Kampman, Jesse Dodge, Neil D. Lawrence","Modeling the Machine Learning Multiverse",2022,"","","","",14,"2022-07-13 10:06:04","","10.48550/arXiv.2206.05985","","",,,,,0,0.00,0,4,1,"Amid mounting concern about the reliability and credibility of machine learning research, we present a principled framework for making robust and generalizable claims: the Multiverse Analysis. Our framework builds upon the Multiverse Analysis [1] introduced in response to psychology’s own reproducibility crisis. To efficiently explore high-dimensional and often continuous ML search spaces, we model the multiverse with a Gaussian Process surrogate and apply Bayesian experimental design. Our framework is designed to facilitate drawing robust scientific conclusions about model performance, and thus our approach focuses on exploration rather than conventional optimization. In the first of two case studies, we investigate disputed claims about the relative merit of adaptive optimizers. Second, we synthesize conflicting research on the effect of learning rate on the large batch training generalization gap. For the machine learning community, the Multiverse Analysis is a simple and effective technique for identifying robust claims, for increasing transparency, and a step toward improved reproducibility.","",""
0,"Prabhant Singh","Reproducibility Report : Synthesizing Robust Adversarial Examples ∗",2018,"","","","",15,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,1,4,"Neural network-based classifiers parallel or exceed human-level accuracy on many common tasks and are used in practical systems. Yet, neural networks are susceptible to adversarial examples, carefully perturbed inputs that cause networks to misbehave in arbitrarily chosen ways[11]. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model[? ]. Adversarial examples generated using standard techniques like Fast Gradient sign method[3] require complete control over the direct input to the neural network, this is not the case in real world scenarios.[4] For example, standard adversarial examples are not robust under rotation, cropping and various image transformation methods. Expectation over transformation: In this paper[1], the authors introduced a new algorithm, Expectation over transformation to generate robust adversarial examples.","",""
17,"Khimya Khetarpal, Zafarali Ahmed, Andre Cianflone, Riashat Islam, Joelle Pineau","RE-EVALUATE: Reproducibility in Evaluating Reinforcement Learning Algorithms",2018,"","","","",16,"2022-07-13 10:06:04","","","","",,,,,17,4.25,3,5,4,"Reinforcement learning (RL) has recently achieved tremendous success in solving complex tasks. Careful considerations are made towards reproducible research in machine learning. Reproducibility in RL often becomes more difficult, due to the lack of standard evaluation method and detailed methodology for algorithms and comparisons with existing work. In this work, we highlight key differences in evaluation in RL compared to supervised learning, and discuss specific issues that are often non-intuitive for newcomers. We study the importance of reproducibility in evaluation in RL, and propose an evaluation pipeline that can be decoupled from the algorithm code. We hope such an evaluation pipeline can be standardized, as a step towards robust and reproducible research in RL.","",""
0,"Tianhan Zhang, Yuxiao Yi, Yifan Xu, Z. X. Chen, Yaoyu Zhang, E. Weinan, Zhi-Qin John Xu","A multi-scale sampling method for accurate and robust deep neural network to predict combustion chemical kinetics",2022,"","","","",17,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,7,1,"Machine learning has long been considered as a black box for predicting combustion chemical kinetics due to the extremely large number of parameters and the lack of evaluation standards and reproducibility. The current work aims to understand two basic questions regarding the deep neural network (DNN) method: what data the DNN needs and how general the DNN method can be. Sampling and preprocessing determine the DNN training dataset, further affect DNN prediction ability. The current work proposes using Box-Cox transformation (BCT) to preprocess the combustion data. In addition, this work compares different sampling methods with or without preprocessing, including the Monte Carlo method, ∗Corresponding authors. January 12, 2022 ar X iv :2 20 1. 03 54 9v 1 [ ph ys ic s. ch em -p h] 9 J an 2 02 2 manifold sampling, generative neural network method (cycle-GAN), and newlyproposed multi-scale sampling. Our results reveal that the DNN trained by the manifold data can capture the chemical kinetics in limited configurations but cannot remain robust toward perturbation, which is inevitable for the DNN coupled with the flow field. The Monte Carlo and cycle-GAN samplings can cover a wider phase space but fail to capture small-scale intermediate species, producing poor prediction results. A three-hidden-layer DNN, based on the multi-scale method without specific flame simulation data, allows predicting chemical kinetics in various scenarios and being stable during the temporal evolutions. This single DNN is readily implemented with several CFD codes and validated in various combustors, including (1). zero-dimensional autoignition, (2). one-dimensional freely propagating flame, (3). two-dimensional jet flame with triple-flame structure, and (4). three-dimensional turbulent lifted flames. The ignition delay time, laminar flame speed, lifted flame height, and contours of physical quantities demonstrate the satisfying accuracy and generalization ability of the pre-trained DNN. The Fortran and Python versions of DNN and example code are attached in the supplementary for reproducibility.","",""
9,"J.-G. Pineau, Koustuv Sinha, G. Fried, Rosemary Nan Ke, H. Larochelle, N. Rougier","ICLR Reproducibility Challenge 2019",2019,"","","","",18,"2022-07-13 10:06:04","","","","",,,,,9,3.00,2,6,3,"DOI 10.5281/zenodo.3158244 Welcome to this special issue of the ReScience C journal, which presents results of the 2019 ICLR Reproducibility Challenge (2nd edition). One of the challenges in machine learning research is to ensure that published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper, using the same code and data (when available), is a necessary step to verify research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes use of robust experimentation workflows, which can potentially reduce unintentional errors.","",""
24,"Tianyu Kang, W. Ding, Luoyan Zhang, D. Ziemek, Kourosh Zarringhalam","A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data",2017,"","","","",19,"2022-07-13 10:06:04","","10.1186/s12859-017-1984-2","","",,,,,24,4.80,5,5,5,"","",""
2,"J. Hind, A. Hussain, D. Al-Jumeily, C. C. Montañez, C. Chalmers, P. Lisboa","Robust Interpretation of Genomic Data in Chronic Obstructive Pulmonary Disease (COPD)",2018,"","","","",20,"2022-07-13 10:06:04","","10.1109/DeSE.2018.00009","","",,,,,2,0.50,0,6,4,"Within genomic studies, a considerable amount of publications have reported SNP variants associated with COPD with little to no reproducibility. In this paper, we present a robust methodology which analyses a COPD cohort dataset using a genome-wide association study, additionally an investigation of the associated results using a variety of machine learning (ML) methods is performed. We use a logistic regression model to provide preliminary results and for further analysis we use machine learning models, RF, MLP, GLM and SVM. Within this study, indications of well established SNPs in previous publications occur in the preliminary results but fail to provide further indication of associative relationship when using ML methods for classification purposes. Results within this study show little to no predictive power after performing a robust methodology. These results indicate that a standardization of practice should be implemented to ensure the publication of false positive results is reduced and deterred. Further investigation of associative features should be considered a standard practice given the resulting information that can be provided with its' use.","",""
1,"Olov Andersson","Toward Robust Deep RL via Better Benchmarks : Identifying Neglected Problem Dimensions",2018,"","","","",21,"2022-07-13 10:06:04","","","","",,,,,1,0.25,1,1,4,"We consider a wider sense of reproducibility in practice for deep reinforcement learning on control tasks, where it holds promise as a general purpose solution. However, unlike other branches of machine learning, for practical reasons only simulation data is used in RL benchmarks. This puts greater responsibility on experiment design for advances on benchmarks to translate to real-world performance. There has been a string of successes with solving ever more impressive-looking problems in the Mujoco physics simulator. However, while involving control with different agent dynamics, there is reason to believe that these benchmarks are in other respects fairly homogeneous, e.g. having deterministic state transitions with quadratic objectives. For instance, [9] recently showed that many of them are solvable by a simple linear policy and suggest widening the initial state distribution to avoid fragile ""trajectory-centric"" policies. We take this further and argue that the environments themselves should have both an inherent uncertainty, and more complex objectives. Autonomous robots and vehicles have to deal with a complex uncertain world that changes over time. To exemplify this we introduce a seemingly simple benchmark where randomly moving obstacles have to be avoided. This both precludes a trajectory-centric solution and involves a more difficult objective than commonly used. We show that this toy example actually has higher sample complexity than the Mujoco benchmarks. We further find that the level of robustness expected of real-world autonomous agents leads to requirements on tail-end convergence that is rarely given much consideration in benchmarks, resulting in difficult tuning problems. While some environment variation has recently been shown for e.g. complex humanoid agents in Mujoco, with training times increasingly requiring massive cloud infrastructure, we finally suggest that such toy examples designed to test different problem dimensions have an important role to play in research.","",""
1,"Yixiao Gong, C. Lazaris, A. Lozano, P. Kambadur, P. Ntziachristos, I. Aifantis, A. Tsirigos","Robust Estimation Of Hi-C Contact Matrices Using Fused Lasso Reveals Preferential Insulation Of Super-Enhancers By Strong TAD Boundaries",2017,"","","","",22,"2022-07-13 10:06:04","","10.1101/141481","","",,,,,1,0.20,0,7,5,"The metazoan genome is compartmentalized in megabase-scale areas of highly interacting chromatin known as topologically associating domains (TADs), typically identified by computational analyses of Hi-C sequencing data. TADs are demarcated by boundaries that have been shown to be largely conserved across cell types and even across species. Increasing evidence suggests that the seemingly invariant TADs may exhibit some plasticity in certain cases and their boundary strength can vary. However, a genome-wide characterization of TAD boundary strength in mammals is still lacking. In this study, we use fused two-dimensional lasso as a machine-learning method to first improve Hi-C contact matrix reproducibility and subsequently categorize TAD boundaries based on their strength. We demonstrate that increased boundary strength is associated with elevated levels of CTCF and that TAD boundary insulation scores may differ across cell types. Intriguingly, we also found that super-enhancer elements are preferentially insulated by strong boundaries. Presumably, genetic or epigenetic inactivation of strong boundaries may lead to loss of insulation around super-enhancers, disrupt the physiological transcriptional program and cause disease.","",""
5,"Sudipta Roy, T. Whitehead, Shunqiang Li, F. Ademuyiwa, R. Wahl, F. Dehdashti, K. Shoghi","Co-clinical FDG-PET radiomic signature in predicting response to neoadjuvant chemotherapy in triple-negative breast cancer",2021,"","","","",23,"2022-07-13 10:06:04","","10.1007/s00259-021-05489-8","","",,,,,5,5.00,1,7,1,"","",""
2,"C. Bouvier, N. Souedet, J. Levy, C. Jan, Z. You, A. Hérard, G. Mergoil, B. H. Rodriguez, C. Clouchoux, T. Delzescaux","Reduced and stable feature sets selection with random forest for neurons segmentation in histological images of macaque brain",2021,"","","","",24,"2022-07-13 10:06:04","","10.1038/s41598-021-02344-6","","",,,,,2,2.00,0,10,1,"","",""
2,"Edward Raff","Does the Market of Citations Reward Reproducible Work?",2022,"","","","",25,"2022-07-13 10:06:04","","10.48550/arXiv.2204.03829","","",,,,,2,2.00,2,1,1,"The field of bibliometrics, studying citations and behavior, is critical to the discussion of reproducibility. Citations are one of the primary incentive and reward systems for academic work, and so we desire to know if this incentive rewards reproducible work. Yet to the best of our knowledge, only one work has attempted to look at this combined space, concluding that non-reproducible work is more highly cited. We show that answering this question is more challenging than first proposed, and subtle issues can inhibit a robust conclusion. To make inferences with more robust behavior, we propose a hierarchical Bayesian model that incorporates the citation rate over time, rather than the total number of citations after a fixed amount of time. In doing so we show that, under current evidence the answer is more likely that certain fields of study such as Medicine and Machine Learning (ML) do correlate reproducible works with more citations, but other fields appear to have no relationship. Further, we find that making code available and thoroughly referencing prior works appear to also positively correlate with increased citations. Our code and data can be found at https://github.com/EdwardRaff/ReproducibleCitations.","",""
2,"Z. Magnuska, B. Theek, Milita Darguzyte, M. Palmowski, E. Stickeler, V. Schulz, F. Kiessling","Influence of the Computer-Aided Decision Support System Design on Ultrasound-Based Breast Cancer Classification",2022,"","","","",26,"2022-07-13 10:06:04","","10.3390/cancers14020277","","",,,,,2,2.00,0,7,1,"Simple Summary The implementation of artificial intelligence in the computer-aided decision (CAD) support systems holds great promise for future cancer diagnosis. It is crucial to build these algorithms in a structured manner to ensure reproducibility and reliability. In this context, we used a dataset of breast ultrasound (US) images with 252 breast cancer and 253 benign cases to refine the CAD image analysis workflow. Various dataset preparations (i.e., pre-processing, and spatial augmentation) and machine learning algorithms were tested to establish the framework with the best performance in the detection and classification of breast lesions in US images. The efficacy of the proposed workflows was evaluated regarding accuracy, precision, specificity, and sensitivity. Abstract Automation of medical data analysis is an important topic in modern cancer diagnostics, aiming at robust and reproducible workflows. Therefore, we used a dataset of breast US images (252 malignant and 253 benign cases) to realize and compare different strategies for CAD support in lesion detection and classification. Eight different datasets (including pre-processed and spatially augmented images) were prepared, and machine learning algorithms (i.e., Viola–Jones; YOLOv3) were trained for lesion detection. The radiomics signature (RS) was derived from detection boxes and compared with RS derived from manually obtained segments. Finally, the classification model was established and evaluated concerning accuracy, sensitivity, specificity, and area under the Receiver Operating Characteristic curve. After training on a dataset including logarithmic derivatives of US images, we found that YOLOv3 obtains better results in breast lesion detection (IoU: 0.544 ± 0.081; LE: 0.171 ± 0.009) than the Viola–Jones framework (IoU: 0.399 ± 0.054; LE: 0.096 ± 0.016). Interestingly, our findings show that the classification model trained with RS derived from detection boxes and the model based on the RS derived from a gold standard manual segmentation are comparable (p-value = 0.071). Thus, deriving radiomics signatures from the detection box is a promising technique for building a breast lesion classification model, and may reduce the need for the lesion segmentation step in the future design of CAD systems.","",""
1,"Sudipta Roy, T. Whitehead, Shunqiang Li, F. Ademuyiwa, R. Wahl, F. Dehdashti, K. Shoghi","Co-clinical FDG-PET Radiomic Signature in Predicting Response to Neoadjuvant Chemotherapy in Triple Negative Breast Cancer",2021,"","","","",27,"2022-07-13 10:06:04","","10.1101/2021.06.11.448077","","",,,,,1,1.00,0,7,1,"Purpose We sought to exploit the heterogeneity afforded by patient-derived tumor xenografts (PDX) to optimize robust radiomic features associated with response to therapy in the context of a co-clinical trial and implement PDX-optimized image features in the corresponding clinical study to predict and assess response to therapy using machine-learning (ML) algorithms. Methods TNBC patients and subtype-matched PDX were recruited into a co-clinical FDG-PET imaging study to predict response to therapy. One hundred thirty-one imaging features were extracted from PDX and human segmented tumors. Robust image features were identified based on reproducibility, cross-correlation, and volume independence. A rank importance of predictors using ReliefF was used to identify predictive radiomic features in the preclinical PDX trial in conjunction with ML algorithms: classification and regression tree (CART), Naïve Bayes (NB), and support vector machines (SVM). The top four PDX-optimized image features, defined as radiomic signatures (RadSig), from each task were then used to predict or assess response to therapy. Performance of RadSig in predicting/assessing response was compared to SUVmean, SUVmax, and lean body mass normalized SULpeak measures. Results Sixty-four out of 131 preclinical imaging features were identified as robust. NB-RadSig performed highest in predicting and assessing response to therapy in the preclinical PDX trial. In the clinical study, the performance of SVM-RadSig and NB-RadSig to predict and assess response was practically identical and superior to SUVmean, SUVmax, and SULpeak, measures. Conclusions We optimized robust FDG-PET radiomic signatures (RadSig) to predict and assess response to therapy in a context of a co-clinical imaging trial. DECLARATIONS Funding This work was supported by NCI grants U24CA209837, U24CA253531, and U54CA224083; U2CCA233303, and K12CA167540; Siteman Cancer Center (SCC) Support Grant P30CA091842; and Internal funds provided by Mallinckrodt Institute of Radiology. Conflicts of interest/Competing interests. None. Availability of data and material All the co-clinical data will be available for download through the Washington University School of Medicine Co-Clinical Imaging Research Resource web portal at https://c2ir2.wustl.edu/, co-clinical database (CCDB). Code availability Not applicable. Authors’ contributions Conceptualization: SR, FOA, KIS; Methodology: SR, TDW, SL, KIS; Formal analysis and investigation: SR, KIS; Writing - original draft preparation: SR; Writing - review and editing: RLW, FD, KIS; Funding acquisition: RWL, FOA, SL, KIS; Resources: SL; Supervision: FD, KIS. All authors read and approved the final manuscript. Ethics approval All studies were performed with approval from the Washington University Humans subjects research committee and animal studies committee. Consent to participate Informed consent to participate in the study was obtained from all participants. Consent for publication Not applicable.","",""
17,"Meletios Doulgkeroglou, Alessia Di Nubila, B. Nießing, N. König, R. Schmitt, J. Damen, S. Szilvassy, W. Chang, L. Csontos, S. Louis, P. Kugelmeier, V. Ronfard, Y. Bayon, D. Zeugolis","Automation, Monitoring, and Standardization of Cell Product Manufacturing",2020,"","","","",28,"2022-07-13 10:06:04","","10.3389/fbioe.2020.00811","","",,,,,17,8.50,2,14,2,"Although regenerative medicine products are at the forefront of scientific research, technological innovation, and clinical translation, their reproducibility and large-scale production are compromised by automation, monitoring, and standardization issues. To overcome these limitations, new technologies at software (e.g., algorithms and artificial intelligence models, combined with imaging software and machine learning techniques) and hardware (e.g., automated liquid handling, automated cell expansion bioreactor systems, automated colony-forming unit counting and characterization units, and scalable cell culture plates) level are under intense investigation. Automation, monitoring and standardization should be considered at the early stages of the developmental cycle of cell products to deliver more robust and effective therapies and treatment plans to the bedside, reducing healthcare expenditure and improving services and patient care.","",""
0,"Calvin Fung, Matthew Rusling, Thomas Lampeter, Charles Love, Lilian Yuan","QIIME 2 Automation for Microbiome Analysis: An Opportunity to Reduce Barriers to Entry While Improving Analytic Speed and Reliability",2021,"","","","",29,"2022-07-13 10:06:04","","10.1096/FASEBJ.2021.35.S1.00394","","",,,,,0,0.00,0,5,1,"The cost of next‐generation sequencing has significantly reduced since its arrival in 2004, allowing metagenomic research to flourish with applications in medicine, genetics, agriculture, and environment. QIIME 2 is an open‐source microbiome analysis software package that converts raw sequence data into interpretable visualizations and statistical results. Most common analyses include classifying sequences taxonomically, analyzing alpha and beta diversity, assessing phylogenetic relationship between features, and identifying features with differential abundances in various treatment groups. Third parties can contribute functionality such as longitudinal analysis and machine‐learning analysis, making it a robust microbiome tool that is widely used. However, there exist several barriers in using QIIME 2. There is a steep learning curve for users with limited technical computer skill. The high volume of user inputs increases risk for user error and inefficient reproducibility among collaborators. However, these issues with efficiency, accessibility, and consistency can be addressed through automation. Using LINUX shells, we developed a robust QIIME 2 automation pipeline that automates the core functions of QIIME 2 metagenomic analysis. The process covers raw sequence data importing, demultiplexing, and denoising. It also automates data subset filtering, taxonomic classification, and alpha and beta diversity analyses. Files created with standardized nomenclature are organized into a simple folder structure comprising of data, visualizations, and metadata. QIIME 2 parameters are saved into accessible text files for transparency. The pipeline was trialed with 3 novices to both data science and metagenomic research: one PhD principal investigator, one 2nd year medical student and one 1st year medical student. They were given our scripts and tutorial, and they recorded the time and keystrokes to reach 3 endpoints: 1) construct a PCOA plot of an entire dataset, 2) perform ADONIS test on a distance matrix subset, and 3) compare alpha diversity using the Shannon metric on a metadata subset feature table. 2 out of 3 trials were successful in meeting these endpoints within 2 weeks, requiring 7 (PhD) and 9 hours (2nd year medical student) to do so. Using the fewest possible keystrokes, this analysis would have taken 11,594 characters over roughly 40 hours if done manually. Using our QIIME 2 automation, these endpoints were completed with 228 user keystrokes. The limitations of QIIME 2 can be diminished by automation and clarification of steps at decision points within a metagenomic analysis. The goal of this project was to reduce risk of error and time spent, limiting the obstacles facing a new user using QIIME 2. With growing popularity in metagenomic research, our automation tool can help computer novices navigate through the technical barriers of metagenomic analysis.","",""
0,"M. Vaisband, Maria Schubert, F. Gassner, R. Geisberger, R. Greil, N. Zaborsky, J. Hasenauer","Validation of genetic variants from NGS data using Deep Convolutional Neural Networks",2022,"","","","",30,"2022-07-13 10:06:04","","10.1101/2022.04.12.488021","","",,,,,0,0.00,0,7,1,"Accurate somatic variant calling from next-generation sequencing data is one most important tasks in personalised cancer therapy. The sophistication of the available technologies is ever-increasing, yet, manual candidate refinement is still a necessary step in state-of-the-art processing pipelines. This limits reproducibility and introduces a bottleneck with respect to scalability. We demonstrate that the validation of genetic variants can be improved using a machine learning approach resting on a Convolutional Neural Network, trained using existing human annotation. In contrast to existing approaches, we introduce a way in which contextual data from sequencing tracks can be included into the automated assessment. A rigorous evaluation shows that the resulting model is robust and performs on par with trained researchers following published standard operating procedure.","",""
0,"Deep Chanda, Debojyoti De","Meta-analysis reveals obesity associated gut microbial alteration patterns and reproducible contributors of functional shift",2022,"","","","",31,"2022-07-13 10:06:04","","10.1101/2022.06.05.494850","","",,,,,0,0.00,0,2,1,"Cohort-specific 16S rRNA sequence-based studies associating gut microbiota with obesity are often marred with contradictory findings regarding community structure and composition leading to “reproducibility crisis” of the signals. Moreover, taxonomic drivers of the obesity-linked gut microbial functional imbalances and their replicability also remains unexplored which should be useful for in-depth understanding of obese host-gut microbiota interaction and, strategizing therapeutics. We addressed these questions through unbiased meta-analysis and further machine-learning validation of 692 curated fecal whole metagenomic sequence datasets from diverse geographical locations. Further, obesity-linked pathway shifts were traced back to their specific drivers by integrating the species and pathway profiles through genomic content of the species. We found reproducible depletion of diversity in obese gut microbiome without any pattern in Firmicutes/Bacteroidetes ratio. Additionally, we also identified obesity-linked robust and reproducible gut microbial species and pathway features. Contributors of these pathway features identified as both dataset-specific and shared across the datasets.","",""
8,"Jean J L Hsieh, I. Svalbe","Magnetic resonance fingerprinting: from evolution to clinical applications",2020,"","","","",32,"2022-07-13 10:06:04","","10.1002/jmrs.413","","",,,,,8,4.00,4,2,2,"In 2013, Magnetic Resonance Fingerprinting (MRF) emerged as a method for fast, quantitative Magnetic Resonance Imaging. This paper reviews the current status of MRF up to early 2020 and aims to highlight the advantages MRF can offer medical imaging professionals. By acquiring scan data as pseudorandom samples, MRF elicits a unique signal evolution, or ‘fingerprint’, from each tissue type. It matches ‘randomised’ free induction decay acquisitions against pre‐computed simulated tissue responses to generate a set of quantitative images of T1, T2 and proton density (PD) with co‐registered voxels, rather than as traditional relative T1‐ and T2‐weighted images. MRF numeric pixel values retain accuracy and reproducibility between 2% and 8%. MRF acquisition is robust to strong undersampling of k‐space. Scan sequences have been optimised to suppress sub‐sampling artefacts, while artificial intelligence and machine learning techniques have been employed to increase matching speed and precision. MRF promises improved patient comfort with reduced scan times and fewer image artefacts. Quantitative MRF data could be used to define population‐wide numeric biomarkers that classify normal versus diseased tissue. Certification of clinical centres for MRF scan repeatability would permit numeric comparison of sequential images for any individual patient and the pooling of multiple patient images across large, cross‐site imaging studies. MRF has to date shown promising results in early clinical trials, demonstrating reliable differentiation between malignant and benign prostate conditions, and normal and sclerotic hippocampal tissue. MRF is now undergoing small‐scale trials at several sites across the world; moving it closer to routine clinical application.","",""
73,"Peter Henderson, Koustuv Sinha, Nicolas Angelard-Gontier, Nan Rosemary Ke, G. Fried, Ryan Lowe, Joelle Pineau","Ethical Challenges in Data-Driven Dialogue Systems",2017,"","","","",33,"2022-07-13 10:06:04","","10.1145/3278721.3278777","","",,,,,73,14.60,10,7,5,"The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.","",""
3,"Yunxiao Deng, C. Kesselman, S. Sen, Jiajun Xu","Computational Operations Research Exchange (Core): A Cyber-Infrastructure for Analytics",2019,"","","","",34,"2022-07-13 10:06:04","","10.1109/WSC40007.2019.9004737","","",,,,,3,1.00,1,4,3,"cORe is a new cyber-infrastructure which will facilitate computational Operations Research exchange. OR models arise in many engineering domains, such as design, manufacturing, and services (e.g., banking/finance, health systems), as well as specific infrastructure-centric applications such as logistics/supply chains, power system operations, telecommunications, traffic/ transportation, and many more. In addition, modern OR tools have also been adopted in many foundational disciplines, such as computer science, machine learning, and others. Given the broad footprint of OR, the development of a robust cyber-infrastructure has the potential to not only promote greater exchange of data, models, software, and experiments but also enhance reproducibility and re-usability, both within OR, and across multiple disciplines mentioned above. cORe also has the potential to drastically reduce the computational burden on research communities which study resource allocation using analytics. This paper presents an overview of the functionality, design, and computations using cORe.","",""
6,"E. Binaghi, V. Pedoia, S. Balbi","Meningioma and peritumoral edema segmentation of preoperative MRI brain scans",2018,"","","","",35,"2022-07-13 10:06:04","","10.1080/21681163.2016.1250108","","",,,,,6,1.50,2,3,4,"AbstractThis work focuses the attention on the segmentation of meningioma and peritumoral edema from multispectral brain MR imagery. Precise tumour and edema delineation and volume quantification from preoperative MRI data contribute to formulate surgical indications in elderly patients harbouring intracranial meningioma. The authors propose a fully automatic procedure based on the allied use of Graph Cut and support vector machine. The overall strategy combines the advantages of the image-based and machine learning techniques adopted, optimising the balancing between accuracy and stability/reproducibility of the results. Experimental results, obtained by processing in-house collected data, prove that the method is robust and oriented to the use in clinical practice.","",""
1,"A. Chambaz, A. Hubbard, M. J. van der Laan","Special Issue on Data-Adaptive Statistical Inference",2016,"","","","",36,"2022-07-13 10:06:04","","10.1515/ijb-2016-0033","","",,,,,1,0.17,0,3,6,"The concomitant emergence of big data, explosion of ubiquitous computational resources and democratization of the access to more powerful computing make it necessary and possible to rethink pragmatically the practice of statistics. While numerous machine learning methods provide much ever easier access to datamining tools and sophisticated prediction, there is a growing realization that ad hoc and non-prespecified approaches to high-dimensional problems lend themselves to a proliferation of “findings” of dubious reproducibility. This period of fast-paced evolution is thus a blessing for statistics. It is a golden opportunity to build upon more than a century of methodological research in statistics and five decades of methodological research in machine learning to bend the course of statistics in a new direction, away from the misuse of parametric models and reporting of non-robust inference, to tackle rigorously the challenges that we, as a community, are confronted with. The foundation of statistics is incorporating knowledge about the data-generating experiment through the definition of a statistical model (a set of laws), formalizing the question of interest through the definition of an estimand seen as the value of a statistical parameter (a functional mapping the model to a parameter set) at the true law of the experiment and inferring the estimand based on data yielded by the experiment. Typically, one would construct an estimator of (a collection of key features of) the true law and evaluate the statistical parameter at its value. The present special issue broadly focuses on the inference of various statistical parameters in situations where either the data-generating law or the statistical parameter or both are dataadaptively defined and/or estimated. Statistical theory has advanced in sync with scientific computing so practical implementation is now possible for the resulting computationally challenging estimators. We asked researchers currently engaged in cutting edge research on data-adaptive inferential methods to share their views with us. The result is a compelling collection of advances in statistical theory and practice. The special issue consists of 19 articles. Its theoretical spectrum is wide. Semiparametric models and inference, empirical process theory and machine learning are the three major subfields explored in the articles. Across this special issue, the acceptation of the word inference covers the estimation of finite-dimensional parameters and the construction of confidence regions for them, the estimation of infinite-dimensional features (either as an endgame or as a means to an end); testing hypotheses (for the sake of making discoveries), identifying particular subgroups in a population, selecting (groups or clusters of) significant variables, comparing data-adaptive predictors. Cross-validating, decomposing a task in a series of sub-tasks (by partitioning or relying on a recurrence), fluctuating and weighting are the recurring technical concepts. Most articles are motivated by applications arising from medicine (analyzing neuroimages, comparing treatments, inferring optimal individualized treatment rules). The others address challenging theoretical questions. They shed light on delicate theoretical problems, offer guidance for better practice, open exciting new territories to explore. We hope you will enjoy perusing the special issue and that it will serve as a useful pivot towards methods that can address new challenges in data science. We wish to thank warmly the De Gruyter team for its unconditional scientific and technical support, in particular Theresa Haney, Spencer McGrath and John Wolfe.","",""
0,"H. P. Oliveira, Jaime S. Cardoso","BCCT.core Model Enhancement With Interpretability and Lateral Information",2010,"","","","",37,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,2,12,"Breast Cancer Conservative Treatment (BCCT) is considered the gold standard of breast cancer treatment. The heterogeneity of the aesthetic result and the limited reproducibility of the subjective evaluation motivated the research towards objective methods, such as, the recent computer system named BCCT.core, based on machine learning techniques, namely support vector machines (SVMs). In the current work we investigate the accuracy of different interpretable methods against the model currently deployed in the BCCT.core software and the improvement of the model by introducing lateral information extracted from patients images. Experimental results show only a marginal improvement in the performance of the new models, suggesting that is essential to use more robust models, such as 3D approaches.","",""
49,"Eric Wong, J. Z. Kolter","Learning perturbation sets for robust machine learning",2020,"","","","",38,"2022-07-13 10:06:04","","","","",,,,,49,24.50,25,2,2,"Although much progress has been made towards robust deep learning, a significant gap in robustness remains between real-world perturbations and more narrowly defined sets typically studied in adversarial defenses. In this paper, we aim to bridge this gap by learning perturbation sets from data, in order to characterize real-world effects for robust training and evaluation. Specifically, we use a conditional generator that defines the perturbation set over a constrained region of the latent space. We formulate desirable properties that measure the quality of a learned perturbation set, and theoretically prove that a conditional variational autoencoder naturally satisfies these criteria. Using this framework, our approach can generate a variety of perturbations at different complexities and scales, ranging from baseline spatial transformations, through common image corruptions, to lighting variations. We measure the quality of our learned perturbation sets both quantitatively and qualitatively, finding that our models are capable of producing a diverse set of meaningful perturbations beyond the limited data seen during training. Finally, we leverage our learned perturbation sets to train models which are empirically and certifiably robust to adversarial image corruptions and adversarial lighting variations, while improving generalization on non-adversarial data. All code and configuration files for reproducing the experiments as well as pretrained model weights can be found at this https URL.","",""
43,"Matthew B. A. McDermott, Shirly Wang, N. Marinsek, R. Ranganath, L. Foschini, M. Ghassemi","Reproducibility in machine learning for health research: Still a ways to go",2021,"","","","",39,"2022-07-13 10:06:04","","10.1126/scitranslmed.abb1655","","",,,,,43,43.00,7,6,1,"Machine learning applied to health falls short on several reproducibility metrics compared to other machine learning subfields. Machine learning for health must be reproducible to ensure reliable clinical use. We evaluated 511 scientific papers across several machine learning subfields and found that machine learning for health compared poorly to other areas regarding reproducibility metrics, such as dataset and code accessibility. We propose recommendations to address this problem.","",""
0,"Ransalu Senanayake, Daniel J. Fremont, Mykel J. Kochenderfer, A. Lomuscio, D. Margineantu, Cheng Soon Ong","Guest Editorial: Special issue on robust machine learning",2021,"","","","",40,"2022-07-13 10:06:04","","10.1007/s10994-021-06113-4","","",,,,,0,0.00,0,6,1,"","",""
31,"Benjamin J. Heil, M. M. Hoffman, F. Markowetz, Su-In Lee, C. Greene, S. C. Hicks","Reproducibility standards for machine learning in the life sciences.",2021,"","","","",41,"2022-07-13 10:06:04","","10.1038/s41592-021-01256-7","","",,,,,31,31.00,5,6,1,"","",""
4,"Joelle Pineau","Building reproducible, reusable, and robust machine learning software",2020,"","","","",42,"2022-07-13 10:06:04","","10.1145/3401025.3407941","","",,,,,4,2.00,4,1,2,"We have seen significant achievements with machine learning in recent years. Yet reproducing results for state-of-the-art deep learning methods is seldom straightforward. High variance of some methods can make learning particularly difficult. Furthermore, results can be brittle to even minor perturbations in the domain or experimental procedure. In this talk, I will review challenges that arise in experimental techniques and reporting procedures in deep learning, with a particular focus on reinforcement learning. I will also describe several recent results and guidelines designed to make future results more reproducible, reusable and robust.","",""
109,"Andrew Beam, A. Manrai, M. Ghassemi","Challenges to the Reproducibility of Machine Learning Models in Health Care.",2020,"","","","",43,"2022-07-13 10:06:04","","10.1001/jama.2019.20866","","",,,,,109,54.50,36,3,2,"Reproducibility has been an important and intensely debated topic in science and medicine for the past few decades.1 As the scientific enterprise has grown in scope and complexity, concerns regarding how well new findings can be reproduced and validated across different scientific teams and study populations have emerged. In some instances,2 the failure to replicate numerous previous studies has added to the growing concern that science and biomedicine may be in the midst of a “reproducibility crisis.” Against this backdrop, high-capacity machine learning models are beginning to demonstrate early successes in clinical applications,3 and some have received approval from the US Food and Drug Administration. This new class of clinical prediction tools presents unique challenges and obstacles to reproducibility, which must be carefully considered to ensure that these techniques are valid and deployed safely and effectively. Reproducibility is a minimal prerequisite for the creation of new knowledge and scientific progress, but defining precisely what it means for a scientific study to be “reproducible” is complex and has been the subject of considerable effort by both individual researchers and organizations like the National Academies of Science, Engineering, and Medicine. First, it is important to distinguish between the notions of reproducibility and replication. A study is reproducible if, given access to the underlying data and analysis code, an independent group can obtain the same result observed in the original study. However, being reproducible does not imply that a study is correct, only thattheresultswereabletobeverifiedbyadifferentgroup not involved in the original study. A study is replicable if an independent group studying the same phenomenon reaches the same conclusion after performing the same set of experiments or analyses after collecting new data. The discussion around reproducibility and replication has primarily focused on traditional statistical models and the results from randomized clinical trials, but these considerations can and should apply equally to machine learning studies. Challenges to reproducibility and replication include confounding, multiple hypothesis testing, randomness inherent to the analysis procedure, incomplete documentation, and restricted access to the underlying data and code. The last concern, data access, is especially germane for medicine, as privacy barriers are important considerations for data sharing. However, by definition, replication does not require access to the original data or code because a replication exercise examines the extent to which the original phenomenon generalizes to new contexts and new populations. This Viewpoint focuses on reproducibility, even though it is important to acknowledge that replication is often the ultimate goal. Replication is especially important for studies that use observational data (which is almost always the case for machine learning studies) because these dataareoftenbiased,andmodelscouldoperationalizethis bias if not replicated. The challenges of reproducing a machinelearningmodeltrainedbyanotherresearchteamcan be difficult, perhaps even prohibitively so, even with unfettered access to raw data and code.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",44,"2022-07-13 10:06:04","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
57,"Lal Hussain","Detecting epileptic seizure with different feature extracting strategies using robust machine learning classification techniques by applying advance parameter optimization approach",2018,"","","","",45,"2022-07-13 10:06:04","","10.1007/s11571-018-9477-1","","",,,,,57,14.25,57,1,4,"","",""
101,"G. Lecu'e, M. Lerasle","Robust machine learning by median-of-means: Theory and practice",2017,"","","","",46,"2022-07-13 10:06:04","","10.1214/19-AOS1828","","",,,,,101,20.20,51,2,5,"We introduce new estimators for robust machine learning based on median-of-means (MOM) estimators of the mean of real valued random variables. These estimators achieve optimal rates of convergence under minimal assumptions on the dataset. The dataset may also have been corrupted by outliers on which no assumption is granted. We also analyze these new estimators with standard tools from robust statistics. In particular, we revisit the concept of breakdown point. We modify the original definition by studying the number of outliers that a dataset can contain without deteriorating the estimation properties of a given estimator. This new notion of breakdown number, that takes into account the statistical performances of the estimators, is non-asymptotic in nature and adapted for machine learning purposes. We proved that the breakdown number of our estimator is of the order of (number of observations)*(rate of convergence). For instance, the breakdown number of our estimators for the problem of estimation of a d-dimensional vector with a noise variance sigma^2 is sigma^2d and it becomes sigma^2 s log(d/s) when this vector has only s non-zero component. Beyond this breakdown point, we proved that the rate of convergence achieved by our estimator is (number of outliers) divided by (number of observation).  Besides these theoretical guarantees, the major improvement brought by these new estimators is that they are easily computable in practice. In fact, basically any algorithm used to approximate the standard Empirical Risk Minimizer (or its regularized versions) has a robust version approximating our estimators. As a proof of concept, we study many algorithms for the classical LASSO estimator. A byproduct of the MOM algorithms is a measure of depth of data that can be used to detect outliers.","",""
34,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, Semeen Rehman, M. Shafique","Robust Machine Learning Systems: Reliability and Security for Deep Neural Networks",2018,"","","","",47,"2022-07-13 10:06:04","","10.1109/IOLTS.2018.8474192","","",,,,,34,8.50,7,5,4,"Machine learning is commonly being used in almost all the areas that involve advanced data analytics and intelligent control. From applications like Natural Language Processing (NLP) to autonomous driving are based upon machine learning algorithms. An increasing trend is observed in the use of Deep Neural Networks (DNNs) for such applications. While the slight inaccuracy in applications like NLP does not have any severe consequences, it is not the same for other safety-critical applications, like autonomous driving and smart healthcare, where a small error can lead to catastrophic effects. Apart from high-accuracy DNN algorithms, there is a significant need for robust machine learning systems and hardware architectures that can generate reliable and trustworthy results in the presence of hardware-level faults while also preserving security and privacy. This paper provides an overview of the challenges being faced in ensuring reliable and secure execution of DNNs. To address the challenges, we present several techniques for analyzing and mitigating the reliability and security threats in machine learning systems.","",""
189,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, F. Hutter","Auto-sklearn: Efficient and Robust Automated Machine Learning",2019,"","","","",48,"2022-07-13 10:06:04","","10.1007/978-3-030-05318-5_6","","",,,,,189,63.00,32,6,3,"","",""
0,"E. Kondrateva, Polina Belozerova, M. Sharaev, Evgeny Burnaev, A. Bernstein, I. Samotaeva","Machine learning models reproducibility and validation for MR images recognition",2020,"","","","",49,"2022-07-13 10:06:04","","10.1117/12.2559525","","",,,,,0,0.00,0,6,2,"In the present work, we introduce a data processing and analysis pipeline, which ensures the reproducibility of machine learning models chosen for MR image recognition. The proposed pipeline is applied to solve the binary classification problems: epilepsy and depression diagnostics based on vectorized features from MR images. This model is then assessed in terms of classification performance, robustness and reliability of the results, including predictive accuracy on unseen data. The classification performance achieved with our approach compares favorably to ones reported in the literature, where usually no thorough model evaluation is performed.","",""
209,"J. Blanchet, Yang Kang, M. KarthyekRajhaaA.","Robust Wasserstein profile inference and applications to machine learning",2016,"","","","",50,"2022-07-13 10:06:04","","10.1017/jpr.2019.49","","",,,,,209,34.83,70,3,6,"We show that several machine learning estimators, including square-root least absolute shrinkage and selection and regularized logistic regression, can be represented as solutions to distributionally robust optimization problems. The associated uncertainty regions are based on suitably defined Wasserstein distances. Hence, our representations allow us to view regularization as a result of introducing an artificial adversary that perturbs the empirical distribution to account for out-of-sample effects in loss estimation. In addition, we introduce RWPI (robust Wasserstein profile inference), a novel inference methodology which extends the use of methods inspired by empirical likelihood to the setting of optimal transport costs (of which Wasserstein distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence we are able to choose regularization parameters for these machine learning estimators without the use of cross validation. Numerical experiments are also given to validate our theoretical findings.","",""
43,"B. Koçak, Ece Ateş, E. S. Durmaz, M. Ulusan, O. Kilickesmez","Influence of segmentation margin on machine learning–based high-dimensional quantitative CT texture analysis: a reproducibility study on renal clear cell carcinomas",2019,"","","","",51,"2022-07-13 10:06:04","","10.1007/s00330-019-6003-8","","",,,,,43,14.33,9,5,3,"","",""
31,"Matthew B. A. McDermott, Shirly Wang, N. Marinsek, R. Ranganath, M. Ghassemi, L. Foschini","Reproducibility in Machine Learning for Health",2019,"","","","",52,"2022-07-13 10:06:04","","","","",,,,,31,10.33,5,6,3,"Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning.  In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.","",""
665,"Weihua Hu, Matthias Fey, M. Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, J. Leskovec","Open Graph Benchmark: Datasets for Machine Learning on Graphs",2020,"","","","",53,"2022-07-13 10:06:04","","","","",,,,,665,332.50,83,8,2,"We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .","",""
0,"H. Anh, Cao Van Kien","Robust extreme learning machine neural approach for uncertain nonlinear hyper‐chaotic system identification",2021,"","","","",54,"2022-07-13 10:06:04","","10.1002/rnc.5756","","",,,,,0,0.00,0,2,1,"This paper proposes a novel nonlinearly parameterized advanced single‐hidden layer neural extreme learning machine (ASHLN‐ELM) model in which the hidden and output weighting values are simultaneously updated using adaptively robust rules that are implemented based on Lyapunov stability principle. The proposed scheme guarantees the fast convergence speed of the state‐estimation residual errors bounded to null regarding to the influence of time‐varied disturbances. Additionally, proposed method needs no any knowledge related to desired weighting values or required approximating error. Typical uncertain hyper‐chaotic benchmark systems are used as to verify the new ASHLN‐ELM approach and to demonstrate the efficiency and the robustness of proposed method.","",""
0,"Jha","Robust Optimization for Trajectory-Centric Model-based Reinforcement Learning /Author=Jha, D.; Kolaric, P.; Romeres, D.; Raghunathan, A.; Benosman, M.; Nikovski, D.N. /CreationDate=December 18, 2019 /Subject=Control, Machine Learning, Robotics",2019,"","","","",55,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,1,3,"This paper presents a method to perform robust trajectory optimization for trajectory-centric Model-based Reinforcement Learning (MBRL). We propose a method that allows us to use the uncertainty estimates present in predictions obtained from a model-learning algorithm to generate robustness certificates for trajectory optimization. This is done by simultaneously solving for a time-invariant controller which is optimized to satisfy a constraint to generate the robustness certificate. We first present a novel formulation of the proposed method for the robust optimization that incorporates use of local sets around a trajectory where the closed-loop dynamics of the system is stabilized using a time-invariant policy. The method is demonstrated on an inverted pendulum system with parametric uncertainty. A Gaussian process is used to learn the residual dynamics and the uncertainty sets generated by the Gaussian process are then used to generate the trajectories with the local stabilizing policy. NeurIPS Workshop on Safety and Robustness in Decision Making This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2019 201 Broadway, Cambridge, Massachusetts 02139 Robust Optimization for Trajectory-Centric Model-based Reinforcement Learning Patrik Kolaric Univ. of Texas at Arlington Fort Worth, TX patrik.kolaric@mavs.uta.edu Devesh K. Jha MERL Cambridge, MA jha@merl.com Diego Romeres MERL Cambridge, MA romeres@merl.com Arvind U. Raghunathan MERL Cambridge, MA raghunathan@merl.com Mouhacine Benosman MERL Cambridge, MA benosman@merl.com Daniel Nikovski MERL Cambridge, MA nikovski@merl.com","",""
139,"T. Luechtefeld, Dan Marsh, C. Rowlands, T. Hartung","Machine Learning of Toxicological Big Data Enables Read-Across Structure Activity Relationships (RASAR) Outperforming Animal Test Reproducibility",2018,"","","","",56,"2022-07-13 10:06:04","","10.1093/toxsci/kfy152","","",,,,,139,34.75,35,4,4,"Abstract Earlier we created a chemical hazard database via natural language processing of dossiers submitted to the European Chemical Agency with approximately 10 000 chemicals. We identified repeat OECD guideline tests to establish reproducibility of acute oral and dermal toxicity, eye and skin irritation, mutagenicity and skin sensitization. Based on 350–700+ chemicals each, the probability that an OECD guideline animal test would output the same result in a repeat test was 78%–96% (sensitivity 50%–87%). An expanded database with more than 866 000 chemical properties/hazards was used as training data and to model health hazards and chemical properties. The constructed models automate and extend the read-across method of chemical classification. The novel models called RASARs (read-across structure activity relationship) use binary fingerprints and Jaccard distance to define chemical similarity. A large chemical similarity adjacency matrix is constructed from this similarity metric and is used to derive feature vectors for supervised learning. We show results on 9 health hazards from 2 kinds of RASARs—“Simple” and “Data Fusion”. The “Simple” RASAR seeks to duplicate the traditional read-across method, predicting hazard from chemical analogs with known hazard data. The “Data Fusion” RASAR extends this concept by creating large feature vectors from all available property data rather than only the modeled hazard. Simple RASAR models tested in cross-validation achieve 70%–80% balanced accuracies with constraints on tested compounds. Cross validation of data fusion RASARs show balanced accuracies in the 80%–95% range across 9 health hazards with no constraints on tested compounds.","",""
11,"B. Celik, J. Vanschoren","Adaptation Strategies for Automated Machine Learning on Evolving Data",2020,"","","","",57,"2022-07-13 10:06:04","","10.1109/TPAMI.2021.3062900","","",,,,,11,5.50,6,2,2,"Automated Machine Learning (AutoML) systems have been shown to efficiently build good models for new datasets. However, it is often not clear how well they can adapt when the data evolves over time. The main goal of this study is to understand the effect of concept drift on the performance of AutoML methods, and which adaptation strategies can be employed to make them more robust to changes in the underlying data. To that end, we propose 6 concept drift adaptation strategies and evaluate their effectiveness on a variety of AutoML approaches for building machine learning pipelines, including Bayesian optimization, genetic programming, and random search with automated stacking. These are evaluated empirically on real-world and synthetic data streams with different types of concept drift. Based on this analysis, we propose ways to develop more sophisticated and robust AutoML techniques.","",""
9,"Doris Xin, Hui Miao, Aditya G. Parameswaran, Neoklis Polyzotis","Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities",2021,"","","","",58,"2022-07-13 10:06:04","","10.1145/3448016.3457566","","",,,,,9,9.00,2,4,1,"Machine learning (ML) is now commonplace, powering data-driven applications in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple times on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for optimization, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can reduce wasted computation cost by 50% without compromising the model deployment cadence.","",""
6,"O. Spjuth, Jens Frid, A. Hellander","The machine learning life cycle and the cloud: implications for drug discovery",2021,"","","","",59,"2022-07-13 10:06:04","","10.1080/17460441.2021.1932812","","",,,,,6,6.00,2,3,1,"ABSTRACT Introduction: Artificial intelligence (AI) and machine learning (ML) are increasingly used in many aspects of drug discovery. Larger data sizes and methods such as Deep Neural Networks contribute to challenges in data management, the required software stack, and computational infrastructure. There is an increasing need in drug discovery to continuously re-train models and make them available in production environments. Areas covered: This article describes how cloud computing can aid the ML life cycle in drug discovery. The authors discuss opportunities with containerization and scientific workflows and introduce the concept of MLOps and describe how it can facilitate reproducible and robust ML modeling in drug discovery organizations. They also discuss ML on private, sensitive and regulated data. Expert opinion: Cloud computing offers a compelling suite of building blocks to sustain the ML life cycle integrated in iterative drug discovery. Containerization and platforms such as Kubernetes together with scientific workflows can enable reproducible and resilient analysis pipelines, and the elasticity and flexibility of cloud infrastructures enables scalable and efficient access to compute resources. Drug discovery commonly involves working with sensitive or private data, and cloud computing and federated learning can contribute toward enabling collaborative drug discovery within and between organizations. Abbreviations: AI = Artificial Intelligence; DL = Deep Learning; GPU = Graphics Processing Unit; IaaS = Infrastructure as a Service; K8S = Kubernetes; ML = Machine Learning; MLOps = Machine Learning and Operations; PaaS = Platform as a Service; QC = Quality Control; SaaS = Software as a Service","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",60,"2022-07-13 10:06:04","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
6,"Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, Jie Tang","Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning",2021,"","","","",61,"2022-07-13 10:06:04","","","","",,,,,6,6.00,1,8,1,"Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.","",""
3,"","Moving towards reproducible machine learning",2021,"","","","",62,"2022-07-13 10:06:04","","10.1038/s43588-021-00152-6","","",,,,,3,3.00,0,0,1,"","",""
2,"Yifeng Gao, Hosein Mohammadi Makrani, Mehrdad Aliasgari, Amin Rezaei, Jessica Lin, H. Homayoun, H. Sayadi","Adaptive-HMD: Accurate and Cost-Efficient Machine Learning-Driven Malware Detection using Microarchitectural Events",2021,"","","","",63,"2022-07-13 10:06:04","","10.1109/IOLTS52814.2021.9486701","","",,,,,2,2.00,0,7,1,"To address the high complexity and computational overheads of conventional software-based detection techniques, Hardware Malware Detection (HMD) has shown promising results as an alternative anomaly detection solution. HMD methods apply Machine Learning (ML) classifiers on microarchitectural events monitored by built-in Hardware Performance Counter (HPC) registers available in modern microprocessors to recognize the patterns of anomalies (e.g., signatures of malicious applications). Existing hardware malware detection solutions have mainly focused on utilizing standard ML algorithms to detect the existence of malware without considering an adaptive and cost-efficient approach for online malware detection. Our comprehensive analysis across a wide range of malicious software applications and different branches of machine learning algorithms indicates that the type of adopted ML algorithm to detect malicious applications at the hardware level highly correlates with the type of the examined malware, and the ultimate performance evaluation metric (F-measure, robustness, latency, detection rate/cost, etc.) to select the most efficient ML model for distinguishing the target malware from benign program. Therefore, in this work we propose Adaptive-HMD, an accurate and cost-efficient machine learning-driven framework for online malware detection using low-level microarchitectural events collected from HPC registers. Adaptive-HMD is equipped with a lightweight tree-based decision-making algorithm that accurately selects the most efficient ML model to be used for the inference in online malware detection according to the users' preference and optimal performance vs. cost (hardware overhead and latency) criteria. The experimental results demonstrate that Adaptive-HMD achieves up to 94% detection rate (F-measure) while improving the cost-efficiency of ML-based malware detection by more than 5X as compared to existing ensemble-based malware detection methods.","",""
0,"Ni Hanwen, Li Zhanfeng","An adaptive online machine learning method based on a robust optimal control approach",2018,"","","","",64,"2022-07-13 10:06:04","","10.1360/SCM-2017-0308","","",,,,,0,0.00,0,2,4,"Reproducing kernel Hilbert space (RKHS) based models are promisingones for image processing, function approximation, patternrecognition, data mining problems and also have shown theireffectiveness in the system identification of nonlinear stochasticdynamical systems. In this paper, a novel control approach to theonline learning (regression) problems of RKHS based models isstudied in order to develop efficient algorithms with real time andadaptive parameter updates. To this aim, the learning 问题 forstochastic dynamical systems is reasonably translated into an outputfeedback control 问题 for discrete time varying linear dynamicalsystems with bounded random disturbances by some established newresults for RKHS, and an adaptive robust control algorithm istherefore developed for the learning 问题 using the robustoptimal model predictive control techniques. Compared with theexisting online kernel learning methods, the proposed one canrealize real time model parameter update without introducing anydata window principle, pruning technique, adjusting of learningsteps and any assumptions on random noise to achieve accurate onlinemodeling performance for stochastic dynamics with abrupt changes,and meanwhile guarantee the fast and robust convergence. Moreover, thisstudy could be the first attempt to use a kernel method to tackle theonline learning problems from the perspective of robustoptimal control theory. And under the proposed learning framework,existing well established control techniques can be potentiallyutilized to develop new robust learning methods, resultantly somenovel insight for kernel learning theory is provided as well.Theoretical analysis, numeral examples and comparisons are alsogiven to demonstrate our results.","",""
1,"Vikrant V. Jadhav, C. Pennock, A. Subramaniam, R. Sagar, P. K. Nayak","UOCS – III. UVIT catalogue of open clusters with machine learning-based membership using Gaia EDR3 astrometry",2021,"","","","",65,"2022-07-13 10:06:04","","10.1093/mnras/stab213","","",,,,,1,1.00,0,5,1,"We present a study of six open clusters (Berkeley 67, King 2, NGC 2420, NGC 2477, NGC 2682 and NGC 6940) using the Ultra Violet Imaging Telescope (UVIT) aboard ASTROSAT and Gaia EDR3. We used combinations of astrometric, photometric and systematic parameters to train and supervise a machine learning algorithm along with a Gaussian mixture model for the determination of cluster membership. This technique is robust, reproducible and versatile in various cluster environments. In this study, the Gaia EDR3 membership catalogues are provided along with classification of the stars as members, candidates and field in the six clusters. We could detect 200–2500 additional members using our method with respect to previous studies, which helped estimate mean space velocities, distances, number of members and core radii. UVIT photometric catalogues, which include blue stragglers, main-sequence and red giants are also provided. From UV–Optical colour-magnitude diagrams, we found that majority of the sources in NGC 2682 and a few in NGC 2420, NGC 2477 and NGC 6940 showed excess UV flux. NGC 2682 images have ten white dwarf detection in far-UV. The far-UV and near-UV images of the massive cluster NGC 2477 have 92 and 576 members respectively, which will be useful to study the UV properties of stars in the extended turn-off and in various evolutionary stages from main-sequence to red clump. Future studies will carry out panchromatic and spectroscopic analysis of noteworthy members detected in this study.","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",66,"2022-07-13 10:06:04","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
2,"Recep Onler, Ahmet Selim Koca, Baris Kirim, E. Soylemez","Multi-objective optimization of binder jet additive manufacturing of Co-Cr-Mo using machine learning",2021,"","","","",67,"2022-07-13 10:06:04","","10.1007/s00170-021-08183-z","","",,,,,2,2.00,1,4,1,"","",""
2,"Martina Bertazzo, D. Gobbo, S. Decherchi, A. Cavalli","Machine Learning and Enhanced Sampling Simulations for Computing the Potential of Mean Force and Standard Binding Free Energy",2021,"","","","",68,"2022-07-13 10:06:04","","10.1021/acs.jctc.1c00177","","",,,,,2,2.00,1,4,1,"Computational capabilities are rapidly increasing, primarily because of the availability of GPU-based architectures. This creates unprecedented simulative possibilities for the systematic and robust computation of thermodynamic observables, including the free energy of a drug binding to a target. In contrast to calculations of relative binding free energy, which are nowadays widely exploited for drug discovery, we here push the boundary of computing the binding free energy and the potential of mean force. We introduce a novel protocol that leverages enhanced sampling, machine learning, and ad hoc algorithms to limit human intervention, computing time, and free parameters in free energy calculations. We first validate the method on a host–guest system, and then we apply the protocol to glycogen synthase kinase 3 beta, a protein kinase of pharmacological interest. Overall, we obtain a good correlation with experimental values in relative and absolute terms. While we focus on protein–ligand binding, the strategy is of broad applicability to any complex event that can be described with a path collective variable. We systematically discuss key details that influence the final result. The parameters and simulation settings are available at PLUMED-NEST to allow full reproducibility.","",""
2,"Vuong Van Pham, E. Fathi, Fatemeh Belyadi","New Hybrid Approach for Developing Automated Machine Learning Workflows: A Real Case Application in Evaluation of Marcellus Shale Gas Production",2021,"","","","",69,"2022-07-13 10:06:04","","10.3390/fuels2030017","","",,,,,2,2.00,1,3,1,"The success of machine learning (ML) techniques implemented in different industries heavily rely on operator expertise and domain knowledge, which is used in manually choosing an algorithm and setting up the specific algorithm parameters for a problem. Due to the manual nature of model selection and parameter tuning, it is impossible to quantify or evaluate the quality of this manual process, which in turn limits the ability to perform comparison studies between different algorithms. In this study, we propose a new hybrid approach for developing machine learning workflows to help automated algorithm selection and hyperparameter optimization. The proposed approach provides a robust, reproducible, and unbiased workflow that can be quantified and validated using different scoring metrics. We have used the most common workflows implemented in the application of artificial intelligence (AI) and ML in engineering problems including grid/random search, Bayesian search and optimization, genetic programming, and compared that with our new hybrid approach that includes the integration of Tree-based Pipeline Optimization Tool (TPOT) and Bayesian optimization. The performance of each workflow is quantified using different scoring metrics such as Pearson correlation (i.e., R2 correlation) and Mean Square Error (i.e., MSE). For this purpose, actual field data obtained from 1567 gas wells in Marcellus Shale, with 121 features from reservoir, drilling, completion, stimulation, and operation is tested using different proposed workflows. A proposed new hybrid workflow is then used to evaluate the type well used for evaluation of Marcellus shale gas production. In conclusion, our automated hybrid approach showed significant improvement in comparison to other proposed workflows using both scoring matrices. The new hybrid approach provides a practical tool that supports the automated model and hyperparameter selection, which is tested using real field data that can be implemented in solving different engineering problems using artificial intelligence and machine learning. The new hybrid model is tested in a real field and compared with conventional type wells developed by field engineers. It is found that the type well of the field is very close to P50 predictions of the field, which shows great success in the completion design of the field performed by field engineers. It also shows that the field average production could have been improved by 8% if shorter cluster spacing and higher proppant loading per cluster were used during the frac jobs.","",""
0,"N. Kirlic, E. Akeman, Danielle C DeVille, Hung-wen Yeh, K. Cosgrove, Timothy McDermott, James Touthang, A. Clausen, M. Paulus, R. Aupperle","A machine learning analysis of risk and protective factors of suicidal thoughts and behaviors in college students.",2021,"","","","",70,"2022-07-13 10:06:04","","10.1080/07448481.2021.1947841","","",,,,,0,0.00,0,10,1,"OBJECTIVE To identify robust and reproducible factors associated with suicidal thoughts and behaviors (STBs) in college students.   METHODS 356 first-year university students completed a large battery of demographic and clinically-relevant self-report measures during the first semester of college and end-of-year (n = 228). Suicide Behaviors Questionnaire-Revised (SBQ-R) assessed STBs. A machine learning (ML) pipeline using stacking and nested cross-validation examined correlates of SBQ-R scores.   RESULTS 9.6% of students were identified at significant STBs risk by the SBQ-R. The ML algorithm explained 28.3% of variance (95%CI: 28-28.5%) in baseline SBQ-R scores, with depression severity, social isolation, meaning and purpose in life, and positive affect among the most important factors. There was a significant reduction in STBs at end-of-year with only 1.8% of students identified at significant risk.   CONCLUSION Analyses replicated known factors associated with STBs during the first semester of college and identified novel, potentially modifiable factors including positive affect and social connectedness.","",""
0,"Olga Gorodetskaya, Yana L. Gobareva, M. Koroteev","A Machine Learning Pipeline for Forecasting Time Series in the Banking Sector",2021,"","","","",71,"2022-07-13 10:06:04","","10.3390/economies9040205","","",,,,,0,0.00,0,3,1,"The problem of forecasting time series is very widely debated. In recent years, machine learning algorithms have been very prolific in this area. This paper describes a systematic approach to building a machine learning predictive model for solving optimization problems in the banking sector. A literature analysis on applying such methods in this particular area is presented. As a direct result of the described research, a universal scenario for forecasting various non-stationary time series in automatic mode was developed. The developed scenario for solving specific banking tasks to improve business efficiency, including optimizing demand for ATMs, forecasting the load on the call center and cash center, is considered. A machine learning methodology in economics that can yield robust and reproducible results and can be reused in solving other similar tasks is described. The methodology described in the article was tested on three cases and showed the ability to generate models that are superior in accuracy to similar predictive models described in the literature by at least three percentage points. This article will be helpful to specialists dealing with the problem of forecasting economic time series and students and researchers due to a large number of links to systematic literature reviews on this topic.","",""
0,"Yinyihong Liu","Airbnb Pricing Based on Statistical Machine Learning Models",2021,"","","","",72,"2022-07-13 10:06:04","","10.1109/CONF-SPML54095.2021.00042","","",,,,,0,0.00,0,1,1,"Being one of the largest online accommodation booking platforms, Airbnb has many hosts who are seeking for more proper prices to increase their booking rate. To develop a good pricing prediction model, this paper has employed machine learning models including KNN, MLR, LASSO regression, Ridge regression, Random Forest, Gradient Boosting and XGBoost etc. While past studies on Airbnb pricing have applied quantitative pricing, some face the problems that the models are not robust enough and some face the problem of not training the model plentily. To fill this gap, we give careful consideration in exploratory data analysis to make the dataset more reasonable, apply many robust models ranging from regularized regression to ensemble models and use cross validation and random search to tune each parameter in each model. In this way, we not only select XGBoost as the best model for price prediction with R2 score 0.6321, but also uncover the features which have statistical significance with the target price.","",""
0,"Uma Gunasilan","Debate as a learning activity for teaching programming: a case in the subject of machine learning",2021,"","","","",73,"2022-07-13 10:06:04","","10.1108/heswbl-01-2021-0006","","",,,,,0,0.00,0,1,1,"PurposeDebates are well known to encompass a variety of skills we would like higher education candidates to embody when they graduate.Design/methodology/approachDebates in a classroom with computer science as the main subject has been popular in high schools particularly with emerging issues around the area, however it does not have as an extensive similar documented outreach in tertiary education, particularly in the area of hard computer sciences and more recent concentrations of computer science, such as machine learning, artificial intelligence and cloud computing.FindingsTo explore further, the debate dataset had more methodologies applied and was split into training and testing sets, whose results were then compared by a standardized measure: Root Mean Square Error (RMSE) which is currently standard in the industry. The rationale of the approach is to quantify that debate activities have an immensely positive impact towards both the teaching and learning in technical subjects and needs to be more often and robustly used within higher education.Originality/valueThe rationale of the approach is that classroom debate activities equip students with verbal and social learning styles and an opportunity to engage with content in a way that is more comfortable than working with traditional lecture-and-laboratory style learning.","",""
0,"Yan Zhou, Murat Kantarcioglu, B. Xi","A Game Theoretic Perspective on Adversarial Machine Learning and Related Cybersecurity Applications",2021,"","","","",74,"2022-07-13 10:06:04","","10.1002/9781119723950.ch13","","",,,,,0,0.00,0,3,1,"In cybersecurity applications where machine learning algorithms are increasingly used to detect vulnerabilities, a somewhat unique challenge arises as exploits targeting machine learning models are constantly devised by the attackers. Traditional machine learning models are no longer robust and reliable when they are under attack. The action and reaction between machine learning systems and the adversary can be modeled as a game between two or more players. Under well‐defined attack models, game theory can provide robustness guarantee for machine learning models that are otherwise vulnerable to application‐time data corruption. We review two cases of game theory‐based machine learning techniques: in one case, players play a zero sum game by following a minimax strategy, while in the other case, players play a sequential game with one player as the leader and the rest as the followers. Experimental results on e‐mail spam and web spam datasets are presented. In the zero sum game, we demonstrate that an adversarial SVM model built upon the minimax strategy is much more resilient to adversarial attacks than standard SVM and one‐class SVM models. We also show that optimal learning strategies derived to counter overly pessimistic attack models can produce unsatisfactory results when the real attacks are much weaker. In the sequential game, we demonstrate that the mixed strategy, allowing a player to randomize over available strategies, is the best solution in general without knowing what types of adversaries machine learning applications are facing in the wild. We also discuss scenarios where players' behavior may derail rational decision making and models that consider such decision risks.","",""
26,"A. Michel, A. Morrison, Victoria L. Preston, Charles T. Marx, Beckett C. Colson, H. K. White","Rapid Identification of Marine Plastic Debris via Spectroscopic Techniques and Machine Learning Classifiers.",2020,"","","","",75,"2022-07-13 10:06:04","","10.1021/acs.est.0c02099","","",,,,,26,13.00,4,6,2,"To advance our understanding of the environmental fate and transport of macro- and micro-plastic debris, robust and reproducible methods, technologies, and analytical approaches are necessary for in situ plastic-type identification and characterization. This investigation compares four spectroscopic techniques: attenuated total reflectance - Fourier transform infrared spectroscopy (ATR-FTIR), near-infrared (NIR) reflectance spectroscopy, laser-induced breakdown spectroscopy (LIBS), and X-ray fluorescence (XRF) spectroscopy, coupled to seven classification methods, including machine learning classifiers, to determine accuracy for identifying type of both consumer plastics and marine plastic debris. With machine learning classifiers, consumer plastic types were identified with 99%, 91%, 97%, and 70% success rates for ATR-FTIR, NIR reflectance spectroscopy, LIBS, and XRF respectively. The classification of marine plastic debris had similar or lower success rates likely arising from alterations to the plastic from environmental weathering processes with success rates of 99%, 81%, 76%, and 66% for ATR-FTIR, NIR reflectance spectroscopy, LIBS, and XRF respectively. Success rates of 76% and higher indicate that ATR-FTIR, NIR reflectance spectroscopy, and LIBS coupled to machine learning classifiers can be used to robustly identify both consumer and environmental plastic samples.","",""
0,"Farzad Hasani, S. Shabanlou","Outlier robust extreme learning machine to simulate discharge coefficient of side slots",2022,"","","","",76,"2022-07-13 10:06:04","","10.1007/s13201-022-01687-3","","",,,,,0,0.00,0,2,1,"","",""
3,"Dohoon Lee, Youngjune Park, Sun Kim","Towards multi-omics characterization of tumor heterogeneity: a comprehensive review of statistical and machine learning approaches",2020,"","","","",77,"2022-07-13 10:06:04","","10.1093/bib/bbaa188","","",,,,,3,1.50,1,3,2,"The multi-omics molecular characterization of cancer opened a new horizon for our understanding of cancer biology and therapeutic strategies. However, a tumor biopsy comprises diverse types of cells limited not only to cancerous cells but also to tumor microenvironmental cells and adjacent normal cells. This heterogeneity is a major confounding factor that hampers a robust and reproducible bioinformatic analysis for biomarker identification using multi-omics profiles. Besides, the heterogeneity itself has been recognized over the years for its significant prognostic values in some cancer types, thus offering another promising avenue for therapeutic intervention. A number of computational approaches to unravel such heterogeneity from high-throughput molecular profiles of a tumor sample have been proposed, but most of them rely on the data from an individual omics layer. Since the heterogeneity of cells is widely distributed across multi-omics layers, methods based on an individual layer can only partially characterize the heterogeneous admixture of cells. To help facilitate further development of the methodologies that synchronously account for several multi-omics profiles, we wrote a comprehensive review of diverse approaches to characterize tumor heterogeneity based on three different omics layers: genome, epigenome and transcriptome. As a result, this review can be useful for the analysis of multi-omics profiles produced by many large-scale consortia. Contact:sunkim.bioinfo@snu.ac.kr.","",""
3,"Dohoon Lee, Youngjune Park, Sun Kim","Towards multi-omics characterization of tumor heterogeneity: a comprehensive review of statistical and machine learning approaches.",2021,"","","","",78,"2022-07-13 10:06:04","","10.1093/bib/bbaa188","","",,,,,3,3.00,1,3,1,"The multi-omics molecular characterization of cancer opened a new horizon for our understanding of cancer biology and therapeutic strategies. However, a tumor biopsy comprises diverse types of cells limited not only to cancerous cells but also to tumor microenvironmental cells and adjacent normal cells. This heterogeneity is a major confounding factor that hampers a robust and reproducible bioinformatic analysis for biomarker identification using multi-omics profiles. Besides, the heterogeneity itself has been recognized over the years for its significant prognostic values in some cancer types, thus offering another promising avenue for therapeutic intervention. A number of computational approaches to unravel such heterogeneity from high-throughput molecular profiles of a tumor sample have been proposed, but most of them rely on the data from an individual omics layer. Since the heterogeneity of cells is widely distributed across multi-omics layers, methods based on an individual layer can only partially characterize the heterogeneous admixture of cells. To help facilitate further development of the methodologies that synchronously account for several multi-omics profiles, we wrote a comprehensive review of diverse approaches to characterize tumor heterogeneity based on three different omics layers: genome, epigenome and transcriptome. As a result, this review can be useful for the analysis of multi-omics profiles produced by many large-scale consortia. Contact:sunkim.bioinfo@snu.ac.kr.","",""
0,"T. Martin, S. Areibi, G. Grewal","Effective Machine-Learning Models for Predicting Routability During FPGA Placement",2021,"","","","",79,"2022-07-13 10:06:04","","10.1109/MLCAD52597.2021.9531243","","",,,,,0,0.00,0,3,1,"The ability to efficiently and accurately predict placement routability, while avoiding the large computational cost of performing routing, is an asset when seeking to reduce total placement and routing runtime. In this paper, we present a series of simple ML models and ensembles to predict the routability of a placement solution. Ensembles based on Bagging, Boosting and Stack of classifiers are introduced to produce more accurate and robust solutions than single/simple models. Our results show an improvement in prediction accuracy and runtime compared to the best published results in the literature.","",""
14,"L. Claude, J. Houenou, E. Duchesnay, P. Favre","Will machine learning applied to neuroimaging in bipolar disorder help the clinician? A critical review and methodological suggestions",2020,"","","","",80,"2022-07-13 10:06:04","","10.1111/bdi.12895","","",,,,,14,7.00,4,4,2,"The existence of anatomofunctional brain abnormalities in bipolar disorder (BD) is now well established by magnetic resonance imaging (MRI) studies. To create diagnostic and prognostic tools, as well as identifying biologically valid subtypes of BD, research has recently turned towards the use of machine learning (ML) techniques. We assessed both supervised ML and unsupervised ML studies in BD to evaluate their robustness, reproducibility and the potential need for improvement.","",""
21,"Aaron M. Smith, J. Walsh, John J Long, Craig B Davis, Peter V. Henstock, M. Hodge, M. Maciejewski, X. Mu, Stephen Ra, Shanrong Zhao, D. Ziemek, Charles K. Fisher","Standard machine learning approaches outperform deep representation learning on phenotype prediction from transcriptomics data",2020,"","","","",81,"2022-07-13 10:06:04","","10.1186/s12859-020-3427-8","","",,,,,21,10.50,2,12,2,"","",""
13,"Jinlong Liu, Christopher J. Ulishney, C. Dumitrescu","Random Forest Machine Learning Model for Predicting Combustion Feedback Information of a Natural Gas Spark Ignition Engine",2020,"","","","",82,"2022-07-13 10:06:04","","10.1115/1.4047761","","",,,,,13,6.50,4,3,2,"  Engine calibration requires detailed feedback information that can reflect the combustion process as the optimized objective. Indicated mean effective pressure (IMEP) is such an indicator describing an engine’s capacity to do work under different combinations of control variables. In this context, it is of interest to find cost-effective solutions that will reduce the number of experimental tests. This paper proposes a random forest machine learning model as a cost-effective tool for optimizing engine performance. Specifically, the model estimated IMEP for a natural gas spark ignited engine obtained from a converted diesel engine. The goal was to develop an economical and robust tool that can help reduce the large number of experiments usually required throughout the design and development of internal combustion engines. The data used for building such correlative model came from engine experiments that varied the spark advance, fuel-air ratio, and engine speed. The inlet conditions and the coolant/oil temperature were maintained constant. As a result, the model inputs were the key engine operation variables that affect engine performance. The trained model was shown to be able to predict the combustion-related feedback information with good accuracy (R2 ≈ 0.9 and MSE ≈ 0). In addition, the model accurately reproduced the effect of control variables on IMEP, which would help narrow the choice of operating conditions for future designs of experiment. Overall, the machine learning approach presented here can provide new chances for cost-efficient engine analysis and diagnostics work.","",""
12,"Liangyuan Hu, Bian Liu, J. Ji, Yan Li","Tree‐Based Machine Learning to Identify and Understand Major Determinants for Stroke at the Neighborhood Level",2020,"","","","",83,"2022-07-13 10:06:04","","10.1161/JAHA.120.016745","","",,,,,12,6.00,3,4,2,"Background Stroke is a major cardiovascular disease that causes significant health and economic burden in the United States. Neighborhood community‐based interventions have been shown to be both effective and cost‐effective in preventing cardiovascular disease. There is a dearth of robust studies identifying the key determinants of cardiovascular disease and the underlying effect mechanisms at the neighborhood level. We aim to contribute to the evidence base for neighborhood cardiovascular health research. Methods and Results We created a new neighborhood health data set at the census tract level by integrating 4 types of potential predictors, including unhealthy behaviors, prevention measures, sociodemographic factors, and environmental measures from multiple data sources. We used 4 tree‐based machine learning techniques to identify the most critical neighborhood‐level factors in predicting the neighborhood‐level prevalence of stroke, and compared their predictive performance for variable selection. We further quantified the effects of the identified determinants on stroke prevalence using a Bayesian linear regression model. Of the 5 most important predictors identified by our method, higher prevalence of low physical activity, larger share of older adults, higher percentage of non‐Hispanic Black people, and higher ozone levels were associated with higher prevalence of stroke at the neighborhood level. Higher median household income was linked to lower prevalence. The most important interaction term showed an exacerbated adverse effect of aging and low physical activity on the neighborhood‐level prevalence of stroke. Conclusions Tree‐based machine learning provides insights into underlying drivers of neighborhood cardiovascular health by discovering the most important determinants from a wide range of factors in an agnostic, data‐driven, and reproducible way. The identified major determinants and the interactive mechanism can be used to prioritize and allocate resources to optimize community‐level interventions for stroke prevention.","",""
85,"P. Graff, F. Feroz, M. Hobson, A. Lasenby","SKYNET: an efficient and robust neural network training tool for machine learning in astronomy",2013,"","","","",84,"2022-07-13 10:06:04","","10.1093/mnras/stu642","","",,,,,85,9.44,21,4,9,"We present the first public release of our generic neural network training algorithm, called SKYNET. This efficient and robust machine-learning tool is able to train large and deep feedforward neural networks, including autoencoders, for use in a wide range of supervised and unsupervised learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SKYNET uses a powerful ‘pre-training’ method, to obtain a set of network parameters close to the true global maximum of the training objective function, followed by further optimisation using an automatically-regularised variant of Newton’s method; the latter uses second-order derivative information to improve convergence, but without the need to evaluate or store the full Hessian matrix, by using a fast approximate method to calculate Hessian-vector products. This combination of methods allows for the training of complicated networks that are difficult to optimise using standard backpropagation techniques. SKYNET employs convergence criteria that naturally prevent overfitting, and also includes a fast algorithm for estimating the accuracy of network outputs. The utility and flexibility of SKYNET are demonstrated by application to a number of toy problems, and to astronomical problems focusing on the recovery of structure from blurred and noisy images, the identification of gamma-ray bursters, and the compression and denoising of galaxy images. The SKYNET software, which is implemented in standard ANSI C and fully parallelised using MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/.","",""
11,"H. Jo, Javier E. Santos, M. Pyrcz","Conditioning well data to rule-based lobe model by machine learning with a generative adversarial network",2020,"","","","",85,"2022-07-13 10:06:04","","10.1177/0144598720937524","","",,,,,11,5.50,4,3,2,"Rule-based reservoir modeling methods integrate geological depositional process concepts to generate reservoir models that capture realistic geologic features for improved subsurface predictions and uncertainty models to support development decision making. However, the robust and direct conditioning of these models to subsurface data, such as well logs, core descriptions, and seismic inversions and interpretations, remains as an obstacle for the broad application as a standard subsurface modeling technology. We implement a machine learning-based method for fast and flexible data conditioning of rule-based models. This study builds on a rule-based modeling method for deep-water lobe reservoirs. The model has three geological inputs: (1) the depositional element geometry, (2) the compositional exponent for element stacking pattern, and (3) the distribution of petrophysical properties with hierarchical trends conformable to the surfaces. A deep learning-based workflow is proposed for robust and non-iterative data conditioning. First, a generative adversarial network learns salient geometric features from the ensemble of the training rule-based models. Then, a new rule-based model is generated and a mask is applied to remove the model near local data along the well trajectories. Last, semantic image inpainting restores the mask with the optimum generative adversarial network realization that is consistent with both local data and the surrounding model. For the deep-water lobe example, the generative adversarial network learns the primary geological spatial features to generate reservoir realizations that reproduce hierarchical trend as well as the surface geometries and stacking pattern. Moreover, the trained generative adversarial network explores the latent reservoir manifold and identifies the ensemble of models to represent an uncertainty model. Semantic image inpainting determines the optimum replacement for the near-data mask that is consistent with the local data and the rest of the model. This work results in subsurface models that accurately reproduce reservoir heterogeneity, continuity, and spatial distribution of petrophysical parameters while honoring the local well data constraints.","",""
7,"C. Chang, S. Ku, R. Hager, R. Churchill, J. Hughes, F. Köchl, A. Loarte, V. Parail, R. Pitts","Constructing a new predictive scaling formula for ITER's divertor heat-load width informed by a simulation-anchored machine learning",2020,"","","","",86,"2022-07-13 10:06:04","","10.1063/5.0027637","","",,,,,7,3.50,1,9,2,"Understanding and predicting divertor heat-load width λq is a critically important problem for an easier and more robust operation of ITER with high fusion gain. Previous predictive simulation data for λq using the extreme-scale edge gyrokinetic code XGC1 [S. Ku et al., Phys. Plasmas 25, 056107 (2018)] in the electrostatic limit under attached divertor plasma conditions in three major US tokamaks [C. S. Chang et al., Nucl. Fusion 57, 116023 (2017)] reproduced the Eich and Goldston attached-divertor formula results [formula #14 in T. Eich et al., Nucl. Fusion 53, 093031 (2013) and R. J. Goldston, Nucl. Fusion 52, 013009 (2012)] and furthermore predicted over six times wider λq than the maximal Eich and Goldston formula predictions on a full-power (Q = 10) scenario ITER plasma. After adding data from further predictive simulations on a highest current JET and highest-current Alcator C-Mod, a machine learning program is used to identify a new scaling formula for λq as a simple modification to the Eich formula #14, which reproduces the Eich scaling formula for the present tokamaks and which embraces the wide λqXGC for the full-current Q = 10 ITER plasma. The new formula is then successfully tested on three more ITER plasmas: two corresponding to long burning scenarios with Q = 5 and one at low plasma current to be explored in the initial phases of ITER operation. The new physics that gives rise to the wider λqXGC is identified to be the weakly collisional, trapped-electron-mode turbulence across the magnetic separatrix, which is known to be an efficient transporter of the electron heat and mass. Electromagnetic turbulence and high-collisionality effects on the new formula are the next study topics for XGC1.","",""
3,"Morten Ledum, Sigbjørn Løland Bore, M. Cascella","Automated determination of hybrid particle-field parameters by machine learning",2020,"","","","",87,"2022-07-13 10:06:04","","10.1080/00268976.2020.1785571","","",,,,,3,1.50,1,3,2,"The hybrid particle-field molecular dynamics method is an efficient alternative to standard particle-based coarse grained approaches. In this work, we propose an automated protocol for optimisation of the effective parameters that define the interaction energy density functional, based on Bayesian optimisation. The machine-learning protocol makes use of an arbitrary fitness function defined upon a set of observables of relevance, which are optimally matched by an iterative process. Employing phospholipid bilayers as test systems, we demonstrate that the parameters obtained through our protocol are able to reproduce reference data better than currently employed sets derived by Flory-Huggins models. The optimisation procedure is robust and yields physically sound values. Moreover, we show that the parameters are satisfactorily transferable among chemically analogous species. Our protocol is general, and does not require heuristic a posteriori rebalancing. Therefore it is particularly suited for optimisation of reliable hybrid particle-field potentials of complex chemical mixtures, and extends the applicability corresponding simulations to all those systems for which calibration of the density functionals may not be done via simple theoretical models. GRAPHICAL ABSTRACT","",""
15,"Chenhao Ma, B. Zhu, Xue-qiao Xu, Weixing Wang","Machine learning surrogate models for Landau fluid closure",2019,"","","","",88,"2022-07-13 10:06:04","","10.1063/1.5129158","","",,,,,15,5.00,4,4,3,"The first result of applying the machine/deep learning technique to the fluid closure problem is presented in this paper. As a start, three different types of neural networks [multilayer perceptron (MLP), convolutional neural network (CNN), and two-layer discrete Fourier transform (DFT) network] were constructed and trained to learn the well-known Hammett–Perkins Landau fluid closure in configuration space. We find that in order to train a well-preformed network, a minimum size of the training data set is needed; MLP also requires a minimum number of neurons in the hidden layers that equals the degrees of freedom in Fourier space, despite the fact that training data are being fed into the configuration space. Out of the three models, DFT performs the best for the clean data, most likely due to the existence of the simple Fourier expression for the Hammett–Perkins closure, but it is the least robust with respect to input noise. Overall, with appropriate tuning and optimization, all three neural networks are able to accurately predict the Hammett–Perkins closure and reproduce the intrinsic nonlocal feature, suggesting a promising path to calculating more sophisticated closures with the machine/deep learning technique.","",""
0,"Gabriel D. Patrón, D. León, Edwin Lopez, G. Hernández","An Interpretable Automated Machine Learning Credit Risk Model",2020,"","","","",89,"2022-07-13 10:06:04","","10.1007/978-3-030-61834-6_2","","",,,,,0,0.00,0,4,2,"","",""
0,"A. Chakrabarty, K. Berntorp, S. D. Cairano","Learning-based Parameter-Adaptive Reference Governors /Author=Chakrabarty, Ankush; Berntorp, Karl; Di Cairano, Stefano /CreationDate=July 3, 2020 /Subject=Control, Machine Learning",2020,"","","","",90,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,2,"Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example. American Control Conference (ACC) This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2020 201 Broadway, Cambridge, Massachusetts 02139 Learning-based Parameter-Adaptive Reference Governors Ankush Chakrabarty†, Karl Berntorp, Stefano Di Cairano Abstract—Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example.","",""
2,"Jian Wu, Rajal Nivargi, Sree Sai Teja Lanka, A. Menon, Sai Ajay Modukuri, Nishanth Nakshatri, Xin Wei, Zhuoer Wang, James Caverlee, S. Rajtmajer, C. Lee Giles","Predicting the Reproducibility of Social and Behavioral Science Papers Using Supervised Learning Models",2021,"","","","",91,"2022-07-13 10:06:04","","","","",,,,,2,2.00,0,11,1,"In recent years, significant effort has been invested verifying the reproducibility and robustness of research claims in social and behavioral sciences (SBS), much of which has involved resourceintensive replication projects. In this paper, we investigate prediction of the reproducibility of SBS papers using machine learning methods based on a set of features. We propose a framework that extracts five types of features from scholarly work that can be used to support assessments of reproducibility of published research claims. Bibliometric features, venue features, and author features are collected from public APIs or extracted using open source machine learning libraries with customized parsers. Statistical features, such as p-values, are extracted by recognizing patterns ar X iv :2 10 4. 04 58 0v 2 [ cs .D L ] 2 1 O ct 2 02 1 A PREPRINT OCTOBER 22, 2021 in the body text. Semantic features, such as funding information, are obtained from public APIs or are extracted using natural language processing models. We analyze pairwise correlations between individual features and their importance for predicting a set of human-assessed ground truth labels. In doing so, we identify a subset of 9 top features that play relatively more important roles in predicting the reproducibility of SBS papers in our corpus. Results are verified by comparing performances of 10 supervised predictive classifiers trained on different sets of features.","",""
2,"Moritz Lange, Henri Suominen, M. Kurppa, L. Järvi, Emilia Oikarinen, Rafael Savvides, K. Puolamäki","Machine learning models to replicate large-eddy simulations of air pollutant concentrations along boulevard-type streets",2020,"","","","",92,"2022-07-13 10:06:04","","10.5194/gmd-2020-200","","",,,,,2,1.00,0,7,2,"Abstract. Running large-eddy simulations (LES) can be burdensome and computationally too expensive from the application point-of-view for example to support urban planning. In this study, regression models are used to replicate modelled air pollutant concentrations from LES in urban boulevards. We study the performance of regression models and discuss how to detect situations where the models are applied outside their training domain and their outputs cannot be trusted. Regression models from 10 different model families are trained and a cross-validation methodology is used to evaluate their performance and to find the best set of features needed to reproduce the LES outputs. We also test the regression models on an independent testing dataset. Our results suggest that in general, log-linear regression gives the best and most robust performance on new independent data. It clearly outperforms the dummy model which would predict constant concentrations for all locations (mRMSE of 0.76 vs 1.78 of the dummy model). Furthermore, we demonstrate that it is possible to detect concept drift, i.e., situations where the model is applied outside its training domain and a new LES run may be necessary to obtain reliable results. Regression models can be used to replace LES simulations in estimating air pollutant concentrations, unless higher accuracy is needed. In order to have reliable results, it is however important to do the model and feature selection carefully to avoid over-fitting and to use methods to detect the concept drift. ","",""
2,"S. Siltanen, Takanori Ide","Electrical Impedance Tomography, Enclosure Method and Machine Learning",2020,"","","","",93,"2022-07-13 10:06:04","","10.1109/MLSP49062.2020.9231717","","",,,,,2,1.00,1,2,2,"Electrical impedance tomography (EIT) is a non-destructive imaging method, where a physical body is probed with electric measurements at the boundary, and information about the internal conductivity is extracted from the data. The enclosure method of Ikehata [J. Inv. III-Posed Prob. 8(2000)] recovers the convex hull of an inclusion of unknown conductivity embedded in known background conductivity. Practical implementations of the enclosure method are based on least-squares (LS) fitting of lines to noise-robust values of the so-called indicator function. It is shown how a convolutional neural network instead of LS fitting improves the accuracy of the enclosure method significantly while retaining interpretability.","",""
0,"D. Efremenko, Himani Jain, Jian Xu","Two Machine Learning Based Schemes for Solving Direct and Inverse Problems of Radiative Transfer Theory",2020,"","","","",94,"2022-07-13 10:06:04","","10.51130/graphicon-2020-2-3-45","","",,,,,0,0.00,0,3,2,"Artificial neural networks (ANNs) are used to substitute computationally expensive radiative transfer models (RTMs) and inverse operators (IO) for retrieving optical parameters of the medium. However, the direct parametrization of RTMs and IOs by means of ANNs has certain drawbacks, such as loss of generality, computations of huge training datasets, robustness issues etc. This paper provides an analysis of different ANN-related methods, based on our results and those published by other authors. In particular, two techniques are proposed. In the first method, the ANN substitutes the eigenvalue solver in the discrete ordinate RTM, thereby reducing the computational time. Unlike classical RTM parametrization schemes based on ANN, in this method the resulting ANN can be used for arbitrary geometry and layer optical thicknesses. In the second method, the IO is trained by using the real measurements (preprocessed Level-2 TROPOMI data) to improve the stability of the inverse operator. This method provides robust results even without applying the Tikhonov regularization method.","",""
0,"Upma Yadav, Ashok Kumar, A. Tiwari, S. Mukherjee","Machine Learning in Medical Imaging for Early Detection of Skin Diseases.",2020,"","","","",95,"2022-07-13 10:06:04","","10.35940/ijitee.e3019.049620","","",,,,,0,0.00,0,4,2,"Dermatology is a medical field that treats skin health and diseases. These skin diseases are perilous and often transmittable but can be cured or reversed with higher degree if detected at an early stage. Early detection and treatment can correct most skin disorders. Diagnosis of these diseases requires a sophisticated of proficiency due to the variety of their illustration aspects. As manual conclusion are often skewed and hardly reproducible, to achieve a more intent and undependable diagnosis, a computer aided diagnostic system should be considered. This work is to provide a comparative view of advancements the works as a robust literature of with techniques, methodology, experimented results and dataset done in medical science using medical images to predict diseases with early detection and higher accuracy .","",""
658,"Wieland Brendel, Jonas Rauber, M. Bethge","Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",2017,"","","","",96,"2022-07-13 10:06:04","","","","",,,,,658,131.60,219,3,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .","",""
66,"R. Cuocolo, Maria Brunella Cipullo, A. Stanzione, L. Ugga, V. Romeo, L. Radice, A. Brunetti, M. Imbriaco","Machine learning applications in prostate cancer magnetic resonance imaging",2019,"","","","",97,"2022-07-13 10:06:04","","10.1186/s41747-019-0109-2","","",,,,,66,22.00,8,8,3,"","",""
0,"Zhang Jing, Ren Yong-gong","Robust Multi-feature Extreme Learning Machine",2017,"","","","",98,"2022-07-13 10:06:04","","10.1007/978-3-030-01520-6_13","","",,,,,0,0.00,0,2,5,"","",""
49,"Edward Raff","A Step Toward Quantifying Independently Reproducible Machine Learning Research",2019,"","","","",99,"2022-07-13 10:06:04","","","","",,,,,49,16.33,49,1,3,"What makes a paper independently reproducible? Debates on reproducibility center around intuition or assumptions but lack empirical results. Our field focuses on releasing code, which is important, but is not sufficient for determining reproducibility. We take the first step toward a quantifiable answer by manually attempting to implement 255 papers published from 1984 until 2017, recording features of each paper, and performing statistical analysis of the results. For each paper, we did not look at the authors code, if released, in order to prevent bias toward discrepancies between code and paper.","",""
27,"A. Kokhanovskiy, A. Ivanenko, S. Kobtsev, S. Smirnov, S. Turitsyn","Machine Learning Methods for Control of Fibre Lasers with Double Gain Nonlinear Loop Mirror",2019,"","","","",100,"2022-07-13 10:06:04","","10.1038/s41598-019-39759-1","","",,,,,27,9.00,5,5,3,"","",""
27,"A. Kokhanovskiy, A. Ivanenko, S. Kobtsev, S. Smirnov, S. Turitsyn","Machine Learning Methods for Control of Fibre Lasers with Double Gain Nonlinear Loop Mirror",2019,"","","","",101,"2022-07-13 10:06:04","","10.1038/s41598-019-39759-1","","",,,,,27,9.00,5,5,3,"","",""
6,"Rudrasis Chakraborty, Liu Yang, Søren Hauberg, B. Vemuri","Intrinsic Grassmann Averages for Online Linear, Robust and Nonlinear Subspace Learning",2017,"","","","",102,"2022-07-13 10:06:04","","10.1109/tpami.2020.2992392","","",,,,,6,1.20,2,4,5,"Principal component analysis (PCA) and Kernel principal component analysis (KPCA) are fundamental methods in machine learning for dimensionality reduction. The former is a technique for finding this approximation in finite dimensions and the latter is often in an infinite dimensional reproducing Kernel Hilbert-space (RKHS). In this paper, we present a geometric framework for computing the principal linear subspaces in both (finite and infinite) situations as well as for the robust PCA case, that amounts to computing the intrinsic average on the space of all subspaces: the Grassmann manifold. Points on this manifold are defined as the subspaces spanned by <inline-formula><tex-math notation=""LaTeX"">$K$</tex-math><alternatives><mml:math><mml:mi>K</mml:mi></mml:math><inline-graphic xlink:href=""chakraborty-ieq1-2992392.gif""/></alternatives></inline-formula>-tuples of observations. The intrinsic Grassmann average of these subspaces are shown to coincide with the principal components of the observations when they are drawn from a Gaussian distribution. We show similar results in the RKHS case and provide an efficient algorithm for computing the projection onto the this average subspace. The result is a method akin to KPCA which is substantially faster. Further, we present a novel online version of the KPCA using our geometric framework. Competitive performance of all our algorithms are demonstrated on a variety of real and synthetic data sets.","",""
21,"Nidan Qiao","A systematic review on machine learning in sellar region diseases: quality and reporting items",2019,"","","","",103,"2022-07-13 10:06:04","","10.1530/EC-19-0156","","",,,,,21,7.00,21,1,3,"Introduction Machine learning methods in sellar region diseases present a particular challenge because of the complexity and the necessity for reproducibility. This systematic review aims to compile the current literature on sellar region diseases that utilized machine learning methods and to propose a quality assessment tool and reporting checklist for future studies. Methods PubMed and Web of Science were searched to identify relevant studies. The quality assessment included five categories: unmet needs, reproducibility, robustness, generalizability and clinical significance. Results Seventeen studies were included with the diagnosis of general pituitary neoplasms, acromegaly, Cushing’s disease, craniopharyngioma and growth hormone deficiency. 87.5% of the studies arbitrarily chose one or two machine learning models. One study chose ensemble models, and one study compared several models. 43.8% of studies did not provide the platform for model training, and roughly half did not offer parameters or hyperparameters. 62.5% of the studies provided a valid method to avoid over-fitting, but only five reported variations in the validation statistics. Only one study validated the algorithm in a different external database. Four studies reported how to interpret the predictors, and most studies (68.8%) suggested possible clinical applications of the developed algorithm. The workflow of a machine-learning study and the recommended reporting items were also provided based on the results. Conclusions Machine learning methods were used to predict diagnosis and posttreatment outcomes in sellar region diseases. Though most studies had substantial unmet need and proposed possible clinical application, replicability, robustness and generalizability were major limits in current studies.","",""
17,"V. Lam, Thanh Nguyen, T. Phan, B. Chung, G. Nehmetallah, C. Raub","Machine Learning with Optical Phase Signatures for Phenotypic Profiling of Cell Lines",2019,"","","","",104,"2022-07-13 10:06:04","","10.1002/cyto.a.23774","","",,,,,17,5.67,3,6,3,"Robust and reproducible profiling of cell lines is essential for phenotypic screening assays. The goals of this study were to determine robust and reproducible optical phase signatures of cell lines for classification with machine learning and to correlate optical phase parameters to motile behavior. Digital holographic microscopy (DHM) reconstructed phase maps of cells from two pairs of cancer and non‐cancer cell lines. Seventeen image parameters were extracted from each cell's phase map, used for linear support vector machine learning, and correlated to scratch wound closure and Boyden chamber chemotaxis. The classification accuracy was between 90% and 100% for the six pairwise cell line comparisons. Several phase parameters correlated with wound closure rate and chemotaxis across the four cell lines. The level of cell confluence in culture affected phase parameters in all cell lines tested. Results indicate that optical phase features of cell lines are a robust set of quantitative data of potential utility for phenotypic screening and prediction of motile behavior. © 2019 International Society for Advancement of Cytometry","",""
2,"Jiyuan Tu, Weidong Liu, Xiaojun Mao","Byzantine-robust distributed sparse learning for M-estimation",2021,"","","","",105,"2022-07-13 10:06:04","","10.1007/S10994-021-06001-X","","",,,,,2,2.00,1,3,1,"","",""
0,"Daniel C. Anderson","Comment on gmd-2022-44 Anonymous Referee # 1 Referee comment on "" A Machine Learning Methodology for the Generation of a Parameterization of the Hydroxyl Radical : a Tool to Improve Computational-Efficiency in Chemistry Climate Models",2022,"","","","",106,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,1,1,"This paper describes the application of a gradient boosted regression tree machine learning approach to derive a parameterization for tropospheric OH based on CCM simulations. The approach is shown to reproduce simulated OH well under current conditions even for cases it has not been trained on, and it behaves acceptably, albeit with increasing errors, when applied to future conditions outside the standard training set. There is substantial novelty in the approach taken, and the results offer a degree of interpretability that is very interesting. The paper is generally well structured, clearly written, and appropriately illustrated. The authors have been thorough in evaluating their approach, and it is particularly good to see robust testing of input variable choice and hyperparameter value selection. the paper approach","",""
0,"Suparna De, Harry Moss, Jon Johnson, Jenny Li, Haeron Pereira, Sanaz Jabbari","Engineering a machine learning pipeline for automating metadata extraction from longitudinal survey questionnaires",2022,"","","","",107,"2022-07-13 10:06:04","","10.29173/iq1023","","",,,,,0,0.00,0,6,1,"Data Documentation Initiative-Lifecycle (DDI-L) introduced a robust metadata model to support the capture of questionnaire content and flow, and encouraged through support for versioning and provenancing, objects such as BasedOn for the reuse of existing question items. However, the dearth of questionnaire banks including both question text and response domains has meant that an ecosystem to support the development of DDI ready Computer Assisted Interviewing (CAI) tools has been limited. Archives hold the information in PDFs associated with surveys but extracting that in an efficient manner into DDI-Lifecycle is a significant challenge.  While CLOSER Discovery has been championing the provision of high-quality questionnaire metadata in DDI-Lifecycle, this has primarily been done manually. More automated methods need to be explored to ensure scalable metadata annotation and uplift.  This paper presents initial results in engineering a machine learning (ML) pipeline to automate the extraction of questions from survey questionnaires as PDFs. Using CLOSER Discovery as a ‘training and test dataset’, a number of machine learning approaches have been explored to classify parsed text from questionnaires to be output as valid DDI items for inclusion in a DDI-L compliant repository.  The developed ML pipeline adopts a continuous build and integrate approach, with processes in place to keep track of various combinations of the structured DDI-L input metadata, ML models and model parameters against the defined evaluation metrics, thus enabling reproducibility and comparative analysis of the experiments.  Tangible outputs include a map of the various metadata and model parameters with the corresponding evaluation metrics’ values, which enable model tuning as well as transparent management of data and experiments.","",""
0,"Yiyang Chen, Wei Jiang, Themistoklis Charalambous","Machine learning based iterative learning control for non-repetitive time-varying systems",2021,"","","","",108,"2022-07-13 10:06:04","","10.1002/rnc.6272","","",,,,,0,0.00,0,3,1,"The repetitive tracking task for time-varying systems (TVSs) with non-repetitive time-varying parameters, which is also called non-repetitive TVSs, is realized in this paper using iterative learning control (ILC). A machine learning (ML) based nominal model update mechanism, which utilizes the linear regression technique to update the nominal model at each ILC trial only using the current trial information, is proposed for non-repetitive TVSs in order to enhance the ILC performance. Given that the ML mechanism forces the model uncertainties to remain within the ILC robust tolerance, an ILC update law is proposed to deal with non-repetitive TVSs. How to tune parameters inside ML and ILC algorithms to achieve the desired aggregate performance is also provided. The robustness and reliability of the proposed method are verified by simulations. Comparison with current state-of-the-art demonstrates its superior control performance in terms of controlling precision. This paper broadens ILC applications from time-invariant systems to non-repetitive TVSs, adopts ML regression technique to estimate non-repetitive time-varying parameters between two ILC trials and proposes a detailed parameter tuning mechanism to achieve desired performance, which are the main contributions.","",""
0,"J. Stein, Vinay Pulim, T. Cottrell, P. Forde, J. Taube","Abstract 463: Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies",2022,"","","","",109,"2022-07-13 10:06:04","","10.1158/1538-7445.am2022-463","","",,,,,0,0.00,0,5,1,"  Pathological complete response (no residual viable tumor, RVT) and/or major pathologic response (≤10% RVT) are now primary or secondary endpoints for a large proportion of clinical trials studying neoadjuvant immunotherapeutic regimens. We previously developed a scoring system for assessing pathologic response after immunotherapy, termed irPRC (Cottrell et al. Ann Oncol 2018). By these criteria, %RVT is assessed by dividing RVT by the sum of the surface area on the slide composed of RVT + necrosis + regression bed– the latter feature is where the tumor used to be and is characterized by fibroinflammatory stroma that is distinct from tumoral stroma. We have previously reported high inter-observer reproducibility for pathologic response assessment following immunotherapy. However, these assessments involve performing evaluations that are currently outside the scope of routine surgical pathology training and may be time-consuming. To date, these assessments have primarily been performed by academic pathologists who have seen the largest number of these cases as a part of clinical trials. A machine learning (ML)-powered assessment of irPRC would allow for faster, standardized evaluation and expanded access to patients treated outside of large academic centers. We trained a supervised convolutional neural network to assess pathologic response using irPRC on n=92 H&E-stained slides from patients with advanced, resectable NSCLC treated with neoadjuvant anti-PD-1 +/- anti-CTLA-4 at a single institution. The ML algorithm was trained based on ground-truth manual annotations by pathologists on whole slide digital scans and tested using leave-one-out cross validation. Each of ~830,000 image tiles was classified into one of four classes: tumor, necrosis, immune-mediated regression, or background lung tissue. Receiver operating curves showed that the algorithm exhibited high accuracy for predicting the various tissue classes with an area under the curve of 0.95, 0.96, 0.90, and 0.90 for the four classes, respectively. %RVT was calculated by dividing the surface area of RVT by total tumor bed surface area (RVT + necrosis + regression). There was a strong positive correlation between the machine assessed RVT and the human assessed RVT at both the slide level and case level (aggregate %RVT based on surface area from all slides for a given patient), Pearson’s r=0.95 and r=0.99, respectively. Here, we demonstrate that a ML algorithm performs as well as an experienced pathologist assessment in scoring pathologic response. These findings will need to be validated in larger studies. Additionally, the association of pathologic response with longer term patient outcomes will be evaluated as survival data matures to determine whether pathologic response is a robust surrogate of survival.  Citation Format: Julie E. Stein, Vinay Pulim, Tricia R. Cottrell, Patrick M. Forde, Janis M. Taube. Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2022; 2022 Apr 8-13. Philadelphia (PA): AACR; Cancer Res 2022;82(12_Suppl):Abstract nr 463.","",""
0,"T. Giese, Jinzhe Zeng, S. Ekesan, D. York","Combined QM/MM, Machine Learning Path Integral Approach to Compute Free Energy Profiles and Kinetic Isotope Effects in RNA Cleavage Reactions.",2022,"","","","",110,"2022-07-13 10:06:04","","10.1021/acs.jctc.2c00151","","",,,,,0,0.00,0,4,1,"We present a fast, accurate, and robust approach for determination of free energy profiles and kinetic isotope effects for RNA 2'-O-transphosphorylation reactions with inclusion of nuclear quantum effects. We apply a deep potential range correction (DPRc) for combined quantum mechanical/molecular mechanical (QM/MM) simulations of reactions in the condensed phase. The method uses the second-order density-functional tight-binding method (DFTB2) as a fast, approximate base QM model. The DPRc model modifies the DFTB2 QM interactions and applies short-range corrections to the QM/MM interactions to reproduce ab initio DFT (PBE0/6-31G*) QM/MM energies and forces. The DPRc thus enables both QM and QM/MM interactions to be tuned to high accuracy, and the QM/MM corrections are designed to smoothly vanish at a specified cutoff boundary (6 Å in the present work). The computational speed-up afforded by the QM/MM+DPRc model enables free energy profiles to be calculated that include rigorous long-range QM/MM interactions under periodic boundary conditions and nuclear quantum effects through a path integral approach using a new interface between the AMBER and i-PI software. The approach is demonstrated through the calculation of free energy profiles of a native RNA cleavage model reaction and reactions involving thio-substitutions, which are important experimental probes of the mechanism. The DFTB2+DPRc QM/MM free energy surfaces agree very closely with the PBE0/6-31G* QM/MM results, and it is vastly superior to the DFTB2 QM/MM surfaces with and without weighted thermodynamic perturbation corrections. 18O and 34S primary kinetic isotope effects are compared, and the influence of nuclear quantum effects on the free energy profiles is examined.","",""
0,"Marco Rasetto, Qingzhou Wan, Himanshu Akolkar, Bertram E. Shi, Feng Xiong, R. Benosman","The Challenges Ahead for Bio-inspired Neuromorphic Event Processors: How Memristors Dynamic Properties Could Revolutionize Machine Learning",2022,"","","","",111,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,6,1,"Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artificial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efficient approach to build novel bio-inspired processing units in silicon.","",""
9,"R. Roelofs","Measuring Generalization and Overfitting in Machine Learning",2019,"","","","",112,"2022-07-13 10:06:04","","","","",,,,,9,3.00,9,1,3,"Author(s): Roelofs, Rebecca | Advisor(s): Recht, Benjamin; Demmel, James | Abstract: Due to the prevalence of machine learning algorithms and the potential for their decisions to profoundly impact billions of human lives, it is crucial that they are robust, reliable, and understandable. This thesis examines key theoretical pillars of machine learning surrounding generalization and overfitting, and tests the extent to which empirical behavior matches existing theory. We develop novel methods for measuring overfitting and generalization, and we characterize how reproducible observed behavior is across differences in optimization algorithm, dataset, task, evaluation metric, and domain.First, we examine how optimization algorithms bias machine learning models towards solutions with varying generalization properties. We show that adaptive gradient methods empirically find solutions with inferior generalization behavior compared to those found by stochastic gradient descent. We then construct an example using a simple overparameterized model that corroborates the algorithms’ empirical behavior on neural networks. Next, we study the extent to which machine learning models have overfit to commonly reused datasets in both academic benchmarks and machine learning competitions. We build new test sets for the CIFAR-10 and ImageNet datasets and evaluate a broad range of classification models on the new datasets. All models experience a drop in accuracy, which indicates that current accuracy numbers are susceptible to even minute natural variations in the data distribution. Surprisingly, despite several years of adaptively selecting the models to perform well on these competitive benchmarks, we find no evidence of overfitting. We then analyze data from the machine learning platform Kaggle and find little evidence of substantial overfitting in ML competitions. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.Overall, our work suggests that the true concern for robust machine learning is distribution shift rather than overfitting, and designing models that still work reliably in dynamic environments is a challenging but necessary undertaking.","",""
132,"Trang T. Le, Weixuan Fu, J. Moore","Scaling tree-based automated machine learning to biomedical big data with a feature set selector",2019,"","","","",113,"2022-07-13 10:06:04","","10.1093/bioinformatics/btz470","","",,,,,132,44.00,44,3,3,"Abstract Motivation Automated machine learning (AutoML) systems are helpful data science assistants designed to scan data for novel features, select appropriate supervised learning models and optimize their parameters. For this purpose, Tree-based Pipeline Optimization Tool (TPOT) was developed using strongly typed genetic programing (GP) to recommend an optimized analysis pipeline for the data scientist’s prediction problem. However, like other AutoML systems, TPOT may reach computational resource limits when working on big data such as whole-genome expression data. Results We introduce two new features implemented in TPOT that helps increase the system’s scalability: Feature Set Selector (FSS) and Template. FSS provides the option to specify subsets of the features as separate datasets, assuming the signals come from one or more of these specific data subsets. FSS increases TPOT’s efficiency in application on big data by slicing the entire dataset into smaller sets of features and allowing GP to select the best subset in the final pipeline. Template enforces type constraints with strongly typed GP and enables the incorporation of FSS at the beginning of each pipeline. Consequently, FSS and Template help reduce TPOT computation time and may provide more interpretable results. Our simulations show TPOT-FSS significantly outperforms a tuned XGBoost model and standard TPOT implementation. We apply TPOT-FSS to real RNA-Seq data from a study of major depressive disorder. Independent of the previous study that identified significant association with depression severity of two modules, TPOT-FSS corroborates that one of the modules is largely predictive of the clinical diagnosis of each individual. Availability and implementation Detailed simulation and analysis code needed to reproduce the results in this study is available at https://github.com/lelaboratoire/tpot-fss. Implementation of the new TPOT operators is available at https://github.com/EpistasisLab/tpot. Supplementary information Supplementary data are available at Bioinformatics online.","",""
3,"N. Radziwill","Machine Learning with R, Third Edition (Book Review)",2019,"","","","",114,"2022-07-13 10:06:04","","10.1080/10686967.2019.1648086","","",,,,,3,1.00,3,1,3,"This book is highly recommended for anyone with previous programing experience who seeks a solid, grounded introduction to basic machine learning using the R statistical software. With nearly 100 additional pages added since the first edition in 2013, this update to Brett Lantz’s excellent text is well worth the purchase, even for those who already have an earlier copy on their shelf. Clear writing, robust explanations, and compelling examples appear throughout, and most chapters explain the math underlying the methods in as simple and easy a manner as possible. I liked the first edition so much, I used it as the primary textbook for my applied machine learning class for undergraduate juniors and seniors in science and engineering. Chapter 1 provides an overview of the main concepts associated with developing and using ML models for decision making. It includes discussions of traditional topics like overfitting and emerging issues like bias and artificial intelligence (AI) ethics. The chapter structure follows the same pattern as previous editions, so knn, Naive Bayes, decision trees, four neural networks and SVMs, association rules, k-means, and performance are all covered. Chapter 12 on specialized machine learning topics is significantly updated from previous editions and now covers tidyverse, domain-specific data, and brief examinations of performance optimization techniques like parallelization, MapReduce, Hadoop, and Spark. In most chapters, there are fully reproducible examples clearly broken down into steps. Within those steps, subtasks (for example, transformation, data preparation, model specification) are also clearly specified, making it clear how to structure different types of problems. This book is excellent for beginners and others who want to use R to learn how to skillfully address ML problems using their own data.","",""
1,"Ramkumar Harikrishnakumar, A. Dand, S. Nannapaneni, K. Krishnan","Supervised Machine Learning Approach for Effective Supplier Classification",2019,"","","","",115,"2022-07-13 10:06:04","","10.1109/ICMLA.2019.00045","","",,,,,1,0.33,0,4,3,"Supplier assessment plays a critical role in the supply chain management, which involves the flow of goods and services from the initial stage (raw material procurement) to the final stage (delivery). Supplier assessment is a multi-criteria decision-making (MCDM) approach that requires several criteria for the proper assessment of the suppliers. When there are several criteria involved, it makes the supplier assessment process more complicated. For a comprehensive and robust assessment process, we propose the use of supervised machine learning algorithms to classify various suppliers into four categories: excellent, good, satisfactory, and unsatisfactory. In this paper, supervised learning (classification) algorithms are applied for a supplier assessment problem where a model is trained based on the previous historical data and then tested on the new unseen data set. This method will provide an efficient way for supplier assessment that is more effective in terms of accuracy and time when compared to MCDM approach. Classification algorithms such as support vector machines (with linear, polynomial and radial basis kernels), logistic regression, k-nearest neighbors, and naïve Bayes methods are used to train the model and their performance is assessed against a test data. Finally, the performance measures from all the classification methods are used to assess the best supplier.","",""
6,"H. Bonakdari, Ali Jamshidi, J. Pelletier, F. Abram, G. Tardif, J. Martel-Pelletier","A warning machine learning algorithm for early knee osteoarthritis structural progressor patient screening",2021,"","","","",116,"2022-07-13 10:06:04","","10.1177/1759720X21993254","","",,,,,6,6.00,1,6,1,"Aim: In osteoarthritis (OA) there is a need for automated screening systems for early detection of structural progressors. We built a comprehensive machine learning (ML) model that bridges major OA risk factors and serum levels of adipokines/related inflammatory factors at baseline for early prediction of at-risk knee OA patient structural progressors over time. Methods: The patient- and gender-based model development used baseline serum levels of six adipokines, three related inflammatory factors and their ratios (36), as well as major OA risk factors [age and bone mass index (BMI)]. Subjects (677) were selected from the Osteoarthritis Initiative (OAI) progression subcohort. The probability values of being structural progressors (PVBSP) were generated using our previously published prediction model, including five baseline structural features of the knee, i.e. two X-rays and three magnetic resonance imaging variables. To identify the most important variables amongst the 47 studied in relation to PVBSP, we employed the ML feature classification methodology. Among five supervised ML algorithms, the support vector machine (SVM) demonstrated the best accuracy and use for gender-based classifiers development. Performance and sensitivity of the models were assessed. A reproducibility analysis was performed with clinical trial OA patients. Results: Feature selections revealed that the combination of age, BMI, and the ratios CRP/MCP-1 and leptin/CRP are the most important variables in predicting OA structural progressors in both genders. Classification accuracies for both genders in the testing stage (OAI) were >80%, with the highest sensitivity of CRP/MCP-1. Reproducibility analysis showed an accuracy ⩾92%; the ratio CRP/MCP-1 demonstrated the highest sensitivity in women and leptin/CRP in men. Conclusion: This is the first time that such a framework was built for predicting knee OA structural progressors. Using this automated ML patient- and gender-based model, early prediction of knee structural OA progression can be performed with high accuracy using only three baseline serum biomarkers and two risk factors. Plain language summary Machine learning model for early knee osteoarthritis structural progression Knee osteoarthritis is a well-known debilitating disease leading to reduced mobility and quality of life – the main causes of chronic invalidity. Disease evolution can be slow and span many years; however, for some individuals, the progression/evolution can be fast. Current treatments are only symptomatic and conventional diagnosis of osteoarthritis is not very effective in early identification of patients who will progress rapidly. To improve therapeutic approaches, we need a robust prediction model to stratify osteoarthritis patients at an early stage according to risk of joint structure disease progression. We hypothesize that a prediction model using a machine learning system would enable such an early identification of individuals for whom osteoarthritis knee structure will degrade rapidly. Data were from the Osteoarthritis Initiative, a National Institute of Health (United States) databank, and the robustness and generalizability of the developed model was further evaluated using osteoarthritis patients from an external cohort. Using the supervised machine learning system (support vector machine), we developed an automated patient- and gender-based model enabling an early clinical prognosis for individuals at high risk of structural progressive osteoarthritis. In brief, this model employed at baseline (when the subject sees a physician) easily obtained features consisting of the two main osteoarthritis risk factors, age and bone mass index (BMI), in addition to the serum levels of three molecules. Two of these molecules belong to a family of factors names adipokines and one to a related inflammatory factor. In brief, the model comprising a combination of age, BMI, and the ratios CRP/MCP-1 and leptin/CRP were found very robust for both genders, and the high accuracy persists when tested with an external cohort conferring the gender-based model generalizability. This study offers a new automated system for identifying early knee osteoarthritis structural progressors, which will significantly improve clinical prognosis with real time patient monitoring.","",""
74,"G. Chand, D. Dwyer, G. Erus, A. Sotiras, E. Varol, D. Srinivasan, J. Doshi, Raymond Pomponio, A. Pigoni, P. Dazzan, R. Kahn, H. Schnack, M. Zanetti, E. Meisenzahl, G. Busatto, B. Crespo-Facorro, C. Pantelis, S. Wood, C. Zhuo, R. Shinohara, H. Shou, Yong Fan, R. Gur, R. Gur, T. Satterthwaite, N. Koutsouleris, D. Wolf, C. Davatzikos","Two distinct neuroanatomical subtypes of schizophrenia revealed using machine learning.",2020,"","","","",117,"2022-07-13 10:06:04","","10.1093/brain/awaa025","","",,,,,74,37.00,7,28,2,"Neurobiological heterogeneity in schizophrenia is poorly understood and confounds current analyses. We investigated neuroanatomical subtypes in a multi-institutional multi-ethnic cohort, using novel semi-supervised machine learning methods designed to discover patterns associated with disease rather than normal anatomical variation. Structural MRI and clinical measures in established schizophrenia (n = 307) and healthy controls (n = 364) were analysed across three sites of PHENOM (Psychosis Heterogeneity Evaluated via Dimensional Neuroimaging) consortium. Regional volumetric measures of grey matter, white matter, and CSF were used to identify distinct and reproducible neuroanatomical subtypes of schizophrenia. Two distinct neuroanatomical subtypes were found. Subtype 1 showed widespread lower grey matter volumes, most prominent in thalamus, nucleus accumbens, medial temporal, medial prefrontal/frontal and insular cortices. Subtype 2 showed increased volume in the basal ganglia and internal capsule, and otherwise normal brain volumes. Grey matter volume correlated negatively with illness duration in Subtype 1 (r = -0.201, P = 0.016) but not in Subtype 2 (r = -0.045, P = 0.652), potentially indicating different underlying neuropathological processes. The subtypes did not differ in age (t = -1.603, d.f. = 305, P = 0.109), sex (chi-square = 0.013, d.f. = 1, P = 0.910), illness duration (t = -0.167, d.f. = 277, P = 0.868), antipsychotic dose (t = -0.439, d.f. = 210, P = 0.521), age of illness onset (t = -1.355, d.f. = 277, P = 0.177), positive symptoms (t = 0.249, d.f. = 289, P = 0.803), negative symptoms (t = 0.151, d.f. = 289, P = 0.879), or antipsychotic type (chi-square = 6.670, df = 3, P = 0.083). Subtype 1 had lower educational attainment than Subtype 2 (chi-square = 6.389, d.f. = 2, P = 0.041). In conclusion, we discovered two distinct and highly reproducible neuroanatomical subtypes. Subtype 1 displayed widespread volume reduction correlating with illness duration, and worse premorbid functioning. Subtype 2 had normal and stable anatomy, except for larger basal ganglia and internal capsule, not explained by antipsychotic dose. These subtypes challenge the notion that brain volume loss is a general feature of schizophrenia and suggest differential aetiologies. They can facilitate strategies for clinical trial enrichment and stratification, and precision diagnostics.","",""
74,"Kai Fukami, K. Fukagata, K. Taira","Machine-learning-based spatio-temporal super resolution reconstruction of turbulent flows",2020,"","","","",118,"2022-07-13 10:06:04","","10.1017/jfm.2020.948","","",,,,,74,37.00,25,3,2,"Abstract We present a new data reconstruction method with supervised machine learning techniques inspired by super resolution and inbetweening to recover high-resolution turbulent flows from grossly coarse flow data in space and time. For the present machine-learning-based data reconstruction, we use the downsampled skip-connection/multiscale model based on a convolutional neural network, incorporating the multiscale nature of fluid flows into its network structure. As an initial example, the model is applied to the two-dimensional cylinder wake at $Re_D = 100$. The reconstructed flow fields by the present method show great agreement with the reference data obtained by direct numerical simulation. Next, we apply the current model to a two-dimensional decaying homogeneous isotropic turbulence. The machine-learned model is able to track the decaying evolution from spatial and temporal coarse input data. The proposed concept is further applied to a complex turbulent channel flow over a three-dimensional domain at $Re_{\tau }=180$. The present model reconstructs high-resolved turbulent flows from very coarse input data in space, and also reproduces the temporal evolution for appropriately chosen time interval. The dependence on the number of training snapshots and duration between the first and last frames based on a temporal two-point correlation coefficient are also assessed to reveal the capability and robustness of spatio-temporal super resolution reconstruction. These results suggest that the present method can perform a range of flow reconstructions in support of computational and experimental efforts.","",""
0,"Muhammad Abdullah Hanif, R. Hafiz, M. Javed, Semeen Rehman, M. Shafique","Energy-Efficient Design of Advanced Machine Learning Hardware",2019,"","","","",119,"2022-07-13 10:06:04","","10.1007/978-3-030-04666-8_21","","",,,,,0,0.00,0,5,3,"","",""
4,"Mahender Singh, K. Singh","A Review of Publicly Available Automatic Brain Segmentation Methodologies, Machine Learning Models, Recent Advancements, and Their Comparison",2021,"","","","",120,"2022-07-13 10:06:04","","10.1177/0972753121990175","","",,,,,4,4.00,2,2,1,"Background: The noninvasive study of the structure and functions of the brain using neuroimaging techniques is increasingly being used for its clinical and research perspective. The morphological and volumetric changes in several regions and structures of brains are associated with the prognosis of neurological disorders such as Alzheimer’s disease, epilepsy, schizophrenia, etc. and the early identification of such changes can have huge clinical significance. The accurate segmentation of three-dimensional brain magnetic resonance images into tissue types (i.e., grey matter, white matter, cerebrospinal fluid) and brain structures, thus, has huge importance as they can act as early biomarkers. The manual segmentation though considered the “gold standard” is time-consuming, subjective, and not suitable for bigger neuroimaging studies. Several automatic segmentation tools and algorithms have been developed over the years; the machine learning models particularly those using deep convolutional neural network (CNN) architecture are increasingly being applied to improve the accuracy of automatic methods. Purpose: The purpose of the study is to understand the current and emerging state of automatic segmentation tools, their comparison, machine learning models, their reliability, and shortcomings with an intent to focus on the development of improved methods and algorithms. Methods: The study focuses on the review of publicly available neuroimaging tools, their comparison, and emerging machine learning models particularly those based on CNN architecture developed and published during the last five years. Conclusion: Several software tools developed by various research groups and made publicly available for automatic segmentation of the brain show variability in their results in several comparison studies and have not attained the level of reliability required for clinical studies. The machine learning models particularly three dimensional fully convolutional network models can provide a robust and efficient alternative with relation to publicly available tools but perform poorly on unseen datasets. The challenges related to training, computation cost, reproducibility, and validation across distinct scanning modalities for machine learning models need to be addressed.","",""
4,"I. Scott","Demystifying machine learning: a primer for physicians",2021,"","","","",121,"2022-07-13 10:06:04","","10.1111/imj.15200","","",,,,,4,4.00,4,1,1,"Machine learning is a tool for analysing digitised data sets and formulating predictions that can optimise clinical decision‐making. It aims to identify complex patterns in large data sets and encode them into models that can then classify new unseen cases or make predictions on new data. Machine learning methods take several forms and individual models can be of many different types. More than 50 models have been approved for use in routine healthcare, and the numbers continue to grow exponentially. The reliability and robustness of any model depends on multiple factors, including the quality and quantity of the data used to develop the models, and the selection of features in the data considered most important to maximising accuracy. In ensuring models are safe, effective and reproducible in routine care, physicians need to have some understanding of how these models are developed and evaluated, and to collaborate with data and computer scientists in their design and validation. This narrative review introduces principles, methods and examples of machine learning in a way that does not require mastery of highly complex statistical and computational concepts.","",""
29,"Yuhui Zheng, Le Sun, Shunfeng Wang, Jianwei Zhang, J. Ning","Spatially Regularized Structural Support Vector Machine for Robust Visual Tracking",2019,"","","","",122,"2022-07-13 10:06:04","","10.1109/TNNLS.2018.2855686","","",,,,,29,9.67,6,5,3,"Structural support vector machine (SSVM) is popular in the visual tracking field as it provides a consistent target representation for both learning and detection. However, the spatial distribution of feature is not considered in standard SSVM-based trackers, therefore leading to limited performance. To obtain a robust discriminative classifier, this paper proposes a novel tracking framework that spatially regularizes SSVM, which yields a new spatially regularized SSVM (SRSSVM). We utilize the spatial regularization prior to penalize the learning classifier with the same size as the target region. The location of classifier spatially located far from the center of region is assigned large weight and vice versa. Then, it is introduced into the SSVM model as a regularization factor to learn the robust discriminative model. Furthermore, an optimizing algorithm with dual coordination descent is presented to efficiently solve the SRSSVM tracking model. Our proposed SRSSVM tracking method has low computational cost like the traditional linear SSVM tracker while can significantly improve the robustness of the discriminative classifier. The experimental results on three popular tracking benchmark data sets show that the proposed SRSSVM tracking method performs favorably against the state-of-the-art trackers.","",""
20,"Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae","Engineering problems in machine learning systems",2019,"","","","",123,"2022-07-13 10:06:04","","10.1007/s10994-020-05872-w","","",,,,,20,6.67,7,3,3,"","",""
0,"Hsiao-Chi Li, Chang-Yu Cheng, Chia Chou, Chien-Chang Hsu, Meng-Lin Chang, Y. Chiu, J. Chai","Multi-Class Brain Age Discrimination Using Machine Learning Algorithm",2019,"","","","",124,"2022-07-13 10:06:04","","10.1109/ICMLC48188.2019.8949317","","",,,,,0,0.00,0,7,3,"Resting-state functional connectivity analyses have revealed a significant effect on the inter-regional interactions in brain. The brain age prediction based on resting-state functional magnetic resonance imaging has been proved as biomarkers to characterize the typical brain development and neuropsychiatric disorders. The brain age prediction model based on functional connectivity measurements derived from resting-state functional magnetic resonance imaging has received a lots of interest in recent years due to its great success in age prediction. However, some of the recent studies rely on experienced neuroscientist experts to select appropriate connectivity features in order to build a robust model for prediction while the others just selected the features based on trial-and-error test. Besides, the subjects used in this studies omitted some subjects that can be divided into two groups with less similarity which may confused the prediction model. In this study, we proposed a multi-class age categories discrimination method with the connectivity features selected via K-means clustering with no prior knowledge provided. The experimental results show that with K-means selected features the proposed model better discriminate multi-class age categories.","",""
0,"Yuya Jeremy Ong, Tomoki Takasawa","Efficiency Characterization of the Kepler Exoplanet Discovery Pipeline Using Machine Learning",2019,"","","","",125,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,2,3,"The Kepler mission, launched by NASA has been used to discover the possibilities for the existence of exoplanets beyond our solar system, providing massive amounts of data that we can use to speculate such candidates. However, to collect the massive amounts of data to identify new and potentially interesting planet candidates, researchers have developed several different methods, heuristics, and data pipelines to facilitate the discovery of new exoplanets. In this work, we characterize the efficiency of the Kepler missionâĂŹs Transiting Planet Search (TPS) system known as Robovetter, using the Robovetter’s simulated light-curve pipeline data and provide insights towards building robust automated pipelines for detecting potentially new and interesting stellar objects and identify potential potential false positives within the samples. Furthermore, to facilitate the research and discovery process of this work, we also develop and propose a data-driven research pipeline specifically for our modeling purposes to provide an efficient workflow for researchers to easily design reproducible machine learning-based experimental workflows that both enables automation and flexibility in modeling approaches.","",""
141,"F. Thabtah","Machine learning in autistic spectrum disorder behavioral research: A review and ways forward",2019,"","","","",126,"2022-07-13 10:06:04","","10.1080/17538157.2017.1399132","","",,,,,141,47.00,141,1,3,"ABSTRACT Autistic Spectrum Disorder (ASD) is a mental disorder that retards acquisition of linguistic, communication, cognitive, and social skills and abilities. Despite being diagnosed with ASD, some individuals exhibit outstanding scholastic, non-academic, and artistic capabilities, in such cases posing a challenging task for scientists to provide answers. In the last few years, ASD has been investigated by social and computational intelligence scientists utilizing advanced technologies such as machine learning to improve diagnostic timing, precision, and quality. Machine learning is a multidisciplinary research topic that employs intelligent techniques to discover useful concealed patterns, which are utilized in prediction to improve decision making. Machine learning techniques such as support vector machines, decision trees, logistic regressions, and others, have been applied to datasets related to autism in order to construct predictive models. These models claim to enhance the ability of clinicians to provide robust diagnoses and prognoses of ASD. However, studies concerning the use of machine learning in ASD diagnosis and treatment suffer from conceptual, implementation, and data issues such as the way diagnostic codes are used, the type of feature selection employed, the evaluation measures chosen, and class imbalances in data among others. A more serious claim in recent studies is the development of a new method for ASD diagnoses based on machine learning. This article critically analyses these recent investigative studies on autism, not only articulating the aforementioned issues in these studies but also recommending paths forward that enhance machine learning use in ASD with respect to conceptualization, implementation, and data. Future studies concerning machine learning in autism research are greatly benefitted by such proposals.","",""
0,"J. Figuerêdo, V. T. Sarinho, R. Calumby","Low-Cost Machine Learning for Effective and Efficient Bad Smells Detection",2021,"","","","",127,"2022-07-13 10:06:04","","10.5753/kdmile.2021.17468","","",,,,,0,0.00,0,3,1,"Bad smells are characteristics of software that indicate a code or design problem which can make information system hard to understand, evolve, and maintain. To address this problem, different approaches, manual and automated, have been proposed over the years, including more recently machine learning alternatives. However, despite the advances achieved, some machine learning techniques have not yet been effectively explored, such as the use of feature selection techniques. Moreover, it is not clear to what extent the use of numerous source-code features are necessary for reasonable bad smell detection success. Therefore, in this work we propose an approach using low-cost machine learning for effective and efficient detection of bad smells, through explicit feature selection. Our results showed that the selection allowed to statistically improve the effectiveness of the models. For some cases, the models achieved statistical equivalence, but relying on a highly reduced set of features. Indeed, by using explicit feature selection, simpler models such as Naive Bayes became statistically equivalent to robust models such as Random Forest. Therefore, the selection of features allowed keeping competitive or even superior effectiveness while also improving the efficiency of the models, demanding less computational resources for source-code preprocessing, model training and bad smell detection.","",""
0,"Maria Sailer, F. Schiller, Thorsten Falk, A. Jud, Sven Arke Lang, J. Ruf, M. Mix","Prediction of the histopathological tumor type of newly diagnosed liver lesions from standard abdominal computer tomography with a machine-learning classifier based on convolutional neural networks",2021,"","","","",128,"2022-07-13 10:06:04","","10.1515/cdbme-2021-1032","","",,,,,0,0.00,0,7,1,"Abstract Background and objectives: Liver lesions are a relatively common incidental finding in computer tomography (CT) of the abdomen. The current gold standard is liver biopsy, which has the downside of respecting only a small part of the total lesion volume. Furthermore, this invasive method carries interventional risks like bleeding or infection. Therefore, an image-based biomarker would be highly desirable. Conventional “radiomics” methods have often been utilized for similar problems, but the results are often not reproducible. This is mainly due to sampling errors and interobserver variability, but also the seemingly complex nature of the problem. We present a new approach that implements cutting-edge research in machine learning which is nevertheless cheap and easily applicable in a routine clinical setting. To achieve this, we use convolutional neural networks (CNN) to predict the histopathological findings from liver lesions from preoperative liver CT. Methods: After splitting the study population into a training and test set we trained a CNN to predict the histopathological tumor type from CT data. Results: The developed CNN workflow is able to predict liver tumor histology from routine CT images. We also evaluated in how far transfer learning and data augmentation can help in solving this problem and implemented the developed workflow in a clinical routine setting. Conclusion: We propose a robust semiautomatic end-to-end classification workflow for the prediction of the histopathological type of tumor lesions based on abdominal CT and a deep convolutional neural network model. In our cohort, the model shows reliable and accurate results even with limited computational resources.","",""
0,"W. Zong, Yang-Wai Chow, W. Susilo","Visual Analysis of Adversarial Examples in Machine Learning",2021,"","","","",129,"2022-07-13 10:06:04","","10.1007/978-981-33-6726-5_4","","",,,,,0,0.00,0,3,1,"","",""
0,"Cameron Fen, Samir S Undavia","Improving External Validity of Machine Learning, Reduced Form, and Structural Macroeconomic Models using Panel Data",2021,"","","","",130,"2022-07-13 10:06:04","","10.2139/ssrn.3839863","","",,,,,0,0.00,0,2,1,"We show that adding countries as a panel dimension to macroeconomic data can statistically significantly improve the generalization ability of structural and reduced-form models, as well as allow machine learning methods to outperform these and other macroeconomic forecasting models. Using GDP forecasts for evaluation, this procedure reduces root mean squared error (RMSE) by 12% across horizons and models for certain reduced-form models and by 24% across horizons for structural DSGE models. Removing US data from the training set and forecasting out-of-sample country-wise, we show that both reduced form and structural models become more policy invariant, and outperform a baseline model that uses US data only. Finally, given the comparative advantage of ""nonparametric"" machine learning forecasting models in a data-rich regime, we demonstrate that our recurrent neural network (RNN) model and automated machine learning (AutoML) approach outperforms all baseline economic models in this regime. Robustness checks indicate that machine learning outperformance is reproducible, numerically stable, and generalizes across models.","",""
0,"S. Turner","Extragalactic machine learning: in theory and in practice",2021,"","","","",131,"2022-07-13 10:06:04","","10.24377/LJMU.T.00014348","","",,,,,0,0.00,0,1,1,"Galaxy evolution is complicated. Throughout their lifetimes, galaxies are subject to an amalgamation of astrophysical and cosmological processes that direct the growth of their stellar masses, the transformation of their morphologies, and the cessation of their star formation. The variable action of these processes begets a diverse population of galaxies, which exhibit a variety of brightnesses, colours, shapes, and sizes, among myriad other features. Many of these features are bimodally distributed, which has led to the general acceptance of a simple empirical paradigm of galaxy evolution. However, connecting this diversity among galaxies with the array of processes that are involved in their evolution, and constraining the relative influences of each of these processes, requires that several features are analysed simultaneously. This has been enabled by the recent advent of machine learning techniques, which are capable of extracting scientifically useful information from complicated, multi-dimensional datasets, to astronomy and astrophysics. Unsupervised machine learning techniques, free from the requirement for pre-labelled training data, are especially well suited to the exploration of the data structures of galaxy samples in multi-dimensional feature spaces. This thesis assesses the use of clustering, an unsupervised machine learning technique, for the research of galaxy evolution. Clustering is first tested on a well-characterised sample of galaxies from the GAMA survey. Galaxies are represented in five dimensions by a set of intrinsic astrophysical features. Use of a unique cluster evaluation framework enables the robust identification of reproducible and astrophysically meaningful clustering structures via the k-means method. Outcomes consisting of two, three, five, and six clusters are deemed stable, and form a hierarchical structure that agrees well with established notions of the galaxy bimodality. The two- and three-cluster outcomes are dominated in their structures by the stellar masses, colours, and star formation activity of galaxies, with Sersic indices and half-light radii becoming important for the five- and six-cluster outcomes. Clusters also exhibit broad correspondence with detailed morphological classifications, and it is suggested that the inclusion of additional morphological features might improve this correspondence further. The five- and six-cluster outcomes indicate the differential role of environment in the evolution of galaxies with intermediate colours. This cluster evaluation framework is then applied for the validation of the cosmological, hydrodynamical EAGLE simulations against the GAMA survey. Outcomes consisting of seven and five clusters respectively, determined using the same five features for both samples, are selected for analysis. These outcomes produce an agreement score of Vₐ = 0.76, indicating broad, overall agreement, but differences in their substructures. These differences include discrepancies in the growth of the central bulges of galaxies along the star-forming main sequence, an over-abundance of low-mass, bulge-dominated, star-forming galaxies in the EAGLE sample, and a subpopulation of high-mass, disc-dominated, star-forming galaxies in the EAGLE sample that is not present in the GAMA sample. These differences are attributed to the resolution of EAGLE, and to an active galactic nucleus feedback prescription that is not sufficiently effective in EAGLE. Finally, clustering is used to compare samples of galaxies at low (z ~ 0.06; GSWLC-2) and intermediate (z ~ 0.67; VIPERS) redshifts, in order to examine the evolution of subpopulations of galaxies. Galaxies are clustered in a nine-dimensional feature space defined by a series of ultraviolet-through-near-infrared colours using the Subspace Expectation-Maximisation algorithm, which includes iterative dimensionality reduction. The algorithm models both samples using seven clusters: four containing mostly star-forming galaxies, and three containing mostly passive galaxies. Both sets of star-forming clusters form clear morphological sequences, capturing the gradual internally-driven growth of galaxy bulges at both epochs. At high stellar masses, this growth is linked with quenching. However, it is only at low redshifts that additional, environmental processes appear to be involved in the evolution of low-mass passive galaxies. The results of this thesis demonstrate the utility of clustering as a method with which to analyse the large galaxy samples that are anticipated from next-generation surveys, and with which to facilitate the multi-dimensional comparison of cosmological galaxy simulations with observations. Clustering is robustly able to identify astrophysically meaningful substructures in complex, multi-dimensional feature spaces, and these substructures may readily be interpreted with respect to the evolutionary contexts of the galaxies that they encompass.","",""
8,"Mustafa Anil Koçak, David Ramirez, E. Erkip, D. Shasha","SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness",2017,"","","","",132,"2022-07-13 10:06:04","","10.1109/TPAMI.2019.2932415","","",,,,,8,1.60,2,4,5,"<italic>SafePredict</italic> is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, <inline-formula><tex-math notation=""LaTeX"">$1-\epsilon$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""kocak-ieq1-2932415.gif""/></alternatives></inline-formula>, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm so that the error rate on non-refused predictions does not exceed <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq2-2932415.gif""/></alternatives></inline-formula>. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq3-2932415.gif""/></alternatives></inline-formula>, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the-art confidence-based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software is included in the supplementary material, which can be found on the Computer Society Digital Library at <uri>http://doi.ieeecomputersociety.org/10.1109/TPAMI.2019.2932415</uri>.","",""
0,"Sannasi Chakravarthy S R, H. Rajaguru","Deep Features with Improved Extreme Learning Machine for Breast Cancer Classification",2021,"","","","",133,"2022-07-13 10:06:04","","10.1109/ISCMI53840.2021.9654814","","",,,,,0,0.00,0,2,1,"Breast cancer classification problem is receiving more attention among researchers due to its global impact on women's healthcare. There is always a demand for research analysis in the earlier diagnosis of breast cancer. The paper proposes a new computer-aided diagnosis (CAD) framework which integrates deep learning and Extreme Learning Machine (ELM) for feature extrication and classification of breast cancer. The proposed CAD tool is very much helpful for radiologists in the earlier diagnosis of breast cancer using digital mammograms. Herein, the research uses the Sine-Cosine Crow-Search Optimization Algorithm (SC-CSOA) for improving the ELM’s classification performance. And to extricate the robust features from the input mammograms, the concept of transfer learning is applied. For that, the work adopts the three most efficient Residual Network (ResNet) families of CNN, namely ResNet18, ResNet50, and ResNet101 architectures. The input database used for evaluation is the INbreast dataset which comprises Full-Field Digital Mammogram (FFDM) images. At this point, the research compares the results obtained with the existing ELM and K-NN algorithms where it is found that the performance of the proposed framework provides the supreme classification (95.811% of accuracy) over others.","",""
8,"J. Coyle, N. Hejazi, I. Malenica, Rachael V. Phillips, B. Arnold, A. Mertens, J. Benjamin-Chung, Weixin Cai, Sonali Dayal, J. Colford, A. Hubbard, M. Laan","Targeting Learning: Robust Statistics for Reproducible Research",2020,"","","","",134,"2022-07-13 10:06:04","","","","",,,,,8,4.00,1,12,2,"Targeted Learning is a subfield of statistics that unifies advances in causal inference, machine learning and statistical theory to help answer scientifically impactful questions with statistical confidence. Targeted Learning is driven by complex problems in data science and has been implemented in a diversity of real-world scenarios: observational studies with missing treatments and outcomes, personalized interventions, longitudinal settings with time-varying treatment regimes, survival analysis, adaptive randomized trials, mediation analysis, and networks of connected subjects. In contrast to the (mis)application of restrictive modeling strategies that dominate the current practice of statistics, Targeted Learning establishes a principled standard for statistical estimation and inference (i.e., confidence intervals and p-values). This multiply robust approach is accompanied by a guiding roadmap and a burgeoning software ecosystem, both of which provide guidance on the construction of estimators optimized to best answer the motivating question. The roadmap of Targeted Learning emphasizes tailoring statistical procedures so as to minimize their assumptions, carefully grounding them only in the scientific knowledge available. The end result is a framework that honestly reflects the uncertainty in both the background knowledge and the available data in order to draw reliable conclusions from statistical analyses - ultimately enhancing the reproducibility and rigor of scientific findings.","",""
5,"Stefan Klus, Patrick Gelß, F. Nüske, Frank No'e","Symmetric and antisymmetric kernels for machine learning problems in quantum physics and chemistry",2021,"","","","",135,"2022-07-13 10:06:04","","10.1088/2632-2153/ac14ad","","",,,,,5,5.00,1,4,1,"We derive symmetric and antisymmetric kernels by symmetrizing and antisymmetrizing conventional kernels and analyze their properties. In particular, we compute the feature space dimensions of the resulting polynomial kernels, prove that the reproducing kernel Hilbert spaces induced by symmetric and antisymmetric Gaussian kernels are dense in the space of symmetric and antisymmetric functions, and propose a Slater determinant representation of the antisymmetric Gaussian kernel, which allows for an efficient evaluation even if the state space is high-dimensional. Furthermore, we show that by exploiting symmetries or antisymmetries the size of the training data set can be significantly reduced. The results are illustrated with guiding examples and simple quantum physics and chemistry applications.","",""
5,"R. Gafeira, D. O. Su'arez, I. Milić, C. Q. Noda, B. R. Cobo, H. Uitenbroek","Machine learning initialization to accelerate Stokes profile inversions",2021,"","","","",136,"2022-07-13 10:06:04","","10.1051/0004-6361/201936910","","",,,,,5,5.00,1,6,1,"Context. At present, an exponential growth in scientific data from current and upcoming solar observatories is expected. Most of the data consist of high spatial and temporal resolution cubes of Stokes profiles taken in both local thermodynamic equilibrium (LTE) and non-LTE spectral lines. The analysis of such solar observations requires complex inversion codes. Hence, it is necessary to develop new tools to boost the speed and efficiency of inversions and reduce computation times and costs. Aims. In this work we discuss the application of convolutional neural networks (CNNs) as a tool to advantageously initialize Stokes profile inversions. Methods. To demonstrate the usefulness of CNNs, we concentrate in this paper on the inversion of LTE Stokes profiles. We use observations taken with the spectropolarimeter on board the Hinode spacecraft as a test bench mark. First, we carefully analyse the data with the SIR inversion code using a given initial atmospheric model. The code provides a set of atmospheric models that reproduce the observations well. These models are then used to train a CNN. Afterwards, the same data are again inverted with SIR but using the trained CNN to provide the initial guess atmospheric models for SIR. Results. The CNNs allow us to significantly reduce the number of inversion cycles when used to compute initial guess model atmospheres (‘assisted inversions’), therefore decreasing the computational time for LTE inversions by a factor of two to four. CNNs alone are much faster than assisted inversions, but the latter are more robust and accurate. CNNs also help to automatically cluster pixels with similar physical properties, allowing the association with different solar features on the solar surface, which is useful when inverting huge datasets where completely different regimes are present. The advantages and limitations of machine learning techniques for estimating optimum initial atmospheric models for spectral line inversions are discussed. Finally, we describe a python wrapper for the SIR and DeSIRe codes that allows for the easy setup of parallel inversions. The tool implements the assisted inversion method described in this paper. The parallel wrapper can also be used to synthesize Stokes profiles with the RH code. Conclusions. The assisted inversions can speed up the inversion process, but the efficiency and accuracy of the inversion results depend strongly on the solar scene and the data used for the CNN training. This method (assisted inversions) will not obviate the need for analysing individual events with the utmost care but will provide solar scientists with a much better opportunity to sample large amounts of inverted data, which will undoubtedly broaden the physical discovery space.","",""
0,"Murilo Cruz Lopes, Marília de Matos Amorim, V. S. Freitas, R. Calumby","Survival Prediction for Oral Cancer Patients: A Machine Learning Approach",2021,"","","","",137,"2022-07-13 10:06:04","","10.5753/kdmile.2021.17466","","",,,,,0,0.00,0,4,1,"There is a high incidence of oral cancer in Brazil, with 150,000 new cases estimated for 2020-2022. In most cases, it is diagnosed at an advanced stage and are related to many risk factors. The Registro Hospitalar de Câncer (RHC), managed by Instituto Nacional de Câncer (INCA), is a nation-wide database that integrates cancer registers from several hospitals in Brazil. RHC is mostly an administrative database but also include clinical, socioeconomic and hospitalization data for each patient with a cancer diagnostic in the country. For these patients, prognostication is always a difficult task a demand multi-dimensional analysis. Therefore, exploiting large-scale data and machine intelligence approaches emerge as promising tool for computer-aided decision support on death risk estimation. Given the importance of this context, some works have reported high prognostication effectiveness, however with extremely limited data collections, relying on weak validation protocols or simple robustness analysis. Hence, this work describes a detailed workflow and experimental analysis for oral cancer patient survival prediction considering careful data curation and strict validation procedures. By exploiting multiple machine learning algorithms and optimization techniques the proposed approach allowed promising survival prediction effectiveness with F1 and AuC-ROC over 0.78 and 0.80, respectively. Moreover, a detailed analysis have shown that the minimization of different types of prediction errors were achieved by different models, which highlights the importance of the rigour in this kind of validation.","",""
1,"Zhen Guo, J. Song, G. Barbastathis, M. Glinsky, C. Vaughan, K. Larson, B. Alpert, Z. Levine","Advantage of Machine Learning over Maximum Likelihood in Limited-Angle Low-Photon X-Ray Tomography",2021,"","","","",138,"2022-07-13 10:06:04","","","","",,,,,1,1.00,0,8,1,"Limited-angle X-ray tomography reconstruction is an illconditioned inverse problem in general. Especially when the projection angles are limited and the measurements are taken in a photon-limited condition, reconstructions from classical algorithms such as filtered backprojection may lose fidelity and acquire artifacts due to the missing-cone problem. To obtain satisfactory reconstruction results, prior assumptions, such as total variation minimization and nonlocal image similarity, are usually incorporated within the reconstruction algorithm. In this work, we introduce deep neural networks to determine and apply a prior distribution in the reconstruction process. Our neural networks learn the prior directly from synthetic training samples. The neural nets thus obtain a prior distribution that is specific to the class of objects we are interested in reconstructing. In particular, we used deep generative models with 3D convolutional layers and 3D attention layers which are trained on 3D synthetic integrated circuit (IC) data from a model dubbed CircuitFaker. We demonstrate that, when the projection angles and photon budgets are limited, the priors from our deep generative models can dramatically improve the IC reconstruction quality on synthetic data compared with maximum likelihood estimation. Training the deep generative models with synthetic IC data from CircuitFaker illustrates the capabilities of the learned prior from machine learning. We expect that if the process were reproduced with experimental data, the advantage of the machine learning would persist. The advantages of machine learning in limited angle X-ray tomography may further enable applications in low-photon nanoscale imaging. Background Limited-angle X-ray tomography has the ability to image the interior of three-dimensional (3D) objects non-invasively without collecting the measurements from a full set of rotation angles. It has drawn wide attention in practical nanoscale imaging due to its advantage in having a relatively short data acquisition time. Also, in some cases, not all angles are physically accessible. Typically, the tomographic imaging system consists of a sample holder, an objective zone plate, and a CCD camera, and the illumination is generated from the X-ray source. The measurements are taken from a series of rotational angles with respect to the sample of interest, where a cone-beam geometry is generally assumed to produce the ray projection from the source point to the sample, and then from sample to the center of each detector pixel. After the measurements, objects subsequently can be reconstructed based on 3D computed tomography algorithms. Theoretically, full-angle measurement is preferred to avoid the missing cone problem in the reconstruction process. In practice, however, limited-angle measurement is often used due to the time of acquiring the full angle measurement. For objects or samples that are radiation sensitive, a low-photon budget per scan is also preferred to minimize the total exposure and potential damage. Limited-angle X-ray tomography is an ill-conditioned inverse problem [1, 2], where the goal is to find a discrete representation of an object f based on the observations g taken on a digital camera at limited number of angles. When limited-angle tomography is applied where the illumination is limited to only a few photons, the noise sensitivity of poor conditioning becomes even more evident: not only do the collected Fourier slices cover the Fourier space unevenly due to the limited scans, they are also inaccurate due to the presence of shot noise in the measurements. Limited angle X-ray tomography therefore has had limited utility for radiation sensitive samples. To solve the limited angle X-ray tomography with photon scarcity, regularization is required during the reconstruction process. Some improvement can be obtained by extrapolating missing data [3]. Data consistency conditions, e.g., the Helgason-Ludwig consistency conditions, further improves the quality of extrapolation [4]. Still, extrapolating methods are struggling with complex structures and are not robust to noise in the experimental measurements. Iterative algorithms with constraints known a priori reconstruct the object using multiple steps. The algorithms start with an assumed object, simulate the measurement from the assumed object, compare the experimental measurements and simulated measurements, and then update the object based on the difference between measurements and simulations. The last step also includes discrepancy in the prior terms into the computation of the update. The process continues until a certain convergence criterion is achieved. Iterative algorithms with prior constraints such as total variation minimization and nonlocal image similarity often exhibit improved resilience to noise. Previously, we also have shown a Bayesian approach [5] based on the Bouman-Sauer formulation for the iterative reconstruction algorithm [6]. The regularization constrains the iterative optimization to a subdomain in which the object belongs, thereby effectively improving the reconstruction quality [7, 8]. Recently, machine learning has been applied successfully to ar X iv :2 11 1. 08 01 1v 2 [ ee ss .I V ] 1 8 D ec 2 02 1 limited-angle tomography to overcome the challenge in solving the inverse problem. Efforts have been made in using learned priors to provide information of missing data during reconstruction [9, 10, 11]. In particular, deep learning, a subset of machine learning that is based on artificial neural networks with representation learning, achieved promising results [11, 12, 13]. For tomographic inverse problems, U-net-like neural network architectures [14] have been widely used to produce reconstruction pixel-by-pixel. For example, U-net has been used to predict invisible singularities in the image object [12], to generate missing projections with a data-consistent reconstruction method [13], and to improve the reconstruction quality from the conventional FBP method [11]. Unlike the general priors in iterative algorithms, the learned prior from a deep learning method is conditioned on a large amount of paired training data. Therefore, the learned prior explores the statistical property of the training distribution. In this work, we extend the application of limited-angle Xray tomography to experimental conditions of low-photon incidence. To approximate the resulting ill-conditioned inverse problem and to obtain a satisfactory reconstruction quality, we apply machine learning to determine a prior distribution for the reconstruction process. In particular, we use deep generative models with 3D convolution and 3D attention which are trained on 3D synthetic integrated circuit (IC) data from a model dubbed CircuitFaker. We demonstrate that the priors from our deep generative models drastically improve the IC reconstruction quality on synthetic data from maximum likelihood estimation when the projection angles and photon budgets are limited. Beyond existing research that uses machine learning for limited angle X-ray tomography, our generative model exhibits improvements over maximum likelihood reconstructions under low-photon conditions. We further examine different neural network architectures to reveal some of the important network design choices for solving the inverse problem. Method The overall pipeline of our method is organized as follows: First, we generate synthetic integrated circuit (IC) layouts using CircuitFaker, an in-house model. Then, we simulate the limitedangle X-ray tomography radiographs. Next, we apply the maximum likelihood method to generate an initial IC reconstruction. Finally, we feed the initial IC reconstruction to the (trained) deep generative model and compare the reconstruction quality of the test set by calculating the bit error rate. CircuitFaker CircuitFaker is an algorithm that generates a random set of voxels with binary values which resembles an integrated circuit interconnect. The synthetic circuits from CircuitFaker is the class of artificial objects for tomographic reconstruction, and the implicit correlations in their spatial features are the priors to be assumed or to be learned for the inverse algorithms. A particular draw of CircuitFaker assigns a bit in each of N = NxNyNz locations. These locations are indexed as i` = 1, ...,N`, with ` = 1, 2, 3 for x, y, and z. All bits are initialized to 0. In the first round, there are wire seed points for all locations (i1, i2, i3) with i1, ..., i3 odd. Each seed point is set by a Bernoulli draw with probability pw of getting a 1. There are three kinds of layers, x, y, and via Figure 1. Selected 16× 16× 8 circuit from CircuitFaker. Each image is a slice of 2D layer in the z dimension. The value of z increases as a raster scan of the 8 slices shown. Black indicates copper and white indicates silicon. Here, x layers are the first and fifth layers in z, y layers are the third and seventh layers in z. Others are via layers. layers. The x wiring layers have index i3 = 1 mod 4. The y wiring layers have i3 = 3 mod 4. The via layers are the others, i.e., i3 even. In the second round, a point on an x wiring layer to the immediate right of a point with value 1 is set to 1 with probability px. A point on a y wiring layer immediately above in plan view a point with a value 1 is set to 1 with probability py. Similarly, a point on a via layer immediately above a point with a value 1 is set to 1 with probability pz. In this paper, we chose these parameters: Nx = Ny = 16, Nz = 8, pw = 0.75, px = py = 0.8, and pz = 0.5. Fig. 1 shows one of the generated circuits with size 16×16×8. Imaging geometry for X-ray tomography We assumed that each voxel in the circuit is in size of size 0.15 μm × 0.15 μm × 0.30 μm. Therefore, the total volume of the circuit is 2.4 μm× 2.4 μm× 2.4 μm. The detector is assumed to be in the x-z plane at a tilt angle of φ = 0◦. The rotation axis is ","",""
1,"Devontae C. Baxter, M. Cooper, S. Fillingham","A machine learning approach to measuring the quenched fraction of low-mass satellites beyond the Local Group",2021,"","","","",139,"2022-07-13 10:06:04","","10.1093/mnras/stab523","","",,,,,1,1.00,0,3,1,"Observations suggest that satellite quenching plays a major role in the buildup of passive, low-mass galaxies at late cosmic times. Studies of low-mass satellites, however, are limited by the ability to robustly characterize the local environment and star-formation activity of faint systems. In an effort to overcome the limitations of existing data sets, we utilize deep photometry in Stripe 82 of the Sloan Digital Sky Survey, in conjunction with a neural network classification scheme, to study the suppression of star formation in low-mass satellite galaxies in the local Universe. Using a statistically-driven approach, we are able to push beyond the limits of existing spectroscopic data sets, measuring the satellite quenched fraction down to satellite stellar masses of ∼107 M in group environments (Mhalo = 1013−14 h−1 M ). At high satellite stellar masses (& 10 M ), our analysis successfully reproduces existing measurements of the quenched fraction based on spectroscopic samples. Pushing to lower masses, we find that the fraction of passive satellites increases, potentially signaling a change in the dominant quenching mechanism at M? ∼ 10 M . Similar to the results of previous studies of the Local Group, this increase in the quenched fraction at low satellite masses may correspond to an increase in the efficacy of ram-pressure stripping as a quenching mechanism in groups.","",""
299,"J Zhang, M. Harman, Lei Ma, Yang Liu","Machine Learning Testing: Survey, Landscapes and Horizons",2019,"","","","",140,"2022-07-13 10:06:04","","10.1109/tse.2019.2962027","","",,,,,299,99.67,75,4,3,"This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.","",""
33,"Ved P. Kafle, Y. Fukushima, P. Martinez-Julia, T. Miyazawa","Consideration On Automation of 5G Network Slicing with Machine Learning",2018,"","","","",141,"2022-07-13 10:06:04","","10.23919/ITU-WT.2018.8597639","","",,,,,33,8.25,8,4,4,"Machine learning has the capability to provide simpler solutions to complex problems by analyzing a huge volume of data in a short time, learning for adapting its functionality to dynamically changing environments, and predicting near future events with reasonably good accuracy. The 5G communication networks are getting complex due to emergence of unprecedentedly huge number of new connected devices and new types of services. Moreover, the requirements of creating virtual network slices suitable to provide optimal services for diverse users and applications are posing challenges to the efficient management of network resources, processing information about a huge volume of traffic, staying robust against all potential security threats, and adaptively adjustment of network functionality for time-varying workload. In this paper, we introduce about the envisioned 5G network slicing and elaborate the necessity of automation of network functions for the design, construction, deployment, operation, control and management of network slices. We then revisit the machine learning techniques that can be applied for the automation of network functions. We also discuss the status of artificial intelligence and machine learning related activities being progressed in standards development organizations and industrial forums.","",""
241,"B. Goldstein, A. Navar, R. Carter","Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges",2016,"","","","",142,"2022-07-13 10:06:04","","10.1093/eurheartj/ehw302","","",,,,,241,40.17,80,3,6,"Abstract Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning.","",""
12,"C. Fisher, H. J. Hoeijmakers, D. Kitzmann, Pablo M'arquez-Neila, S. Grimm, R. Sznitman, K. Heng","Interpreting High-resolution Spectroscopy of Exoplanets using Cross-correlations and Supervised Machine Learning",2019,"","","","",143,"2022-07-13 10:06:04","","10.3847/1538-3881/ab7a92","","",,,,,12,4.00,2,7,3,"We present a new method for performing atmospheric retrieval on ground-based, high-resolution data of exoplanets. Our method combines cross-correlation functions with a random forest, a supervised machine learning technique, to overcome challenges associated with high-resolution data. A series of cross-correlation functions are concatenated to give a ""CCF-sequence"" for each model atmosphere, which reduces the dimensionality by a factor of ~100. The random forest, trained on our grid of ~65,000 models, provides a likelihood-free method of retrieval. The pre-computed grid spans 31 values of both temperature and metallicity, and incorporates a realistic noise model. We apply our method to HARPS-N observations of the ultra-hot Jupiter KELT-9b, and obtain a metallicity consistent with solar (logM = $-0.2\pm0.2$). Our retrieved transit chord temperature (T = $6000^{+0}_{-200}$K) is unreliable as the ion cross-correlations lie outside of the training set, which we interpret as being indicative of missing physics in our atmospheric model. We compare our method to traditional nested-sampling, as well as other machine learning techniques, such as Bayesian neural networks. We demonstrate that the likelihood-free aspect of the random forest makes it more robust than nested-sampling to different error distributions, and that the Bayesian neural network we tested is unable to reproduce complex posteriors. We also address the claim in Cobb et al. (2019) that our random forest retrieval technique can be over-confident but incorrect. We show that this is an artefact of the training set, rather than the machine learning method, and that the posteriors agree with those obtained using nested-sampling.","",""
130,"A. Subasi, Jasmin Kevric, Muhammed Abdullah Canbaz","Epileptic seizure detection using hybrid machine learning methods",2017,"","","","",144,"2022-07-13 10:06:04","","10.1007/s00521-017-3003-y","","",,,,,130,26.00,43,3,5,"","",""
3,"Ethan G. Armstrong, J. Verhoeven","Machine learning analyses of bacterial oligonucleotide frequencies to assess the benthic impact of aquaculture",2020,"","","","",145,"2022-07-13 10:06:04","","10.3354/aei00353","","",,,,,3,1.50,2,2,2,"Aquaculture is a rapidly expanding industry and is now one of the primary sources of all consumed seafood. Intensive aquaculture production is associated with organic enrichment, which occurs as organic material settles onto the seafloor, creating anoxic conditions which disrupt ecological processes. Bacteria are sensitive bioindicators of organic enrichment, and supervised classifiers using features derived from 16s rRNA gene sequences have shown potential to become useful in aquaculture environmental monitoring. Current taxonomy-based approaches, however, are time intensive and built upon emergent features which cannot easily be condensed into a monitoring pipeline. Here, we used a taxonomy-free approach to examine 16s rRNA gene sequences derived from flocculent matter underneath and in proximity to hard-bottom salmon aquaculture sites in Newfoundland, Canada. Tetranucleotide frequencies (k = 4) were tabulated from sample sequences and included as features in a machine learning pipeline using the random forest algorithm to predict 4 levels of benthic disturbance; resulting classifications were compared to those obtained using a published taxonomy-based approach. Our results show that k-mer count features can effectively be used to create highly accurate predictions of benthic disturbance and can resolve intermediate changes in seafloor condition. In addition, we present a robust assessment of model performance which accounts for the effect of randomness in model creation. This work outlines a flexible framework for environmental assessments at aquaculture sites that is highly reproducible and free of taxonomy-assignment bias.","",""
1,"C. Duetz, S. Van Gassen, T. Westers, F. I. '. in 't Hout, E. Cremers, C. Alhan, C. Bachas, M. V. van Spronsen, H. Visser-Wisselaar, D. Chitu, A. D. de Graaf, J. Jansen, Y. Saeys, A. A. van de Loosdrecht","Machine Learning-Based Flow Cytometry Diagnostics in Myelodysplastic Syndromes: Validation in the HOVON89 Clinical Trial (EudraCT 2008-002195-10)",2020,"","","","",146,"2022-07-13 10:06:04","","10.1182/BLOOD-2020-136719","","",,,,,1,0.50,0,14,2,"Introduction  Flow cytometry is a recommended tool in the diagnostic work-up of cytopenic patients suspected for myelodysplastic syndromes. Currently used flow cytometry scores rely on human assessment of dysplastic features in the bone marrow. Although proven useful, these methods are labor intensive and require a high level of expertise. Therefore, we previously developed a machine learning-based workflow for flow cytometry diagnostics in MDS by combining computational cell detection and a machine learning-classifier. This workflow outperformed traditional diagnostic scores with respect to accuracy (sensitivity 85-97%, specificity 93-97%), time investment (<30 seconds) and required materials (manuscript submitted). In the present study, we validated sensitivity of the workflow in a well-characterized clinical trial cohort (HOVON89 EudraCT 2008-002195-10) of lower risk MDS patients.  Method  Patient inclusion and characteristics  Very low to intermediate risk MDS patients enrolled in the HOVON89 clinical trial (EudraCT 2008-002195-10) were included. 53 patients met the additional inclusion criteria, concerning written consent for add-on studies and availability of required flow cytometry data.  Sample preparation  Bone marrow samples were processed for flow cytometry analysis according to the European Leukemia Net guidelines. This study focused on the antibody combination optimized for assessment of myeloid progenitors and erythroid dysplasia (CD45, CD34, CD117, HLA-DR, CD71, CD36, CD105, CD33, sideward light scatter (SSC) and forward light scatter (FSC)).  Machine learning-based workflow  The machine learning-based workflow was developed in a prior study based on a reference cohort consisting of MDS patients without excess of blasts(n=67) and non-MDS cases (n=81) (Figure 1). MDS patients were diagnosed based on (cyto)morphology, cytogenetics and clinical follow-up. Non-MDS cases were patients with confirmed non-neoplastic cytopenias (n=69) and age-matched healthy individuals (n=12).  Results  In the validation cohort, the machine learning-based diagnostic workflow classified 49 out of 53 patients correctly, reaching a sensitivity of 92%. The workflow outperformed two currently used diagnostic tools for MDS flow cytometry, the Ogata score and integrated flow cytometry score (iFS). The former obtained 72% sensitivity (McNemar: p = 0.001) and the latter 83% sensitivity (McNemar: p = 0.06) in the validation cohort. Per patient, time required for automated analysis was less than 30 seconds.  All four MDS patients that classified false negatively had a normal karyotype and (very) low risk disease according to the IPSS-r. In three out of four patients, no mutations or MDS-associated immunophenotypic features were detected. One patients was diagnosed as MDS-MLD and three patients as MDS-RS-SLD according to the WHO 2016 classification.  The ten most relevant cellular features that discriminated between MDS and non-MDS patients in the reference data were confirmed in the current validation cohort. All ten features of MDS patients in the validation cohort were significantly different from non-MDS patients of the reference cohort (all features, p < 0.00001) (Figure 2). Seven out of ten features were similar in MDS patients of the validation cohort compared to those of the MDS patients of the reference cohort (p>0.05) (Figure 2).  Conclusion  In this validation study, we confirmed accuracy of machine learning-based flow cytometry diagnostics in lower risk MDS. The workflow obtained 92% sensitivity, which is in accordance with results from our previous study (85-97%), and outperformed currently used diagnostic flow cytometry scores for MDS (i.e. Ogata score and iFS). In our previous study specificity was 95% in both reference and test cohorts. Cellular features, most discriminative for diagnosis, were confirmed in the validation cohort, emphasizing robustness of the method. Additional benefits of this approach are the reduction in analysis time to less than thirty seconds per patient, reduction of required antibodies and increased reproducibility.        van de Loosdrecht: celgene: Honoraria; novartis: Honoraria. ","",""
1,"E. Bollt","Regularized Kernel Machine Learning for Data Driven Forecasting of Chaos",2020,"","","","",147,"2022-07-13 10:06:04","","","","",,,,,1,0.50,1,1,2,"Forecasting outcomes from initial states continues to be an essential task in dynamical systems theory as applied across the sciences and engineering. The data-driven philosophy has become prevalent across the community. While geometric methods founded in time series to rebuild the underlying geometry based on Taken’s embedding theorem have been popular and successful in previous decades, they are complex, computationally expensive, and parametrically intensive. The wave of machine learning methods have come to reveal that a black box oriented approach has a great deal to offer the fundamental problem of forecasting the future. Modelling the flow operator as a linear combination of nonlinear basis functions in terms of regression least squares fitting in a data-driven manner is straight forward to pose. However, there are two major obstacles to overcome. First, model complexity may lead to either underfitting or overfitting, but these can be mitigated by Tikohonov regularization. Another serious issue regards computational complexity, which can be overcome by the kernel trick, so that all necessary inner products in a high dimensional feature (basis function) space are computed implicitly as low-dimensional kernel operations. In particular kernel methods from the broader theory of support vector machines is founded in the functional analytic theory of Mercer’s theorem and also reproducing kernel Hilbert spaces (RKHS), but practically this fundamental concept in machine learning has become central to many efficient algorithms. Putting these concepts together, the efficiency of kernel methods, and the robustness of regularized regression are both possible within an approach called kernelized ridge regression. We show here that these allow for an especially useful way to carry forward time-series forecasting problems, as a simple to use and computationally efficient methodology. We demonstrate the utility of these concepts in terms of a progression of examples from low dimensional where direct analysis is possible, to high-dimensional and spatiotemporally chaotic, and then an experimental data set from physiology of heart rate and breathing interactions.","",""
17,"Yoonha Choi, T. Liu, D. Pankratz, T. Colby, N. Barth, D. Lynch, P. Walsh, G. Raghu, G. Kennedy, Jing Huang","Identification of usual interstitial pneumonia pattern using RNA-Seq and machine learning: challenges and solutions",2018,"","","","",148,"2022-07-13 10:06:04","","10.1186/s12864-018-4467-6","","",,,,,17,4.25,2,10,4,"","",""
21,"Daniyal Amir Awan, R. L. Cavalcante, M. Yukawa, S. Stańczak","Detection for 5G-NOMA: An Online Adaptive Machine Learning Approach",2017,"","","","",149,"2022-07-13 10:06:04","","10.1109/ICC.2018.8422449","","",,,,,21,4.20,5,4,5,"Non-orthogonal multiple access (NOMA) has emerged as a promising radio access technique for enabling the performance enhancements promised by the fifth-generation (5G) networks in terms of connectivity, latency, and spectrum efficiency. In the NOMA uplink, detection based on successive interference cancellation (SIC) with device clustering has been suggested. If the receivers are equipped with multiple antennas, SIC can be combined with minimum mean-squared error (MMSE) beamforming. However, there exists a tradeoff between the NOMA cluster size and the incurred SIC error. Larger clusters lead to larger errors but they are desirable from the spectrum efficiency and connectivity point of view. To enable the deployment of large clusters, we propose a novel online learning detection method for the NOMA uplink. We design an online adaptive filter in the sum space of linear and Gaussian reproducing kernel Hilbert spaces (RKHSs). Such a sum space design is robust against variations of a dynamic wireless network that can deteriorate the performance of a purely nonlinear adaptive filter. We demonstrate by simulations that the proposed method outperforms (symbol level) MMSE-SIC based detection for large cluster sizes.","",""
0,"Z. N. Ghaziani, Jesse Sun, R. Chan, H. Rakowski, M. Maron, E. Rowin, Bo Wang, W. Tsang","Abstract 16082: Machine Learning to Improve Left Ventricular Scar Quantification in Hypertrophic Cardiomyopathy Patients",2020,"","","","",150,"2022-07-13 10:06:04","","10.1161/CIRC.142.SUPPL_3.16082","","",,,,,0,0.00,0,8,2,"  Introduction:  Accurate and reproducible scar quantification of late gadolinium enhancement (LGE) images from cardiac magnetic resonance imaging (CMR) is important in risk stratifying hypertrophic cardiomyopathy (HCM) patients. Previous machine learning algorithms for CMR LGE quantification deployed three-dimensional convolutional neural network (CNN) architecture, which required image cropping and custom graphic processing units (GPUs) to function, thus limiting their general applicability. We aim to develop a deep two-dimensional (2D) CNN model that contours the left ventricle (LV) endo- and epicardial borders and quantifies LGE.      Hypothesis:  We hypothesize that a deep 2D CNN model, which uses commercially available GPUs, could be used to efficiently and accurately contour LV endo- and epicardial borders and quantify CMR LGE in HCM patients.      Methods:  We retrospectively studied 296 HCM patients (2423 images) from the University Health Network (Toronto, Canada) and Tufts Medical Center (Boston, USA). LGE images were manually segmented by an expert reader. Scar was defined as 5 standard deviations higher than the mean of the annotated normal region pixels. A 2D U-net CNN variant was used to train a model on 80% of the datasets. Testing was performed on the remaining 20%. We applied a 5-folds cross validation algorithm for training to improve model robustness. Model performance was assessed using the Dice Similarity Coefficient (DSC).      Results:  We were able to develop a deep learning model that could successfully perform both LV segmentation and scar quantification using a generally available GPU card. Our algorithm did not require image cropping and processed one image every 60 milliseconds. DSC scores averaged across the 5-folds was excellent at 0.89+0.22 for the endocardium and 0.81+0.17 for the epicardium, and good at 0.57+0.31 for scar.      Conclusions:  Using novel 2D CNN methods, we have successfully developed an automatic algorithm that rapidly provides LV endo- and epicardial contours and scar quantification on LGE CMR images that is superior to previously published studies. Unlike previous algorithms, our program does not require the use of custom CPUs or image cropping, potentially allowing it to be integrated into routine clinical practice. ","",""
0,"Jin Wook Kim, D. Moon","Optimizing Aging Male Symptom Questionnaire Through Genetic Algorithms Based Machine Learning Techniques",2020,"","","","",151,"2022-07-13 10:06:04","","10.5534/wjmh.190077","","",,,,,0,0.00,0,2,2,"Purpose Genetic algorithm (GA) is a machine learning optimization strategy where sample strategies compete for fitness to evolve an optimum solution. This study evolves the Aging Male Symptoms (AMS) with GA to better identify late onset hypogonadism (LOH) with serum testosterone. Materials and Methods GA was trained on a training set of standard AMS questionnaire on a nationwide LOH epidemiology study. Random matrices of selectors for particular items were generated. Each generation of was evolved through a fitness function determined by sensitivity. Threshold to determine positive serum testosterone level for LOH was randomized for each competing strategy. After 2,000 runs, with each run producing the best result out of a set of 3,000 randomly generated sets evolved through 300 generations, the best AMS selection matrix was then applied to a separately enrolled validation set to compare outcomes. Results Predictability for serum testosterone levels dropped markedly above 3.5 ng/mL during pilot training. Limiting the training to testosterone thresholds between 2.5 and 3.5 ng/mL the GA 93 different strategies. Only a selection of 5 items, determining for a threshold of 20 points and determining for a serum testosterone level of 3.16 ng/mL, showed robust reproducibility within the internal validation set. Applying these conditions to the independent validation set showed sensitivity improved from 0.66 to 0.77, with a specificity of 0.07 to 0.19, respectively. Conclusions GA method of selecting questionnaires improved AMS questionnaire significantly. This method can be easily applied to other questionnaires that do not correlate with physiological markers.","",""
0,"Bradley Drumheller, M. Amgad, A. Aljudi, Elliott B. Burdette, Leila Kutob, Cameron Neely, Adam J. Perricone, C. Shebelut, D. Jaye","Early Development of a Machine Learning Approach to Quantify MYC Immunohistochemical Staining in Lymphoma",2020,"","","","",152,"2022-07-13 10:06:04","","10.1093/ajcp/aqaa137.034","","",,,,,0,0.00,0,9,2,"  Newer data suggest that double expression of MYC and BCL2 proteins (DE) evaluated by quantitative immunohistochemistry (qIHC) may be a powerful marker of worse prognosis in diffuse large B cell lymphoma (DLBCL). Testing for DE status, defined as >40% MYC+ and >50% BCL2+ tumor cells, is recommended in the WHO 2016 classification and clinical trials are using DE scoring to assign therapy arms. However, other data suggest that significant variability in manual DE scoring diminishes the predictive value. Error sources include high interobserver variability (IOV) associated with field choice, discrimination of tumor immunoreactivity from adjacent non-neoplastic cells, cell-to-cell variability in staining intensity, crush artifacts and necrosis. Thus, there is a need for standardized, reproducible approaches for DE scoring by qIHC. To address this need, we have begun developing a novel machine-learning approach to analyze IHC digital pathology whole-slide images, focusing initially on MYC IHC.  Digital whole-slide images (400x) of 22 DLBCL cases were uploaded to a web-based annotation platform. Using all cases, one annotator created 138 regions of interest (ROIs) containing approximately 200 nucleated cells and representing a variety of tissue types. Eight pathologists were assigned the same 10 ROIs in which to annotate all nuclei from which ground-truth seed nucleus labels (location, classification) were created for a validation set. Nuclei were classified as “tumor-positive”, “tumor-negative”, “non-tumor-positive”, “non-tumor-negative”, or “unknown”. This generated a set of 15,792 annotations with 1974 +/- 272 (Avg+/-STD) labels/annotator. Agglomerative hierarchical clustering afforded the creation of 2299 ground-truth seed locations. A maximum diameter of 3 mm/cluster was set by visual inspection of annotations. Of these seed locations, 1041 (45%) were detected by 8/8 annotators and, on average, 6/8 agreed on class. 302 +/- 72 (Avg+/-STD) “tumor positive” labels per annotator generated 382 seeds locations, 178 (47%) of which were detected by 8/8 annotators, with an average of 7.5/8 agreeing on class. 286 +/- 168 (Avg+/-STD) “tumor-negative” labels per annotator generated 336 seeds, 195 (58%) of which were detected by 8/8 annotators, with an average of 5/8 agreeing on class. Among all classes, the “tumor-positive” label displayed best overall label agreement whereas the “tumor-negative“ label yielded similar localization rate, but lower class agreement. These promising early findings provide a novel basis for quantifying IOV and utilizing multi-observer agreement to create a ground-truth validation set for a supervised machine learning approach to qIHC. Future efforts will make use of these data to optimize the validation set by rationally determining the number of additional annotations required, optimizing the number of annotators per ROI required, devising an adaptive approach to nuclear clustering based on nuclear density, and utilizing the additional 31,422 annotations in hand from all annotators as a robust algorithm training set.","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",153,"2022-07-13 10:06:04","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
4,"Jungang Lou, Yunliang Jiang, Qing Shen, Ruiqin Wang, Zechao Li","Probabilistic Regularized Extreme Learning for Robust Modeling of Traffic Flow Forecasting.",2020,"","","","",154,"2022-07-13 10:06:04","","10.1109/TNNLS.2020.3027822","","",,,,,4,2.00,1,5,2,"The adaptive neurofuzzy inference system (ANFIS) is a structured multioutput learning machine that has been successfully adopted in learning problems without noise or outliers. However, it does not work well for learning problems with noise or outliers. High-accuracy real-time forecasting of traffic flow is extremely difficult due to the effect of noise or outliers from complex traffic conditions. In this study, a novel probabilistic learning system, probabilistic regularized extreme learning machine combined with ANFIS (probabilistic R-ELANFIS), is proposed to capture the correlations among traffic flow data and, thereby, improve the accuracy of traffic flow forecasting. The new learning system adopts a fantastic objective function that minimizes both the mean and the variance of the model bias. The results from an experiment based on real-world traffic flow data showed that, compared with some kernel-based approaches, neural network approaches, and conventional ANFIS learning systems, the proposed probabilistic R-ELANFIS achieves competitive performance in terms of forecasting ability and generalizability.","",""
80,"Xiaoqin Zhang, Mingyu Fan, Di Wang, Peng Zhou, D. Tao","Top-k Feature Selection Framework Using Robust 0–1 Integer Programming",2020,"","","","",155,"2022-07-13 10:06:04","","10.1109/TNNLS.2020.3009209","","",,,,,80,40.00,16,5,2,"Feature selection (FS), which identifies the relevant features in a data set to facilitate subsequent data analysis, is a fundamental problem in machine learning and has been widely studied in recent years. Most FS methods rank the features in order of their scores based on a specific criterion and then select the <inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> top-ranked features, where <inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> is the number of desired features. However, these features are usually not the top-<inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> features and may present a suboptimal choice. To address this issue, we propose a novel FS framework in this article to select the exact top-<inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> features in the unsupervised, semisupervised, and supervised scenarios. The new framework utilizes the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{0,2}$ </tex-math></inline-formula>-norm as the matrix sparsity constraint rather than its relaxations, such as the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1,2}$ </tex-math></inline-formula>-norm. Since the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{0,2}$ </tex-math></inline-formula>-norm constrained problem is difficult to solve, we transform the discrete <inline-formula> <tex-math notation=""LaTeX"">$\ell _{0,2}$ </tex-math></inline-formula>-norm-based constraint into an equivalent 0–1 integer constraint and replace the 0–1 integer constraint with two continuous constraints. The obtained top-<inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> FS framework with two continuous constraints is theoretically equivalent to the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{0,2}$ </tex-math></inline-formula>-norm constrained problem and can be optimized by the alternating direction method of multipliers (ADMM). Unsupervised and semisupervised FS methods are developed based on the proposed framework, and extensive experiments on real-world data sets are conducted to demonstrate the effectiveness of the proposed FS framework.","",""
5,"Sindhu Ghanta, Sriram Ganapathi Subramanian, S. Sundararaman, L. Khermosh, Vinay Sridhar, D. Arteaga, Q. Luo, Dhananjoy Das, Nisha Talagala","Interpretability and Reproducability in Production Machine Learning Applications",2018,"","","","",156,"2022-07-13 10:06:04","","10.1109/ICMLA.2018.00105","","",,,,,5,1.25,1,9,4,"Explainability/Interpretability in machine learning applications is becoming critical, with legal and industry requirements demanding human understandable machine learning results. We describe the additional complexities that occur when a known interpretability technique (canary models) is applied to a real production scenario. We furthermore argue that reproducibility is a key feature in practical usages of such interpretability techniques in production scenarios. With this motivation, we present a production ML reproducibility solution, namely a comprehensive time ordered event sequence for machine learning applications. We demonstrate how our approach can bring this known common interpretability technique into production viability. We further present the system design and early performance characteristics of our reproducibility solution.","",""
8,"Xiaoxuan Lu, Yushen Long, Han Zou, Chengpu Yu, Lihua Xie","Robust extreme learning machine for regression problems with its application to wifi based indoor positioning system",2014,"","","","",157,"2022-07-13 10:06:04","","10.1109/MLSP.2014.6958903","","",,,,,8,1.00,2,5,8,"We propose two kinds of robust extreme learning machines (RELMs) based on the close-to-mean constraint and the small-residual constraint respectively to solve the problem of noisy measurements in indoor positioning systems (IPSs). We formulate both RELMs as second order cone programming problems. The fact that feature mapping in ELM is known to users is exploited to give the needed information for robust constraints. Real-world indoor localization experimental results show that, the proposed algorithms can not only improve the accuracy and repeatability, but also reduce the deviations and worst case errors of IPSs compared with basic ELM and OPT-ELM based IPSs.","",""
12,"Zhongyang Zhang, Haoxiang Cheng, X. Hong, A. D. Narzo, O. Franzén, Shouneng Peng, A. Ruusalepp, J. Kovacic, J. Bjorkegren, Xiaobin Wang, K. Hao","EnsembleCNV: an ensemble machine learning algorithm to identify and genotype copy number variation using SNP array data",2018,"","","","",158,"2022-07-13 10:06:04","","10.1101/356667","","",,,,,12,3.00,1,11,4,"The associations between diseases/traits and copy number variants (CNVs) have not been systematically investigated in genome-wide association studies (GWASs), primarily due to a lack of robust and accurate tools for CNV genotyping. Herein, we propose a novel ensemble learning framework, ensembleCNV, to detect and genotype CNVs using single nucleotide polymorphism (SNP) array data. EnsembleCNV a) identifies and eliminates batch effects at raw data level; b) assembles individual CNV calls into CNV regions (CNVRs) from multiple existing callers with complementary strengths by a heuristic algorithm; c) re-genotypes each CNVR with local likelihood model adjusted by global information across multiple CNVRs; d) refines CNVR boundaries by local correlation structure in copy number intensities; e) provides direct CNV genotyping accompanied with confidence score, directly accessible for downstream quality control and association analysis. Benchmarked on two large datasets, ensembleCNV outperformed competing methods and achieved a high call rate (93.3%) and reproducibility (98.6%), while concurrently achieving high sensitivity by capturing 85% of common CNVs documented in the 1000 Genomes Project. Given this CNV call rate and accuracy, which are comparable to SNP genotyping, we suggest ensembleCNV holds significant promise for performing genome-wide CNV association studies and investigating how CNVs predispose to human diseases.","",""
1,"S. Valverde, Llucia Coll, Liliana Valencia, Albert Clérigues, A. Oliver, J. Vilanova, L. Ramió-Torrentá, À. Rovira, X. Lladó","Assessing the Accuracy and Reproducibility of PARIETAL: A Deep Learning Brain Extraction Algorithm.",2021,"","","","",159,"2022-07-13 10:06:04","","10.1002/jmri.27776","","",,,,,1,1.00,0,9,1,"BACKGROUND Manual brain extraction from magnetic resonance (MR) images is time-consuming and prone to intra- and inter-rater variability. Several automated approaches have been developed to alleviate these constraints, including deep learning pipelines. However, these methods tend to reduce their performance in unseen magnetic resonance imaging (MRI) scanner vendors and different imaging protocols.   PURPOSE To present and evaluate for clinical use PARIETAL, a pre-trained deep learning brain extraction method. We compare its reproducibility in a scan/rescan analysis and its robustness among scanners of different manufacturers.   STUDY TYPE Retrospective.   POPULATION Twenty-one subjects (12 women) with age range 22-48 years acquired using three different MRI scanner machines including scan/rescan in each of them.   FIELD STRENGTH/SEQUENCE T1-weighted images acquired in a 3-T Siemens with magnetization prepared rapid gradient-echo sequence and two 1.5 T scanners, Philips and GE, with spin-echo and spoiled gradient-recalled (SPGR) sequences, respectively.   ASSESSMENT Analysis of the intracranial cavity volumes obtained for each subject on the three different scanners and the scan/rescan acquisitions.   STATISTICAL TESTS Parametric permutation tests of the differences in volumes to rank and statistically evaluate the performance of PARIETAL compared to state-of-the-art methods.   RESULTS The mean absolute intracranial volume differences obtained by PARIETAL in the scan/rescan analysis were 1.88 mL, 3.91 mL, and 4.71 mL for Siemens, GE, and Philips scanners, respectively. PARIETAL was the best-ranked method on Siemens and GE scanners, while decreasing to Rank 2 on the Philips images. Intracranial differences for the same subject between scanners were 5.46 mL, 27.16 mL, and 30.44 mL for GE/Philips, Siemens/Philips, and Siemens/GE comparison, respectively. The permutation tests revealed that PARIETAL was always in Rank 1, obtaining the most similar volumetric results between scanners.   DATA CONCLUSION PARIETAL accurately segments the brain and it generalizes to images acquired at different sites without the need of training or fine-tuning it again. PARIETAL is publicly available.   LEVEL OF EVIDENCE 2 TECHNICAL EFFICACY STAGE: 2.","",""
217,"Ian J. Goodfellow, Nicolas Papernot, P. Mcdaniel","Cleverhans V0.1: an Adversarial Machine Learning Library",2016,"","","","",160,"2022-07-13 10:06:04","","","","",,,,,217,36.17,72,3,6,"cleverhans is a software library that provides standardized reference implementations of adversarial example construction techniques and adversarial training. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models’ performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section 1 provides an overview of adversarial examples in machine learning and of the cleverhans software. Section 2 presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section 3 describes how to report benchmark results using the library. Section 4 describes the versioning system.","",""
174,"Andrew F. Zahrt, J. Henle, Brennan T Rose, Yang Wang, William T. Darrow, S. Denmark","Prediction of higher-selectivity catalysts by computer-driven workflow and machine learning",2019,"","","","",161,"2022-07-13 10:06:04","","10.1126/science.aau5631","","",,,,,174,58.00,29,6,3,"Predicting catalyst selectivity Asymmetric catalysis is widely used in chemical research and manufacturing to access just one of two possible mirror-image products. Nonetheless, the process of tuning catalyst structure to optimize selectivity is still largely empirical. Zahrt et al. present a framework for more efficient, predictive optimization. As a proof of principle, they focused on a known coupling reaction of imines and thiols catalyzed by chiral phosphoric acid compounds. By modeling multiple conformations of more than 800 prospective catalysts, and then training machine-learning algorithms on a subset of experimental results, they achieved highly accurate predictions of enantioselectivities. Science, this issue p. eaau5631 A model encompassing multiple conformations of chiral phosphoric acid catalysts accurately predicts enantioselectivities. INTRODUCTION The development of new synthetic methods in organic chemistry is traditionally accomplished through empirical optimization. Catalyst design, wherein experimentalists attempt to qualitatively identify correlations between catalyst structure and catalyst efficiency, is no exception. However, this approach is plagued by numerous deficiencies, including the lack of mechanistic understanding of a new transformation, the inherent limitations of human cognitive abilities to find patterns in large collections of data, and the lack of quantitative guidelines to aid catalyst identification. Chemoinformatics provides an attractive alternative to empiricism for several reasons: Mechanistic information is not a prerequisite, catalyst structures can be characterized by three-dimensional (3D) descriptors (numerical representations of molecular properties derived from the 3D molecular structure) that quantify the steric and electronic properties of thousands of candidate molecules, and the suitability of a given catalyst candidate can be quantified by comparing its properties with a computationally derived model trained on experimental data. The ability to accurately predict a selective catalyst by using a set of less than optimal data remains a major goal for machine learning with respect to asymmetric catalysis. We report a method to achieve this goal and propose a more efficient alternative to traditional catalyst design. RATIONALE The workflow we have created consists of the following components: (i) construction of an in silico library comprising a large collection of conceivable, synthetically accessible catalysts derived from a particular scaffold; (ii) calculation of relevant chemical descriptors for each scaffold; (iii) selection of a representative subset of the catalysts [this subset is termed the universal training set (UTS) because it is agnostic to reaction or mechanism and thus can be used to optimize any reaction catalyzed by that scaffold]; (iv) collection of the training data; and (v) application of machine learning methods to generate models that predict the enantioselectivity of each member of the in silico library. These models are evaluated with an external test set of catalysts (predicting selectivities of catalysts outside of the training data). The validated models can then be used to select the optimal catalyst for a given reaction. RESULTS To demonstrate the viability of our method, we predicted reaction outcomes with substrate combinations and catalysts different from the training data and simulated a situation in which highly selective reactions had not been achieved. In the first demonstration, a model was constructed by using support vector machines and validated with three different external test sets. The first test set evaluated the ability of the model to predict the selectivity of only reactions forming new products with catalysts from the training set. The model performed well, with a mean absolute deviation (MAD) of 0.161 kcal/mol. Next, the same model was used to predict the selectivity of an external test set of catalysts with substrate combinations from the training set. The performance of the model was still highly accurate, with a MAD of 0.211 kcal/mol. Lastly, reactions forming new products with the external test catalysts were predicted with a MAD of 0.236 kcal/mol. In the second study, no reactions with selectivity above 80% enantiomeric excess were used as training data. Deep feed-forward neural networks accurately reproduced the experimental selectivity data, successfully predicting the most selective reactions. More notably, the general trends in selectivity, on the basis of average catalyst selectivity, were correctly identified. Despite omitting about half of the experimental free energy range from the training data, we could still make accurate predictions in this region of selectivity space. CONCLUSION The capability to predict selective catalysts has the potential to change the way chemists select and optimize chiral catalysts from an empirically guided to a mathematically guided approach. Chemoinformatics-guided optimization protocol. (A) Generation of a large in silico library of catalyst candidates. (B) Calculation of robust chemical descriptors. (C) Selection of a UTS. (D) Acquisition of experimental selectivity data. (E) Application of machine learning to use moderate- to low-selectivity reactions to predict high-selectivity reactions. R, any group; X, O or S; Y, OH, SH, or NHTf; PC, principal component; ΔΔG, mean selectivity. Catalyst design in asymmetric reaction development has traditionally been driven by empiricism, wherein experimentalists attempt to qualitatively recognize structural patterns to improve selectivity. Machine learning algorithms and chemoinformatics can potentially accelerate this process by recognizing otherwise inscrutable patterns in large datasets. Herein we report a computationally guided workflow for chiral catalyst selection using chemoinformatics at every stage of development. Robust molecular descriptors that are agnostic to the catalyst scaffold allow for selection of a universal training set on the basis of steric and electronic properties. This set can be used to train machine learning methods to make highly accurate predictive models over a broad range of selectivity space. Using support vector machines and deep feed-forward neural networks, we demonstrate accurate predictive modeling in the chiral phosphoric acid–catalyzed thiol addition to N-acylimines.","",""
0,"A. Shamsa, M. Paydayesh","Data-Driven Signal Recognition- A Machine Learning Application For The Real-Time Microseismic Monitoring",2018,"","","","",162,"2022-07-13 10:06:04","","10.3997/2214-4609.201803007","","",,,,,0,0.00,0,2,4,"A simple and robust machine learning technique is applied to automate signal detection and analyse recorded microseismic data. The method’s performance is tested and evaluated on real data. The fracture signals were well-detected using the proposed workflow and techniques when more data were introduced. In contrast to conventional methods, the techniques implemented herein described work on training the model prediction with additional data without restarting from the beginning, making them viable for continuous online learning. This method attempts to remove the burden of labour-intensive processing of microseismic data and replace it with a faster, cheaper, and more accurate way of achieving signal detection.","",""
0,"Matteo Zecchin, Sangwoo Park, O. Simeone, M. Kountouris, D. Gesbert","Robust Bayesian Learning for Reliable Wireless AI: Framework and Applications",2022,"","","","",163,"2022-07-13 10:06:04","","10.48550/arXiv.2207.00300","","",,,,,0,0.00,0,5,1,"—This work takes a critical look at the application of conventional machine learning methods to wireless communication problems through the lens of reliability and robustness. Deep learning techniques adopt a frequentist framework, and are known to provide poorly calibrated decisions that do not reproduce the true uncertainty caused by limitations in the size of the training data. Bayesian learning, while in principle capable of addressing this shortcoming, is in practice impaired by model misspeciﬁcation and by the presence of outliers. Both problems are pervasive in wireless communication settings, in which the capacity of machine learning models is subject to resource constraints and training data is affected by noise and interference. In this context, we explore the application of the framework of robust Bayesian learning. After a tutorial-style introduction to robust Bayesian learning, we showcase the merits of robust Bayesian learning on several important wireless communication problems in terms of accuracy, calibration, and robustness to outliers and misspeciﬁcation.","",""
1,"Adis Alihodzic, Eva Tuba, M. Tuba","An Improved Extreme Learning Machine Tuning by Flower Pollination Algorithm",2020,"","","","",164,"2022-07-13 10:06:04","","10.1007/978-3-030-28553-1_5","","",,,,,1,0.50,0,3,2,"","",""
48,"A. Chiuso, G. Pillonetto","System Identification: A Machine Learning Perspective",2019,"","","","",165,"2022-07-13 10:06:04","","10.1146/ANNUREV-CONTROL-053018-023744","","",,,,,48,16.00,24,2,3,"Estimation of functions from sparse and noisy data is a central theme in machine learning. In the last few years, many algorithms have been developed that exploit Tikhonov regularization theory and reproducing kernel Hilbert spaces. These are the so-called kernel-based methods, which include powerful approaches like regularization networks, support vector machines, and Gaussian regression. Recently, these techniques have also gained popularity in the system identification community. In both linear and nonlinear settings, kernels that incorporate information on dynamic systems, such as the smoothness and stability of the input–output map, can challenge consolidated approaches based on parametric model structures. In the classical parametric setting, the complexity of the model (the model order) needs to be chosen, typically from a finite family of alternatives, by trading bias and variance. This (discrete) model order selection step may be critical, especially when the true model does not belong to the model class. In regularization-based approaches, model complexity is controlled by tuning (continuous) regularization parameters, making the model selection step more robust. In this article, we review these new kernel-based system identification approaches and discuss extensions based on nuclear and [Formula: see text] norms.","",""
0,"Qunxiong Zhu, Xiaohan Zhang, Yuan Xu, Yanlin He","Intelligent Measurement Modeling Using a Novel Multi-nonlinear Mapping Based Extreme Learning Machine Integrated with Partial Least Square Regression",2020,"","","","",166,"2022-07-13 10:06:04","","10.1109/DDCLS49620.2020.9275221","","",,,,,0,0.00,0,4,2,"Accurate intelligent measurement modeling plays a key role in complex process industries. However, establishing an accurate and robust measurement model tends to be more and more difficult because of the increasing complexity in terms of nonlinearity and collinearity of data. To solve this problem, a novel multi-nonlinear mapping based extreme learning machine integrated with partial least square regression is proposed in this paper. In the proposed model, two problems of nonlinearity and collinearity are effectively dealt with by using multi-nonlinear mapping and partial least square regression, respectively. For evaluating performance, empirical studies on a commonly used bench mark problem and a real-world application confirm that the presented method can obtain high accuracy and high stability performance for intelligent measurement.","",""
8,"Hongyang Li, Y. Guan","Machine learning empowers phosphoproteome prediction in cancers",2020,"","","","",167,"2022-07-13 10:06:04","","10.1093/bioinformatics/btz639","","",,,,,8,4.00,4,2,2,"MOTIVATION Reversible protein phosphorylation is an essential post-translational modification regulating protein functions and signaling pathways in many cellular processes. Aberrant activation of signaling pathways often contributes to cancer development and progression. The mass spectrometry-based phosphoproteomics technique is a powerful tool to investigate the site-level phosphorylation of the proteome in a global fashion, paving the way for understanding the regulatory mechanisms underlying cancers. However, this approach is time-consuming and requires expensive instruments, specialized expertise, and a large amount of starting material. An alternative in silico approach is predicting the phosphoproteomic profiles of cancer patients from the available proteomic, transcriptomic, and genomic data.   RESULTS Here, we present a winning algorithm in the 2017 NCI-CPTAC DREAM Proteogenomics Challenge for predicting phosphorylation levels of the proteome across cancer patients. We integrate four components into our algorithm, including (1) baseline correlations between protein and phosphoprotein abundances, (2) universal protein-protein interactions, (3) shareable regulatory information across cancer tissues, and (4) associations among multi-phosphorylation sites of the same protein. When tested on a large held-out testing dataset of 108 breast and 62 ovarian cancer samples, our method ranked first in both cancer tissues, demonstrating its robustness and generalization ability.   AVAILABILITY Our code and reproducible results are freely available on GitHub: https://github.com/GuanLab/phosphoproteome_prediction.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
0,"Shaoyan Guo, Huifu Xu, Liwei Zhang","Statistical Robustness of Empirical Risks in Machine Learning",2020,"","","","",168,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,2,"This paper studies convergence of empirical risks in reproducing kernel Hilbert spaces (RKHS). A conventional assumption in the existing research is that empirical training data do not contain any noise but this may not be satisfied in some practical circumstances. Consequently the existing convergence results do not provide a guarantee as to whether empirical risks based on empirical data are reliable or not when the data contain some noise. In this paper, we fill out the gap in a few steps. First, we derive moderate sufficient conditions under which the expected risk changes stably (continuously) against small perturbation of the probability distribution of the underlying random variables and demonstrate how the cost function and kernel affect the stability. Second, we examine the difference between laws of the statistical estimators of the expected optimal loss based on pure data and contaminated data using Prokhorov metric and Kantorovich metric and derive some qualitative and quantitative statistical robustness results. Third, we identify appropriate metrics under which the statistical estimators are uniformly asymptotically consistent. These results provide theoretical grounding for analysing asymptotic convergence and examining reliability of the statistical estimators in a number of well-known machine learning models.","",""
22,"Y. Arai, T. Kondo, K. Fuse, Y. Shibasaki, M. Masuko, J. Sugita, T. Teshima, N. Uchida, T. Fukuda, K. Kakihana, Y. Ozawa, T. Eto, Masatsugu Tanaka, K. Ikegame, Takehiko Mori, K. Iwato, T. Ichinohe, Y. Kanda, Y. Atsuta","Using a machine learning algorithm to predict acute graft-versus-host disease following allogeneic transplantation.",2019,"","","","",169,"2022-07-13 10:06:04","","10.1182/bloodadvances.2019000934","","",,,,,22,7.33,2,19,3,"Acute graft-versus-host disease (aGVHD) is 1 of the critical complications that often occurs following allogeneic hematopoietic stem cell transplantation (HSCT). Thus far, various types of prediction scores have been created using statistical calculations. The primary objective of this study was to establish and validate the machine learning-dependent index for predicting aGVHD. This was a retrospective cohort study that involved analyzing databases of adult HSCT patients in Japan. The alternating decision tree (ADTree) machine learning algorithm was applied to develop models using the training cohort (70%). The ADTree algorithm was confirmed using the hazard model on data from the validation cohort (30%). Data from 26 695 HSCT patients transplanted from allogeneic donors between 1992 and 2016 were included in this study. The cumulative incidence of aGVHD was 42.8%. Of >40 variables considered, 15 were adapted into a model for aGVHD prediction. The model was tested in the validation cohort, and the incidence of aGVHD was clearly stratified according to the categorized ADTree scores; the cumulative incidence of aGVHD was 29.0% for low risk and 58.7% for high risk (hazard ratio, 2.57). Predicting scores for aGVHD also demonstrated the link between the risk of development aGVHD and overall survival after HSCT. The machine learning algorithms produced clinically reasonable and robust risk stratification scores. The relatively high reproducibility and low impacts from the interactions among the variables indicate that the ADTree algorithm, along with the other data-mining approaches, may provide tools for establishing risk score.","",""
21,"C. Maltecca, D. Lu, Constantino Schillebeeckx, N. McNulty, C. Schwab, C. Shull, F. Tiezzi","Predicting Growth and Carcass Traits in Swine Using Microbiome Data and Machine Learning Algorithms",2019,"","","","",170,"2022-07-13 10:06:04","","10.1038/s41598-019-43031-x","","",,,,,21,7.00,3,7,3,"","",""
2,"Ian Convy, W. Huggins, Haoran Liao, K. Birgitta Whaley","Mutual information scaling for tensor network machine learning",2021,"","","","",171,"2022-07-13 10:06:04","","10.1088/2632-2153/ac44a9","","",,,,,2,2.00,1,4,1,"Tensor networks have emerged as promising tools for machine learning, inspired by their widespread use as variational ansatze in quantum many-body physics. It is well known that the success of a given tensor network ansatz depends in part on how well it can reproduce the underlying entanglement structure of the target state, with different network designs favoring different scaling patterns. We demonstrate here how a related correlation analysis can be applied to tensor network machine learning, and explore whether classical data possess correlation scaling patterns similar to those found in quantum states, which might indicate the best network to use for a given dataset. We utilize mutual information (MI) as measure of correlations in classical data, and show that it can serve as a lower-bound on the entanglement needed for a probabilistic tensor network classifier. We then develop a logistic regression algorithm to estimate the MI between bipartitions of data features, and verify its accuracy on a set of Gaussian distributions designed to mimic different correlation patterns. Using this algorithm, we characterize the scaling patterns in the Modified National Institute of Standards and Technology and Tiny Images datasets, and find clear evidence of boundary-law scaling in the latter. This quantum-inspired classical analysis offers insight into the design of tensor networks that are best suited for specific learning tasks.","",""
0,"Junbo Wang, Amitangshu Pal, Qinglin Yang, K. Kant, Kaiming Zhu, Song Guo","Collaborative Machine Learning: Schemes, Robustness, and Privacy.",2022,"","","","",172,"2022-07-13 10:06:04","","10.1109/TNNLS.2022.3169347","","",,,,,0,0.00,0,6,1,"Distributed machine learning (ML) was originally introduced to solve a complex ML problem in a parallel way for more efficient usage of computation resources. In recent years, such learning has been extended to satisfy other objectives, namely, performing learning in situ on the training data at multiple locations and keeping the training datasets private while still allowing sharing of the model. However, these objectives have led to considerable research on the vulnerabilities of distributed learning both in terms of privacy concerns of the training data and the robustness of the learned overall model due to bad or maliciously crafted training data. This article provides a comprehensive survey of various privacy, security, and robustness issues in distributed ML.","",""
0,"H. Hosseiny, C. Masteller, Colin P. Phillips","Development of a machine learning model for river bedload",2022,"","","","",173,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,1,". Prediction of bedload sediment transport rates in rivers is a notoriously challenging problem due to inherent variability in river hydraulics and channel morphology. Machine learning offers a compelling approach to leverage the growing wealth of bedload transport observations towards the development of a data driven predictive model. We present an artificial neural network (ANN) model for predicting bedload transport rates informed by 8,117 measurements from 134 10 rivers. Inputs to the model were river discharge, flow width, bed slope, and four bed surface sediment sizes. A sensitivity analysis showed that all inputs to the ANN model contributed to a reasonable estimate of bedload flux. At individual sites, the ANN model was able to reproduce observed sediment rating curves with a variety of shapes and outperformed four standard bedload models. This ANN model has the potential to be broadly applied to predict bedload fluxes based on discharge and reach properties alone. This paper presented an artificial neural network (ANN) model for predicting river bedload. To do that, a large, measured bedload dataset, including 8,117 data points from 134 rivers, was gathered from the BedloadWeb, a free public online platform. The structure of the ANN included an input layer, an output layer, and five hidden layers with 600 neurons. The 255 inputs to the model included temporally variable river discharge and flow width, and static measurements of bed slope, D 16 , D 50 , D 84 , and D 90 . A sensitivity analysis was carried out to show the sensitivity of the model with the input parameters. The results showed that the ANN model was most sensitive to the river discharge and least sensitive to the largest grain size ( D 90 ). Our analysis suggests that including all available parameters in the ANN model better captures the covariations between the input and output parameters. Further, the ANN model provides robust prediction of the test (unseen) bedload 260 data ( n = 1,624) within the bounds of one order of magnitude. We highlight that an advantage of this ANN model is that it was developed on a broad range of rivers and appears to accurately capture the variation in the data, making this model a good candidate for predicting bedload fluxes at gaged sites. The proposed machine learning model in this research lays the foundations for efficient and accurate predictions of river bedload.","",""
0,"G. Sasikala, M. Laavanya, B. Sathyasri, C. Supraja, V. Mahalakshmi, S. Mole, J. Mulerikkal, S. Chidambaranathan, C. Arvind, K. Srihari, Minilu Dejene","An Innovative Sensing Machine Learning Technique to Detect Credit Card Frauds in Wireless Communications",2022,"","","","",174,"2022-07-13 10:06:04","","10.1155/2022/2439205","","",,,,,0,0.00,0,11,1,"There has been an increase in credit card fraud as e-commerce has become more widespread. Financial transactions are essential to our economy, so detecting bank fraud is essential. Experiments on automated and real-time fraud detection are needed here. There are numerous machine learning techniques for identifying credit card fraud, and the most prevalent are support vector machine (SVM), logic regression, and random forest. When models penalise all errors equally during training, the quality of these detection approaches becomes crucial. This paper uses an innovative sensing method to judge the classification algorithm by considering the misclassification cost and at the same time by employing SVM hyperparameter optimization using grid search cross-validation and separating the hyperplane using the theory of reproducing kernels like linear, Gaussian, and polynomial, and the robustness is maintained. Because of this, credit card fraud has been identified significantly more successful than in the past.","",""
0,"G. M. Anand, Heitor C. Megale, Sean H. Murphy, Theresa Weis, Zuwan Lin, Yichun He, Xiao Wang, Jia Liu, S. Ramanathan","Machine learning directed organoid morphogenesis uncovers an excitable system driving human axial elongation",2022,"","","","",175,"2022-07-13 10:06:04","","10.1101/2022.05.10.491358","","",,,,,0,0.00,0,9,1,"The human embryo breaks symmetry to form the anterior-posterior axis of the body. As the embryo elongates along this axis, progenitors in the tailbud give rise to axial tissues that generate the spinal cord, skeleton, and musculature. The mechanisms underlying human axial elongation are unknown. While ethics necessitate in vitro studies, the variability of human organoid systems has hindered mechanistic insights. Here we developed a bioengineering and machine learning framework that optimizes symmetry breaking by tuning the spatial coupling between human pluripotent stem cell-derived organoids. This framework enabled the reproducible generation of hundreds of axially elongating organoids, each possessing a tailbud and an epithelial neural tube with a single lumen. We discovered that an excitable system composed of WNT and FGF signaling drives axial elongation through the induction of a signaling center in the form of neuromesodermal progenitor (NMP)-like cells. The ability of NMP-like cells to function as a signaling center and drive elongation is independent of their potency to generate mesodermal cell types. We further discovered that the instability of the underlying excitable system is suppressed by secreted WNT inhibitors of the secreted frizzled-related protein (SFRP) family. Absence of these inhibitors led to the formation of ectopic tailbuds and branches. Our results identify mechanisms governing stable human axial elongation to achieve robust morphogenesis.","",""
0,"Davide Piras, B. Joachimi, F. Villaescusa-Navarro","Fast and realistic large-scale structure from machine-learning-augmented random field simulations",2022,"","","","",176,"2022-07-13 10:06:04","","10.48550/arXiv.2205.07898","","",,,,,0,0.00,0,3,1,"Producing thousands of simulations of the dark matter distribution in the Universe with increasing precision is a challenging but critical task to facilitate the exploitation of current and forthcoming cosmological surveys. Many inexpensive substitutes to full 𝑁 -body simulations have been proposed, even though they often fail to reproduce the statistics of the smaller, non-linear scales. Among these alternatives, a common approximation is represented by the lognormal distribution, which comes with its own limitations as well, while being extremely fast to compute even for high-resolution density ﬁelds. In this work, we train a machine learning model to transform projected lognormal dark matter density ﬁelds to more realistic dark matter maps, as obtained from full 𝑁 -body simulations. We detail the procedure that we follow to generate highly correlated pairs of lognormal and simulated maps, which we use as our training data, exploiting the information of the Fourier phases. We demonstrate the performance of our model comparing various statistical tests with diﬀerent ﬁeld resolutions, redshifts and cosmological parameters, proving its robustness and explaining its current limitations. The augmented lognormal random ﬁelds reproduce the power spectrum up to wavenumbers of 1 ℎ Mpc − 1 , the bispectrum and the peak counts within 10%, and always within the error bars, of the ﬁducial target simulations. Finally, we describe how we plan to integrate our proposed model with existing tools to yield more accurate spherical random ﬁelds for weak lensing analysis, going beyond the lognormal approximation.","",""
0,"A. Cornhill, S. Dykstra, A. Satriano, D. Labib, Y. Mikami, J. Flewitt, Easter Prosio, S. Rivest, R. Sandonato, A. Howarth, C. Lydell, C. Eastwood, H. Quan, N. Fine, Joon Lee, J. White","Machine Learning Patient-Specific Prediction of Heart Failure Hospitalization Using Cardiac MRI-Based Phenotype and Electronic Health Information",2022,"","","","",177,"2022-07-13 10:06:04","","10.3389/fcvm.2022.890904","","",,,,,0,0.00,0,16,1,"Background Heart failure (HF) hospitalization is a dominant contributor of morbidity and healthcare expenditures in patients with systolic HF. Cardiovascular magnetic resonance (CMR) imaging is increasingly employed for the evaluation of HF given capacity to provide highly reproducible phenotypic markers of disease. The combined value of CMR phenotypic markers and patient health information to deliver predictions of future HF events has not been explored. We sought to develop and validate a novel risk model for the patient-specific prediction of time to HF hospitalization using routinely reported CMR variables, patient-reported health status, and electronic health information. Methods Standardized data capture was performed for 1,775 consecutive patients with chronic systolic HF referred for CMR imaging. Patient demographics, symptoms, Health-related Quality of Life, pharmacy, and routinely reported CMR features were provided to both machine learning (ML) and competing risk Fine-Gray-based models (FGM) for the prediction of time to HF hospitalization. Results The mean age was 59 years with a mean LVEF of 36 ± 11%. The population was evenly distributed between ischemic (52%) and idiopathic non-ischemic cardiomyopathy (48%). Over a median follow-up of 2.79 years (IQR: 1.59–4.04) 333 patients (19%) experienced HF related hospitalization. Both ML and competing risk FGM based models achieved robust performance for the prediction of time to HF hospitalization. Respective 90-day, 1 and 2-year AUC values were 0.87, 0.83, and 0.80 for the ML model, and 0.89, 0.84, and 0.80 for the competing risk FGM-based model in a holdout validation cohort. Patients classified as high-risk by the ML model experienced a 34-fold higher occurrence of HF hospitalization at 90 days vs. the low-risk group. Conclusion In this study we demonstrated capacity for routinely reported CMR phenotypic markers and patient health information to be combined for the delivery of patient-specific predictions of time to HF hospitalization. This work supports an evolving migration toward multi-domain data collection for the delivery of personalized risk prediction at time of diagnostic imaging.","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",178,"2022-07-13 10:06:04","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
0,"Benjamin Holzschuh, C. M. O’Riordan, S. Vegetti, V. Rodriguez-Gomez, Nils Thuerey","Realistic galaxy images and improved robustness in machine learning tasks from generative modelling",2022,"","","","",179,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,5,1,"We examine the capability of generative models to produce realistic galaxy images. We show that mixing generated data with the original data improves the robustness in downstream machine learning tasks. We focus on three different data sets; analytical Sérsic profiles, real galaxies from the COSMOS survey, and galaxy images produced with the SKIRT code, from the IllustrisTNG simulation. We quantify the performance of each generative model using the Wasserstein distance between the distributions of morphological properties (e.g. the Gini-coefficient, the asymmetry, and ellipticity), the surface brightness distribution on various scales (as encoded by the power-spectrum), the bulge statistic and the colour for the generated and source data sets. With an average Wasserstein distance (Fréchet Inception Distance) of 7.19 × 10−2 (0.55), 5.98 × 10−2 (1.45) and 5.08 × 10−2 (7.76) for the Sérsic, COSMOS and SKIRT data set, respectively, our best models convincingly reproduce even themost complicated galaxy properties and create images that are visually indistinguishable from the source data. We demonstrate that by supplementing the training data set with generated data, it is possible to significantly improve the robustness against domain-shifts and out-ofdistribution data. In particular, we train a convolutional neural network to denoise a data set of mock observations. By mixing generated images into the original training data, we obtain an improvement of 11 and 45 per cent in the model performance regarding domain-shifts in the physical pixel size and background noise level, respectively.","",""
0,"K. Shimamura, Koura Akihide, F. Shimojo","Construction of Machine-Learning Interatomic Potential Under Heat Flux Regularization and Its Application to Power Spectrum Analysis for Silver Chalcogenides",2022,"","","","",180,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,1,"We propose a data-driven approach for constructing machine-learning interatomic potentials (MLIPs) trained under a regularization with the aim of avoiding nonphysical heat ﬂux. Speciﬁcally, we introduce a regularization term for the heat ﬂux into the cost function of MLIPs to be minimized. Since the treatment of heat ﬂux using MLIPs with regularization can be decomposed into elemental contributions or conducted in frequency space, this approach is expected to be useful for investigating the origin of thermal conductivity obtained from the Green-Kubo formula. However, the strength of regularization needs to be appropriately set because it may reduce not only the nonphysical part but also the intrinsic heat ﬂux one. To this end, we investigated the conditions for constructing MLIPs that can reproduce the power spectra of heat ﬂux associated with the empirical interatomic potential of Ag 2 Se, which consists of pairwise functions and do not contain a nonphysical heat ﬂux. The appropriate strength could be estimated from the variation of the magnitude of regularization term as well as root mean square errors for total potential energy, atomic force, and virial stress with respect to the strengths, without reference spectrum data. As an application example, we explored the differences in power spectra between superionic and nonsuperionic conducting phases based on the heat ﬂux regularization to MLIPs trained with the ﬁrst-principles calculation data of Ag 2 S. Furthermore, our results demonstrate that training with the regularization improves the robustness of MLIPs as well as the reduction of the nonphysical heat ﬂux.","",""
8,"Adedeji Olugboja, Zenghui Wang","Malaria parasite detection using different machine learning classifier",2017,"","","","",181,"2022-07-13 10:06:04","","10.1109/ICMLC.2017.8107772","","",,,,,8,1.60,4,2,5,"In the tropical and the subtropical countries, malaria has been a challenge, which really needs a quick and precise diagnosis to put a stop or control the disease. The conventional microscopy method has some shortcomings which includes time consumption and reproducibility. Many of the alternative methods are expensive and it's not readily accessible to the developing countries that need them. In this paper a fast and precise system was developed using stained blood smear images. We employed watershed segmentation technique to acquire plasmodium infected and non-infected erythrocytes and relevant feature was extracted. Six different machine learning techniques for classification are used in the experiments. Fine Gaussian SVM had a True Positive Rate (TPR) of 99.8% in the detection of the plasmodium infected erythrocyte.","",""
456,"Amir Mosavi, Pınar Öztürk, K. Chau","Flood Prediction Using Machine Learning Models: Literature Review",2018,"","","","",182,"2022-07-13 10:06:04","","10.3390/w10111536","","",,,,,456,114.00,152,3,4,"Floods are among the most destructive natural disasters, which are highly complex to model. The research on the advancement of flood prediction models contributed to risk reduction, policy suggestion, minimization of the loss of human life, and reduction of the property damage associated with floods. To mimic the complex mathematical expressions of physical processes of floods, during the past two decades, machine learning (ML) methods contributed highly in the advancement of prediction systems providing better performance and cost-effective solutions. Due to the vast benefits and potential of ML, its popularity dramatically increased among hydrologists. Researchers through introducing novel ML methods and hybridizing of the existing ones aim at discovering more accurate and efficient prediction models. The main contribution of this paper is to demonstrate the state of the art of ML models in flood prediction and to give insight into the most suitable models. In this paper, the literature where ML models were benchmarked through a qualitative analysis of robustness, accuracy, effectiveness, and speed are particularly investigated to provide an extensive overview on the various ML algorithms used in the field. The performance comparison of ML models presents an in-depth understanding of the different techniques within the framework of a comprehensive evaluation and discussion. As a result, this paper introduces the most promising prediction methods for both long-term and short-term floods. Furthermore, the major trends in improving the quality of the flood prediction models are investigated. Among them, hybridization, data decomposition, algorithm ensemble, and model optimization are reported as the most effective strategies for the improvement of ML methods. This survey can be used as a guideline for hydrologists as well as climate scientists in choosing the proper ML method according to the prediction task.","",""
0,"Wen Pan, C. Torres‐Verdín, I. Duncan, M. Pyrcz","REDUCING THE UNCERTAINTY OF MULTI-WELL PETROPHYSICAL INTERPRETATION FROM WELL LOGS VIA MACHINE-LEARNING AND STATISTICAL MODELS",2022,"","","","",183,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,4,1,"Well-log interpretation provides in situ estimates of formation properties such as porosity, hydrocarbon pore volume, and permeability. Reservoir models based on well-log-derived formation properties deliver reserve-volume estimates, production forecasts, and help with decision making in reservoir development. However, due to measurement errors, variability of well logs due to multiple measurement vendors, different borehole tools, and non-uniform drilling/borehole conditions, conventional well-log interpretation methods may not yield accurate estimates of formation properties, especially in the context of multi-well interpretation. To improve the robustness of multi-well petrophysical interpretation, well-log normalization techniques such as two-point scaling and mean-variance normalization are commonly used to impose stationarity constraints for well logs requiring correction. However, these techniques are mostly based on the marginal distribution of well logs and require expert knowledge to be effectively implemented. To reduce the uncertainties and time associated with multi-well petrophysical interpretation, we develop the discriminative adversarial (DA) model and the linear constraint model for well-log normalization and interpretation. We also develop a new divergence-based type well identification method for improved test-well and trainingwell adaptation. The DA neural network model developed for well-log normalization and interpretation can perform both linear and nonlinear well-log normalization by considering the joint distribution of all types of well logs and formation properties. To train the DA model, classical machinelearning models or classical petrophysical models are first trained to minimize the prediction error of formation properties in the training data set; then the adversarial model is trained to normalize well logs in the test set, such that the joint distribution of normalized well logs and formation property estimates of the test data set reproduce those of the training data set. The linear constraint model uses an ensemble of predictions from linear models to constrain both well-log normalization and interpretation. To identify wells with stationary formation properties as well as well logs, the divergence-based type well identification method is Petrophysical Interpretation via Machine-Learning and Statistical Models 3 developed to choose type wells for wells requiring correction based on well-log statistical similarity instead of closeness of wells. We apply the developed methods to improve the accuracy of well-log normalization and the estimation of permeability in a carbonate reservoir. Six types of well logs and over 9000 feet of core measurements from 30 wells drilled between 1980s and 2010s in the Seminole San Andres Unit are available to validate the new multi-well interpretation workflow. Our interpretation models is flexible to integrate any types of classical machine-learning methods and petrophysical assumptions for robust petrophysical estimations. In comparison to classical machine-learning models with no normalization, with two-point scaling normalization and with linear constraints, the DA method yields better performance, e.g., the mean-squared error of permeability estimation decreases by approximately 20-50%. Our interpretation workflow can be applied to other stationary signal and image processing problems to mitigate errors introduced by biased measurements, and to better adapt models calibrated with data from one field to other neighboring fields.","",""
0,"Suleyman Emre Isik, Ali Eren Aytekin, Halil Vurus","A machine learning approach for abstraction and reasoning problems without large amounts of data",2022,"","","","",184,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,1,"Journal of Emerging Investigators • www.emerginginvestigators.org level abstraction-reasoning ability which makes it difficult for algorithms to handle volatile and hard-to-predict real-life problems. The problems caused by this task-based nature necessitated flexibility and robustness for certain broader subfields of AI, such as L5 self-driving, domestic robotics, or personal assistants; there is even increasing interest in generality itself (e.g., developmental robotics, artificial general intelligence) (2, 3). The first and most important step to take in order to offer an approach that is closer to human intelligence is to examine the concept of intelligence and to define it in the most useful way. Various definitions have been made for intelligence in the past. Legg and Hutter summarized the definitions made in the context of artificial intelligence research as follows: ""Intelligence measures a person's ability to achieve goals in a wide and varied environment (4)."" Two main characteristics are emphasized here: a task-goal focus and generalizability to a wide range of environments. Accordingly, while human intelligence can perform tasks with its high ability, these abilities can also be generalized for new tasks in new environments (skill acquisition). This feature is a mechanism that human nature has developed in line with evolutionary psychology to solve new unknown tasks and problems (5, 6). In the direction of the development of AI, many approaches have emerged to develop and evaluate AI models. One of them is the human observational approach that examines, judges, and scores the system’s inputs and outputs. This is a highly subjective, difficult, and expensive method to automate. White-box analysis, on the other hand, is inspecting the implementation of the system to determine its input-output response and score it (e.g., an algorithm that plays “Connect Four”) (7). Peer confrontation, for example, is having the system compete against either other AIs or humans. This is the preferred mode of evaluation for player-versus-player games, such as chess. The benchmarking approach, which is based on enabling the system through algorithms to produce outputs for a ""test set"" of inputs (or environments) for which the desired outcome is known (solvable by humans), is another of the most valuable approaches for the evaluation of artificial intelligence. In particular, it is reproducible (test set fixed), scalable (cheap to run the evaluation multiple times), easy to set up, and flexible enough to be applied to a wide variety of possible tasks (8). For this reason, benchmarking has been an important part of progress in artificial intelligence A machine learning approach for abstraction and reasoning problems without large amounts of data","",""
0,"Daniel Castillo-Secilla, J. M. Gálvez, Francisco Carrillo-Perez, Juan Carlos Prieto- Prieto, O. Valenzuela, Luis Javier Herrera, Ignacio Rojas","Comprehensive PanCancer Gene Signature Assessment Through the Implementation of a Cascade Machine Learning System",2022,"","","","",185,"2022-07-13 10:06:04","","10.2174/1574893617666220421100512","","",,,,,0,0.00,0,7,1,"  Despite all the medical advances introduced for personalized patient treatment and the research supported in search of genetic patterns inherent to the occurrence of its different manifestations on the human being, the unequivocal and effective treatment of cancer unfortunately remains as an unresolved challenge within the scientific panorama. Until a universal solution for its control is achieved, early detection mechanisms for preventative diagnosis are increasingly avoiding therapeutic treatments which result in unreliable effectiveness. The discovery of unequivocal gene patterns allowing us to discern between multiple pathological states, could help to shed light on those patients with suspicion of oncological disease but with uncertainty in the histological and immunohistochemical results.    This study presents an approach for pancancer diagnosis based on gene expression analysis that determines a reduced set of 12 genes, which makes it possible to distinguish between the main 14 cancer diseases.    Our cascade machine learning process has been robustly designed, obtaining a mean F1-score of 92% and a mean AUC of 99.37% in the test set. Our study showed heterogeneous over-or underexpression of the analyzed genes, which are able to act as oncogenes or tumor suppressor genes. Upregulation of LPAR5 and PAX8 was demonstrated in thyroid cancer samples. KLF5 was highly expressed in the majority of cancer types.    Our model constituted a useful tool for pancancer gene expression evaluation. In addition to providing biological clues about a hypothetical common origin of cancer, the scalability of this study promises to be very useful for future studies to reinforce, confirm, and extend the biological observations presented here. Code availability and datasets are stored in the following GitHub repository to aim the research reproducibility: https://github.com/CasedUgr/PanCancerClassification. ","",""
3,"Finn Kuusisto, V. S. Costa, Zhonggang Hou, James A. Thomson, David Page, R. Stewart","Machine Learning to Predict Developmental Neurotoxicity with High-Throughput Data from 2D Bio-Engineered Tissues",2019,"","","","",186,"2022-07-13 10:06:04","","10.1109/ICMLA.2019.00055","","",,,,,3,1.00,1,6,3,"There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.","",""
3,"Minsung Hong, R. Akerkar","Analytics and Evolving Landscape of Machine Learning for Emergency Response",2019,"","","","",187,"2022-07-13 10:06:04","","10.1007/978-3-030-15628-2_11","","",,,,,3,1.00,2,2,3,"","",""
3,"Haoyu Yang, Wen Chen, P. Pathak, Frank Gennari, Ya-Chieh Lai, Bei Yu","Automatic Layout Generation with Applications in Machine Learning Engine Evaluation",2019,"","","","",188,"2022-07-13 10:06:04","","10.1109/MLCAD48534.2019.9142121","","",,,,,3,1.00,1,6,3,"Machine learning-based lithography hotspot detection has been deeply studied recently, from varies feature extraction techniques to efficient learning models. It has been observed that such machine learning-based frameworks are providing satisfactory metal layer hotspot prediction results on known public metal layer benchmarks. In this work, we seek to evaluate how these machine learning-based hotspot detectors generalize to complicated patterns. We first introduce a automatic layout generation tool that can synthesize varies layout patterns given a set of design rules. The tool currently supports both metal layer and via layer generation. As a case study, we conduct hotspot detection on the generated via layer layouts with representative machine learning-based hotspot detectors, which shows that continuous study on model robustness and generality is necessary to prototype and integrate the learning engines in DFM flows. The source code of the layout generation tool will be available at https://github.com/phdyang007/layout-generation.","",""
227,"Naomi Zimmerman, A. Presto, Srini Kumar, J. Gu, A. Hauryliuk, E. Robinson, A. Robinson, R. Subramanian","A machine learning calibration model using random forests to improve sensor performance for lower-cost air quality monitoring",2018,"","","","",189,"2022-07-13 10:06:04","","10.5194/AMT-11-291-2018","","",,,,,227,56.75,28,8,4,"Abstract. Low-cost sensing strategies hold the promise of denser air quality monitoring networks, which could significantly improve our understanding of personal air pollution exposure. Additionally, low-cost air quality sensors could be deployed to areas where limited monitoring exists. However, low-cost sensors are frequently sensitive to environmental conditions and pollutant cross-sensitivities, which have historically been poorly addressed by laboratory calibrations, limiting their utility for monitoring. In this study, we investigated different calibration models for the Real-time Affordable Multi-Pollutant (RAMP) sensor package, which measures CO, NO2, O3, and CO2. We explored three methods: (1) laboratory univariate linear regression, (2) empirical multiple linear regression, and (3) machine-learning-based calibration models using random forests (RF). Calibration models were developed for 16–19 RAMP monitors (varied by pollutant) using training and testing windows spanning August 2016 through February 2017 in Pittsburgh, PA, US. The random forest models matched (CO) or significantly outperformed (NO2, CO2, O3) the other calibration models, and their accuracy and precision were robust over time for testing windows of up to 16 weeks. Following calibration, average mean absolute error on the testing data set from the random forest models was 38 ppb for CO (14 % relative error), 10 ppm for CO2 (2 % relative error), 3.5 ppb for NO2 (29 % relative error), and 3.4 ppb for O3 (15 % relative error), and Pearson r versus the reference monitors exceeded 0.8 for most units. Model performance is explored in detail, including a quantification of model variable importance, accuracy across different concentration ranges, and performance in a range of monitoring contexts including the National Ambient Air Quality Standards (NAAQS) and the US EPA Air Sensors Guidebook recommendations of minimum data quality for personal exposure measurement. A key strength of the RF approach is that it accounts for pollutant cross-sensitivities. This highlights the importance of developing multipollutant sensor packages (as opposed to single-pollutant monitors); we determined this is especially critical for NO2 and CO2. The evaluation reveals that only the RF-calibrated sensors meet the US EPA Air Sensors Guidebook recommendations of minimum data quality for personal exposure measurement. We also demonstrate that the RF-model-calibrated sensors could detect differences in NO2 concentrations between a near-road site and a suburban site less than 1.5 km away. From this study, we conclude that combining RF models with carefully controlled state-of-the-art multipollutant sensor packages as in the RAMP monitors appears to be a very promising approach to address the poor performance that has plagued low-cost air quality sensors.","",""
0,"R. Murphy, Joshua D Kangas, C. Langmead","Tools Needed for Automating Science : Formalizing the use of Active Machine Learning to Drive Experimentation",2017,"","","","",190,"2022-07-13 10:06:04","","","","",,,,,0,0.00,0,3,5,"There is a need to develop and deploy advanced technologies for fully automating the execution of science and engineering projects. These technologies could dramatically decrease the costs of research and engineering, while increasing throughput and reproducibility. Existing platforms for automating research merely execute experiments selected by humans. What is needed are generalizable technologies (open source software and community standards) capable of closed-loop hypothesis generation from available data, experiment selection, and automated execution. Many biological and chemical systems are too complex for humans to understand completely, due to their scale and their nonlinear and stochastic behaviors. Traditionally, scientists and engineers choose and perform experiments to test hypotheses or to optimize designs. As the system’s complexity increases, the number of possible experiments that could be performed to study it rises exponentially, and, since resource constraints limit the number of experiments performed, we are faced with the need to select a maximally informative set of experiments from a combinatorial space of possible experiments, trying to optimize financial or other constraints. Unfortunately, the human mind is not well suited to solving this type of optimization problem, due most often to our inability to form predictive models at the scales involved. The result is that, in practice, many humanselected experiments are “wasted” on conditions where no effect is observed or, more importantly, where the effect is predictable from other experiments, given computational assistance. This waste of resources ultimately limits what scientists and engineers can accomplish. This type of problem is the realm of Active Learning [1-6], a sub-domain of Machine Learning focused on algorithms for iteratively choosing experiments expected to optimally improve an underlying computational model (Figure 1). While active learning could provide benefits for essentially all large scale screening and experimentation, such as drug development [7-8], there are significant barriers to its routine use. Perhaps the most significant is the absence of robust, readily available software to facilitate use by any group embarking on large scale experimentation. We therefore suggest the need for the development of open source tools and open access standards to enable the routine use of active learning driven experimentation. We suggest tools are needed for four connected tasks: random access experimentation; experimental data analysis; predictive model construction; and active learning experiment selection (Figure 2). The first component is the most involved, in that it may be highly specialized for particular types of experiments. However, the first step is to have the experimenter communicate to an automated system the specifics of how to perform an experiment and what experiments are allowed (e.g., which cell lines and drugs may be chosen from). The former is simply a protocol that, for example, liquid-handling robots and automated measurement systems are used to execute and open standards currently exist. The latter is simply defining the source plates/libraries. However, most current systems can only run the protocol for entire rows, columns or plates. The key to using such systems for active learning is to allow a computer to specify a particular set of experiments to perform that does not conform to these limitations (e.g., cells 1a, 4c, 9f, 2e, etc.). We suggest the need for collaboration between software developers, instrument manufacturers and contract research organizations to Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science 2 implement such systems and create open standards for a computer to communicate a desired set of experiments to an automated system without human intervention. The second component, predictive model generation, is also specialized for a particular type of data or problem, and would typically be paired with a particular protocol or instrument type. However, much work has been done on automated analysis and modeling pipelines for various data sources , the interfaces to which can be standardized. There has been significant work on the third of these components in the context of large experimental spaces. This first is on matrix completion methods that construct a predictive model for an entire space given data for some parts of that space. For example, work has been done on constructing a predictive model of drug-target interactions in the setting of drug discovery [9-11]. However, that work has focused on the task of predicting which new drugs will interact with known targets given data on the interactions of known drugs with those targets. In most settings, this has meant providing complete data for the subset of known drugs in order to train the model (i.e., values for many complete columns of the drug-target matrix); the assumption was that one was going to do no new experiments but simply try to predict their outcomes from a large body of comprehensive data. Recent results for the setting in which the training data is non-uniformly distributed over the drug-target matrix has been done [12,13]. The fourth component is active learning engines. Active learning has been studied in many contexts and for a number of different criteria for choosing experiments. However, the vast majority of this work has been retrospective: a large, complete dataset is ‘hidden’ from the active learner and individual data points are revealed upon request. This setting enables the calculation of the accuracy of the model at any point in the active learning process because all of the data is actually available. This setting does not apply to any real-world application in which the point is to avoid collecting all of the data. Additional work is needed on approaches for estimating the accuracy of an actively-learned model so that we can know when the model is good enough to stop doing acquisition Conclusion: Automation is the future of science and engineering. It will dramatically reduce the costs of discovery and development, while increasing throughput and reproducibility. More importantly, the use of automated model building and experiment selection via active learning will overcome the limits of the human mind, when it comes to reasoning about complex systems and the data they produce Figure 1. The Active Learning Cycle. The key is to iteratively select and execute experiments based on the current predictive model. Note that this is not the traditional “systems biology” approach that focuses on constructing a predictive model using data from a very large set of experiments and then trying to “prove” the model by doing selected additional Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science 3 experiments to verify high-confidence predictions. Such approaches ignore the fact that it is impossible to prove empirical models, and that the most appropriate use of new data is to improve a model! Note also that this different from trying to predict everything in silico – the active learning approach optimally combines computational prediction and experimental data acquisition. Figure 2. Components to be developed by the STC. 1) Tools for the experimenter to communicate to an automated system the specifics of what experiments are allowed (e.g., which cell lines and compounds may be chosen from) and how to perform them. 2) Tools for processing measurements (e.g., image analysis). These are specific to each type of study. 3) Tools for converting processed data into predictive models. This uses traditional machine learning methods or system identification methods, depending on the study. 4) Active learning engines. Most past work has been retrospective: a large, complete dataset is ‘hidden’ from the active learner and individual data points are revealed upon request. The STC will demonstrate the utility in real-world, prospective settings. Figure 3. Active Learning Examples. In a retrospective study of drug effects, 57% of active compounds were discovered with only 2.5% of possible experiments [13]. In a prospective study, a 92% accurate model of complex phenotypes was obtained after only 28% of possible experiments [14]. Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science","",""
3,"Noureldin Laban, B. Abdellatif, H. M. Ebeid, H. Shedeed, M. Tolba","Machine Learning for Enhancement Land Cover and Crop Types Classification",2018,"","","","",191,"2022-07-13 10:06:04","","10.1007/978-3-030-02357-7_4","","",,,,,3,0.75,1,5,4,"","",""
2,"Zhiqiang Geng, Qingchao Meng, Yongming Han, Qin Wei, Zhi Ouyang","An Improved Extreme Learning Machine Based on Auto-Encoder for Production Predictive Modeling of Industrial Processes",2019,"","","","",192,"2022-07-13 10:06:04","","10.1109/DDCLS.2019.8908949","","",,,,,2,0.67,0,5,3,"Industrial process data has the characteristics of complexity, variability and noisy, which brings challenges to data-driven production predictive modeling for industrial processes basing on the traditional extreme learning machine (ELM). Therefore, this paper proposes an improved ELM based on auto-encoder (AE) (AE-ELM). The AE can extract the main features with lower-dimension by eliminating the linear correlation among the original complex data. Then, the main features are used as the inputs of the ELM. For the purpose of verifying the effectiveness of the proposed method, the AE-ELM model has been experimented on the production prediction of the pure terephthalic acid (PTA). The experimental results prove that the AE-ELM is less sensitive to the structure of the traditional ELM and principal components extraction based robust ELM (PCE-RELM). Moreover, the modeling accuracy can be improved by 2.4%, which has certain guiding significance for process modeling and production prediction.","",""
3,"H. Clausen, R. Flood, D. Aspinall","Traffic Generation using Containerization for Machine Learning",2019,"","","","",193,"2022-07-13 10:06:04","","10.1145/3464458.3464460","","",,,,,3,1.00,1,3,3,"The design and evaluation of data-driven network intrusion detection methods are currently held back by a lack of adequate data, both in terms of benign and attack traffic. Existing datasets are mostly gathered in isolated lab environments containing virtual machines, to both offer more control over the computer interactions and prevent any malicious code from escaping. This procedure however leads to datasets that lack four core properties: heterogeneity, ground truth traffic labels, large data size, and contemporary content. Here, we present a novel data generation framework based on Docker containers that addresses these problems systematically. For this, we arrange suitable containers into relevant traffic communication scenarios and subscenarios, which are subject to appropriate input randomization as well as WAN emulation. By relying on process isolation through containerization, we can match traffic events with individual processes, and achieve scalability and modularity of individual traffic scenarios. We perform two experiments to assess the reproducability and traffic properties of our framework, and demonstrate the usefulness of our framework on a traffic classification example.","",""
7,"Ghislain Takam Tchendjou, Rshdee Alhakim, E. Simeu, F. Lebowsky","Evaluation of machine learning algorithms for image quality assessment",2016,"","","","",194,"2022-07-13 10:06:04","","10.1109/IOLTS.2016.7604697","","",,,,,7,1.17,2,4,6,"In this article, we apply different machine learning (ML) techniques for building objective models, that permit to automatically assess the image quality in agreement with human visual perception. The six ML methods proposed are discriminant analysis, k-nearest neighbors, artificial neural network, non-linear regression, decision tree and fuzzy logic. Both the stability and the robustness of designed models are evaluated by using Monte-Carlo cross-validation approach (MCCV). The simulation results demonstrate that fuzzy logic model provides the best prediction accuracy.","",""
312,"Jonas Rauber, Wieland Brendel, M. Bethge","Foolbox: A Python toolbox to benchmark the robustness of machine learning models",2017,"","","","",195,"2022-07-13 10:06:04","","","","",,,,,312,62.40,104,3,5,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox. The most up-to-date documentation can be found at http://foolbox.readthedocs.io. In 2013, Szegedy et al. demonstrated that minimal perturbations, often almost imperceptible to humans, can have devastating effects on machine predictions. These so-called adversarial perturbations thus demonstrate a striking difference between human and machine perception. As a result, adversarial perturbations have been subject to many Equal contribution Centre for Integrative Neuroscience, University of Tübingen, Germany Bernstein Center for Computational Neuroscience, Tübingen, Germany International Max Planck Research School for Intelligent Systems, Tübingen, Germany Max Planck Institute for Biological Cybernetics, Tübingen, Germany Institute for Theoretical Physics, University of Tübingen, Germany. Correspondence to: Jonas Rauber <jonas.rauber@bethgelab.org>. Reliable Machine Learning in the Wild Workshop, 34 th International Conference on Machine Learning, Sydney, Australia, 2017. studies concerning the generation of such perturbations and strategies to protect machine learning models such as deep neural networks against them. A practical definition of the robustness R of a model, first used by Szegedy et al. (2013), is the average size of the minimum adversarial perturbation ρ(x) across many samples x, R = 〈ρ(x)〉 x where (1) ρ(x) = min δ d(x,x+ δ) s.t. x+ δ is adversarial (2) and d(·) is some distance measure. Unfortunately, finding the global minimum adversarial perturbation is close to impossible in any practical setting, and we thus employ heuristic attacks to find a suitable approximation. Such heuristics, however, can fail, in which case we could easily be mislead to believe that a model is robust (Brendel & Bethge, 2017). Our best strategy is thus to employ as many attacks as possible, and to use the minimal perturbation found across all attacks as an approximation to the true global minimum. At the moment, however, such a strategy is severely obstructed by two problems: first, the code for most known attack methods is either not available at all, or only available for one particular deep learning framework. Second, implementations of the same attack often differ in many details and are thus not directly comparable. Foolbox improves upon the existing Python package cleverhans by Papernot et al. (2016b) in three important aspects: 1. It interfaces with most popular machine learning frameworks such as PyTorch, Keras, TensorFlow, Theano, Lasagne and MXNet and provides a straight forward way to add support for other frameworks, 2. it provides reference implementations for more than 15 adversarial attacks with a simple and consistent API, and 3. it supports many different criteria for adversarial examples, including custom ones. This technical report is structured as follows: In section 1 we provide an overview over Foolbox and demonstrate Foolbox: A Python toolbox to benchmark the robustness of machine learning models how to benchmark a model and report the result. In section 2 we describe the adversarial attack methods that are implemented in Foolbox and explain the internal hyperparameter tuning.","",""
10,"Yang Zhou, Yiu-ming Cheung","Bayesian Low-Tubal-Rank Robust Tensor Factorization with Multi-Rank Determination",2021,"","","","",196,"2022-07-13 10:06:04","","10.1109/TPAMI.2019.2923240","","",,,,,10,10.00,5,2,1,"Robust tensor factorization is a fundamental problem in machine learning and computer vision, which aims at decomposing tensors into low-rank and sparse components. However, existing methods either suffer from limited modeling power in preserving low-rank structures, or have difficulties in determining the target tensor rank and the trade-off between the low-rank and sparse components. To address these problems, we propose a fully Bayesian treatment of robust tensor factorization along with a generalized sparsity-inducing prior. By adapting the recently proposed low-tubal-rank model in a generative manner, our method is effective in preserving low-rank structures. Moreover, benefiting from the proposed prior and the Bayesian framework, the proposed method can automatically determine the tensor rank while inferring the trade-off between the low-rank and sparse components. For model estimation, we develop a variational inference algorithm, and further improve its efficiency by reformulating the variational updates in the frequency domain. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the proposed method in multi-rank determination as well as its superiority in image denoising and background modeling over state-of-the-art approaches.","",""
294,"Jaideep Pathak, Zhixin Lu, B. Hunt, M. Girvan, E. Ott","Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data.",2017,"","","","",197,"2022-07-13 10:06:04","","10.1063/1.5010300","","",,,,,294,58.80,59,5,5,"We use recent advances in the machine learning area known as ""reservoir computing"" to formulate a method for model-free estimation from data of the Lyapunov exponents of a chaotic process. The technique uses a limited time series of measurements as input to a high-dimensional dynamical system called a ""reservoir."" After the reservoir's response to the data is recorded, linear regression is used to learn a large set of parameters, called the ""output weights."" The learned output weights are then used to form a modified autonomous reservoir designed to be capable of producing an arbitrarily long time series whose ergodic properties approximate those of the input signal. When successful, we say that the autonomous reservoir reproduces the attractor's ""climate."" Since the reservoir equations and output weights are known, we can compute the derivatives needed to determine the Lyapunov exponents of the autonomous reservoir, which we then use as estimates of the Lyapunov exponents for the original input generating system. We illustrate the effectiveness of our technique with two examples, the Lorenz system and the Kuramoto-Sivashinsky (KS) equation. In the case of the KS equation, we note that the high dimensional nature of the system and the large number of Lyapunov exponents yield a challenging test of our method, which we find the method successfully passes.","",""
128,"S. Kiranyaz, T. Ince, M. Gabbouj","Multidimensional Particle Swarm Optimization for Machine Learning and Pattern Recognition",2013,"","","","",198,"2022-07-13 10:06:04","","10.1007/978-3-642-37846-1","","",,,,,128,14.22,43,3,9,"","",""
1,"Rober Boshra","Automated Machine Learning Framework for EEG/ERP Analysis: Viable Improvement on Traditional Approaches?",2016,"","","","",199,"2022-07-13 10:06:04","","","","",,,,,1,0.17,1,1,6,"Event Related Potential (ERP) measures derived from the electroencephalogram (EEG) have been widely used in research on language, cognition, and pathology. The high dimensionality (time x channel x condition) of a typical EEG/ERP dataset makes it a timeconsuming prospect to properly analyze, explore, and validate knowledge without a particular restricted hypothesis. This study proposes an automated empirical greedy approach to the analysis process to datamine an EEG dataset for the location, robustness, and latency of ERPs, if any, present in a given dataset. We utilize Support Vector Machines (SVM), a well established machine learning model, on top of a preprocessing pipeline that focuses on detecting differences across experimental conditions. A hybrid of monte-carlo bootstrapping, cross-validation, and permutation tests is used to ensure the reproducibility of results. This framework serves to reduce researcher bias, time spent during analysis, and provide statistically sound results that are agnostic to dataset specifications including the ERPs in question. This method has been tested and validated on three different datasets with different ERPs (N100, Mismatch Negativity (MMN), N2b, Phonological Mapping Negativity (PMN), and P300). Results show statistically significant, above-chance level identification of all ERPs in their respective experimental conditions, latency, and location.","",""
270,"Jonas Rauber, Wieland Brendel, M. Bethge","Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models",2017,"","","","",200,"2022-07-13 10:06:04","","","","",,,,,270,54.00,90,3,5,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at this https URL . The most up-to-date documentation can be found at this http URL .","",""
