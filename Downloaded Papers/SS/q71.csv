Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"Sebastian A. Schober, Y. Bahri, Cecilia Carbonelli, R. Wille","Neural Network Robustness Analysis Using Sensor Simulations for a Graphene-Based Semiconductor Gas Sensor",2022,"","","","",1,"2022-07-13 09:29:15","","10.3390/chemosensors10050152","","",,,,,0,0.00,0,4,1,"Despite their advantages regarding production costs and flexibility, chemiresistive gas sensors often show drawbacks in reproducibility, signal drift and ageing. As pattern recognition algorithms, such as neural networks, are operating on top of raw sensor signals, assessing the impact of these technological drawbacks on the prediction performance is essential for ensuring a suitable measuring accuracy. In this work, we propose a characterization scheme to analyze the robustness of different machine learning models for a chemiresistive gas sensor based on a sensor simulation model. Our investigations are structured into four separate studies: in three studies, the impact of different sensor instabilities on the concentration prediction performance of the algorithms is investigated, including sensor-to-sensor variations, sensor drift and sensor ageing. In a further study, the explainability of the machine learning models is analyzed by applying a state-of-the-art feature ranking method called SHAP. Our results show the feasibility of model-based algorithm testing and substantiate the need for the thorough characterization of chemiresistive sensor algorithms before sensor deployment in order to ensure robust measurement performance.","",""
32,"Christoph Haarburger, Gustav Müller-Franzes, Leon Weninger, C. Kuhl, D. Truhn, D. Merhof","Radiomics feature reproducibility under inter-rater variability in segmentations of CT images",2020,"","","","",2,"2022-07-13 09:29:15","","10.1038/s41598-020-69534-6","","",,,,,32,16.00,5,6,2,"","",""
15,"Prateek Munjal, Nasir Hayat, Munawar Hayat, J. Sourati, Shadab Khan","Towards Robust and Reproducible Active Learning Using Neural Networks",2020,"","","","",3,"2022-07-13 09:29:15","","","","",,,,,15,7.50,3,5,2,"Active learning (AL) is a promising ML paradigm that has the potential to parse through large unlabeled data and help reduce annotation cost in domains where labeling entire data can be prohibitive. Recently proposed neural network based AL methods use different heuristics to accomplish this goal. In this study, we show that recent AL methods offer a gain over random baseline under a brittle combination of experimental conditions. We demonstrate that such marginal gains vanish when experimental factors are changed, leading to reproducibility issues and suggesting that AL methods lack robustness. We also observe that with a properly tuned model, which employs recently proposed regularization techniques, the performance significantly improves for all AL methods including the random sampling baseline, and performance differences among the AL methods become negligible. Based on these observations, we suggest a set of experiments that are critical to assess the true effectiveness of an AL method. To facilitate these experiments we also present an open source toolkit. We believe our findings and recommendations will help advance reproducible research in robust AL using neural networks.","",""
4,"B. Nephew, M. Febo, R. Cali, K. Workman, L. Payne, C. Moore, J. King, A. Lacreuse","Robustness of sex-differences in functional connectivity over time in middle-aged marmosets",2020,"","","","",4,"2022-07-13 09:29:15","","10.1038/s41598-020-73811-9","","",,,,,4,2.00,1,8,2,"","",""
56,"N. Arun, N. Gaw, P. Singh, K. Chang, M. Aggarwal, B. Chen, K. Hoebel, S. Gupta, J. Patel, M. Gidwani, J. Adebayo, M. D. Li, Jayashree Kalpathy-Cramer","Assessing the (Un)Trustworthiness of Saliency Maps for Localizing Abnormalities in Medical Imaging",2020,"","","","",5,"2022-07-13 09:29:15","","10.1101/2020.07.28.20163899","","",,,,,56,28.00,6,13,2,"Saliency maps have become a widely used method to make deep learning models more interpretable by providing post-hoc explanations of classifiers through identification of the most pertinent areas of the input medical image. They are increasingly being used in medical imaging to provide clinically plausible explanations for the decisions the neural network makes. However, the utility and robustness of these visualization maps has not yet been rigorously examined in the context of medical imaging. We posit that trustworthiness in this context requires 1) localization utility, 2) sensitivity to model weight randomization, 3) repeatability, and 4) reproducibility. Using the localization information available in two large public radiology datasets, we quantify the performance of eight commonly used saliency map approaches for the above criteria using area under the precision-recall curves (AUPRC) and structural similarity index (SSIM), comparing their performance to various baseline measures. Using our framework to quantify the trustworthiness of saliency maps, we show that all eight saliency map techniques fail at least one of the criteria and are, in most cases, less trustworthy when compared to the baselines. We suggest that their usage in the high-risk domain of medical imaging warrants additional scrutiny and recommend that detection or segmentation models be used if localization is the desired output of the network.","",""
10,"Peter L. Schrammen, N. Ghaffari Laleh, A. Echle, D. Truhn, V. Schulz, T. Brinker, H. Brenner, J. Chang-Claude, E. Alwers, A. Brobeil, M. Kloor, L. Heij, D. Jäger, C. Trautwein, H. Grabsch, P. Quirke, N. West, M. Hoffmeister, J. Kather","Weakly supervised annotation‐free cancer detection and prediction of genotype in routine histopathology",2021,"","","","",6,"2022-07-13 09:29:15","","10.1002/path.5800","","",,,,,10,10.00,1,19,1,"Deep learning is a powerful tool in computational pathology: it can be used for tumor detection and for predicting genetic alterations based on histopathology images alone. Conventionally, tumor detection and prediction of genetic alterations are two separate workflows. Newer methods have combined them, but require complex, manually engineered computational pipelines, restricting reproducibility and robustness. To address these issues, we present a new method for simultaneous tumor detection and prediction of genetic alterations: The Slide‐Level Assessment Model (SLAM) uses a single off‐the‐shelf neural network to predict molecular alterations directly from routine pathology slides without any manual annotations, improving upon previous methods by automatically excluding normal and non‐informative tissue regions. SLAM requires only standard programming libraries and is conceptually simpler than previous approaches. We have extensively validated SLAM for clinically relevant tasks using two large multicentric cohorts of colorectal cancer patients, Darmkrebs: Chancen der Verhütung durch Screening (DACHS) from Germany and Yorkshire Cancer Research Bowel Cancer Improvement Programme (YCR‐BCIP) from the UK. We show that SLAM yields reliable slide‐level classification of tumor presence with an area under the receiver operating curve (AUROC) of 0.980 (confidence interval 0.975, 0.984; n = 2,297 tumor and n = 1,281 normal slides). In addition, SLAM can detect microsatellite instability (MSI)/mismatch repair deficiency (dMMR) or microsatellite stability/mismatch repair proficiency with an AUROC of 0.909 (0.888, 0.929; n = 2,039 patients) and BRAF mutational status with an AUROC of 0.821 (0.786, 0.852; n = 2,075 patients). The improvement with respect to previous methods was validated in a large external testing cohort in which MSI/dMMR status was detected with an AUROC of 0.900 (0.864, 0.931; n = 805 patients). In addition, SLAM provides human‐interpretable visualization maps, enabling the analysis of multiplexed network predictions by human experts. In summary, SLAM is a new simple and powerful method for computational pathology that could be applied to multiple disease contexts. © 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland.","",""
38,"M. Zareef, Quansheng Chen, M. Hassan, Muhammad Arslan, M. M. Hashim, Waqas Ahmad, F. Kutsanedzie, A. A. Agyekum","An Overview on the Applications of Typical Non-linear Algorithms Coupled With NIR Spectroscopy in Food Analysis",2020,"","","","",7,"2022-07-13 09:29:15","","10.1007/s12393-020-09210-7","","",,,,,38,19.00,5,8,2,"","",""
2,"Anna Asch, Ethan Brady, Hugo Gallardo, John Hood, Bryan Chu, M. Farazmand","Model-assisted deep learning of rare extreme events from partial observations",2021,"","","","",8,"2022-07-13 09:29:15","","10.1063/5.0077646","","",,,,,2,2.00,0,6,1,"To predict rare extreme events using deep neural networks, one encounters the so-called small data problem because even long-term observations often contain few extreme events. Here, we investigate a model-assisted framework where the training data are obtained from numerical simulations, as opposed to observations, with adequate samples from extreme events. However, to ensure the trained networks are applicable in practice, the training is not performed on the full simulation data; instead, we only use a small subset of observable quantities, which can be measured in practice. We investigate the feasibility of this model-assisted framework on three different dynamical systems (Rössler attractor, FitzHugh-Nagumo model, and a turbulent fluid flow) and three different deep neural network architectures (feedforward, long short-term memory, and reservoir computing). In each case, we study the prediction accuracy, robustness to noise, reproducibility under repeated training, and sensitivity to the type of input data. In particular, we find long short-term memory networks to be most robust to noise and to yield relatively accurate predictions, while requiring minimal fine-tuning of the hyperparameters.","",""
57,"Steven Zimmerman, Udo Kruschwitz, C. Fox","Improving Hate Speech Detection with Deep Learning Ensembles",2018,"","","","",9,"2022-07-13 09:29:15","","","","",,,,,57,14.25,19,3,4,"Hate speech has become a major issue that is currently a hot topic in the domain of social media. Simultaneously, current proposed methods to address the issue raise concerns about censorship. Broadly speaking, our research focus is the area human rights, including the development of new methods to identify and better address discrimination while protecting freedom of expression. As neural network approaches are becoming state of the art for text classification problems, an ensemble method is adapted for usage with neural networks and is presented to better classify hate speech. Our method utilizes a publicly available embedding model, which is tested against a hate speech corpus from Twitter. To confirm robustness of our results, we additionally test against a popular sentiment dataset. Given our goal, we are pleased that our method has a nearly 5 point improvement in F-measure when compared to original work on a publicly available hate speech evaluation dataset. We also note difficulties encountered with reproducibility of deep learning methods and comparison of findings from other work. Based on our experience, more details are needed in published work reliant on deep learning methods, with additional evaluation information a consideration too. This information is provided to foster discussion within the research community for future work.","",""
11,"Laura Sander, S. Pezold, Simon Andermatt, M. Amann, D. Meier, M. J. Wendebourg, T. Sinnecker, E. Radue, Y. Naegelin, C. Granziera, L. Kappos, J. Wuerfel, P. Cattin, R. Schlaeger","Accurate, rapid and reliable, fully automated MRI brainstem segmentation for application in multiple sclerosis and neurodegenerative diseases",2019,"","","","",10,"2022-07-13 09:29:15","","10.1002/hbm.24687","","",,,,,11,3.67,1,14,3,"Neurodegenerative disorders, such as Alzheimer's disease (AD) and progressive forms of multiple sclerosis (MS), can affect the brainstem and are associated with atrophy that can be visualized by MRI. Anatomically accurate, large‐scale assessments of brainstem atrophy are challenging due to lack of automated, accurate segmentation methods. We present a novel method for brainstem volumetry using a fully‐automated segmentation approach based on multi‐dimensional gated recurrent units (MD‐GRU), a deep learning based semantic segmentation approach employing a convolutional adaptation of gated recurrent units. The neural network was trained on 67 3D‐high resolution T1‐weighted MRI scans from MS patients and healthy controls (HC) and refined using segmentations of 20 independent MS patients' scans. Reproducibility was assessed in MR test–retest experiments in 33 HC. Accuracy and robustness were examined by Dice scores comparing MD‐GRU to FreeSurfer and manual brainstem segmentations in independent MS and AD datasets. The mean %‐change/SD between test–retest brainstem volumes were 0.45%/0.005 (MD‐GRU), 0.95%/0.009 (FreeSurfer), 0.86%/0.007 (manually edited segmentations). Comparing MD‐GRU to manually edited segmentations the mean Dice scores/SD were: 0.97/0.005 (brainstem), 0.95/0.013 (mesencephalon), 0.98/0.006 (pons), 0.95/0.015 (medulla oblongata). Compared to the manual gold standard, MD‐GRU brainstem segmentations were more accurate than FreeSurfer segmentations (p < .001). In the multi‐centric acquired AD data, the mean Dice score/SD for the MD‐GRU‐manual segmentation comparison was 0.97/0.006. The fully automated brainstem segmentation method MD‐GRU provides accurate, highly reproducible, and robust segmentations in HC and patients with MS and AD in 200 s/scan on an Nvidia GeForce GTX 1080 GPU and shows potential for application in large and longitudinal datasets.","",""
131,"V. Afraimovich, V. Zhigulin, M. Rabinovich","On the origin of reproducible sequential activity in neural circuits.",2004,"","","","",11,"2022-07-13 09:29:15","","10.1063/1.1819625","","",,,,,131,7.28,44,3,18,"Robustness and reproducibility of sequential spatio-temporal responses is an essential feature of many neural circuits in sensory and motor systems of animals. The most common mathematical images of dynamical regimes in neural systems are fixed points, limit cycles, chaotic attractors, and continuous attractors (attractive manifolds of neutrally stable fixed points). These are not suitable for the description of reproducible transient sequential neural dynamics. In this paper we present the concept of a stable heteroclinic sequence (SHS), which is not an attractor. SHS opens the way for understanding and modeling of transient sequential activity in neural circuits. We show that this new mathematical object can be used to describe robust and reproducible sequential neural dynamics. Using the framework of a generalized high-dimensional Lotka-Volterra model, that describes the dynamics of firing rates in an inhibitory network, we present analytical results on the existence of the SHS in the phase space of the network. With the help of numerical simulations we confirm its robustness in presence of noise in spite of the transient nature of the corresponding trajectories. Finally, by referring to several recent neurobiological experiments, we discuss possible applications of this new concept to several problems in neuroscience.","",""
0,"V. Afraimovich, V. Zhigulin, M. Rabinovich","Detecting event-related recurrences by symbolic analysis: Applications to human language processing",2019,"","","","",12,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,3,3,"Robustness and reproducibility of sequential spatio-temporal responses is an essential feature of many neural circuits in sensory and motor systems of animals. The most common mathematical images of dynamical regimes in neural systems are ﬁxed points, limit cycles, chaotic attractors, and continuous attractors ( attractive manifolds of neutrally stable ﬁxed points ) . These are not suitable for the description of reproducible transient sequential neural dynamics. In this paper we present the concept of a stable heteroclinic sequence ( SHS ) , which is not an attractor. SHS opens the way for understanding and modeling of transient sequential activity in neural circuits. We show that this new mathematical object can be used to describe robust and reproducible sequential neural dynamics. Using the framework of a generalized high-dimensional Lotka–Volterra model, that describes the dynamics of ﬁring rates in an inhibitory network, we present analytical results on the existence of the SHS in the phase space of the network. With the help of numerical simulations we conﬁrm its robustness in presence of noise in spite of the transient nature of the corresponding trajectories. Finally, by referring to several recent neurobiological experiments, we discuss possible applications of this new concept to several problems in neuroscience. © 2004 American Institute of Physics . [ DOI: 10.1063/1.1819625 hunting motion to ﬁnd its prey and, in spite of the irregularity of this motion, the sequence of Clione’s tail positions is also reproducible. Reproducible sequential neural activity is involved in sequential memory processes, fast recognition of stimuli by olfactory and auditory sensory systems and many other dynamical functions of the nervous system. What is the dynamical origin of such reproducibility? Which conditions do the synaptic connections of the neural circuits have to satisfy to generate reproducible transient sequences? In this paper we answer these questions using a generalized Lotka–Volterra model. We present a new mathematical construction—a stable heteroclinic sequence (SHS)—that describes reproducible sequence generation in the phase space of the dynamical model of a neural circuit. This construction keeps trajectories the vicinity of the heteroclinic to of a stable","",""
1,"Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jie Tang","Graph Robustness Benchmark: Rethinking and Benchmarking Adversarial Robustness of Graph Neural Networks",2021,"","","","",13,"2022-07-13 09:29:15","","","","",,,,,1,1.00,0,6,1,"Recent studies have shown that Graph Neural Networks (GNNs) are vulnerable to 1 adversarial attacks. Previous attacks and defenses on GNNs face common prob2 lems like scalability or generality, which hinder the progress of this domain. By 3 rethinking limitations in previous works, we propose Graph Robustness Benchmark 4 (GRB), the first benchmark that aims to provide scalable, general, unified, and 5 reproducible evaluation on adversarial robustness of GNNs. GRB includes (1) 6 scalable datasets processed by a novel splitting scheme; (2) diverse set of baseline 7 methods covering GNNs, attacks, and defenses; (3) unified evaluation pipeline that 8 permits a fair comparison; (4) modular coding framework that facilitates imple9 mentation of various methods and ensures reproducibility; (5) leaderboards that 10 track the progress of the field. Besides, we propose two strong baseline defenses 11 that significantly outperform previous ones. With extensive experiments, we can 12 fairly compare all methods and investigate their pros and cons. GRB is open-source 13 and maintains all datasets, codes, leaderboards at https://cogdl.ai/grb/home, 14 which will be continuously updated to promote future research in this field. 15","",""
4,"Mingpeng Zhao, Murong Xu, Hanhui Li, O. Alqawasmeh, J. Chung, T. Li, Tin-Lap Lee, P. Tang, D. Chan","Application of convolutional neural network on early human embryo segmentation during in vitro fertilization",2021,"","","","",14,"2022-07-13 09:29:15","","10.1111/jcmm.16288","","",,,,,4,4.00,0,9,1,"Selection of the best quality embryo is the key for a faithful implantation in in vitro fertilization (IVF) practice. However, the process of evaluating numerous images captured by time‐lapse imaging (TLI) system is time‐consuming and some important features cannot be recognized by naked eyes. Convolutional neural network (CNN) is used in medical imaging yet in IVF. The study aims to apply CNN on day‐one human embryo TLI. We first presented CNN algorithm for day‐one human embryo segmentation on three distinct features: zona pellucida (ZP), cytoplasm and pronucleus (PN). We tested the CNN performance compared side‐by‐side with manual labelling by clinical embryologist, then measured the segmented day‐one human embryo parameters and compared them with literature reported values. The precisions of segmentation were that cytoplasm over 97%, PN over 84% and ZP around 80%. For the morphometrics data of cytoplasm, ZP and PN, the results were comparable with those reported in literatures, which showed high reproducibility and consistency. The CNN system provides fast and stable analytical outcome to improve work efficiency in IVF setting. To conclude, our CNN system is potential to be applied in practice for day‐one human embryo segmentation as a robust tool with high precision, reproducibility and speed.","",""
4,"Yukiya Hono, Kei Hashimoto, Keiichiro Oura, Yoshihiko Nankaku, K. Tokuda","Sinsy: A Deep Neural Network-Based Singing Voice Synthesis System",2021,"","","","",15,"2022-07-13 09:29:15","","10.1109/TASLP.2021.3104165","","",,,,,4,4.00,1,5,1,"This paper presents Sinsy, a deep neural network (DNN)-based singing voice synthesis (SVS) system. In recent years, DNNs have been utilized in statistical parametric SVS systems, and DNN-based SVS systems have demonstrated better performance than conventional hidden Markov model-based ones. SVS systems are required to synthesize a singing voice with pitch and timing that strictly follow a given musical score. Additionally, singing expressions that are not described on the musical score, such as vibrato and timing fluctuations, should be reproduced. The proposed system is composed of four modules: a time-lag model, a duration model, an acoustic model, and a vocoder, and singing voices can be synthesized taking these characteristics of singing voices into account. To better model a singing voice, the proposed system incorporates improved approaches to modeling pitch and vibrato and better training criteria into the acoustic model. In addition, we incorporated PeriodNet, a non-autoregressive neural vocoder with robustness for the pitch, into our systems to generate a high-fidelity singing voice waveform. Moreover, we propose automatic pitch correction techniques for DNN-based SVS to synthesize singing voices with correct pitch even if the training data has out-of-tune phrases. Experimental results show our system can synthesize a singing voice with better timing, more natural vibrato, and correct pitch, and it can achieve better mean opinion scores in subjective evaluation tests.","",""
36,"Wei He, Yongkun Sun, Zichen Yan, Chenguang Yang, Zhijun Li, O. Kaynak","Disturbance Observer-Based Neural Network Control of Cooperative Multiple Manipulators With Input Saturation",2020,"","","","",16,"2022-07-13 09:29:15","","10.1109/TNNLS.2019.2923241","","",,,,,36,18.00,6,6,2,"In this paper, the complex problems of internal forces and position control are studied simultaneously and a disturbance observer-based radial basis function neural network (RBFNN) control scheme is proposed to: 1) estimate the unknown parameters accurately; 2) approximate the disturbance experienced by the system due to input saturation; and 3) simultaneously improve the robustness of the system. More specifically, the proposed scheme utilizes disturbance observers, neural network (NN) collaborative control with an adaptive law, and full state feedback. Utilizing Lyapunov stability principles, it is shown that semiglobally uniformly bounded stability is guaranteed for all controlled signals of the closed-loop system. The effectiveness of the proposed controller as predicted by the theoretical analysis is verified by comparative experimental studies.","",""
1,"Maxpool, Preact","Reproducibility report: Interpretable Complex-Valued Neural Networks For Privacy Protection",2021,"","","","",17,"2022-07-13 09:29:15","","","","",,,,,1,1.00,1,2,1,"Since the code was not made publicly available we implemented our own version of the reported DNNs. Baseline DNNs were created using the default model architecture. The figures and math of the original paper were used to recreate the structure of the complex-valued DNNs, in which the model is divided into an encoder, a processing module on the cloud, and a decoder. The goal of the complex-valued DNN is to make sure that the features are rotated and obfuscated to ensure that the privacy of the data is secured. We compare the performance of the baseline and complex-valued DNNs. Then, we test the robustness of the models against privacy attacks, where potential attackers were mimicked using inversion attacks.","",""
0,"Eduardo Mineo, A. Assunção, T. Morais, S.F.C. Camara, H. Ribeiro, J. Sims, C. Nomura","U-Net Neural Network for Locating Midpoint of Insertion Zone of Transcatheter Aortic Valves in CTA Images",2021,"","","","",18,"2022-07-13 09:29:15","","10.23919/cinc53138.2021.9662743","","",,,,,0,0.00,0,7,1,"Identifying the insertion zone of transcatheter heart valves can be time-consuming and suffers from variability and reproducibility problems. We present a deep leaning approach in CTA images to locate the midpoint of the insertion zone. A U-Net neural network is implemented to automatically segment the aortic valve on axial projection. The insertion zone midpoint is calculated based on the range of slices with the more concentrated area of activated pixels. We found a very low systematic error with a median computed error of 0.38mm and interquartile range of 0.15 – 0.75mm. The proposed model was shown to be a robust and powerful tool to automatically locate the insertion zone midpoint and we believe it will play a critical role on automated assessment of aortic stenosis.","",""
4,"Yongqiang Tian, Zhihua Zeng, Ming Wen, Yepang Liu, Tzu-yang Kuo, S. Cheung","EvalDNN: A Toolbox for Evaluating Deep Neural Network Models",2020,"","","","",19,"2022-07-13 09:29:15","","10.1145/3377812.3382133","","",,,,,4,2.00,1,6,2,"Recent studies have shown that the performance of deep learning models should be evaluated using various important metrics such as robustness and neuron coverage, besides the widely-used prediction accuracy metric. However, major deep learning frameworks currently only provide APIs to evaluate a model’s accuracy. In order to comprehensively assess a deep learning model, framework users and researchers often need to implement new metrics by themselves, which is a tedious job. What is worse, due to the large number of hyper-parameters and inadequate documentation, evaluation results of some deep learning models are hard to reproduce, especially when the models and metrics are both new.To ease the model evaluation in deep learning systems, we have developed EvalDNN, a user-friendly and extensible toolbox supporting multiple frameworks and metrics with a set of carefully designed APIs. Using EvalDNN, evaluation of a pre-trained model with respect to different metrics can be done with a few lines of code. We have evaluated EvalDNN on 79 models from TensorFlow, Keras, GluonCV, and PyTorch. As a result of our effort made to reproduce the evaluation results of existing work, we release a performance benchmark of popular models, which can be a useful reference to facilitate future research. The tool and benchmark are available at https://github.com/yqtianust/EvalDNN and https://yqtianust.github.io/EvalDNN-benchmark/, respectively. A demo video of EvalDNN is available at: https://youtu.be/v69bNJN2bJc.","",""
0,"Leevi Kerkela, K. Seunarine, R. Henriques, J. Clayden, C. Clark","Improved reproducibility of diffusion kurtosis imaging using regularized non-linear optimization informed by artificial neural networks",2022,"","","","",20,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,5,1,"Diﬀusion kurtosis imaging is an extension of diﬀusion tensor imaging that provides scientiﬁcally and clinically valuable information about brain tissue microstructure but suﬀers from poor robustness to noise, especially in voxels containing tightly packed aligned axons. We present a new algorithm for estimating diﬀusion and kurtosis tensors using regularized non-linear optimization and make it publicly available in an easy-to-use open-source Python software package. Our approach uses fully-connected feed-forward neural networks to predict kurtosis values in voxels where the standard non-linear least squares ﬁt fails. The predicted values are then used in the objective function to avoid implausible kurtosis values. We show that our algorithm is more robust than standard non-linear least squares and a previously proposed regularized non-linear optimization method. The algorithm was then applied on a multi-site scan-rescan dataset acquired using a clinical scan protocol to assess the reproducibility of diﬀusion kurtosis parameter estimation in human white matter using the proposed algorithm. Our results show that the reproducibility of diﬀusion kurtosis parameters is similar to diﬀusion tensor parameters.","",""
2,"Keshuang Tang, S. Chen, Yumin Cao, Xiaosong Li, D. Zang, Jian Sun, Yangbeibei Ji","Short-Term Travel Speed Prediction for Urban Expressways: Hybrid Convolutional Neural Network Models",2022,"","","","",21,"2022-07-13 09:29:15","","10.1109/tits.2020.3027628","","",,,,,2,2.00,0,7,1,"Deep learning models for short-term travel speed prediction on urban expressways, such as the convolutional neural network (CNN), still present several limitations in multiscale spatiotemporal feature extraction. Hence, in this paper, three hybrid CNN models are proposed to improve the basic CNN model with regard to three target aspects for short-term (i.e., 5 min) travel speed prediction on urban expressways. More specifically, long short-term memory (LSTM), AutoEncoder (AE), and Inception module are incorporated into the basic CNN model to capture multiscale spatiotemporal features of travel speed data effectively and improve the accuracy and robustness of the basic CNN model. Based on loop detector data collected on the Yan’an expressway in Shanghai, the proposed hybrid CNN models are trained and tuned. To validate the improvements on the target aspects, a comprehensive comparison is conducted using a classical statistical model (i.e., autoregressive integrated moving average), a typical shallow neural network model (i.e., artificial neural network), and two basic deep learning models (i.e., recurrent neural network and CNN). Results show that the prediction accuracies of all the proposed hybrid CNN models exceed 96% and the mean absolute errors are less than 2.5 km/h, which are superior to other models. In terms of target improving aspects, two new metrics were introduced, and the proposed models, especially the AE–CNN model, showed better robustness under various input data structures and traffic states. The LSTM–CNN model outperformed the other models in learning time-series features, and the Inception–CNN model is superior in reproducing the dynamics of traffic congestion patterns on urban expressways.","",""
0,"Tianhan Zhang, Yuxiao Yi, Yifan Xu, Z. X. Chen, Yaoyu Zhang, E. Weinan, Zhi-Qin John Xu","A multi-scale sampling method for accurate and robust deep neural network to predict combustion chemical kinetics",2022,"","","","",22,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,7,1,"Machine learning has long been considered as a black box for predicting combustion chemical kinetics due to the extremely large number of parameters and the lack of evaluation standards and reproducibility. The current work aims to understand two basic questions regarding the deep neural network (DNN) method: what data the DNN needs and how general the DNN method can be. Sampling and preprocessing determine the DNN training dataset, further affect DNN prediction ability. The current work proposes using Box-Cox transformation (BCT) to preprocess the combustion data. In addition, this work compares different sampling methods with or without preprocessing, including the Monte Carlo method, ∗Corresponding authors. January 12, 2022 ar X iv :2 20 1. 03 54 9v 1 [ ph ys ic s. ch em -p h] 9 J an 2 02 2 manifold sampling, generative neural network method (cycle-GAN), and newlyproposed multi-scale sampling. Our results reveal that the DNN trained by the manifold data can capture the chemical kinetics in limited configurations but cannot remain robust toward perturbation, which is inevitable for the DNN coupled with the flow field. The Monte Carlo and cycle-GAN samplings can cover a wider phase space but fail to capture small-scale intermediate species, producing poor prediction results. A three-hidden-layer DNN, based on the multi-scale method without specific flame simulation data, allows predicting chemical kinetics in various scenarios and being stable during the temporal evolutions. This single DNN is readily implemented with several CFD codes and validated in various combustors, including (1). zero-dimensional autoignition, (2). one-dimensional freely propagating flame, (3). two-dimensional jet flame with triple-flame structure, and (4). three-dimensional turbulent lifted flames. The ignition delay time, laminar flame speed, lifted flame height, and contours of physical quantities demonstrate the satisfying accuracy and generalization ability of the pre-trained DNN. The Fortran and Python versions of DNN and example code are attached in the supplementary for reproducibility.","",""
0,"Libin Huang, Lin Jiang, Liye Zhao, Xukai Ding","Temperature Compensation Method Based on an Improved Firefly Algorithm Optimized Backpropagation Neural Network for Micromachined Silicon Resonant Accelerometers",2022,"","","","",23,"2022-07-13 09:29:15","","10.3390/mi13071054","","",,,,,0,0.00,0,4,1,"The output of the micromachined silicon resonant accelerometer (MSRA) is prone to drift in a temperature-changing environment. Therefore, it is crucial to adopt an appropriate suppression method for temperature error to improve the performance of the accelerometer. In this study, an improved firefly algorithm-backpropagation (IFA-BP) neural network is proposed in order to realize temperature compensation. IFA can improve a BP neural network’s convergence accuracy and robustness in the training process by optimizing the initial weights and thresholds of the BP neural network. Additionally, zero-bias experiments at room temperature and full-temperature experiments were conducted on the MSRA, and the reproducible experimental data were used to train and evaluate the temperature compensation model. Compared with the firefly algorithm-backpropagation (FA-BP) neural network, it was proven that the IFA-BP neural network model has a better temperature compensation performance. The experimental results of the zero-bias experiment at room temperature indicated that the stability of the zero-bias was improved by more than an order of magnitude after compensation by the IFA-BP neural network temperature compensation model. The results of the full-temperature experiment indicated that in the temperature range of −40 °C~60 °C, the variation of the scale factor at full temperature improved by more than 70 times, and the variation of the bias at full temperature improved by around three orders of magnitude.","",""
0,"P. Serafim, Y. L. B. Nogueira, J. B. C. Neto, C. Vidal","Assessing the Robustness of Deep Q-Network Agents to Changes on Game Object Textures",2021,"","","","",24,"2022-07-13 09:29:15","","10.1109/SBGames54170.2021.00013","","",,,,,0,0.00,0,4,1,"The research in autonomous agents aspires to achieve Artificial General Intelligence, where agents, like humans, are able to understand concepts and learn how to solve tasks. We would like to observe this ability on game agents as well. Recent research on autonomous agents for game playing uses a combination of Deep Neural Networks and Reinforcement Learning algorithms. Commonly, Neural Networks present vision-based models, usually Convolutional Neural Networks (CNN). However, those models can undergo performance degradation when dealing with different pixel patterns, an issue that also happens with vision-based autonomous agents in games. Prior works have shown that CNN-based autonomous agents cannot reproduce the behavior learned in one scene when they are placed into a brand new version with different textures. In this work, we evaluate whether the agents educe high-level elements, such as enemy, foreground, and background. Instead of testing the agent in a completely different scene, we designed two experiments based on slight changes. In the first experiment, we change only a subset of the game objects. In the second experiment, the agents play in an interpolated version of two scenes. Even when changing only a single game object texture, the agents are not guaranteed to present good behavior. We show that, depending on the training scenario, the agents are not fully robust to generalize a high-level concept of game objects.","",""
17,"Saima Sharmin, P. Panda, Syed Shakib Sarwar, Chankyu Lee, Wachirawit Ponghiran, K. Roy","A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks",2019,"","","","",25,"2022-07-13 09:29:15","","10.1109/IJCNN.2019.8851732","","",,,,,17,5.67,3,6,3,"In this era of machine learning models, their functionality is being threatened by adversarial attacks. In the face of this struggle for making artificial neural networks robust, finding a model, resilient to these attacks, is very important. In this work, we present, for the first time, a comprehensive analysis of the behavior of more bio-plausible networks, namely Spiking Neural Network (SNN) under state-of-the-art adversarial tests. We perform a comparative study of the accuracy degradation between conventional VGG-9 Artificial Neural Network (ANN) and equivalent spiking network with CIFAR-10 dataset in both whitebox and blackbox setting for different types of single-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We demonstrate that SNNs tend to show more resiliency compared to ANN under blackbox attack scenario. Additionally, we find that SNN robustness is largely dependent on the corresponding training mechanism. We observe that SNNs trained by spike-based backpropagation are more adversarially robust than the ones obtained by ANN-to-SNN conversion rules in several whitebox and blackbox scenarios. Finally, we also propose a simple, yet, effective framework for crafting adversarial attacks from SNNs. Our results suggest that attacks crafted from SNNs following our proposed method are much stronger than those crafted from ANNs.","",""
3,"Y. Horio","Chaotic Neural Network Reservoir",2019,"","","","",26,"2022-07-13 09:29:15","","10.1109/IJCNN.2019.8852265","","",,,,,3,1.00,3,1,3,"Simple structure and robust property of a reservoir neural network are preferable for hardware implementation of a high performance learning system, especially for time-series data processing. One of salient feature of the reservoir network is reproducibility or consistency of its responses to the same or similar inputs. This is usually guaranteed through the echo state property of the network by properly choosing synaptic weights among reservoir neurons. Another important feature is a variety of dynamics in the reservoir, which makes the reservoir to process complex time-varying input signals. One way to increase the variety of dynamics is introducing chaotic behavior by destabilize the reservoir network by changing weight values. However, this will violate the echo state property, therefore, chaotic dynamics are usually avoided in the reservoir computing.In this paper, we propose a method to introduce high-dimensional chaotic dynamics into the reservoir network, but keeping its consistency. To achieve this, we use a chaotic neural network model in the reservoir network, while keeping the weight matrix in the reservoir network to satisfy the echo state property criteria. In order to show the consistency of the chaotic neural network reservoir, preliminary results for chaotic time-series predictions through the chaotic neural network reservoir are illustrated. In addition, we discuss the application of the chaotic neural network reservoir to a self-aware hardware system.","",""
144,"Tong Yang, Ning Sun, He Chen, Yongchun Fang","Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones",2020,"","","","",27,"2022-07-13 09:29:15","","10.1109/TNNLS.2019.2910580","","",,,,,144,72.00,36,4,2,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.","",""
137,"Shuangming Yang, Bin Deng, Jiang Wang, Huiyan Li, Meili Lu, Yanqiu Che, Xile Wei, K. Loparo","Scalable Digital Neuromorphic Architecture for Large-Scale Biophysically Meaningful Neural Network With Multi-Compartment Neurons",2020,"","","","",28,"2022-07-13 09:29:15","","10.1109/TNNLS.2019.2899936","","",,,,,137,68.50,17,8,2,"Multicompartment emulation is an essential step to enhance the biological realism of neuromorphic systems and to further understand the computational power of neurons. In this paper, we present a hardware efficient, scalable, and real-time computing strategy for the implementation of large-scale biologically meaningful neural networks with one million multi-compartment neurons (CMNs). The hardware platform uses four Altera Stratix III field-programmable gate arrays, and both the cellular and the network levels are considered, which provides an efficient implementation of a large-scale spiking neural network with biophysically plausible dynamics. At the cellular level, a cost-efficient multi-CMN model is presented, which can reproduce the detailed neuronal dynamics with representative neuronal morphology. A set of efficient neuromorphic techniques for single-CMN implementation are presented with all the hardware cost of memory and multiplier resources removed and with hardware performance of computational speed enhanced by 56.59% in comparison with the classical digital implementation method. At the network level, a scalable network-on-chip (NoC) architecture is proposed with a novel routing algorithm to enhance the NoC performance including throughput and computational latency, leading to higher computational efficiency and capability in comparison with state-of-the-art projects. The experimental results demonstrate that the proposed work can provide an efficient model and architecture for large-scale biologically meaningful networks, while the hardware synthesis results demonstrate low area utilization and high computational speed that supports the scalability of the approach.","",""
7,"Stephen T. Lam, Qing-Jie Li, R. Ballinger, C. Forsberg, Ju Li","Modeling LiF and FLiBe Molten Salts with Robust Neural Network Interatomic Potential.",2021,"","","","",29,"2022-07-13 09:29:15","","10.1021/acsami.1c00604","","",,,,,7,7.00,1,5,1,"Lithium-based molten salts have attracted significant attention due to their applications in energy storage, advanced fission reactors, and fusion devices. Lithium fluorides and particularly 66.6%LiF-33.3%BeF2 (Flibe) are of considerable interest in nuclear systems, as they show an excellent combination of favorable heat transfer, neutron moderation, and transmutation characteristics. For nuclear salts, the range of possible local structures, compositions, and thermodynamic conditions presents significant challenges in atomistic modeling. In this work, we demonstrate that atom-centered neural network interatomic potentials (NNIPs) provide a fast method for performing molecular dynamics of molten salts that is as accurate as ab initio molecular dynamics. For LiF, these potentials are able to accurately reproduce ab initio interactions of dimers, crystalline solids under deformation, crystalline LiF near the melting point, and liquid LiF at high temperatures. For Flibe, NNIPs accurately predict the structures and dynamics at normal operating conditions, high-temperature-pressure conditions, and in the crystalline solid phase. Furthermore, we show that NNIP-based molecular dynamics of molten salts are scalable to reach long time scales (e.g., nanosecond) and large system sizes (e.g., 105 atoms) while maintaining ab initio density functional theory accuracy and providing more than 3 orders of magnitude of computational speedup for calculating structure and transport properties.","",""
6,"Wenbo Zhang, G. Rossini, D. Kamensky, T. Bui-Thanh, M. Sacks","Isogeometric finite element‐based simulation of the aortic heart valve: Integration of neural network structural material model and structural tensor fiber architecture representations",2021,"","","","",30,"2022-07-13 09:29:15","","10.1002/cnm.3438","","",,,,,6,6.00,1,5,1,"The functional complexity of native and replacement aortic heart valves (AVs) is well known, incorporating such physical phenomenons as time‐varying non‐linear anisotropic soft tissue mechanical behavior, geometric non‐linearity, complex multi‐surface time varying contact, and fluid–structure interactions to name a few. It is thus clear that computational simulations are critical in understanding AV function and for the rational basis for design of their replacements. However, such approaches continued to be limited by ad‐hoc approaches for incorporating tissue fibrous structure, high‐fidelity material models, and valve geometry. To this end, we developed an integrated tri‐leaflet valve pipeline built upon an isogeometric analysis framework. A high‐order structural tensor (HOST)‐based method was developed for efficient storage and mapping the two‐dimensional fiber structural data onto the valvular 3D geometry. We then developed a neural network (NN) material model that learned the responses of a detailed meso‐structural model for exogenously cross‐linked planar soft tissues. The NN material model not only reproduced the full anisotropic mechanical responses but also demonstrated a considerable efficiency improvement, as it was trained over a range of realizable fibrous structures. Results of parametric simulations were then performed, as well as population‐based bicuspid AV fiber structure, that demonstrated the efficiency and robustness of the present approach. In summary, the present approach that integrates HOST and NN material model provides an efficient computational analysis framework with increased physical and functional realism for the simulation of native and replacement tri‐leaflet heart valves.","",""
36,"T. Roshni, M. Jha, J. Drisya","Neural network modeling for groundwater-level forecasting in coastal aquifers",2020,"","","","",31,"2022-07-13 09:29:15","","10.1007/s00521-020-04722-z","","",,,,,36,18.00,12,3,2,"","",""
2,"Abdelrahman Gouda, S. Khaled, S. Gomaa, A. Attia","Prediction of the Rheological Properties of Invert Emulsion Mud Using an Artificial Neural Network",2021,"","","","",32,"2022-07-13 09:29:15","","10.1021/acsomega.1c04937","","",,,,,2,2.00,1,4,1,"Successful drilling operations require optimum well planning to overcome the challenges associated with geological and environmental constraints. One of the main well design programs is the mud program, which plays a crucial role in each drilling operation. Researchers focus on modeling the rheological properties of the drilling fluid seeking for accurate and real-time predictions that confirm its crucial potential as a research point. However, only substantial studies have real impact on the literature. Several AI-based models have been proposed for estimating mud rheological properties. However, most of them suffer from non-being field applicable attractive due to using non-readily field parameters as input variables. Some other studies have not provided a comprehensive description of the model to replicate or reproduce results using other datasets. In this study, two novel robust artificial neural network (ANN) models for estimating invert emulsion mud plastic viscosity and yield point have been developed using actual field data based on 407 datasets. These datasets include mud plastic viscosity (PV), yield point (YP), mud temperature (T), marsh funnel viscosity (MF), and solid content. The mathematical base of each model has been provided to provide a clear means for models’ replicability. Results of the evaluation criteria depicted the outstanding performance and consistency of the proposed models over extant ANN models and empirical correlations. Statistical evaluation revealed that the plastic viscosity ANN model has a coefficient of determination (R2) of 98.82%, a root-mean-square error (RMSE) of 1.37, an average relative error (ARE) of 0.12, and an absolute average relative error of 2.69, while for yield point, this model has a coefficient of determination (R2) of 94%, a root-mean-square error (RMSE) of 0.76, an average relative error (ARE) of −0.67, and an absolute average relative error of 3.18.","",""
1,"C. J. Rojas, Marco L. Bitterncourt, J. L. Boldrini","Parameter identification for a damage model using a physics informed neural network",2021,"","","","",33,"2022-07-13 09:29:15","","","","",,,,,1,1.00,0,3,1,"This work applies concepts of artificial neural networks to identify the parameters of a mathematical model based on phase fields for damage and fracture. Damage mechanics is the part of the continuum mechanics that models the effects of micro-defect formation using state variables at the macroscopic level. The equations that define the model are derived from fundamental laws of physics and provide important relationships between state variables. Simulations using the model considered in this work produce good qualitative and quantitative results, but many parameters must be adjusted to reproduce a certain material behavior. The identification of model parameters is considered by solving an inverse problem that uses pseudo-experimental data to find the values that produce the best fit to the data. We apply a physics informed neural network and combine some classical estimation methods to identify the material parameters that appear in the damage equation of the model. Our strategy consists of a neural network that acts as an approximating function of the damage evolution with its output regularized using the residue of the differential equation. Three stages of optimization seek the best possible values for the neural network and the material parameters. The training alternates between the fitting of only the pseudo-experimental data or the total loss that includes the regularizing terms. We test the robustness of the method to noisy data and its generalization capabilities using a simple physical case for the damage model. This procedure deals better with noisy data in comparison with a PDE-constrained optimization method, and it also provides good approximations of the material parameters and the evolution of damage.","",""
2,"Sebastian Ziegelmayer, S. Reischl, Felix N Harder, M. Makowski, R. Braren, J. Gawlitza","Feature Robustness and Diagnostic Capabilities of Convolutional Neural Networks Against Radiomics Features in Computed Tomography Imaging.",2021,"","","","",34,"2022-07-13 09:29:15","","10.1097/RLI.0000000000000827","","",,,,,2,2.00,0,6,1,"Radiomics and deep learning algorithms such as convolutional neural networks (CNNs) are increasingly used for radiological image classification and outcome prediction. One of the main challenges is to create robustness against technical alterations. Both methods initially extract specific imaging features, which are then used as input for machine learning algorithms or in an end-to-end fashion for outcome prediction. For radiomics features, it has previously been shown that differences in image acquisition parameters can cause variability in feature values, making them irreproducible. However, it remains unclear how these technical variations influence feature values extracted by a CNN. Therefore, the aim of this study was to compare the robustness of CNN features versus radiomics features to technical variations in image acquisition parameters. An additional retrospective analysis was performed to show the in vivo capabilities of these features compared with classical radiomics features in a tumor differentiation task.   MATERIALS AND METHODS Imaging phantoms were scanned twice on 3 computed tomography scanners from 2 different manufactures with varying tube voltages and currents. Phantoms were segmented, and features were extracted using PyRadiomics and a pretrained CNN. After standardization the concordance correlation coefficient (CCC), mean feature variance, feature range, and the coefficient of variant were calculated to assess feature robustness. In addition, the cosine similarity was calculated for the vectorized activation maps for an exemplary phantom. For the in vivo comparison, the radiomics and CNN features of 30 patients with hepatocellular carcinoma (HCC) and 30 patients with hepatic colon carcinoma metastasis were compared.   RESULTS In total, 851 radiomics features and 256 CNN features were extracted for each phantom. For all phantoms, the global CCC of the CNN features was above 98%, whereas the highest CCC for the radiomics features was 36%. The mean feature variance and feature range was significantly lower for the CNN features. Using a coefficient of variant ≤0.2 as a threshold to define robust features and averaging across all phantoms 346 of 851 (41%) radiomics features and 196 of 256 (77%) CNN features were found to be robust. The cosine similarity was greater than 0.98 for all scanner and parameter variations. In the retrospective analysis, 122 of the 256 CNN (49%) features showed significant differences between HCC and hepatic colon metastasis.   DISCUSSION Convolutional neural network features were more stable compared with radiomics features against technical variations. Moreover, the possibility of tumor entity differentiation based on CNN features was shown. Combined with visualization methods, CNN features are expected to increase reproducibility of quantitative image representations. Further studies are warranted to investigate the impact of feature stability on radiological image-based prediction of clinical outcomes.","",""
431,"Liam Li, Ameet S. Talwalkar","Random Search and Reproducibility for Neural Architecture Search",2019,"","","","",35,"2022-07-13 09:29:15","","","","",,,,,431,143.67,216,2,3,"Neural architecture search (NAS) is a promising research direction that has the potential to replace expert-designed networks with learned, task-specific architectures. In this work, in order to help ground the empirical results in this field, we propose new NAS baselines that build off the following observations: (i) NAS is a specialized hyperparameter optimization problem; and (ii) random search is a competitive baseline for hyperparameter optimization. Leveraging these observations, we evaluate both random search with early-stopping and a novel random search with weight-sharing algorithm on two standard NAS benchmarks---PTB and CIFAR-10. Our results show that random search with early-stopping is a competitive NAS baseline, e.g., it performs at least as well as ENAS, a leading NAS method, on both benchmarks. Additionally, random search with weight-sharing outperforms random search with early-stopping, achieving a state-of-the-art NAS result on PTB and a highly competitive result on CIFAR-10. Finally, we explore the existing reproducibility issues of published NAS results. We note the lack of source material needed to exactly reproduce these results, and further discuss the robustness of published results given the various sources of variability in NAS experimental setups. Relatedly, we provide all information (code, random seeds, documentation) needed to exactly reproduce our results, and report our random search with weight-sharing results for each benchmark on multiple runs.","",""
1,"Mohammad Mehdi Yadollahi, Farzaneh Shoeleh, S. Dadkhah, A. Ghorbani","Robust Black-box Watermarking for Deep Neural Network using Inverse Document Frequency",2021,"","","","",36,"2022-07-13 09:29:15","","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00100","","",,,,,1,1.00,0,4,1,"Recently, Deep Neural Networks (DNNs), presented exceptional achievement in implementing human-level capabilities for various predicaments, such as Natural Language Processing (NLP), voice recognition, and image processing, etc. Training these models is expensive in terms of computational power and the existence of enough labelled data. Thus, ML-based models such as DNNs establish genuine business value and intellectual property (IP) for their owners. Therefore the trained models need to be protected from any adversary attacks such as illegal redistribution, reproducing, and derivation. Watermarking can be considered as an effective technique for securing a DNN model. However, so far, most of the watermarking algorithms focus on watermarking the DNN by adding noise to an image. To this end, we propose a framework for watermarking a DNN model designed for textual domain. The watermark generation scheme provides a secure watermarking method by combining Term Frequency (TF) and Inverse Document Frequency (IDF) of a particular word. The proposed embedding procedure takes place in the model's training stage, which makes the watermark verification stage straightforward by sending the watermarked document to the trained model. The experimental results show that watermarked models have the same accuracy as the original one, and the proposed framework accurately verifies the ownership of all surrogate models without impairing the performance. The proposed algorithm is robust against well-known attacks such as parameter pruning and brute force attack.","",""
0,"Nikolaos N. Vlassis, Puhan Zhao, R. Ma, T. Sewell, Waiching Sun","MD-inferred neural network monoclinic finite-strain hyperelasticity models for β-HMX: Sobolev training and validation against physical constraints",2021,"","","","",37,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,5,1,"We present a machine learning framework to train and validate neural networks to predict the anisotropic elastic response of the monoclinic organic molecular crystal β -HMX in the geometrical nonlinear regime. A ﬁltered molecular dynamic (MD) simulations database is used to train the neural networks with a Sobolev norm that uses the stress measure and a reference conﬁguration to deduce the elastic stored energy functional. To improve the accuracy of the elasticity tangent predictions originating from the learned stored energy, a transfer learning technique is used to introduce additional tangential constraints from the data while necessary conditions (e.g. strong ellipticity, crystallographic symmetry) for the correctness of the model are either introduced as additional physical constraints or incorporated in the validation tests. Assessment of the neural networks is based on (1) the accuracy with which they reproduce the bottom-line constitutive responses predicted by MD, (2) detailed examination of their stability and uniqueness, and (3) admissibility of the predicted responses with respect to continuum mechanics theory in the ﬁnite-deformation regime. We compare the neural networks’ training efﬁciency under different Sobolev constraints and assess the models’ accuracy and robustness against MD benchmarks for β -HMX.","",""
15,"S. Mahdavifar, A. Ghorbani","DeNNeS: deep embedded neural network expert system for detecting cyber attacks",2020,"","","","",38,"2022-07-13 09:29:15","","10.1007/s00521-020-04830-w","","",,,,,15,7.50,8,2,2,"","",""
11,"B. Mathison, J. Kohan, John F Walker, Richard Boyd Smith, O. Ardon, M. Couturier","Detection of Intestinal Protozoa in Trichrome-Stained Stool Specimens by Use of a Deep Convolutional Neural Network",2020,"","","","",39,"2022-07-13 09:29:15","","10.1128/JCM.02053-19","","",,,,,11,5.50,2,6,2,"Intestinal protozoa are responsible for relatively few infections in the developed world, but the testing volume is disproportionately high. Manual light microscopy of stool remains the gold standard but can be insensitive, time-consuming, and difficult to maintain competency. Artificial intelligence and digital slide scanning show promise for revolutionizing the clinical parasitology laboratory by augmenting the detection of parasites and slide interpretation using a convolutional neural network (CNN) model. ABSTRACT Intestinal protozoa are responsible for relatively few infections in the developed world, but the testing volume is disproportionately high. Manual light microscopy of stool remains the gold standard but can be insensitive, time-consuming, and difficult to maintain competency. Artificial intelligence and digital slide scanning show promise for revolutionizing the clinical parasitology laboratory by augmenting the detection of parasites and slide interpretation using a convolutional neural network (CNN) model. The goal of this study was to develop a sensitive model that could screen out negative trichrome slides, while flagging potential parasites for manual confirmation. Conventional protozoa were trained as “classes” in a deep CNN. Between 1,394 and 23,566 exemplars per class were used for training, based on specimen availability, from a minimum of 10 unique slides per class. Scanning was performed using a 40× dry lens objective automated slide scanner. Data labeling was performed using a proprietary Web interface. Clinical validation of the model was performed using 10 unique positive slides per class and 125 negative slides. Accuracy was calculated as slide-level agreement (e.g., parasite present or absent) with microscopy. Positive agreement was 98.88% (95% confidence interval [CI], 93.76% to 99.98%), and negative agreement was 98.11% (95% CI, 93.35% to 99.77%). The model showed excellent reproducibility using slides containing multiple classes, a single class, or no parasites. The limit of detection of the model and scanner using serially diluted stool was 5-fold more sensitive than manual examinations by multiple parasitologists using 4 unique slide sets. Digital slide scanning and a CNN model are robust tools for augmenting the conventional detection of intestinal protozoa.","",""
7,"M. Madkhali, C. Rankine, T. Penfold","The Role of Structural Representation in the Performance of a Deep Neural Network for X-ray Spectroscopy",2020,"","","","",40,"2022-07-13 09:29:15","","10.3390/molecules25112715","","",,,,,7,3.50,2,3,2,"An important consideration when developing a deep neural network (DNN) for the prediction of molecular properties is the representation of the chemical space. Herein we explore the effect of the representation on the performance of our DNN engineered to predict Fe K-edge X-ray absorption near-edge structure (XANES) spectra, and address the question: How important is the choice of representation for the local environment around an arbitrary Fe absorption site? Using two popular representations of chemical space—the Coulomb matrix (CM) and pair-distribution/radial distribution curve (RDC)—we investigate the effect that the choice of representation has on the performance of our DNN. While CM and RDC featurisation are demonstrably robust descriptors, it is possible to obtain a smaller mean squared error (MSE) between the target and estimated XANES spectra when using RDC featurisation, and converge to this state a) faster and b) using fewer data samples. This is advantageous for future extension of our DNN to other X-ray absorption edges, and for reoptimisation of our DNN to reproduce results from higher levels of theory. In the latter case, dataset sizes will be limited more strongly by the resource-intensive nature of the underlying theoretical calculations.","",""
16,"Xiangmin Lun, Shuyue Jia, Yimin Hou, Yan Shi, Y. Li, Hanrui Yang, Shu Zhang, J. Lv","GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals",2020,"","","","",41,"2022-07-13 09:29:15","","","","",,,,,16,8.00,2,8,2,"Towards developing effective and efficient brain-computer interface (BCI) systems, precise decoding of brain activity measured by electroencephalogram (EEG), is highly demanded. Traditional works classify EEG signals without considering the topological relationship among electrodes. However, neuroscience research has increasingly emphasized network patterns of brain dynamics. Thus, the Euclidean structure of electrodes might not adequately reflect the interaction between signals. To fill the gap, a novel deep learning framework based on the graph convolutional neural networks (GCNs) was presented to enhance the decoding performance of raw EEG signals during different types of motor imagery (MI) tasks while cooperating with the functional topological relationship of electrodes. Based on the absolute Pearson's matrix of overall signals, the graph Laplacian of EEG electrodes was built up. The GCNs-Net constructed by graph convolutional layers learns the generalized features. The followed pooling layers reduce dimensionality, and the fully-connected softmax layer derives the final prediction. The introduced approach has been shown to converge for both personalized and group-wise predictions. It has achieved the highest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and 80.89% (High Gamma Dataset), at the subject and group level, respectively, compared with existing studies, which suggests adaptability and robustness to individual variability. Moreover, the performance was stably reproducible among repetitive experiments for cross-validation. To conclude, the GCNs-Net filters EEG signals based on the functional topological relationship, which manages to decode relevant features for brain motor imagery.","",""
1,"M. Ohsaki, Hayato Sasaki, Naoya Kishimoto, S. Katagiri, P. Then","Discovery of Sets and Representatives of Variables in Co-nonlinear Relationships by Neural Network Regression and Group Lasso",2018,"","","","",42,"2022-07-13 09:29:15","","10.1109/BIBM.2018.8621207","","",,,,,1,0.25,0,5,4,"In regression and classification, the dependences among input variables lead to the reduction in prediction performance and reliability and to the misidentification of contributable input variables. Not only for these issues but also knowledge discovery, it is necessary to clarify variable dependences. This study aims to discover the sets and representatives of co-nonlinear variables, ensuring a high nonlinearity modeling capability and a high reproducibility without variable combinational explosion. Our proposed method achieves this by combining neural network regression, group lasso, and complementary aggregation of regression results. We conducted experiments to examine the fundamental effectiveness of the proposed method, using synthetic data of which co-nonlinearities were known. As a result, the proposed method succeeded to discover the sets and representatives of co-nonlinear variables robustly to noise added to the variables.","",""
2,"G. Portwood, B. Nadiga, J. Saenz, D. Livescu","Analysis and interpretation of out-performing neural network residual flux models",2020,"","","","",43,"2022-07-13 09:29:15","","","","",,,,,2,1.00,1,4,2,"We present novel approaches for the development, evaluation and interpretation of artificial neural networks (ANNs) for subfilter closures and demonstrate their usage in the context of large-eddy simulations (LES) of a passive scalar in homogeneous isotropic turbulence. Exact subfilter fluxes obtained by filtering direct numerical simulations (DNS) are used both to train deep ANN models as a function of filtered variables, and to optimise the coefficients of common spatio-temporally local LES closures. \textit{A-priori} analysis with respect to important dynamical features such as backscatter and subfilter scalar variance transfer rate, reveals that learnt ANN models out-performs optimised, turbulent Prandtl number closure models and gradient models. Next, \textit{a-posteriori} solutions are obtained with each model over several integral timescales. These solutions are obtained by explicitly filtering DNS-resolved velocity in order to isolate sources of error to subfilter flux closure. These experiments reveal that ANN models temporally track resolved scalar variance with greater accuracy compared to other subfilter flux models for a given filter length scale. Similarly, moments of scalar two-point structure functions reveal that trained neural network models reproduce statistics of ground-truth DNS with greater fidelity compared to common algebraic closure models. Finally, we interpret the artificial neural networks statistically with differential sensitivity analysis to show that the ANN models learns dynamics reminiscent of so-called ""mixed models"", where mixed models are understood as comprising both a structural and functional component. Besides enabling enhanced-accuracy LES of passive scalars henceforth, we anticipate this work to contribute to utilising well-performing neural network models as a tool in interpretability, robustness and model discovery.","",""
24,"Tianyu Kang, W. Ding, Luoyan Zhang, D. Ziemek, Kourosh Zarringhalam","A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data",2017,"","","","",44,"2022-07-13 09:29:15","","10.1186/s12859-017-1984-2","","",,,,,24,4.80,5,5,5,"","",""
2,"Jinhe Yu, L. Bi, Wei Han, Xiaoye Zhang","Application of a Neural Network to Store and Compute the Optical Properties of Non-Spherical Particles",2022,"","","","",45,"2022-07-13 09:29:15","","10.1007/s00376-021-1375-5","","",,,,,2,2.00,1,4,1,"","",""
170,"Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, D. Boning, Cho-Jui Hsieh","Towards Stable and Efficient Training of Verifiably Robust Neural Networks",2019,"","","","",46,"2022-07-13 09:29:15","","","","",,,,,170,56.67,28,6,3,"Training neural networks with verifiable robustness guarantees is challenging. Several existing approaches utilize linear relaxation based neural network output bounds under perturbation, but they can slow down training by a factor of hundreds depending on the underlying network architectures. Meanwhile, interval bound propagation (IBP) based training is efficient and significantly outperforms linear relaxation based methods on many tasks, yet it may suffer from stability issues since the bounds are much looser especially at the beginning of training. In this paper, we propose a new certified adversarial training method, CROWN-IBP, by combining the fast IBP bounds in a forward bounding pass and a tight linear relaxation based bound, CROWN, in a backward bounding pass. CROWN-IBP is computationally efficient and consistently outperforms IBP baselines on training verifiably robust neural networks. We conduct large scale experiments on MNIST and CIFAR datasets, and outperform all previous linear relaxation and bound propagation based certified defenses in $\ell_\infty$ robustness. Notably, we achieve 7.02% verified test error on MNIST at $\epsilon=0.3$, and 66.94% on CIFAR-10 with $\epsilon=8/255$. Code is available at this https URL (TensorFlow) and this https URL (PyTorch).","",""
4,"Sen Jia, Jianhui Liao, Meng Xu, Yan Li, Jiasong Zhu, Weiwei Sun, X. Jia, Qingquan Li","3-D Gabor Convolutional Neural Network for Hyperspectral Image Classification",2021,"","","","",47,"2022-07-13 09:29:15","","10.1109/tgrs.2021.3087186","","",,,,,4,4.00,1,8,1,"Due to the detailed spectral information through hundreds of narrow spectral bands provided by hyperspectral image (HSI) data, it can be employed to accurately classify diverse materials of interest, which is one of the core applications of hyperspectral remote sensing technology. In recent years, with the rapid development of deep learning, convolutional neural networks (CNNs) have been successfully applied in many fields, including HSI classification. However, the random gradient descent-based parameter updating scheme is too general and leading to the inefficiency of CNN models. Moreover, the high dimensionality and limited training samples of HSI data also exacerbate the overfitting problem. To tackle these issues, in this article, a novel deep network with multilayer and multibranch architecture, named 3-D Gabor CNN (3DG-CNN), is proposed for HSI classification. More precisely, since the predefined 3-D Gabor filters in multiple scales and orientations could well characterize the internal spatial–spectral structure of HSI data from various perspectives, the 3-D Gabor-modulated kernels (3-D GMKs) are employed to replace the random initialization kernels. Moreover, the specially designed multibranch architecture enables the network to better integrating the scalable property of 3-D Gabor filters; thus, the representative ability and robustness of the extracted features can be greatly improved. Alternatively, the number of network parameters is substantially reduced due to the incorporation of 3-D Gabor modulation, relieving the training complexity and also alleviating the training process from overfitting. Experimental results on four real HSI datasets (including two newly released ones in the literature) have demonstrated that the proposed 3DG-CNN model can achieve better performance than several widely used machine-learning-based and deep-learning-based approaches. For the sake of reproducibility, the codes of the proposed 3DG-CNN model are available at http://jiasen.tech/papers/.","",""
1,"Yin Yu, Xinyuan Jiang, Daning Huang, Yan Li","PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of Networked Microgrids Through Full-Field Measurement",2022,"","","","",48,"2022-07-13 09:29:15","","10.48550/arXiv.2204.08557","","",,,,,1,1.00,0,4,1,"—A Physics-Informed Dynamic Graph Neural Net- work (PIDGeuN) is presented to accurately, efﬁciently and robustly predict the nonlinear transient dynamics of microgrids in the presence of disturbances. The graph-based architecture of PIDGeuN provides a natural representation of the microgrid topology. Using only the state information that is practically measurable, PIDGeuN employs a time delay embedding for- mulation to fully reproduce the system dynamics, avoiding the dependency of conventional methods on internal dynamic states such as controllers. Based on a judiciously designed message passing mechanism, the PIDGeuN incorporates two physics- informed techniques to improve its prediction performance, including a physics-data-infusion approach to determining the inter-dependencies between buses, and a loss term to respect the known physical law of the power system, i.e., the Kirchhoff’s law, to ensure the feasibility of the model prediction. Extensive tests show that PIDGeuN can provide accurate and robust prediction of transient dynamics for nonlinear microgrids over a long-term time period. Therefore, the PIDGeuN offers a potent tool for the modeling of large scale networked microgrids (NMs), with potential applications to predictive or preventive control in real time applications for the stable and resilient operations of NMs.","",""
8,"K. Shimamura, S. Fukushima, A. Koura, F. Shimojo, Masaaki Misawa, R. Kalia, A. Nakano, P. Vashishta, Takashi Matsubara, Shigenori Tanaka","Guidelines for creating artificial neural network empirical interatomic potential from first-principles molecular dynamics data under specific conditions and its application to α-Ag2Se.",2019,"","","","",49,"2022-07-13 09:29:15","","10.1063/1.5116420","","",,,,,8,2.67,1,10,3,"First-principles molecular dynamics (FPMD) simulations are highly accurate, but due to their high calculation cost, the computational scale is often limited to hundreds of atoms and few picoseconds under specific temperature and pressure conditions. We present here the guidelines for creating artificial neural network empirical interatomic potential (ANN potential) trained with such a limited FPMD data, which can perform long time scale MD simulations at least under the same conditions. The FPMD data for training are prepared on the basis of the convergence of radial distribution function [g(r)]. While training the ANN using total energy and atomic forces of the FPMD data, the error of pressure is also monitored and minimized. To create further robust potential, we add a small amount of FPMD data to reproduce the interaction between two atoms that are close to each other. ANN potentials for α-Ag2Se were created as an application example, and it has been confirmed that not only g(r) and mean square displacements but also the specific heat requiring a long time scale simulation matched the FPMD and the experimental values. In addition, the MD simulation using the ANN potential achieved over 104 acceleration over the FPMD one. The guidelines proposed here mitigate the creation difficulty of the ANN potential, and a lot of FPMD data sleeping on the hard disk after the research may be put on the front stage again.","",""
37,"C. Pham, Yaonan Wang","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",50,"2022-07-13 09:29:15","","10.1007/s00521-015-1873-4","","",,,,,37,6.17,19,2,6,"","",""
1,"J. Collens","Rhythmogenesis and Bifurcation Analysis of 3-Node Neural Network Kernels",2017,"","","","",51,"2022-07-13 09:29:15","","","","",,,,,1,0.20,1,1,5,"Central pattern generators (CPGs) are small neural circuits of coupled cells stably producing a range of multiphasic coordinated rhythmic activities like locomotion, heartbeat, and respiration. Rhythm generation resulting from synergistic interaction of CPG circuitry and intrinsic cellular properties remains deficiently understood and characterized. Pairing of experimental and computational studies has proven key in unlocking practical insights into operational and dynamical principles of CPGs, underlining growing consensus that the same fundamental circuitry may be shared by invertebrates and vertebrates. We explore the robustness of synchronized oscillatory patterns in small local networks, revealing universal principles of rhythmogenesis and multi-functionality in systems capable of facilitating stability in rhythm formation. Understanding principles leading to functional neural network behavior benefits future study of abnormal neurological diseases that result from perturbations of mechanisms governing normal rhythmic states. Qualitative and quantitative stability analysis of a family of reciprocally coupled neural circuits, constituted of generalized Fitzhugh–Nagumo neurons, explores symmetric and asymmetric connectivity within three-cell motifs, often forming constituent kernels within larger networks. Intrinsic mechanisms of synaptic release, escape, and post-inhibitory rebound lead to differing polyrhythmicity, where a single parameter or perturbation may trigger rhythm switching in otherwise robust networks. Bifurcation analysis and phase reduction methods elucidate qualitative changes in rhythm stability, permitting rapid identification and exploration of pivotal parameters describing biologically plausible network connectivity. Additional rhythm outcomes are elucidated, including phase-varying lags and broader cyclical behaviors, helping to characterize system capability and robustness reproducing experimentally observed outcomes. This work further develops a suite of visualization approaches and computational tools, describing robustness of network rhythmogenesis and disclosing principles for neuroscience applicable to other systems beyond motor-control. A framework for modular organization is introduced, using inhibitory and electrical synapses to couple well-characterized 3-node motifs described in this research as building blocks within larger networks to describe underlying cooperative mechanisms. INDEX WORDS: Network dynamics, Fitzhugh-Nagumo model, Dynamical systems, Bifurcation analysis, 3-cell networks, Inhibitory coupling, Current stimulus, Phase return maps, Subcritical Andronov-Hopf, Supercritical Andronov-Hopf, Subcritical pitchfork, Supercritical pitchfork, Saddle-node bifurcation, Heteroclinic, Homoclinic, Asymmetric networks, Phase slip, Pattern stability, Jitter, Invariant circles, Modular networking, Visualization, Rhythmogenesis RHYTHMOGENESIS AND BIFURCATION ANALYSIS OF 3-NODE NEURAL NETWORK KERNELS","",""
0,"Archana Balmik, Arnab Paikaray, Mrityunjay Jha, Anup Nandy","Motion recognition using deep convolutional neural network for Kinect-based NAO teleoperation",2022,"","","","",52,"2022-07-13 09:29:15","","10.1017/s0263574722000169","","",,,,,0,0.00,0,4,1,"  The capabilities of teleoperated robots can be enhanced with the ability to recognise and reproduce human-like behaviour. The proposed framework presents motion recognition for a Kinect-based NAO teleoperation. It allows the NAO robot to recognise the human motions and act as a human motion imitator. A stable whole-body imitation is still a challenging issue because of the difficulty in dynamic balancing of centre of mass (CoM). In this paper, a novel adaptive balancing technique for NAO (ABTN) is proposed to control the whole body in single as well as double supporting phases. It targets dynamic balancing of the humanoid robot by solving forward kinematics and applying a weighted average of mass with the CoMs of individual links with respect to the previous joint frames, which provides us with the dynamic CoM of the whole body. Our novel approach uses this dynamic CoM and calculates joint angles using proposed pitch and roll control algorithm to keep the dynamic CoM inside the stable region. Additionally, the NAO robot is capable of recognising human motions using the proposed 7-layer one-dimensional convolutional neural network (1D-CNN). To solve the problem of variable length of time sequences, Zero padding is introduced with 1D-CNN. It attains a recognition accuracy of 95% as compared to the hidden Markov model and neural network. The experimental results demonstrate that the developed teleoperation framework is robust and serves as potential support for the development and application of teleoperated robots.","",""
4,"R. Carter, Z. Attia, J. Geske, A. Conners, D. Whaley, Katie N Hunt, M. O’Connor, D. Rhodes, C. Hruska","Classification of Background Parenchymal Uptake on Molecular Breast Imaging Using a Convolutional Neural Network.",2019,"","","","",53,"2022-07-13 09:29:15","","10.1200/CCI.18.00133","","",,,,,4,1.33,0,9,3,"PURPOSE Background parenchymal uptake (BPU), which describes the level of radiotracer uptake in normal fibroglandular tissue on molecular breast imaging (MBI), has been identified as a breast cancer risk factor. Our objective was to develop and validate a deep learning model using image convolution to automatically categorize BPU on MBI.   METHODS MBI examinations obtained for clinical and research purposes from 2004 to 2015 were reviewed to classify the BPU pattern using a standardized five-category scale. Two expert radiologists provided interpretations that were used as the reference standard for modeling. The modeling consisted of training and validating a convolutional neural network to predict BPU. Model performance was summarized in data reserved to test the performance of the algorithm at the per-image and per-breast levels.   RESULTS Training was performed on 24,639 images from 3,133 unique patients. The model performance on the withheld testing data (6,172 images; 786 patients) was evaluated. Using direct matching on the predicted classification resulted in an accuracy of 69.4% (95% CI, 67.4% to 71.3%), and if prediction within one category was considered, accuracy increased to 96.0% (95% CI, 95.2% to 96.7%). When considering the breast-level prediction of BPU, the accuracy remained strong, with 70.3% (95% CI, 68.0% to 72.6%) and 96.2% (95% CI, 95.3% to 97.2%) for the direct match and allowance for one category, respectively.   CONCLUSION BPU provided a robust target for training a convolutional neural network. A validated computer algorithm will allow for objective, reproducible encoding of BPU to foster its integration into risk-stratification algorithms.","",""
0,"Yang Xia, S. Uenohara, K. Aihara, T. Levi","Real-time implementation of ReSuMe learning in Spiking Neural Network",2019,"","","","",54,"2022-07-13 09:29:15","","10.5954/ICAROB.2019.OS2-4","","",,,,,0,0.00,0,4,3,"Neuromorphic systems are designed by mimicking or being inspired by the nervous system, which realizes robust, autonomous, and power-efficient information processing by highly parallel architecture. Supervised learning was proposed as a successful concept of information processing in neural network. Recently, there has been an increasing body of evidence that instruction-based learning is also exploited by the brain. ReSuMe is a proposed algorithm by Ponulak and Kasinski in 2010. It proposes a supervised learning for biologically plausible neurons that reproduce template signals (instructions) or patterns encoded in precisely timed sequences of spikes. Here, we present a real-time ReSuMe learning implementation on FPGA using Leaky Integrate-and-fire (LIF) Spiking Neural Network (SNN). FPGA allows real-time implementation and embedded system. We show that this implementation can make successful the learning on a specific pattern.","",""
0,"J. Ahmadi-Farsani, B. Linares-Barranco, T. Serrano-Gotarredona","Digital-Signal-Processor Realization of Izhikevich Neural Network for Real-Time Interaction with Electrophysiology Experiments",2019,"","","","",55,"2022-07-13 09:29:15","","10.1109/ICECS46596.2019.8965064","","",,,,,0,0.00,0,3,3,"The paper presents a realization on a digital signal processor (DSP) of an Izhikevich Neural Network operating with biologically plausible real-time constants. The paper demonstrates the real-time realization of different neuron behavioral modes, i.e., regular-spiking, chattering, bursting, and fast-spiking under proper parametrization. Real-time spike-timing-dependent-plasticity has also been embedded in the neural network realization. The paper studies the maximum array size that can be implemented on a TMS320C6455 microprocessor to be able to reproduce correctly the real-time dynamics of the different behaviors. The TMS320C6454, from the same DSP family as TMS320C6455, is embedded in a commercial microelectrode array system for real-time interaction with biological neural cell cultures. As demonstrator, a simple classification of two binary patterns has been implemented. Upon learning activation, the system robustly unsupervisely learns to differentiate the two patterns.","",""
1,"Nadav Ben-Shushan, M. Tsodyks","Stabilizing patterns in time: Neural network approach",2017,"","","","",56,"2022-07-13 09:29:15","","10.1371/journal.pcbi.1005861","","",,,,,1,0.20,1,2,5,"Recurrent and feedback networks are capable of holding dynamic memories. Nonetheless, training a network for that task is challenging. In order to do so, one should face non-linear propagation of errors in the system. Small deviations from the desired dynamics due to error or inherent noise might have a dramatic effect in the future. A method to cope with these difficulties is thus needed. In this work we focus on recurrent networks with linear activation functions and binary output unit. We characterize its ability to reproduce a temporal sequence of actions over its output unit. We suggest casting the temporal learning problem to a perceptron problem. In the discrete case a finite margin appears, providing the network, to some extent, robustness to noise, for which it performs perfectly (i.e. producing a desired sequence for an arbitrary number of cycles flawlessly). In the continuous case the margin approaches zero when the output unit changes its state, hence the network is only able to reproduce the sequence with slight jitters. Numerical simulation suggest that in the discrete time case, the longest sequence that can be learned scales, at best, as square root of the network size. A dramatic effect occurs when learning several short sequences in parallel, that is, their total length substantially exceeds the length of the longest single sequence the network can learn. This model easily generalizes to an arbitrary number of output units, which boost its performance. This effect is demonstrated by considering two practical examples for sequence learning. This work suggests a way to overcome stability problems for training recurrent networks and further quantifies the performance of a network under the specific learning scheme.","",""
92,"Xiaojian Li, Guanghong Yang","Neural-Network-Based Adaptive Decentralized Fault-Tolerant Control for a Class of Interconnected Nonlinear Systems",2018,"","","","",57,"2022-07-13 09:29:15","","10.1109/TNNLS.2016.2616906","","",,,,,92,23.00,46,2,4,"This paper is concerned with the adaptive decentralized fault-tolerant tracking control problem for a class of uncertain interconnected nonlinear systems with unknown strong interconnections. An algebraic graph theory result is introduced to address the considered interconnections. In addition, to achieve the desirable tracking performance, a neural-network-based robust adaptive decentralized fault-tolerant control (FTC) scheme is given to compensate the actuator faults and system uncertainties. Furthermore, via the Lyapunov analysis method, it is proven that all the signals of the resulting closed-loop system are semiglobally bounded, and the tracking errors of each subsystem exponentially converge to a compact set, whose radius is adjustable by choosing different controller design parameters. Finally, the effectiveness and advantages of the proposed FTC approach are illustrated with two simulated examples.","",""
1,"Cheng-Xia Sun, Xian Liu","A state observer for the computational network model of neural populations.",2021,"","","","",58,"2022-07-13 09:29:15","","10.1063/5.0020184","","",,,,,1,1.00,1,2,1,"A state observer plays a vital role in the design of state feedback neuromodulation schemes used to prevent and treat neurological or psychiatric disorders. This paper aims to design a state observer to reconstruct all unmeasured states of the computational network model of neural populations that replicates patterns seen on the electroencephalogram by using the model inputs and outputs, as the theoretical basis for designing state feedback neuromodulation clinical schemes. The feasibility problem of linear matrix inequality conditions, which is the most important one for observer design of the computational network model of neural populations, is solved by using the input-output stability theory and the Lurie system theory. The observer matrices of the designed observer are formed by the optimal solution of the linear matrix inequality conditions. An illustrative example shows that the observer can simultaneously reproduce internal state variables of normal and lesion populations of the computational network model of neural populations under the background of focal origin brain dysfunction, and the designed observer has certain robustness toward input uncertainty and measurement noise. To the best of our knowledge, no observers have previously been designed for the computational network model of neural populations. The design of state feedback neuromodulation schemes based on the computational network model of neural populations is a new direction in the field of computational neuroscience.","",""
104,"Liu Yang, Hanxin Chen","Fault diagnosis of gearbox based on RBF-PF and particle swarm optimization wavelet neural network",2019,"","","","",59,"2022-07-13 09:29:15","","10.1007/s00521-018-3525-y","","",,,,,104,34.67,52,2,3,"","",""
42,"G. Basalyga, E. Salinas","When Response Variability Increases Neural Network Robustness to Synaptic Noise",2005,"","","","",60,"2022-07-13 09:29:15","","10.1162/neco.2006.18.6.1349","","",,,,,42,2.47,21,2,17,"Cortical sensory neurons are known to be highly variable, in the sense that responses evoked by identical stimuli often change dramatically from trial to trial. The origin of this variability is uncertain, but it is usually interpreted as detrimental noise that reduces the computational accuracy of neural circuits. Here we investigate the possibility that such response variability might in fact be beneficial, because it may partially compensate for a decrease in accuracy due to stochastic changes in the synaptic strengths of a network. We study the interplay between two kinds of noise, response (or neuronal) noise and synaptic noise, by analyzing their joint influence on the accuracy of neural networks trained to perform various tasks. We find an interesting, generic interaction: when fluctuations in the synaptic connections are proportional to their strengths (multiplicative noise), a certain amount of response noise in the input neurons can significantly improve network performance, compared to the same network without response noise. Performance is enhanced because response noise and multiplicative synaptic noise are in some ways equivalent. So if the algorithm used to find the optimal synaptic weights can take into account the variability of the model neurons, it can also take into account the variability of the synapses. Thus, the connection patterns generated with response noise are typically more resistant to synaptic degradation than those obtained without response noise. As a consequence of this interplay, if multiplicative synaptic noise is present, it is better to have response noise in the network than not to have it. These results are demonstrated analytically for the most basic network consisting of two input neurons and one output neuron performing a simple classification task, but computer simulations show that the phenomenon persists in a wide range of architectures, including recurrent (attractor) networks and sensorimotor networks that perform coordinate transformations. The results suggest that response variability could play an important dynamic role in networks that continuously learn.","",""
40,"Hongwei Zhang, Xiong Xiao, O. Hasegawa","A Load-Balancing Self-Organizing Incremental Neural Network",2014,"","","","",61,"2022-07-13 09:29:15","","10.1109/TNNLS.2013.2287884","","",,,,,40,5.00,13,3,8,"Clustering is widely used in machine learning, feature extraction, pattern recognition, image analysis, information retrieval, and bioinformatics. Online unsupervised incremental learning is an important branch of data clustering. However, accurately separating high-density overlapped areas in a network has a direct impact on the performance of the clustering algorithm. In this paper, we propose a load-balancing self-organizing incremental neural network (LB-SOINN) to achieve good clustering results and demonstrate that it is more stable than an enhanced SOINN (E-SOINN). LB-SOINN has all the advantages of E-SOINN, such as robustness to noise and online unsupervised incremental learning. It overcomes the shortcomings of the topology structure generated by E-SOINN, such as dependence on the sequence of the input data, and avoids the turbulence that occurs when separating a composite class into subclasses. Furthermore, we also introduce a distance combination framework to obtain good performance for high-dimensional space-clustering tasks. Experiments involving both artificial and real world data sets indicate that LB-SOINN has superior performance in comparison with E-SOINN and other methods.","",""
76,"Yong Xu, Qiuqiang Kong, Qiang Huang, Wenwu Wang, Mark D. Plumbley","Convolutional gated recurrent neural network incorporating spatial features for audio tagging",2017,"","","","",62,"2022-07-13 09:29:15","","10.1109/IJCNN.2017.7966291","","",,,,,76,15.20,15,5,5,"Environmental audio tagging is a newly proposed task to predict the presence or absence of a specific audio event in a chunk. Deep neural network (DNN) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene. In this paper, we propose to use a convolutional neural network (CNN) to extract robust features from mel-filter banks (MFBs), spectrograms or even raw waveforms for audio tagging. Gated recurrent unit (GRU) based recurrent neural networks (RNNs) are then cascaded to model the long-term temporal structure of the audio signal. To complement the input information, an auxiliary CNN is designed to learn on the spatial features of stereo recordings. We evaluate our proposed methods on Task 4 (audio tagging) of the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE 2016) challenge. Compared with our recent DNN-based method, the proposed structure can reduce the equal error rate (EER) from 0.13 to 0.11 on the development set. The spatial features can further reduce the EER to 0.10. The performance of the end-to-end learning on raw waveforms is also comparable. Finally, on the evaluation set, we get the state-of-the-art performance with 0.12 EER while the performance of the best existing system is 0.15 EER.","",""
18,"A. Antonietti, J. Monaco, E. D’Angelo, A. Pedrocchi, C. Casellato","Dynamic Redistribution of Plasticity in a Cerebellar Spiking Neural Network Reproducing an Associative Learning Task Perturbed by TMS",2018,"","","","",63,"2022-07-13 09:29:15","","10.1142/S012906571850020X","","",,,,,18,4.50,4,5,4,"During natural learning, synaptic plasticity is thought to evolve dynamically and redistribute within and among subcircuits. This process should emerge in plastic neural networks evolving under behavioral feedback and should involve changes distributed across multiple synaptic sites. In eyeblink classical conditioning (EBCC), the cerebellum learns to predict the precise timing between two stimuli, hence EBCC represents an elementary yet meaningful paradigm to investigate the cerebellar network functioning. We have simulated EBCC mechanisms by reconstructing a realistic cerebellar microcircuit model and embedding multiple plasticity rules imitating those revealed experimentally. The model was tuned to fit experimental EBCC human data, estimating the underlying learning time-constants. Learning started rapidly with plastic changes in the cerebellar cortex followed by slower changes in the deep cerebellar nuclei. This process was characterized by differential development of long-term potentiation and depression at individual synapses, with a progressive accumulation of plasticity distributed over the whole network. The experimental data included two EBCC sessions interleaved by a trans-cranial magnetic stimulation (TMS). The experimental and the model response data were not significantly different in each learning phase, and the model goodness-of-fit was [Formula: see text] for all the experimental conditions. The models fitted on TMS data revealed a slowed down re-acquisition (sessions-2) compared to the control condition ([Formula: see text]). The plasticity parameters characterizing each model significantly differ among conditions, and thus mechanistically explain these response changes. Importantly, the model was able to capture the alteration in EBCC consolidation caused by TMS and showed that TMS affected plasticity at cortical synapses thereby altering the fast learning phase. This, secondarily, also affected plasticity in deep cerebellar nuclei altering learning dynamics in the entire sensory-motor loop. This observation reveals dynamic redistribution of changes over the entire network and suggests how TMS affects local circuit computation and memory processing in the cerebellum.","",""
55,"O. Meneghini, Sterling P. Smith, P. Snyder, G. Staebler, J. Candy, E. Belli, L. Lao, M. Kostuk, T. Luce, T. Luda, J. M. Park, F. Poli","Self-consistent core-pedestal transport simulations with neural network accelerated models",2017,"","","","",64,"2022-07-13 09:29:15","","10.1088/1741-4326/AA7776","","",,,,,55,11.00,6,12,5,"Fusion whole device modeling simulations require comprehensive models that are simultaneously physically accurate, fast, robust, and predictive. In this paper we describe the development of two neural-network (NN) based models as a means to perform a snon-linear multivariate regression of theory-based models for the core turbulent transport fluxes, and the pedestal structure. Specifically, we find that a NN-based approach can be used to consistently reproduce the results of the TGLF and EPED1 theory-based models over a broad range of plasma regimes, and with a computational speedup of several orders of magnitudes. These models are then integrated into a predictive workflow that allows prediction with self-consistent core-pedestal coupling of the kinetic profiles within the last closed flux surface of the plasma. The NN paradigm is capable of breaking the speed-accuracy trade-off that is expected of traditional numerical physics models, and can provide the missing link towards self-consistent coupled core-pedestal whole device modeling simulations that are physically accurate and yet take only seconds to run.","",""
47,"A. Tavanaei, A. Maida","Multi-layer unsupervised learning in a spiking convolutional neural network",2017,"","","","",65,"2022-07-13 09:29:15","","10.1109/IJCNN.2017.7966099","","",,,,,47,9.40,24,2,5,"Spiking neural networks (SNNs) have advantages over traditional, non-spiking networks with respect to biorealism, potential for low-power hardware implementations, and theoretical computing power. However, in practice, spiking networks with multi-layer learning have proven difficult to train. This paper explores a novel, bio-inspired spiking convolutional neural network (CNN) that is trained in a greedy, layer-wise fashion. The spiking CNN consists of a convolutional/pooling layer followed by a feature discovery layer, both of which undergo bio-inspired learning. Kernels for the convolutional layer are trained using a sparse, spiking auto-encoder representing primary visual features. The feature discovery layer uses a probabilistic spike-timing-dependent plasticity (STDP) learning rule. This layer represents complex visual features using WTA-thresholded, leaky, integrate-and-fire (LIF) neurons. The new model is evaluated on the MNIST digit dataset using clean and noisy images. Intermediate results show that the convolutional layer is stack-admissible, enabling it to support a multi-layer learning architecture. The recognition performance for clean images is above 98%. This performance is accounted for by the independent and informative visual features extracted in a hierarchy of convolutional and feature discovery layers. The performance loss for recognizing the noisy images is in the range 0.1% to 8.5%. This level of performance loss indicates that the network is robust to additive noise.","",""
40,"J. Dethier, P. Nuyujukian, S. Ryu, K. Shenoy, K. Boahen","Design and validation of a real-time spiking-neural-network decoder for brain-machine interfaces.",2013,"","","","",66,"2022-07-13 09:29:15","","10.1088/1741-2560/10/3/036008","","",,,,,40,4.44,8,5,9,"OBJECTIVE Cortically-controlled motor prostheses aim to restore functions lost to neurological disease and injury. Several proof of concept demonstrations have shown encouraging results, but barriers to clinical translation still remain. In particular, intracortical prostheses must satisfy stringent power dissipation constraints so as not to damage cortex.   APPROACH One possible solution is to use ultra-low power neuromorphic chips to decode neural signals for these intracortical implants. The first step is to explore in simulation the feasibility of translating decoding algorithms for brain-machine interface (BMI) applications into spiking neural networks (SNNs).   MAIN RESULTS Here we demonstrate the validity of the approach by implementing an existing Kalman-filter-based decoder in a simulated SNN using the Neural Engineering Framework (NEF), a general method for mapping control algorithms onto SNNs. To measure this system's robustness and generalization, we tested it online in closed-loop BMI experiments with two rhesus monkeys. Across both monkeys, a Kalman filter implemented using a 2000-neuron SNN has comparable performance to that of a Kalman filter implemented using standard floating point techniques.   SIGNIFICANCE These results demonstrate the tractability of SNN implementations of statistical signal processing algorithms on different monkeys and for several tasks, suggesting that a SNN decoder, implemented on a neuromorphic chip, may be a feasible computational platform for low-power fully-implanted prostheses. The validation of this closed-loop decoder system and the demonstration of its robustness and generalization hold promise for SNN implementations on an ultra-low power neuromorphic chip using the NEF.","",""
1,"Zhengyu Ma, Haixin Liu, T. Komiyama, R. Wessel","Stability of motor cortex network states during learning-associated neural reorganizations.",2020,"","","","",67,"2022-07-13 09:29:15","","10.1152/jn.00061.2020","","",,,,,1,0.50,0,4,2,"A substantial reorganization of neural activity and neuron-to-movement relationship in motor cortical circuits accompanies the emergence of reproducible movement patterns during motor learning. Little is known about how this tempest of neural activity restructuring impacts the stability of network states in recurrent cortical circuits. To investigate this issue, we reanalyzed data in which we recorded for 14 days via population calcium imaging the activity of the same neural populations of pyramidal neurons in layer 2/3 and layer 5 of forelimb motor and pre-motor cortex in mice during the daily learning of a lever-press task. We found that motor cortex network states remained stable with respect to the critical network state during the extensive reorganization of both neural population activity and its relation to lever movement throughout learning. Specifically, layer 2/3 cortical circuits unceasingly displayed robust evidence for operating at the critical network state, a regime that maximizes information capacity and transmission, and provides a balance between network robustness and flexibility. In contrast, layer 5 circuits operated away from the critical network state for all 14 days of recording and learning. In conclusion, this result indicates that the wide-ranging malleability of synapses, neurons, and neural connectivity during learning operates within the constraint of a stable and layer-specific network state regarding dynamic criticality, and suggests that different cortical layers operate under distinct constraints because of their specialized goals.","",""
0,"Jing Li, I. Liu, Weixin Gao, Xiaoyan Huang","Spiking neural network with synaptic plasticity for recognition",2018,"","","","",68,"2022-07-13 09:29:15","","10.1109/IAEAC.2018.8577629","","",,,,,0,0.00,0,4,4,"The spiking neural network referred to the third generation of neural network simulates the mechanisms of neurons and networks in brain. It has the distributed computational mechanism and robust information processing way like the nervous system. This paper describes that a spiking neural network with the synaptic plasticity recognizes the input scenes. The Digital spiking silicon neuron (DSSN), a mathematical structure-based qualitative model, is used to reproduce the various behaviors of neurons. We also designed the synapse model in our spiking neural network to precisely describe the dynamics of the transmitter release and the postsynaptic current generation. There are three layers in our network. The spiking neurons in layer 1 and 2 with special receptive fields perform the edge detection and orientation selection, respectively. The synaptic plasticity is realized in synaptic connections between spiking neurons in layer 2 and the output layer. The changing of connection is based on the Hebbian learning rule which supposes that the time difference of two spikes modifies the value of connection. We evaluated our spiking neural network with the task of image recognition. The spiking neurons in the output layer fire with the high frequency in response to their relevant input scenes. The simulation results show that our spiking neural network can successfully recognize the input scenes learned before. The recognition is robust against various distortions.","",""
181,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","Continuous Online Sequence Learning with an Unsupervised Neural Network Model",2015,"","","","",69,"2022-07-13 09:29:15","","10.1162/NECO_a_00893","","",,,,,181,25.86,45,4,7,"Abstract The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.","",""
31,"Anjith George, S. Marcel","Learning One Class Representations for Face Presentation Attack Detection Using Multi-Channel Convolutional Neural Networks",2020,"","","","",70,"2022-07-13 09:29:15","","10.1109/TIFS.2020.3013214","","",,,,,31,15.50,16,2,2,"Face recognition has evolved as a widely used biometric modality. However, its vulnerability against presentation attacks poses a significant security threat. Though presentation attack detection (PAD) methods try to address this issue, they often fail in generalizing to unseen attacks. In this work, we propose a new framework for PAD using a one-class classifier, where the representation used is learned with a Multi-Channel Convolutional Neural Network (MCCNN). A novel loss function is introduced, which forces the network to learn a compact embedding for bonafide class while being far from the representation of attacks. A one-class Gaussian Mixture Model is used on top of these embeddings for the PAD task. The proposed framework introduces a novel approach to learn a robust PAD system from bonafide and available (known) attack classes. This is particularly important as collecting bonafide data and simpler attacks are much easier than collecting a wide variety of expensive attacks. The proposed system is evaluated on the publicly available WMCA multi-channel face PAD database, which contains a wide variety of 2D and 3D attacks. Further, we have performed experiments with MLFP and SiW-M datasets using RGB channels only. Superior performance in unseen attack protocols shows the effectiveness of the proposed approach. Software, data, and protocols to reproduce the results are made available publicly.","",""
0,"Y. Hao, Wenbiao Ding, Zitao Liu","NeuCrowd: Neural Sampling Network for Representation Learning with Crowdsourced Labels",2020,"","","","",71,"2022-07-13 09:29:15","","10.1007/s10115-021-01644-7","","",,,,,0,0.00,0,3,2,"","",""
3,"A. Habibnia, E. Maasoumi","Forecasting in Big Data Environments: an Adaptable and Automated Shrinkage Estimation of Neural Networks (AAShNet)",2019,"","","","",72,"2022-07-13 09:29:15","","10.1007/s40953-021-00275-7","","",,,,,3,1.00,2,2,3,"","",""
3,"G. Rojas-Dueñas, J. Riba, M. Moreno-Eguilaz","Black-Box Modeling of DC–DC Converters Based on Wavelet Convolutional Neural Networks",2021,"","","","",73,"2022-07-13 09:29:15","","10.1109/TIM.2021.3098377","","",,,,,3,3.00,1,3,1,"This article presents an offline deep learning approach focused to model and identify a 270- to 28-V dc–dc step-down converter used in on-board distribution systems of more electric aircrafts (MEAs). Manufacturers usually do not provide enough information of the converters. Thus, it is difficult to perform design and planning tasks and to check the behavior of the power distribution system without an accurate model. This work considers the converter as a black box and trains a wavelet convolutional neural network (WCNN) that is able to accurately reproduce the behavior of the dc–dc converter from a large set of experimental data. The methodology to design a WCNN based on the characteristics of the input and output signals of the converter is also described. The method is validated with the experimental data obtained from a setup that replicates the 28-V on-board distribution system of an aircraft. The results presented in this article show a high correlation between the measured and estimated data, robustness, and low computational burden. This article also compares the proposed approach against other techniques presented in the literature. It is possible to extend this method to other dc–dc converters, depending on their requirements.","",""
90,"Jen-Tzung Chien, Y. Ku","Bayesian Recurrent Neural Network for Language Modeling",2016,"","","","",74,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2499302","","",,,,,90,15.00,45,2,6,"A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.","",""
8,"Bilal Hadjadji, Y. Chibani","Optimized selection of training samples for One-Class Neural Network classifier",2014,"","","","",75,"2022-07-13 09:29:15","","10.1109/IJCNN.2014.6889429","","",,,,,8,1.00,4,2,8,"One-Class Classification (OCC) based on the Auto-Associative Neural Networks (AANN) has been widely used in various recognition applications for its effective robustness. Its main advantage lies in the description of samples more accurately to other OCCs. However, it is considerably sensitive to the presence of outliers or noisy data contained into the training set, which may affect badly the representative model. Hence, we propose in this paper an algorithm that uses the AANN for selecting the most representative training samples. The same AANN is retrained to reproduce the selected samples for generating an optimal representative model. The experimental evaluation conducted on several real-world benchmarks confirms the effective use of the Selected Training Samples for Associative Neural Network (STS-AANN) versus the training on the entire set.","",""
58,"Youshen Xia, Changyin Sun, W. Zheng","Discrete-Time Neural Network for Fast Solving Large Linear $L_{1}$ Estimation Problems and its Application to Image Restoration",2012,"","","","",76,"2022-07-13 09:29:15","","10.1109/TNNLS.2012.2184800","","",,,,,58,5.80,19,3,10,"There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","",""
18,"E. Egrioglu, U. Yolcu, E. Bas, Ali Z. Dalar","Median-Pi artificial neural network for forecasting",2019,"","","","",77,"2022-07-13 09:29:15","","10.1007/s00521-017-3002-z","","",,,,,18,6.00,5,4,3,"","",""
14,"Hui Zhao, Lixiang Li, Haipeng Peng, J. Kurths, Jinghua Xiao, Yixian Yang","Finite-Time Robust Synchronization of Memrisive Neural Network with Perturbation",2017,"","","","",78,"2022-07-13 09:29:15","","10.1007/s11063-017-9664-9","","",,,,,14,2.80,2,6,5,"","",""
55,"Chih-Min Lin, A. Ting, Chun-Fei Hsu, Chao-Ming Chung","Adaptive Control for MIMO uncertain nonlinear Systems Using Recurrent Wavelet Neural Network",2012,"","","","",79,"2022-07-13 09:29:15","","10.1142/S0129065712002992","","",,,,,55,5.50,14,4,10,"Recurrent wavelet neural network (RWNN) has the advantages such as fast learning property, good generalization capability and information storing ability. With these advantages, this paper proposes an RWNN-based adaptive control (RBAC) system for multi-input multi-output (MIMO) uncertain nonlinear systems. The RBAC system is composed of a neural controller and a bounding compensator. The neural controller uses an RWNN to online mimic an ideal controller, and the bounding compensator can provide smooth and chattering-free stability compensation. From the Lyapunov stability analysis, it is shown that all signals in the closed-loop RBAC system are uniformly ultimately bounded. Finally, the proposed RBAC system is applied to the MIMO uncertain nonlinear systems such as a mass-spring-damper mechanical system and a two-link robotic manipulator system. Simulation results verify that the proposed RBAC system can achieve favorable tracking performance with desired robustness without any chattering phenomenon in the control effort.","",""
1,"Tong Chen, Zhan Ma","Towards Robust Neural Image Compression: Adversarial Attack and Model Finetuning",2021,"","","","",80,"2022-07-13 09:29:15","","","","",,,,,1,1.00,1,2,1,"Deep neural network based image compression has been extensively studied. Model robustness is largely overlooked, though it is crucial to service enabling. We perform the adversarial attack by injecting a small amount of noise perturbation to original source images, and then encode these adversarial examples using prevailing learnt image compression models. Experiments report severe distortion in the reconstruction of adversarial examples, revealing the general vulnerability of existing methods, regardless of the settings used in underlying compression model (e.g., network architecture, loss function, quality scale) and optimization strategy used for injecting perturbation (e.g., noise threshold, signal distance measurement). Later, we apply the iterative adversarial finetuning to refine pretrained models. In each iteration, random source images and adversarial examples are mixed to update underlying model. Results show the effectiveness of the proposed finetuning strategy by substantially improving the compression model robustness. Overall, our methodology is simple, effective, and generalizable, making it attractive for developing robust learnt image compression solution. All materials have been made publicly accessible at https://njuvision.github.io/RobustNIC for reproducible research.","",""
60,"Qingshan Liu, Jun Wang","$L_{1}$ -Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network",2016,"","","","",81,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2481006","","",,,,,60,10.00,30,2,6,"This paper presents several L1 -minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1 -minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1 -minimization algorithms.","",""
119,"Yi Shen, Jun Wang","Robustness Analysis of Global Exponential Stability of Recurrent Neural Networks in the Presence of Time Delays and Random Disturbances",2012,"","","","",82,"2022-07-13 09:29:15","","10.1109/TNNLS.2011.2178326","","",,,,,119,11.90,60,2,10,"In recent years, the global stability of recurrent neural networks (RNNs) has been investigated extensively. It is well known that time delays and external disturbances can derail the stability of RNNs. In this paper, we analyze the robustness of global stability of RNNs subject to time delays and random disturbances. Given a globally exponentially stable neural network, the problem to be addressed here is how much time delay and noise the RNN can withstand to be globally exponentially stable in the presence of delay and noise. The upper bounds of the time delay and noise intensity are characterized by using transcendental equations for the RNNs to sustain global exponential stability. Moreover, we prove theoretically that, for any globally exponentially stable RNNs, if additive noises and time delays are smaller than the derived lower bounds arrived at here, then the perturbed RNNs are guaranteed to also be globally exponentially stable. Three numerical examples are provided to substantiate the theoretical results.","",""
0,"Federico A. Galatolo, M. Cimino, Alessandro Marincioni, G. Vaglini","Noise Boosted Neural Receptive Fields",2021,"","","","",83,"2022-07-13 09:29:15","","10.1109/SSCI50451.2021.9660191","","",,,,,0,0.00,0,4,1,"Conventional neural networks (NNs) for image classification make use of a convolutional layer and a feedforward (FF) classification layer. This paper presents a novel classification layer architecture and a training paradigm, in which the FF layer is split into small and specialized FF nets called Noise Boosted Receptive Fields (NBRFs), one per class. Each i-th NBRF provides three membership degrees: to the i-th class, to the super class made by its complementary classes, and to an extra class representing out-of-classes images. The training process artificially generates extra-class samples, via image transformation and noise addition. Experimental results, carried out on MNIST, KMNIST and FMNIST datasets show that, with respect to an FF layer, the NBRF layer improves robustness and accuracy of classification. The repository with the source code and experimental data has been publicly released to facilitate reproducibility and widespread adoption.","",""
12,"Jinliang Zhang, Shasha Liu, Jingzhe Li, Longlong Liu, Huimin Liu, Zhongqiang Sun","Identification of sedimentary facies with well logs: an indirect approach with multinomial logistic regression and artificial neural network",2017,"","","","",84,"2022-07-13 09:29:15","","10.1007/s12517-017-3045-6","","",,,,,12,2.40,2,6,5,"","",""
68,"Qiang Yu, Rui Yan, Huajin Tang, K. Tan, Haizhou Li","A Spiking Neural Network System for Robust Sequence Recognition",2016,"","","","",85,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2416771","","",,,,,68,11.33,14,5,6,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.","",""
36,"Lin Sun, Jiucheng Xu, Shangwang Liu, Shiguang Zhang, Yuan Li, Chang'an Shen","A robust image watermarking scheme using Arnold transform and BP neural network",2018,"","","","",86,"2022-07-13 09:29:15","","10.1007/s00521-016-2788-4","","",,,,,36,9.00,6,6,4,"","",""
0,"A. Leventi-Peetz, T. Östreich","Deep Learning Reproducibility and Explainable AI (XAI)",2022,"","","","",87,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,2,1,"The nondeterminism of Deep Learning (DL) training algorithms and its influence on the explainability of neural network (NN) models are investigated in this work with the help of image classification examples. To discuss the issue, two convolutional neural networks (CNN) have been trained and their results compared. The comparison serves the exploration of the feasibility of creating deterministic, robust DL models and deterministic explainable artificial intelligence (XAI) in practice. Successes and limitation of all here carried out efforts are described in detail. The source code of the attained deterministic models has been listed in this work. Reproducibility is indexed as a development-phase-component of the Model Governance Framework, proposed by the EU within their excellence in AI approach. Furthermore, reproducibility is a requirement for establishing causality for the interpretation of model results and building of trust towards the overwhelming expansion of AI systems applications. Problems that have to be solved on the way to reproducibility and ways to deal with some of them, are examined in this work.","",""
83,"Hao Quan, D. Srinivasan, A. Khosravi","Incorporating Wind Power Forecast Uncertainties Into Stochastic Unit Commitment Using Neural Network-Based Prediction Intervals",2015,"","","","",88,"2022-07-13 09:29:15","","10.1109/TNNLS.2014.2376696","","",,,,,83,11.86,28,3,7,"Penetration of renewable energy resources, such as wind and solar power, into power systems significantly increases the uncertainties on system operation, stability, and reliability in smart grids. In this paper, the nonparametric neural network-based prediction intervals (PIs) are implemented for forecast uncertainty quantification. Instead of a single level PI, wind power forecast uncertainties are represented in a list of PIs. These PIs are then decomposed into quantiles of wind power. A new scenario generation method is proposed to handle wind power forecast uncertainties. For each hour, an empirical cumulative distribution function (ECDF) is fitted to these quantile points. The Monte Carlo simulation method is used to generate scenarios from the ECDF. Then the wind power scenarios are incorporated into a stochastic security-constrained unit commitment (SCUC) model. The heuristic genetic algorithm is utilized to solve the stochastic SCUC problem. Five deterministic and four stochastic case studies incorporated with interval forecasts of wind power are implemented. The results of these cases are presented and discussed together. Generation costs, and the scheduled and real-time economic dispatch reserves of different unit commitment strategies are compared. The experimental results show that the stochastic model is more robust than deterministic ones and, thus, decreases the risk in system operations of smart grids.","",""
58,"S. Naz, A. I. Umar, Riaz Ahmad, S. Ahmed, S. H. Shirazi, M. I. Razzak","Urdu Nasta’liq text recognition system based on multi-dimensional recurrent neural network and statistical features",2017,"","","","",89,"2022-07-13 09:29:15","","10.1007/s00521-015-2051-4","","",,,,,58,11.60,10,6,5,"","",""
75,"Qinmin Yang, S. Jagannathan, Youxian Sun","Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems",2015,"","","","",90,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2470175","","",,,,,75,10.71,25,3,7,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.","",""
24,"G. Rajchakit, R. Sriraman","Robust Passivity and Stability Analysis of Uncertain Complex-Valued Impulsive Neural Networks with Time-Varying Delays",2021,"","","","",91,"2022-07-13 09:29:15","","10.1007/s11063-020-10401-w","","",,,,,24,24.00,12,2,1,"","",""
61,"Zhijun Li, Yuanqing Xia, C. Su, Jun Deng, Jun Fu, W. He","Missile Guidance Law Based on Robust Model Predictive Control Using Neural-Network Optimization",2015,"","","","",92,"2022-07-13 09:29:15","","10.1109/TNNLS.2014.2345734","","",,,,,61,8.71,10,6,7,"In this brief, the utilization of robust model-based predictive control is investigated for the problem of missile interception. Treating the target acceleration as a bounded disturbance, novel guidance law using model predictive control is developed by incorporating missile inside constraints. The combined model predictive approach could be transformed as a constrained quadratic programming (QP) problem, which may be solved using a linear variational inequality-based primal-dual neural network over a finite receding horizon. Online solutions to multiple parametric QP problems are used so that constrained optimal control decisions can be made in real time. Simulation studies are conducted to illustrate the effectiveness and performance of the proposed guidance control law for missile interception.","",""
22,"Foued Saâdaoui","A seasonal feedforward neural network to forecast electricity prices",2017,"","","","",93,"2022-07-13 09:29:15","","10.1007/s00521-016-2356-y","","",,,,,22,4.40,22,1,5,"","",""
22,"Ikbal Eski, Ş. Yıldırım","Neural network-based fuzzy inference system for speed control of heavy duty vehicles with electronic throttle control system",2017,"","","","",94,"2022-07-13 09:29:15","","10.1007/s00521-016-2362-0","","",,,,,22,4.40,11,2,5,"","",""
94,"Richard Gilmore, Neil Hanley, M. O’Neill","Neural network based attack on a masked implementation of AES",2015,"","","","",95,"2022-07-13 09:29:15","","10.1109/HST.2015.7140247","","",,,,,94,13.43,31,3,7,"Masked implementations of cryptographic algorithms are often used in commercial embedded cryptographic devices to increase their resistance to side channel attacks. In this work we show how neural networks can be used to both identify the mask value, and to subsequently identify the secret key value with a single attack trace with high probability. We propose the use of a pre-processing step using principal component analysis (PCA) to significantly increase the success of the attack. We have developed a classifier that can correctly identify the mask for each trace, hence removing the security provided by that mask and reducing the attack to being equivalent to an attack against an unprotected implementation. The attack is performed on the freely available differential power analysis (DPA) contest data set to allow our work to be easily reproducible. We show that neural networks allow for a robust and efficient classification in the context of side-channel attacks.","",""
13,"L. Wandera, K. Mallick, G. Kiely, O. Roupsard, M. Peichl, V. Magliulo","Upscaling instantaneous to daily evapotranspiration using modelled daily shortwave radiation for remote sensing applications: an artificial neural network approach",2016,"","","","",96,"2022-07-13 09:29:15","","10.5194/HESS-21-197-2017","","",,,,,13,2.17,2,6,6,"Abstract. Upscaling instantaneous evapotranspiration retrieved at any specific time-of-day (ETi) to daily evapotranspiration (ETd) is a key challenge in mapping regional ET using polar orbiting sensors. Various studies have unanimously cited the shortwave incoming radiation (RS) to be the most robust reference variable explaining the ratio between ETd and ETi. This study aims to contribute in ETi upscaling for global studies using the ratio between daily and instantaneous incoming shortwave radiation (RSd ∕ RSi) as a factor for converting ETi to ETd. This paper proposes an artificial neural network (ANN) machine-learning algorithm first to predict RSd from RSi followed by using the RSd ∕ RSi ratio to convert ETi to ETd across different terrestrial ecosystems. Using RSi and RSd observations from multiple sub-networks of the FLUXNET database spread across different climates and biomes (to represent inputs that would typically be obtainable from remote sensors during the overpass time) in conjunction with some astronomical variables (e.g. solar zenith angle, day length, exoatmospheric shortwave radiation), we developed the ANN model for reproducing RSd and further used it to upscale ETi to ETd. The efficiency of the ANN is evaluated for different morning and afternoon times of day, under varying sky conditions, and also at different geographic locations. RS-based upscaled ETd produced a significant linear relation (R2 =  0.65 to 0.69), low bias (−0.31 to −0.56 MJ m−2 d−1; approx. 4 %), and good agreement (RMSE 1.55 to 1.86 MJ m−2 d−1; approx. 10 %) with the observed ETd, although a systematic overestimation of ETd was also noted under persistent cloudy sky conditions. Inclusion of soil moisture and rainfall information in ANN training reduced the systematic overestimation tendency in predominantly overcast days. An intercomparison with existing upscaling method at daily, 8-day, monthly, and yearly temporal resolution revealed a robust performance of the ANN-driven RS-based ETi upscaling method and was found to produce lowest RMSE under cloudy conditions. Sensitivity analysis revealed variable sensitivity of the method to biome selection and high ETd prediction errors in forest ecosystems are primarily associated with greater rainfall and cloudiness. The overall methodology appears to be promising and has substantial potential for upscaling ETi to ETd for field and regional-scale evapotranspiration mapping studies using polar orbiting satellites.","",""
1,"Federico Adolfi, J. Bowers, D. Poeppel","Successes and critical failures of neural networks in capturing human-like speech recognition",2022,"","","","",97,"2022-07-13 09:29:15","","10.48550/arXiv.2204.03740","","",,,,,1,1.00,0,3,1,"Natural and artiﬁcial audition can in principle evolve diﬀerent solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would im- prove artiﬁcial hearing systems and process models of the mind and brain. Speech recognition — an area ripe for such exploration — is inherently robust in humans to a number transformations at various spectrotempo- ral granularities. To what extent are these robust- ness proﬁles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus- computable, optimized observers. In a series of experiments, we (1) clarify how inﬂuential speech manipula- tions in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the speciﬁc conditions where model predictions of human performance diﬀer, and (4) demonstrate a crucial fail- ure of all artiﬁcial systems to perceptually recover where humans do, suggesting a key speciﬁcation for theory and model building. These ﬁndings encourage a tighter synergy between the cognitive science and engineering of audition.","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",98,"2022-07-13 09:29:15","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
0,"Manuel Günther, Andras Rozsa, T. Boult","On the Robustness of Deep Neural Networks",2017,"","","","",99,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,3,5,"Deep Neural Networks (DNNs) have become the quasi-standard in many machine learning tasks since they obtain state-of-the-art results and outperform more traditional machine learning models for problems in vision, image and speech processing, and many other tasks. One reason that DNNs have proven very useful is that they are one of the few algorithms that can make principled use of huge databases for training. However, despite their brilliant recognition capabilities, little is known about how DNNs achieve their accuracies, and even less is known about their robustness and their limitations. After Szegedy et al. [19] showed that deep networks have some “intriguing” properties, several researchers started actively exploring the limitations, and showed how easily the networks could be attacked or fooled – demonstrating essential limits of the robustness of DNNs. This paper analyzes these two categories of attacks: adversarial images [19, 3], which are imperceptible perturbations to an input to turn it into another class, and fooling images [9], which look like none of the ∗This research is based upon work funded in part by NSF IIS-1320956 and in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. 2014-14071600012. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.","",""
75,"Vaibhav Gandhi, G. Prasad, D. Coyle, L. Behera, T. McGinnity","Quantum Neural Network-Based EEG Filtering for a Brain–Computer Interface",2014,"","","","",100,"2022-07-13 09:29:15","","10.1109/TNNLS.2013.2274436","","",,,,,75,9.38,15,5,8,"A novel neural information processing architecture inspired by quantum mechanics and incorporating the well-known Schrodinger wave equation is proposed in this paper. The proposed architecture referred to as recurrent quantum neural network (RQNN) can characterize a nonstationary stochastic signal as time-varying wave packets. A robust unsupervised learning algorithm enables the RQNN to effectively capture the statistical behavior of the input signal and facilitates the estimation of signal embedded in noise with unknown characteristics. The results from a number of benchmark tests show that simple signals such as dc, staircase dc, and sinusoidal signals embedded within high noise can be accurately filtered and particle swarm optimization can be employed to select model parameters. The RQNN filtering procedure is applied in a two-class motor imagery-based brain-computer interface where the objective was to filter electroencephalogram (EEG) signals before feature extraction and classification to increase signal separability. A two-step inner-outer fivefold cross-validation approach is utilized to select the algorithm parameters subject-specifically for nine subjects. It is shown that the subject-specific RQNN EEG filtering significantly improves brain-computer interface performance compared to using only the raw EEG or Savitzky-Golay filtered EEG across multiple sessions.","",""
90,"Jen-Tzung Chien, Y. Ku","Bayesian Recurrent Neural Network for Language Modeling",2016,"","","","",101,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2499302","","",,,,,90,15.00,45,2,6,"A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.","",""
8,"Bilal Hadjadji, Y. Chibani","Optimized selection of training samples for One-Class Neural Network classifier",2014,"","","","",102,"2022-07-13 09:29:15","","10.1109/IJCNN.2014.6889429","","",,,,,8,1.00,4,2,8,"One-Class Classification (OCC) based on the Auto-Associative Neural Networks (AANN) has been widely used in various recognition applications for its effective robustness. Its main advantage lies in the description of samples more accurately to other OCCs. However, it is considerably sensitive to the presence of outliers or noisy data contained into the training set, which may affect badly the representative model. Hence, we propose in this paper an algorithm that uses the AANN for selecting the most representative training samples. The same AANN is retrained to reproduce the selected samples for generating an optimal representative model. The experimental evaluation conducted on several real-world benchmarks confirms the effective use of the Selected Training Samples for Associative Neural Network (STS-AANN) versus the training on the entire set.","",""
2,"Guillermo B. Morales, M. A. Muñoz","Optimal Input Representation in Neural Systems at the Edge of Chaos",2021,"","","","",103,"2022-07-13 09:29:15","","10.3390/biology10080702","","",,,,,2,2.00,1,2,1,"Simple Summary Here we show that a simple neural network within the paradigm of reservoir computing is able to reproduce an important feature of internal representations of neural inputs, in agreement with what theoretically predicted and empirically measured in the mouse visual cortex, only when it is set to operate at the edge of chaos. Abstract Shedding light on how biological systems represent, process and store information in noisy environments is a key and challenging goal. A stimulating, though controversial, hypothesis poses that operating in dynamical regimes near the edge of a phase transition, i.e., at criticality or the “edge of chaos”, can provide information-processing living systems with important operational advantages, creating, e.g., an optimal trade-off between robustness and flexibility. Here, we elaborate on a recent theoretical result, which establishes that the spectrum of covariance matrices of neural networks representing complex inputs in a robust way needs to decay as a power-law of the rank, with an exponent close to unity, a result that has been indeed experimentally verified in neurons of the mouse visual cortex. Aimed at understanding and mimicking these results, we construct an artificial neural network and train it to classify images. We find that the best performance in such a task is obtained when the network operates near the critical point, at which the eigenspectrum of the covariance matrix follows the very same statistics as actual neurons do. Thus, we conclude that operating near criticality can also have—besides the usually alleged virtues—the advantage of allowing for flexible, robust and efficient input representations.","",""
58,"Youshen Xia, Changyin Sun, W. Zheng","Discrete-Time Neural Network for Fast Solving Large Linear $L_{1}$ Estimation Problems and its Application to Image Restoration",2012,"","","","",104,"2022-07-13 09:29:15","","10.1109/TNNLS.2012.2184800","","",,,,,58,5.80,19,3,10,"There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","",""
18,"E. Egrioglu, U. Yolcu, E. Bas, Ali Z. Dalar","Median-Pi artificial neural network for forecasting",2019,"","","","",105,"2022-07-13 09:29:15","","10.1007/s00521-017-3002-z","","",,,,,18,6.00,5,4,3,"","",""
14,"Hui Zhao, Lixiang Li, Haipeng Peng, J. Kurths, Jinghua Xiao, Yixian Yang","Finite-Time Robust Synchronization of Memrisive Neural Network with Perturbation",2017,"","","","",106,"2022-07-13 09:29:15","","10.1007/s11063-017-9664-9","","",,,,,14,2.80,2,6,5,"","",""
55,"Chih-Min Lin, A. Ting, Chun-Fei Hsu, Chao-Ming Chung","Adaptive Control for MIMO uncertain nonlinear Systems Using Recurrent Wavelet Neural Network",2012,"","","","",107,"2022-07-13 09:29:15","","10.1142/S0129065712002992","","",,,,,55,5.50,14,4,10,"Recurrent wavelet neural network (RWNN) has the advantages such as fast learning property, good generalization capability and information storing ability. With these advantages, this paper proposes an RWNN-based adaptive control (RBAC) system for multi-input multi-output (MIMO) uncertain nonlinear systems. The RBAC system is composed of a neural controller and a bounding compensator. The neural controller uses an RWNN to online mimic an ideal controller, and the bounding compensator can provide smooth and chattering-free stability compensation. From the Lyapunov stability analysis, it is shown that all signals in the closed-loop RBAC system are uniformly ultimately bounded. Finally, the proposed RBAC system is applied to the MIMO uncertain nonlinear systems such as a mass-spring-damper mechanical system and a two-link robotic manipulator system. Simulation results verify that the proposed RBAC system can achieve favorable tracking performance with desired robustness without any chattering phenomenon in the control effort.","",""
1,"Julia Gusak, A. Katrutsa, Talgat Daulbaev, A. Cichocki, I. Oseledets","Meta-Solver for Neural Ordinary Differential Equations",2021,"","","","",108,"2022-07-13 09:29:15","","","","",,,,,1,1.00,0,5,1,"A conventional approach to train neural ordinary differential equations (ODEs) is to fix an ODE solver and then learn the neural network’s weights to optimize a target loss function. However, such an approach is tailored for a specific discretization method and its properties, which may not be optimal for the selected application and yield the overfitting to the given solver. In our paper, we investigate how the variability in solvers’ space can improve neural ODEs performance. We consider a family of Runge-Kutta methods that are parameterized by no more than two scalar variables. Based on the solvers’ properties, we propose an approach to decrease neural ODEs overfitting to the pre-defined solver, along with a criterion to evaluate such behaviour. Moreover, we show that the right choice of solver parameterization can significantly affect neural ODEs models in terms of robustness to adversarial attacks. Recently it was shown that neural ODEs demonstrate superiority over conventional CNNs in terms of robustness. Our work demonstrates that the model robustness can be further improved by optimizing solver choice for a given task. The source code to reproduce our experiments is available at https://github.com/juliagusak/neural-ode-metasolver.","",""
1,"Tong Chen, Zhan Ma","Towards Robust Neural Image Compression: Adversarial Attack and Model Finetuning",2021,"","","","",109,"2022-07-13 09:29:15","","","","",,,,,1,1.00,1,2,1,"Deep neural network based image compression has been extensively studied. Model robustness is largely overlooked, though it is crucial to service enabling. We perform the adversarial attack by injecting a small amount of noise perturbation to original source images, and then encode these adversarial examples using prevailing learnt image compression models. Experiments report severe distortion in the reconstruction of adversarial examples, revealing the general vulnerability of existing methods, regardless of the settings used in underlying compression model (e.g., network architecture, loss function, quality scale) and optimization strategy used for injecting perturbation (e.g., noise threshold, signal distance measurement). Later, we apply the iterative adversarial finetuning to refine pretrained models. In each iteration, random source images and adversarial examples are mixed to update underlying model. Results show the effectiveness of the proposed finetuning strategy by substantially improving the compression model robustness. Overall, our methodology is simple, effective, and generalizable, making it attractive for developing robust learnt image compression solution. All materials have been made publicly accessible at https://njuvision.github.io/RobustNIC for reproducible research.","",""
1,"D. Wamriew, R. Pevzner, E. Maltsev, D. Pissarenko","Deep Neural Networks for Detection and Location of Microseismic Events and Velocity Model Inversion from Microseismic Data Acquired by Distributed Acoustic Sensing Array",2021,"","","","",110,"2022-07-13 09:29:15","","10.3390/s21196627","","",,,,,1,1.00,0,4,1,"Fiber-optic cables have recently gained popularity for use as Distributed Acoustic Sensing (DAS) arrays for borehole microseismic monitoring due to their physical robustness as well as high spatial and temporal resolutions. As a result, the sensors record large amounts of data, making it very difficult to process in real-/semi-real-time using the conventional processing routines. We present a novel approach, based on deep learning, for handling the large amounts of DAS data in real-/semi-real-time. The proposed neural network was trained on synthetic microseismic data contaminated with real-ambient noise from field data and was validated using field DAS microseismic data obtained from a hydraulic fracturing operation. The results indicate that the trained network is capable of detecting and locating microseismic events from DAS data and simultaneously update the velocity model to a high degree of precision. The mean absolute errors in the event locations and the velocity model parameters are 2.04, 0.72, 2.76, 4.19 and 0.97 percent for distance (x), depth (z), P-wave velocity, S-wave velocity and density, respectively. In addition to automation and computational efficiency, deep learning reduces human expert data handling during processing, thus preserving data integrity leading to more accurate and reproducible results.","",""
60,"Qingshan Liu, Jun Wang","$L_{1}$ -Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network",2016,"","","","",111,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2481006","","",,,,,60,10.00,30,2,6,"This paper presents several L1 -minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1 -minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1 -minimization algorithms.","",""
119,"Yi Shen, Jun Wang","Robustness Analysis of Global Exponential Stability of Recurrent Neural Networks in the Presence of Time Delays and Random Disturbances",2012,"","","","",112,"2022-07-13 09:29:15","","10.1109/TNNLS.2011.2178326","","",,,,,119,11.90,60,2,10,"In recent years, the global stability of recurrent neural networks (RNNs) has been investigated extensively. It is well known that time delays and external disturbances can derail the stability of RNNs. In this paper, we analyze the robustness of global stability of RNNs subject to time delays and random disturbances. Given a globally exponentially stable neural network, the problem to be addressed here is how much time delay and noise the RNN can withstand to be globally exponentially stable in the presence of delay and noise. The upper bounds of the time delay and noise intensity are characterized by using transcendental equations for the RNNs to sustain global exponential stability. Moreover, we prove theoretically that, for any globally exponentially stable RNNs, if additive noises and time delays are smaller than the derived lower bounds arrived at here, then the perturbed RNNs are guaranteed to also be globally exponentially stable. Three numerical examples are provided to substantiate the theoretical results.","",""
0,"Federico A. Galatolo, M. Cimino, Alessandro Marincioni, G. Vaglini","Noise Boosted Neural Receptive Fields",2021,"","","","",113,"2022-07-13 09:29:15","","10.1109/SSCI50451.2021.9660191","","",,,,,0,0.00,0,4,1,"Conventional neural networks (NNs) for image classification make use of a convolutional layer and a feedforward (FF) classification layer. This paper presents a novel classification layer architecture and a training paradigm, in which the FF layer is split into small and specialized FF nets called Noise Boosted Receptive Fields (NBRFs), one per class. Each i-th NBRF provides three membership degrees: to the i-th class, to the super class made by its complementary classes, and to an extra class representing out-of-classes images. The training process artificially generates extra-class samples, via image transformation and noise addition. Experimental results, carried out on MNIST, KMNIST and FMNIST datasets show that, with respect to an FF layer, the NBRF layer improves robustness and accuracy of classification. The repository with the source code and experimental data has been publicly released to facilitate reproducibility and widespread adoption.","",""
12,"Jinliang Zhang, Shasha Liu, Jingzhe Li, Longlong Liu, Huimin Liu, Zhongqiang Sun","Identification of sedimentary facies with well logs: an indirect approach with multinomial logistic regression and artificial neural network",2017,"","","","",114,"2022-07-13 09:29:15","","10.1007/s12517-017-3045-6","","",,,,,12,2.40,2,6,5,"","",""
133,"Peijun Hu, Fa Wu, Jialin Peng, Yuanyuan Bao, F. Chen, D. Kong","Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets",2016,"","","","",115,"2022-07-13 09:29:15","","10.1007/s11548-016-1501-5","","",,,,,133,22.17,22,6,6,"","",""
68,"Qiang Yu, Rui Yan, Huajin Tang, K. Tan, Haizhou Li","A Spiking Neural Network System for Robust Sequence Recognition",2016,"","","","",116,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2416771","","",,,,,68,11.33,14,5,6,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.","",""
36,"Lin Sun, Jiucheng Xu, Shangwang Liu, Shiguang Zhang, Yuan Li, Chang'an Shen","A robust image watermarking scheme using Arnold transform and BP neural network",2018,"","","","",117,"2022-07-13 09:29:15","","10.1007/s00521-016-2788-4","","",,,,,36,9.00,6,6,4,"","",""
2,"A. A. Abello, R. Hirata, Zhangyang Wang","Dissecting the High-Frequency Bias in Convolutional Neural Networks",2021,"","","","",118,"2022-07-13 09:29:15","","10.1109/CVPRW53098.2021.00096","","",,,,,2,2.00,1,3,1,"For convolutional neural networks (CNNs), a common hypothesis that explains both their generalization capability and their characteristic brittleness is that these models are implicitly regularized to rely on imperceptible high-frequency patterns, more than humans would do. This hypothesis has seen some empirical validation, but most works do not rigorously divide the image frequency spectrum. We present a model to divide the spectrum in disjointed discs based on the distribution of energy and apply simple feature importance procedures to test whether high-frequencies are more important than lower ones. We find evidence that mid or high-level frequencies are disproportionately important for CNNs. The evidence is robust across different datasets and networks. Moreover, we find the diverse effects of the network’s attributes, such as architecture and depth, on frequency bias and robustness in general. Code for reproducing our experiments is available at: https://github.com/Abello966/FrequencyBiasExperiments","",""
0,"A. Leventi-Peetz, T. Östreich","Deep Learning Reproducibility and Explainable AI (XAI)",2022,"","","","",119,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,2,1,"The nondeterminism of Deep Learning (DL) training algorithms and its influence on the explainability of neural network (NN) models are investigated in this work with the help of image classification examples. To discuss the issue, two convolutional neural networks (CNN) have been trained and their results compared. The comparison serves the exploration of the feasibility of creating deterministic, robust DL models and deterministic explainable artificial intelligence (XAI) in practice. Successes and limitation of all here carried out efforts are described in detail. The source code of the attained deterministic models has been listed in this work. Reproducibility is indexed as a development-phase-component of the Model Governance Framework, proposed by the EU within their excellence in AI approach. Furthermore, reproducibility is a requirement for establishing causality for the interpretation of model results and building of trust towards the overwhelming expansion of AI systems applications. Problems that have to be solved on the way to reproducibility and ways to deal with some of them, are examined in this work.","",""
83,"Hao Quan, D. Srinivasan, A. Khosravi","Incorporating Wind Power Forecast Uncertainties Into Stochastic Unit Commitment Using Neural Network-Based Prediction Intervals",2015,"","","","",120,"2022-07-13 09:29:15","","10.1109/TNNLS.2014.2376696","","",,,,,83,11.86,28,3,7,"Penetration of renewable energy resources, such as wind and solar power, into power systems significantly increases the uncertainties on system operation, stability, and reliability in smart grids. In this paper, the nonparametric neural network-based prediction intervals (PIs) are implemented for forecast uncertainty quantification. Instead of a single level PI, wind power forecast uncertainties are represented in a list of PIs. These PIs are then decomposed into quantiles of wind power. A new scenario generation method is proposed to handle wind power forecast uncertainties. For each hour, an empirical cumulative distribution function (ECDF) is fitted to these quantile points. The Monte Carlo simulation method is used to generate scenarios from the ECDF. Then the wind power scenarios are incorporated into a stochastic security-constrained unit commitment (SCUC) model. The heuristic genetic algorithm is utilized to solve the stochastic SCUC problem. Five deterministic and four stochastic case studies incorporated with interval forecasts of wind power are implemented. The results of these cases are presented and discussed together. Generation costs, and the scheduled and real-time economic dispatch reserves of different unit commitment strategies are compared. The experimental results show that the stochastic model is more robust than deterministic ones and, thus, decreases the risk in system operations of smart grids.","",""
58,"S. Naz, A. I. Umar, Riaz Ahmad, S. Ahmed, S. H. Shirazi, M. I. Razzak","Urdu Nasta’liq text recognition system based on multi-dimensional recurrent neural network and statistical features",2017,"","","","",121,"2022-07-13 09:29:15","","10.1007/s00521-015-2051-4","","",,,,,58,11.60,10,6,5,"","",""
75,"Qinmin Yang, S. Jagannathan, Youxian Sun","Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems",2015,"","","","",122,"2022-07-13 09:29:15","","10.1109/TNNLS.2015.2470175","","",,,,,75,10.71,25,3,7,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.","",""
24,"G. Rajchakit, R. Sriraman","Robust Passivity and Stability Analysis of Uncertain Complex-Valued Impulsive Neural Networks with Time-Varying Delays",2021,"","","","",123,"2022-07-13 09:29:15","","10.1007/s11063-020-10401-w","","",,,,,24,24.00,12,2,1,"","",""
17,"Sheheryar Zaidi, Arber Zela, T. Elsken, Chris C. Holmes, F. Hutter, Y. Teh","Neural Ensemble Search for Uncertainty Estimation and Dataset Shift",2020,"","","","",124,"2022-07-13 09:29:15","","","","",,,,,17,8.50,3,6,2,"Ensembles of neural networks achieve superior performance compared to standalone networks in terms of accuracy, uncertainty calibration and robustness to dataset shift. Deep ensembles, a state-of-the-art method for uncertainty estimation, only ensemble random initializations of a fixed architecture. Instead, we propose two methods for automatically constructing ensembles with varying architectures, which implicitly trade-off individual architectures’ strengths against the ensemble’s diversity and exploit architectural variation as a source of diversity. On a variety of classification tasks and modern architecture search spaces, we show that the resulting ensembles outperform deep ensembles not only in terms of accuracy but also uncertainty calibration and robustness to dataset shift. Our further analysis and ablation studies provide evidence of higher ensemble diversity due to architectural variation, resulting in ensembles that can outperform deep ensembles, even when having weaker average base learners. To foster reproducibility, our code is available: https://github.com/automl/nes","",""
61,"Zhijun Li, Yuanqing Xia, C. Su, Jun Deng, Jun Fu, W. He","Missile Guidance Law Based on Robust Model Predictive Control Using Neural-Network Optimization",2015,"","","","",125,"2022-07-13 09:29:15","","10.1109/TNNLS.2014.2345734","","",,,,,61,8.71,10,6,7,"In this brief, the utilization of robust model-based predictive control is investigated for the problem of missile interception. Treating the target acceleration as a bounded disturbance, novel guidance law using model predictive control is developed by incorporating missile inside constraints. The combined model predictive approach could be transformed as a constrained quadratic programming (QP) problem, which may be solved using a linear variational inequality-based primal-dual neural network over a finite receding horizon. Online solutions to multiple parametric QP problems are used so that constrained optimal control decisions can be made in real time. Simulation studies are conducted to illustrate the effectiveness and performance of the proposed guidance control law for missile interception.","",""
22,"Ikbal Eski, Ş. Yıldırım","Neural network-based fuzzy inference system for speed control of heavy duty vehicles with electronic throttle control system",2017,"","","","",126,"2022-07-13 09:29:15","","10.1007/s00521-016-2362-0","","",,,,,22,4.40,11,2,5,"","",""
22,"Foued Saâdaoui","A seasonal feedforward neural network to forecast electricity prices",2017,"","","","",127,"2022-07-13 09:29:15","","10.1007/s00521-016-2356-y","","",,,,,22,4.40,22,1,5,"","",""
94,"Richard Gilmore, Neil Hanley, M. O’Neill","Neural network based attack on a masked implementation of AES",2015,"","","","",128,"2022-07-13 09:29:15","","10.1109/HST.2015.7140247","","",,,,,94,13.43,31,3,7,"Masked implementations of cryptographic algorithms are often used in commercial embedded cryptographic devices to increase their resistance to side channel attacks. In this work we show how neural networks can be used to both identify the mask value, and to subsequently identify the secret key value with a single attack trace with high probability. We propose the use of a pre-processing step using principal component analysis (PCA) to significantly increase the success of the attack. We have developed a classifier that can correctly identify the mask for each trace, hence removing the security provided by that mask and reducing the attack to being equivalent to an attack against an unprotected implementation. The attack is performed on the freely available differential power analysis (DPA) contest data set to allow our work to be easily reproducible. We show that neural networks allow for a robust and efficient classification in the context of side-channel attacks.","",""
13,"L. Wandera, K. Mallick, G. Kiely, O. Roupsard, M. Peichl, V. Magliulo","Upscaling instantaneous to daily evapotranspiration using modelled daily shortwave radiation for remote sensing applications: an artificial neural network approach",2016,"","","","",129,"2022-07-13 09:29:15","","10.5194/HESS-21-197-2017","","",,,,,13,2.17,2,6,6,"Abstract. Upscaling instantaneous evapotranspiration retrieved at any specific time-of-day (ETi) to daily evapotranspiration (ETd) is a key challenge in mapping regional ET using polar orbiting sensors. Various studies have unanimously cited the shortwave incoming radiation (RS) to be the most robust reference variable explaining the ratio between ETd and ETi. This study aims to contribute in ETi upscaling for global studies using the ratio between daily and instantaneous incoming shortwave radiation (RSd ∕ RSi) as a factor for converting ETi to ETd. This paper proposes an artificial neural network (ANN) machine-learning algorithm first to predict RSd from RSi followed by using the RSd ∕ RSi ratio to convert ETi to ETd across different terrestrial ecosystems. Using RSi and RSd observations from multiple sub-networks of the FLUXNET database spread across different climates and biomes (to represent inputs that would typically be obtainable from remote sensors during the overpass time) in conjunction with some astronomical variables (e.g. solar zenith angle, day length, exoatmospheric shortwave radiation), we developed the ANN model for reproducing RSd and further used it to upscale ETi to ETd. The efficiency of the ANN is evaluated for different morning and afternoon times of day, under varying sky conditions, and also at different geographic locations. RS-based upscaled ETd produced a significant linear relation (R2 =  0.65 to 0.69), low bias (−0.31 to −0.56 MJ m−2 d−1; approx. 4 %), and good agreement (RMSE 1.55 to 1.86 MJ m−2 d−1; approx. 10 %) with the observed ETd, although a systematic overestimation of ETd was also noted under persistent cloudy sky conditions. Inclusion of soil moisture and rainfall information in ANN training reduced the systematic overestimation tendency in predominantly overcast days. An intercomparison with existing upscaling method at daily, 8-day, monthly, and yearly temporal resolution revealed a robust performance of the ANN-driven RS-based ETi upscaling method and was found to produce lowest RMSE under cloudy conditions. Sensitivity analysis revealed variable sensitivity of the method to biome selection and high ETd prediction errors in forest ecosystems are primarily associated with greater rainfall and cloudiness. The overall methodology appears to be promising and has substantial potential for upscaling ETi to ETd for field and regional-scale evapotranspiration mapping studies using polar orbiting satellites.","",""
1,"Federico Adolfi, J. Bowers, D. Poeppel","Successes and critical failures of neural networks in capturing human-like speech recognition",2022,"","","","",130,"2022-07-13 09:29:15","","10.48550/arXiv.2204.03740","","",,,,,1,1.00,0,3,1,"Natural and artiﬁcial audition can in principle evolve diﬀerent solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would im- prove artiﬁcial hearing systems and process models of the mind and brain. Speech recognition — an area ripe for such exploration — is inherently robust in humans to a number transformations at various spectrotempo- ral granularities. To what extent are these robust- ness proﬁles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus- computable, optimized observers. In a series of experiments, we (1) clarify how inﬂuential speech manipula- tions in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the speciﬁc conditions where model predictions of human performance diﬀer, and (4) demonstrate a crucial fail- ure of all artiﬁcial systems to perceptually recover where humans do, suggesting a key speciﬁcation for theory and model building. These ﬁndings encourage a tighter synergy between the cognitive science and engineering of audition.","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",131,"2022-07-13 09:29:15","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
0,"Manuel Günther, Andras Rozsa, T. Boult","On the Robustness of Deep Neural Networks",2017,"","","","",132,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,3,5,"Deep Neural Networks (DNNs) have become the quasi-standard in many machine learning tasks since they obtain state-of-the-art results and outperform more traditional machine learning models for problems in vision, image and speech processing, and many other tasks. One reason that DNNs have proven very useful is that they are one of the few algorithms that can make principled use of huge databases for training. However, despite their brilliant recognition capabilities, little is known about how DNNs achieve their accuracies, and even less is known about their robustness and their limitations. After Szegedy et al. [19] showed that deep networks have some “intriguing” properties, several researchers started actively exploring the limitations, and showed how easily the networks could be attacked or fooled – demonstrating essential limits of the robustness of DNNs. This paper analyzes these two categories of attacks: adversarial images [19, 3], which are imperceptible perturbations to an input to turn it into another class, and fooling images [9], which look like none of the ∗This research is based upon work funded in part by NSF IIS-1320956 and in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. 2014-14071600012. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.","",""
75,"Vaibhav Gandhi, G. Prasad, D. Coyle, L. Behera, T. McGinnity","Quantum Neural Network-Based EEG Filtering for a Brain–Computer Interface",2014,"","","","",133,"2022-07-13 09:29:15","","10.1109/TNNLS.2013.2274436","","",,,,,75,9.38,15,5,8,"A novel neural information processing architecture inspired by quantum mechanics and incorporating the well-known Schrodinger wave equation is proposed in this paper. The proposed architecture referred to as recurrent quantum neural network (RQNN) can characterize a nonstationary stochastic signal as time-varying wave packets. A robust unsupervised learning algorithm enables the RQNN to effectively capture the statistical behavior of the input signal and facilitates the estimation of signal embedded in noise with unknown characteristics. The results from a number of benchmark tests show that simple signals such as dc, staircase dc, and sinusoidal signals embedded within high noise can be accurately filtered and particle swarm optimization can be employed to select model parameters. The RQNN filtering procedure is applied in a two-class motor imagery-based brain-computer interface where the objective was to filter electroencephalogram (EEG) signals before feature extraction and classification to increase signal separability. A two-step inner-outer fivefold cross-validation approach is utilized to select the algorithm parameters subject-specifically for nine subjects. It is shown that the subject-specific RQNN EEG filtering significantly improves brain-computer interface performance compared to using only the raw EEG or Savitzky-Golay filtered EEG across multiple sessions.","",""
5,"P. Choudhary, S. Dubey, B. Tiwari, B. Dewangan","Efficiency optimization of induction motor drive using Artificial Neural Network",2016,"","","","",134,"2022-07-13 09:29:15","","10.1109/ICEETS.2016.7583860","","",,,,,5,0.83,1,4,6,"Induction motors are the workhorse of industry, have good efficiency at rated load, but long duration usage of IM at partial load shows poor efficiency which leads to waste in energy and revenue as well. These motors are reliable, robust, high power/mass ratio and economic, hence replaced all other motors in the industry, so even minute increment in induction motor efficiency can have a major impact on consumption of electricity and saving of revenue, globally. This paper utilizes, a combination of two key concepts of efficiency optimization-loss model control (LMC) and search control (SC) for efficient operation of induction motors used in various industrial applications, in aforesaid load condition. At first, to estimate optimal Ids values for various load conditions, an optimal Ids expression in terms of machine parameters and load parameters, based on machine loss model in d-q frame along with classical optimization technique, is utilized. Secondly, an offline trained artificial neural network (ANN) controller is used to reproduce the optimal Ids values, in run-time load condition. This eliminates run-time computations and perturbation for optimal flux, as in conventional SC method. The (ANN) optimal controller is designed for optimal Ids as output, while providing load torque and speed information as inputs. The training is performed in MATLAB and good accuracy of the training model is seen. Dynamic and steady-state performances are compared for proposed optimal (optimal Ids) operations and conventional vector operations (constant Ids), with the help of a simulation model, developed in MATLAB. Excellent dynamic response in load transients as well as superior efficiency performance (1- 18%) at steady-state, for a wide range of speed and torque in simulation is attained. Assimilated with similar earlier work, the proposed methodology offers effortless implementation in real-time industrial facilities, ripple free operations, fast response and higher energy savings.","",""
5,"Katelyn Morrison, B. Gilby, Colton Lipchak, Adam Mattioli, Adriana Kovashka","Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers",2021,"","","","",135,"2022-07-13 09:29:15","","","","",,,,,5,5.00,1,5,1,"Recently, vision transformers and MLP-based models have been developed in order to address some of the prevalent weaknesses in convolutional neural networks. Due to the novelty of transformers being used in this domain along with the selfattention mechanism, it remains unclear to what degree these architectures are robust to corruptions. Despite some works proposing that data augmentation remains essential for a model to be robust against corruptions, we propose to explore the impact that the architecture has on corruption robustness. We find that vision transformer architectures are inherently more robust to corruptions than the ResNet-50 and MLP-Mixers. We also find that vision transformers with 5 times fewer parameters than a ResNet-50 have more shape bias. Our code is available to reproduce.","",""
18,"Claudio Ciancio, G. Ambrogio, F. Gagliardi, R. Musmanno","Heuristic techniques to optimize neural network architecture in manufacturing applications",2016,"","","","",136,"2022-07-13 09:29:15","","10.1007/s00521-015-1994-9","","",,,,,18,3.00,5,4,6,"","",""
0,"M. Vaisband, Maria Schubert, F. Gassner, R. Geisberger, R. Greil, N. Zaborsky, J. Hasenauer","Validation of genetic variants from NGS data using Deep Convolutional Neural Networks",2022,"","","","",137,"2022-07-13 09:29:15","","10.1101/2022.04.12.488021","","",,,,,0,0.00,0,7,1,"Accurate somatic variant calling from next-generation sequencing data is one most important tasks in personalised cancer therapy. The sophistication of the available technologies is ever-increasing, yet, manual candidate refinement is still a necessary step in state-of-the-art processing pipelines. This limits reproducibility and introduces a bottleneck with respect to scalability. We demonstrate that the validation of genetic variants can be improved using a machine learning approach resting on a Convolutional Neural Network, trained using existing human annotation. In contrast to existing approaches, we introduce a way in which contextual data from sequencing tracks can be included into the automated assessment. A rigorous evaluation shows that the resulting model is robust and performs on par with trained researchers following published standard operating procedure.","",""
0,"Ernst Strüngmann","Successes and critical failures of neural networks in capturing human-like speech recognition",2022,"","","","",138,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,1,1,"Natural and artificial audition can in principle evolve different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would improve artificial hearing systems and process models of the mind and brain. Speech recognition — an area ripe for such exploration — is inherently robust in humans to a number transformations at various spectrotemporal granularities. To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimuluscomputable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the specific conditions where model predictions of human performance differ, and (4) demonstrate a crucial failure of all artificial systems to perceptually recover where humans do, suggesting a key specification for theory and model building. These findings encourage a tighter synergy between the cognitive science and engineering of audition.","",""
5,"Mayank K. Mittal, Marco Gallieri, A. Quaglino, Seyed Sina Mirrazavi Salehian, Jan Koutn'ik","Neural Lyapunov Model Predictive Control",2020,"","","","",139,"2022-07-13 09:29:15","","","","",,,,,5,2.50,1,5,2,"This paper presents Neural Lyapunov MPC, an algorithm to alternately train a Lyapunov neural network and a stabilising constrained Model Predictive Controller (MPC), given a neural network model of the system dynamics. This extends recent works on Lyapunov networks to be able to train solely from expert demonstrations of one-step transitions. The learned Lyapunov network is used as the value function for the MPC in order to guarantee stability and extend the stable region. Formal results are presented on the existence of a set of MPC parameters, such as discount factors, that guarantees stability with a horizon as short as one. Robustness margins are also discussed and existing performance bounds on value function MPC are extended to the case of imperfect models. The approach is tested on unstable non-linear continuous control tasks with hard constraints. Results demonstrate that, when a neural network trained on short sequences is used for predictions, a one-step horizon Neural Lyapunov MPC can successfully reproduce the expert behaviour and significantly outperform longer horizon MPCs.","",""
93,"W. Yeh","New Parameter-Free Simplified Swarm Optimization for Artificial Neural Network Training and its Application in the Prediction of Time Series",2013,"","","","",140,"2022-07-13 09:29:15","","10.1109/TNNLS.2012.2232678","","",,,,,93,10.33,93,1,9,"A new soft computing method called the parameter-free simplified swarm optimization (SSO)-based artificial neural network (ANN), or improved SSO for short, is proposed to adjust the weights in ANNs. The method is a modification of the SSO, and seeks to overcome some of the drawbacks of SSO. In the experiments, the iSSO is compared with five other famous soft computing methods, including the backpropagation algorithm, the genetic algorithm, the particle swarm optimization (PSO) algorithm, cooperative random learning PSO, and the SSO, and its performance is tested on five famous time-series benchmark data to adjust the weights of two ANN models (multilayer perceptron and single multiplicative neuron model). The experimental results demonstrate that iSSO is robust and more efficient than the other five algorithms.","",""
11,"H. Suleman, A. Maulud, Z. Man","Reconciliation of outliers in CO2-alkanolamine-H2O datasets by robust neural network winsorization",2017,"","","","",141,"2022-07-13 09:29:15","","10.1007/s00521-016-2213-z","","",,,,,11,2.20,4,3,5,"","",""
0,"Houssam El-Hariri","Reliable and robust hip dysplasia measurement with three-dimensional ultrasound and convolutional neural networks",2020,"","","","",142,"2022-07-13 09:29:15","","10.14288/1.0389533","","",,,,,0,0.00,0,1,2,"Developmental Dysplasia of the Hip is one of the most common congenital disorders. Misdiagnosis leads to financial consequences and reduced quality of life. The current standard diagnostic technique involves imaging the hip with ultrasound and extracting metrics such as the α angle. This has been shown to be unreliable due to human error in probe positioning, leading to misdiagnosis. 3D ultrasound, being more robust to errors in probe positioning, has been introduced as a more reliable alternative. In this thesis, we aim to further improve the image processing techniques of the 3D ultrasound-based system, addressing three components: segmentation, metrics extraction, and adequacy classification. Segmentation in 3D is prohibitively slow when performed manually and introduces human error. Previous work introduced automatic segmentation techniques, but our observations indicate lack of accuracy and robustness with these techniques. We propose to use deep Convolutional Neural Network (CNN)s for improving the segmentation accuracy and consequently the reproducibility and robustness of dysplasia measurement. We show that 3D-U-Net achieves higher agreement with human labels compared to the state-of-the-art. For pelvis bone surface segmentation, we report mean DSC of 85% with 3D-U-Net vs. 26% with CSPS. For femoral head segmentation, we report mean CED Error of 1.42mm with 3D-U-Net vs. 3.90mm with the Random Forest Classifier. We implement methods for extracting α3D, FHC3D, and OCR dysplasia metrics using the improved segmentation. On a clinical set of 42 hips, we report interexam, intra-sonographer intraclass correlation coefficients of 87%, 84%, and 74% for these three metrics, respectively, beating the state-of-the-art. Qualitative observations show improved robustness and reduced failure rates.","",""
6,"Xixun Lin, Chuan Zhou, Hong Yang, Jia Wu, Haibo Wang, Yanan Cao, Bin Wang","Exploratory Adversarial Attacks on Graph Neural Networks",2020,"","","","",143,"2022-07-13 09:29:15","","10.1109/ICDM50108.2020.00138","","",,,,,6,3.00,1,7,2,"Graph neural networks (GNNs) have been successfully used to analyze non-Euclidean network data. Recently, there emerge a number of works to investigate the robustness of GNNs by adding adversarial noises into the graph topology, where gradient-based attacks are widely studied due to their inherent efficiency and high effectiveness. However, the gradient-based attacks often lead to sub-optimal results due to the discrete structure of graph data. To this end, we design a novel exploratory adversarial attack (termed as EpoAtk) to boost the gradient-based perturbations on graphs. The exploratory strategy in EpoAtk includes three phases, generation, evaluation and recombination, with the goal of sidesteping the possible misinformation that the maximal gradient provides. In experiments, EpoAtk is evaluated on benchmark datasets for the task of semi-supervised node classification in different attack settings. Experimental results demonstrate that the proposed method significantly outperforms the state-of-the-art attacks with the same attack budgets11Our reproducible code is available at https://github.com/EpoAtk/EpoAtk..","",""
184,"D. Querlioz, O. Bichler, C. Gamrat","Simulation of a memristor-based spiking neural network immune to device variations",2011,"","","","",144,"2022-07-13 09:29:15","","10.1109/IJCNN.2011.6033439","","",,,,,184,16.73,61,3,11,"We propose a design methodology to exploit adaptive nanodevices (memristors), virtually immune to their variability. Memristors are used as synapses in a spiking neural network performing unsupervised learning. The memristors learn through an adaptation of spike timing dependent plasticity. Neurons' threshold is adjusted following a homeostasis-type rule. System level simulations on a textbook case show that performance can compare with traditional supervised networks of similar complexity. They also show the system can retain functionality with extreme variations of various memristors' parameters, thanks to the robustness of the scheme, its unsupervised nature, and the power of homeostasis. Additionally the network can adjust to stimuli presented with different coding schemes.","",""
6,"Rida El-Allami, Alberto Marchisio, M. Shafique, Ihsen Alouani","Securing Deep Spiking Neural Networks against Adversarial Attacks through Inherent Structural Parameters",2020,"","","","",145,"2022-07-13 09:29:15","","10.23919/DATE51398.2021.9473981","","",,,,,6,3.00,2,4,2,"Deep Learning (DL) algorithms have gained popularity owing to their practical problem-solving capacity. However, they suffer from a serious integrity threat, i.e., their vulnerability to adversarial attacks. In the quest for DL trustworthiness, recent works claimed the inherent robustness of Spiking Neural Networks (SNNs) to these attacks, without considering the variability in their structural spiking parameters. This paper explores the security enhancement of SNNs through internal structural parameters. Specifically, we investigate the SNNs robustness to adversarial attacks with different values of the neuron's firing voltage thresholds and time window boundaries. We thoroughly study SNNs security under different adversarial attacks in the strong white-box setting, with different noise budgets and under variable spiking parameters. Our results show a significant impact of the structural parameters on the SNNs' security, and promising sweet spots can be reached to design trustworthy SNNs with 85% higher robustness than a traditional non-spiking DL system. To the best of our knowledge, this is the first work that investigates the impact of structural parameters on SNNs robustness to adversarial attacks. The proposed contributions and the experimental framework is available online 11https://github.com/rda-ela/SNN-Adversarial-Attacks to the community for reproducible research.","",""
25,"Hai Wang, Zhengming Xu, Do Manh Tuan, Jinchuan Zheng, Z. Cao, Linsen Xie","Neural-network-based robust control for steer-by-wire systems with uncertain dynamics",2015,"","","","",146,"2022-07-13 09:29:15","","10.1007/s00521-014-1819-2","","",,,,,25,3.57,4,6,7,"","",""
122,"Huaguang Zhang, Jinhai Liu, Dazhong Ma, Zhanshan Wang","Data-Core-Based Fuzzy Min–Max Neural Network for Pattern Classification",2011,"","","","",147,"2022-07-13 09:29:15","","10.1109/TNN.2011.2175748","","",,,,,122,11.09,31,4,11,"A fuzzy min-max neural network based on data core (DCFMN) is proposed for pattern classification. A new membership function for classifying the neuron of DCFMN is defined in which the noise, the geometric center of the hyperbox, and the data core are considered. Instead of using the contraction process of the FMNN described by Simpson, a kind of overlapped neuron with new membership function based on the data core is proposed and added to neural network to represent the overlapping area of hyperboxes belonging to different classes. Furthermore, some algorithms of online learning and classification are presented according to the structure of DCFMN. DCFMN has strong robustness and high accuracy in classification taking onto account the effect of data core and noise. The performance of DCFMN is checked by some benchmark datasets and compared with some traditional fuzzy neural networks, such as the fuzzy min-max neural network (FMNN), the general FMNN, and the FMNN with compensatory neuron. Finally the pattern classification of a pipeline is evaluated using DCFMN and other classifiers. All the results indicate that the performance of DCFMN is excellent.","",""
11,"Timothée Lesort, Mathieu Seurin, Xinrui Li, Natalia Díaz Rodríguez, David Filliat","Deep unsupervised state representation learning with robotic priors: a robustness analysis",2019,"","","","",148,"2022-07-13 09:29:15","","10.1109/IJCNN.2019.8852042","","",,,,,11,3.67,2,5,3,"Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation metric of the learned representation that uses nearest neighbors in the state space and allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset.","",""
34,"A. Odawara, M. Gotoh, I. Suzuki","Control of neural network patterning using collagen gel photothermal etching.",2013,"","","","",149,"2022-07-13 09:29:15","","10.1039/c3lc00036b","","",,,,,34,3.78,11,3,9,"Two-dimensional (2D) micropatterning techniques have been developed to guide dissociated neurons into predefined distributions on solid substrates, such as glass and plastic. Micropatterning methods using three-dimensional (3D) substrates or scaffolds that reproduce aspects of the in vivo microenvironment could facilitate the engineering of functional tissues for transplantation or more robust experimental models. We developed a 3D collagen gel photothermal etching method using an infrared laser that precisely controls the area of cell adhesion and neurite projection by etching a small targeted section of the collage gel. It was then possible to guide neural network formation under microscopic observation. After conventional cell seeding, we succeeded in creating isolated 3D networks, while controlling (1) the number of each neural subtype (neurons, glia, and fluorescently-labeled neurons) and (2) the direction of neurite elongation. Neurons seeded on a 10-μm-thick collagen gel survived longer and projected greater numbers of neurites than neurons growing on 2D culture substrates. Intracellular Ca(2+) imaging revealed both synchronous and discordant oscillations in different neuronal populations that suggested the pattern and strength of synaptic connectivity. This photothermal etching technique allows for the creation of designed 3D neural networks during cultivation for use in studies of synaptic transmission, neuron-glial signaling, pathogenesis, and drug responses.","",""
5,"Guilherme Pedrollo, Andréa Aparecida Konzen, W. O. D. Morais, E. P. Freitas","Using Smart Virtual-Sensor Nodes to Improve the Robustness of Indoor Localization Systems",2021,"","","","",150,"2022-07-13 09:29:15","","10.3390/s21113912","","",,,,,5,5.00,1,4,1,"Young, older, frail, and disabled individuals can require some form of monitoring or assistance, mainly when critical situations occur, such as falling and wandering. Healthcare facilities are increasingly interested in e-health systems that can detect and respond to emergencies on time. Indoor localization is an essential function in such e-health systems, and it typically relies on wireless sensor networks (WSN) composed of fixed and mobile nodes. Nodes in the network can become permanently or momentarily unavailable due to, for example, power failures, being out of range, and wrong placement. Consequently, unavailable sensors not providing data can compromise the system’s overall function. One approach to overcome the problem is to employ virtual sensors as replacements for unavailable sensors and generate synthetic but still realistic data. This paper investigated the viability of modelling and artificially reproducing the path of a monitored target tracked by a WSN with unavailable sensors. Particularly, the case with just a single sensor was explored. Based on the coordinates of the last measured positions by the unavailable node, a neural network was trained with 4 min of not very linear data to reproduce the behavior of a sensor that become unavailable for about 2 min. Such an approach provided reasonably successful results, especially for areas close to the room’s entrances and exits, which are critical for the security monitoring of patients in healthcare facilities.","",""
4,"Seungdae Baek, Min Song, Jaeson Jang, Gwangsun Kim, Se-Bum Paik","Face detection in untrained deep neural networks",2021,"","","","",151,"2022-07-13 09:29:15","","10.1038/s41467-021-27606-9","","",,,,,4,4.00,1,5,1,"","",""
4,"Jiaheng Li, Junchao Chen, Biao Li","Gradient-optimized physics-informed neural networks (GOPINNs): a deep learning method for solving the complex modified KdV equation",2021,"","","","",152,"2022-07-13 09:29:15","","10.1007/s11071-021-06996-x","","",,,,,4,4.00,1,3,1,"","",""
130,"David Sussillo, P. Nuyujukian, Joline M. Fan, J. Kao, S. Stavisky, S. Ryu, K. Shenoy","A recurrent neural network for closed-loop intracortical brain-machine interface decoders.",2012,"","","","",153,"2022-07-13 09:29:15","","10.1088/1741-2560/9/2/026027","","",,,,,130,13.00,19,7,10,"Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships in time series data with complex temporal dependences. In this paper, we explore the ability of a simplified type of RNN, one with limited modifications to the internal weights called an echostate network (ESN), to effectively and continuously decode monkey reaches during a standard center-out reach task using a cortical brain-machine interface (BMI) in a closed loop. We demonstrate that the RNN, an ESN implementation termed a FORCE decoder (from first order reduced and controlled error learning), learns the task quickly and significantly outperforms the current state-of-the-art method, the velocity Kalman filter (VKF), using the measure of target acquire time. We also demonstrate that the FORCE decoder generalizes to a more difficult task by successfully operating the BMI in a randomized point-to-point task. The FORCE decoder is also robust as measured by the success rate over extended sessions. Finally, we show that decoded cursor dynamics are more like naturalistic hand movements than those of the VKF. Taken together, these results suggest that RNNs in general, and the FORCE decoder in particular, are powerful tools for BMI decoder applications.","",""
45,"Yimeng Qi, Long Jin, Yaonan Wang, Lin Xiao, Jiliang Zhang","Complex-Valued Discrete-Time Neural Dynamics for Perturbed Time-Dependent Complex Quadratic Programming With Applications",2019,"","","","",154,"2022-07-13 09:29:15","","10.1109/TNNLS.2019.2944992","","",,,,,45,15.00,9,5,3,"It has been reported that some specially designed recurrent neural networks and their related neural dynamics are efficient for solving quadratic programming (QP) problems in the real domain. A complex-valued QP problem is generated if its variable vector is composed of the magnitude and phase information, which is often depicted in a time-dependent form. Given the important role that complex-valued problems play in cybernetics and engineering, computational models with high accuracy and strong robustness are urgently needed, especially for time-dependent problems. However, the research on the online solution of time-dependent complex-valued problems has been much less investigated compared to time-dependent real-valued problems. In this article, to solve the online time-dependent complex-valued QP problems subject to linear constraints, two new discrete-time neural dynamics models, which can achieve global convergence performance in the presence of perturbations with the provided theoretical analyses, are proposed and investigated. In addition, the second proposed model is developed to eliminate the operation of explicit matrix inversion by introducing the quasi-Newton Broyden–Fletcher–Goldfarb–Shanno (BFGS) method. Moreover, computer simulation results and applications in robotics and filters are provided to illustrate the feasibility and superiority of the proposed models in comparison with the existing solutions.","",""
74,"A. Azar","Fast neural network learning algorithms for medical applications",2013,"","","","",155,"2022-07-13 09:29:15","","10.1007/s00521-012-1026-y","","",,,,,74,8.22,74,1,9,"","",""
34,"H. Dinh, R. Kamalapurkar, S. Bhasin, W. Dixon","Dynamic neural network-based robust observers for uncertain nonlinear systems",2014,"","","","",156,"2022-07-13 09:29:15","","10.1016/j.neunet.2014.07.009","","",,,,,34,4.25,9,4,8,"","",""
18,"M. Witczak, M. Mrugalski, J. Korbicz","Towards Robust Neural-Network-Based Sensor and Actuator Fault Diagnosis: Application to a Tunnel Furnace",2015,"","","","",157,"2022-07-13 09:29:15","","10.1007/s11063-014-9387-0","","",,,,,18,2.57,6,3,7,"","",""
39,"H. Singh, N. Sukavanam","Stability analysis of robust adaptive hybrid position/force controller for robot manipulators using neural network with uncertainties",2013,"","","","",158,"2022-07-13 09:29:15","","10.1007/s00521-012-0966-6","","",,,,,39,4.33,20,2,9,"","",""
9,"Yiming Li, Baoyuan Wu, Yan Feng, Yanbo Fan, Yong Jiang, Zhifeng Li, Shutao Xia","Toward Adversarial Robustness via Semi-supervised Robust Training",2020,"","","","",159,"2022-07-13 09:29:15","","","","",,,,,9,4.50,1,7,2,"Adversarial examples have been shown to be the severe threat to deep neural networks (DNNs). One of the most effective adversarial defense methods is adversarial training (AT) through minimizing the adversarial risk $R_{adv}$, which encourages both the benign example $x$ and its adversarially perturbed neighborhoods within the $\ell_{p}$-ball to be predicted as the ground-truth label. In this work, we propose a novel defense method, the robust training (RT), by jointly minimizing two separated risks ($R_{stand}$ and $R_{rob}$), which is with respect to the benign example and its neighborhoods respectively. The motivation is to explicitly and jointly enhance the accuracy and the adversarial robustness. We prove that $R_{adv}$ is upper-bounded by $R_{stand} + R_{rob}$, which implies that RT has similar effect as AT. Intuitively, minimizing the standard risk enforces the benign example to be correctly predicted, and the robust risk minimization encourages the predictions of the neighbor examples to be consistent with the prediction of the benign example. Besides, since $R_{rob}$ is independent of the ground-truth label, RT is naturally extended to the semi-supervised mode ($i.e.$, SRT), to further enhance the adversarial robustness. Moreover, we extend the $\ell_{p}$-bounded neighborhood to a general case, which covers different types of perturbations, such as the pixel-wise ($i.e.$, $x + \delta$) or the spatial perturbation ($i.e.$, $ AX + b$). Extensive experiments on benchmark datasets not only verify the superiority of the proposed SRT method to state-of-the-art methods for defensing pixel-wise or spatial perturbations separately, but also demonstrate its robustness to both perturbations simultaneously. The code for reproducing main results is available at \url{this https URL}.","",""
1,"Anjun Ma, Xiaoying Wang, Cankun Wang, Jingxiang Li, Tong Xiao, Juexin Wang, Yuzhou Chang, Yang Li, Yuntao Liu, Shaopeng Gu, Duolin Wang, Yuexu Jiang, Jinpu Li, Lingtao Su, Zihai Li, Bingqiang Liu, Dong Xu, Q. Ma","Biological network inference from single-cell multi-omics data using heterogeneous graph transformer",2021,"","","","",160,"2022-07-13 09:29:15","","10.1101/2021.10.31.466658","","",,,,,1,1.00,0,18,1,"We present DeepMAPS, a deep learning platform for cell-type-specific biological gene network inference from single-cell multi-omics (scMulti-omics). DeepMAPS includes both cells and genes in a heterogeneous graph to infer cell-cell, cell-gene, and gene-gene relations simultaneously. The graph attention neural network considers a cell and a gene with both local and global information, making DeepMAPS more robust to data noises. We benchmarked DeepMAPS on 18 datasets for cell clustering and network inference, and the results showed that our method outperforms various existing tools. We further applied DeepMAPS on a case study of lung tumor leukocyte CITE-seq data and observed superior performance in cell clustering, and predicted biologically meaningful cell-cell communication pathways based on the inferred gene networks. To improve the feasibility and ensure the reproducibility of analyzing scMulti-omics data, we deployed a webserver with multi-functions and various visualizations. Overall, we valued DeepMAPS as a novel platform of the state-of-the-art deep learning model in the single-cell study and can promote the use of scMulti-omics data in the community.","",""
0,"Keaton Rowley","On Developing Efficient and Robust Neural Networks for Healthcare using Condensa Model Compression System",2021,"","","","",161,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,1,1,"This thesis describes a study of how compressing neural networks used to identify malaria cells and respiratory diseases affects network accuracy, and system performance metrics. Its focus is on a state-of-the-art framework for neural network (NN) compression called Condensa to compress network size and improve network performance according to different compression schemes. It details the impact malaria and lung disease have on a worldwide level each year. It then describes previous research in automating medical image classification. It also gives a background on what research has been applied towards network compression. The study also describes work in developing a CNN for the Malarial and Chest-X-ray datasets. It details the results of compressing the CNN using Condensa’s Filter, StructPrune, Prune, and Quantization schemes. This thesis provides a complete software implementation to help reproduce our results and facilitate tool adoption. It also indicates a plan for future research in applying Condensa towards the problem of developing an efficient system of disease identification for different medical dataset problems.","",""
0,"F. Centracchio, L. Burghignoli, Giorgio Palma, Ilaria Cioffi, U. Iemma","Noise shielding surrogate models using dynamic artificial neural networks",2021,"","","","",162,"2022-07-13 09:29:15","","10.3397/in-2021-3008","","",,,,,0,0.00,0,5,1,"The optimal design methodologies in aeronautics are known to be constrained by the computational burden required by direct simulations. Due to this reason, the development of efficient metamodelling techniques represents nowadays an imperative need for the designers. In fact, surrogate  models has been demonstrated to significantly reduce the number of high-fidelity evaluations, thus alleviating the computing effort. Over the last years, the aeronautical designers community has switched from a design approach predominantly based on direct simulations to an extensive use of  metamodels. Recently, to further improve the efficiency, several dynamic approaches based on parameters self-tuning have been developed to support the metamodel construction. This work deals with the use of surrogate models based on Artificial Neural Network for the noise shielding of unconventional  aircraft configurations. Here, the insertion loss field of the a Blended Wing Body is reproduced by means of advanced machine learning techniques. The relevant framework is the calculation of the noise emitted by innovative aircraft configurations by means of suitable corrections of existing  well-assessed noise prediction tools. The self-tuning algorithm has demonstrated to be accurate and efficient, and the observed performance discloses the possibility to implement numerical strategies for the reliable and robust unconventional aircraft optimal design","",""
0,"N. D. Klimkin","Emulating ultrafast dissipative quantum dynamics with deep neural networks",2021,"","","","",163,"2022-07-13 09:29:15","","","","",,,,,0,0.00,0,1,1,"The simulation of driven dissipative quantum dynamics is often prohibitively computationintensive, especially when it is calculated for various shapes of the driving field. We engineer a new feature space for representing the field and demonstrate that a deep neural network can be trained to emulate these dynamics by mapping this representation directly to the target observables. We demonstrate that with this approach, the system response can be retrieved many orders of magnitude faster. We verify the validity of our approach using the example of finite transverse Ising model irradiated with few-cycle magnetic pulses interacting with a Markovian environment. We show that our approach is sufficiently generalizable and robust to reproduce responses to pulses outside the training set.","",""
96,"An‐Min Zou, K. Kumar","Neural Network-Based Distributed Attitude Coordination Control for Spacecraft Formation Flying With Input Saturation",2012,"","","","",164,"2022-07-13 09:29:15","","10.1109/TNNLS.2012.2196710","","",,,,,96,9.60,48,2,10,"This brief considers the attitude coordination control problem for spacecraft formation flying when only a subset of the group members has access to the common reference attitude. A quaternion-based distributed attitude coordination control scheme is proposed with consideration of the input saturation and with the aid of the sliding-mode observer, separation principle theorem, Chebyshev neural networks, smooth projection algorithm, and robust control technique. Using graph theory and a Lyapunov-based approach, it is shown that the distributed controller can guarantee the attitude of all spacecraft to converge to a common time-varying reference attitude when the reference attitude is available only to a portion of the group of spacecraft. Numerical simulations are presented to demonstrate the performance of the proposed distributed controller.","",""
0,"Tianle Zhang, Wenjie Ruan, J. Fieldsend","PRoA: A Probabilistic Robustness Assessment against Functional Perturbations",2022,"","","","",165,"2022-07-13 09:29:15","","10.48550/arXiv.2207.02036","","",,,,,0,0.00,0,3,1,". In safety-critical deep learning applications robustness mea-surement is a vital pre-deployment phase. However, existing robustness veriﬁcation methods are not suﬃciently practical for deploying machine learning systems in the real world. On the one hand, these methods at-tempt to claim that no perturbations can “fool” deep neural networks (DNNs), which may be too stringent in practice. On the other hand, existing works rigorously consider L p bounded additive perturbations on the pixel space, although perturbations, such as colour shifting and geometric transformations, are more practically and frequently occurring in the real world. Thus, from the practical standpoint, we present a novel and general probabilistic robustness assessment method (PRoA) based on the adaptive concentration, and it can measure the robustness of deep learning models against functional perturbations. PRoA can provide statistical guarantees on the probabilistic robustness of a model, i.e. , the probability of failure encountered by the trained model after deployment. Our experiments demonstrate the eﬀectiveness and ﬂexibility of PRoA in terms of evaluating the probabilistic robustness against a broad range of functional perturbations, and PRoA can scale well to various large-scale deep neural networks compared to existing state-of-the-art base-lines. For the purpose of reproducibility, we release our tool on GitHub: https://github.com/TrustAI/PRoA .","",""
118,"Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, A. Madry","Adversarial Robustness as a Prior for Learned Representations",2019,"","","","",166,"2022-07-13 09:29:15","","","","",,,,,118,39.33,20,6,3,"An important goal in deep learning is to learn versatile, high-level feature representations of input data. However, standard networks' representations seem to possess shortcomings that, as we illustrate, prevent them from fully realizing this goal. In this work, we show that robust optimization can be re-cast as a tool for enforcing priors on the features learned by deep neural networks. It turns out that representations learned by robust models address the aforementioned shortcomings and make significant progress towards learning a high-level encoding of inputs. In particular, these representations are approximately invertible, while allowing for direct visualization and manipulation of salient input features. More broadly, our results indicate adversarial robustness as a promising avenue for improving learned representations. Our code and models for reproducing these results is available at this https URL .","",""
31,"M. Senapati, P. Dash","Local linear wavelet neural network based breast tumor classification using firefly algorithm",2013,"","","","",167,"2022-07-13 09:29:15","","10.1007/s00521-012-0927-0","","",,,,,31,3.44,16,2,9,"","",""
47,"W. Yao, Xiaoqian Chen, Yong Zhao, M. V. Tooren","Concurrent Subspace Width Optimization Method for RBF Neural Network Modeling",2012,"","","","",168,"2022-07-13 09:29:15","","10.1109/TNNLS.2011.2178560","","",,,,,47,4.70,12,4,10,"Radial basis function neural networks (RBFNNs) are widely used in nonlinear function approximation. One of the challenges in RBFNN modeling is determining how to effectively optimize width parameters to improve approximation accuracy. To solve this problem, a width optimization method, concurrent subspace width optimization (CSWO), is proposed based on a decomposition and coordination strategy. This method decomposes the large-scale width optimization problem into several subspace optimization (SSO) problems, each of which has a single optimization variable and smaller training and validation data sets so as to greatly simplify optimization complexity. These SSOs can be solved concurrently, thus computational time can be effectively reduced. With top-level system coordination, the optimization of SSOs can converge to a consistent optimum, which is equivalent to the optimum of the original width optimization problem. The proposed method is tested with four mathematical examples and one practical engineering approximation problem. The results demonstrate the efficiency and robustness of CSWO in optimizing width parameters over the traditional width optimization methods.","",""
24,"Ç. Aladag, E. Egrioglu, U. Yolcu","Robust multilayer neural network based on median neuron model",2014,"","","","",169,"2022-07-13 09:29:15","","10.1007/s00521-012-1315-5","","",,,,,24,3.00,8,3,8,"","",""
2,"Edmundo Lopez-Sola, R. Sanchez-Todo, Èlia Lleal, Elif Köksal-Ersöz, M. Yochum, Julia Makhalova, Borja Mercadal, R. Salvador, D. Lozano-Soldevilla, J. Modolo, F. Bartolomei, F. Wendling, P. Benquet, G. Ruffini","A personalizable autonomous neural mass model of epileptic seizures",2021,"","","","",170,"2022-07-13 09:29:15","","10.1101/2021.12.24.474090","","",,,,,2,2.00,0,14,1,"Work in the last two decades has shown that neural mass models (NMM) can realistically reproduce and explain epileptic seizure transitions as recorded by electrophysiological methods (EEG, SEEG). In previous work, advances were achieved by increasing excitation and heuristically varying network inhibitory coupling parameters in the models. Based on these early studies, we provide a laminar NMM capable of realistically reproducing the electrical activity recorded by SEEG in the epileptogenic zone during interictal to ictal states. With the exception of the external noise input into the pyramidal cell population, the model dynamics are autonomous. By setting the system at a point close to bifurcation, seizure-like transitions are generated, including pre-ictal spikes, low voltage fast activity, and ictal rhythmic activity. A novel element in the model is a physiologically motivated algorithm for chloride dynamics: the gain of GABAergic post-synaptic potentials is modulated by the pathological accumulation of chloride in pyramidal cells due to high inhibitory input and/or dysfunctional chloride transport. In addition, in order to simulate SEEG signals for comparison with real seizure recordings, the NMM is embedded first in a layered model of the neocortex and then in a realistic physical model. We compare modelling results with data from four epilepsy patient cases. By including key pathophysiological mechanisms, the proposed framework captures succinctly the electrophysiological phenomenology observed in ictal states, paving the way for robust personalization methods based on NMMs.","",""
28,"Song Zhu, Yi Shen","Robustness analysis for connection weight matrices of global exponential stability of stochastic recurrent neural networks",2013,"","","","",171,"2022-07-13 09:29:15","","10.1016/j.neunet.2012.10.004","","",,,,,28,3.11,14,2,9,"","",""
70,"Ziang Yan, Yiwen Guo, Changshui Zhang","Deep Defense: Training DNNs with Improved Adversarial Robustness",2018,"","","","",172,"2022-07-13 09:29:15","","","","",,,,,70,17.50,23,3,4,"Despite the efficacy on a variety of computer vision tasks, deep neural networks (DNNs) are vulnerable to adversarial attacks, limiting their applications in security-critical systems. Recent works have shown the possibility of generating imperceptibly perturbed image inputs (a.k.a., adversarial examples) to fool well-trained DNN classifiers into making arbitrary predictions. To address this problem, we propose a training recipe named ""deep defense"". Our core idea is to integrate an adversarial perturbation-based regularizer into the classification objective, such that the obtained models learn to resist potential attacks, directly and precisely. The whole optimization problem is solved just like training a recursive network. Experimental results demonstrate that our method outperforms training with adversarial/Parseval regularizations by large margins on various datasets (including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code and models for reproducing our results are available at this https URL","",""
37,"Devon K. Barrow, S. Crone, N. Kourentzes","An evaluation of neural network ensembles and model selection for time series prediction",2010,"","","","",173,"2022-07-13 09:29:15","","10.1109/IJCNN.2010.5596686","","",,,,,37,3.08,12,3,12,"Ensemble methods represent an approach to combine a set of models, each capable of solving a given task, but which together produce a composite global model whose accuracy and robustness exceeds that of the individual models. Ensembles of neural networks have traditionally been applied to machine learning and pattern recognition but more recently have been applied to forecasting of time series data. Several methods have been developed to produce neural network ensembles ranging from taking a simple average of individual model outputs to more complex methods such as bagging and boosting. Which ensemble method is best; what factors affect ensemble performance, under what data conditions are ensembles most useful and when is it beneficial to use ensembles over model selection are a few questions which remain unanswered. In this paper we present some initial findings using neural network ensembles based on the mean and median applied to forecast synthetic time series data. We vary factors such as the number of models included in the ensemble and how the models are selected, whether randomly or based on performance. We compare the performance of different ensembles to model selection and present the results.","",""
81,"Yang Young Lu, Yingying Fan, Jinchi Lv, William Stafford Noble","DeepPINK: reproducible feature selection in deep neural networks",2018,"","","","",174,"2022-07-13 09:29:15","","","","",,,,,81,20.25,20,4,4,"Deep learning has become increasingly popular in both supervised and unsupervised machine learning thanks to its outstanding empirical performance. However, because of their intrinsic complexity, most deep learning methods are largely treated as black box tools with little interpretability. Even though recent attempts have been made to facilitate the interpretability of deep neural networks (DNNs), existing methods are susceptible to noise and lack of robustness. Therefore, scientists are justifiably cautious about the reproducibility of the discoveries, which is often related to the interpretability of the underlying statistical models. In this paper, we describe a method to increase the interpretability and reproducibility of DNNs by incorporating the idea of feature selection with controlled error rate. By designing a new DNN architecture and integrating it with the recently proposed knockoffs framework, we perform feature selection with a controlled error rate, while maintaining high power. This new method, DeepPINK (Deep feature selection using Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data sets to demonstrate its empirical utility.","",""
10,"Justin Cosentino, Federico Zaiter, Dan Pei, Jun Zhu","The Search for Sparse, Robust Neural Networks",2019,"","","","",175,"2022-07-13 09:29:15","","","","",,,,,10,3.33,3,4,3,"Recent work on deep neural network pruning has shown there exist sparse subnetworks that achieve equal or improved accuracy, training time, and loss using fewer network parameters when compared to their dense counterparts. Orthogonal to pruning literature, deep neural networks are known to be susceptible to adversarial examples, which may pose risks in security- or safety-critical applications. Intuition suggests that there is an inherent trade-off between sparsity and robustness such that these characteristics could not co-exist. We perform an extensive empirical evaluation and analysis testing the Lottery Ticket Hypothesis with adversarial training and show this approach enables us to find sparse, robust neural networks. Code for reproducing experiments is available here: this https URL.","",""
8,"S. Pontes-Filho, M. Liwicki","Bidirectional Learning for Robust Neural Networks",2018,"","","","",176,"2022-07-13 09:29:15","","10.1109/IJCNN.2019.8852120","","",,,,,8,2.00,4,2,4,"A multilayer perceptron can behave as a generative classifier by applying bidirectional learning (BL). It consists of training an undirected neural network to map input to output and vice-versa; therefore it can produce a classifier in one direction, and a generator in the opposite direction for the same data. The learning process of BL tries to reproduce the neuroplasticity stated in Hebbian theory using only backward propagation of errors. In this paper, two learning techniques are independently introduced which use BL for improving robustness to white noise static and adversarial examples. The first method is bidirectional propagation of errors, which the error propagation occurs in backward and forward directions. Motivated by the fact that its generative model receives as input a constant vector per class, we introduce as a second method the novel hybrid adversarial networks (HAN). Its generative model receives a random vector as input and its training is based on generative adversarial networks (GAN). To assess the performance of BL, we perform experiments using several architectures with fully and convolutional layers, with and without bias. Experimental results show that both methods improve robustness to white noise static and adversarial examples, and even increase accuracy, but have different behavior depending on the architecture and task, being more beneficial to use the one or the other. Nevertheless, HAN using a convolutional architecture with batch normalization presents outstanding robustness, reaching state-of-the-art accuracy on adversarial examples of hand-written digits.","",""
1,"D. Müller, Iñaki Soto-Rey, F. Kramer","An Analysis on Ensemble Learning Optimized Medical Image Classification With Deep Convolutional Neural Networks",2022,"","","","",177,"2022-07-13 09:29:15","","10.1109/access.2022.3182399","","",,,,,1,1.00,0,3,1,"Novel and high-performance medical image classification pipelines are heavily utilizing ensemble learning strategies. The idea of ensemble learning is to assemble diverse models or multiple predictions and, thus, boost prediction performance. However, it is still an open question to what extent as well as which ensemble learning strategies are beneficial in deep learning based medical image classification pipelines. In this work, we proposed a reproducible medical image classification pipeline for analyzing the performance impact of the following ensemble learning techniques: Augmenting, Stacking, and Bagging. The pipeline consists of state-of-the-art preprocessing and image augmentation methods as well as 9 deep convolution neural network architectures. It was applied on four popular medical imaging datasets with varying complexity. Furthermore, 12 pooling functions for combining multiple predictions were analyzed, ranging from simple statistical functions like unweighted averaging up to more complex learning-based functions like support vector machines. Our results revealed that Stacking achieved the largest performance gain of up to 13% F1-score increase. Augmenting showed consistent improvement capabilities by up to 4% and is also applicable to single model based pipelines. Cross-validation based Bagging demonstrated significant performance gain close to Stacking, which resulted in an F1-score increase up to +11%. Furthermore, we demonstrated that simple statistical pooling functions are equal or often even better than more complex pooling functions. We concluded that the integration of ensemble learning techniques is a powerful method for any medical image classification pipeline to improve robustness and boost performance.","",""
1,"Dandan Ding, Xiang Gao, Chenran Tang, Zhan Ma","Neural Reference Synthesis for Inter Frame Coding",2021,"","","","",178,"2022-07-13 09:29:15","","10.1109/TIP.2021.3134465","","",,,,,1,1.00,0,4,1,"This work proposes the neural reference synthesis (NRS) to generate high-fidelity reference block for motion estimation and motion compensation (MEMC) in inter frame coding. The NRS is comprised of two submodules: one for reconstruction enhancement and the other for reference generation. Although numerous methods have been developed in the past for these two submodules using either handcrafted rules or deep convolutional neural network (CNN) models, they basically deal with them separately, resulting in limited coding gains. By contrast, the NRS proposes to optimize them collaboratively. It first develops two CNN-based models, namely EnhNet and GenNet. The EnhNet only uses spatial correlations within the current frame for reconstruction enhancement and the GenNet is then augmented by further aggregating temporal correlations across multiple frames for reference synthesis. However, a direct concatenation of EnhNet and GenNet without considering the complex temporal reference dependency across inter frames would implicitly induce iterative CNN processing and cause the data overfitting problem, leading to visually-disturbing artifacts and oversmoothed pixels. To tackle this problem, the NRS applies a new training strategy to coordinate the EnhNet and GenNet for more robust and generalizable models, and also devises a lightweight multi-level R-D (rate-distortion) selection policy for the encoder to adaptively choose reference blocks generated from the proposed NRS model or conventional coding process. Our NRS not only offers state-of-the-art coding gains, e.g., >10% BD-Rate (Bjøntegaard Delta Rate) reduction against the High Efficiency Video Coding (HEVC) anchor for a variety of common test video sequences encoded at a wide bit range in both low-delay and random access settings, but also greatly reduces the complexity relative to existing learning-based methods by utilizing more lightweight DNNs. All models are made publicly accessible at https://github.com/IVC-Projects/NRS for reproducible research.","",""
66,"Dechao Chen, Yunong Zhang","Robust Zeroing Neural-Dynamics and Its Time-Varying Disturbances Suppression Model Applied to Mobile Robot Manipulators",2018,"","","","",179,"2022-07-13 09:29:15","","10.1109/TNNLS.2017.2764529","","",,,,,66,16.50,33,2,4,"This paper proposes a novel robust zeroing neural-dynamics (RZND) approach as well as its associated model for solving the inverse kinematics problem of mobile robot manipulators. Unlike existing works based on the assumption that neural network models are free of external disturbances, four common forms of time-varying disturbances suppressed by the proposed RZND model are investigated in this paper. In addition, theoretical analyses on the antidisturbance performance are presented in detail to prove the effectiveness and robustness of the proposed RZND model with time-varying disturbances suppressed for solving the inverse kinematics problem of mobile robot manipulators. That is, the RZND model converges toward the exact solution of the inverse kinematics problem of mobile robot manipulators with bounded or zero-oriented steady-state position error. Moreover, simulation studies and comprehensive comparisons with existing neural network models, e.g., the conventional Zhang neural network model and the gradient-based recurrent neural network model, together with extensive tests with four common forms of time-varying disturbances substantiate the efficacy, robustness, and superiority of the proposed RZND approach as well as its time-varying disturbances suppression model for solving the inverse kinematics problem of mobile robot manipulators.","",""
67,"Wei He, Zichen Yan, Yongkun Sun, Y. Ou, Changyin Sun","Neural-Learning-Based Control for a Constrained Robotic Manipulator With Flexible Joints",2018,"","","","",180,"2022-07-13 09:29:15","","10.1109/TNNLS.2018.2803167","","",,,,,67,16.75,13,5,4,"Nowadays, the control technology of the robotic manipulator with flexible joints (RMFJ) is not mature enough. The flexible-joint manipulator dynamic system possesses many uncertainties, which brings a great challenge to the controller design. This paper is motivated by this problem. In order to deal with this and enhance the system robustness, the full-state feedback neural network (NN) control is proposed. Moreover, output constraints of the RMFJ are achieved, which improve the security of the robot. Through the Lyapunov stability analysis, we identify that the proposed controller can guarantee not only the stability of flexible-joint manipulator system but also the boundedness of system state variables by choosing appropriate control gains. Then, we make some necessary simulation experiments to verify the rationality of our controllers. Finally, a series of control experiments are conducted on the Baxter. By comparing with the proportional–derivative control and the NN control with the rigid manipulator model, the feasibility and the effectiveness of NN control based on flexible-joint manipulator model are verified.","",""
188,"Shuai Li, Yunong Zhang, Long Jin","Kinematic Control of Redundant Manipulators Using Neural Networks",2017,"","","","",181,"2022-07-13 09:29:15","","10.1109/TNNLS.2016.2574363","","",,,,,188,37.60,63,3,5,"Redundancy resolution is a critical problem in the control of robotic manipulators. Recurrent neural networks (RNNs), as inherently parallel processing models for time-sequence processing, are potentially applicable for the motion control of manipulators. However, the development of neural models for high-accuracy and real-time control is a challenging problem. This paper identifies two limitations of the existing RNN solutions for manipulator control, i.e., position error accumulation and the convex restriction on the projection set, and overcomes them by proposing two modified neural network models. Our method allows nonconvex sets for projection operations, and control error does not accumulate over time in the presence of noise. Unlike most works in which RNNs are used to process time sequences, the proposed approach is model-based and training-free, which makes it possible to achieve fast tracking of reference signals with superior robustness and accuracy. Theoretical analysis reveals the global stability of a system under the control of the proposed neural networks. Simulation results confirm the effectiveness of the proposed control method in both the position regulation and tracking control of redundant PUMA 560 manipulators.","",""
0,"Connor Bybee, Alexander Belsten, F. Sommer","Cross-Frequency Coupling Increases Memory Capacity in Oscillatory Neural Networks",2022,"","","","",182,"2022-07-13 09:29:15","","10.48550/arXiv.2204.07163","","",,,,,0,0.00,0,3,1,": An open problem in neuroscience is to explain the functional role of oscillations in neural networks, contributing, for example, to perception, attention, and memory. Cross-frequency coupling (CFC) is associated with information integration across populations of neurons [1]. Impaired CFC is linked to neurological disease [2]. It is unclear what role CFC has in information processing and brain functional connectivity. We construct a model of CFC which predicts a computational role for observed θ − γ oscillatory circuits in the hippocampus and cortex [3]. Our model predicts that the complex dynamics in recurrent and feedforward networks of coupled oscillators performs robust information storage and pattern retrieval. Based on phasor associative memories (PAM) [4], we present a novel oscillator neural network (ONN) model [5] that includes subharmonic injection locking (SHIL) [6] and which reproduces experimental observations of CFC. We show that the presence of CFC increases the memory capacity of a population of neurons connected by plastic synapses. CFC enables error-free pattern retrieval whereas pattern retrieval fails without CFC. In addition, the trade-oﬀs between sparse connectivity, capacity, and information per connection are identiﬁed. The associative memory is based on a complex-valued neural network, or phasor neural network (PNN). We show that for values of Q which are the same as the ratio of γ to θ oscillations observed in the hippocampus and the cortex, the associative memory achieves greater capacity and information storage than previous models. The novel contri-butions of this work are providing a computational framework based on oscillator dynamics which predicts the functional role of neural oscillations and connecting concepts in neural network theory and dynamical system theory. Description: Identifying the mechanisms which integrate activity across neural circuits is needed in order to understand cognitive processes. CFC is the observation","",""
22,"Qingsong Lv, Ming Ding, Qiang Liu, Yuxiang Chen, Wenzheng Feng, Siming He, Chang Zhou, Jianguo Jiang, Yuxiao Dong, Jie Tang","Are we really making much progress?: Revisiting, benchmarking and refining heterogeneous graph neural networks",2021,"","","","",183,"2022-07-13 09:29:15","","10.1145/3447548.3467350","","",,,,,22,22.00,2,10,1,"Heterogeneous graph neural networks (HGNNs) have been blossoming in recent years, but the unique data processing and evaluation setups used by each work obstruct a full understanding of their advancements. In this work, we present a systematical reproduction of 12 recent HGNNs by using their official codes, datasets, settings, and hyperparameters, revealing surprising findings about the progress of HGNNs. We find that the simple homogeneous GNNs, e.g., GCN and GAT, are largely underestimated due to improper settings. GAT with proper inputs can generally match or outperform all existing HGNNs across various scenarios. To facilitate robust and reproducible HGNN research, we construct the Heterogeneous Graph Benchmark (HGB) , consisting of 11 diverse datasets with three tasks. HGB standardizes the process of heterogeneous graph data splits, feature processing, and performance evaluation. Finally, we introduce a simple but very strong baseline Simple-HGN-which significantly outperforms all previous models on HGB-to accelerate the advancement of HGNNs in the future.","",""
8,"Xiaolei Liu, Yuheng Luo, Xiaosong Zhang, Qingxin Zhu","A Black-box Attack on Neural Networks Based on Swarm Evolutionary Algorithm",2019,"","","","",184,"2022-07-13 09:29:15","","10.1007/978-3-030-55304-3_14","","",,,,,8,2.67,2,4,3,"","",""
5,"J. V. Berg, S. Krönke, A. Gooßen, D. Bystrov, M. Brück, T. Harder, N. Wieberneit, S. Young","Robust chest x-ray quality assessment using convolutional neural networks and atlas regularization",2020,"","","","",185,"2022-07-13 09:29:15","","10.1117/12.2549541","","",,,,,5,2.50,1,8,2,"The quality of chest radiographs is a practical issue because deviations from quality standards cost radiologists' time, may lead to misdiagnosis and hold legal risks. Automatic and reproducible assessment of the most important quality figures on every acquisition can enable a radiology department to measure, maintain, and improve quality rates on an everyday basis. A method is proposed here to automatically quantify the quality according to the aspects of (i) collimation, (ii) patient rotation, and (iii) inhalation state of a chest PA radiograph by localizing a number of anatomical features and calculating some quality figures in accordance with international standards. The anatomical features related to these quality aspects are robustly detected by a combination of three convolutional neural networks and two probabilistic anatomical atlases. An error analysis demonstrates the accuracy and robustness of the method. The implementation proposed here works in real time (less than a second) on a CPU without any GPU support.","",""
4,"B. Kriener, R. Chaudhuri, I. Fiete","Robust parallel decision-making in neural circuits with nonlinear inhibition",2019,"","","","",186,"2022-07-13 09:29:15","","10.1073/pnas.1917551117","","",,,,,4,1.33,1,3,3,"Significance Animals frequently need to choose the best alternative from a set of possibilities, whether it is which direction to swim in or which food source to favor. How long should a network of neurons take to choose the best of N options? Theoretical results suggest that the optimal time grows as log(N), if the values of each option are imperfectly perceived. However, standard self-terminating neural network models of decision-making cannot achieve this optimal behavior. We show how using certain additional nonlinear response properties in neurons, which are ignored in standard models, results in a decision-making architecture that both achieves the optimal scaling of decision time and accounts for multiple experimentally observed features of neural decision-making. An elemental computation in the brain is to identify the best in a set of options and report its value. It is required for inference, decision-making, optimization, action selection, consensus, and foraging. Neural computing is considered powerful because of its parallelism; however, it is unclear whether neurons can perform this max-finding operation in a way that improves upon the prohibitively slow optimal serial max-finding computation (which takes ∼N⁡log(N) time for N noisy candidate options) by a factor of N, the benchmark for parallel computation. Biologically plausible architectures for this task are winner-take-all (WTA) networks, where individual neurons inhibit each other so only those with the largest input remain active. We show that conventional WTA networks fail the parallelism benchmark and, worse, in the presence of noise, altogether fail to produce a winner when N is large. We introduce the nWTA network, in which neurons are equipped with a second nonlinearity that prevents weakly active neurons from contributing inhibition. Without parameter fine-tuning or rescaling as N varies, the nWTA network achieves the parallelism benchmark. The network reproduces experimentally observed phenomena like Hick’s law without needing an additional readout stage or adaptive N-dependent thresholds. Our work bridges scales by linking cellular nonlinearities to circuit-level decision-making, establishes that distributed computation saturating the parallelism benchmark is possible in networks of noisy, finite-memory neurons, and shows that Hick’s law may be a symptom of near-optimal parallel decision-making with noisy input.","",""
116,"Zhouhua Peng, Jun Wang","Predictor-Based Neural Dynamic Surface Control for Uncertain Nonlinear Systems in Strict-Feedback Form",2017,"","","","",187,"2022-07-13 09:29:15","","10.1109/TNNLS.2016.2577342","","",,,,,116,23.20,58,2,5,"This paper presents a predictor-based neural dynamic surface control (PNDSC) design method for a class of uncertain nonlinear systems in a strict-feedback form. In contrast to existing NDSC approaches where the tracking errors are commonly used to update neural network weights, a predictor is proposed for every subsystem, and the prediction errors are employed to update the neural adaptation laws. The proposed scheme enables smooth and fast identification of system dynamics without incurring high-frequency oscillations, which are unavoidable using classical NDSC methods. Furthermore, the result is extended to the PNDSC with observer feedback, and its robustness against measurement noise is analyzed. Numerical and experimental results are given to demonstrate the efficacy of the proposed PNDSC architecture.","",""
0,"S. Quondam Antonio, F. Riganti Fulginei, H. Rimal, A. M. Ghanim","On the Use of Feedforward Neural Networks to Simulate Magnetic Hysteresis in Electrical Steels",2020,"","","","",188,"2022-07-13 09:29:15","","10.1109/MELECON48756.2020.9140585","","",,,,,0,0.00,0,4,2,"The present investigation aims at the definition of an efficient and robust neural network-based model to simulate the magnetic hysteresis in performing magnetic alloys suitable for aircraft applications. Starting from a set of measured hysteresis loops, a convenient and effective method to train the network consists to identify the Preisach model and use it for the generation of the training set. The obtained neural network turned out to be particularly robust and able to reproduce the behaviour of the Preisach model with a significant reduction of the computational time. The comparative analysis between the two approaches takes into account different kinds of excitation waveforms.","",""
0,"Weitao Chen, Rick Salay, Sean Sedwards, Vahdat Abdelzad, K. Czarnecki","Accelerating the Training of Convolutional Neural Networks for Image Segmentation with Deep Active Learning",2020,"","","","",189,"2022-07-13 09:29:15","","10.1109/ITSC45102.2020.9294260","","",,,,,0,0.00,0,5,2,"Semantic segmentation is an important perception function for automated driving (AD), but training a deep neural network for the task using supervised learning requires expensive manual labelling. Active learning (AL) addresses this challenge by automatically querying and selecting a subset of the dataset to label with the aim to iteratively improve the model performance while minimizing labelling costs. This paper presents a systematic study of deep AL for semantic segmentation and offers three contributions. First, we compare six different state-of-the-art querying methods, including uncertainty-estimate, Bayesian, and out-of-distribution methods. Our comparison uses the state-of-the-art image segmentation architecture DeepLab on the Cityscapes dataset. Our results demonstrate subtle differences between the querying methods, which we analyze and explain. We show that the differences are nevertheless robust by reproducing them on architecture-independent randomly generated data. Second, we propose a novel way to aggregate the output of a query, by counting the number of pixels having acquisition values above a certain threshold. Our method outperforms the standard averaging approach. Finally, we demonstrate that our findings remain consistent for whole images and image crops.","",""
0,"L. Xiaolei, Teng Hu, Kangyi Ding, Yang Bai, Weina Niu, Jiazhong Lu","A Black-Box Attack on Neural Networks Based on Swarm Evolutionary Algorithm",2020,"","","","",190,"2022-07-13 09:29:15","","10.1007/978-3-030-55304-3_14","","",,,,,0,0.00,0,6,2,"","",""
154,"Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, Jiliang Tang","Graph Structure Learning for Robust Graph Neural Networks",2020,"","","","",191,"2022-07-13 09:29:15","","10.1145/3394486.3403049","","",,,,,154,77.00,26,6,2,"Graph Neural Networks (GNNs) are powerful tools in representation learning for graphs. However, recent studies show that GNNs are vulnerable to carefully-crafted perturbations, called adversarial attacks. Adversarial attacks can easily fool GNNs in making predictions for downstream tasks. The vulnerability to adversarial attacks has raised increasing concerns for applying GNNs in safety-critical applications. Therefore, developing robust algorithms to defend adversarial attacks is of great significance. A natural idea to defend adversarial attacks is to clean the perturbed graph. It is evident that real-world graphs share some intrinsic properties. For example, many real-world graphs are low-rank and sparse, and the features of two adjacent nodes tend to be similar. In fact, we find that adversarial attacks are likely to violate these graph properties. Therefore, in this paper, we explore these properties to defend adversarial attacks on graphs. In particular, we propose a general framework Pro-GNN, which can jointly learn a structural graph and a robust graph neural network model from the perturbed graph guided by these properties. Extensive experiments on real-world graphs demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art defense methods, even when the graph is heavily perturbed. We release the implementation of Pro-GNN to our DeepRobust repository for adversarial attacks and defenses. The specific experimental settings to reproduce our results can be found in https://github.com/ChandlerBang/Pro-GNN.","",""
46,"Ammara Mehmood, Aneela Zameer, S. Ling, A. Rehman, R. Zahoor","Integrated computational intelligent paradigm for nonlinear electric circuit models using neural networks, genetic algorithms and sequential quadratic programming",2019,"","","","",192,"2022-07-13 09:29:15","","10.1007/s00521-019-04573-3","","",,,,,46,15.33,9,5,3,"","",""
81,"Min Han, Jianchao Fan, Jun Wang","A Dynamic Feedforward Neural Network Based on Gaussian Particle Swarm Optimization and its Application for Predictive Control",2011,"","","","",193,"2022-07-13 09:29:15","","10.1109/TNN.2011.2162341","","",,,,,81,7.36,27,3,11,"A dynamic feedforward neural network (DFNN) is proposed for predictive control, whose adaptive parameters are adjusted by using Gaussian particle swarm optimization (GPSO) in the training process. Adaptive time-delay operators are added in the DFNN to improve its generalization for poorly known nonlinear dynamic systems with long time delays. Furthermore, GPSO adopts a chaotic map with Gaussian function to balance the exploration and exploitation capabilities of particles, which improves the computational efficiency without compromising the performance of the DFNN. The stability of the particle dynamics is analyzed, based on the robust stability theory, without any restrictive assumption. A stability condition for the GPSO+DFNN model is derived, which ensures a satisfactory global search and quick convergence, without the need for gradients. The particle velocity ranges could change adaptively during the optimization process. The results of a comparative study show that the performance of the proposed algorithm can compete with selected algorithms on benchmark problems. Additional simulation results demonstrate the effectiveness and accuracy of the proposed combination algorithm in identifying and controlling nonlinear systems with long time delays.","",""
42,"Edward Kantz, Saumya Tiwari, J. Watrous, Susan Cheng, Mohit M. Jain","Deep Neural Networks for Classification of LC-MS Spectral Peaks.",2019,"","","","",194,"2022-07-13 09:29:15","","10.1021/acs.analchem.9b02983","","",,,,,42,14.00,8,5,3,"Liquid chromatography-mass spectrometry (LC-MS)-based metabolomics has emerged as a valuable tool for biological discovery, capable of assaying thousands of diverse chemical entities in a single biospecimen. Processing of non-targeted LC-MS spectral data requires identification and isolation of true spectral features from the random, false noise peaks that comprise a significant portion of total signals, using inexact peak selection algorithms and time-consuming visual inspection of data. To increase the fidelity and speed of data processing, herein we establish, optimize and evaluate a machine learning pipeline employing deep neural networks as well as a simpler multiple logistic regression model for classification of spectral features from non-targeted LC-MS metabolomics data. Machine learning based approaches were found to remove up to 90% of false peaks from complex non-targeted LC-MS datasets without reducing true positive signals and exhibit excellent reproducibility across multiple datasets. Application of machine learning for non-targeted LC-MS based peak selection provides for robust and scalable peak classification and data filtering, enabling handling and processing of large scale, complex metabolomics datasets.","",""
39,"H. Sadr, M. Pedram, M. Teshnehlab","A Robust Sentiment Analysis Method Based on Sequential Combination of Convolutional and Recursive Neural Networks",2019,"","","","",195,"2022-07-13 09:29:15","","10.1007/s11063-019-10049-1","","",,,,,39,13.00,13,3,3,"","",""
24,"Timothée Lesort, Mathieu Seurin, Xinrui Li, Natalia Díaz Rodríguez, David Filliat","Unsupervised state representation learning with robotic priors: a robustness benchmark",2017,"","","","",196,"2022-07-13 09:29:15","","","","",,,,,24,4.80,5,5,5,"Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation of the learned representation using nearest neighbors in the state space that allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset.","",""
4,"Francesco Grussu, Stefano B. Blumberg, M. Battiston, Lebina S. Kakkar, Hongxiang Lin, A. Ianuş, T. Schneider, Saurabh Singh, R. Bourne, S. Punwani, D. Atkinson, Claudia A. M. Gandini Wheeler-Kingshott, Eleftheria Panagiotaki, T. Mertzanidou, D. Alexander","“Select and retrieve via direct upsampling” network (SARDU-Net): a data-driven, model-free, deep learning approach for quantitative MRI protocol design",2020,"","","","",197,"2022-07-13 09:29:15","","10.1101/2020.05.26.116491","","",,,,,4,2.00,0,15,2,"Purpose We introduce “Select and retrieve via direct upsampling” network (SARDU-Net), a data-driven framework for model-free quantitative MRI (qMRI) protocol design, and demonstrate it on in vivo brain and prostate diffusion-relaxation imaging (DRI). Methods SARDU-Net selects subsets of informative measurements within lengthy pilot scans, without the requirement to identify tissue parameters for which to optimise for. The algorithm consists of a selector, identifying measurement subsets, and a predictor, estimating fully-sampled signals from the subsets. We implement both using deep neural networks, which are trained jointly end-to-end. We demonstrate the algorithm on brain (32 diffusion-/T1-weightings) and prostate (16 diffusion-/T2-weightings) DRI scans acquired on 3 healthy volunteers on two separate 3T Philips systems each. We used SARDU-Net to identify sub-protocols of fixed size, assessing the reproducibility of the procedure and testing sub-protocols for their potential to inform multi-contrast analyses via T1-weighted spherical mean diffusion tensor (T1-SMDT, brain) and hybrid multi-dimensional MRI (HM-MRI, prostate) modelling. Results In both brain and prostate, SARDU-Net identifies sub-protocols that maximise information content in a reproducible manner across training instantiations. The sub-protocols enable multi-contrast modelling for which they were not optimised explicitly, providing robust T1-SMDT and HM-MRI maps and goodness-of-fit in the top 5% against extensive sub-protocol comparisons. Conclusions SARDU-Net gives new opportunities to identify economical but informative qMRI protocols from a subset of the pilot scans that can be used for acquisition-time-sensitive applications. The simple architecture makes the algorithm easy to train when exhaustive searches are intractable, and applicable to a variety of anatomical contexts.","",""
21,"M. Marouf, Pierre Machart, V. Bansal, Christoph Kilian, D. S. Magruder, C. Krebs, S. Bonn","Realistic in silico generation and augmentation of single cell RNA-seq data using Generative Adversarial Neural Networks",2018,"","","","",198,"2022-07-13 09:29:15","","10.1101/390153","","",,,,,21,5.25,3,7,4,"A fundamental problem in biomedical research is the low number of observations available, mostly due to a lack of available biosamples, prohibitive costs, or ethical reasons. Augmenting few real observations with generated in silico samples could lead to more robust analysis results and a higher reproducibility rate. Here we propose the use of conditional single cell Generative Adversarial Neural Networks (cscGANs) for the realistic generation of single cell RNA-seq data. cscGANs learn non-linear gene-gene dependencies from complex, multi cell type samples and use this information to generate realistic cells of defined types. Augmenting sparse cell populations with cscGAN generated cells improves downstream analyses such as the detection of marker genes, the robustness and reliability of classifiers, the assessment of novel analysis algorithms, and might reduce the number of animal experiments and costs in consequence. cscGANs outperform existing methods for single cell RNA-seq data generation in quality and hold great promise for the realistic generation and augmentation of other biomedical data types.","",""
37,"M. Senapati, A. K. Mohanty, S. Dash, P. Dash","Local linear wavelet neural network for breast cancer recognition",2011,"","","","",199,"2022-07-13 09:29:15","","10.1007/s00521-011-0670-y","","",,,,,37,3.36,9,4,11,"","",""
234,"Jialong Zhang, Zhongshu Gu, J. Jang, Hui Wu, M. Stoecklin, Heqing Huang, Ian Molloy","Protecting Intellectual Property of Deep Neural Networks with Watermarking",2018,"","","","",200,"2022-07-13 09:29:15","","10.1145/3196494.3196550","","",,,,,234,58.50,33,7,4,"Deep learning technologies, which are the key components of state-of-the-art Artificial Intelligence (AI) services, have shown great success in providing human-level capabilities for a variety of tasks, such as visual analysis, speech recognition, and natural language processing and etc. Building a production-level deep learning model is a non-trivial task, which requires a large amount of training data, powerful computing resources, and human expertises. Therefore, illegitimate reproducing, distribution, and the derivation of proprietary deep learning models can lead to copyright infringement and economic harm to model creators. Therefore, it is essential to devise a technique to protect the intellectual property of deep learning models and enable external verification of the model ownership. In this paper, we generalize the ""digital watermarking'' concept from multimedia ownership verification to deep neural network (DNNs) models. We investigate three DNN-applicable watermark generation algorithms, propose a watermark implanting approach to infuse watermark into deep learning models, and design a remote verification mechanism to determine the model ownership. By extending the intrinsic generalization and memorization capabilities of deep neural networks, we enable the models to learn specially crafted watermarks at training and activate with pre-specified predictions when observing the watermark patterns at inference. We evaluate our approach with two image recognition benchmark datasets. Our framework accurately (100%) and quickly verifies the ownership of all the remotely deployed deep learning models without affecting the model accuracy for normal input data. In addition, the embedded watermarks in DNN models are robust and resilient to different counter-watermark mechanisms, such as fine-tuning, parameter pruning, and model inversion attacks.","",""
