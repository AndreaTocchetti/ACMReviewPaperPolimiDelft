Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",1,"2022-07-13 09:39:14","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
26,"W. Gou, Chu-wen Ling, Yan He, Zengliang Jiang, Yuanqing Fu, Fengzhe Xu, Z. Miao, Ting-yu Sun, Jie-sheng Lin, Hui-lian Zhu, Hongwei Zhou, Yu-ming Chen, Ju-Sheng Zheng","Interpretable Machine Learning Framework Reveals Robust Gut Microbiome Features Associated With Type 2 Diabetes",2020,"","","","",2,"2022-07-13 09:39:14","","10.2337/dc20-1536","","",,,,,26,13.00,3,13,2,"OBJECTIVE To identify the core gut microbial features associated with type 2 diabetes risk and potential demographic, adiposity, and dietary factors associated with these features. RESEARCH DESIGN AND METHODS We used an interpretable machine learning framework to identify the type 2 diabetes–related gut microbiome features in the cross-sectional analyses of three Chinese cohorts: one discovery cohort (n = 1,832, 270 cases of type 2 diabetes) and two validation cohorts (cohort 1: n = 203, 48 cases; cohort 2: n = 7,009, 608 cases). We constructed a microbiome risk score (MRS) with the identified features. We examined the prospective association of the MRS with glucose increment in 249 participants without type 2 diabetes and assessed the correlation between the MRS and host blood metabolites (n = 1,016). We transferred human fecal samples with different MRS levels to germ-free mice to confirm the MRS–type 2 diabetes relationship. We then examined the prospective association of demographic, adiposity, and dietary factors with the MRS (n = 1,832). RESULTS The MRS (including 14 microbial features) consistently associated with type 2 diabetes, with risk ratio for per 1-unit change in MRS 1.28 (95% CI 1.23–1.33), 1.23 (1.13–1.34), and 1.12 (1.06–1.18) across three cohorts. The MRS was positively associated with future glucose increment (P < 0.05) and was correlated with a variety of gut microbiota–derived blood metabolites. Animal study further confirmed the MRS–type 2 diabetes relationship. Body fat distribution was found to be a key factor modulating the gut microbiome–type 2 diabetes relationship. CONCLUSIONS Our results reveal a core set of gut microbiome features associated with type 2 diabetes risk and future glucose increment.","",""
6,"D. Raimondi, J. Simm, A. Arany, P. Fariselli, I. Cleynen, Y. Moreau","An interpretable low-complexity machine learning framework for robust exome-based in-silico diagnosis of Crohn’s disease patients",2020,"","","","",3,"2022-07-13 09:39:14","","10.1093/nargab/lqaa011","","",,,,,6,3.00,1,6,2,"Abstract Whole exome sequencing (WES) data are allowing researchers to pinpoint the causes of many Mendelian disorders. In time, sequencing data will be crucial to solve the genome interpretation puzzle, which aims at uncovering the genotype-to-phenotype relationship, but for the moment many conceptual and technical problems need to be addressed. In particular, very few attempts at the in-silico diagnosis of oligo-to-polygenic disorders have been made so far, due to the complexity of the challenge, the relative scarcity of the data and issues such as batch effects and data heterogeneity, which are confounder factors for machine learning (ML) methods. Here, we propose a method for the exome-based in-silico diagnosis of Crohn’s disease (CD) patients which addresses many of the current methodological issues. First, we devise a rational ML-friendly feature representation for WES data based on the gene mutational burden concept, which is suitable for small sample sizes datasets. Second, we propose a Neural Network (NN) with parameter tying and heavy regularization, in order to limit its complexity and thus the risk of over-fitting. We trained and tested our NN on 3 CD case-controls datasets, comparing the performance with the participants of previous CAGI challenges. We show that, notwithstanding the limited NN complexity, it outperforms the previous approaches. Moreover, we interpret the NN predictions by analyzing the learned patterns at the variant and gene level and investigating the decision process leading to each prediction.","",""
3,"Tao Zhong, Zian Zhuang, Xiao-fei Dong, Ka-hing Wong, W. Wong, Jian Wang, D. He, Shengyuan Liu","Predicting Antituberculosis Drug–Induced Liver Injury Using an Interpretable Machine Learning Method: Model Development and Validation Study",2021,"","","","",4,"2022-07-13 09:39:14","","10.2196/29226","","",,,,,3,3.00,0,8,1,"Background Tuberculosis (TB) is a pandemic, being one of the top 10 causes of death and the main cause of death from a single source of infection. Drug-induced liver injury (DILI) is the most common and serious side effect during the treatment of TB. Objective We aim to predict the status of liver injury in patients with TB at the clinical treatment stage. Methods We designed an interpretable prediction model based on the XGBoost algorithm and identified the most robust and meaningful predictors of the risk of TB-DILI on the basis of clinical data extracted from the Hospital Information System of Shenzhen Nanshan Center for Chronic Disease Control from 2014 to 2019. Results In total, 757 patients were included, and 287 (38%) had developed TB-DILI. Based on values of relative importance and area under the receiver operating characteristic curve, machine learning tools selected patients’ most recent alanine transaminase levels, average rate of change of patients’ last 2 measures of alanine transaminase levels, cumulative dose of pyrazinamide, and cumulative dose of ethambutol as the best predictors for assessing the risk of TB-DILI. In the validation data set, the model had a precision of 90%, recall of 74%, classification accuracy of 76%, and balanced error rate of 77% in predicting cases of TB-DILI. The area under the receiver operating characteristic curve score upon 10-fold cross-validation was 0.912 (95% CI 0.890-0.935). In addition, the model provided warnings of high risk for patients in advance of DILI onset for a median of 15 (IQR 7.3-27.5) days. Conclusions Our model shows high accuracy and interpretability in predicting cases of TB-DILI, which can provide useful information to clinicians to adjust the medication regimen and avoid more serious liver injury in patients.","",""
1,"Ana Kostovska, Matej Petković, Tomaz Stepisnik, L. Lucas, T. Finn, José Antonio Martinez Heras, P. Panov, S. Džeroski, A. Donati, N. Simidjievski, D. Kocev","GalaxAI: Machine learning toolbox for interpretable analysis of spacecraft telemetry data",2021,"","","","",5,"2022-07-13 09:39:14","","10.1109/smc-it51442.2021.00013","","",,,,,1,1.00,0,11,1,"We present GalaxAI - a versatile machine learning toolbox for efficient and interpretable end-to-end analysis of spacecraft telemetry data. GalaxAI employs various machine learning algorithms for multivariate time series analyses, classification, regression and structured output prediction, capable of handling high-throughput heterogeneous data. These methods allow for the construction of robust and accurate predictive models, that are in turn applied to different tasks of spacecraft monitoring and operations planning. More importantly, besides the accurate building of models, GalaxAI implements a visualisation layer, providing mission specialists and operators with a full, detailed and interpretable view of the data analysis process. We show the utility and versatility of GalaxAI on two use-cases concerning two different spacecraft: i) analysis and planning of Mars Express thermal power consumption and ii) predicting of INTEGRAL’s crossings through Van Allen belts.","",""
2,"Artur Movsessian, D. Cava, D. Tcherniak","Interpretable machine learning in damage detection using Shapley Additive Explanations",2021,"","","","",6,"2022-07-13 09:39:14","","10.31224/osf.io/96yf5","","",,,,,2,2.00,1,3,1,"In recent years, Machine Learning (ML) techniques have gained popularity in Structural Health Monitoring (SHM). These have been particularly used for damage detection in a wide range of engineering applications such as wind turbine blades. The outcomes of previous research studies in this area have demonstrated the capabilities of ML for robust damage detection. However, the primary challenge facing ML in SHM is the lack of interpretability of the prediction models hindering the broader implementation of these techniques. For this purpose, this study integrates the novel Shapley Additive exPlanations (SHAP) method into a ML-based damage detection process as a tool for introducing interpretability and, thus, build evidence for reliable decision-making in SHM applications. The SHAP method is based on coalitional game theory and adds global and local interpretability to ML-based models by computing the marginal contribution of each feature. The contribution is used to understand the nature of damage indices (DIs). The applicability of the SHAP method is first demonstrated on a simple lumped mass-spring-damper system with simulated temperature variabilities. Later, the SHAP method has been evaluated on data from an in-operation V27 wind turbine with artificially introduced damage in one of its blades. The results show the relationship between the environmental and operational variabilities (EOVs) and their direct influence on the damage indices. This ultimately helps to understand the difference between false positives caused by EOVs and true positives resulting from damage in the structure.","",""
0,"James Dean, M. Scheffler, Thomas A. R. Purcell, S. Barabash, Rahul Bhowmik, T. Bazhirov","Interpretable Machine Learning for Materials Design",2021,"","","","",7,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,6,1,"Fueled by the widespread adoption of Machine Learning and the high-throughput screening of materials, the data-centric approach to materials design has asserted itself as a robust and powerful tool for the in-silico prediction of materials properties. When training models to predict material properties, researchers often face a difficult choice between a model’s interpretability or its performance. We study this trade-off by leveraging four different state-of-the-art Machine Learning techniques: XGBoost, SISSO, Roost, and TPOT for the prediction of structural and electronic properties of perovskites and 2D materials. We then assess the future outlook of the continued integration of Machine Learning into materials discovery, and identify key problems that will continue to challenge researchers as the size of the literature’s datasets and complexity of models increases. Finally, we offer several possible solutions to these challenges with a focus on retaining interpretability, and share our thoughts on magnifying the impact of Machine Learning on materials design.","",""
10,"Krupal P. Jethava, Jonathan A Fine, Yingqi Chen, Ahad Hossain, G. Chopra","Accelerated Reactivity Mechanism and Interpretable Machine Learning Model of N-Sulfonylimines toward Fast Multicomponent Reactions.",2020,"","","","",8,"2022-07-13 09:39:14","","10.26434/chemrxiv.12116163.v1","","",,,,,10,5.00,2,5,2,"We introduce chemical reactivity flowcharts to help chemists interpret reaction outcomes using statistically robust machine learning models trained on a small number of reactions. We developed fast N-sulfonylimine multicomponent reactions for understanding reactivity and to generate training data. Accelerated reactivity mechanisms were investigated using density functional theory. Intuitive chemical features learned by the model accurately predicted heterogeneous reactivity of N-sulfonylimine with different carboxylic acids. Validation of the predictions shows that reaction outcome interpretation is useful for human chemists.","",""
8,"C. Rea, K. Montes, A. Pau, R. Granetz, O. Sauter","Progress Toward Interpretable Machine Learning–Based Disruption Predictors Across Tokamaks",2020,"","","","",9,"2022-07-13 09:39:14","","10.1080/15361055.2020.1798589","","",,,,,8,4.00,2,5,2,"Abstract In this paper we lay the groundwork for a robust cross-device comparison of data-driven disruption prediction algorithms on DIII-D and JET tokamaks. In order to consistently carry on a comparative analysis, we define physics-based indicators of disruption precursors based on temperature, density, and radiation profiles that are currently not used in many other machine learning predictors for DIII-D data. These profile-based indicators are shown to well-describe impurity accumulation events in both DIII-D and JET discharges that eventually disrupt. The univariate analysis of the features used as input signals in the data-driven algorithms applied on the data of both tokamaks statistically highlights the differences in the dominant disruption precursors. JET with its ITER-like wall is more prone to impurity accumulation events, while DIII-D is more subject to edge-cooling mechanisms that destabilize dangerous magnetohydrodynamic modes. Even though the analyzed data sets are characterized by such intrinsic differences, we show through a few examples that the inclusion of physics-based disruption markers in data-driven algorithms is a promising path toward the realization of a uniform framework to predict and interpret disruptive scenarios across different tokamaks. As long as the destabilizing precursors are diagnosed in a device-independent way, the knowledge that data-driven algorithms learn on one device can be re-used to explain a disruptive behavior on another device.","",""
3,"Numair Sani, Jaron J. R. Lee, Razieh Nabi, I. Shpitser","A Semiparametric Approach to Interpretable Machine Learning",2020,"","","","",10,"2022-07-13 09:39:14","","","","",,,,,3,1.50,1,4,2,"Black box models in machine learning have demonstrated excellent predictive performance in complex problems and high-dimensional settings. However, their lack of transparency and interpretability restrict the applicability of such models in critical decision-making processes. In order to combat this shortcoming, we propose a novel approach to trading off interpretability and performance in prediction models using ideas from semiparametric statistics, allowing us to combine the interpretability of parametric regression models with performance of nonparametric methods. We achieve this by utilizing a two-piece model: the first piece is interpretable and parametric, to which a second, uninterpretable residual piece is added. The performance of the overall model is optimized using methods from the sufficient dimension reduction literature. Influence function based estimators are derived and shown to be doubly robust. This allows for use of approaches such as double Machine Learning in estimating our model parameters. We illustrate the utility of our approach via simulation studies and a data application based on predicting the length of stay in the intensive care unit among surgery patients.","",""
2,"J. Sarkar, Cory Peterson","Operational Workload Impact on Robust Solid-State Storage Analyzed with Interpretable Machine Learning",2019,"","","","",11,"2022-07-13 09:39:14","","10.1109/IRPS.2019.8720510","","",,,,,2,0.67,1,2,3,"Solid-state storage technology is finding increasing adoption in enterprise and data center environments due to their high reliability and reducing cost. With high performance solid-state storage devices (SSDs) internally designed as distributed resilient systems, their operational behavior under materially different workloads is described in this research. Application of interpretable machine learning on internal parametric data of SSDs enables insights on workloads' interaction with the resilient system design. After prior research demonstrated significantly different accelerated workload stress, the analysis on resilience of the SSDs under random vs. pseudo-sequential workloads emphasize the efficacy and importance of their distributed resilience schemes. As such, these results provide causational insights on the mechanism of differential stress of the workloads impacting the resilience design principles. Moreover, the results elucidate guidelines strongly relevant from design robustness perspective for research on novel SSD architectures such as the proposed Open Channel SSD, towards deployment in hyperscale and virtualization environments.","",""
1,"W. Gou, Chu-wen Ling, Yan He, Zengliang Jiang, Yuanqing Fu, Fengzhe Xu, Z. Miao, Ting-yu Sun, Jie-sheng Lin, Hui-lian Zhu, Hongwei Zhou, Yu-ming Chen, Ju-Sheng Zheng","Interpretable machine learning framework reveals novel gut microbiome features in predicting type 2 diabetes",2020,"","","","",12,"2022-07-13 09:39:14","","10.1101/2020.04.05.024984","","",,,,,1,0.50,0,13,2,"Gut microbiome targets for type 2 diabetes (T2D) prevention among human cohorts have been controversial. Using an interpretable machine learning-based analytic framework, we identified robust human gut microbiome features, with their optimal threshold, in predicting T2D. Based on the results, we constructed a microbiome risk score (MRS), which was consistently associated with T2D across 3 independent Chinese cohorts involving 9111 participants (926 T2D cases). The MRS could also predict future glucose increment, and was correlated with a variety of gut microbiota-derived blood metabolites. Faecal microbiota transplantation from humans to germ-free mice demonstrated a causal role of the identified combination of microbes in the T2D development. We further identified adiposity and dietary factors which could prospectively modulate the MRS, and found that body fat distribution may be the key factor modulating the gut microbiome-T2D relationship. Taken together, we proposed a new analytical framework for the investigation of microbiome-disease relationship. The identified microbiota may serve as potential drug targets for T2D in future.","",""
0,"Gabriel D. Patrón, D. León, Edwin Lopez, G. Hernández","An Interpretable Automated Machine Learning Credit Risk Model",2020,"","","","",13,"2022-07-13 09:39:14","","10.1007/978-3-030-61834-6_2","","",,,,,0,0.00,0,4,2,"","",""
0,"J. Sarkar, Cory Peterson","Enabling Prognostics of Robust Design with Interpretable Machine Learning",2019,"","","","",14,"2022-07-13 09:39:14","","10.1109/IEDM19573.2019.8993481","","",,,,,0,0.00,0,2,3,"Design of robust systems needs to fully account for reliability physics, operational stresses and interactions thereof - while accommodating range of stresses from qualification to field. This research demonstrates the method of empirically analyzing system-internal parametric data of Solid-State Storage devices (SSD) with Machine Learning (ML). ML is shown to be a necessary, effective and novel means of proactively assessing and interpreting prognostics of the resilient system design. The methodologies and results also bear strong relevance to assessment of current and future designs for evolving usage models and new application areas.","",""
327,"Nicolas Papernot, P. Mcdaniel","Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning",2018,"","","","",15,"2022-07-13 09:39:14","","","","",,,,,327,81.75,164,2,4,"Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.","",""
0,"Joseph Giorgio, W. Jagust, S. Baker, S. Landau, P. Tiňo, Z. Kourtzi","A robust and interpretable machine learning approach using multimodal biological data to predict future pathological tau accumulation",2022,"","","","",16,"2022-07-13 09:39:14","","10.1038/s41467-022-28795-7","","",,,,,0,0.00,0,6,1,"","",""
5,"Gideon A. Lyngdoh, Mohd Zaki, N. Krishnan, Sumanta","Prediction of Concrete Strengths Enabled by Missing Data Imputation and Interpretable Machine Learning",2022,"","","","",17,"2022-07-13 09:39:14","","","","",,,,,5,5.00,1,4,1,"Machine learning (ML)-based prediction of non-linear composition-strength relationship in concretes requires a large, complete, and consistent dataset. However, the availability of such datasets is limited as the datasets often suffer from incompleteness because of missing data corresponding to different input features, which makes the development of robust ML-based predictive models challenging. Besides, as the degree of complexity in these ML models increases, the interpretation of the results becomes challenging. These interpretations of results are critical towards the development of efficient materials design strategies for enhanced materials performance. To address these challenges, this paper implements different data imputation approaches for enhanced dataset completeness. The imputed dataset is leveraged to predict the compressive and tensile strength of concrete using various hyperparameteroptimized ML approaches. Among all the approaches, Extreme Gradient Boosted Decision Trees (XGBoost) showed the highest prediction efficacy when the dataset is imputed using k-nearest neighbors (kNN) with a 10-neighbor configuration. To interpret the predicted results, SHapley Additive exPlanations (SHAP) is employed. Overall, by implementing efficient combinations of data imputation approach, machine learning, and data interpretation, this paper develops an efficient approach to evaluate the compositionstrength relationship in concrete. This work, in turn, can be used as a starting point toward the design and development of various performance-enhanced and sustainable concretes.","",""
0,"Yilin Ning, Siqi Li, M. Ong, F. Xie, B. Chakraborty, D. Ting, Nan Liu","A novel interpretable machine learning system to generate clinical risk scores: An application for predicting early mortality or unplanned readmission in a retrospective cohort study",2022,"","","","",18,"2022-07-13 09:39:14","","10.1371/journal.pdig.0000062","","",,,,,0,0.00,0,7,1,"Risk scores are widely used for clinical decision making and commonly generated from logistic regression models. Machine-learning-based methods may work well for identifying important predictors to create parsimonious scores, but such ‘black box’ variable selection limits interpretability, and variable importance evaluated from a single model can be biased. We propose a robust and interpretable variable selection approach using the recently developed Shapley variable importance cloud (ShapleyVIC) that accounts for variability in variable importance across models. Our approach evaluates and visualizes overall variable contributions for in-depth inference and transparent variable selection, and filters out non-significant contributors to simplify model building steps. We derive an ensemble variable ranking from variable contributions across models, which is easily integrated with an automated and modularized risk score generator, AutoScore, for convenient implementation. In a study of early death or unplanned readmission after hospital discharge, ShapleyVIC selected 6 variables from 41 candidates to create a well-performing risk score, which had similar performance to a 16-variable model from machine-learning-based ranking. Our work contributes to the recent emphasis on interpretability of prediction models for high-stakes decision making, providing a disciplined solution to detailed assessment of variable importance and transparent development of parsimonious clinical risk scores.","",""
0,"Gang Yu, Jiawang Tao, Jie Wang","Odysseia: Genetic Regulatory Feature Analysis with Interpretable Classification Machine Learning Models",2022,"","","","",19,"2022-07-13 09:39:14","","10.1101/2022.02.17.480852","","",,,,,0,0.00,0,3,1,"With rapid progress of robust single-cell transcriptome sequencing since last decade, numerous complex mechanisms underlying cell development has been revealed. Single-cell RNA sequencing (scRNA-seq) analysis is widely accepted as the main approach to define cell stages and phenotypes. As conversion of somatic cells into induced pluripotency cells succeeded, identification key genetic factors(GFs) with scRNA-seq for cell reprogramming in biological research and regenerative medicine fields gained increasing attention. Herein, we describe Odysseia, an interpretable machine learning classifier based single-cell gene expression profile(scGEP) analysis system, that assesses importances of genetic regulatory features in differentiating cell states(CSs). Furthermore, extracted factors, when combining with regulatory network analysis, can help to find key GFs in classifying CSs and possibly inducing CS conversions. Analyzed three published scRNA-seq datasets used to study divergent cell types, Odysseia correctly extracted GFs acclaimed to be capable of inducing CS conversions. Overall, Odysseia provides an automated alternative to obtain guidance information while explicating mechanism to engineer cellular phenotypes.","",""
0,"Pongpisit Thanasutives, Takeshi Morita, M. Numao, Ken-ichi Fukui","Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",2022,"","","","",20,"2022-07-13 09:39:14","","10.48550/arXiv.2206.12901","","",,,,,0,0.00,0,4,1,"—This work is concerned with discovering the gov- erning partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identiﬁcation from ﬁnite observations but failed to maintain satisfying performance against noisy data, partly owing to suboptimal estimated deriva- tives and found PDE coefﬁcients. We address the issues by introducing a noise-aware physics-informed machine learning (nPIML) framework to discover the governing PDE from data following arbitrary distributions. Our proposals are twofold. First, we propose a couple of neural networks, namely solver and preselector, which yield an interpretable neural representation of the hidden physical constraint. After they are jointly trained, the solver network approximates potential candidates, e.g., partial derivatives, which are then fed to the sparse regression algorithm that initially unveils the most likely parsimonious PDE, decided according to the information criterion. Second, we propose the denoising physics-informed neural networks (dPINNs), based on Discrete Fourier Transform (DFT), to deliver a set of the optimal ﬁnetuned PDE coefﬁcients respecting the noise-reduced variables. The denoising PINNs’ structures are compartmentalized into forefront projection networks and a PINN, by which the formerly learned solver initializes. Our extensive experiments on ﬁve canonical PDEs afﬁrm that the proposed framework presents a robust and interpretable approach for PDE discovery, applicable to a wide range of systems, possibly complicated by noise. and model while suppressing paved towards the applications of interpretable artiﬁcial intelligence (AI) to enhance the understandability of physical sciences.","",""
0,"Daniel Grahn, Melonie Richey","The prediction management framework: ethical, governable, and interpretable deployment of artificial intelligence/machine learning systems",2022,"","","","",21,"2022-07-13 09:39:14","","10.1117/12.2617772","","",,,,,0,0.00,0,2,1,"As defense organizations integrate artificial intelligence (AI) into evermore critical operations, especially those near the tactical edge with real-time decision making, the necessity of a standardized, robust framework for deployment and management of AI systems is increasing. In this paper, we propose a Prediction Management Framework (PMF) that aligns with the Department of Defense’s Ethical Principles for AI for ethical, governable, and interpretable deployments. We explore different requirements for the framework with inspiration drawn from various regulatory, safety, and communication standards. In support of these requirements, we offer recommendations and implementation guidance to provide comprehensive visibility into the system.","",""
0,"Willa Potosnak","Robust Rule Learning for Reliable and Interpretable Insight into Expertise Transfer Opportunities",2022,"","","","",22,"2022-07-13 09:39:14","","10.1609/aaai.v36i11.21704","","",,,,,0,0.00,0,1,1,"Intensive care in hospitals is distributed to different units that care for patient populations reflecting specific comorbidities, treatments, and outcomes. Unit expertise can be shared to potentially improve the quality of methods and outcomes for patients across units. We propose an algorithmic rule pruning approach for use in building short lists of human-interpretable rules that reliably identify patient beneficiaries of expertise transfers in the form of machine learning risk models. Our experimental results, obtained with two intensive care monitoring datasets, demonstrate the potential utility of the proposed method in practice.","",""
4,"Alexandra Renouard, A. Maggi, M. Grunberg, C. Doubre, C. Hibert","Toward False Event Detection and Quarry Blast versus Earthquake Discrimination in an Operational Setting Using Semiautomated Machine Learning",2021,"","","","",23,"2022-07-13 09:39:14","","10.1785/0220200305","","",,,,,4,4.00,1,5,1,"  Small-magnitude earthquakes shed light on the spatial and magnitude distribution of natural seismicity, as well as its rate and occurrence, especially in stable continental regions where natural seismicity remains difficult to explain under slow strain-rate conditions. However, capturing them in catalogs is strongly hindered by signal-to-noise ratio issues, resulting in high rates of false and man-made events also being detected. Accurate and robust discrimination of these events is critical for optimally detecting small earthquakes. This requires uncovering recurrent salient features that can rapidly distinguish first false events from real events, then earthquakes from man-made events (mainly quarry blasts), despite high signal variability and noise content. In this study, we combined the complementary strengths of human and interpretable rule-based machine-learning algorithms for solving this classification problem. We used human expert knowledge to co-create two reliable machine-learning classifiers through human-assisted selection of classification features and review of events with uncertain classifier predictions. The two classifiers are integrated into the SeisComP3 operational monitoring system. The first one discards false events from the set of events obtained with a low short-term average/long-term average threshold; the second one labels the remaining events as either earthquakes or quarry blasts. When run in an operational setting, the first classifier correctly detected more than 99% of false events and just over 93% of earthquakes; the second classifier correctly labeled 95% of quarry blasts and 96% of earthquakes. After a manual review of the second classifier low-confidence outputs, the final catalog contained fewer than 2% of misclassified events. These results confirm that machine learning strengthens the quality of earthquake catalogs and that the performance of machine-learning classifiers can be improved through human expertise. Our study promotes a broader implication of hybrid intelligence monitoring within seismological observatories.","",""
5,"Naoya Takeishi, Alexandros Kalousis","Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling",2021,"","","","",24,"2022-07-13 09:39:14","","","","",,,,,5,5.00,3,2,1,"Integrating physics models within machine learning models holds considerable promise toward learning robust models with improved interpretability and abilities to extrapolate. In this work, we focus on the integration of incomplete physics models into deep generative models. In particular, we introduce an architecture of variational autoencoders (VAEs) in which a part of the latent space is grounded by physics. A key technical challenge is to strike a balance between the incomplete physics and trainable components such as neural networks for ensuring that the physics part is used in a meaningful manner. To this end, we propose a regularized learning method that controls the effect of the trainable components and preserves the semantics of the physics-based latent variables as intended. We not only demonstrate generative performance improvements over a set of synthetic and real-world datasets, but we also show that we learn robust models that can consistently extrapolate beyond the training distribution in a meaningful manner. Moreover, we show that we can control the generative process in an interpretable manner.","",""
3,"F. Biessmann, D. Refiano","Quality Metrics for Transparent Machine Learning With and Without Humans In the Loop Are Not Correlated",2021,"","","","",25,"2022-07-13 09:39:14","","","","",,,,,3,3.00,2,2,1,"The field explainable artificial intelligence (XAI) has brought about an arsenal of methods to render Machine Learning (ML) predictions more interpretable. But how useful explanations provided by transparent ML methods are for humans remains difficult to assess. Here we investigate the quality of interpretable computer vision algorithms using techniques from psychophysics. In crowdsourced annotation tasks we study the impact of different interpretability approaches on annotation accuracy and task time. We compare these quality metrics with classical XAI, automated quality metrics. Our results demonstrate that psychophysical experiments allow for robust quality assessment of transparency in machine learning. Interestingly the quality metrics computed without humans in the loop did not provide a consistent ranking of interpretability methods nor were they representative for how useful an explanation was for humans. These findings highlight the potential of methods from classical psychophysics for modern machine learning applications. We hope that our results provide convincing arguments for evaluating interpretability in its natural habitat, human-ML interaction, if the goal is to obtain an authentic assessment of interpretability.","",""
25,"Nastaran Meftahi, M. Klymenko, A. Christofferson, U. Bach, D. Winkler, S. Russo","Machine learning property prediction for organic photovoltaic devices",2020,"","","","",26,"2022-07-13 09:39:14","","10.1038/s41524-020-00429-w","","",,,,,25,12.50,4,6,2,"","",""
2,"S. Newman, R. Furbank","Explainable machine learning models of major crop traits from satellite-monitored continent-wide field trial data",2021,"","","","",27,"2022-07-13 09:39:14","","10.1101/2021.03.08.434495","","",,,,,2,2.00,1,2,1,"Four species of grass generate half of all human-consumed calories1. However, abundant biological data on species that produce our food remains largely inaccessible, imposing direct barriers to understanding crop yield and fitness traits. Here, we assemble and analyse a continent-wide database of field experiments spanning ten years and hundreds of thousands of machine-phenotyped populations of ten major crop species. Training an ensemble of machine learning models, using thousands of variables capturing weather, ground-sensor, soil, chemical and fertiliser dosage, management, and satellite data, produces robust cross-continent yield models exceeding R2 = 0.8 prediction accuracy. In contrast to ‘black box’ analytics, detailed interrogation of these models reveals fundamental drivers of crop behaviour and complex interactions predicting yield and agronomic traits. These results demonstrate the capacity of machine learning models to build unified, interpretable, and explainable models of crop behaviour, and highlight the powerful role of data in the future of food.","",""
2,"J. de Nijs, T. J. Burger, Ronald J. Janssen, S. M. Kia, Daniel P J van Opstal, M. D. de Koning, L. de Haan, Behrooz Z. Agna A. Nico J. Richard Lieuwe Philippe Jurjen  Alizadeh Bartels-Velthuis van Beveren Bruggeman de, B. Alizadeh, A. Bartels-Velthuis, N. V. van Beveren, R. Bruggeman, P. Delespaul, J. Luykx, I. Myin-Germeys, R. Kahn, F. Schirmbeck, C. Simons, T. van Amelsvoort, J. van os, R. van Winkel, W. Cahn, H. Schnack","Individualized prediction of three- and six-year outcomes of psychosis in a longitudinal multicenter study: a machine learning approach",2021,"","","","",28,"2022-07-13 09:39:14","","10.1038/s41537-021-00162-3","","",,,,,2,2.00,0,23,1,"","",""
3,"Chi-Heng Lin, Mehdi Azabou, Eva L. Dyer","Making transport more robust and interpretable by moving data through a small number of anchor points",2020,"","","","",29,"2022-07-13 09:39:14","","","","",,,,,3,1.50,1,3,2,"Optimal transport (OT) is a widely used technique for distribution alignment, with applications throughout the machine learning, graphics, and vision communities. Without any additional structural assumptions on transport, however, OT can be fragile to outliers or noise, especially in high dimensions. Here, we introduce Latent Optimal Transport (LOT), a new approach for OT that simultaneously learns low-dimensional structure in data while leveraging this structure to solve the alignment task. The idea behind our approach is to learn two sets of ""anchors"" that constrain the flow of transport between a source and target distribution. In both theoretical and empirical studies, we show that LOT regularizes the rank of transport and makes it more robust to outliers and the sampling density. We show that by allowing the source and target to have different anchors, and using LOT to align the latent spaces between anchors, the resulting transport plan has better structural interpretability and highlights connections between both the individual data points and the local geometry of the datasets.","",""
0,"Kaiyu Yang","1 Machine Learning for Reasoning",2021,"","","","",30,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,1,"Reasoning is a core component of human intelligence that machines still struggle with. I do research in the field of artificial intelligence, with the long-term goal of building machines that reason precisely, systematically, in ways that are interpretable and robust to ambiguity in real-world environments. My research advances towards this goal by attempting to combine the complementary strengths of machine learning and symbolic reasoning. My graduate research has focused on developing machine learning models that represent reasoning via symbolic proofs. They show the promise of new learning paradigms that I envision to be more robust, interpretable, and trustworthy for deployment in real-world high-stake applications. Symbolic reasoning is precise and generalizes systematically to unseen scenarios. But it has been restricted to domains amenable to rigid formalization. In contrast, machine learning has the flexibility to handle noisy and ambiguous domains that are hard to formalize. But predominant machine learning models, such as deep neural networks, are notoriously uninterpretable, data-hungry, and incapable of generalizing outside the training data distribution. Integrating the strengths of both approaches is essential for building flexible reasoning machines with precise and systematic generalization. However, due to the discrete nature of symbolic reasoning, such integration may require a radical departure from the predominant paradigm of gradient-based learning. And my research tries to answer what that alternative form of learning might look like.","",""
2,"Weishen Pan, Changshui Zhang","The Definitions of Interpretability and Learning of Interpretable Models",2021,"","","","",31,"2022-07-13 09:39:14","","","","",,,,,2,2.00,1,2,1,"As machine learning algorithms getting adopted in an ever-increasing number of applications, interpretation has emerged as a crucial desideratum. In this paper, we propose a mathematical definition for the humaninterpretable model. In particular, we define interpretability between two information process systems. If a prediction model is interpretable by a human recognition system based on the above interpretability definition, the prediction model is defined as a completely human-interpretable model. We further design a practical framework to train a completely human-interpretable model by user interactions. Experiments on image datasets show the advantages of our proposed model in two aspects: 1) The completely human-interpretable model can provide an entire decisionmaking process that is human-understandable; 2) The completely humaninterpretable model is more robust against adversarial attacks.","",""
17,"Frank Male, J. Jensen, L. Lake","Comparison of permeability predictions on cemented sandstones with physics-based and machine learning approaches",2020,"","","","",32,"2022-07-13 09:39:14","","10.31223/osf.io/3w6jx","","",,,,,17,8.50,6,3,2,"Abstract Permeability prediction has been an important problem since the time of Darcy. Most approaches to solve this problem have used either idealized physical models or empirical relations. In recent years, machine learning (ML) has led to more accurate and robust, but less interpretable empirical models. Using 211 core samples collected from 12 wells in the Garn Sandstone from the North Sea, this study compared idealized physical models based on the Carman-Kozeny equation to interpretable ML models. We found that ML models trained on estimates of physical properties are more accurate than physical models. Also, the results show evidence of a threshold of about 10% volume fraction, above which pore-filling cement strongly affects permeability.","",""
6,"Olivier Deiss, S. Biswal, Jing Jin, Haoqi Sun, M. Westover, Jimeng Sun","HAMLET: Interpretable Human And Machine co-LEarning Technique",2018,"","","","",33,"2022-07-13 09:39:14","","","","",,,,,6,1.50,1,6,4,"Efficient label acquisition processes are key to obtaining robust classifiers. However, data labeling is often challenging and subject to high levels of label noise. This can arise even when classification targets are well defined, if instances to be labeled are more difficult than the prototypes used to define the class, leading to disagreements among the expert community. Here, we enable efficient training of deep neural networks. From low-confidence labels, we iteratively improve their quality by simultaneous learning of machines and experts. We call it Human And Machine co-LEarning Technique (HAMLET). Throughout the process, experts become more consistent, while the algorithm provides them with explainable feedback for confirmation. HAMLET uses a neural embedding function and a memory module filled with diverse reference embeddings from different classes. Its output includes classification labels and highly relevant reference embeddings as explanation. We took the study of brain monitoring at intensive care unit (ICU) as an application of HAMLET on continuous electroencephalography (cEEG) data. Although cEEG monitoring yields large volumes of data, labeling costs and difficulty make it hard to build a classifier. Additionally, while experts agree on the labels of clear-cut examples of cEEG patterns, labeling many real-world cEEG data can be extremely challenging. Thus, a large minority of sequences might be mislabeled. HAMLET has shown significant performance gain against deep learning and other baselines, increasing accuracy from 7.03% to 68.75% on challenging inputs. Besides improved performance, clinical experts confirmed the interpretability of those reference embeddings in helping explaining the classification results by HAMLET.","",""
0,"Yu-Chung Peng, N. S. D'Souza, Brian Bush, Charles Brown, A. Venkataraman","Predicting Acute Kidney Injury via Interpretable Ensemble Learning and Attention Weighted Convoutional-Recurrent Neural Networks",2021,"","","","",34,"2022-07-13 09:39:14","","10.1109/CISS50987.2021.9400242","","",,,,,0,0.00,0,5,1,"Acute Kidney Injury (AKI) is one of the most frequent postoperative complications and is associated with both short- and long-term mortality. Improved prediction of AKI is crucial and may help clinicians prevent and mitigate its adverse effects. In this paper, we explore the use of machine learning methods to predict postoperative AKI. Our analysis centers on the ensemble-based random forest (RF) classifier, which operates on static clinical variables, and a novel deep learning architecture that incorporates intraoperative time series data along with the static variables. The architecture uses a dual-attention mechanism to select both features and time intervals relevant for AKI prediction. We evaluate our models on the publicly available VitalDB database of 3,640 patients who underwent non-cardiac surgery. The RF outperformed existing machine learning classifiers in the AKI literature (AUROC: 0.86, AUPRC: 0.54). In addition, the RF identified a robust set of preoperative variables that can be screened in a simple blood test. While the deep learning model achieved slightly lower performance (AUROC: 0.84, AUPRC: 0.44), the attention weights provide important intraoperative information, which can be monitored by clinicians during surgery. Taken together, our results highlight the promise of machine learning for AKI prediction and take the first steps towards developing clinically translatable models.","",""
0,"Jian Jiang","MIIDL: a Python package for microbial biomarkers identification powered by interpretable deep learning",2021,"","","","",35,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,1,"Summary: Detecting microbial biomarkers used to predict disease phenotypes and clinical outcomes is crucial for disease early-stage screening and diagnosis. Most methods for biomarker identification are linear-based, which is very limited as biological processes are rarely fully linear. The introduction of machine learning to this field tends to bring a promising solution. However, identifying microbial biomarkers in an interpretable, datadriven and robust manner remains challenging. We present MIIDL, a Python package for the identification of microbial biomarkers based on interpretable deep learning. MIIDL innovatively applies convolutional neural networks, a variety of interpretability algorithms and plenty of pre-processing methods to provide a one-stop and robust pipeline for microbial biomarkers identification from high-dimensional and sparse data sets. Availability: Source code is available on GitHub (https://github.com/chunribu/miidl/) under the MIT license. MIIDL is operating system independent and can be installed directly via pip or conda. Contact: chunribu@mail.sdu.edu.cn","",""
10,"T. Botari, Frederik Hvilshøj, Rafael Izbicki, A. Carvalho","MeLIME: Meaningful Local Explanation for Machine Learning Models",2020,"","","","",36,"2022-07-13 09:39:14","","","","",,,,,10,5.00,3,4,2,"Most state-of-the-art machine learning algorithms induce black-box models, preventing their application in many sensitive domains. Hence, many methodologies for explaining machine learning models have been proposed to address this problem. In this work, we introduce strategies to improve local explanations taking into account the distribution of the data used to train the black-box models. We show that our approach, MeLIME, produces more meaningful explanations compared to other techniques over different ML models, operating on various types of data. MeLIME generalizes the LIME method, allowing more flexible perturbation sampling and the use of different local interpretable models. Additionally, we introduce modifications to standard training algorithms of local interpretable models fostering more robust explanations, even allowing the production of counterfactual examples. To show the strengths of the proposed approach, we include experiments on tabular data, images, and text; all showing improved explanations. In particular, MeLIME generated more meaningful explanations on the MNIST dataset than methods such as GuidedBackprop, SmoothGrad, and Layer-wise Relevance Propagation. MeLIME is available on this https URL.","",""
1,"Huijun Wu, Chen Wang, R. Nock, Wei Wang, Jie Yin, Kai Lu, Liming Zhu","SMINT: Toward Interpretable and Robust Model Sharing for Deep Neural Networks",2020,"","","","",37,"2022-07-13 09:39:14","","10.1145/3381833","","",,,,,1,0.50,0,7,2,"Sharing a pre-trained machine learning model, particularly a deep neural network via prediction APIs, is becoming a common practice on machine learning as a service (MLaaS) platforms nowadays. Although deep neural networks (DNN) have shown remarkable successes in many tasks, they are also criticized for the lack of interpretability and transparency. Interpreting a shared DNN model faces two additional challenges compared with interpreting a general model. (1) Limited training data can be disclosed to users. (2) The internal structure of the models may not be available. These two challenges impede the application of most existing interpretability approaches, such as saliency maps or influence functions, for DNN models. Case-based reasoning methods have been used for interpreting decisions; however, how to select and organize the data points under the constraints of shared DNN models is not discussed. Moreover, simply providing cases as explanations may not be sufficient for supporting instance level interpretability. Meanwhile, existing interpretation methods for DNN models generally lack the means to evaluate the reliability of the interpretation. In this article, we propose a framework named Shared Model INTerpreter (SMINT) to address the above limitations. We propose a new data structure called a boundary graph to organize training points to mimic the predictions of DNN models. We integrate local features, such as saliency maps and interpretable input masks, into the data structure to help users to infer the model decision boundaries. We show that the boundary graph is able to address the reliability issues in many local interpretation methods. We further design an algorithm named hidden-layer aware p-test to measure the reliability of the interpretations. Our experiments show that SMINT is able to achieve above 99% fidelity to corresponding DNN models on both MNIST and ImageNet by sharing only a tiny fraction of training data to make these models interpretable. The human pilot study demonstrates that SMINT provides better interpretability compared with existing methods. Moreover, we demonstrate that SMINT is able to assist model tuning for better performance on different user data.","",""
12,"Frank Male, I. Duncan","Lessons for machine learning from the analysis of porosity-permeability transforms for carbonate reservoirs",2019,"","","","",38,"2022-07-13 09:39:14","","10.31223/osf.io/fwndb","","",,,,,12,4.00,6,2,3,"Abstract Prediction of permeability is one of the most difficult aspects of reservoir characterization because permeability cannot be directly measured by current well logging technology. This is particularly challenging for carbonate rocks. Machine learning (ML) and robust multivariate methods have been developed that have been used in many fields of study to make accurate estimators for variables of interest from both large and small datasets. ML has been criticized for utilizing approaches that are typically not interpretable. That is, it is not clear how the answers are arrived at and what aspects of input data may be resulting in inaccurate results. The current study uses a number of the mathematical algorithms that operate inside ML modules. It applies them to developing porosity-permeability transforms, with or without rock types, to two well-characterized data sets for carbonate reservoirs. One data set is from Jerry Lucia's 1995 study of carbonate rock types, and the other is from a study of the Seminole, West Texas, San Andres Unit. This study of statistical analysis of porosity-permeability transforms includes: transforming the data to normal distributions; performing cross-validation blind testing; and detecting heteroscedasticity by creating plots of residuals. Heteroscedastic data (populations with variable variance) may have an adverse impact on ML algorithms such as Random Forests (RF). We find that including lithofacies information does not greatly improve porosity-permeability transforms. We also propose a number of strategies to make ML analyses of reservoir (and other geosciences) data sets more robust and accurate.","",""
37,"","Towards trustable machine learning",2018,"","","","",39,"2022-07-13 09:39:14","","10.1038/s41551-018-0315-x","","",,,,,37,9.25,0,0,4,"","",""
8,"Brandon M. Booth, Tiantian Feng, Abhishek Jangalwa, Shrikanth S. Narayanan","Toward Robust Interpretable Human Movement Pattern Analysis in a Workplace Setting",2019,"","","","",40,"2022-07-13 09:39:14","","10.1109/ICASSP.2019.8683730","","",,,,,8,2.67,2,4,3,"Gaining a better understanding of how people move about and interact with their environment is an important piece of understanding human behavior. Careful analysis of individuals’ deviations or variations in movement over time can provide an awareness about changes to their physical or mental state and may be helpful in tracking performance and well-being especially in workplace settings. We propose a technique for clustering and discovering patterns in human movement data by extracting motifs from the time series of durations where participants linger at different locations. Using a data set of over 200 participants moving around a hospital for ten weeks, we show this technique intuitively captures local temporal relationships between hospital rooms and also clusters them in a fashion consistent with the room type labels (e.g. lounge, break room, etc.) without using prior knowledge. Machine learning features derived from these clusters are empirically shown to provide information similar to features attained using domain knowledge of the room type labels directly when predicting mental wellness from self-reports.","",""
7,"I. L. Ruiz, M. A. Gómez-Nieto","Building of Robust and Interpretable QSAR Classification Models by Means of the Rivality Index",2019,"","","","",41,"2022-07-13 09:39:14","","10.1021/acs.jcim.9b00264","","",,,,,7,2.33,4,2,3,"An unambiguous algorithm, added to the study of the applicability domain and appropriate measures of the goodness of fit and robustness, represent the key characteristics that should be ideally fulfilled for a QSAR model to be considered for regulatory purposes. In this paper, we propose a new algorithm (RINH) based on the rivality index for the construction of QSAR classification models. This index is capable of predicting the activity of the data set molecules by means of a measurement of the rivality between their nearest neighbors belonging to different classes, contributing with a robust measurement of the reliability of the predictions. In order to demonstrate the goodness of the proposed algorithm we have selected four independent and orthogonally different benchmark data sets (balanced/unbalanced and high/low modelable) and we have compared the results with those obtained using 12 different machine learning algorithms. These results have been validated using 20 data sets of different balancing and sizes, corroborating that the proposed algorithm is able to generate highly accurate classification models and contribute with valuable measurements of the reliability of the predictions and the applicability domain of the built models.","",""
1,"William Briguglio, Sherif Saad","Interpreting Machine Learning Malware Detectors Which Leverage N-gram Analysis",2019,"","","","",42,"2022-07-13 09:39:14","","10.1007/978-3-030-45371-8_6","","",,,,,1,0.33,1,2,3,"","",""
0,"George J. Siedel, S. Vock, A. Morozov, Stefan Voss","Utilizing Class Separation Distance for the Evaluation of Corruption Robustness of Machine Learning Classifiers",2022,"","","","",43,"2022-07-13 09:39:14","","10.48550/arXiv.2206.13405","","",,,,,0,0.00,0,4,1,"Robustness is a fundamental pillar of Machine Learning (ML) classifiers, substantially determining their reliability. Methods for assessing classifier robustness are therefore essential. In this work, we address the challenge of evaluating corruption robustness in a way that allows comparability and interpretability on a given dataset. We propose a test data augmentation method that uses a robustness distance 𝜖 derived from the datasets minimal class separation distance. The resulting MSCR (mean statistical corruption robustness) metric allows a dataset-specific comparison of different classifiers with respect to their corruption robustness. The MSCR value is interpretable, as it represents the classifiers avoidable loss of accuracy due to statistical corruptions. On 2D and image data, we show that the metric reflects different levels of classifier robustness. Furthermore, we observe unexpected optima in classifiers robust accuracy through training and testing classifiers with different levels of noise. While researchers have frequently reported on a significant tradeoff on accuracy when training robust models, we strengthen the view that a tradeoff between accuracy and corruption robustness is not inherent. Our results indicate that robustness training through simple data augmentation can already slightly improve accuracy.","",""
0,"Jing-Jing Liu, Jian-chao Liu","Permeability Predictions for Tight Sandstone Reservoir Using Explainable Machine Learning and Particle Swarm Optimization",2022,"","","","",44,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,1,"High-precision permeability prediction is of great significance to tight sandstone reservoirs. However, while considerable progress has recently been made in the machine learning based prediction of reservoir permeability, the generalization of this approach is limited by weak interpretability. Hence, an interpretable XGBoost model is proposed herein based on particle swarm optimization to predict the permeability of tight sandstone reservoirs with higher accuracy and robust interpretability. The porosity and permeability of 202 core plugs and 6 logging curves (namely, the gamma-ray (GR) curve, the acoustic curve (AC), the spontaneous potential (SP) curve, the caliper (CAL) curve, the deep lateral resistivity (RILD) curve, and eight lateral resistivity (RFOC) curve) are extracted along with three derived variables (i.e., the shale content, the AC slope, and the GR slope) as data sets. Based on the data preprocessing, global and local interpretations are performed according to the Shapley additive explanations (SHAP) analysis, and the redundant features in the data set are screened to identify the porosity, AC, CAL, and GR slope as the four most important features. The particle swarm optimization algorithm is then used to optimize the hyperparameters of the XGBoost model. The prediction results of the PSO-XGBoost model indicate a superior performance compared with that of the benchmark XGBoost model. In addition, the reliable application of the interpretable PSO-XGBoost model in the prediction of tight sandstone reservoir permeability is examined by comparing the results with those of two traditional mathematical regression models, five machine learning models, and three deep learning models. Thus, the interpretable PSO-XGBoost model is shown to have more advantages in permeability prediction along with the lowest root mean square error, thereby confirming the effectiveness and practicability of this method.","",""
0,"Daniel Organisciak, Hubert P. H. Shum, E. Nwoye, W. L. Woo","RobIn: A Robust Interpretable Deep Network for Schizophrenia Diagnosis",2022,"","","","",45,"2022-07-13 09:39:14","","10.48550/arXiv.2203.17085","","",,,,,0,0.00,0,4,1,"Schizophrenia is a severe mental health condition that requires a long and com-plicated diagnostic process. However, early diagnosis is vital to control symptoms. Deep learning has recently become a popular way to analyse and interpret medical data. Past attempts to use deep learning for schizophrenia diagnosis from brain-imaging data have shown promise but suﬀer from a large training-application gap - it is diﬃcult to apply lab research to the real world. We propose to reduce this training-application gap by focusing on readily accessible data. We collect a data set of psychiatric observations of patients based on DSM-5 criteria. Because similar data is already recorded in all mental health clinics that diagnose schizophrenia using DSM-5, our method could be easily integrated into current processes as a tool to assist clinicians, whilst abiding by formal diagnostic criteria. To facilitate real-world usage of our system, we show that it is interpretable and robust. Understanding how a machine learning tool reaches its diagnosis is essential to allow clinicians to trust that diagnosis. To interpret the framework, we fuse two complementary attention mechanisms, ‘squeeze and excitation’ and ‘self-attention’, to determine global attribute importance and attribute interactivity, respectively. The model uses these im-∗ portance scores to make decisions. This allows clinicians to understand how a diagnosis was reached, improving trust in the model. Because machine learning models often struggle to generalise to data from diﬀerent sources, we perform experiments with augmented test data to evaluate the model’s applicability to the real world. We ﬁnd that our model is more robust to perturbations, and should therefore perform better in a clinical setting. It achieves 98% accuracy with 10-fold cross-validation.","",""
1,"Johannes Haug, Klaus Broelemann, Gjergji Kasneci","Dynamic Model Tree for Interpretable Data Stream Learning",2022,"","","","",46,"2022-07-13 09:39:14","","10.48550/arXiv.2203.16181","","",,,,,1,1.00,0,3,1,"—Data streams are ubiquitous in modern business and society. In practice, data streams may evolve over time and cannot be stored indeﬁnitely. Effective and transparent machine learning on data streams is thus often challenging. Hoeffding Trees have emerged as a state-of-the art for online predictive modelling. They are easy to train and provide meaningful convergence guarantees under a stationary process. Yet, at the same time, Hoeffding Trees often require heuristic and costly extensions to adjust to distributional change, which may considerably impair their interpretability. In this work, we revisit Model Trees for machine learning in evolving data streams. Model Trees are able to maintain more ﬂexible and locally robust representations of the active data concept, making them a natural ﬁt for data stream applications. Our novel framework, called Dynamic Model Tree, satisﬁes desirable consistency and minimality properties. In experiments with synthetic and real-world tabular streaming data sets, we show that the proposed framework can drastically reduce the number of splits required by existing incremental decision trees. At the same time, our framework often outperforms state- of-the-art models in terms of predictive quality – especially when concept drift is involved. Dynamic Model Trees are thus a powerful online learning framework that contributes to more lightweight and interpretable machine learning in data streams.","",""
4,"Wei Zhang, Q. Chen, Yunfang Chen","Deep Learning Based Robust Text Classification Method via Virtual Adversarial Training",2020,"","","","",47,"2022-07-13 09:39:14","","10.1109/ACCESS.2020.2981616","","",,,,,4,2.00,1,3,2,"The existing methods of generating adversarial texts usually change the original meanings of texts significantly and even generate the unreadable texts. These less readable adversarial texts can misclassify the machine classifier successfully, but they cannot deceive the human observers very well. In this paper, we propose a novel method that generates readable adversarial texts with some perturbations that can also confuse human observers successfully. Based on the continuous bag-of-words (CBOW) model, the proposed method looks for the appropriate perturbations to generate the adversarial texts through controlling the perturbation direction vectors. Meanwhile, we apply adversarial training to regularize the classification model and extend it to semi-supervised tasks with virtual adversarial training. Experiments are conducted to show that the generated adversaries are interpretable and confused to humans and the virtual adversarial training effectively improves the robustness of the model.","",""
3,"A. Preece, Daniel Harborne, R. Raghavendra, Richard J. Tomsett, Dave Braines","Provisioning Robust and Interpretable AI/ML-Based Service Bundles",2018,"","","","",48,"2022-07-13 09:39:14","","10.1109/MILCOM.2018.8599838","","",,,,,3,0.75,1,5,4,"Coalition operations environments are characterised by the need to share intelligence, surveillance and reconnaissance services. Increasingly, such services are based on artificial intelligence (AI)and machine learning (ML)technologies. Two key issues in the exploitation of AI/ML services are robustness and interpretability. Employing a diverse portfolio of services can make a system robust to ‘unknown unknowns’. Interpretability - the need for services to offer explanation facilities to engender user trust - can be addressed by a variety of methods to generate either transparent or post hoc explanations according to users' requirements. This paper shows how a service-provisioning framework for coalition operations can be extended to address specific requirements for robustness and interpretability, allowing automatic selection of service bundles for intelligence, surveillance and reconnaissance tasks. The approach is demonstrated in a case study on traffic monitoring featuring a diverse set of AI/ML services based on deep neural networks and heuristic reasoning approaches.","",""
0,"Yixuan Li","Scalable , Interpretable and Robust Machine Intelligence For The Web ( Research Statement )",,"","","","",49,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,,"(Research Statement) Yixuan Li PhD Candidate, Cornell University Machine learning is a method that can learn from and make predictions on data, and has been placed at the core of many computing tasks when devising explicit ​algorithms​ is unfeasible (e.g., search engines, spam filtering, and computer vision). The excitement of web-driven machine learning research comes at two different granularity levels: on one hand, it enables us to model the complex interactions among web users and web components in the abstract; and on the other hand, it provides us with an automated means for comprehending concrete web contents such as texts, images and audios. Through the lens of machine learning and perception, my thesis research is a quest for gleaning insight from web-scale data in perspectives of ​web user interactions and ​web content comprehension​.","",""
2,"Min Lu, H. Ishwaran","A Machine Learning Alternative to P-values",2017,"","","","",50,"2022-07-13 09:39:14","","","","",,,,,2,0.40,1,2,5,"This paper presents an alternative approach to p-values in regression settings. This approach, whose origins can be traced to machine learning, is based on the leave-one-out bootstrap for prediction error. In machine learning this is called the out-of-bag (OOB) error. To obtain the OOB error for a model, one draws a bootstrap sample and fits the model to the in-sample data. The out-of-sample prediction error for the model is obtained by calculating the prediction error for the model using the out-of-sample data. Repeating and averaging yields the OOB error, which represents a robust cross-validated estimate of the accuracy of the underlying model. By a simple modification to the bootstrap data involving ""noising up"" a variable, the OOB method yields a variable importance (VIMP) index, which directly measures how much a specific variable contributes to the prediction precision of a model. VIMP provides a scientifically interpretable measure of the effect size of a variable, we call the ""predictive effect size"", that holds whether the researcher's model is correct or not, unlike the p-value whose calculation is based on the assumed correctness of the model. We also discuss a marginal VIMP index, also easily calculated, which measures the marginal effect of a variable, or what we call ""the discovery effect"". The OOB procedure can be applied to both parametric and nonparametric regression models and requires only that the researcher can repeatedly fit their model to bootstrap and modified bootstrap data. We illustrate this approach on a survival data set involving patients with systolic heart failure and to a simulated survival data set where the model is incorrectly specified to illustrate its robustness to model misspecification.","",""
0,"Thomas Raffinot","Asset Allocation, Economic Cycles and Machine Learning",2017,"","","","",51,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,5,"A well-worked theory of macro-based investment decision is introduced. The theoretical influence of economic cycles on time-varying risk premiums is explained and exhibited. The importance of the turning points of the growth cycle, better known as the output gap, is outlined. To quickly and accurately detect economic turning points, probabilistic indicators are first created from a simple and transparent machine-learning algorithm known as Learning Vector Quantization. Those indicators are robust, interpretable and preserve economic consistency. A more complex approach is then evaluated: ensemble machine learning algorithms, referred to as random forest and as boosting, are applied. The two key features of those algorithms are their abilities to entertain a large number of predictors and to perform estimation and variable selection simultaneously. With both approaches investment strategies based on the models achieve impressive risk-adjusted returns: timing the market is thus possible. At last, exploring a new way of capital allocation, a hierarchical clustering based asset allocation method is introduced. The empirical results indicate that hierarchical clustering based portfolios are robust, truly diversified and achieve statistically better risk-adjusted performances than commonly used portfolio optimization techniques.","",""
0,"J. Sanz","SS11: Soft Computing Techniques for Machine Learning",2017,"","","","",52,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,5,"This special session is aimed at discussing recent and novel fuzzy methods to deal with the current challenges on machine learning. This research field is very active due to the large number of real-world problems that can be faced using techniques of this field. The canonical problems of this area of research are classification, regression and clustering. However, in recent years there are a great number of hot topics like the problem of imbalanced data, low quality and/or noisy instances, semi-supervised learning or multi-label and multi-instance problems among others. When tackling the previously mentioned problems, soft computing techniques are widely applied. Specifically, fuzzy systems are a common tool as they provide an interpretable model understandable by human beings whilst the results obtained are accurate, since fuzzy logic has an inherent ability to cope with the great uncertainty present in these new challenging problems. Evolutionary computation is a robust technique for optimization, learning and adaptation tasks. They can adjust the model parameters for each specific problem for the sake of enhancing their performance. The synergy between these two techniques leads to a better capability for the design and optimization of fuzzy models. Moreover, Big Data also offers new possibilities for fuzzy methods, where new challenges appear with respect to their scalability when dealing with enormous amounts of data. The special session is composed of seven contributions dealing with different topics of the machine learning field.","",""
11,"Henry Kenlay, D. Thanou, Xiaowen Dong","Interpretable Stability Bounds for Spectral Graph Filters",2021,"","","","",53,"2022-07-13 09:39:14","","","","",,,,,11,11.00,4,3,1,"Graph-structured data arise in a variety of realworld context ranging from sensor and transportation to biological and social networks. As a ubiquitous tool to process graph-structured data, spectral graph filters have been used to solve common tasks such as denoising and anomaly detection, as well as design deep learning architectures such as graph neural networks. Despite being an important tool, there is a lack of theoretical understanding of the stability properties of spectral graph filters, which are important for designing robust machine learning models. In this paper, we study filter stability and provide a novel and interpretable upper bound on the change of filter output, where the bound is expressed in terms of the endpoint degrees of the deleted and newly added edges, as well as the spatial proximity of those edges. This upper bound allows us to reason, in terms of structural properties of the graph, when a spectral graph filter will be stable. We further perform extensive experiments to verify intuition that can be gained from the bound.","",""
3,"Tao Peng, Jingxu Zhao, Jing Wang","Interpretable Mathematical Model-guided Ultrasound Prostate Contour Extraction Using Data Mining Techniques",2021,"","","","",54,"2022-07-13 09:39:14","","10.1109/BIBM52615.2021.9669419","","",,,,,3,3.00,1,3,1,"Among all image features, the contour is one of the most critical features for displaying the shape of the object intuitively. Due to unseen/missing regions of transrectal ultrasound images caused by imaging artifacts and limited field of view, accurate and robust ultrasound prostate contour extraction is challenging. Hence, we propose a triple cascaded framework for ultrasound prostate contour extraction using a few existing points as the prior. The proposed scheme contains two types of data mining: principal curve-based and machine learning-based methods. The first stage is using an improved polygonal segment method to obtain a contour composed of line segments connected by sorted vertices, where only a few radiologist-defined seed points are used as the prior. The second stage is to achieve an optimal machine learning-based approach based on an improved differential evolution-based method. The third stage is to find a map function (realized by the machine learning-based method) to generate the smooth contour represented by the output of neural network (i.e., optimized vertices) to match the ground truth contour. Our results demonstrated that the performance of the proposed method outperformed several other state-of-the-art methods.","",""
2,"K. Yan, Adam P. Harrison","Interpretable Medical Image Classification with Self-Supervised Anatomical Embedding and Prior Knowledge",2021,"","","","",55,"2022-07-13 09:39:14","","","","",,,,,2,2.00,1,2,1,"In medical image analysis tasks, it is important to make machine learning models focus on correct anatomical locations, so as to improve interpretability and robustness of the model. We adopt a latest algorithm called self-supervised anatomical embedding (SAM) to locate point of interest (POI) on computed tomography (CT) scans. SAM can detect arbitrary POI with only one labeled sample needed. Then, we can extract targeted features from the POIs to train a simple prediction model guided by clinical prior knowledge. This approach mimics the practice of human radiologists, thus is interpretable, controllable, and robust. We illustrate our approach on the application of CT contrast phase classification and it outperforms an existing deep learning based method trained on the whole image.","",""
1,"Yipei Wang, Xiaoqian Wang","Self-Interpretable Model with TransformationEquivariant Interpretation",2021,"","","","",56,"2022-07-13 09:39:14","","","","",,,,,1,1.00,1,2,1,"With the proliferation of machine learning applications in the real world, the demand for explaining machine learning predictions continues to grow especially in high-stakes fields. Recent studies have found that interpretation methods can be sensitive and unreliable, where the interpretations can be disturbed by perturbations or transformations of input data. To address this issue, we propose to learn robust interpretations through transformation equivariant regularization in a self-interpretable model. The resulting model is capable of capturing valid interpretations that are equivariant to geometric transformations. Moreover, since our model is self-interpretable, it enables faithful interpretations that reflect the true predictive mechanism. Unlike existing self-interpretable models, which usually sacrifice expressive power for the sake of interpretation quality, our model preserves the high expressive capability comparable to the state-of-the-art deep learning models in complex tasks, while providing visualizable and faithful highquality interpretation. We compare with various related methods and validate the interpretation quality and consistency of our model.","",""
1,"T. Bai, Xue Zhu, Xiang Zhou, D. Grathwohl, Pengshuo Yang, Yuguo Zha, Yu Jin, Hui Chong, Qing-Yang Yu, N. Isberner, Dongke Wang, Lei Zhang, K. M. Kortüm, Jun Song, L. Rasche, H. Einsele, K. Ning, X. Hou","Reliable and Interpretable Mortality Prediction With Strong Foresight in COVID-19 Patients: An International Study From China and Germany",2020,"","","","",57,"2022-07-13 09:39:14","","10.3389/frai.2021.672050","","",,,,,1,0.50,0,18,2,"Cohort-independent robust mortality prediction model in patients with COVID-19 infection is not yet established. To build up a reliable, interpretable mortality prediction model with strong foresight, we have performed an international, bi-institutional study from China (Wuhan cohort, collected from January to March) and Germany (Würzburg cohort, collected from March to September). A Random Forest-based machine learning approach was applied to 1,352 patients from the Wuhan cohort, generating a mortality prediction model based on their clinical features. The results showed that five clinical features at admission, including lymphocyte (%), neutrophil count, C-reactive protein, lactate dehydrogenase, and α-hydroxybutyrate dehydrogenase, could be used for mortality prediction of COVID-19 patients with more than 91% accuracy and 99% AUC. Additionally, the time-series analysis revealed that the predictive model based on these clinical features is very robust over time when patients are in the hospital, indicating the strong association of these five clinical features with the progression of treatment as well. Moreover, for different preexisting diseases, this model also demonstrated high predictive power. Finally, the mortality prediction model has been applied to the independent Würzburg cohort, resulting in high prediction accuracy (with above 90% accuracy and 85% AUC) as well, indicating the robustness of the model in different cohorts. In summary, this study has established the mortality prediction model that allowed early classification of COVID-19 patients, not only at admission but also along the treatment timeline, not only cohort-independent but also highly interpretable. This model represents a valuable tool for triaging and optimizing the resources in COVID-19 patients.","",""
1,"Burim Ramosaj","Interpretable Machines: Constructing Valid Prediction Intervals with Random Forests",2021,"","","","",58,"2022-07-13 09:39:14","","","","",,,,,1,1.00,1,1,1,"An important issue when using Machine Learning algorithms in recent research is the lack of interpretability. Although these algorithms provide accurate point predictions for various learning problems, uncertainty estimates connected with point predictions are rather sparse. A contribution to this gap for the Random Forest Regression Learner is presented here. Based on its Out-of-Bag procedure, several parametric and nonparametric prediction intervals are provided for Random Forest point predictions and theoretical guarantees for its correct coverage probability is delivered. In a second part, a thorough investigation through MonteCarlo simulation is conducted evaluating the performance of the proposed methods from three aspects: (i) Analyzing the correct coverage rate of the proposed prediction intervals, (ii) Inspecting interval width and (iii) Verifying the competitiveness of the proposed intervals with existing methods. The simulation yields that the proposed prediction intervals are robust towards non-normal residual distributions and are competitive by providing correct coverage rates and comparably narrow interval lengths, even for comparably small samples.","",""
0,"Evan M. Yu, Alan Q. Wang, Adrian V. Dalca, M. Sabuncu","KeypointMorph: Robust Multi-modal A ne Registration via Unsupervised Keypoint Detection",2021,"","","","",59,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,4,1,"Registration is a fundamental task in medical imaging, and recent machine learning methods have become the state-of-the-art. However, these approaches are often not interpretable, lack robustness to large misalignments, and do not incorporate symmetries of the problem. In this work, we propose KeypointMorph, an unsupervised end-to-end learningbased image registration framework that relies on automatically detecting corresponding keypoints. Our core insight is straightforward: matching keypoints between images can be used to obtain the optimal transformation via a di↵erentiable closed-form expression. We use this observation to drive the unsupervised learning of anatomically-consistent keypoints from images. This not only leads to substantially more robust registration but also yields better interpretability, since the keypoints reveal which parts of the image are driving the final alignment. Moreover, KeypointMorph can be designed to be equivariant under image translations and/or symmetric with respect to the input image ordering. We demonstrate the proposed framework in solving 3D a ne registration of multi-modal brain MRI scans. Remarkably, we show that this strategy leads to consistent keypoints, even across modalities. We demonstrate registration accuracy that surpasses current state-of-the-art methods, especially in the context of large displacements. Our code is available at URL1","",""
6,"Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao","Explainable Tsetlin Machine framework for fake news detection with credibility score assessment",2021,"","","","",60,"2022-07-13 09:39:14","","","","",,,,,6,6.00,2,3,1,"The proliferation of fake news, i.e., news intentionally spread for misinformation, poses a threat to individuals and society. Despite various fact-checking websites such as PolitiFact, robust detection techniques are required to deal with the increase in fake news. Several deep learning models show promising results for fake news classification, however, their black-box nature makes it difficult to explain their classification decisions and qualityassure the models. We here address this problem by proposing a novel interpretable fake news detection framework based on the recently introduced Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to capture lexical and semantic properties of both true and fake news text. Further, we use the clause ensembles to calculate the credibility of fake news. For evaluation, we conduct experiments on two publicly available datasets, PolitiFact and GossipCop, and demonstrate that the TM framework significantly outperforms previously published baselines by at least 5% in terms of accuracy, with the added benefit of an interpretable logicbased representation. Further, our approach provides higher F1-score than BERT and XLNet, however, we obtain slightly lower accuracy. We finally present a case study on our model’s explainability, demonstrating how it decomposes into meaningful words and their negations.","",""
3,"Fabian Berns, Markus Lange-Hegermann, C. Beecks","Towards Gaussian Processes for Automatic and Interpretable Anomaly Detection in Industry 4.0",2020,"","","","",61,"2022-07-13 09:39:14","","10.5220/0010130300870092","","",,,,,3,1.50,1,3,2,"Discerning unexpected from expected data patterns is the key challenge of anomaly detection. Although a multitude of solutions has been applied to this modern Industry 4.0 problem, it remains an open research issue to identify the key characteristics subjacent to an anomaly, sc. generate hypothesis as to why they appear. In recent years, machine learning models have been regarded as universal solution for a wide range of problems. While most of them suffer from non-self-explanatory representations, Gaussian Processes (GPs) deliver interpretable and robust statistical data models, which are able to cope with unreliable, noisy, or partially missing data. Thus, we regard them as a suitable solution for detecting and appropriately representing anomalies and their respective characteristics. In this position paper, we discuss the problem of automatic and interpretable anomaly detection by means of GPs. That is, we elaborate on why GPs are well suited for anomaly detection and what the current challenges are when applying these probabilistic models to large-scale production data.","",""
5,"Tong Zeng, Daniel Ernesto Acuna","Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models",2020,"","","","",62,"2022-07-13 09:39:14","","10.1007/s11192-020-03421-9","","",,,,,5,2.50,3,2,2,"","",""
12,"Yibo Yang, M. A. Bhouri, P. Perdikaris","Bayesian differential programming for robust systems identification under uncertainty",2020,"","","","",63,"2022-07-13 09:39:14","","10.1098/rspa.2020.0290","","",,,,,12,6.00,4,3,2,"This paper presents a machine learning framework for Bayesian systems identification from noisy, sparse and irregular observations of nonlinear dynamical systems. The proposed method takes advantage of recent developments in differentiable programming to propagate gradient information through ordinary differential equation solvers and perform Bayesian inference with respect to unknown model parameters using Hamiltonian Monte Carlo sampling. This allows an efficient inference of the posterior distributions over plausible models with quantified uncertainty, while the use of sparsity-promoting priors enables the discovery of interpretable and parsimonious representations for the underlying latent dynamics. A series of numerical studies is presented to demonstrate the effectiveness of the proposed methods, including nonlinear oscillators, predator–prey systems and examples from systems biology. Taken together, our findings put forth a flexible and robust workflow for data-driven model discovery under uncertainty. All codes and data accompanying this article are available at https://bit.ly/34FOJMj.","",""
38,"Hassan Ismail Fawaz, G. Forestier, J. Weber, L. Idoumghar, Pierre-Alain Muller","Accurate and interpretable evaluation of surgical skills from kinematic data using fully convolutional neural networks",2019,"","","","",64,"2022-07-13 09:39:14","","10.1007/s11548-019-02039-4","","",,,,,38,12.67,8,5,3,"","",""
13,"Michal Balazia, Petr Sojka","Learning robust features for gait recognition by Maximum Margin Criterion",2016,"","","","",65,"2022-07-13 09:39:14","","10.1109/ICPR.2016.7899750","","",,,,,13,2.17,7,2,6,"In the field of gait recognition from motion capture data, designing human-interpretable gait features is a common practice of many fellow researchers. To refrain from ad-hoc schemes and to find maximally discriminative features we may need to explore beyond the limits of human interpretability. This paper contributes to the state-of-the-art with a machine learning approach for extracting robust gait features directly from raw joint coordinates. The features are learned by a modification of Linear Discriminant Analysis with Maximum Margin Criterion so that the identities are maximally separated and, in combination with an appropriate classifier, used for gait recognition. Experiments on the CMU MoCap database show that this method outperforms eight other relevant methods in terms of the distribution of biometric templates in respective feature spaces expressed in four class separability coefficients. Additional experiments indicate that this method is a leading concept for rank-based classifier systems.","",""
0,"Nahim Adnan, Maryam Zand, T. Huang, Jianhua Ruan","Construction and Evaluation of Robust Interpretation Models for Breast Cancer Metastasis Prediction",2021,"","","","",66,"2022-07-13 09:39:14","","10.1109/TCBB.2021.3120673","","",,,,,0,0.00,0,4,1,"Interpretability of machine learning (ML) models represents the extent to which a model’s decision-making process can be understood by model developers and/or end users. Transcriptomics-based cancer prognosis models, for example, while achieving good accuracy, are usually hard to interpret, due to the high-dimensional feature space and the complexity of models. As interpretability is critical for the transparency and fairness of ML models, several algorithms have been proposed to improve the interpretability of arbitrary classifiers. However, evaluation of these algorithms often requires substantial domain knowledge. Here, we propose a breast cancer metastasis prediction model using a very small number of biologically interpretable features, and a simple yet novel model interpretation approach that can provide personalized interpretations. In addition, we contributed, to the best of our knowledge, the first method to quantitatively compare different interpretation algorithms. Experimental results show that our model not only achieved competitive prediction accuracy, but also higher inter-classifier interpretation consistency than state-of-the-art interpretation methods. Importantly, our interpretation results can improve the generalizability of the prediction models. Overall, this work provides several novel ideas to construct and evaluate interpretable ML models that can be valuable to both the cancer machine learning community and related application domains.","",""
0,"Bruce Lee, Thomas T. C. K. Zhang, Hamed Hassani, N. Matni","Performance-Robustness Tradeoffs in Adversarially Robust Linear-Quadratic Control",2022,"","","","",67,"2022-07-13 09:39:14","","10.48550/arXiv.2203.10763","","",,,,,0,0.00,0,4,1,"While H∞ methods can introduce robustness against worst-case perturbations, their nominal performance under conventional stochastic disturbances is often drastically reduced. Though this fundamental tradeoff between nominal performance and robustness is known to exist, it is not well-characterized in quantitative terms. Toward addressing this issue, we borrow from the increasingly ubiquitous notion of adversarial training from machine learning to construct a class of controllers which are optimized for disturbances consisting of mixed stochastic and worst-case components. We find that this problem admits a stationary optimal controller that has a simple analytic form closely related to suboptimal H∞ solutions. We then provide a quantitative performance-robustness tradeoff analysis, in which systemtheoretic properties such as controllability and stability explicitly manifest in an interpretable manner. This provides practitioners with general guidance for determining how much robustness to incorporate based on a priori system knowledge. We empirically validate our results by comparing the performance of our controller against standard baselines, and plotting tradeoff curves.","",""
2,"Rupsa Saha, Ole-Christoffer Granmo, V. Zadorozhny, Morten Goodwin","A relational tsetlin machine with applications to natural language understanding",2021,"","","","",68,"2022-07-13 09:39:14","","10.1007/s10844-021-00682-5","","",,,,,2,2.00,1,4,1,"","",""
3,"M. Werner, Andrej Junginger, Philipp Hennig, G. Martius","Informed Equation Learning",2021,"","","","",69,"2022-07-13 09:39:14","","","","",,,,,3,3.00,1,4,1,"Distilling data into compact and interpretable analytic equations is one of the goals of science. Instead, contemporary supervised machine learning methods mostly produce unstructured and dense maps from input to output. Particularly in deep learning, this property is owed to the generic nature of simple standard link functions. To learn equations rather than maps, standard non-linearities can be replaced with structured building blocks of atomic functions. However, without strong priors on sparsity and structure, representational complexity and numerical conditioning limit this direct approach. To scale to realistic settings in science and engineering, we propose an informed equation learning system. It provides a way to incorporate expert knowledge about what are permitted or prohibited equation components, as well as a domain-dependent structured sparsity prior. Our system then utilizes a robust method to learn equations with atomic functions exhibiting singularities, as e.g. logarithm and division. We demonstrate several artificial and real-world experiments from the engineering domain, in which our system learns interpretable models of high predictive power.","",""
11,"B. Daniels, W. Ryu, I. Nemenman","Automated, predictive, and interpretable inference of Caenorhabditis elegans escape dynamics",2018,"","","","",70,"2022-07-13 09:39:14","","10.1073/pnas.1816531116","","",,,,,11,2.75,4,3,4,"Significance The cost of an empirical bit in biophysics has fallen dramatically, and high-precision data are now abundant. However, biological systems are notoriously complex, multiscale, and inhomogeneous, so that we often lack intuition for transforming such measurements into theoretical frameworks. Modern machine learning can be used as an aid. Here we apply our Sir Isaac platform for automatic inference of a model of the escape response behavior in a roundworm directly from time series data. The automatically constructed model is more accurate than that curated manually, is biophysically interpretable, and makes nontrivial predictions about the system. The roundworm Caenorhabditis elegans exhibits robust escape behavior in response to rapidly rising temperature. The behavior lasts for a few seconds, shows history dependence, involves both sensory and motor systems, and is too complicated to model mechanistically using currently available knowledge. Instead we model the process phenomenologically, and we use the Sir Isaac dynamical inference platform to infer the model in a fully automated fashion directly from experimental data. The inferred model requires incorporation of an unobserved dynamical variable and is biologically interpretable. The model makes accurate predictions about the dynamics of the worm behavior, and it can be used to characterize the functional logic of the dynamical system underlying the escape response. This work illustrates the power of modern artificial intelligence to aid in discovery of accurate and interpretable models of complex natural systems.","",""
1,"Keyang Cheng, Ning Wang, Maozhen Li","Interpretability of Deep Learning: A Survey",2020,"","","","",71,"2022-07-13 09:39:14","","10.1007/978-3-030-70665-4_54","","",,,,,1,0.50,0,3,2,"","",""
1,"S. Saha, A. Guzmán-Sáenz, A. Bose, F. Utro, D. Platt, L. Parida","RubricOE: a learning framework for genetic epidemiology",2021,"","","","",72,"2022-07-13 09:39:14","","10.1101/2021.03.09.21253105","","",,,,,1,1.00,0,6,1,"Genetic epidemiology is a growing area of interest in the past years due to the availability of genetic data with the decreasing cost of sequencing. Machine learning (ML) algorithms can be a very useful tool to study the genetic factors on disease incidence or on different traits characterizing a population. There are many challenges that plagues the field of genetic epidemiology including the unbalanced case-control data sets, fallibility of standard genome wide association studies with single marker analysis, heavily underdetermined systems with millions of markers in contrast of a few thousands of samples, to name a few. Ensemble ML methods can be a very useful tool to tackle many of these challenges and thus we propose RubricOE, a pipeline of ML algorithms with error bar computations to obtain interpretable genetic and non-genetic features from genomic or transcriptomic data combined with clinical factors in the form of electronic health records. RubricOE is shown to be robust in simulation studies, detecting true associations with traits of interest in arbitrarily structured multi-ethnic populations. It also finds functionally significant biological pathways related to progression of neurodegenerative diseases when applied on a cohort of Parkinson's Disease patients and corresponding controls.","",""
3,"Alexander Jordan, François Gauthier, Behnaz Hassanshahi, David Zhao","Unacceptable Behavior: Robust PDF Malware Detection Using Abstract Interpretation",2019,"","","","",73,"2022-07-13 09:39:14","","10.1145/3338504.3357341","","",,,,,3,1.00,1,4,3,"The popularity of the PDF format and the rich JavaScript environment that PDF viewers offer make PDF documents an attractive attack vector for malware developers. PDF documents present a serious threat to the security of organizations because most users are unsuspecting of them and thus likely to open documents from untrusted sources. State-of-the-art approaches use machine learning to learn features that characterize PDF malware, which makes them subject to adversarial attacks that mimic the structure of benign documents. In this paper, we instead propose to detect malicious code inside a PDF by statically reasoning about its possible behavior using abstract interpretation. A comparison with state-of-the-art PDF malware detection tools shows that our conservative abstract interpretation approach achieves similar accuracy, is more resilient to evasion attacks, and provides interpretable reports.","",""
2,"Hossein Tavakoli, Jahan B. Ghasemi","An improved ensemble learning machine for biological activity prediction of tyrosine kinase inhibitors",2015,"","","","",74,"2022-07-13 09:39:14","","10.1002/cem.2698","","",,,,,2,0.29,1,2,7,"Boosting is one of the most important strategies in ensemble learning because of its ability to improve the stability and performance of weak learners. It is nonparametric, multivariate, fast and interpretable but is not robust against outliers. To enhance its prediction accuracy as well as immunize it against outliers, a modified version of a boosting algorithm (AdaBoost R2) was developed and called AdaBoost R3. In the sampling step, extremum samples were added to the boosting set. In the robustness step, a modified Huber loss function was applied to overcome the outlier problem. In the output step, a deterministic threshold was used to guarantee that bad predictions do not participate in the final output. The performance of the modified algorithm was investigated with two anticancer data sets of tyrosine kinase inhibitors, and the mechanism of inhibition was studied using the relative weighted variable importance procedure. Investigating the effect of base learner's strength reveals that boosting is only successful using the classification and regression tree method (a weak to moderate learner) and does not have a significant effect using the radial basis functions partial least square method (a strong base learners). Copyright © 2015 John Wiley & Sons, Ltd.","",""
35,"A. Malinin","Uncertainty estimation in deep learning with application to spoken language assessment",2019,"","","","",75,"2022-07-13 09:39:14","","10.17863/CAM.45912","","",,,,,35,11.67,35,1,3,"Since convolutional neural networks (CNNs) achieved top performance on the ImageNet task in 2012, deep learning has become the preferred approach to addressing computer vision, natural language processing, speech recognition and bio-informatics tasks. However, despite impressive performance, neural networks tend to make over-confident predictions. Thus, it is necessary to investigate robust, interpretable and tractable estimates of uncertainty in a model’s predictions in order to construct safer Machine Learning systems. This is crucial to applications where the cost of an error is high, such as in autonomous vehicle control, high-stakes automatic proficiency assessment and in the medical, financial and legal fields. In the first part of this thesis uncertainty estimation via ensemble and single-model approaches is discussed in detail and a new class of models for uncertainty estimation, called Prior Networks, is proposed. Prior Networks are able to emulate an ensemble of models using a single deterministic neural network, which allows sources of uncertainty to be determined within the same probabilistic framework as in ensemble-based approaches, but with the computational simplicity and ease of training of single-model approaches. Thus, Prior Networks combine the advantages of ensemble and single-model approaches to estimating uncertainty. In this thesis Prior Networks are evaluated on a range classification datasets, where they are shown to outperform baseline approaches, such as Monte-Carlo dropout, on the task of detecting out-of-distribution inputs. In the second part of this thesis deep learning and uncertainty estimation approaches are applied to the area of automatic assessment of non-native spoken language proficiency. Specifically deep-learning based graders and spoken response relevance assessment systems are constructed using data from the BULATS and LinguaSkill exams, provided by Cambridge English Language Assessment. Baseline approaches for uncertainty estimation discussed and evaluated in the first half of the thesis are then applied to these models and assessed on the task of rejecting predictions to be graded by human examiners and detecting misclassifications.","",""
0,"","Differential Equations as Model Prior for Deep Learning and Applications to Robotics",2020,"","","","",76,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,0,2,"For many decades, much of the scientific knowledge of physics and engineering has been expressed via differential equations. These differential equations describe the underlying phenomena and the relations between different interpretable quantities. Therefore, differential equations are a promising approach to incorporate prior knowledge in machine learning models to obtain robust and interpretable models. Especially, deep networks and differential equations fit naturally as deep networks are differentiable and enable the computation of the partial derivatives in closed form at machine precision (Raissi & Karniadakis, 2018). Therefore, combining deep networks and differential equations is a promising approach to constrain deep networks to learn meaningful representations.","",""
5,"Morten Källberg, Hui Lu","An improved machine learning protocol for the identification of correct Sequest search results",2010,"","","","",77,"2022-07-13 09:39:14","","10.1186/1471-2105-11-591","","",,,,,5,0.42,3,2,12,"","",""
0,"M. Lutter, Jan Peters","Differential Equations as a Model Prior for Deep Learning and its Applications in Robotics",2020,"","","","",78,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,2,"For many decades, much of the scientific knowledge of physics and engineering has been expressed via differential equations. These differential equations describe the underlying phenomena and the relations between different interpretable quantities. Therefore, differential equations are a promising approach to incorporate prior knowledge in machine learning models to obtain robust and interpretable models. Especially, deep networks and differential equations fit naturally as deep networks are differentiable and enable the computation of the partial derivatives in closed form at machine precision (Raissi & Karniadakis, 2018). Therefore, combining deep networks and differential equations is a promising approach to constrain deep networks to learn meaningful representations.","",""
0,"B. Apolloni, E. Damiani","Learning Simplified Functions to Understand",2020,"","","","",79,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,2,"We propose an unprecedented approach to post-hoc interpretable machine learning. Facing a complex phenomenon, rather than fully capturing its mechanisms through a universal learner, albeit structured in modular building blocks, we train a robust neural network, no matter its complexity, to use as an oracle. Then we approximate its behavior via a linear combination of simple, explicit functions of its input. Simplicity is achieved by (i) marginal functions mapping individual inputs to the network output, (ii) the same consisting of univariate polynomials with a low degree,(iii) a small number of polynomials being involved in the linear combination, whose input is properly granulated. With this contrivance, we handle various real-world learning scenarios arising from expertise and experimental frameworks’ composition. They range from cooperative training instances to transfer learning. Concise theoretical considerations and comparative numerical experiments further detail and support the proposed approach .","",""
0,"Jiadong Dan, Xiaoxu Zhao, S. Ning, Jiong Lu, K. Loh, N. Loh, S. Pennycook","A hierarchical active-learning framework for classifying structural motifs in atomic resolution microscopy",2020,"","","","",80,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,7,2,"Progress in functional materials discovery has been accelerated by advances in high throughput materials synthesis and by the development of high-throughput computation. However, a complementary robust and high throughput structural characterization framework is still lacking. New methods and tools in the field of machine learning suggest that a highly automated high-throughput structural characterization framework based on atomic-level imaging can establish the crucial statistical link between structure and macroscopic properties. Here we develop a machine learning framework towards this goal. Our framework captures local structural features in images with Zernike polynomials, which is demonstrably noise-robust, flexible, and accurate. These features are then classified into readily interpretable structural motifs with a hierarchical active learning scheme powered by a novel unsupervised two-stage relaxed clustering scheme. We have successfully demonstrated the accuracy and efficiency of the proposed methodology by mapping a full spectrum of structural defects, including point defects, line defects, and planar defects in scanning transmission electron microscopy (STEM) images of various 2D materials, with greatly improved separability over existing methods. Our techniques can be easily and flexibly applied to other types of microscopy data with complex features, providing a solid foundation for automatic, multiscale feature analysis with high veracity.","",""
140,"V. G. Krishnan, D. Westhead","A comparative study of machine-learning methods to predict the effects of single nucleotide polymorphisms on protein function",2003,"","","","",81,"2022-07-13 09:39:14","","10.1093/bioinformatics/btg297","","",,,,,140,7.37,70,2,19,"MOTIVATION The large volume of single nucleotide polymorphism data now available motivates the development of methods for distinguishing neutral changes from those which have real biological effects. Here, two different machine-learning methods, decision trees and support vector machines (SVMs), are applied for the first time to this problem. In common with most other methods, only non-synonymous changes in protein coding regions of the genome are considered.   RESULTS In detailed cross-validation analysis, both learning methods are shown to compete well with existing methods, and to out-perform them in some key tests. SVMs show better generalization performance, but decision trees have the advantage of generating interpretable rules with robust estimates of prediction confidence. It is shown that the inclusion of protein structure information produces more accurate methods, in agreement with other recent studies, and the effect of using predicted rather than actual structure is evaluated.   AVAILABILITY Software is available on request from the authors.","",""
28,"Sunghwan Kim, Chien-Wei Lin, G. Tseng","MetaKTSP: a meta-analytic top scoring pair method for robust cross-study validation of omics prediction analysis",2016,"","","","",82,"2022-07-13 09:39:14","","10.1093/bioinformatics/btw115","","",,,,,28,4.67,9,3,6,"MOTIVATION Supervised machine learning is widely applied to transcriptomic data to predict disease diagnosis, prognosis or survival. Robust and interpretable classifiers with high accuracy are usually favored for their clinical and translational potential. The top scoring pair (TSP) algorithm is an example that applies a simple rank-based algorithm to identify rank-altered gene pairs for classifier construction. Although many classification methods perform well in cross-validation of single expression profile, the performance usually greatly reduces in cross-study validation (i.e. the prediction model is established in the training study and applied to an independent test study) for all machine learning methods, including TSP. The failure of cross-study validation has largely diminished the potential translational and clinical values of the models. The purpose of this article is to develop a meta-analytic top scoring pair (MetaKTSP) framework that combines multiple transcriptomic studies and generates a robust prediction model applicable to independent test studies.   RESULTS We proposed two frameworks, by averaging TSP scores or by combining P-values from individual studies, to select the top gene pairs for model construction. We applied the proposed methods in simulated data sets and three large-scale real applications in breast cancer, idiopathic pulmonary fibrosis and pan-cancer methylation. The result showed superior performance of cross-study validation accuracy and biomarker selection for the new meta-analytic framework. In conclusion, combining multiple omics data sets in the public domain increases robustness and accuracy of the classification model that will ultimately improve disease understanding and clinical treatment decisions to benefit patients.   AVAILABILITY AND IMPLEMENTATION An R package MetaKTSP is available online. (http://tsenglab.biostat.pitt.edu/software.htm).   CONTACT ctseng@pitt.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
0,"Samuel Madden","AutoFE : Efficient and Robust Automated Feature Engineering by Hyunjoon Song",2018,"","","","",83,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,4,"Feature engineering is the key to building highly successful machine learning models. We present AutoFE, a system designed to automate feature engineering. AutoFE generates a large set of new interpretable features by combining information in the original features. Given an augmented dataset, it discovers a set of features that significantly improves the performance of any traditional classification using an evolutionary algorithm. We demonstrate the effectiveness and robustness of our approach by conducting an extensive evaluation on 8 datasets and 5 different classification algorithms. We show that AutoFE can achieve an average improvement in predictive performance of 25.24% for all classification algorithms over their baseline performance obtained with the original features. Thesis Supervisor: Samuel Madden Title: Professor of Electrical Engineering and Computer Science","",""
2,"Xin Qiu, Yuanjia Wang","Composite interaction tree for simultaneous learning of optimal individualized treatment rules and subgroups",2019,"","","","",84,"2022-07-13 09:39:14","","10.1002/sim.8105","","",,,,,2,0.67,1,2,3,"Treatment response heterogeneity has long been observed in patients affected by chronic diseases. Administering an individualized treatment rule (ITR) offers an opportunity to tailor treatment strategies according to patient‐specific characteristics. Overly complex machine learning methods for estimating ITRs may produce treatment rules that have higher benefit but lack transparency and interpretability. In clinical practices, it is desirable to derive a simple and interpretable ITR while maintaining certain optimality that leads to improved benefit in subgroups of patients, if not on the overall sample. In this work, we propose a tree‐based robust learning method to estimate optimal piecewise linear ITRs and identify subgroups of patients with a large benefit. We achieve these goals by simultaneously identifying qualitative and quantitative interactions through a tree model, referred to as the composite interaction tree (CITree). We show that it has improved performance compared to existing methods on both overall sample and subgroups via extensive simulation studies. Lastly, we fit CITree to Research Evaluating the Value of Augmenting Medication with Psychotherapy trial for treating patients with major depressive disorders, where we identified both qualitative and quantitative interactions and subgroups of patients with a large benefit.","",""
3,"Barbara Rychalska, Dominika Basaj, P. Biecek","Are you tough enough? Framework for Robustness Validation of Machine Comprehension Systems",2018,"","","","",85,"2022-07-13 09:39:14","","","","",,,,,3,0.75,1,3,4,"Deep Learning NLP domain lacks procedures for the analysis of model robustness. In this paper we propose a framework which validates robustness of any Question Answering model through model explainers. We propose that a robust model should transgress the initial notion of semantic similarity induced by word embeddings to learn a more human-like understanding of meaning. We test this property by manipulating questions in two ways: swapping important question word for 1) its semantically correct synonym and 2) for word vector that is close in embedding space. We estimate importance of words in asked questions with Locally Interpretable Model Agnostic Explanations method (LIME). With these two steps we compare state-of-the-art Q&A models. We show that although accuracy of state-of-the-art models is high, they are very fragile to changes in the input. Moreover, we propose 2 adversarial training scenarios which raise model sensitivity to true synonyms by up to 7% accuracy measure. Our findings help to understand which models are more stable and how they can be improved. In addition, we have created and published a new dataset that may be used for validation of robustness of a Q&A model.","",""
7,"Shashanka Ubaru, Kesheng Wu, K. Bouchard","UoI-NMF Cluster: A Robust Nonnegative Matrix Factorization Algorithm for Improved Parts-Based Decomposition and Reconstruction of Noisy Data",2017,"","","","",86,"2022-07-13 09:39:14","","10.1109/ICMLA.2017.0-152","","",,,,,7,1.40,2,3,5,"With the ever growing collection of large volumes of scientific data, development of interpretable machine learning tools to analyze such data is becoming more important. However, robust, interpretable machine learning tools are lacking, threatening extraction of scientific insight and discovery. Nonnegative Matrix Factorization (NMF) algorithms decompose an m × n nonnegative data matrix A into a k × n basis matrix H and an m × k weight matrix W, such that A ≈ WH, where k is the desired rank. In this paper, we present a novel two stage algorithm, UoI-NMF_cluster for NMF, which is based on three innovations: (i) completely separate bases learning from weight estimation, (ii) learn bases by clustering NMF results across bootstrap resamples of the data, and (iii) use the recently introduced Union of Intersections (UoI) framework to estimate ultra-sparse weights that maximize data reconstruction accuracy. We deploy our algorithm on various synthetic and scientific data to illustrate its performance, with a focus on neuroscience data. Compared to other NMF algorithms, UoI-NMF_cluster yields: a) more accurate parts-based decompositions of noisy data, b) a sparse and accurate weight matrix, and c) high accuracy reconstructions of the de-noised data. Together, these improvements enhance the performance and interpretability of NMF application to noisy data, and suggest similar approaches may benefit other matrix decomposition algorithms.","",""
17,"I. Wieczorek","Improved Software Cost Estimation – A Robust and Interpretable Modelling Method and a Comprehensive Empirical Investigation",2002,"","","","",87,"2022-07-13 09:39:14","","10.1023/A:1015206216560","","",,,,,17,0.85,17,1,20,"","",""
6,"Jayaraman J. Thiagarajan, Rushil Anirudh, B. Kailkhura, Nikhil Jain, T. Islam, A. Bhatele, Jae-Seung Yeom, T. Gamblin","PADDLE: Performance Analysis Using a Data-Driven Learning Environment",2018,"","","","",88,"2022-07-13 09:39:14","","10.1109/IPDPS.2018.00088","","",,,,,6,1.50,1,8,4,"The use of machine learning techniques to model execution time and power consumption, and, more generally, to characterize performance data is gaining traction in the HPC community. Although this signifies huge potential for automating complex inference tasks, a typical analytics pipeline requires selecting and extensively tuning multiple components ranging from feature learning to statistical inferencing to visualization. Further, the algorithmic solutions often do not generalize between problems, thereby making it cumbersome to design and validate machine learning techniques in practice. In order to address these challenges, we propose a unified machine learning framework, PADDLE, which is specifically designed for problems encountered during analysis of HPC data. The proposed framework uses an information-theoretic approach for hierarchical feature learning and can produce highly robust and interpretable models. We present user-centric workflows for using PADDLE and demonstrate its effectiveness in different scenarios: (a) identifying causes of network congestion; (b) determining the best performing linear solver for sparse matrices; and (c) comparing performance characteristics of parent and proxy application pairs.","",""
224,"Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, P. Blunsom","e-SNLI: Natural Language Inference with Natural Language Explanations",2018,"","","","",89,"2022-07-13 09:39:14","","","","",,,,,224,56.00,56,4,4,"In order for machine learning to garner widespread public adoption, models must be able to provide interpretable and robust explanations for their decisions, as well as learn from human-provided explanations at train time. In this work, we extend the Stanford Natural Language Inference dataset with an additional layer of human-annotated natural language explanations of the entailment relations. We further implement models that incorporate these explanations into their training process and output them at test time. We show how our corpus of explanations, which we call e-SNLI, can be used for various goals, such as obtaining full sentence justifications of a model’s decisions, improving universal sentence representations and transferring to out-of-domain NLI datasets. Our dataset thus opens up a range of research directions for using natural language explanations, both for improving models and for asserting their trust","",""
4,"Hang Ren, Weiqun Xu, Yonghong Yan","Optimizing human-interpretable dialog management policy using genetic algorithm",2015,"","","","",90,"2022-07-13 09:39:14","","10.1109/ASRU.2015.7404869","","",,,,,4,0.57,1,3,7,"Automatic optimization of spoken dialog management policies that are robust to environmental noise has long been the goal for both academia and industry. Approaches based on reinforcement learning have been proved to be effective. However, the numerical representation of dialog policy is human-incomprehensible and difficult for dialog system designers to verify or modify, which limits its practical application. In this paper we propose a novel framework for optimizing dialog policies specified in domain language using genetic algorithm. The human-interpretable representation of policy makes the method suitable for practical employment. We present learning algorithms using user simulation and real human-machine dialogs respectively. Empirical experimental results are given to show the effectiveness of the proposed approach.","",""
180,"Noah D. Brenowitz, C. Bretherton","Prognostic Validation of a Neural Network Unified Physics Parameterization",2018,"","","","",91,"2022-07-13 09:39:14","","10.1029/2018GL078510","","",,,,,180,45.00,90,2,4,"Weather and climate models approximate diabatic and sub‐grid‐scale processes in terms of grid‐scale variables using parameterizations. Current parameterizations are designed by humans based on physical understanding, observations, and process modeling. As a result, they are numerically efficient and interpretable, but potentially oversimplified. However, the advent of global high‐resolution simulations and observations enables a more robust approach based on machine learning. In this letter, a neural network‐based parameterization is trained using a near‐global aqua‐planet simulation with a 4‐km resolution (NG‐Aqua). The neural network predicts the apparent sources of heat and moisture averaged onto (160 km)2 grid boxes. A numerically stable scheme is obtained by minimizing the prediction error over multiple time steps rather than single one. In prognostic single‐column model tests, this scheme matches both the fluctuations and equilibrium of NG‐Aqua simulation better than the Community Atmosphere Model does.","",""
24,"Kui Yu, Xianjie Guo, Lin Liu, Jiuyong Li, Hao Wang, Zhaolong Ling, Xindong Wu","Causality-based Feature Selection",2019,"","","","",92,"2022-07-13 09:39:14","","10.1145/3409382","","",,,,,24,8.00,3,7,3,"Feature selection is a crucial preprocessing step in data analytics and machine learning. Classical feature selection algorithms select features based on the correlations between predictive features and the class variable and do not attempt to capture causal relationships between them. It has been shown that the knowledge about the causal relationships between features and the class variable has potential benefits for building interpretable and robust prediction models, since causal relationships imply the underlying mechanism of a system. Consequently, causality-based feature selection has gradually attracted greater attentions and many algorithms have been proposed. In this article, we present a comprehensive review of recent advances in causality-based feature selection. To facilitate the development of new algorithms in the research area and make it easy for the comparisons between new methods and existing ones, we develop the first open-source package, called CausalFS, which consists of most of the representative causality-based feature selection algorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we conduct extensive experiments to compare the representative algorithms with both synthetic and real-world datasets. Finally, we discuss some challenging problems to be tackled in future research.","",""
5,"Max Ryabinin, A. Malinin, M. Gales","Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets",2021,"","","","",93,"2022-07-13 09:39:14","","","","",,,,,5,5.00,2,3,1,"Ensembles of machine learning models yield improved system performance as well as robust and interpretable uncertainty estimates; however, their inference costs may often be prohibitively high. Ensemble Distribution Distillation is an approach that allows a single model to efficiently capture both the predictive performance and uncertainty estimates of an ensemble. For classification, this is achieved by training a Dirichlet distribution over the ensemble members’ output distributions via the maximum likelihood criterion. Although theoretically principled, this criterion exhibits poor convergence when applied to large-scale tasks where the number of classes is very high. In our work, we analyze this effect and show that for the Dirichlet log-likelihood criterion classes with low probability induce larger gradients than high-probability classes. This forces the model to focus on the distribution of the ensemble tail-class probabilities. We propose a new training objective which minimizes the reverse KL-divergence to a Proxy-Dirichlet target derived from the ensemble. This loss resolves the gradient issues of Ensemble Distribution Distillation, as we demonstrate both theoretically and empirically on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes, respectively.","",""
19,"Mohsen Hajiloo, H. Rabiee, Mahdi Anooshahpour","Fuzzy support vector machine: an efficient rule-based classification technique for microarrays",2013,"","","","",94,"2022-07-13 09:39:14","","10.1186/1471-2105-14-S13-S4","","",,,,,19,2.11,6,3,9,"","",""
4,"Longzhu Li, Yaojin Lin, Hong Zhao, Jinkun Chen, Shaozi Li","Causality‐based online streaming feature selection",2021,"","","","",95,"2022-07-13 09:39:14","","10.1002/cpe.6347","","",,,,,4,4.00,1,5,1,"Online streaming feature selection, as a well‐known and effective preprocessing approach in machine learning, is an eternal topic. Amount of online streaming feature selection algorithms have achieved a great deal of success in classification and prediction tasks. However, most of these existing algorithms only concentrate on the relevance between features and labels, and neglect the causal relationships between them. Discovering the potential causal relationships between features and labels, that is, the Markov blanket (MB) of class label, which can build a more interpretable and robust classification model. In this paper, we put forward a causality‐based online streaming feature selection algorithm with neighborhood conditional mutual information. First, we apply neighborhood symmetrical uncertainty to discover a candidate Markov blanket (CMB) with causal information. Then, neighborhood conditional mutual information instead of conditional independence test is used to delete the false positives in CMB, which can significantly alleviate the computational cost. Moreover, we utilize the updated CMB to choose the true spouses, which may be mistakenly deleted during the process of removing false positives, and then acquire an optimal MB as the online selected feature subset. Finally, causality‐based online streaming feature selection with neighborhood conditional mutual information is compared with four well‐established online streaming feature selection methods on 13 real‐world datasets. Experiment results show that the proposed algorithm outperforms these online streaming feature selection algorithms.","",""
2,"A. Tahmassebi, M. Motamedi, A. Alavi, A. Gandomi","An explainable prediction framework for engineering problems: case studies in reinforced concrete members modeling",2021,"","","","",96,"2022-07-13 09:39:14","","10.1108/EC-02-2021-0096","","",,,,,2,2.00,1,4,1,"PurposeEngineering design and operational decisions depend largely on deep understanding of applications that requires assumptions for simplification of the problems in order to find proper solutions. Cutting-edge machine learning algorithms can be used as one of the emerging tools to simplify this process. In this paper, we propose a novel scalable and interpretable machine learning framework to automate this process and fill the current gap.Design/methodology/approachThe essential principles of the proposed pipeline are mainly (1) scalability, (2) interpretibility and (3) robust probabilistic performance across engineering problems. The lack of interpretibility of complex machine learning models prevents their use in various problems including engineering computation assessments. Many consumers of machine learning models would not trust the results if they cannot understand the method. Thus, the SHapley Additive exPlanations (SHAP) approach is employed to interpret the developed machine learning models.FindingsThe proposed framework can be applied to a variety of engineering problems including seismic damage assessment of structures. The performance of the proposed framework is investigated using two case studies of failure identification in reinforcement concrete (RC) columns and shear walls. In addition, the reproducibility, reliability and generalizability of the results were validated and the results of the framework were compared to the benchmark studies. The results of the proposed framework outperformed the benchmark results with high statistical significance.Originality/valueAlthough, the current study reveals that the geometric input features and reinforcement indices are the most important variables in failure modes detection, better model can be achieved with employing more robust strategies to establish proper database to decrease the errors in some of the failure modes identification.","",""
2,"Marc T. Ratkovic, D. Tingley","Estimation and Inference on Nonlinear and Heterogeneous Effects∗",2021,"","","","",97,"2022-07-13 09:39:14","","","","",,,,,2,2.00,1,2,1,"Multiple regression has been the go-to method for data analysis for generations of scholars due to its transparency, interpretability, and desirable theoretical properties. However, the method’s simplicity precludes the discovery of complex heterogeneities in the data. We introduce the Method of Direct Estimation and Inference (MDEI) that embraces these potential complexities, is interpretable, has desirable theoretical guarantees, and, unlike some existing methods, returns appropriate uncertainty estimates. The proposed method uses a machine learning regression methodology to estimate the observation-level effect of a treatment variable. Importantly, we introduce a robust approach to uncertainty estimates. We provide simulation evidence and an application illustrating the performance of the method.","",""
1,"Aparna Balagopalan, Haoran Zhang, Kimia Hamidieh, Thomas Hartvigsen, F. Rudzicz, M. Ghassemi","The Road to Explainability is Paved with Bias: Measuring the Fairness of Explanations",2022,"","","","",98,"2022-07-13 09:39:14","","10.1145/3531146.3533179","","",,,,,1,1.00,0,6,1,"Machine learning models in safety-critical settings like healthcare are often “blackboxes”: they contain a large number of parameters which are not transparent to users. Post-hoc explainability methods where a simple, human-interpretable model imitates the behavior of these blackbox models are often proposed to help users trust model predictions. In this work, we audit the quality of such explanations for different protected subgroups using real data from four settings in finance, healthcare, college admissions, and the US justice system. Across two different blackbox model architectures and four popular explainability methods, we find that the approximation quality of explanation models, also known as the fidelity, differs significantly between subgroups. We also demonstrate that pairing explainability methods with recent advances in robust machine learning can improve explanation fairness in some settings. However, we highlight the importance of communicating details of non-zero fidelity gaps to users, since a single solution might not exist across all settings. Finally, we discuss the implications of unfair explanation models as a challenging and understudied problem facing the machine learning community.","",""
20,"Stefano Calzavara, C. Lucchese, Gabriele Tolomei, Seyum Assefa Abebe, S. Orlando","Treant: training evasion-aware decision trees",2019,"","","","",99,"2022-07-13 09:39:14","","10.1007/s10618-020-00694-9","","",,,,,20,6.67,4,5,3,"","",""
0,"Rongyao Hu, Xiaofeng Zhu, W. He, Jilian Zhang, Shichao Zhang","Supervised Feature Selection by Robust Sparse Reduced-Rank Regression",2016,"","","","",100,"2022-07-13 09:39:14","","10.1007/978-3-319-49586-6_50","","",,,,,0,0.00,0,5,6,"","",""
0,"David Alvarez-Melis, Harmanpreet Kaur, Hal Daum'e, H. Wallach, Jennifer Wortman Vaughan","A Human-Centered Interpretability Framework Based on Weight of Evidence",2021,"","","","",101,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,5,1,"In this paper, we take a human-centered approach to interpretable machine learning. First, drawing inspiration from the study of explanation in philosophy, cognitive science, and the social sciences, we propose a list of design principles for machinegenerated explanations that are meaningful to humans. Using the concept of weight of evidence from information theory, we develop a method for producing explanations that adhere to these principles. We show that this method can be adapted to handle high-dimensional, multi-class settings, yielding a flexible meta-algorithm for generating explanations. We demonstrate that these explanations can be estimated accurately from finite samples and are robust to small perturbations of the inputs. We also evaluate our method through a qualitative user study with machine learning practitioners, where we observe that the resulting explanations are usable despite some participants struggling with background concepts like prior class probabilities. Finally, we conclude by surfacing design implications for interpretability tools.","",""
0,"A. Dave, Hao Wang, R. Ponciroli, Richard B. Vilim","Numerical Demonstration of Multiple Actuator Constraint Enforcement Algorithm for a Molten Salt Loop",2022,"","","","",102,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,4,1,"To advance the paradigm of autonomous operation for nuclear power plants, a data-driven machine learning approach to control is sought. Autonomous operation for next-generation reactor designs is anticipated to bolster safety and improve economics. However, any algorithms that are utilized need to be interpretable, adaptable, and robust. Interpretable means that one can inspect and understand the underlying relationships between inputs and outputs of the algorithm. Adaptable refers to the capability of accommodating temporal changes in the underlying system dynamics (e.g., due to reactivity swings or fouling). Robustness refers to stability over long horizons under the presence of sensor or process noise. In this work, we focus on the specific problem of optimal control during autonomous operation.","",""
0,"Charlotte Van Petegem, Louise Deconinck, Dieter Mourisse, Rien Maertens, Niko Strijbol, B. Dhoedt, Bram De Wever, P. Dawyndt, B. Mesuere","Pass/Fail Prediction in Programming Courses",2022,"","","","",103,"2022-07-13 09:39:14","","10.1177/07356331221085595","","",,,,,0,0.00,0,9,1,"We present a privacy-friendly early-detection framework to identify students at risk of failing in introductory programming courses at university. The framework was validated for two different courses with annual editions taken by higher education students ( N = 2 080) and was found to be highly accurate and robust against variation in course structures, teaching and learning styles, programming exercises and classification algorithms. By using interpretable machine learning techniques, the framework also provides insight into what aspects of practising programming skills promote or inhibit learning or have no or minor effect on the learning process. Findings showed that the framework was capable of predicting students’ future success already early on in the semester.","",""
3,"Chen Wang, Chengyuan Deng, Vladimir A. Ivanov","SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations",2019,"","","","",104,"2022-07-13 09:39:14","","10.1109/IJCNN48605.2020.9207154","","",,,,,3,1.00,1,3,3,"The ability to capture relations within data can provide the much needed inductive bias for robust and interpretable Machine Learning algorithms. Variational Autoencoder (VAE) is a promising candidate for such purpose thanks to their power in data representation inference, but its vanilla form and common variations cannot process feature relations. In this paper, inspired by recent advances in relational learning with graph neural networks, we propose the Self-Attention Graph Variational AutoEncoder (SAG-VAE) model which can simultaneously learn feature relations and data representations in an end-to-end manner. The SAG-VAE is trained by jointly inferring the posterior distribution of two types of latent variables, which respectively represent the data and the feature relations. The feature relations are represented as a graph structure, and the presence of each edge is determined by a Gumbel-Softmax distribution. The generative model is accordingly parameterized by a graph neural network with a special attention mechanism we introduced in the paper. Therefore, the SAG-VAE model can generate via graph convolution and be trained via backpropagation. Experiments based on graphs show that SAG-VAE is capable of approximately retrieving edges and links between vertices based entirely on feature observations. Furthermore, experiments on image data illustrate that the learned feature relations can provide the SAG-VAE robustness against perturbations in image reconstruction and sampling. The learned feature relations as graph adjacency matrices are observed to be structured, which provides intuitive interpretability of the models.","",""
19,"Kui Yu, Xianjie Guo, Lin Liu, Jiuyong Li, Hao Wang, Zhaolong Ling, Xindong Wu","Causality-based Feature Selection: Methods and Evaluations",2019,"","","","",105,"2022-07-13 09:39:14","","","","",,,,,19,6.33,3,7,3,"Feature selection is a crucial preprocessing step in data analytics and machine learning. Classical feature selection algorithms select features based on the correlations between predictive features and the class variable and do not attempt to capture causal relationships between them. It has been shown that the knowledge about the causal relationships between features and the class variable has potential benefits for building interpretable and robust prediction models, since causal relationships imply the underlying mechanism of a system. Consequently, causality-based feature selection has gradually attracted greater attentions and many algorithms have been proposed. In this paper, we present a comprehensive review of recent advances in causality-based feature selection. To facilitate the development of new algorithms in the research area and make it easy for the comparisons between new methods and existing ones, we develop the first open-source package, called CausalFS, which consists of most of the representative causality-based feature selection algorithms (available at this https URL). Using CausalFS, we conduct extensive experiments to compare the representative algorithms with both synthetic and real-world data sets. Finally, we discuss some challenging problems to be tackled in future causality-based feature selection research.","",""
21,"Yue Chen, Chen Gong, H. Hao, Yi Guo, Shujun Xu, Yu-huan Zhang, G. Yin, Xin Cao, A. Yang, F. Meng, Jingying Ye, Hesheng Liu, Jianguo Zhang, Yanan Sui, Luming Li","Automatic Sleep Stage Classification Based on Subthalamic Local Field Potentials",2019,"","","","",106,"2022-07-13 09:39:14","","10.1109/TNSRE.2018.2890272","","",,,,,21,7.00,2,15,3,"Deep brain stimulation (DBS) is an established treatment for patients with Parkinson’s disease (PD). Sleep disorders are common complications of PD and affected by subthalamic DBS treatment. To achieve more precise neuromodulation, chronicsleepmonitoringand closed-loop DBS toward sleep–wake cycles could potentially be utilized. Local field potential (LFP) signals that are sensed by the DBS electrode could be processed as primary feedback signals. This is the first study to systematically investigate the sleep-stage classification based on LFPs in subthalamic nucleus (STN). With our newly developed recording and transmission system, STN-LFPs were collected from 12 PD patients during wakefulness and nocturnal polysomnography sleep monitoring at one month after DBS implantation. Automatic sleep-stage classificationmodels were built with robust and interpretable machine learning methods (support vector machine and decision tree). The accuracy, sensitivity, selectivity, and specificity of the classification reached high values (above90% at most measures) at group and individual levels. Features extracted in alpha (8–13 Hz), beta (13–35 Hz), and gamma (35–50 Hz) bandswere found to contribute the most to the classification. These results will directly guide the engineering development of implantable sleepmonitoring and closed-loopDBS and pave the way for a better understanding of the STN-LFP sleep patterns.","",""
43,"Edward Raff, J. Sylvester, S. Mills","Fair Forests: Regularized Tree Induction to Minimize Model Bias",2017,"","","","",107,"2022-07-13 09:39:14","","10.1145/3278721.3278742","","",,,,,43,8.60,14,3,5,"The potential lack of fairness in the outputs of machine learning algorithms has recently gained attention both within the research community as well as in society more broadly. Surprisingly, there is no prior work developing tree-induction algorithms for building fair decision trees or fair random forests. These methods have widespread popularity as they are one of the few to be simultaneously interpretable, non-linear, and easy-to-use. In this paper we develop, to our knowledge, the first technique for the induction of fair decision trees.We show that our ""Fair Forest"" retains the benefits of the tree-based approach, while providing both greater accuracy and fairness than other alternatives, for both ""group fairness'' and ""individual fairness.'' We also introduce new measures for fairness which are able to handle multinomial and continues attributes as well as regression problems, as opposed to binary attributes and labels only. Finally, we demonstrate a new, more robust evaluation procedure for algorithms that considers the dataset in its entirety rather than only a specific protected attribute.","",""
1,"Joseph Giorgio, W. Jagust, S. Baker, S. Landau, P. Tiňo, Z. Kourtzi","Predicting future regional tau accumulation in asymptomatic and early Alzheimer’s disease",2020,"","","","",108,"2022-07-13 09:39:14","","10.1101/2020.08.15.252601","","",,,,,1,0.50,0,6,2,"The earliest stages of Alzheimer’s disease (AD) involve interactions between multiple pathophysiological processes. Although these processes are well studied, we still lack robust tools to predict individualised trajectories of disease progression. Here, we employ a robust and interpretable machine learning approach to combine multimodal biological data and predict future tau accumulation, translating predictive information from deep phenotyping cohorts at early stages of AD to cognitively normal individuals. In particular, we use machine learning to quantify interactions between key pathological markers (β-amyloid, medial temporal atrophy, tau and APOE 4) at early and asymptomatic stages of AD. We next derive a predictive index that stratifies individuals based on future pathological tau accumulation, highlighting two critical features for optimal clinical trial design. First, future tau accumulation provides a better outcome measure compared to changes in cognition. Second, stratification based on multimodal data compared to β-amyloid alone reduces the sample size required to detect a clinically meaningful change in tau accumulation. Further, we extend our machine learning approach to derive individualised trajectories of future pathological tau accumulation in early AD patients and accurately predict regional future rate of tau accumulation in an independent sample of cognitively unimpaired individuals. Our results propose a robust approach for fine scale stratification and prognostication with translation impact for clinical trial design at asymptomatic and early stages of AD. One Sentence Summary Our machine learning approach combines baseline multimodal data to make individualised predictions of future pathological tau accumulation at prodromal and asymptomatic stages of Alzheimer’s disease with high accuracy and regional specificity.","",""
0,"Joseph Giorgio, Jagust William J, S. Baker, S. Landau, P. Tiňo, Z. Kourtzi","Title: Predicting future regional tau accumulation in asymptomatic and early Alzheimer’s disease",2020,"","","","",109,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,6,2,"The earliest stages of Alzheimer’s disease (AD) involve interactions between multiple pathophysiological processes. Although these processes are well studied, we still lack robust tools to predict individualised trajectories of disease progression. Here, we employ a robust and interpretable machine learning approach to combine multimodal biological data and predict future tau accumulation, translating predictive information from deep phenotyping cohorts at early stages of AD to cognitively normal individuals. In particular, we use machine learning to quantify interactions between key pathological markers ( b -amyloid, medial temporal atrophy, tau and APOE 4) at early and asymptomatic stages of AD. We next derive a predictive index that stratifies individuals based on future pathological tau accumulation, highlighting two critical features for optimal clinical trial design. First, future tau accumulation provides a better outcome measure compared to changes in cognition. Second, stratification based on multimodal data compared to b -amyloid alone reduces the sample size required to detect a clinically meaningful change in tau accumulation. Further, we extend our machine learning approach to derive individualised trajectories of future pathological tau accumulation in early AD patients and accurately predict regional future rate of tau accumulation in an independent sample of cognitively unimpaired individuals. Our results propose a robust approach for fine scale stratification and prognostication with translation impact for clinical trial design at asymptomatic and early stages of AD. Aβ PET, temporal grey matter density using T1 weighted MRI and APOE 4 genotype. derives a continuous prognostic metric by training a learning model with classes determined by longitudinal diagnostic labels.","",""
26,"Farzaneh Khoshnevisan, J. Ivy, M. Capan, R. Arnold, J. Huddleston, Min Chi","Recent Temporal Pattern Mining for Septic Shock Early Prediction",2018,"","","","",110,"2022-07-13 09:39:14","","10.1109/ICHI.2018.00033","","",,,,,26,6.50,4,6,4,"Sepsis is a leading cause of in-hospital death over the world and septic shock, the most severe complication of sepsis, reaches a mortality rate as high as 50%. Early diagnosis and treatment can prevent most morbidity and mortality. In this work, Recent Temporal Patterns (RTPs) are used in conjunction with SVM classifier to build a robust yet interpretable model for early diagnosis of septic shock. This model is applied to two different prediction tasks: visit-level early diagnosis and event-level early prediction. For each setting, this model is compared against several strong baselines including atemporal method called Last-Value, six classic machine learning algorithms, and lastly, a state-of-the-art deep learning model: Long Short-Term Memory (LSTM). Our results suggest that RTP-based model can outperform all aforementioned baseline models for both diagnosis tasks. More importantly, the extracted interpretative RTPs can shed lights for the clinicians to discover progression behavior and latent patterns among septic shock patients.","",""
3,"A. Hempel, Holger Hähnel, G. Herbst","Learning non-convex fuzzy classifiers using single-class SVMs",2013,"","","","",111,"2022-07-13 09:39:14","","10.1109/FUZZ-IEEE.2013.6622470","","",,,,,3,0.33,1,3,9,"In this paper, we propose an approach for building tree-like structured fuzzy classifiers. In order to learn classes for non-convex shapes of data, basic building blocks modelling convex classes are composed. For this purpose, an idea for the integration of single-class support vector machines (SVMs) into fuzzy class learning is sketched. The leading thought of this hybrid approach is the creation of a robust and most notably well interpretable parametric fuzzy classification model. Its feasibility is demonstrated in the context of a machine diagnosis task and compared to standard soft-margin SVMs.","",""
62,"Filip Korzeniowski, G. Widmer","A fully convolutional deep auditory model for musical chord recognition",2016,"","","","",112,"2022-07-13 09:39:14","","10.1109/MLSP.2016.7738895","","",,,,,62,10.33,31,2,6,"Chord recognition systems depend on robust feature extraction pipelines. While these pipelines are traditionally hand-crafted, recent advances in end-to-end machine learning have begun to inspire researchers to explore data-driven methods for such tasks. In this paper, we present a chord recognition system that uses a fully convolutional deep auditory model for feature extraction. The extracted features are processed by a Conditional Random Field that decodes the final chord sequence. Both processing stages are trained automatically and do not require expert knowledge for optimising parameters. We show that the learned auditory system extracts musically interpretable features, and that the proposed chord recognition system achieves results on par or better than state-of-the-art algorithms.","",""
18,"K. Birchall, V. Gillet, G. Harper, S. Pickett","Evolving Interpretable Structure-Activity Relationships. 1. Reduced Graph Queries",2008,"","","","",113,"2022-07-13 09:39:14","","10.1021/ci8000502","","",,,,,18,1.29,5,4,14,"A new machine learning method is presented for extracting interpretable structure-activity relationships from screening data. The method is based on an evolutionary algorithm and reduced graphs and aims to evolve a reduced graph query (subgraph) that is present within the active compounds and absent from the inactives. The reduced graph representation enables heterogeneous compounds, such as those found in high-throughput screening data, to be captured in a single representation with the resulting query encoding structure-activity information in a form that is readily interpretable by a chemist. The application of the method is illustrated using data sets extracted from the well-known MDDR data set and GSK in-house screening data. Queries are evolved that are consistent with the known SARs, and they are also shown to be robust when applied to independent sets that were not used in training.","",""
8,"Raul Moreno, D. Moreno-Salinas, J. Aranda","Black-Box Marine Vehicle Identification with Regression Techniques for Random Manoeuvres",2019,"","","","",114,"2022-07-13 09:39:14","","10.3390/ELECTRONICS8050492","","",,,,,8,2.67,3,3,3,"As a critical step to efficiently design control structures, system identification is concerned with building models of dynamical systems from observed input–output data. In this paper, a number of regression techniques are used for black-box marine system identification of a scale ship. Unlike other works that train the models using specific manoeuvres, in this work the data have been collected from several random manoeuvres and trajectories. Therefore, the aim is to develop general and robust mathematical models using real experimental data from random movements. The techniques used in this work are ridge, kernel ridge and symbolic regression, and the results show that machine learning techniques are robust approaches to model surface marine vehicles, even providing interpretable results in closed form equations using techniques such as symbolic regression.","",""
5,"Carlos Aguilar-Palacios, Sergio Muñoz-Romero, J. Rojo-álvarez","Forecasting Promotional Sales Within the Neighbourhood",2019,"","","","",115,"2022-07-13 09:39:14","","10.1109/ACCESS.2019.2920380","","",,,,,5,1.67,2,3,3,"Promotions are a widely used strategy to engage consumers and as such, retailers dedicate immense effort and resources to their planning and forecasting. This paper introduces a novel interpretable machine learning method specifically tailored to the automatic prediction of promotional sales in real-market applications. Particularly, we present fully automated weighted k-nearest neighbors where the distances are calculated based on a feature selection process that focuses on the similarity of promotional sales. The method learns online, thereby avoiding the model being retrained and redeployed. It is robust and able to infer the mechanisms leading to sales as demonstrated on detailed surrogate models. Also, to validate this method, real market data provided by a worldwide retailer have been used, covering numerous categories from three different countries and several types of stores. The algorithm is benchmarked against an ensemble of regression trees and the forecast provided by the retailer and it outperforms both on a merit figure composed not only by the mean absolute error but also by the error deviations used in the retail business. The proposed method significantly improves the accuracy of the forecast in many diverse categories and geographical locations, yielding significant and operative benefits for supply chains. Additionally, we briefly discuss in the Appendix how to deploy our method as a RESTful service in a production environment.","",""
3,"Selim Ickin, Jawwad Ahmed, A. Johnsson, Jorgen Gustafsson","On Network Performance Indicators for Network Promoter Score Estimation",2019,"","","","",116,"2022-07-13 09:39:14","","10.1109/QoMEX.2019.8743206","","",,,,,3,1.00,1,4,3,"Estimation of user perceived quality of offered services, from massive number of Key Performance Indicator (KPI)’s that are measured in diverse components, has been a necessity for mobile network operators. The goal is first to have a good estimator for poor Quality of Experience (QoE), which can potentially be achieved with machine learning, and then pinpoint the features that are contributing to the poor performance. There is often a tradeoff between accuracy and interpretability of models. In this paper, we address this tradeoff by first developing a robust but complex teacher machine learning model to map the subjective Net Promoter Score (NPS) values computed from the user quality feedback to the underlying subset of KPI metrics. Next, we develop a rather interpretable student model supervised by the pre-trained teacher model. Eventually the compact student decision tree model learns to mimic the behavior of the teacher model with an at least 10 % improved accuracy in testset as compared to conventional way of directly training using the decision tree model. In the last step, we extract the rules and important influential features of the distilled student model.","",""
33,"T. Knijnenburg, G. Klau, Francesco Iorio, M. Garnett, U. McDermott, I. Shmulevich, L. Wessels","Logic models to predict continuous outputs based on binary inputs with an application to personalized cancer therapy",2016,"","","","",117,"2022-07-13 09:39:14","","10.1101/036970","","",,,,,33,5.50,5,7,6,"Mining large datasets using machine learning approaches often leads to models that are hard to interpret and not amenable to the generation of hypotheses that can be experimentally tested. Finding ‘actionable knowledge’ is becoming more important, but also more challenging as datasets grow in size and complexity. We present ‘Logic Optimization for Binary Input to Continuous Output’ (LOBICO), a computational approach that infers small and easily interpretable logic models of binary input features that explain a binarized continuous output variable. Although the continuous output variable is binarized prior to optimization, the continuous information is retained to find the optimal logic model. Applying LOBICO to a large cancer cell line panel, we find that logic combinations of multiple mutations are more predictive of drug response than single gene predictors. Importantly, we show that the use of the continuous information leads to robust and more accurate logic models. LOBICO is formulated as an integer programming problem, which enables rapid computation on large datasets. Moreover, LOBICO implements the ability to uncover logic models around predefined operating points in terms of sensitivity and specificity. As such, it represents an important step towards practical application of interpretable logic models.","",""
51,"David Filliat, Emmanuel Battesti, S. Bazeille, G. Duceux, A. Gepperth, Lotfi Harrath, Islem Jebari, Rafael Pereira, A. Tapus, Cedric Meyer, S. Ieng, R. Benosman, Eddy Cizeron, Jean-Charles Mamanna, Benoit Pothier","RGBD object recognition and visual texture classification for indoor semantic mapping",2012,"","","","",118,"2022-07-13 09:39:14","","10.1109/TePRA.2012.6215666","","",,,,,51,5.10,5,15,10,"We present a mobile robot whose goal is to autonomously explore an unknown indoor environment and to build a semantic map containing high-level information similar to those extracted by humans. This information includes the rooms, their connectivity, the objects they contain and the material of the walls and ground. This robot was developed in order to participate in a French exploration and mapping contest called CAROTTE whose goal is to produce easily interpretable maps of an unknown environment. In particular we present our object detection approach based on a color+depth camera that fuse 3D, color and texture information through a neural network for robust object recognition. We also present the material recognition approach based on machine learning applied to vision. We demonstrate the performances of these modules on image databases and provide examples on the full system working in real environments.","",""
1,"J. Günther, Elias Reichensdörfer, P. Pilarski, K. Diepold","General Dynamic Neural Networks for explainable PID parameter tuning in control engineering: An extensive comparison",2019,"","","","",119,"2022-07-13 09:39:14","","","","",,,,,1,0.33,0,4,3,"Automation, the ability to run processes without human supervision, is one of the most important drivers of increased scalability and productivity. Modern automation largely relies on forms of closed loop control, wherein a controller interacts with a controlled process via actions, based on observations. Despite an increase in the use of machine learning for process control, most deployed controllers still are linear Proportional-Integral-Derivative (PID) controllers. PID controllers perform well on linear and near-linear systems but are not robust enough for more complex processes. As a main contribution of this paper, we examine the utility of extending standard PID controllers with General Dynamic Neural Networks (GDNN); we show that GDNN (neural) PID controllers perform well on a range of control systems and highlight what is needed to make them a stable, scalable, and interpretable option for control. To do so, we provide a comprehensive study using four different benchmark processes. All control environments are evaluated with and without noise as well as with and without disturbances. The neural PID controller performs better than standard PID control in 15 of 16 tasks and better than model-based control in 13 of 16 tasks. As a second contribution of this work, we address the Achilles heel that prevents neural networks from being used in real-world control processes so far: lack of interpretability. We use bounded-input bounded-output stability analysis to evaluate the parameters suggested by the neural network, thus making them understandable for human engineers. This combination of rigorous evaluation paired with better explainability is an important step towards the acceptance of neural-network-based control approaches for real-world systems. It is furthermore an important step towards explainable and safe applied artificial intelligence.","",""
13,"S. Saralajew, Lars Holdijk, Maike Rees, T. Villmann","Prototype-based Neural Network Layers: Incorporating Vector Quantization",2018,"","","","",120,"2022-07-13 09:39:14","","","","",,,,,13,3.25,3,4,4,"Neural networks currently dominate the machine learning community and they do so for good reasons. Their accuracy on complex tasks such as image classification is unrivaled at the moment and with recent improvements they are reasonably easy to train. Nevertheless, neural networks are lacking robustness and interpretability. Prototype-based vector quantization methods on the other hand are known for being robust and interpretable. For this reason, we propose techniques and strategies to merge both approaches. This contribution will particularly highlight the similarities between them and outline how to construct a prototype-based classification layer for multilayer networks. Additionally, we provide an alternative, prototype-based, approach to the classical convolution operation. Numerical results are not part of this report, instead the focus lays on establishing a strong theoretical framework. By publishing our framework and the respective theoretical considerations and justifications before finalizing our numerical experiments we hope to jump-start the incorporation of prototype-based learning in neural networks and vice versa.","",""
7,"William Herlands, Edward McFowland, A. G. Wilson, D. Neill","Automated Local Regression Discontinuity Design Discovery",2018,"","","","",121,"2022-07-13 09:39:14","","10.1145/3219819.3219982","","",,,,,7,1.75,2,4,4,"Inferring causal relationships in observational data is crucial for understanding scientific and social processes. We develop the first statistical machine learning approach for automatically discovering regression discontinuity designs (RDDs), a quasi-experimental setup often used in econometrics. Our method identifies interpretable, localized RDDs in arbitrary dimensional data and can seamlessly compute treatment effects without expert supervision. By applying the technique to a variety of synthetic and real datasets, we demonstrate robust performance under adverse conditions including unobserved variables, substantial noise, and model","",""
5,"Maarten Bieshaar, Malte Depping, Jan Schneegans, B. Sick","Starting Movement Detection of Cyclists Using Smart Devices",2018,"","","","",122,"2022-07-13 09:39:14","","10.1109/DSAA.2018.00042","","",,,,,5,1.25,1,4,4,"In near future, vulnerable road users (VRUs) such as cyclists and pedestrians will be equipped with smart devices and wearables which are capable to communicate with intelligent vehicles and other traffic participants. Road users are then able to cooperate on different levels, such as in cooperative intention detection for advanced VRU protection. Smart devices can be used to detect intentions, e.g., an occluded cyclist intending to cross the road, to warn vehicles of VRUs, and prevent potential collisions. This article presents a human activity recognition approach to detect the starting movement of cyclists wearing smart devices. We propose a novel two-stage feature selection procedure using a score specialized for robust starting detection reducing the false positive detections and leading to understandable and interpretable features. The detection is modelled as a classification problem and realized by means of a machine learning classifier. We introduce an auxiliary class, that models starting movements and allows to integrate early movement indicators, i.e., body part movements indicating future behaviour. In this way we improve the robustness and reduce the detection time of the classifier. Our empirical studies with real-world data originating from experiments which involve 49 test subjects and consists of 84 starting motions show that we are able to detect the starting movements early. Our approach reaches an F1-score of 67 % within 0.33 s after the first movement of the bicycle wheel. Investigations concerning the device wearing location show that for devices worn in the trouser pocket the detector has less false detections and detects starting movements faster on average. % compared to reference detector involving all wearing locations. We found that we can further improve the results when we train distinct classifiers for different wearing locations. In this case we reach an F1-score of 94 % with a mean detection time of 0.34 s for the device worn in the trouser pocket.","",""
6,"Alwin Yaoxian Zhang, Sean Shao Wei Lam, Nan Liu, Yan Pang, L. Chan, Phua Hwee Tang","Development of a Radiology Decision Support System for the Classification of MRI Brain Scans",2018,"","","","",123,"2022-07-13 09:39:14","","10.1109/BDCAT.2018.00021","","",,,,,6,1.50,1,6,4,"Previous studies revealed that the ordering of Magnetic resonance imaging (MRI) brain scans following American College of Radiology (ACR) guidelines showed a higher percentage of brain abnormalities compared to scans that do not. As the process of manually labelling patient orders obtained from a local tertiary hospital in accordance to ACR guidelines is intensive and time consuming, this study aims to develop predictive machine learning models; Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF) and XGBoost (XGB), to automate the classification process through text mining methods and derive insights that are useful for future clinical decision-making and resource optimization. Using 1,924 observations as the labelled training data, RF and XGB were found to be the best performing robust models with ROC values of 0.9459 and 0.9508 respectively on the validation set (481 observations). Further exploration into the interpretability of black-box algorithms using the model agnostic LIME (Local Interpretable Model-Agnostic Explanations) framework was used to generate further insights for decisions made using a separate XGB model with respect to individual patients. The LIME framework is a significant first step towards the development of a comprehensive decision support system for patient-level decisions in the ordering of MRI scans.","",""
8,"Jian Liu, Bin Ma, Ming Li","Prima: Peptide Robust Identification from Ms/ms Spectra",2006,"","","","",124,"2022-07-13 09:39:14","","10.1142/S0219720006001746","","",,,,,8,0.50,3,3,16,"In proteomics, tandem mass spectrometry is the key technology for peptide sequencing. However, partially due to the deficiency of peptide identification software, a large portion of the tandem mass spectra are discarded in almost all proteomics centers because they are not interpretable. The problem is more acute with the lower quality data from low end but more popular devices such as the ion trap instruments. In order to deal with the noisy and low quality data, this paper develops a systematic machine learning approach to construct a robust linear scoring function, whose coefficients are determined by a linear programming. A prototype, PRIMA, was implemented. When tested with large benchmarks of varying qualities, PRIMA consistently has higher accuracy than commonly used software MASCOT, SEQUEST and X! Tandem.","",""
28,"Xiaofeng Zhu, Heung-Il Suk, Yonghua Zhu, K. Thung, Guorong Wu, D. Shen","Multi-view Classification for Identification of Alzheimer's Disease",2015,"","","","",125,"2022-07-13 09:39:14","","10.1007/978-3-319-24888-2_31","","",,,,,28,4.00,5,6,7,"","",""
10,"Julia Proskurnia, R. Mavlyutov, C. Castillo, K. Aberer, P. Cudré-Mauroux","Efficient Document Filtering Using Vector Space Topic Expansion and Pattern-Mining: The Case of Event Detection in Microposts",2017,"","","","",126,"2022-07-13 09:39:14","","10.1145/3132847.3133016","","",,,,,10,2.00,2,5,5,"Automatically extracting information from social media is challenging given that social content is often noisy, ambiguous, and inconsistent. However, as many stories break on social channels first before being picked up by mainstream media, developing methods to better handle social content is of utmost importance. In this paper, we propose a robust and effective approach to automatically identify microposts related to a specific topic defined by a small sample of reference documents. Our framework extracts clusters of semantically similar microposts that overlap with the reference documents, by extracting combinations of key features that define those clusters through frequent pattern mining. This allows us to construct compact and interpretable representations of the topic, dramatically decreasing the computational burden compared to classical clustering and k-NN-based machine learning techniques and producing highly-competitive results even with small training sets (less than 1'000 training objects). Our method is efficient and scales gracefully with large sets of incoming microposts. We experimentally validate our approach on a large corpus of over 60M microposts, showing that it significantly outperforms state-of-the-art techniques.","",""
8,"Svetlin Penkov, S. Ramamoorthy","Using Program Induction to Interpret Transition System Dynamics",2017,"","","","",127,"2022-07-13 09:39:14","","","","",,,,,8,1.60,4,2,5,"Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to two problems: system identification of dynamical systems and explaining the behaviour of a DQN agent. Our results show that the $\pi$-machine can efficiently induce interpretable programs from individual data traces.","",""
2,"Tejaswini Mallavarapu, Jie Hao, Youngsoon Kim, J. Oh, Mingon Kang","PASCL: Pathway-based Sparse Deep Clustering for Identifying Unknown Cancer Subtypes",2018,"","","","",128,"2022-07-13 09:39:14","","10.1109/BIBM.2018.8621387","","",,,,,2,0.50,0,5,4,"Cancer is a heterogeneous disease which has several subtypes that can be distinguished by molecular, histopathological, and clinical stages. Accurate diagnosis of cancer subtypes is vital to identify distinct disease states and develop effective personalized therapies. A number of unsupervised machine learning techniques have been applied to genomic data of the tumor samples, where clusters of patients were formed to be associated with a clinical outcome such as the survival of patients. However, clustering methods based on distance (or similarity) between data often fail to cluster biological data, due to their nonlinearity. In this paper, we develop a PAthway-based Sparse deep CLustering (PASCL) method for the identification of cancer subtypes. PASCL incorporates prior biological knowledge from pathway databases to build a robust and biological interpretable model. We evaluated the performance of PASCL by comparing with several state-of-the-art clustering methods. PASCL outperformed the benchmarking methods with lowest p-value in logrank test, and its outstanding performance is statistically assessed. PASCL provides a solution not only to effectively identify subtypes using high-dimensional nonlinear genomic data, but also to biologically interpret the model at a pathway level.","",""
2,"Gongfeng Li, K. Daoudi, J. Klempír, J. Rusz","Linear Classification in Speech-Based Objective Differential Diagnosis of Parkinsonism",2018,"","","","",129,"2022-07-13 09:39:14","","10.1109/ICASSP.2018.8462681","","",,,,,2,0.50,1,4,4,"Parkinsonism refers to Parkinsons disease (PD) and Atypical parkinsonian syndromes (APS). Speech disorder is a common and early symptom in Parkinsonism which makes speech analysis a very important research area for the purpose of early diagnosis. Most of research have however focused on discrimination between PD and healthy controls. Such research does not take into account the fact that PD and APS syndromes are very similar in early disease stages. The main problem that has to be addressed first is then differential diagnosis: discrimination between PD and APS and within APS. This paper is a continuation of an earlier pioneer work in differential diagnosis where we mostly address the machine learning problem due to the small amount of training data. We show that classical linear and generalized linear models can provide interpretable and robust classifiers in term of accuracy and generalization ability.","",""
19,"W. Shoombuatong, V. Prachayasittikul, V. Prachayasittikul, C. Nantasenamat","Prediction of aromatase inhibitory activity using the efficient linear method (ELM)",2015,"","","","",130,"2022-07-13 09:39:14","","10.17179/excli2015-140","","",,,,,19,2.71,5,4,7,"Aromatase inhibition is an effective treatment strategy for breast cancer. Currently, several in silico methods have been developed for the prediction of aromatase inhibitors (AIs) using artificial neural network (ANN) or support vector machine (SVM). In spite of this, there are ample opportunities for further improvements by developing a simple and interpretable quantitative structure-activity relationship (QSAR) method. Herein, an efficient linear method (ELM) is proposed for constructing a highly predictive QSAR model containing a spontaneous feature importance estimator. Briefly, ELM is a linear-based model with optimal parameters derived from genetic algorithm. Results showed that the simple ELM method displayed robust performance with 10-fold cross-validation MCC values of 0.64 and 0.56 for steroidal and non-steroidal AIs, respectively. Comparative analyses with other machine learning methods (i.e. ANN, SVM and decision tree) were also performed. A thorough analysis of informative molecular descriptors for both steroidal and non-steroidal AIs provided insights into the mechanism of action of compounds. Our findings suggest that the shape and polarizability of compounds may govern the inhibitory activity of both steroidal and non-steroidal types whereas the terminal primary C(sp3) functional group and electronegativity may be required for non-steroidal AIs. The R code of the ELM method is available at http://dx.doi.org/10.6084/m9.figshare.1274030.","",""
18,"M. Strickert, B. Hammer, T. Villmann, Michael Biehl","Regularization and improved interpretation of linear data mappings and adaptive distance measures",2013,"","","","",131,"2022-07-13 09:39:14","","10.1109/CIDM.2013.6597211","","",,,,,18,2.00,5,4,9,"Linear data transformations are essential operations in many machine learning algorithms, helping to make such models more flexible or to emphasize certain data directions. In particular for high dimensional data sets linear transformations are not necessarily uniquely determined, though, and alternative parameterizations exist which do not change the mapping of the training data. Thus, regularization is required to make the model robust to noise and more interpretable for the user. In this contribution, we characterize the group of transformations which leave a linear mapping invariant for a given finite data set, and we discuss the consequences on the interpretability of the models. We propose an intuitive regularization mechanism to avoid problems in under-determined configurations, and we test the approach in two machine learning models.","",""
7,"Svetlin Penkov, S. Ramamoorthy","Explaining Transition Systems through Program Induction",2017,"","","","",132,"2022-07-13 09:39:14","","","","",,,,,7,1.40,4,2,5,"Explaining and reasoning about processes which underlie observed black-box phenomena enables the discovery of causal mechanisms, derivation of suitable abstract representations and the formulation of more robust predictions. We propose to learn high level functional programs in order to represent abstract models which capture the invariant structure in the observed data. We introduce the $\pi$-machine (program-induction machine) -- an architecture able to induce interpretable LISP-like programs from observed data traces. We propose an optimisation procedure for program learning based on backpropagation, gradient descent and A* search. We apply the proposed method to three problems: system identification of dynamical systems, explaining the behaviour of a DQN agent and learning by demonstration in a human-robot interaction scenario. Our experimental results show that the $\pi$-machine can efficiently induce interpretable programs from individual data traces.","",""
0,"Shashanka Ubaru, K. Bouchard, A. Wani","Challenge 2018-Parts-based decomposition of noisy data Organizers :",2018,"","","","",133,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,3,4,"With the ever growing collection of large volumes of scientific data, development of interpretable machine learning tools to analyze such data is becoming more important. However, robust, interpretable machine learning tools are lacking, threatening extraction of scientific insight and discovery. Dimensionality reduction and low rank approximations/decompositions are popular tools used in many applications to analyze high dimensional data. However, popular dimensionality reduction methods, often yield uninterpretable results, particularly for noisy data. In this challenge, we focus on parts based feature extraction from noisy data using unsupervised learning. We desire to decompose given noisy data into a small set of interpretable (parts based) features. Such a decomposition will not require any training examples, making it a very important tool for exploratory data analysis, particularly in scientific data applications.","",""
10,"Eric T. Nalisnick, S. Ravi","Infinite Dimensional Word Embeddings",2015,"","","","",134,"2022-07-13 09:39:14","","","","",,,,,10,1.43,5,2,7,"We describe a method for learning word embeddings with stochastic dimensionality. Our Infinite Skip-Gram (iSG) model specifies an energy-based joint distribution over a word vector, a context vector, and their dimensionality. By employing the same techniques used to make the Infinite Restricted Boltzmann Machine (Cote & Larochelle, 2015) tractable, we define vector dimensionality over a countably infinite domain, allowing vectors to grow as needed during training. After training, we find that the distribution over embedding dimensionality for a given word is highly interpretable and leads to an elegant probabilistic mechanism for word sense induction. We show qualitatively and quantitatively that the iSG produces parameter-efficient representations that are robust to language's inherent ambiguity.","",""
6,"Benjamin Ulfenborg, K. Klinga-Levan, B. Olsson","Classification of Tumor Samples from Expression Data Using Decision Trunks",2013,"","","","",135,"2022-07-13 09:39:14","","10.4137/CIN.S10356","","",,,,,6,0.67,2,3,9,"We present a novel machine learning approach for the classification of cancer samples using expression data. We refer to the method as “decision trunks,” since it is loosely based on decision trees, but contains several modifications designed to achieve an algorithm that: (1) produces smaller and more easily interpretable classifiers than decision trees; (2) is more robust in varying application scenarios; and (3) achieves higher classification accuracy. The decision trunk algorithm has been implemented and tested on 26 classification tasks, covering a wide range of cancer forms, experimental methods, and classification scenarios. This comprehensive evaluation indicates that the proposed algorithm performs at least as well as the current state of the art algorithms in terms of accuracy, while producing classifiers that include on average only 2–3 markers. We suggest that the resulting decision trunks have clear advantages over other classifiers due to their transparency, interpretability, and their correspondence with human decision-making and clinical testing practices.","",""
10,"Ye Mao","One minute is enough : Early Prediction of Student Success and Event-level Difficulty during a Novice Programming Task",,"","","","",136,"2022-07-13 09:39:14","","","","",,,,,10,0.00,10,1,,"Early prediction of student difficulty during long-duration learning activities allows a tutoring system to intervene by providing needed support, such as a hint, or by alerting an instructor. To be effective, these predictions must come early and be highly accurate, but such predictions are difficult for open-ended programming problems. In this work, Recent Temporal Patterns (RTPs) are used in conjunction with Support Vector Machine and Logistic Regression to build robust yet interpretable models for early predictions. We performed two tasks: to predict student success and difficulty during one, open-ended novice programming task of drawing a square-shaped spiral. We compared RTP against several machine learning models ranging from the classic to the more recent deep learning models such as Long Short Term Memory to predict whether students would be able to complete the programming task. Our results show that RTP-based models outperformed all others, and could successfully classify students after just one minute of a 20minute exercise (students can spend more than 1 hour on it). To determine when a system might intervene to prevent incompleteness or eventual dropout, we applied RTP at regular intervals to predict whether a student would make progress within the next five minutes, reflecting that they may be having difficulty. RTP successfully classified these students needing interventions over 85% of the time, with increased accuracy using data-driven program features. These results contribute significantly to the potential to build a fully data-driven tutoring system for novice programming.","",""
14,"G. Landrum, J. Penzotti, S. Putta","Feature-map vectors: a new class of informative descriptors for computational drug discovery",2007,"","","","",137,"2022-07-13 09:39:14","","10.1007/s10822-006-9085-8","","",,,,,14,0.93,5,3,15,"","",""
9,"A. W. Example","Belief Propagation in Fuzzy Bayesian Networks",2008,"","","","",138,"2022-07-13 09:39:14","","","","",,,,,9,0.64,9,1,14,"Fuzzy Bayesian networks (FBN) are a graphical machine learning model representation with variables which are simultaneously fuzzy and uncertain[2]. Bayesian networks (BN) are commonly used in machine learning. This is due to their statistical rationality, capacity for rigorous causal inference, and robustness in the face of noisy, partially missing and realistic data. They are also more easily human-interpretable than other machine learning representations such as neural networks, and experts can specify prior knowledge in a principled manner to guide the machine learning search. A wide range of search algorithms have been developed for structural and parameter inference, including structural EM [3] and MCMC. Classically, Bayesian networks use continuous (Gaussian) or multinomial variables. Similarly, a fuzzy model has a wide range of advantages. Fuzzy models are also robust in the face of noise-corrupted data. The use of linguistic terms aids human comprehension of the learnt model, and they are particularly useful when the data is insufficient to formulate a precise model. The need to specify membership functions also forces the designer to consider the semantic interpretation of the model parameterisation and construction more explicitly. For these reasons, FBN (which combine these advantages) may be useful. Theoretical analysis in current research[1] indicates that fuzzy variables can be more expressive than multinomial or continuous variables. FBN may also be used as part of an integrated sequence of machine learning techniques that include reversible dimensionality reduction techniques such as fuzzy cover clustering algorithms. This may allow larger problems to be addressed with FBN than with classic BN.","",""
0,"H. P. Oliveira, Jaime S. Cardoso","BCCT.core Model Enhancement With Interpretability and Lateral Information",2010,"","","","",139,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,12,"Breast Cancer Conservative Treatment (BCCT) is considered the gold standard of breast cancer treatment. The heterogeneity of the aesthetic result and the limited reproducibility of the subjective evaluation motivated the research towards objective methods, such as, the recent computer system named BCCT.core, based on machine learning techniques, namely support vector machines (SVMs). In the current work we investigate the accuracy of different interpretable methods against the model currently deployed in the BCCT.core software and the improvement of the model by introducing lateral information extracted from patients images. Experimental results show only a marginal improvement in the performance of the new models, suggesting that is essential to use more robust models, such as 3D approaches.","",""
8,"K. Revett, F. Gorunescu, M. Gorunescu, M. Ene","Mining A Primary Biliary Cirrhosis Dataset Using Rough Sets and a Probabilistic Neural Network",2006,"","","","",140,"2022-07-13 09:39:14","","10.1109/IS.2006.348432","","",,,,,8,0.50,2,4,16,"In this paper, a decision support system based on rough sets and a probabilistic neural network is presented. Rough sets were employed as they have the capacity to reduce the dimensionality of the dataset and also produce a set of readily understandable rules. A probabilistic neural network was also employed to classify this dataset, comparing the classification accuracy to that obtained with rough sets. We firstly evaluate the effectiveness of these machine learning algorithms on a real-life small biomedical dataset. The classification results indicate that both classifiers produce a high level of accuracy (87% or better). The rough sets algorithm produced a set of rules that are readily interpretable by a domain expert. The PNN algorithm produced a classifier that was robust to noise and missing values. These preliminary results indicate that the both rough sets and PNN machine learning approaches can be successfully applied synergistically to biomedical datasets that contain a variety of attribute types, missing values and multiple decision classes","",""
2,"R. Silva, T. Ludermir","Neural network methods for rule induction",1999,"","","","",141,"2022-07-13 09:39:14","","10.1109/IJCNN.1999.830845","","",,,,,2,0.09,1,2,23,"Local basis function networks are a useful category of classifiers, with known variations developed in neural networks, machine learning and statistics communities. The localized range of activation of the hidden units have many similarities with rule-based representations. Neurofuzzy systems are a common example of a framework that explicitly integrates these approaches. Following this concept, we study alternatives for the development of hybrid rule-neural systems with the purpose of inducing robust and interpretable classifiers. Local fitting of parameters is done by a gradient descent optimization that modifies the covering produced by a rule induction algorithm. Two tasks are accomplished: how to select a small number of rules and how to improve precision. The use of this architecture is better suited when one wants to achieve a good compromise between classification performance and simplicity.","",""
1981,"C. Rudin","Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",2018,"","","","",142,"2022-07-13 09:39:14","","10.1038/S42256-019-0048-X","","",,,,,1981,495.25,1981,1,4,"","",""
1,"A. Saadallah, K. Morik","Active Sampling for Learning Interpretable Surrogate Machine Learning Models",2020,"","","","",143,"2022-07-13 09:39:14","","10.1109/DSAA49011.2020.00039","","",,,,,1,0.50,1,2,2,"The use of machine learning methods to inform consequential decisions is increasingly expanding across many fields. As a result, the ability to interpret these models has become to a greater extent crucial to increase the related-technologies acceptance level and reliability. In this paper, we propose an active sampling approach for learning accurately interpretable surrogate machine learning model to better approximate black-box models for supervised learning problems. Hence, the surrogate model is used to learn the black-box model and reflect its properties. Active sampling is used as an informed sampling method to adaptively and iteratively build an optimized training set based on the predictions of the black-box model to enhance the accuracy of the surrogate model. Subsequently, the surrogate model is used to interpret and debug the black-box model. The developed method is flexible and can be used to approximate any family of black-box models using any type of interpretable machine learning models, as it only requires the ability to compute their outputs. It is also applicable to both regression and classification tasks. In this work, we bring focus to decision tree due to their proven high interpretability. An experimental evaluation of the method on several real-world data sets is presented to show its flexibility and its robustness compared to traditional approaches for learning surrogate models.","",""
1973,"Finale Doshi-Velez, Been Kim","Towards A Rigorous Science of Interpretable Machine Learning",2017,"","","","",144,"2022-07-13 09:39:14","","","","",,,,,1973,394.60,987,2,5,"As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.","",""
11,"Markus Jaeger, Stephan Krügel, D. Marinelli, J. Papenbrock, P. Schwendner","Interpretable Machine Learning for Diversified Portfolio Construction",2020,"","","","",145,"2022-07-13 09:39:14","","10.2139/ssrn.3730144","","",,,,,11,5.50,2,5,2,"In this article, the authors construct a pipeline to benchmark hierarchical risk parity (HRP) relative to equal risk contribution (ERC) as examples of diversification strategies allocating to liquid multi-asset futures markets with dynamic leverage (volatility target). The authors use interpretable machine learning concepts (explainable AI) to compare the robustness of the strategies and to back out implicit rules for decision-making. The empirical dataset consists of 17 equity index, government bond, and commodity futures markets across 20 years. The two strategies are back tested for the empirical dataset and for about 100,000 bootstrapped datasets. XGBoost is used to regress the Calmar ratio spread between the two strategies against features of the bootstrapped datasets. Compared to ERC, HRP shows higher Calmar ratios and better matches the volatility target. Using Shapley values, the Calmar ratio spread can be attributed especially to univariate drawdown measures of the asset classes. TOPICS: Quantitative methods, statistical methods, big data/machine learning, portfolio construction, performance measurement Key Findings ▪ The authors introduce a procedure to benchmark rule-based investment strategies and to explain the differences in path-dependent risk-adjusted performance measures using interpretable machine learning. ▪ They apply the procedure to the Calmar ratio spread between hierarchical risk parity (HRP) and equal risk contribution (ERC) allocations of a multi-asset futures portfolio and find HRP to have superior risk-adjusted performance. ▪ The authors regress the Calmar ratio spread against statistical features of bootstrapped futures return datasets using XGBoost and apply the SHAP framework by Lundberg and Lee (2017) to discuss the local and global feature importance.","",""
8,"Lakshya Singhal, Yash Garg, Philip Yang, A. Tabaie, A. Wong, Akram Mohammed, Lokesh Chinthala, D. Kadaria, A. Sodhi, A. Holder, A. Esper, J. Blum, R. Davis, G. Clifford, G. Martin, R. Kamaleswaran","eARDS: A multi-center validation of an interpretable machine learning algorithm of early onset Acute Respiratory Distress Syndrome (ARDS) among critically ill adults with COVID-19",2021,"","","","",146,"2022-07-13 09:39:14","","10.1371/journal.pone.0257056","","",,,,,8,8.00,1,16,1,"We present an interpretable machine learning algorithm called ‘eARDS’ for predicting ARDS in an ICU population comprising COVID-19 patients, up to 12-hours before satisfying the Berlin clinical criteria. The analysis was conducted on data collected from the Intensive care units (ICU) at Emory Healthcare, Atlanta, GA and University of Tennessee Health Science Center, Memphis, TN and the Cerner® Health Facts Deidentified Database, a multi-site COVID-19 EMR database. The participants in the analysis consisted of adults over 18 years of age. Clinical data from 35,804 patients who developed ARDS and controls were used to generate predictive models that identify risk for ARDS onset up to 12-hours before satisfying the Berlin criteria. We identified salient features from the electronic medical record that predicted respiratory failure among this population. The machine learning algorithm which provided the best performance exhibited AUROC of 0.89 (95% CI = 0.88–0.90), sensitivity of 0.77 (95% CI = 0.75–0.78), specificity 0.85 (95% CI = 085–0.86). Validation performance across two separate health systems (comprising 899 COVID-19 patients) exhibited AUROC of 0.82 (0.81–0.83) and 0.89 (0.87, 0.90). Important features for prediction of ARDS included minimum oxygen saturation (SpO2), standard deviation of the systolic blood pressure (SBP), O2 flow, and maximum respiratory rate over an observational window of 16-hours. Analyzing the performance of the model across various cohorts indicates that the model performed best among a younger age group (18–40) (AUROC = 0.93 [0.92–0.94]), compared to an older age group (80+) (AUROC = 0.81 [0.81–0.82]). The model performance was comparable on both male and female groups, but performed significantly better on the severe ARDS group compared to the mild and moderate groups. The eARDS system demonstrated robust performance for predicting COVID19 patients who developed ARDS at least 12-hours before the Berlin clinical criteria, across two independent health systems.","",""
0,"Katrin Sophie Bohnsack, M. Kaden, Julia Abel, S. Saralajew, T. Villmann","The Resolved Mutual Information Function as a Structural Fingerprint of Biomolecular Sequences for Interpretable Machine Learning Classifiers",2021,"","","","",147,"2022-07-13 09:39:14","","10.3390/e23101357","","",,,,,0,0.00,0,5,1,"In the present article we propose the application of variants of the mutual information function as characteristic fingerprints of biomolecular sequences for classification analysis. In particular, we consider the resolved mutual information functions based on Shannon-, Rényi-, and Tsallis-entropy. In combination with interpretable machine learning classifier models based on generalized learning vector quantization, a powerful methodology for sequence classification is achieved which allows substantial knowledge extraction in addition to the high classification ability due to the model-inherent robustness. Any potential (slightly) inferior performance of the used classifier is compensated by the additional knowledge provided by interpretable models. This knowledge may assist the user in the analysis and understanding of the used data and considered task. After theoretical justification of the concepts, we demonstrate the approach for various example data sets covering different areas in biomolecular sequence analysis.","",""
3,"A. Heinlein, A. Klawonn, M. Lanser, J. Weber","Combining Machine Learning and Adaptive Coarse Spaces---A Hybrid Approach for Robust FETI-DP Methods in Three Dimensions",2020,"","","","",148,"2022-07-13 09:39:14","","10.1137/20m1344913","","",,,,,3,1.50,1,4,2,"The hybrid ML-FETI-DP algorithm combines the advantages of adaptive coarse spaces in domain decomposition methods and certain supervised machine learning techniques. Adaptive coarse spaces ensure robustness of highly scalable domain decomposition solvers, even for highly heterogeneous coefficient distributions with arbitrary coefficient jumps. However, their construction requires the setup and solution of local generalized eigenvalue problems, which is typically computationally expensive. The idea of ML-FETI-DP is to interpret the coefficient distribution as image data and predict whether an eigenvalue problem has to be solved or can be neglected while still maintaining robustness of the adaptive FETI-DP method. For this purpose, neural networks are used as image classifiers. In the present work, the ML-FETI-DP algorithm is extended to three dimensions, which requires both a complex data preprocessing procedure to construct consistent input data for the neural network as well as a representative training and validation data set to ensure generalization properties of the machine learning model. Numerical experiments for stationary diffusion and linear elasticity problems with realistic coefficient distributions show that a large number of eigenvalue problems can be saved; in the best case of the numerical results presented here, 97% of the eigenvalue problems can be avoided to be set up and solved.","",""
0,"H. Tomas Rube, Chaitanya Rastogi, Siqian Feng, J. Kribelbauer, Allyson Li, Basheer Becerra, Lucas A. N. Melo, Bach-Viet Do, Xiaoting Li, Hammaad Adam, Neel H. Shah, R. Mann, H. Bussemaker","Probing molecular specificity with deep sequencing and biophysically interpretable machine learning",2021,"","","","",149,"2022-07-13 09:39:14","","10.1101/2021.06.30.450414","","",,,,,0,0.00,0,13,1,"Quantifying sequence-specific protein-ligand interactions is critical for understanding and exploiting numerous cellular processes, including gene regulation and signal transduction. Next-generation sequencing (NGS) based assays are increasingly being used to profile these interactions with high-throughput. However, these assays do not provide the biophysical parameters that have long been used to uncover the quantitative rules underlying sequence recognition. We developed a highly flexible machine learning framework, called ProBound, to define sequence recognition in terms of biophysical parameters based on NGS data. ProBound quantifies transcription factor (TF) behavior with models that accurately predict binding affinity over a range exceeding that of previous resources, captures the impact of DNA modifications and conformational flexibility of multi-TF complexes, and infers specificity directly from in vivo data such as ChIP-seq without peak calling. When coupled with a new assay called Kd-seq, it determines the absolute affinity of protein-ligand interactions. It can also profile the kinetics of kinase-substrate interactions. By constructing a biophysically robust foundation for profiling sequence recognition, ProBound opens up new avenues for decoding biological networks and rationally engineering protein-ligand interactions.","",""
34,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, Semeen Rehman, M. Shafique","Robust Machine Learning Systems: Reliability and Security for Deep Neural Networks",2018,"","","","",150,"2022-07-13 09:39:14","","10.1109/IOLTS.2018.8474192","","",,,,,34,8.50,7,5,4,"Machine learning is commonly being used in almost all the areas that involve advanced data analytics and intelligent control. From applications like Natural Language Processing (NLP) to autonomous driving are based upon machine learning algorithms. An increasing trend is observed in the use of Deep Neural Networks (DNNs) for such applications. While the slight inaccuracy in applications like NLP does not have any severe consequences, it is not the same for other safety-critical applications, like autonomous driving and smart healthcare, where a small error can lead to catastrophic effects. Apart from high-accuracy DNN algorithms, there is a significant need for robust machine learning systems and hardware architectures that can generate reliable and trustworthy results in the presence of hardware-level faults while also preserving security and privacy. This paper provides an overview of the challenges being faced in ensuring reliable and secure execution of DNNs. To address the challenges, we present several techniques for analyzing and mitigating the reliability and security threats in machine learning systems.","",""
5,"M. Kaden, Katrin Sophie Bohnsack, Mirko Weber, Mateusz Kudla, Kaja Gutowska, J. Blazewicz, T. Villmann","Analysis of SARS-CoV-2 RNA-Sequences by Interpretable Machine Learning Models",2020,"","","","",151,"2022-07-13 09:39:14","","10.1101/2020.05.15.097741","","",,,,,5,2.50,1,7,2,"We present an approach to investigate SARS-CoV-2 virus sequences based on alignment-free methods for RNA sequence comparison. In particular, we verify a given clustering result for the GISAID data set, which was obtained analyzing the molecular differences in coronavirus populations by phylogenetic trees. For this purpose, we use alignment-free dissimilarity measures for sequences and combine them with learning vector quantization classifiers for virus type discriminant analysis and classification. Those vector quantizers belong to the class of interpretable machine learning methods, which, on the one hand side provide additional knowledge about the classification decisions like discriminant feature correlations, and on the other hand can be equipped with a reject option. This option gives the model the property of self controlled evidence if applied to new data, i.e. the models refuses to make a classification decision, if the model evidence for the presented data is not given. After training such a classifier for the GISAID data set, we apply the obtained classifier model to another but unlabeled SARS-CoV-2 virus data set. On the one hand side, this allows us to assign new sequences to already known virus types and, on the other hand, the rejected sequences allow speculations about new virus types with respect to nucleotide base mutations in the viral sequences. Author summary The currently emerging global disease COVID-19 caused by novel SARS-CoV-2 viruses requires all scientific effort to investigate the development of the viral epidemy, the properties of the virus and its types. Investigations of the virus sequence are of special interest. Frequently, those are based on mathematical/statistical analysis. However, machine learning methods represent a promising alternative, if one focuses on interpretable models, i.e. those that do not act as black-boxes. Doing so, we apply variants of Learning Vector Quantizers to analyze the SARS-CoV-2 sequences. We encoded the sequences and compared them in their numerical representations to avoid the computationally costly comparison based on sequence alignments. Our resulting model is interpretable, robust, efficient, and has a self-controlling mechanism regarding the applicability to data. This framework was applied to two data sets concerning SARS-CoV-2. We were able to verify previously published virus type findings for one of the data sets by training our model to accurately identify the virus type of sequences. For sequences without virus type information (second data set), our trained model can predict them. Thereby, we observe a new scattered spreading of the sequences in the data space which probably is caused by mutations in the viral sequences.","",""
2,"Axel X. Montout, R. Bhamber, Debbie S. Lange, Doreen Z. Ndlovu, E. Morgan, C. Ioannou, T. Terrill, J. A. van Wyk, T. Burghardt, A. Dowsey","Accurate and interpretable prediction of poor health in small ruminants with accelerometers and machine learning",2020,"","","","",152,"2022-07-13 09:39:14","","10.1101/2020.08.03.234203","","",,,,,2,1.00,0,10,2,"Accurate assessment of the health status of individual animals is a key step in timely and targeted treatment of infections, which is critical in the fight against anthelmintic and antimicrobial resistance. The FAMACHA scoring system has been used successfully to detect levels of anaemia caused by infection with the parasitic nematode Haemonchus contortus in small ruminants and is an effective way to identify individuals in need of treatment. However, assessing FAMACHA is labour-intensive and costly as individuals must be manually examined at frequent intervals over the Haemonchus season. Here, we show that accelerometers can measure individual activity in extensively grazing small ruminants subject to natural Haemonchus contortus worm infection in southern Africa over long time-scales, and when combined with machine learning, can predict the smallest pre-clinical increases in FAMACHA score as well as those individuals that respond to treatment, all with high precision (>95%). We demonstrate that these classifiers remain robust over time, and remarkably, generalise without retraining across goats and sheep in different regions and types of farming enterprise. Interpretation of the trained classifiers reveal that as the effect of haemonchosis increases, both sheep and goats exhibit a similar reduction in the fine-grained variation of their activity levels. Our study thus reveals common behavioural patterns across small ruminant species, which low-cost biologgers can exploit to detect subtle changes in animal health and enable timely and targeted intervention. This has real potential to improve economic outcomes and animal welfare as well as limit the use of anthelmintic drugs and hence diminish pressures on anthelmintic resistance under conditions of both commercial and resource-poor communal farming. Significance Statement Increasing availability make biologgers and machine learning viable solutions to current challenges in global livestock farming. We demonstrate a pipeline that accurately predicts the earliest signs of parasitic disease in small ruminants. With Haemonchus contortus nematode infection in sheep and goats as the exemplar, we illustrate that the predictive model generalises across time and even species without retraining. We show that prediction is driven by a reduction in the variation of activity levels in animals with poor health. Our findings suggest that health of individual livestock can be monitored remotely, reducing labour costs, improving animal welfare, and allowing for targeted selective treatment under contrasting farming conditions. This will decrease animal loss, maximise economic outcomes, and reduce pressures on drug resistance.","",""
189,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, F. Hutter","Auto-sklearn: Efficient and Robust Automated Machine Learning",2019,"","","","",153,"2022-07-13 09:39:14","","10.1007/978-3-030-05318-5_6","","",,,,,189,63.00,32,6,3,"","",""
506,"W. James Murdoch, Chandan Singh, Karl Kumbier, R. Abbasi-Asl, Bin Yu","Definitions, methods, and applications in interpretable machine learning",2019,"","","","",154,"2022-07-13 09:39:14","","10.1073/pnas.1900654116","","",,,,,506,168.67,101,5,3,"Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.","",""
4,"Hala Abdelkader","Towards Robust Production Machine Learning Systems: Managing Dataset Shift",2020,"","","","",155,"2022-07-13 09:39:14","","10.1145/3324884.3415281","","",,,,,4,2.00,4,1,2,"The advances in machine learning (ML) have stimulated the integration of their capabilities into software systems. However, there is a tangible gap between software engineering and machine learning practices, that is delaying the progress of intelligent services development. Software organisations are devoting effort to adjust the software engineering processes and practices to facilitate the integration of machine learning models. Machine learning researchers as well are focusing on improving the interpretability of machine learning models to support overall system robustness. Our research focuses on bridging this gap through a methodology that evaluates the robustness of machine learning-enabled software engineering systems. In particular, this methodology will automate the evaluation of the robustness properties of software systems against dataset shift problems in ML. It will also feature a notification mechanism that facilitates the debugging of ML components.","",""
1,"Xiaoli Liu, P. Hu, Z. Mao, Po-Chih Kuo, Peiyao Li, Chao Liu, Jie Hu, Deyu Li, Desen Cao, R. Mark, L. Celi, Zhengbo Zhang, F. Zhou","Interpretable Machine Learning Model for Early Prediction of Mortality in Elderly Patients with Multiple Organ Dysfunction Syndrome (MODS): a Multicenter Retrospective Study and Cross Validation",2020,"","","","",156,"2022-07-13 09:39:14","","","","",,,,,1,0.50,0,13,2,"Background: Elderly patients with MODS have high risk of death and poor prognosis. The performance of current scoring systems assessing the severity of MODS and its mortality remains unsatisfactory. This study aims to develop an interpretable and generalizable model for early mortality prediction in elderly patients with MODS. Methods: The MIMIC-III, eICU-CRD and PLAGH-S databases were employed for model generation and evaluation. We used the eXtreme Gradient Boosting model with the SHapley Additive exPlanations method to conduct early and interpretable predictions of patients' hospital outcome. Three types of data source combinations and five typical evaluation indexes were adopted to develop a generalizable model. Findings: The interpretable model, with optimal performance developed by using MIMIC-III and eICU-CRD datasets, was separately validated in MIMIC-III, eICU-CRD and PLAGH-S datasets (no overlapping with training set). The performances of the model in predicting hospital mortality as validated by the three datasets were: AUC of 0.858, sensitivity of 0.834 and specificity of 0.705; AUC of 0.849, sensitivity of 0.763 and specificity of 0.784; and AUC of 0.838, sensitivity of 0.882 and specificity of 0.691, respectively. Comparisons of AUC between this model and baseline models with MIMIC-III dataset validation showed superior performances of this model; In addition, comparisons in AUC between this model and commonly used clinical scores showed significantly better performance of this model. Interpretation: The interpretable machine learning model developed in this study using fused datasets with large sample sizes was robust and generalizable. This model outperformed the baseline models and several clinical scores for early prediction of mortality in elderly ICU patients. The interpretative nature of this model provided clinicians with the ranking of mortality risk features.","",""
200,"W. James Murdoch, Chandan Singh, Karl Kumbier, R. Abbasi-Asl, Bin Yu","Interpretable machine learning: definitions, methods, and applications",2019,"","","","",157,"2022-07-13 09:39:14","","10.1073/pnas.1900654116","","",,,,,200,66.67,40,5,3,"M learning (ML) has recently received considerable attention for its ability to accurately predict a wide variety of complex phenomena. However, there is a growing realization that, in addition to predictions, ML models are capable of producing knowledge about domain relationships contained in data, often referred to as interpretations. These interpretations have found uses both in their own right, e.g. medicine (1), policy-making (2), and science (3, 4), as well as in auditing the predictions themselves in response to issues such as regulatory pressure (5) and fairness (6). In the absence of a well-formed definition of interpretability, a broad range of methods with a correspondingly broad range of outputs (e.g. visualizations, natural language, mathematical equations) have been labeled as interpretation. This has led to considerable confusion about the notion of interpretability. In particular, it is unclear what it means to interpret something, what common threads exist among disparate methods, and how to select an interpretation method for a particular problem/audience. In this paper, we attempt to address these concerns. To do so, we first define interpretability in the context of machine learning and place it within a generic data science life cycle. This allows us to distinguish between two main classes of interpretation methods: model-based∗ and post hoc. We then introduce the Predictive, Descriptive, Relevant (PDR) framework, consisting of three desiderata for evaluating and constructing interpretations: predictive accuracy, descriptive","",""
0,"Qiming Wu","A robust audio-based symbol recognition system using machine learning techniques",2020,"","","","",158,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,2,"This research investigates the creation of an audio-shape recognition system that is able to interpret a user’s drawn audio shapes—fundamental shapes, digits and/or letters— on a given surface such as a table-top using a generic stylus such as the back of a pen. The system aims to make use of one, two or three Piezo microphones, as required, to capture the sound of the audio gestures, and a combination of the Mel-Frequency Cepstral Coefficients (MFCC) feature descriptor and Support Vector Machines (SVMs) to recognise audio shapes. The novelty of the system is in the use of piezo microphones which are low cost, light-weight and portable, and the main investigation is around determining whether these microphones are able to provide sufficiently rich information to recognise the audio shapes mentioned in such a framework.","",""
11,"Evan Greene, Greg Finak, Leonard D'Amico, N. Bhardwaj, C. Church, C. Morishima, N. Ramchurren, J. Taube, P. Nghiem, M. Cheever, S. Fling, R. Gottardo","New interpretable machine learning method for single-cell data reveals correlates of clinical response to cancer immunotherapy",2019,"","","","",159,"2022-07-13 09:39:14","","10.1101/702118","","",,,,,11,3.67,1,12,3,"High-dimensional single-cell cytometry is routinely used to characterize patient responses to cancer immunotherapy and other treatments. This has produced a wealth of datasets ripe for exploration but whose biological and technical heterogeneity make them difficult to analyze with current tools. We introduce a new interpretable machine learning method for single-cell mass and flow cytometry studies, FAUST, that robustly performs unbiased cell population discovery and annotation. FAUST processes data on a per-sample basis and returns biologically interpretable cell phenotypes that can be compared across studies, making it well-suited for the analysis and integration of complex datasets. We demonstrate how FAUST can be used for candidate biomarker discovery and validation by applying it to a flow cytometry dataset from a Merkel cell carcinoma anti-PD-1 trial and discover new CD4+ and CD8+ effector-memory T cell correlates of outcome co-expressing PD-1, HLA-DR, and CD28. We then use FAUST to validate these correlates in an independent CyTOF dataset from a published metastatic melanoma trial. Importantly, existing state-of-the-art computational discovery approaches as well as prior manual analysis did not detect these or any other statistically significant T cell sub-populations associated with anti-PD-1 treatment in either data set. We further validate our methodology by using FAUST to replicate the discovery of a previously reported myeloid correlate in a different published melanoma trial, and validate the correlate by identifying itde novoin two additional independent trials. FAUST’s phenotypic annotations can be used to perform cross-study data integration in the presence of heterogeneous data and diverse immunophenotyping staining panels, enabling hypothesis-driven inference about cell sub-population abundance through a multivariate modeling framework we callPhenotypic andFunctionalDifferentialAbundance (PFDA). We demonstrate this approach on data from myeloid and T cell panels across multiple trials. Together, these results establish FAUST as a powerful and versatile new approach for unbiased discovery in single-cell cytometry.","",""
11,"Tamer Karatekin, S. Sancak, G. Celik, S. Topçuoğlu, G. Karatekin, Pınar Kırcı, A. Okatan","Interpretable Machine Learning in Healthcare through Generalized Additive Model with Pairwise Interactions (GA2M): Predicting Severe Retinopathy of Prematurity",2019,"","","","",160,"2022-07-13 09:39:14","","10.1109/Deep-ML.2019.00020","","",,,,,11,3.67,2,7,3,"We have investigated the risk factors that lead to severe retinopathy of prematurity using statistical analysis and logistic regression as a form of generalized additive model (GAM) with pairwise interaction terms (GA2M). In this process, we discuss the trade-off between accuracy and interpretability of these machine learning techniques on clinical data. We also confirm the intuition of expert neonatologists on a few risk factors, such as gender, that were previously deemed as clinically not significant in RoP prediction.","",""
19,"Bradley C. Boehmke, Brandon M. Greenwell","Interpretable Machine Learning",2019,"","","","",161,"2022-07-13 09:39:14","","10.1201/9780367816377-16","","",,,,,19,6.33,10,2,3,"","",""
191,"M. Ahmad, A. Teredesai, C. Eckert","Interpretable Machine Learning in Healthcare",2018,"","","","",162,"2022-07-13 09:39:14","","10.1145/3233547.3233667","","",,,,,191,47.75,64,3,4,"This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare.","",""
199,"Christoph Molnar, Giuseppe Casalicchio, B. Bischl","iml: An R package for Interpretable Machine Learning",2018,"","","","",163,"2022-07-13 09:39:14","","10.21105/joss.00786","","",,,,,199,49.75,66,3,4,"Complex, non-parametric models, which are typically used in machine learning, have proven to be successful in many prediction tasks. But these models usually operate as black boxes: While they are good at predicting, they are often not interpretable. Many inherently interpretable models have been suggested, which come at the cost of losing predictive power. Another option is to apply interpretability methods to a black box model after model training. Given the velocity of research on new machine learning models, it is preferable to have model-agnostic tools which can be applied to a random forest as well as to a neural network. Tools for model-agnostic interpretability methods should improve the adoption of machine learning.","",""
0,"L. Tideman","Interpretable Machine Learning for Biomarker Discovery in Imaging Mass Spectrometry Data",2019,"","","","",164,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,1,3,"Imaging mass spectrometry (IMS) is a multiplexed chemical imaging technique that enables the spatially targeted molecular mapping of biological samples at cellular resolutions. Within a single experiment, IMS can measure the spatial distribution and relative concentration of thousands of distinct molecular species across the surface of a tissue sample. The large size and high-dimensionality of IMS datasets, which can consist of hundreds of thousands of pixels and hundreds to thousands of molecular ions tracked per pixel, have made computational approaches necessary for effective analysis. This thesis focuses primarily on biomarker discovery in IMS data using supervised machine learning algorithms. Biomarker discovery is the identification of molecular markers that enable the recognition of a specific biological state, for example recognizing diseased tissue from healthy tissue. Biomarkers are increasingly used in biology and medicine for diagnostic and prognostic purposes, as well as for driving the development of new drugs and therapies. Traditionally, the focus has been on maximizing the predictive performance of supervised machine learning models, without necessarily examining the models' internal decision-making processes. Yet, in order to generate insight into the underlying chemical mechanism of disease or drug action, we must go beyond the scope of just prediction and learn how these empirically trained models make their decisions and who are the primary chemical drivers of this prediction process. Machine learning model interpretability is the ability to explain a model's predictions, and can practically be translated into the ability to explicitly report the relative predictive importance of each of the dataset's features. When analyzing IMS data, interpretability is crucial for understanding how the spatial distribution and relative concentration of certain molecular features relate to the labeling of pixels into different physiological classes. The key to our data-driven approach to biomarker discovery in IMS data is to establish (in relation to a specific biomedical recognition task) a means of ranking the molecular features of supervised machine learning models according to their respective predictive importance scores. Ensuring model interpretability and feature ranking in supervised machine learning allows empirical model building to be used as a filtering mechanism to rapidly determine, among thousands of features, those features that exert a large amount of relevance to a specific class determination. With regards to biology, the top-ranking features can help empirically highlight important molecular drivers in the biological process under examination, and can help generate new hypotheses. In terms of translational medicine, such top-ranking features can yield a shortlist of candidate biomarkers worthy of further clinical investigation. Three different classifiers, namely logistic regression, random forests, and support vector machines, are implemented and their performance is compared in terms of accuracy, precision, recall, scale invariance, sensitivity to noise, and computational efficiency. Subsequently, several approaches to explaining these classifiers' predictions are implemented and investigated: model-specific interpretability methods are tied to intrinsically interpretable classifiers, such as generalized linear models and decision trees, whereas model-agnostic interpretability methods can also explain the predictions of black-box models, such as support vector machines with nonlinear kernels or deep neural networks. In addition to three model-specific methods, we present two post-hoc model-agnostic interpretability methods: permutation importance and Shapley importance. Our implementation of Shapley importance, based on Shapley values from cooperative game theory, is novel. Having observed a variability between the rankings of different interpretability methods, we investigate improving the inter-method reliability of feature rankings by decorrelating the features prior to training the classifiers. We also propose a robust ensemble approach to interpretability that aggregates the importance scores attributed to each feature by different model-specific interpretability methods. We demonstrate our methodology on two biomedical case studies: one MALDI-FTICR IMS dataset taken from the coronal section of a rat brain, and one MALDI-TOF IMS dataset taken from the sagittal section of a mouse-pup.","",""
0,"Yuan Wang, Liping Yang, Jun Wu, Zisheng Song, Li-nan Shi","Mining Campus Big Data: Prediction of Career Choice Using Interpretable Machine Learning Method",2022,"","","","",165,"2022-07-13 09:39:14","","10.3390/math10081289","","",,,,,0,0.00,0,5,1,"The issue of students’ career choice is the common concern of students themselves, parents, and educators. However, students’ behavioral data have not been thoroughly studied for understanding their career choice. In this study, we used eXtreme Gradient Boosting (XGBoost), a machine learning (ML) technique, to predict the career choice of college students using a real-world dataset collected in a specific college. Specifically, the data include information on the education and career choice of 18,000 graduates during their college years. In addition, SHAP (Shapley Additive exPlanation) was employed to interpret the results and analyze the importance of individual features. The results show that XGBoost can predict students’ career choice robustly with a precision, recall rate, and an F1 value of 89.1%, 85.4%, and 0.872, respectively. Furthermore, the interaction of features among four different choices of students (i.e., choose to study in China, choose to work, difficulty in finding a job, and choose to study aboard) were also explored. Several educational features, especially differences in grade point average (GPA) during their college studying, are found to have relatively larger impact on the final choice of career. These results can be of help in the planning, design, and implementation of higher educational institutions’ (HEIs) events.","",""
45,"H. Escalante, S. Escalera, I. Guyon, Xavier Baró, Yağmur Güçlütürk, Umut Güçlü, M. V. Gerven","Explainable and Interpretable Models in Computer Vision and Machine Learning",2018,"","","","",166,"2022-07-13 09:39:14","","10.1007/978-3-319-98131-4","","",,,,,45,11.25,6,7,4,"","",""
0,"Sasmitha Dasanayaka, S. Silva, V. Shantha, D. Meedeniya, Thanuja D. Ambegoda","Interpretable Machine Learning for Brain Tumor Analysis Using MRI",2022,"","","","",167,"2022-07-13 09:39:14","","10.1109/ICARC54489.2022.9754131","","",,,,,0,0.00,0,5,1,"A brain tumor is a potentially fatal growth of cells in the central nervous system that can be categorized as benign or malignant. Advancements in deep learning in the recent past and the availability of high computational power have been influencing the automation of diagnosing brain tumors. DenseNet and U-Net are considered state of the art deep learning models for classification and segmentation of MRIs respectively. Despite the progress of deep learning in diagnosing using medical images, generic convolutional neural networks are still not fully adopted in clinical settings as they lack robustness and reliability. Moreover, such black-box models don’t offer a human interpretable justification as to why certain classification decisions are made, which makes them less preferable for medical diagnostics. Brain tumor segmentation and classification using deep learning techniques has been a popular research area in the last few decades but still, there are only a few models that are interpretable. In this paper, we have proposed an interpretable deep learning model which is more human understandable than existing black-box models, designed based on U-Net and DenseNet to segment and classify brain tumors using MRI. In our proposed model, we generate a heat map highlighting the contribution of each region of the input to the classification output and have validated the system using the MICCAI 2020 Brain Tumor dataset.","",""
26,"M. Hasan, Md. Ashad Alam, W. Shoombuatong, H. Deng, Balachandran Manavalan, H. Kurata","NeuroPred-FRL: an interpretable prediction model for identifying neuropeptide using feature representation learning.",2021,"","","","",168,"2022-07-13 09:39:14","","10.1093/bib/bbab167","","",,,,,26,26.00,4,6,1,"Neuropeptides (NPs) are the most versatile neurotransmitters in the immune systems that regulate various central anxious hormones. An efficient and effective bioinformatics tool for rapid and accurate large-scale identification of NPs is critical in immunoinformatics, which is indispensable for basic research and drug development. Although a few NP prediction tools have been developed, it is mandatory to improve their NPs' prediction performances. In this study, we have developed a machine learning-based meta-predictor called NeuroPred-FRL by employing the feature representation learning approach. First, we generated 66 optimal baseline models by employing 11 different encodings, six different classifiers and a two-step feature selection approach. The predicted probability scores of NPs based on the 66 baseline models were combined to be deemed as the input feature vector. Second, in order to enhance the feature representation ability, we applied the two-step feature selection approach to optimize the 66-D probability feature vector and then inputted the optimal one into a random forest classifier for the final meta-model (NeuroPred-FRL) construction. Benchmarking experiments based on both cross-validation and independent tests indicate that the NeuroPred-FRL achieves a superior prediction performance of NPs compared with the other state-of-the-art predictors. We believe that the proposed NeuroPred-FRL can serve as a powerful tool for large-scale identification of NPs, facilitating the characterization of their functional mechanisms and expediting their applications in clinical therapy. Moreover, we interpreted some model mechanisms of NeuroPred-FRL by leveraging the robust SHapley Additive exPlanation algorithm.","",""
0,"Takaki Yamamoto, Katie Cockburn, V. Greco, Kyogo Kawaguchi","Probing the rules of cell coordination in live tissues by interpretable machine learning based on graph neural networks",2022,"","","","",169,"2022-07-13 09:39:14","","10.1101/2021.06.23.449559","","",,,,,0,0.00,0,4,1,"Robustness in developing and homeostatic tissues is supported by various types of spatiotemporal cell-to-cell interactions. Although live imaging and cell tracking are powerful in providing direct evidence of cell coordination rules, extracting and comparing these rules across many tissues with potentially different length and timescales of coordination requires a versatile framework of analysis. Here we demonstrate that graph neural network (GNN) models are suited for this purpose, by showing how they can be applied to predict cell fate in tissues and utilized to infer the cell interactions governing the multicellular dynamics. Analyzing the live mammalian epidermis data, where spatiotemporal graphs constructed from cell tracks and cell contacts are given as inputs, GNN discovers distinct neighbor cell fate coordination rules that depend on the region of the body. This approach demonstrates how the GNN framework is powerful in inferring general cell interaction rules from live data without prior knowledge of the signaling involved.","",""
14,"Xuhong Li, Haoyi Xiong, Xingjian Li, Xuanyu Wu, Xiao Zhang, Ji Liu, Jiang Bian, D. Dou","Interpretable Deep Learning: Interpretations, Interpretability, Trustworthiness, and Beyond",2021,"","","","",170,"2022-07-13 09:39:14","","","","",,,,,14,14.00,2,8,1,"Deep neural networks have been well-known for their superb performance in handling various machine learning and artificial intelligence tasks. However, due to their over-parameterized black-box nature, it is often difficult to understand the prediction results of deep models. In recent years, many interpretation tools have been proposed to explain or reveal the ways that deep models make decisions. In this paper, we review this line of research and try to make a comprehensive survey. Specifically, we introduce and clarify two basic concepts— interpretations and interpretability—that people usually get confused. First of all, to address the research efforts in interpretations, we elaborate the design of several recent interpretation algorithms, from different perspectives, through proposing a new taxonomy. Then, to understand the results of interpretation, we also survey the performance metrics for evaluating interpretation algorithms. Further, we summarize the existing work in evaluating models’ interpretability using “trustworthy” interpretation algorithms. Finally, we review and discuss the connections between deep models’ interpretations and other factors, such as adversarial robustness and data augmentations, and we introduce several open-source libraries for interpretation algorithms and evaluation approaches.","",""
5,"A. Pierrefeu, Tommy Löfstedt, C. Laidi, F. Hadj-Selem, M. Leboyer, P. Ciuciu, J. Houenou, E. Duchesnay","Interpretable and stable prediction of schizophrenia on a large multisite dataset using machine learning with structured sparsity",2018,"","","","",171,"2022-07-13 09:39:14","","10.1109/PRNI.2018.8423946","","",,,,,5,1.25,1,8,4,"The use of machine-learning (ML) in neuroimaging offers new perspectives in early diagnosis and prognosis of brain diseases. Indeed, ML algorithms can jointly examine all brain features to capture complex relationships in the data in order to make inferences at a single-subject level. To deal with such high dimensional input and the associated risk of overfitting on the training data, a proper regularization (or feature selection) is required. Standard ℓ2-regularized predictors, such as Support Vector Machine, provide dense patterns of predictors. However, in the context of predictive disease signature discovery, it is now essential to understand the brain pattern that underpins the prediction. Despite ℓ1-regularized (sparse) has often been advocated as leading to more interpretable models, they generally lead to scattered and unstable patterns. We hypothesize that the integration of prior knowledge regarding the structure of the input images should improve the relevance and the stability of the predictive signature. Such structured sparsity can be obtained by combining together ℓ1 (possibly ℓ2) and Total variation (TV) penalties. We demonstrated the relevance of using ML with structured sparsity on a large multisite dataset of schizophrenia patients and controls. Using 3D maps of grey matter density, we obtained promising inter-site prediction performances. More importantly, we have uncovered a predictive signature of schizophrenia that is clinically interpretable and stable across resampling. This suggests that structured sparsity provides a major breakthrough over ‘off-the-shelf’ algorithms to perform a robust selection of important brain regions in the context of biomarkers discovery.","",""
12,"E. M. Mortani Barbosa, B. Georgescu, S. Chaganti, G. Alemañ, Jordi Broncano Cabrero, G. Chabin, T. Flohr, P. Grenier, Sasa Grbic, Nakul Gupta, F. Mellot, S. Nicolaou, Thomas J. Re, P. Sanelli, A. Sauter, Y. Yoo, Valentin Ziebandt, D. Comaniciu","Machine learning automatically detects COVID-19 using chest CTs in a large multicenter cohort",2020,"","","","",172,"2022-07-13 09:39:14","","10.1007/s00330-021-07937-3","","",,,,,12,6.00,1,18,2,"","",""
10,"Alexander Trott, Sunil Srinivasa, D. V. D. Wal, S. Haneuse, Stephan Zheng","Building a Foundation for Data-Driven, Interpretable, and Robust Policy Design using the AI Economist",2021,"","","","",173,"2022-07-13 09:39:14","","10.2139/ssrn.3900237","","",,,,,10,10.00,2,5,1,"Optimizing economic and public policy is critical to address socioeconomic issues and trade-offs, e.g., improving equality, productivity, or wellness, and poses a complex mechanism design problem. A policy designer needs to consider multiple objectives, policy levers, and behavioral responses from strategic actors who optimize for their individual objectives. Moreover, real-world policies should be explainable and robust to simulation-to-reality gaps, e.g., due to calibration issues. Existing approaches are often limited to a narrow set of policy levers or objectives that are hard to measure, do not yield explicit optimal policies, or do not consider strategic behavior, for example. Hence, it remains challenging to optimize policy in real-world scenarios. Here we show that the AI Economist framework enables effective, flexible, and interpretable policy design using two-level reinforcement learning (RL) and data-driven simulations. We validate our framework on optimizing the stringency of \USState{} policies and Federal subsidies during a pandemic, e.g., COVID-19, using a simulation fitted to real data. We find that log-linear policies trained using RL significantly improve social welfare, based on both public health and economic outcomes, compared to past outcomes. Their behavior can be explained, e.g., well-performing policies respond strongly to changes in recovery and vaccination rates. They are also robust to calibration errors, e.g., infection rates that are over or underestimated. As of yet, real-world policymaking has not seen adoption of machine learning methods at large, including RL and AI-driven simulations. Our results show the potential of AI to guide policy design and improve social welfare amidst the complexity of the real world.","",""
7,"E. Rozos, P. Dimitriadis, V. Bellos","Machine Learning in Assessing the Performance of Hydrological Models",2021,"","","","",174,"2022-07-13 09:39:14","","10.3390/hydrology9010005","","",,,,,7,7.00,2,3,1,"Machine learning has been employed successfully as a tool virtually in every scientific and technological field. In hydrology, machine learning models first appeared as simple feed-forward networks that were used for short-term forecasting, and have evolved into complex models that can take into account even the static features of catchments, imitating the hydrological experience. Recent studies have found machine learning models to be robust and efficient, frequently outperforming the standard hydrological models (both conceptual and physically based). However, and despite some recent efforts, the results of the machine learning models require significant effort to interpret and derive inferences. Furthermore, all successful applications of machine learning in hydrology are based on networks of fairly complex topology that require significant computational power and CPU time to train. For these reasons, the value of the standard hydrological models remains indisputable. In this study, we suggest employing machine learning models not as a substitute for hydrological models, but as an independent tool to assess their performance. We argue that this approach can help to unveil the anomalies in catchment data that do not fit in the employed hydrological model structure or configuration, and to deal with them without compromising the understanding of the underlying physical processes.","",""
9,"Chun-Hao Chang, R. Caruana, A. Goldenberg","NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning",2021,"","","","",175,"2022-07-13 09:39:14","","","","",,,,,9,9.00,3,3,1,"Deployment of machine learning models in real high-risk settings (e.g. healthcare) often depends not only on model’s accuracy but also on its fairness, robustness and interpretability. Generalized Additive Models (GAMs) have a long history of use in these high-risk domains, but lack desirable features of deep learning such as differentiability and scalability. In this work, we propose a neural GAM (NODE-GAM) and neural GAM (NODE-GAM) that scale well to large datasets, while remaining interpretable and accurate. We show that our proposed models have comparable accuracy to other non-interpretable models, and outperform other GAMs on large datasets. We also show that our models are more accurate in self-supervised learning setting when access to labeled data is limited.","",""
6,"Matthew Norton, Akiko Takeda, Alexander Mafusalov","Optimistic Robust Optimization With Applications To Machine Learning",2017,"","","","",176,"2022-07-13 09:39:14","","","","",,,,,6,1.20,2,3,5,"Robust Optimization has traditionally taken a pessimistic, or worst-case viewpoint of uncertainty which is motivated by a desire to find sets of optimal policies that maintain feasibility under a variety of operating conditions. In this paper, we explore an optimistic, or best-case view of uncertainty and show that it can be a fruitful approach. We show that these techniques can be used to address a wide variety of problems. First, we apply our methods in the context of robust linear programming, providing a method for reducing conservatism in intuitive ways that encode economically realistic modeling assumptions. Second, we look at problems in machine learning and find that this approach is strongly connected to the existing literature. Specifically, we provide a new interpretation for popular sparsity inducing non-convex regularization schemes. Additionally, we show that successful approaches for dealing with outliers and noise can be interpreted as optimistic robust optimization problems. Although many of the problems resulting from our approach are non-convex, we find that DCA or DCA-like optimization approaches can be intuitive and efficient.","",""
4,"Rahul Singh","A Finite Sample Theorem for Longitudinal Causal Inference with Machine Learning: Long Term, Dynamic, and Mediated Effects",2021,"","","","",177,"2022-07-13 09:39:14","","","","",,,,,4,4.00,4,1,1,"I construct and justify confidence intervals for longitudinal causal parameters estimated with machine learning. Longitudinal parameters include long term, dynamic, and mediated effects. I provide a nonasymptotic theorem for any longitudinal causal parameter estimated with any machine learning algorithm that satisfies a few simple, interpretable conditions. The main result encompasses local parameters defined for specific demographics as well as proximal parameters defined in the presence of unobserved confounding. Formally, I prove consistency, Gaussian approximation, and semiparametric efficiency. The rate of convergence is n for global parameters, and it degrades gracefully for local parameters. I articulate a simple set of conditions to translate mean square rates into statistical inference. A key feature of the main result is a new multiple robustness to ill posedness for proximal causal inference in longitudinal settings.","",""
6,"Kaveri A. Thakoor, Sharath C. Koorathota, D. Hood, P. Sajda","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images",2020,"","","","",178,"2022-07-13 09:39:14","","10.1109/tbme.2020.3043215","","",,,,,6,3.00,2,4,2,"Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","",""
242,"Pantelis Linardatos, Vasilis Papastefanopoulos, S. Kotsiantis","Explainable AI: A Review of Machine Learning Interpretability Methods",2020,"","","","",179,"2022-07-13 09:39:14","","10.3390/e23010018","","",,,,,242,121.00,81,3,2,"Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.","",""
4,"A. Serban, Joost Visser","An Empirical Study of Software Architecture for Machine Learning",2021,"","","","",180,"2022-07-13 09:39:14","","","","",,,,,4,4.00,2,2,1,"Specific developmental and operational characteristics of machine learning (ML) components, as well as their inherent uncertainty, demand robust engineering principles are used to ensure their quality. We aim to determine how software systems can be (re-) architected to enable robust integration of ML components. Towards this goal, we conducted a mixed-methods empirical study consisting of (i) a systematic literature review to identify the challenges and their solutions in software architecture for ML, (ii) semi-structured interviews with practitioners to qualitatively complement the initial findings, and (iii) a survey to quantitatively validate the challenges and their solutions. In total, we compiled and validated twenty challenges and solutions for (re-) architecting systems with ML components. Our results indicate, for example, that traditional software architecture challenges (e.g., component coupling) also play an important role when using ML components; along new ML specific challenges (e.g., the need for continuous retraining). Moreover, the results indicate that ML heightened decision drivers, such as privacy, play a marginal role compared to traditional decision drivers, such as scalability or interoperability. Using the survey, we were able to establish a link between architectural solutions and software quality attributes; which enabled us to provide twenty architectural tactics used for satisfying individual quality requirements of systems with ML components. Altogether, the results can be interpreted as an empirical framework that supports the process of (re-) architecting software systems with ML components.","",""
4,"A. Mei, I. Milosavljevic, A. L. Simpson, Valerie A. Smetanka, Colin P. Feeney, Shay M. Seguin, S. D. Ha, W. Ha, M. Reed","Optimization of quantum-dot qubit fabrication via machine learning",2020,"","","","",181,"2022-07-13 09:39:14","","10.1063/5.0040967","","",,,,,4,2.00,0,9,2,"Precise nanofabrication represents a critical challenge to developing semiconductor quantum-dot qubits for practical quantum computation. Here, we design and train a convolutional neural network to interpret in-line scanning electron micrographs and quantify qualitative features affecting device functionality. The high-throughput strategy is exemplified by optimizing a model lithographic process within a five-dimensional design space and by demonstrating a new approach to address lithographic proximity effects. The present results emphasize the benefits of machine learning for developing robust processes, shortening development cycles, and enforcing quality control during qubit fabrication.","",""
1,"Khansa Rasheed, A. Qayyum, M. Ghaly, A. Al-Fuqaha, A. Razi, Junaid Qadir","Explainable, Trustworthy, and Ethical Machine Learning for Healthcare: A Survey",2021,"","","","",182,"2022-07-13 09:39:14","","10.36227/TECHRXIV.14376179.V1","","",,,,,1,1.00,0,6,1,"With the advent of machine learning (ML) applications in daily life, the questions about liability, trust, and interpretability of their outputs are raising, especially for healthcare applications. The black-box nature of ML models is a roadblock for clinical utilization. Therefore, to gain the trust of clinicians and patients, researchers need to provide explanations of how and why the model is making a specific decision. With the promise of enhancing the trust and transparency of black-box models, researchers are in the phase of maturing the field of eXplainable ML (XML). In this paper, we provide a comprehensive review of explainable and interpretable ML techniques implemented for providing the reasons behind their decisions for various healthcare applications. Along with highlighting various security, safety, and robustness challenges that hinder the trustworthiness of ML we also discussed the ethical issues of healthcare ML and describe how explainable and trustworthy ML can resolve these ethical problems. Finally, we elaborate on the limitations of existing approaches and highlight various open research problems that require further development.","",""
3,"A. Ounajim, M. Billot, L. Goudman, P. Louis, Y. Slaoui, M. Roulaud, B. Bouche, P. Page, B. Lorgeoux, Sandrine Baron, Nihel Adjali, K. Nivole, Nicolas Naiditch, Chantal Wood, Raphaël Rigoard, R. David, M. Moens, P. Rigoard","Machine Learning Algorithms Provide Greater Prediction of Response to SCS Than Lead Screening Trial: A Predictive AI-Based Multicenter Study",2021,"","","","",183,"2022-07-13 09:39:14","","10.3390/jcm10204764","","",,,,,3,3.00,0,18,1,"Persistent pain after spinal surgery can be successfully addressed by spinal cord stimulation (SCS). International guidelines strongly recommend that a lead trial be performed before any permanent implantation. Recent clinical data highlight some major limitations of this approach. First, it appears that patient outco mes, with or without lead trial, are similar. In contrast, during trialing, infection rate drops drastically within time and can compromise the therapy. Using composite pain assessment experience and previous research, we hypothesized that machine learning models could be robust screening tools and reliable predictors of long-term SCS efficacy. We developed several algorithms including logistic regression, regularized logistic regression (RLR), naive Bayes classifier, artificial neural networks, random forest and gradient-boosted trees to test this hypothesis and to perform internal and external validations, the objective being to confront model predictions with lead trial results using a 1-year composite outcome from 103 patients. While almost all models have demonstrated superiority on lead trialing, the RLR model appears to represent the best compromise between complexity and interpretability in the prediction of SCS efficacy. These results underscore the need to use AI-based predictive medicine, as a synergistic mathematical approach, aimed at helping implanters to optimize their clinical choices on daily practice.","",""
3,"R. Barker, S. Barker, M. Cracknell, Elizabeth D. Stock, G. Holmes","Quantitative Mineral Mapping of Drill Core Surfaces II: Long-Wave Infrared Mineral Characterization Using μXRF and Machine Learning",2021,"","","","",184,"2022-07-13 09:39:14","","10.5382/econgeo.4804","","",,,,,3,3.00,1,5,1,"Long-wave infrared (LWIR) spectra can be interpreted using a Random Forest machine learning approach to predict mineral species and abundances. In this study, hydrothermally altered carbonate rock core samples from the Fourmile Carlin-type Au discovery, Nevada, were analyzed by LWIR and micro-X-ray fluorescence (μXRF). Linear programming-derived mineral abundances from quantified μXRF data were used as training data to construct a series of Random Forest regression models. The LWIR Random Forest models produced mineral proportion estimates with root mean square errors of 1.17 to 6.75% (model predictions) and 1.06 to 6.19% (compared to quantitative X-ray diffraction data) for calcite, dolomite, kaolinite, white mica, phlogopite, K-feldspar, and quartz. These results are comparable to the error of proportion estimates from linear spectral deconvolution (±7–15%), a commonly used spectral unmixing technique. Having a mineralogical and chemical training data set makes it possible to identify and quantify mineralogy and provides a more robust and meaningful LWIR spectral interpretation than current methods of utilizing a spectral library or spectral end-member extraction. Using the method presented here, LWIR spectroscopy can be used to overcome the limitations inherent with the use of short-wave infrared (SWIR) in fine-grained, low reflectance rocks. This new approach can be applied to any deposit type, improving the accuracy and speed of infrared data interpretation.","",""
3,"Jivitesh Sharma, Rohan Kumar Yadav, Ole-Christoffer Granmo, Lei Jiao","Human Interpretable AI: Enhancing Tsetlin Machine Stochasticity with Drop Clause",2021,"","","","",185,"2022-07-13 09:39:14","","","","",,,,,3,3.00,1,4,1,"In this article, we introduce a novel variant of the Tsetlin machine (TM) that randomly drops clauses, the key learning elements of a TM. In effect, TM with drop clause ignores a random selection of the clauses in each epoch, selected according to a predefined probability. In this way, additional stochasticity is introduced in the learning phase of TM. Along with producing more distinct and well-structured patterns that improve the performance, we also show that dropping clauses increases learning robustness. To explore the effects clause dropping has on accuracy, training time, and interpretability, we conduct extensive experiments on various benchmark datasets in natural language processing (NLP) (IMDb and SST2) as well as computer vision (MNIST and CIFAR10). In brief, we observe from +2% to +4% increase in accuracy and 2× to 4× faster learning. We further employ the Convolutional TM to document interpretable results on the CIFAR10 dataset. To the best of our knowledge, this is the first time an interpretable machine learning algorithm has been used to produce pixel-level human-interpretable results on CIFAR10. Also, unlike previous interpretable methods that focus on attention visualisation or gradient interpretability, we show that the TM is a more general interpretable method. That is, by producing rule-based propositional logic expressions that are human-interpretable, the TM can explain how it classifies a particular instance at the pixel level for computer vision and at the word level for NLP.","",""
2,"N. Frolov, Muhammad Salman Kabir, V. Maksimenko, A. Hramov","Machine learning evaluates changes in functional connectivity under a prolonged cognitive load.",2021,"","","","",186,"2022-07-13 09:39:14","","10.1063/5.0070493","","",,,,,2,2.00,1,4,1,"One must be aware of the black-box problem by applying machine learning models to analyze high-dimensional neuroimaging data. It is due to a lack of understanding of the internal algorithms or the input features upon which most models make decisions despite outstanding performance in classification, pattern recognition, and prediction. Here, we approach the fundamentally high-dimensional problem of classifying cognitive brain states based on functional connectivity by selecting and interpreting the most relevant input features. Specifically, we consider the alterations in the cortical synchrony under a prolonged cognitive load. Our study highlights the advances of this machine learning method in building a robust classification model and percept-related prestimulus connectivity changes over the conventional trial-averaged statistical analysis.","",""
1,"P. Benner, A. Klawonn, M. Stoll","Topical Issue Scientific Machine Learning (1/2)",2021,"","","","",187,"2022-07-13 09:39:14","","10.1002/gamm.202100005","","",,,,,1,1.00,0,3,1,"Scientific Machine Learning is a rapidly evolving field of research that combines and further develops techniques of scientific computing and machine learning. Special emphasis is given to the scientific (physical, chemical, biological, etc.) interpretability of models learned from data and their usefulness for robust predictions. On the other hand, this young field also investigates the utilization of Machine Learning methods for improving numerical algorithms in Scientific Computing. The name Scientific Machine Learning has been coined at a Basic Research Needs Workshop of the US Department of Energy (DOE) in January, 2018. It resulted in a report [2] published in February, 2019; see also [1] for a short brochure on this topic. The present special issue of the GAMM Mitteilungen, which is the first of a two-part series, contains contributions on the topic of Scientific Machine Learning in the context of complex applications across the sciences and engineering. Research in this new exciting field needs to address challenges such as complex physics, uncertain parameters, and possibly limited data through the development of new methods that combine algorithms from computational science and engineering and from numerical analysis with state of the art techniques from machine learning. At the GAMM Annual Meeting 2019, the activity group Computational and Mathematical Methods in Data Science (CoMinDS) has been established. Meanwhile, it has become a meeting place for researchers interested in all aspects of data science. All three editors of this special issue are founding members of this activity group. Because of the rapid development both in the theoretical foundations and the applicability of Scientific Machine Learning techniques, it is time to highlight developments within the field in the hope that it will become an essential domain within the GAMM and topical issues like this will have a frequent occurrence within this journal. We are happy that eight teams of authors have accepted our invitation to report on recent research highlights in Scientific Machine Learning, and to point out the relevant literature as well as software. The four papers in this first part of the special issue are: • Stoll, Benner: Machine Learning for Material Characterization with an Application for Predicting Mechanical Properties. This work explores the use of machine learning techniques for material property prediction. Given the abundance of data available in industrial applications, machine learning methods can help finding patterns in the data and the authors focus on the case of the small punch test and tensile data for illustration purposes. • Beck, Kurz: A Perspective on Machine Modelling Learning Methods in Turbulence. Turbulence modelling remains a humongous challenge in the simulation and analysis of complex flows. The authors review the use of data-driven techniques to open up new ways for studying turbulence and focus on the challenges and opportunities that machine learning brings to this field. • Heinlein, Klawonn, Lanser, Weber: Combining Machine Learning and Domain Decomposition Methods for the Solution of Partial Differential Equations – A Review. Domain decomposition (DD) has been a workhorse of solving complex simulation tasks. The authors review the combination of machine learning approaches with state-of-the-art DD-schemes. Their focus is on the use of ML techniques to improve the computational effort of adaptive domain decomposition schemes and the use of novel ML methods for the discretization and solution of subdomain problems. • Budd, van Gennip, Latz: Classification and image processing with a semi-discrete scheme for fidelity forced Allen–Cahn on graphs. Learning based on graphs provides exciting possibilities for discovering and using additional structure in data. In this work, the authors illustrate the use of a PDE-based learning technique relying on the graph Allen-Cahn equation for the segmentation of images. The authors illustrate that computational and mathematical advances can lead to efficiency and accuracy gains. Peter Benner1,2 Axel Klawonn3,4 Martin Stoll5","",""
2,"D. Devakumar, Goutham Sunny, B. Sasidharan, S. Bowen, Ambily Nadaraj, L. Jeyseelan, Manu Mathew, A. Irodi, R. Isiah, S. Pavamani, S. John, H. T. T Thomas","Framework for Machine Learning of CT and PET Radiomics to Predict Local Failure after Radiotherapy in Locally Advanced Head and Neck Cancers",2021,"","","","",188,"2022-07-13 09:39:14","","10.4103/jmp.JMP_6_21","","",,,,,2,2.00,0,12,1,"Context: Cancer Radiomics is an emerging field in medical imaging and refers to the process of converting routine radiological images that are typically qualitatively interpreted to quantifiable descriptions of the tumor phenotypes and when combined with statistical analytics can improve the accuracy of clinical outcome prediction models. However, to understand the radiomic features and their correlation to molecular changes in the tumor, first, there is a need for the development of robust image analysis methods, software tools and statistical prediction models which is often limited in low- and middle-income countries (LMIC). Aims: The aim is to build a framework for machine learning of radiomic features of planning computed tomography (CT) and positron emission tomography (PET) using open source radiomics and data analytics platforms to make it widely accessible to clinical groups. The framework is tested in a small cohort to predict local disease failure following radiation treatment for head-and-neck cancer (HNC). The predictors were also compared with the existing Aerts HNC radiomics signature. Settings and Design: Retrospective analysis of patients with locally advanced HNC between 2017 and 2018 and 31 patients with both pre- and post-radiation CT and evaluation PET were selected. Subjects and Methods: Tumor volumes were delineated on baseline PET using the semi-automatic adaptive-threshold algorithm and propagated to CT; PyRadiomics features (total of 110 under shape/intensity/texture classes) were extracted. Two feature-selection methods were tested for model stability. Models were built based on least absolute shrinkage and selection operator-logistic and Ridge regression of the top pretreatment radiomic features and compared to Aerts' HNC-signature. Average model performance across all internal validation test folds was summarized by the area under the receiver operator curve (ROC). Results: Both feature selection methods selected CT features MCC (GLCM), SumEntropy (GLCM) and Sphericity (Shape) that could predict the binary failure status in the cross-validated group and achieved an AUC >0.7. However, models using Aerts' signature features (Energy, Compactness, GLRLM-GrayLevelNonUniformity and GrayLevelNonUniformity-HLH wavelet) could not achieve a clear separation between outcomes (AUC = 0.51–0.54). Conclusions: Radiomics pipeline included open-source workflows which makes it adoptable in LMIC countries. Additional independent validation of data is crucial for the implementation of radiomic models for clinical risk stratification.","",""
1,"Nicola Loi, C. Borile, Daniele Ucci","Towards an Automated Pipeline for Detecting and Classifying Malware through Machine Learning",2021,"","","","",189,"2022-07-13 09:39:14","","","","",,,,,1,1.00,0,3,1,"The constant growth in the number of malware software or code fragment potentially harmful for computers and information networks and the use of sophisticated evasion and obfuscation techniques have seriously hindered classic signature-based approaches. On the other hand, malware detection systems based on machine learning techniques started offering a promising alternative to standard approaches, drastically reducing analysis time and turning out to be more robust against evasion and obfuscation techniques. In this paper, we propose a malware taxonomic classification pipeline able to classify Windows Portable Executable files (PEs). Given an input PE sample, it is first classified as either malicious or benign. If malicious, the pipeline further analyzes it in order to establish its threat type, family, and behavior(s). We tested the proposed pipeline on the open source dataset EMBER, containing approximately 1 million PE samples, analyzed through static analysis. Obtained malware detection results are comparable to other academic works in the current state of art and, in addition, we provide an in-depth classification of malicious samples. Models used in the pipeline provides interpretable results which can help security analysts in better understanding decisions taken by the automated pipeline.","",""
0,"Tochukwu Idika, Ismail Akturk","Attack-Centric Approach for Evaluating Transferability of Adversarial Samples in Machine Learning Models",2021,"","","","",190,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,1,"Transferability of adversarial samples became a serious concern due to their impact on the reliability of machine learning system deployments, as they find their way into many critical applications. Knowing factors that influence transferability of adversarial samples can assist experts to make informed decisions on how to build robust and reliable machine learning systems. The goal of this study is to provide insights on the mechanisms behind the transferability of adversarial samples through an attack-centric approach. This attack-centric perspective interprets how adversarial samples would transfer by assessing the impact of machine learning attacks (that generated them) on a given input dataset. To achieve this goal, we generated adversarial samples using attacker models and transferred these samples to victim models. We analyzed the behavior of adversarial samples on victim models and outlined four factors that can influence the transferability of adversarial samples. Although these factors are not necessarily exhaustive, they provide useful insights to researchers and practitioners of machine learning systems.","",""
0,"V. Yasaswini, P. Reeshika, K. Roy, N. Kalpana, Rajesh Yamparala","Drowsiness Detection Using Machine Learning Algorithms",2021,"","","","",191,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,5,1,": The abstract presents a literature review of driver drowsiness detection based on behavioural measures using machine learning techniques. Faces contain information that can be used to interpret levels of drowsiness. There are many facial features that can be extracted from the face to infer the level of drowsiness. However, the development of a drowsiness detection system that yields reliable and accurate results is a challenging task as it requires accurate and robust algorithms. A wide range of techniques has been examined to detect driver drowsiness in the past. As a result, machine learning techniques which include convolution neural networks in the context of drowsiness detection. Here convolution neural networks performed better than any other techniques.","",""
0,"M. Ntampaka, Matthew Ho, B. Nord","Building Trustworthy Machine Learning Models for Astronomy",2021,"","","","",192,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,3,1,". Astronomy is entering an era of data-driven discovery, due in part to modern machine learning (ML) techniques enabling powerful new ways to interpret observations. This shift in our scientiﬁc approach requires us to consider whether we can trust the black box. Here, we overview methods for an often-overlooked step in the development of ML models: building community trust in the algorithms. Trust is an essential ingredient not just for creating more robust data analysis techniques, but also for building conﬁdence within the astronomy community to embrace machine learning methods and results.","",""
0,"A. Serban, Joost Visser","Adapting Software Architectures to Machine Learning Challenges",2021,"","","","",193,"2022-07-13 09:39:14","","","","",,,,,0,0.00,0,2,1,"Unique developmental and operational characteristics of machine learning (ML) components as well as their inherent uncertainty demand robust engineering principles are used to ensure their quality. We aim to determine how software systems can be (re-) architected to enable robust integration of ML components. Towards this goal, we conducted a mixed-methods empirical study consisting of (i) a systematic literature review to identify the challenges and their solutions in software architecture for ML, (ii) semi-structured interviews with practitioners to qualitatively complement the initial findings and (iii) a survey to quantitatively validate the challenges and their solutions. We compiled and validated twenty challenges and solutions for (re-) architecting systems with ML components. Our results indicate, for example, that traditional software architecture challenges (e.g., component coupling) also play an important role when using ML components; along with new ML specific challenges (e.g., the need for continuous retraining). Moreover, the results indicate that ML heightened decision drivers, such as privacy, play a marginal role compared to traditional decision drivers, such as scalability. Using the survey we were able to establish a link between architectural solutions and software quality attributes, which enabled us to provide twenty architectural tactics used to satisfy individual quality requirements of systems with ML components. Altogether, the results of the study can be interpreted as an empirical framework that supports the process of (re-) architecting software systems with ML components.","",""
25,"F. Noé","Machine Learning for Molecular Dynamics on Long Timescales",2018,"","","","",194,"2022-07-13 09:39:14","","10.1007/978-3-030-40245-7_16","","",,,,,25,6.25,25,1,4,"","",""
4,"M. Valetich, C. Le Losq, R. Arculus, S. Umino, J. Mavrogenes","Compositions and Classification of Fractionated Boninite Series Melts from the Izu–Bonin–Mariana Arc: A Machine Learning Approach",2021,"","","","",195,"2022-07-13 09:39:14","","10.1093/PETROLOGY/EGAB013","","",,,,,4,4.00,1,5,1,"  Much of the boninite magmatism in the Izu–Bonin–Mariana arc is preserved as evolved boninite series compositions wherein extensive fractional crystallization of pyroxene and spinel have obscured the diagnostic geochemical indicators of boninite parentage, such as high Mg and low Ti at intermediate silica contents. As a result, the usual geochemical discriminants used for the classification of the broad range of parental boninites are inapplicable to such highly fractionated melts. These issues are compounded by the mixing of demonstrably different whole-rock and glass analyses in classification schemes and petrological interpretations based thereon. Whole-rock compositions are compromised by entrainment of variable proportions of crystalline phases resulting in inconsistent differences from corresponding in situ glass analyses, which arguably better reflect prior melt compositions. To circumvent such issues, we herein present a robust method for the classification of highly fractionated boninite series glasses. This new classification leverages the analysis of trace elements, which are much more sensitive to evolutionary processes than major elements, and benefits from the use of unsupervised machine learning as a classification tool. The results show that the most fractionated boninite series melts preserve geochemical indicators of their parentage, and highlight the pitfalls of interpreting whole-rock and glass analyses interchangeably.","",""
1,"Ali Foroughi pour, Brian S. White, Jonghanne Park, T. Sheridan, Jeffrey H. Chuang","Deep learning features encode interpretable morphologies within histological images",2021,"","","","",196,"2022-07-13 09:39:14","","10.1101/2021.08.16.456518","","",,,,,1,1.00,0,5,1,"Convolutional neural networks (CNNs) are revolutionizing digital pathology by enabling machine learning-based classification of a variety of phenotypes from hematoxylin and eosin (H&E) whole slide images (WSIs), but the interpretation of CNNs remains difficult. Most studies have considered interpretability in a post hoc fashion, e.g. by presenting example regions with strongly predicted class labels. However, such an approach does not explain the biological features that contribute to correct predictions. To address this problem, here we investigate the interpretability of H&E-derived CNN features (the feature weights in the final layer of a transfer-learning-based architecture), which we show can be construed as abstract morphological genes (“mones”) with strong independent associations to biological phenotypes. We observe that many mones are specific to individual cancer types, while others are found in multiple cancers especially from related tissue types. We also observe that mone-mone correlations are strong and robustly preserved across related cancers. Importantly, linear mone-based classifiers can very accurately separate 38 distinct classes (19 tumor types and their adjacent normals, AUC=97.1% ± 2.8% for each class prediction), and linear classifiers are also highly effective for universal tumor detection (AUC=99.2% ± 0.12%). This linearity provides evidence that individual mones or correlated mone clusters may be associated with interpretable histopathological features or other patient characteristics. In particular, the statistical similarity of mones to gene expression values allows integrative mone analysis via expression-based bioinformatics approaches. We observe strong correlations between individual mones and individual gene expression values, notably mones associated with collagen gene expression in ovarian cancer. Mone-expression comparisons also indicate that immunoglobulin expression can be identified using mones in colon adenocarcinoma and that immune activity can be identified across multiple cancer types, and we verify these findings by expert histopathological review. Our work demonstrates that mones provide a morphological H&E decomposition that can be effectively associated with diverse phenotypes, analogous to the interpretability of transcription via gene expression values.","",""
1,"David Roschewitz, Mary-Anne Hartley, Luca Corinzia, Martin Jaggi","IFedAvg: Interpretable Data-Interoperability for Federated Learning",2021,"","","","",197,"2022-07-13 09:39:14","","","","",,,,,1,1.00,0,4,1,"Recently, the ever-growing demand for privacy-oriented machine learning has motivated researchers to develop federated and decentralized learning techniques, allowing individual clients to train models collaboratively without disclosing their private datasets. However, widespread adoption has been limited in domains relying on high levels of user trust, where assessment of data compatibility is essential. In this work, we define and address low interoperability induced by underlying client data inconsistencies in federated learning for tabular data. The proposed method, iFedAvg, builds on federated averaging adding local element-wise affine layers to allow for a personalized and granular understanding of the collaborative learning process. Thus, enabling the detection of outlier datasets in the federation and also learning the compensation for local data distribution shifts without sharing any original data. We evaluate iFedAvg using several public benchmarks and a previously unstudied collection of real-world datasets from the 2014 2016 West African Ebola epidemic, jointly forming the largest such dataset in the world. In all evaluations, iFedAvg achieves competitive average performance with negligible overhead. It additionally shows substantial improvement on outlier clients, highlighting increased robustness to individual dataset shifts. Most importantly, our method provides valuable client-specific insights at a fine-grained level to guide interoperable federated learning.","",""
1,"T. Welchowski, K. Maloney, R. Mitchell, M. Schmid","Techniques to Improve Ecological Interpretability of Black-Box Machine Learning Models",2021,"","","","",198,"2022-07-13 09:39:14","","10.1007/s13253-021-00479-7","","",,,,,1,1.00,0,4,1,"","",""
2,"I. M. Lei, Chen Jiang, Chon Lok Lei, S. D. de Rijk, Y. C. Tam, C. Swords, M. Sutcliffe, G. Malliaras, M. Bance, Yan Yan Shery Huang","3D printed biomimetic cochleae and machine learning co-modelling provides clinical informatics for cochlear implant patients",2021,"","","","",199,"2022-07-13 09:39:14","","10.1038/s41467-021-26491-6","","",,,,,2,2.00,0,10,1,"","",""
1,"T. Thung, Murray E. White, Wei Dai, J. Wilksch, R. Bamert, A. Rocker, C. Stubenrauch, Daniel Williams, Cheng Huang, Ralf Schittelhelm, J. Barr, E. Jameson, S. McGowan, Yanju Zhang, Jiawei Wang, R. Dunstan, T. Lithgow","The component parts of bacteriophage virions accurately defined by a machine-learning approach built on evolutionary features",2021,"","","","",200,"2022-07-13 09:39:14","","10.1101/2021.02.28.433281","","",,,,,1,1.00,0,17,1,"Antimicrobial resistance (AMR) continues to evolve as a major threat to human health and new strategies are required for the treatment of AMR infections. Bacteriophages (phages) that kill bacterial pathogens are being identified for use in phage therapies, with the intention to apply these bactericidal viruses directly into the infection sites in bespoke phage cocktails. Despite the great unsampled phage diversity for this purpose, an issue hampering the roll out of phage therapy is the poor quality annotation of many of the phage genomes, particularly for those from infrequently sampled environmental sources. We developed a computational tool called STEP3 to use the “evolutionary features” that can be recognized in genome sequences of diverse phages. These features, when integrated into an ensemble framework, achieved a stable and robust prediction performance when benchmarked against other prediction tools using phages from diverse sources. Validation of the prediction accuracy of STEP3 was conducted with high-resolution mass spectrometry analysis of two novel phages, isolated from a watercourse in the Southern Hemisphere. STEP3 provides a robust computational approach to distinguish specific and universal features in phages to improve the quality of phage cocktails, and is available for use at http://step3.erc.monash.edu/. IMPORTANCE In response to the global problem of antimicrobial resistance there are moves to use bacteriophages (phages) as therapeutic agents. Selecting which phages will be effective therapeutics relies on interpreting features contributing to shelf-life and applicability to diagnosed infections. However, the protein components of the phage virions that dictate these properties vary so much in sequence that best estimates suggest failure to recognize up to 90% of them. We have utilised this diversity in evolutionary features as an advantage, to apply machine learning for prediction accuracy for diverse components in phage virions. We benchmark this new tool showing the accurate recognition and evaluation of phage components parts using genome sequence data of phages from under-sampled environments, where the richest diversity of phage still lies.","",""
