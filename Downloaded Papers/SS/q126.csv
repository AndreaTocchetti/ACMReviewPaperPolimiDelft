Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
7,"Md. Kowsher, A. Tahabilder, S. Murad","Impact-Learning: A Robust Machine Learning Algorithm",2020,"","","","",1,"2022-07-13 10:06:33","","10.1145/3411174.3411185","","",,,,,7,3.50,2,3,2,"The ultimate goal of this research paper is to introduce a robust machine learning algorithm called Impact-Learning, which is being used widely to achieve more advanced results on many machine-learning related challenges. Impact learning is a supervised machine learning algorithm for resolving classification and linear or polynomial regression knowledge from examples. It also contributes to analyzing systems for competitive data. This algorithm is unique for being capable of learning from a competition, which is the impact of independent features. In other words, it is trained by the impacts of the features from the intrinsic rate of natural increase (RNI). The input to the Impact Learning is a training set of numerical data. In this work, we used six datasets related to regressions and classifications as the experiment of the Impact Learning, and the comparison indicates that at outperforms other standard machine learning regressions and classifications algorithms such as Random forest tree, SVM, Naive Bayes, Logistic regression and so forth.","",""
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",2,"2022-07-13 10:06:33","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
29,"Nishat Koti, Mahak Pancholi, A. Patra, A. Suresh","SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning",2020,"","","","",3,"2022-07-13 10:06:33","","","","",,,,,29,14.50,7,4,2,"Performing ML computation on private data while maintaining data privacy aka Privacy-preserving Machine Learning (PPML) is an emergent field of research. Recently, PPML has seen a visible shift towards the adoption of Secure Outsourced Computation (SOC) paradigm, due to the heavy computation that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the users irrespective of any adversarial behaviour. Robustness, a highly desirable feature, evokes user participation without the fear of denial of service.  At the heart of our framework lies a highly-efficient, maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output delivery (GOD) in the honest-majority setting. To the best of our knowledge, SWIFT is the first robust and efficient PPML framework in the 3PC setting. SWIFT is as fast as the best-known 3PC framework BLAZE (Patra et al. NDSS'20) which only achieves fairness. Fairness ensures either all or none receive the output, whereas GOD ensures guaranteed output delivery no matter what. We extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS'20) and twice faster than the best-known robust 4PC framework FLASH (Byali et al. PETS'20).  We demonstrate the practical relevance of our framework by benchmarking two important applications-- i) ML algorithms: Logistic Regression and Neural Network, and ii) Biometric matching, both over a 64-bit ring in WAN setting. Our readings reflect our claims as above.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",4,"2022-07-13 10:06:33","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
17,"Zhenfeng Lei, Yuandong Sun, Y. Nanehkaran, Shuangyuan Yang, Md. Saiful Islam, Huiqing Lei, De-fu Zhang","A novel data-driven robust framework based on machine learning and knowledge graph for disease classification",2020,"","","","",5,"2022-07-13 10:06:33","","10.1016/j.future.2019.08.030","","",,,,,17,8.50,2,7,2,"","",""
3,"Suk Joon Hong, B. Bennett","Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning and Machine Learning",2020,"","","","",6,"2022-07-13 10:06:33","","10.4230/OASIcs.LDK.2021.41","","",,,,,3,1.50,2,2,2,"The Winograd Schema Challenge (WSC) is a common-sense reasoning task that requires background knowledge. In this paper, we contribute to tackling WSC in four ways. Firstly, we suggest a keyword method to define a restricted domain where distinctive high-level semantic patterns can be found. A thanking domain was defined by key-words, and the data set in this domain is used in our experiments. Secondly, we develop a high-level knowledge-based reasoning method using semantic roles which is based on the method of Sharma [2019]. Thirdly, we propose an ensemble method to combine knowledge-based reasoning and machine learning which shows the best performance in our experiments. As a machine learning method, we used Bidirectional Encoder Representations from Transformers (BERT) [Kocijan et al., 2019]. Lastly, in terms of evaluation, we suggest a ""robust"" accuracy measurement by modifying that of Trichelair et al. [2018]. As with their switching method, we evaluate a model by considering its performance on trivial variants of each sentence in the test set.","",""
665,"Weihua Hu, Matthias Fey, M. Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, J. Leskovec","Open Graph Benchmark: Datasets for Machine Learning on Graphs",2020,"","","","",7,"2022-07-13 10:06:33","","","","",,,,,665,332.50,83,8,2,"We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .","",""
19,"A. Aravkin, Damek Davis","A SMART Stochastic Algorithm for Nonconvex Optimization with Applications to Robust Machine Learning",2016,"","","","",8,"2022-07-13 10:06:33","","","","",,,,,19,3.17,10,2,6,"In this paper, we show how to transform any optimization problem that arises from fitting a machine learning model into one that (1) detects and removes contaminated data from the training set while (2) simultaneously fitting the trimmed model on the uncontaminated data that remains. To solve the resulting nonconvex optimization problem, we introduce a fast stochastic proximal-gradient algorithm that incorporates prior knowledge through nonsmooth regularization. For datasets of size $n$, our approach requires $O(n^{2/3}/\varepsilon)$ gradient evaluations to reach $\varepsilon$-accuracy and, when a certain error bound holds, the complexity improves to $O(\kappa n^{2/3}\log(1/\varepsilon))$. These rates are $n^{1/3}$ times better than those achieved by typical, full gradient methods.","",""
75,"K. Kashinath, M. Mustafa, A. Albert, J.-L. Wu, C. Jiang, S. Esmaeilzadeh, K. Azizzadenesheli, R. Wang, A. Chattopadhyay, A. Singh, A. Manepalli, D. Chirila, R. Yu, R. Walters, B. White, H. Xiao, H. Tchelepi, P. Marcus, A. Anandkumar, P. Hassanzadeh, Prabhat","Physics-informed machine learning: case studies for weather and climate modelling",2021,"","","","",9,"2022-07-13 10:06:33","","10.1098/rsta.2020.0093","","",,,,,75,75.00,8,21,1,"Machine learning (ML) provides novel and powerful ways of accurately and efficiently recognizing complex patterns, emulating nonlinear dynamics, and predicting the spatio-temporal evolution of weather and climate processes. Off-the-shelf ML models, however, do not necessarily obey the fundamental governing laws of physical systems, nor do they generalize well to scenarios on which they have not been trained. We survey systematic approaches to incorporating physics and domain knowledge into ML models and distill these approaches into broad categories. Through 10 case studies, we show how these approaches have been used successfully for emulating, downscaling, and forecasting weather and climate processes. The accomplishments of these studies include greater physical consistency, reduced training time, improved data efficiency, and better generalization. Finally, we synthesize the lessons learned and identify scientific, diagnostic, computational, and resource challenges for developing truly robust and reliable physics-informed ML models for weather and climate processes. This article is part of the theme issue ‘Machine learning for weather and climate modelling’.","",""
23,"Sina Shaham, Ming Ding, Bo Liu, Shuping Dang, Zihuai Lin, Jun Li","Privacy Preserving Location Data Publishing: A Machine Learning Approach",2019,"","","","",10,"2022-07-13 10:06:33","","10.1109/tkde.2020.2964658","","",,,,,23,7.67,4,6,3,"Publishing datasets plays an essential role in open data research and promoting transparency of government agencies. However, such data publication might reveal users’ private information. One of the most sensitive sources of data is spatiotemporal trajectory datasets. Unfortunately, merely removing unique identifiers cannot preserve the privacy of users. Adversaries may know parts of the trajectories or be able to link the published dataset to other sources for the purpose of user identification. Therefore, it is crucial to apply privacy preserving techniques before the publication of spatiotemporal trajectory datasets. In this paper, we propose a robust framework for the anonymization of spatiotemporal trajectory datasets termed as machine learning based anonymization (MLA). By introducing a new formulation of the problem, we are able to apply machine learning algorithms for clustering the trajectories and propose to use <inline-formula><tex-math notation=""LaTeX"">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=""shaham-ieq1-2964658.gif""/></alternatives></inline-formula>-means algorithm for this purpose. A variation of <inline-formula><tex-math notation=""LaTeX"">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=""shaham-ieq2-2964658.gif""/></alternatives></inline-formula>-means algorithm is also proposed to preserve the privacy in overly sensitive datasets. Moreover, we improve the alignment process by considering multiple sequence alignment as part of the MLA. The framework and all the proposed algorithms are applied to T-Drive, Geolife, and Gowalla location datasets. The experimental results indicate a significantly higher utility of datasets by anonymization based on MLA framework.","",""
12,"Atik Mahabub","A robust voting approach for diabetes prediction using traditional machine learning techniques",2019,"","","","",11,"2022-07-13 10:06:33","","10.1007/s42452-019-1759-7","","",,,,,12,4.00,12,1,3,"","",""
18,"S. Fleming, A. Goodbody","A Machine Learning Metasystem for Robust Probabilistic Nonlinear Regression-Based Forecasting of Seasonal Water Availability in the US West",2019,"","","","",12,"2022-07-13 10:06:33","","10.1109/ACCESS.2019.2936989","","",,,,,18,6.00,9,2,3,"Hydroelectric power generation, water supplies for municipal, agricultural, manufacturing, and service industry uses including technology-sector requirements, dam safety, flood control, recreational uses, and ecological and legal constraints, all place simultaneous, competing demands on the heavily stressed water management infrastructure of the mostly arid American West. Optimally managing these resources depends on predicting water availability. We built a probabilistic nonlinear regression water supply forecast (WSF) technique for the US Department of Agriculture, which runs the largest stand-alone WSF system in the US West. Design criteria included improved accuracy over the existing system; uncertainty estimates that seamlessly handle complex (heteroscedastic, non-Gaussian) prediction errors; integration of physical hydrometeorological process knowledge and domain-specific expert experience; ability to accommodate nonlinearity, model selection uncertainty and equifinality, and predictor multicollinearity and high dimensionality; and relatively easy, low-cost implementation. Some methods satisfied some of these requirements but none met all, leading us to develop a novel, interdisciplinary, and pragmatic prediction metasystem through a carefully considered synthesis of well-established, off-the-shelf components and approaches, spanning supervised and unsupervised machine learning, nonparametric statistical modeling, ensemble learning, and evolutionary optimization, focusing on maintaining but radically updating the principal components regression framework widely used for WSF. Testing this integrated multi-method prediction engine demonstrated its value for river forecasting; USDA adoption is a landmark for transitioning machine learning from research into practice in this field. Its ability to handle all the foregoing design criteria and requirements, which are not unique to WSF, suggests potential for extension to complex probabilistic prediction problems in other fields.","",""
10,"Yifan Cui, E. Tchetgen","Selective machine learning of doubly robust functionals.",2019,"","","","",13,"2022-07-13 10:06:33","","","","",,,,,10,3.33,5,2,3,"While model selection is a well-studied topic in parametric and nonparametric regression or density estimation, model selection of possibly high-dimensional nuisance parameters in semiparametric problems is far less developed. In this paper, we propose a selective machine learning framework for making inferences about a finite-dimensional functional defined on a semiparametric model, when the latter admits a doubly robust estimating function. We introduce two model selection criteria for bias reduction of functional of interest, each based on a novel definition of pseudo-risk for the functional that embodies this double robustness property and thus may be used to select the candidate model that is nearest to fulfilling this property even when all models are wrong. We establish an oracle property for a multi-fold cross-validation version of the new model selection criteria which states that our empirical criteria perform nearly as well as an oracle with a priori knowledge of the pseudo-risk for each candidate model. We also describe a smooth approximation to the selection criteria which allows for valid post-selection inference. Finally, we apply the approach to model selection of a semiparametric estimator of average treatment effect given an ensemble of candidate machine learners to account for confounding in an observational study.","",""
15,"Jungryul Seo, T. Laine, Kyung-ah Sohn","An Exploration of Machine Learning Methods for Robust Boredom Classification Using EEG and GSR Data",2019,"","","","",14,"2022-07-13 10:06:33","","10.3390/s19204561","","",,,,,15,5.00,5,3,3,"In recent years, affective computing has been actively researched to provide a higher level of emotion-awareness. Numerous studies have been conducted to detect the user’s emotions from physiological data. Among a myriad of target emotions, boredom, in particular, has been suggested to cause not only medical issues but also challenges in various facets of daily life. However, to the best of our knowledge, no previous studies have used electroencephalography (EEG) and galvanic skin response (GSR) together for boredom classification, although these data have potential features for emotion classification. To investigate the combined effect of these features on boredom classification, we collected EEG and GSR data from 28 participants using off-the-shelf sensors. During data acquisition, we used a set of stimuli comprising a video clip designed to elicit boredom and two other video clips of entertaining content. The collected samples were labeled based on the participants’ questionnaire-based testimonies on experienced boredom levels. Using the collected data, we initially trained 30 models with 19 machine learning algorithms and selected the top three candidate classifiers. After tuning the hyperparameters, we validated the final models through 1000 iterations of 10-fold cross validation to increase the robustness of the test results. Our results indicated that a Multilayer Perceptron model performed the best with a mean accuracy of 79.98% (AUC: 0.781). It also revealed the correlation between boredom and the combined features of EEG and GSR. These results can be useful for building accurate affective computing systems and understanding the physiological properties of boredom.","",""
21,"A. Naimi, Alan Mishler, Edward H. Kennedy","Challenges in Obtaining Valid Causal Effect Estimates with Machine Learning Algorithms.",2017,"","","","",15,"2022-07-13 10:06:33","","10.1093/aje/kwab201","","",,,,,21,4.20,7,3,5,"Unlike parametric regression, machine learning (ML) methods do not generally require precise knowledge of the true data generating mechanisms. As such, numerous authors have advocated for ML methods to estimate causal effects. Unfortunately, ML algorithmscan perform worse than parametric regression. We demonstrate the performance of ML-based single- and double-robust estimators. We use 100 Monte Carlo samples with sample sizes of 200, 1200, and 5000 to investigate bias and confidence interval coverage under several scenarios. In a simple confounding scenario, confounders were related to the treatment and the outcome via parametric models. In a complex confounding scenario, the simple confounders were transformed to induce complicated nonlinear relationships. In the simple scenario, when ML algorithms were used, double-robust estimators were superior to single-robust estimators. In the complex scenario, single-robust estimators with ML algorithms were at least as biased as estimators using misspecified parametric models. Double-robust estimators were less biased, but coverage was well below nominal. The use of sample splitting, inclusion of confounder interactions, reliance on a richly specified ML algorithm, and use of doubly robust estimators was the only explored approach that yielded negligible bias and nominal coverage. Our results suggest that ML based singly robust methods should be avoided.","",""
22,"F. Emmert‐Streib, M. Dehmer","A Machine Learning Perspective on Personalized Medicine: An Automized, Comprehensive Knowledge Base with Ontology for Pattern Recognition",2018,"","","","",16,"2022-07-13 10:06:33","","10.3390/MAKE1010009","","",,,,,22,5.50,11,2,4,"Personalized or precision medicine is a new paradigm that holds great promise for individualized patient diagnosis, treatment, and care. However, personalized medicine has only been described on an informal level rather than through rigorous practical guidelines and statistical protocols that would allow its robust practical realization for implementation in day-to-day clinical practice. In this paper, we discuss three key factors, which we consider dimensions that effect the experimental design for personalized medicine: (I) phenotype categories; (II) population size; and (III) statistical analysis. This formalization allows us to define personalized medicine from a machine learning perspective, as an automized, comprehensive knowledge base with an ontology that performs pattern recognition of patient profiles.","",""
16,"Yonghan Jung, Jin Tian, E. Bareinboim","Estimating Identifiable Causal Effects through Double Machine Learning",2021,"","","","",17,"2022-07-13 10:06:33","","","","",,,,,16,16.00,5,3,1,"Identifying causal effects from observational data is a perva- sive challenge found throughout the empirical sciences. Very general methods have been developed to decide the identiﬁ- ability of a causal quantity from a combination of observational data and causal knowledge about the underlying sys- tem. In practice, however, there are still challenges to estimating identiﬁable causal functionals from ﬁnite samples. Re- cently, a method known as double/debiased machine learning (DML) (Chernozhukov et al. 2018) has been proposed to learn parameters leveraging modern machine learning techniques, which is both robust to model misspeciﬁcation and bias-reducing. Still, DML has only been used for causal estimation in settings when the back-door condition (also known as conditional ignorability) holds. In this paper, we develop a new, general class of estimators for any identiﬁable causal functionals that exhibit DML properties, which we name DML-ID. In particular, we introduce a complete identiﬁca- tion algorithm that returns an inﬂuence function (IF) for any identiﬁable causal functional. We then construct the DML es- timator based on the derived IF. We show that DML-ID estimators hold the key properties of debiasedness and doubly robustness. Simulation results corroborate with the theory.","",""
127,"Lei Zhang, D. Zhang","Robust Visual Knowledge Transfer via Extreme Learning Machine-Based Domain Adaptation",2016,"","","","",18,"2022-07-13 10:06:33","","10.1109/TIP.2016.2598679","","",,,,,127,21.17,64,2,6,"We address the problem of visual knowledge adaptation by leveraging labeled patterns from source domain and a very limited number of labeled instances in target domain to learn a robust classifier for visual categorization. This paper proposes a new extreme learning machine (ELM)-based cross-domain network learning framework, that is called ELM-based Domain Adaptation (EDA). It allows us to learn a category transformation and an ELM classifier with random projection by minimizing the ℓ2,1-norm of the network output weights and the learning error simultaneously. The unlabeled target data, as useful knowledge, is also integrated as a fidelity term to guarantee the stability during cross-domain learning. It minimizes the matching error between the learned classifier and a base classifier, such that many existing classifiers can be readily incorporated as the base classifiers. The network output weights cannot only be analytically determined, but also transferrable. In addition, a manifold regularization with Laplacian graph is incorporated, such that it is beneficial to semisupervised learning. Extensively, we also propose a model of multiple views, referred as MvEDA. Experiments on benchmark visual datasets for video event recognition and object recognition demonstrate that our EDA methods outperform the existing cross-domain learning methods.","",""
6,"C. Yeomans, R. Shail, S. Grebby, V. Nykänen, M. Middleton, P. Lusty","A machine learning approach to tungsten prospectivity modelling using knowledge-driven feature extraction and model confidence",2019,"","","","",19,"2022-07-13 10:06:33","","10.31223/osf.io/9fet8","","",,,,,6,2.00,1,6,3,"Abstract Novel mineral prospectivity modelling presented here applies knowledge-driven feature extraction to a data-driven machine learning approach for tungsten mineralisation. The method emphasises the importance of appropriate model evaluation and develops a new Confidence Metric to generate spatially refined and robust exploration targets. The data-driven Random Forest™ algorithm is employed to model tungsten mineralisation in SW England using a range of geological, geochemical and geophysical evidence layers which include a depth to granite evidence layer. Two models are presented, one using standardised input variables and a second that implements fuzzy set theory as part of an augmented feature extraction step. The use of fuzzy data transformations mean feature extraction can incorporate some user-knowledge about the mineralisation into the model. The typically subjective approach is guided using the Receiver Operating Characteristics (ROC) curve tool where transformed data are compared to known training samples. The modelling is conducted using 34 known true positive samples with 10 sets of randomly generated true negative samples to test the random effect on the model. The two models have similar accuracy but show different spatial distributions when identifying highly prospective targets. Areal analysis shows that the fuzzy-transformed model is a better discriminator and highlights three areas of high prospectivity that were not previously known. The Confidence Metric, derived from model variance, is employed to further evaluate the models. The new metric is useful for refining exploration targets and highlighting the most robust areas for follow-up investigation. The fuzzy-transformed model is shown to contain larger areas of high model confidence compared to the model using standardised variables. Finally, legacy mining data, from drilling reports and mine descriptions, is used to further validate the fuzzy-transformed model and gauge the depth of potential deposits. Descriptions of mineralisation corroborate that the targets generated in these models could be undercover at depths of less than 300 ​m. In summary, the modelling workflow presented herein provides a novel integration of knowledge-driven feature extraction with data-driven machine learning modelling, while the newly derived Confidence Metric generates reliable mineral exploration targets.","",""
29,"Violeta Mirchevska, M. Luštrek, M. Gams","Combining domain knowledge and machine learning for robust fall detection",2014,"","","","",20,"2022-07-13 10:06:33","","10.1111/exsy.12019","","",,,,,29,3.63,10,3,8,"This paper presents a method for combining domain knowledge and machine learning (CDKML) for classifier generation and online adaptation. The method exploits advantages in domain knowledge and machine learning as complementary information sources. Whereas machine learning may discover patterns in interest domains that are too subtle for humans to detect, domain knowledge may contain information on a domain not present in the available domain dataset. CDKML has three steps. First, prior domain knowledge is enriched with relevant patterns obtained by machine learning to create an initial classifier. Second, genetic algorithms refine the classifier. Third, the classifier is adapted online on the basis of user feedback using the Markov decision process. CDKML was applied in fall detection. Tests showed that the classifiers developed by CDKML have better performance than machine‐learning classifiers generated on a training dataset that does not adequately represent all real‐life cases of the learned concept. The accuracy of the initial classifier was 10 percentage points higher than the best machine‐learning classifier and the refinement added 3 percentage points. The online adaptation improved the accuracy of the refined classifier by an additional 15 percentage points.","",""
242,"Yudong Chen, Lili Su, Jiaming Xu","Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent",2017,"","","","",21,"2022-07-13 10:06:33","","10.1145/3308809.3308857","","",,,,,242,48.40,81,3,5,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server andm working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of them working machines suffer Byzantine faults - a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks.","",""
25,"H. Yoon, Jae-Hoon Sim, M. Han","Analytic continuation via domain knowledge free machine learning",2018,"","","","",22,"2022-07-13 10:06:33","","10.1103/PhysRevB.98.245101","","",,,,,25,6.25,8,3,4,"We present a machine-learning approach to a long-standing issue in quantum many-body physics, namely, analytic continuation. This notorious ill-conditioned problem of obtaining spectral function from an imaginary time Green's function has been a focus of new method developments for past decades. Here we demonstrate the usefulness of modern machine-learning techniques including convolutional neural networks and the variants of a stochastic gradient descent optimizer. The machine-learning continuation kernel is successfully realized without any ``domain knowledge,'' which means that any physical ``prior'' is not utilized in the kernel construction and the neural networks ``learn'' the knowledge solely from ``training.'' The outstanding performance is achieved for both insulating and metallic band structure. Our machine-learning-based approach not only provides the more accurate spectrum than the conventional methods in terms of peak positions and heights, but is also more robust against the noise which is the required key feature for any continuation technique to be successful. Furthermore, its computation speed is ${10}^{4}\text{--}{10}^{5}$ times faster than the maximum entropy method.","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",23,"2022-07-13 10:06:33","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
75,"M. Prosperi, Yi Guo, M. Sperrin, J. Koopman, Jae Min, Xing He, S. Rich, Mo Wang, I. Buchan, J. Bian","Causal inference and counterfactual prediction in machine learning for actionable healthcare",2020,"","","","",24,"2022-07-13 10:06:33","","10.1038/s42256-020-0197-y","","",,,,,75,37.50,8,10,2,"","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",25,"2022-07-13 10:06:33","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",26,"2022-07-13 10:06:33","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
5,"Furkan M. Torun, S. V. Winter, Sophia Doll, Felix M. Riese, A. Vorobyev, Johannes B. Mueller‐Reif, Philipp E. Geyer, Maximilian T. Strauss","Transparent exploration of machine learning for biomarker discovery from proteomics and omics data",2021,"","","","",27,"2022-07-13 10:06:33","","10.1101/2021.03.05.434053","","",,,,,5,5.00,1,8,1,"Biomarkers are of central importance for assessing the health state and to guide medical interventions and their efficacy, but they are lacking for most diseases. Mass spectrometry (MS)-based proteomics is a powerful technology for biomarker discovery, but requires sophisticated bioinformatics to identify robust patterns. Machine learning (ML) has become indispensable for this purpose, however, it is sometimes applied in an opaque manner, generally requires expert knowledge and complex and expensive software. To enable easy access to ML for biomarker discovery without any programming or bioinformatic skills, we developed ‘OmicLearn’ (https://OmicLearn.com), an open-source web-based ML tool using the latest advances in the Python ML ecosystem. We host a web server for the exploration of the researcher’s results that can readily be cloned for internal use. Output tables from proteomics experiments are easily uploaded to the central or a local webserver. OmicLearn enables rapid exploration of the suitability of various ML algorithms for the experimental datasets. It fosters open science via transparent assessment of state-of-the-art algorithms in a standardized format for proteomics and other omics sciences. Graphical Abstract Highlights OmicLearn is an open-source platform allows researchers to apply machine learning (ML) for biomarker discovery The ready-to-use structure of OmicLearn enables accessing state-of-the-art ML algorithms without requiring any prior bioinformatics knowledge OmicLearn’s web-based interface provides an easy-to-follow platform for classification and gaining insights into the dataset Several algorithms and methods for preprocessing, feature selection, classification and cross-validation of omics datasets are integrated All results, settings and method text can be exported in publication-ready formats","",""
168,"Tao Lin, Lingjing Kong, Sebastian U. Stich, Martin Jaggi","Ensemble Distillation for Robust Model Fusion in Federated Learning",2020,"","","","",28,"2022-07-13 10:06:33","","","","",,,,,168,84.00,42,4,2,"Federated Learning (FL) is a machine learning setting where many devices collaboratively train a machine learning model while keeping the training data decentralized. In most of the current training schemes the central model is refined by averaging the parameters of the server model and the updated parameters from the client side. However, directly averaging model parameters is only possible if all models have the same structure and size, which could be a restrictive constraint in many scenarios.  In this work we investigate more powerful and more flexible aggregation schemes for FL. Specifically, we propose ensemble distillation for model fusion, i.e. training the central classifier through unlabeled data on the outputs of the models from the clients. This knowledge distillation technique mitigates privacy risk and cost to the same extent as the baseline FL algorithms, but allows flexible aggregation over heterogeneous client models that can differ e.g. in size, numerical precision or structure. We show in extensive empirical experiments on various CV/NLP datasets (CIFAR-10/100, ImageNet, AG News, SST2) and settings (heterogeneous models/data) that the server model can be trained much faster, requiring fewer communication rounds than any existing FL technique so far.","",""
658,"Wieland Brendel, Jonas Rauber, M. Bethge","Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",2017,"","","","",29,"2022-07-13 10:06:33","","","","",,,,,658,131.60,219,3,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .","",""
19,"Yannick Suter, U. Knecht, Mariana Alão, W. Valenzuela, E. Hewer, P. Schucht, R. Wiest, M. Reyes","Radiomics for glioblastoma survival analysis in pre-operative MRI: exploring feature robustness, class boundaries, and machine learning techniques",2020,"","","","",30,"2022-07-13 10:06:33","","10.1186/s40644-020-00329-8","","",,,,,19,9.50,2,8,2,"","",""
30,"J. Bullock, A. Momeni","Ml.lib: robust, cross-platform, open-source machine learning for max and pure data",2015,"","","","",31,"2022-07-13 10:06:33","","","","",,,,,30,4.29,15,2,7,"This paper documents the development of ml.lib: a set of open-source tools designed for employing a wide range of machine learning techniques within two popular real-time programming environments, namely Max and Pure Data. ml.lib is a cross-platform, lightweight wrapper around Nick Gillian's Gesture Recognition Toolkit, a C++ library that includes a wide range of data processing and machine learning techniques. ml.lib adapts these techniques for real-time use within popular data-flow IDEs, allowing instrument designers and performers to integrate robust learning, classification and mapping approaches within their existing workflows. ml.lib has been carefully de-signed to allow users to experiment with and incorporate ma-chine learning techniques within an interactive arts context with minimal prior knowledge. A simple, logical and consistent, scalable interface has been provided across over sixteen exter-nals in order to maximize learnability and discoverability. A focus on portability and maintainability has enabled ml.lib to support a range of computing architectures - including ARM - and operating systems such as Mac OS, GNU/Linux and Win-dows, making it the most comprehensive machine learning implementation available for Max and Pure Data.","",""
12,"H. Sufriyana, Yu-Wei Wu, E. C. Su","Prediction of Preeclampsia and Intrauterine Growth Restriction: Development of Machine Learning Models on a Prospective Cohort",2020,"","","","",32,"2022-07-13 10:06:33","","10.2196/15411","","",,,,,12,6.00,4,3,2,"Background Preeclampsia and intrauterine growth restriction are placental dysfunction–related disorders (PDDs) that require a referral decision be made within a certain time period. An appropriate prediction model should be developed for these diseases. However, previous models did not demonstrate robust performances and/or they were developed from datasets with highly imbalanced classes. Objective In this study, we developed a predictive model of PDDs by machine learning that uses features at 24-37 weeks’ gestation, including maternal characteristics, uterine artery (UtA) Doppler measures, soluble fms-like tyrosine kinase receptor-1 (sFlt-1), and placental growth factor (PlGF). Methods A public dataset was taken from a prospective cohort study that included pregnant women with PDDs (66/95, 69%) and a control group (29/95, 31%). Preliminary selection of features was based on a statistical analysis using SAS 9.4 (SAS Institute). We used Weka (Waikato Environment for Knowledge Analysis) 3.8.3 (The University of Waikato, Hamilton, NZ) to automatically select the best model using its optimization algorithm. We also manually selected the best of 23 white-box models. Models, including those from recent studies, were also compared by interval estimation of evaluation metrics. We used the Matthew correlation coefficient (MCC) as the main metric. It is not overoptimistic to evaluate the performance of a prediction model developed from a dataset with a class imbalance. Repeated 10-fold cross-validation was applied. Results The classification via regression model was chosen as the best model. Our model had a robust MCC (.93, 95% CI .87-1.00, vs .64, 95% CI .57-.71) and specificity (100%, 95% CI 100-100, vs 90%, 95% CI 90-90) compared to each metric of the best models from recent studies. The sensitivity of this model was not inferior (95%, 95% CI 91-100, vs 100%, 95% CI 92-100). The area under the receiver operating characteristic curve was also competitive (0.970, 95% CI 0.966-0.974, vs 0.987, 95% CI 0.980-0.994). Features in the best model were maternal weight, BMI, pulsatility index of the UtA, sFlt-1, and PlGF. The most important feature was the sFlt-1/PlGF ratio. This model used an M5P algorithm consisting of a decision tree and four linear models with different thresholds. Our study was also better than the best ones among recent studies in terms of the class balance and the size of the case class (66/95, 69%, vs 27/239, 11.3%). Conclusions Our model had a robust predictive performance. It was also developed to deal with the problem of a class imbalance. In the context of clinical management, this model may improve maternal mortality and neonatal morbidity and reduce health care costs.","",""
7,"D. Jacob","Cross-Fitting and Averaging for Machine Learning Estimation of Heterogeneous Treatment Effects",2020,"","","","",33,"2022-07-13 10:06:33","","","","",,,,,7,3.50,7,1,2,"We investigate the finite sample performance of sample splitting, cross-fitting and averaging for the estimation of the conditional average treatment effect. Recently proposed methods, so-called meta-learners, make use of machine learning to estimate different nuisance functions and hence allow for fewer restrictions on the underlying structure of the data. To limit a potential overfitting bias that may result when using machine learning methods, cross-fitting estimators have been proposed. This includes the splitting of the data in different folds to reduce bias and averaging over folds to restore efficiency. To the best of our knowledge, it is not yet clear how exactly the data should be split and averaged. We employ a Monte Carlo study with different data generation processes and consider twelve different estimators that vary in sample-splitting, cross-fitting and averaging procedures. We investigate the performance of each estimator independently on four different meta-learners: the doubly-robust-learner, R-learner, T-learner and X-learner. We find that the performance of all meta-learners heavily depends on the procedure of splitting and averaging. The best performance in terms of mean squared error (MSE) among the sample split estimators can be achieved when applying cross-fitting plus taking the median over multiple different sample-splitting iterations. Some meta-learners exhibit a high variance when the lasso is included in the ML methods. Excluding the lasso decreases the variance and leads to robust and at least competitive results.","",""
7,"Jina Suh, S. Ghorashi, Gonzalo A. Ramos, N. Chen, S. Drucker, J. Verwey, P. Simard","AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning",2019,"","","","",34,"2022-07-13 10:06:33","","10.1145/3241379","","",,,,,7,2.33,1,7,3,"When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.","",""
6,"Wienand A. Omta, Roy G. van Heesbeen, I. Shen, Jacob de Nobel, D. Robers, Lieke M. van der Velden, R. Medema, A. Siebes, A. Feelders, S. Brinkkemper, J. Klumperman, M. Spruit, Matthieu J. S. Brinkhuis, D. Egan","Combining Supervised and Unsupervised Machine Learning Methods for Phenotypic Functional Genomics Screening",2020,"","","","",35,"2022-07-13 10:06:33","","10.1177/2472555220919345","","",,,,,6,3.00,1,14,2,"There has been an increase in the use of machine learning and artificial intelligence (AI) for the analysis of image-based cellular screens. The accuracy of these analyses, however, is greatly dependent on the quality of the training sets used for building the machine learning models. We propose that unsupervised exploratory methods should first be applied to the data set to gain a better insight into the quality of the data. This improves the selection and labeling of data for creating training sets before the application of machine learning. We demonstrate this using a high-content genome-wide small interfering RNA screen. We perform an unsupervised exploratory data analysis to facilitate the identification of four robust phenotypes, which we subsequently use as a training set for building a high-quality random forest machine learning model to differentiate four phenotypes with an accuracy of 91.1% and a kappa of 0.85. Our approach enhanced our ability to extract new knowledge from the screen when compared with the use of unsupervised methods alone.","",""
5,"Dan Jiang, Weihua Lin, N. Raghavan","A Novel Framework for Semiconductor Manufacturing Final Test Yield Classification Using Machine Learning Techniques",2020,"","","","",36,"2022-07-13 10:06:33","","10.1109/ACCESS.2020.3034680","","",,,,,5,2.50,2,3,2,"Advanced data analysis tools and techniques are important for semiconductor companies to gain competitive advantage. In particular, yield prediction tools, which fully utilize production data, help to improve operational efficiency and reduce production costs. This paper introduces a novel and scalable framework for semiconductor manufacturing Final Test (FT) yield prediction leveraging machine learning techniques. This framework is able to predict FT yield at wafer fabrication stage, so that FT low yield problems can be caught at an earlier production stage compared to past studies. Our work presents a robust solution to automatically handle both numerical and categorical production related data without prior knowledge of the low yield root cause. Gaussian Mixture Models, One Hot Encoder and Label Encoder techniques are adopted for data pre-processing. To improve model performance for both binary and multi-class classification, model selection and model ensemble using the F1-macro method is demonstrated. The framework has been applied to three mass production products with different wafer technologies and manufacturing flows. All of them achieved high F1-macro test score indicative of the robustness of our framework.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",37,"2022-07-13 10:06:33","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
12,"Eleni A. Chatzimichali, C. Bessant","Novel application of heuristic optimisation enables the creation and thorough evaluation of robust support vector machine ensembles for machine learning applications",2015,"","","","",38,"2022-07-13 10:06:33","","10.1007/s11306-015-0894-4","","",,,,,12,1.71,6,2,7,"","",""
52,"Yudong Chen, Lili Su, Jiaming Xu","Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent",2017,"","","","",39,"2022-07-13 10:06:33","","10.1145/3219617.3219655","","",,,,,52,10.40,17,3,5,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q łe m for an arbitrarily small but fixed constant ε>0. The parameter estimate converges in O(łog N) rounds with an estimation error on the order of max √dq/N, ~√d/N , which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q . The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log 3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.","",""
41,"Xiang Lu, M. Hasanipanah, Kathirvel Brindhadevi, H. Bakhshandeh Amnieh, Seyedamirhesam Khalafi","ORELM: A Novel Machine Learning Approach for Prediction of Flyrock in Mine Blasting",2019,"","","","",40,"2022-07-13 10:06:33","","10.1007/s11053-019-09532-2","","",,,,,41,13.67,8,5,3,"","",""
33,"Jana Sperschneider","Machine learning in plant-pathogen interactions: empowering biological predictions from field scale to genome scale.",2020,"","","","",41,"2022-07-13 10:06:33","","10.1111/nph.15771","","",,,,,33,16.50,33,1,2,"Contents Summary I. A primer on machine learning: what is it and what are the common pitfalls? II. Machine learning applications in plant-pathogen interactions III. Conclusion Acknowledgements References SUMMARY: Machine learning (ML) encompasses statistical methods that learn to identify patterns in complex datasets. Here, I review application areas in plant-pathogen interactions that have recently benefited from ML, such as disease monitoring, the discovery of gene regulatory networks, genomic selection for disease resistance and prediction of pathogen effectors. However, achieving robust performance from ML is not trivial and requires knowledge of both the methodology and the biology. I discuss common pitfalls and challenges in using ML approaches. Finally, I highlight future opportunities for ML as a tool for dissecting plant-pathogen interactions using high-throughput data, for example, through integration of diverse data sources and the analysis with higher resolution, such as from individual cells or on elaborate spatial and temporal scales.","",""
37,"Tianwei Yu, Dean P. Jones","Improving peak detection in high-resolution LC/MS metabolomics data using preexisting knowledge and machine learning approach",2014,"","","","",42,"2022-07-13 10:06:33","","10.1093/bioinformatics/btu430","","",,,,,37,4.63,19,2,8,"MOTIVATION Peak detection is a key step in the preprocessing of untargeted metabolomics data generated from high-resolution liquid chromatography-mass spectrometry (LC/MS). The common practice is to use filters with predetermined parameters to select peaks in the LC/MS profile. This rigid approach can cause suboptimal performance when the choice of peak model and parameters do not suit the data characteristics.   RESULTS Here we present a method that learns directly from various data features of the extracted ion chromatograms (EICs) to differentiate between true peak regions from noise regions in the LC/MS profile. It utilizes the knowledge of known metabolites, as well as robust machine learning approaches. Unlike currently available methods, this new approach does not assume a parametric peak shape model and allows maximum flexibility. We demonstrate the superiority of the new approach using real data. Because matching to known metabolites entails uncertainties and cannot be considered a gold standard, we also developed a probabilistic receiver-operating characteristic (pROC) approach that can incorporate uncertainties.   AVAILABILITY AND IMPLEMENTATION The new peak detection approach is implemented as part of the apLCMS package available at http://web1.sph.emory.edu/apLCMS/ CONTACT: tyu8@emory.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
13,"Karolis Liulys","Machine Learning Application in Predictive Maintenance",2019,"","","","",43,"2022-07-13 10:06:33","","10.1109/ESTREAM.2019.8732146","","",,,,,13,4.33,13,1,3,"Industrial organizations worldwide cannot ignore Industry 4.0 and its impact to their businesses. The biggest struggle is to find the way how to adopt all the possibilities for each plants unique use cases. In those situations where it is hard to find unified solutions internet is playing major part. Inseparable part of Industry 4.0 is Internet of Things (IoT) paradigm, where it is possible to connect all devices into united system. While robust Distributed Control Systems (DCS) are preferred for their safety, Industrial IoT (IIoT) allows next level prospects: big data performance analyzation, control patterns identification and predictive preventative maintenance by using machine learning algorithms. The study shows how implementing open-source software enables engineers to develop predictive maintenance applications with basic programming knowledge. These type of applications can be widely used in industrial field to inform about possible equipment malfunction helping reduce possible damages.","",""
19,"T. Le, M. Penna, D. Winkler, I. Yarovsky","Quantitative design rules for protein-resistant surface coatings using machine learning",2019,"","","","",44,"2022-07-13 10:06:33","","10.1038/s41598-018-36597-5","","",,,,,19,6.33,5,4,3,"","",""
18,"P. Fusar-Poli, Dominic Stringer, Alice M. S. Durieux, G. Rutigliano, I. Bonoldi, A. De Micheli, D. Ståhl","Clinical-learning versus machine-learning for transdiagnostic prediction of psychosis onset in individuals at-risk",2019,"","","","",45,"2022-07-13 10:06:33","","10.1038/s41398-019-0600-9","","",,,,,18,6.00,3,7,3,"","",""
24,"Saikat Das, Ph.D., Ahmed M. Mahfouz, D. Venugopal, S. Shiva","DDoS Intrusion Detection Through Machine Learning Ensemble",2019,"","","","",46,"2022-07-13 10:06:33","","10.1109/QRS-C.2019.00090","","",,,,,24,8.00,6,4,3,"Distributed Denial of Service (DDoS) attacks have been the prominent attacks over the last decade. A Network Intrusion Detection System (NIDS) should seamlessly configure to fight against these attackers' new approaches and patterns of DDoS attack. In this paper, we propose a NIDS which can detect existing as well as new types of DDoS attacks. The key feature of our NIDS is that it combines different classifiers using ensemble models, with the idea that each classifier can target specific aspects/types of intrusions, and in doing so provides a more robust defense mechanism against new intrusions. Further, we perform a detailed analysis of DDoS attacks, and based on this domain-knowledge verify the reduced feature set [27, 28] to significantly improve accuracy. We experiment with and analyze NSL-KDD dataset with reduced feature set and our proposed NIDS can detect 99.1% of DDoS attacks successfully. We compare our results with other existing approaches. Our NIDS approach has the learning capability to keep up with new and emerging DDoS attack patterns.","",""
11,"Ibrahim Gad, Doreswamy Hosahalli, B. R. Manjunatha, O. Ghoneim","A robust deep learning model for missing value imputation in big NCDC dataset",2020,"","","","",47,"2022-07-13 10:06:33","","10.1007/s42044-020-00065-z","","",,,,,11,5.50,3,4,2,"","",""
10,"E. Adabor, G. Acquaah-Mensah","Machine learning approaches to decipher hormone and HER2 receptor status phenotypes in breast cancer",2019,"","","","",48,"2022-07-13 10:06:33","","10.1093/bib/bbx138","","",,,,,10,3.33,5,2,3,"Breast cancer prognosis and administration of therapies are aided by knowledge of hormonal and HER2 receptor status. Breast cancer lacking estrogen receptors, progesterone receptors and HER2 receptors are difficult to treat. Regarding large data repositories such as The Cancer Genome Atlas, available wet-lab methods for establishing the presence of these receptors do not always conclusively cover all available samples. To this end, we introduce median-supplement methods to identify hormonal and HER2 receptor status phenotypes of breast cancer patients using gene expression profiles. In these approaches, supplementary instances based on median patient gene expression are introduced to balance a training set from which we build simple models to identify the receptor expression status of patients. In addition, for the purpose of benchmarking, we examine major machine learning approaches that are also applicable to the problem of finding receptor status in breast cancer. We show that our methods are robust and have high sensitivity with extremely low false-positive rates compared with the well-established methods. A successful application of these methods will permit the simultaneous study of large collections of samples of breast cancer patients as well as save time and cost while standardizing interpretation of outcomes of such studies.","",""
10,"Mahima Harjani, Moksh Grover, Nikhil Sharma, I. Kaushik","Analysis of Various Machine Learning Algorithm for Cardiac Pulse Prediction",2019,"","","","",49,"2022-07-13 10:06:33","","10.1109/ICCCIS48478.2019.8974519","","",,,,,10,3.33,3,4,3,"By applying machine learning algorithms, patterns are identified or recognized in the process of Pattern Recognition. On the grounds of prior knowledge, the data is collected and sorted. In this method, the raw data is transformed into a susceptible form which can be used by the machine. Electrocardiogram (ECG) Pattern Recognition is the main focus of this paper. ECG keeps a track of heart’s electrical activity. In the field of biometric it is used as a robust biometric. On the person, off the person and in the person, are the three categories for tracking and capturing signals. Only Off-the-person category in which there is no or minimal skin contact, is included in this paper. To analyze and implement data, six baseline methods are utilized. These baseline methods are applied two publicly available databases-CYBHi and UofT. Raw signals and spectrogram of heartbeat are used for studying about representing features. Various machine learning algorithms are also discussed. Implementation for predicting heartbeat as normal or abnormal and heart diseases, is performed.","",""
8,"Mazaher Kianpour, Shao-Fang Wen","Timing Attacks on Machine Learning: State of the Art",2019,"","","","",50,"2022-07-13 10:06:33","","10.1007/978-3-030-29516-5_10","","",,,,,8,2.67,4,2,3,"","",""
4,"Esther Heid, W. Green","Machine Learning of Reaction Properties via Learned Representations of the Condensed Graph of Reaction",2021,"","","","",51,"2022-07-13 10:06:33","","10.1021/acs.jcim.1c00975","","",,,,,4,4.00,2,2,1,"The estimation of chemical reaction properties such as activation energies, rates, or yields is a central topic of computational chemistry. In contrast to molecular properties, where machine learning approaches such as graph convolutional neural networks (GCNNs) have excelled for a wide variety of tasks, no general and transferable adaptations of GCNNs for reactions have been developed yet. We therefore combined a popular cheminformatics reaction representation, the so-called condensed graph of reaction (CGR), with a recent GCNN architecture to arrive at a versatile, robust, and compact deep learning model. The CGR is a superposition of the reactant and product graphs of a chemical reaction and thus an ideal input for graph-based machine learning approaches. The model learns to create a data-driven, task-dependent reaction embedding that does not rely on expert knowledge, similar to current molecular GCNNs. Our approach outperforms current state-of-the-art models in accuracy, is applicable even to imbalanced reactions, and possesses excellent predictive capabilities for diverse target properties, such as activation energies, reaction enthalpies, rate constants, yields, or reaction classes. We furthermore curated a large set of atom-mapped reactions along with their target properties, which can serve as benchmark data sets for future work. All data sets and the developed reaction GCNN model are available online, free of charge, and open source.","",""
9,"F. Maes, D. Robben, D. Vandermeulen, P. Suetens","The Role of Medical Image Computing and Machine Learning in Healthcare",2019,"","","","",52,"2022-07-13 10:06:33","","10.1007/978-3-319-94878-2_2","","",,,,,9,3.00,2,4,3,"","",""
85,"Neoklis Polyzotis, Sudip Roy, S. E. Whang, Martin A. Zinkevich","Data Lifecycle Challenges in Production Machine Learning",2018,"","","","",53,"2022-07-13 10:06:33","","10.1145/3299887.3299891","","",,,,,85,21.25,21,4,4,"Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",54,"2022-07-13 10:06:33","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
9,"Kexin Pei, Jonas Guan, David Williams-King, Junfeng Yang, S. Jana","XDA: Accurate, Robust Disassembly with Transfer Learning",2020,"","","","",55,"2022-07-13 10:06:33","","10.14722/NDSS.2021.23112","","",,,,,9,4.50,2,5,2,"Accurate and robust disassembly of stripped binaries is challenging. The root of the difficulty is that high-level structures, such as instruction and function boundaries, are absent in stripped binaries and must be recovered based on incomplete information. Current disassembly approaches rely on heuristics or simple pattern matching to approximate the recovery, but these methods are often inaccurate and brittle, especially across different compiler optimizations.  We present XDA, a transfer-learning-based disassembly framework that learns different contextual dependencies present in machine code and transfers this knowledge for accurate and robust disassembly. We design a self-supervised learning task motivated by masked Language Modeling to learn interactions among byte sequences in binaries. The outputs from this task are byte embeddings that encode sophisticated contextual dependencies between input binaries' byte tokens, which can then be finetuned for downstream disassembly tasks.  We evaluate XDA's performance on two disassembly tasks, recovering function boundaries and assembly instructions, on a collection of 3,121 binaries taken from SPEC CPU2017, SPEC CPU2006, and the BAP corpus. The binaries are compiled by GCC, ICC, and MSVC on x86/x64 Windows and Linux platforms over 4 optimization levels. XDA achieves 99.0% and 99.7% F1 score at recovering function boundaries and instructions, respectively, surpassing the previous state-of-the-art on both tasks. It also maintains speed on par with the fastest ML-based approach and is up to 38x faster than hand-written disassemblers like IDA Pro.","",""
11,"Ghassan Alnwaimi, Talha Zahir, S. Vahid, K. Moessner","Machine Learning Based Knowledge Acquisition on Spectrum Usage for LTE Femtocells",2013,"","","","",56,"2022-07-13 10:06:33","","10.1109/VTCFall.2013.6692276","","",,,,,11,1.22,3,4,9,"The decentralised and ad hoc nature of femtocell deployments calls for distributed learning strategies to mitigate interference. We propose a distributed spectrum awareness scheme for femtocell networks, based on combined payoff and strategy reinforcement learning (RL) models. We present two different learning strategies, based on modifications to the Bush Mosteller (BM) RL and the Roth-Erev RL algorithms. The simulation results show the convergence behaviour of the learning strategies under a dynamic robust game. As compared to the Bush Mosteller (BM) RL, our modified BM (MBM) converges smoothly to a stable satisfactory solution. Moreover, the MBM significantly reduces the interference collision cost during the learning process. Both the MBM and the modified Roth-Erev (MRE) algorithms are stochastic-based learning strategies which require less computation than the gradient follower (GF) learning strategy and have the capability to escape from suboptimal solution.","",""
5,"Haohan Wang, Zeyi Huang, Hanlin Zhang, Eric P. Xing","Toward Learning Human-aligned Cross-domain Robust Models by Countering Misaligned Features",2021,"","","","",57,"2022-07-13 10:06:33","","","","",,,,,5,5.00,1,4,1,"Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective as-suming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available here.","",""
7,"N. Ball, R. Brunner, A. Myers","Robust Machine Learning Applied to Terascale Astronomical Datasets",2007,"","","","",58,"2022-07-13 10:06:33","","","","",,,,,7,0.47,2,3,15,"We present recent results from the LCDM (Laboratory for Cosmological Data Mining; this http URL) collaboration between UIUC Astronomy and NCSA to deploy supercomputing cluster resources and machine learning algorithms for the mining of terascale astronomical datasets. This is a novel application in the field of astronomy, because we are using such resources for data mining, and not just performing simulations. Via a modified implementation of the NCSA cyberenvironment Data-to-Knowledge, we are able to provide improved classifications for over 100 million stars and galaxies in the Sloan Digital Sky Survey, improved distance measures, and a full exploitation of the simple but powerful k-nearest neighbor algorithm. A driving principle of this work is that our methods should be extensible from current terascale datasets to upcoming petascale datasets and beyond. We discuss issues encountered to-date, and further issues for the transition to petascale. In particular, disk I/O will become a major limiting factor unless the necessary infrastructure is implemented.","",""
89,"Huichen Lihuichen","DECISION-BASED ADVERSARIAL ATTACKS: RELIABLE ATTACKS AGAINST BLACK-BOX MACHINE LEARNING MODELS",2017,"","","","",59,"2022-07-13 10:06:33","","","","",,,,,89,17.80,89,1,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradientor score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available at XXXXXX. Gradient-based Model M Untargeted Flip to any label Targeted Flip to target label FGSM, DeepFool L-BFGS-B, Houdini, JSMA, Carlini & Wagner, Iterative Gradient Descent Score-based Detailed Model Prediction Y (e.g. probabilities or logits) ZOO Local Search Decision-based Final Model Prediction Ymax (e.g. max class label) this work (Boundary Attack) Transfer-based Training Data T","",""
28,"Lili Su, Jiaming Xu","Securing Distributed Machine Learning in High Dimensions",2018,"","","","",60,"2022-07-13 10:06:33","","","","",,,,,28,7.00,14,2,4,"We consider securing a distributed machine learning system wherein the data is kept confidential by its providers who are recruited as workers to help the learner to train a $d$--dimensional model. In each communication round, up to $q$ out of the $m$ workers suffer Byzantine faults; faulty workers are assumed to have complete knowledge of the system and can collude to behave arbitrarily adversarially against the learner. We assume that each worker keeps a local sample of size $n$. (Thus, the total number of data points is $N=nm$.) Of particular interest is the high-dimensional regime $d \gg n$.  We propose a secured variant of the classical gradient descent method which can tolerate up to a constant fraction of Byzantine workers. We show that the estimation error of the iterates converges to an estimation error $O(\sqrt{q/N} + \sqrt{d/N})$ in $O(\log N)$ rounds. The core of our method is a robust gradient aggregator based on the iterative filtering algorithm proposed by Steinhardt et al. \cite{Steinhardt18} for robust mean estimation. We establish a uniform concentration of the sample covariance matrix of gradients, and show that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function. As a by-product, we develop a new concentration inequality for sample covariance matrices of sub-exponential distributions, which might be of independent interest.","",""
23,"Muxin Gu, M. Buckley","Semi-supervised machine learning for automated species identification by collagen peptide mass fingerprinting",2018,"","","","",61,"2022-07-13 10:06:33","","10.1186/s12859-018-2221-3","","",,,,,23,5.75,12,2,4,"","",""
12,"Melanie Weber, M. Zaheer, A. Rawat, A. Menon, Sanjiv Kumar","Robust Large-Margin Learning in Hyperbolic Space",2020,"","","","",62,"2022-07-13 10:06:33","","","","",,,,,12,6.00,2,5,2,"Recently, there has been a surge of interest in representation learning in hyperbolic spaces, driven by their ability to represent hierarchical data with significantly fewer dimensions than standard Euclidean spaces. However, the viability and benefits of hyperbolic spaces for downstream machine learning tasks have received less attention. In this paper, we present, to our knowledge, the first theoretical guarantees for learning a classifier in hyperbolic rather than Euclidean space. Specifically, we consider the problem of learning a large-margin classifier for data possessing a hierarchical structure. Our first contribution is a hyperbolic perceptron algorithm, which provably converges to a separating hyperplane. We then provide an algorithm to efficiently learn a large-margin hyperplane, relying on the careful injection of adversarial examples. Finally, we prove that for hierarchical data that embeds well into hyperbolic space, the low embedding dimension ensures superior guarantees when learning the classifier directly in hyperbolic space.","",""
16,"E. Swann, B. Sun, D. Cleland, A. Barnard","Representing molecular and materials data for unsupervised machine learning",2018,"","","","",63,"2022-07-13 10:06:33","","10.1080/08927022.2018.1450982","","",,,,,16,4.00,4,4,4,"Abstract Statistical analysis and machine learning can help us understand and predict the collective properties and performance of ensembles of molecules and nanostructures, while accounting for all the complexity and diversity of real world specimens. Combining data-driven techniques with robust and reliable simulation methods can provide insights that cannot be made any other way. However, not all statistical and machine learning methods are right for all occasions; testing, validation and perhaps some trial and error are needed. Domain knowledge alone is not sufficient to choose the right algorithms. Data representation methods that are best suited to machine learning are not necessarily scientifically intuitive. The best descriptors are not always the structural features or physiochemical properties that we are aiming to control, and the way our data is distributed can be as important as what it contains. In this review, we discuss the differences, advantages and disadvantages of some of the common data representation, reduction and classification methods applicable to molecular and materials modelling. Focussing on unsupervised methods, we highlight features of these algorithms that determine their suitability and can inform choices of which learning method to use and how to effectively prepare data. A case study is also provided to demonstrate how testing can be undertaken, and how methods can be combined.","",""
524,"S. Raschka","Python Machine Learning",2015,"","","","",64,"2022-07-13 10:06:33","","","","",,,,,524,74.86,524,1,7,"Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk and answer tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource.What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Keras and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success.Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization.Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.","",""
65,"N. Ball, R. Brunner, A. Myers, D. E. U. O. I. A. Urbana-Champaign, National Center for Supercomputing Applications","Robust machine learning applied to astronomical data sets. I. Star-galaxy classification of the sloan digital sky survey DR3 using decision trees",2006,"","","","",65,"2022-07-13 10:06:33","","10.1086/507440","","",,,,,65,4.06,13,5,16,"We provide classifications for all 143 million nonrepeat photometric objects in the Third Data Release of the SDSS using decision trees trained on 477,068 objects with SDSS spectroscopic data. We demonstrate that these star/galaxy classifications are expected to be reliable for approximately 22 million objects with r 20. The general machine learning environment Data-to-Knowledge and supercomputing resources enabled extensive investigation of the decision tree parameter space. This work presents the first public release of objects classified in this way for an entire SDSS data release. The objects are classified as either galaxy, star, or nsng (neither star nor galaxy), with an associated probability for each class. To demonstrate how to effectively make use of these classifications, we perform several important tests. First, we detail selection criteria within the probability space defined by the three classes to extract samples of stars and galaxies to a given completeness and efficiency. Second, we investigate the efficacy of the classifications and the effect of extrapolating from the spectroscopic regime by performing blind tests on objects in the SDSS, 2dFGRS, and 2QZ surveys. Given the photometric limits of our spectroscopic training data, we effectively begin to extrapolate past our star-galaxy training set at r ~ 18. By comparing the number counts of our training sample with the classified sources, however, we find that our efficiencies appear to remain robust to r ~ 20. As a result, we expect our classifications to be accurate for 900,000 galaxies and 6.7 million stars and remain robust via extrapolation for a total of 8.0 million galaxies and 13.9 million stars.","",""
13,"Ali A. Abdallah, S. Saab, Z. Kassas","A machine learning approach for localization in cellular environments",2018,"","","","",66,"2022-07-13 10:06:33","","10.1109/PLANS.2018.8373508","","",,,,,13,3.25,4,3,4,"A machine learning approach is developed for localization based on received signal strength (RSS) from cellular towers. The proposed approach only assumes knowledge of RSS fingerprints of the environment, and does not require knowledge of the cellular base transceiver station (BTS) locations, nor uses any RSS mathematical model. The proposed localization scheme integrates a weighted K-nearest neighbor (WKNN) and a multilayer neural network. The integration takes advantage of the robust clustering ability of WKNN and implements a neural network that could estimate the position within each cluster. Experimental results are presented to demonstrate the proposed approach in two urban environments and one rural environment, achieving a mean distance localization error of 5.9 m and 5.1 m in the urban environments and 8.7 m in the rural environment. This constitutes an improvement of 41%, 45%, and 16%, respectively, over the WKNN-only algorithm.","",""
67,"Yudong Chen, Lili Su, Jiaming Xu","Distributed Statistical Machine Learning in Adversarial Settings",2017,"","","","",67,"2022-07-13 10:06:33","","10.1145/3154503","","",,,,,67,13.40,22,3,5,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q ≤ for an arbitrarily small but fixed constant ε > 0. The parameter estimate converges in O(log N) rounds with an estimation error on the order of max{√dq/N, √d/N, which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q. The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.","",""
10,"J. Collins, K. Howe, B. Nachman","CWoLa Hunting: Extending the Bump Hunt with Machine Learning",2018,"","","","",68,"2022-07-13 10:06:33","","","","",,,,,10,2.50,3,3,4,"The oldest and most robust technique to search for new particles is to look for `bumps' in invariant mass spectra over smoothly falling backgrounds. This is a powerful technique, but only uses one-dimensional information. One can restrict the phase space to enhance a potential signal, but such tagging techniques require a signal hypothesis and training a classifier in simulation and applying it on data. We present a new method for using all of the available information (with machine learning) without using any prior knowledge about potential signals. Given the lack of new physics signals at the Large Hadron Collider (LHC), such model independent approaches are critical for ensuring full coverage to fully exploit the rich datasets from the LHC experiments. In addition to illustrating how the new method works in simple test cases, we demonstrate the power of the extended bump hunt on a realistic all-hadronic resonance search in a channel that would not be covered with existing techniques.","",""
9,"Obed Tettey Nartey, Guowu Yang, Sarpong Kwadwo Asare, Jinzhao Wu, Lady Nadia Frempong","Robust Semi-Supervised Traffic Sign Recognition via Self-Training and Weakly-Supervised Learning",2020,"","","","",69,"2022-07-13 10:06:33","","10.3390/s20092684","","",,,,,9,4.50,2,5,2,"Traffic sign recognition is a classification problem that poses challenges for computer vision and machine learning algorithms. Although both computer vision and machine learning techniques have constantly been improved to solve this problem, the sudden rise in the number of unlabeled traffic signs has become even more challenging. Large data collation and labeling are tedious and expensive tasks that demand much time, expert knowledge, and fiscal resources to satisfy the hunger of deep neural networks. Aside from that, the problem of having unbalanced data also poses a greater challenge to computer vision and machine learning algorithms to achieve better performance. These problems raise the need to develop algorithms that can fully exploit a large amount of unlabeled data, use a small amount of labeled samples, and be robust to data imbalance to build an efficient and high-quality classifier. In this work, we propose a novel semi-supervised classification technique that is robust to small and unbalanced data. The framework integrates weakly-supervised learning and self-training with self-paced learning to generate attention maps to augment the training set and utilizes a novel pseudo-label generation and selection algorithm to generate and select pseudo-labeled samples. The method improves the performance by: (1) normalizing the class-wise confidence levels to prevent the model from ignoring hard-to-learn samples, thereby solving the imbalanced data problem; (2) jointly learning a model and optimizing pseudo-labels generated on unlabeled data; and (3) enlarging the training set to satisfy the hunger of deep learning models. Extensive evaluations on two public traffic sign recognition datasets demonstrate the effectiveness of the proposed technique and provide a potential solution for practical applications.","",""
5,"D. Mislis, S. Pyrzas, K. Alsubai","TSARDI: a Machine Learning data rejection algorithm for transiting exoplanet light curves",2018,"","","","",70,"2022-07-13 10:06:33","","10.1093/mnras/sty2361","","",,,,,5,1.25,2,3,4,"We present TSARDI, an efficient rejection algorithm designed to improve the transit detection efficiency in data collected by large scale surveys. TSARDI is based on the Machine Learning clustering algorithm DBSCAN, and its purpose is to serve as a robust and adaptable filter aiming to identify unwanted noise points left over from data detrending processes. TSARDI is an unsupervised method, which can treat each light curve individually; there is no need of previous knowledge of any other field light curves. We conduct a simulated transit search by injecting planets on real data obtained by the QES project and show that TSARDI leads to an overall transit detection efficiency increase of $\sim$11\%, compared to results obtained from the same sample, but using a standard sigma-clip algorithm. For the brighter end of our sample (host star magnitude < 12), TSARDI achieves a detection efficiency of $\sim$80\% of injected planets. While our algorithm has been developed primarily for the field of exoplanets, it is easily adaptable and extendable for use in any time series.","",""
5,"Y. Malhotra","AI, Machine Learning & Deep Learning Risk Management & Controls: Beyond Deep Learning and Generative Adversarial Networks: Model Risk Management in AI, Machine Learning & Deep Learning",2018,"","","","",71,"2022-07-13 10:06:33","","10.2139/SSRN.3193693","","",,,,,5,1.25,5,1,4,"The current paper proposes how model risk management in operationalizing machine learning for algorithm deployment can be applied in national C4I and Cyber projects such as Project Maven. It builds upon recent leadership of global Management and Leadership industry executives for AI and Machine Learning Executive Education for MIT Sloan School of Management and the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and invited presentations at Princeton University. After building understanding about why model risk management is most crucial to robust AI, Machine Learning, Deep Learning, and, Neural Networks deployment, it introduces a Knowledge Management Framework for Model Risk Management to advance beyond ‘AI Automation’ to ‘AI Augmentation.’","",""
4,"Henggang Cui, G. Ganger, Phillip B. Gibbons","MLtuner: System Support for Automatic Machine Learning Tuning",2018,"","","","",72,"2022-07-13 10:06:33","","","","",,,,,4,1.00,1,3,4,"MLtuner automatically tunes settings for training tunables (such as the learning rate, the momentum, the mini-batch size, and the data staleness bound) that have a significant impact on large-scale machine learning (ML) performance. Traditionally, these tunables are set manually, which is unsurprisingly error-prone and difficult to do without extensive domain knowledge. MLtuner uses efficient snapshotting, branching, and optimization-guided online trial-and-error to find good initial settings as well as to re-tune settings during execution. Experiments show that MLtuner can robustly find and re-tune tunable settings for a variety of ML applications, including image classification (for 3 models and 2 datasets), video classification, and matrix factorization. Compared to state-of-the-art ML auto-tuning approaches, MLtuner is more robust for large problems and over an order of magnitude faster.","",""
3,"Xi Chen, Yining Wang","Robust Dynamic Pricing with Demand Learning in the Presence of Outlier Customers",2020,"","","","",73,"2022-07-13 10:06:33","","10.2139/ssrn.3650656","","",,,,,3,1.50,2,2,2,"Dynamic pricing is a core problem in revenue management. Most existing literature assumes that the demand follows a probabilistic model, with an unknown demand curve as the mean. However, in practice, customers may not always behave according to such a model. In “Robust Dynamic Pricing with Demand Learning in the Presence of Outlier Customers,” Chen and Wang study the dynamic pricing problem under model misspecification. To characterize the behavior of outlier customers, an ε-contamination model—the most fundamental model in robust statistics and machine learning, is adopted. The challenges brought by the presence of outlier customers are mainly due to the fact that arrivals of outliers and their exhibited demand behaviors are completely arbitrary. To address these challenges, the authors propose robust dynamic pricing policies that can handle any outlier arrival and demand patterns. The proposed policies are fully adaptive without requiring prior knowledge of the outlier proportion parameter.","",""
32,"K. Javed","A robust and reliable data-driven prognostics approach based on Extreme Learning Machine and Fuzzy Clustering",2014,"","","","",74,"2022-07-13 10:06:33","","","","",,,,,32,4.00,32,1,8,"Prognostics and Health Management (PHM) aims at extending the life cycle of engineerin gassets, while reducing exploitation and maintenance costs. For this reason,prognostics is considered as a key process with future capabilities. Indeed, accurateestimates of the Remaining Useful Life (RUL) of an equipment enable defining furtherplan of actions to increase safety, minimize downtime, ensure mission completion andefficient production.Recent advances show that data-driven approaches (mainly based on machine learningmethods) are increasingly applied for fault prognostics. They can be seen as black-boxmodels that learn system behavior directly from Condition Monitoring (CM) data, usethat knowledge to infer its current state and predict future progression of failure. However,approximating the behavior of critical machinery is a challenging task that canresult in poor prognostics. As for understanding, some issues of data-driven prognosticsmodeling are highlighted as follows. 1) How to effectively process raw monitoringdata to obtain suitable features that clearly reflect evolution of degradation? 2) Howto discriminate degradation states and define failure criteria (that can vary from caseto case)? 3) How to be sure that learned-models will be robust enough to show steadyperformance over uncertain inputs that deviate from learned experiences, and to bereliable enough to encounter unknown data (i.e., operating conditions, engineering variations,etc.)? 4) How to achieve ease of application under industrial constraints andrequirements? Such issues constitute the problems addressed in this thesis and have ledto develop a novel approach beyond conventional methods of data-driven prognostics.","",""
3,"Kai Liang Tan, Anuj Sharma, S. Sarkar","Robust Deep Reinforcement Learning for Traffic Signal Control",2020,"","","","",75,"2022-07-13 10:06:33","","10.1007/s42421-020-00029-6","","",,,,,3,1.50,1,3,2,"","",""
376,"Rui Zhao, Ruqiang Yan, Jinjiang Wang, K. Mao","Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks",2017,"","","","",76,"2022-07-13 10:06:33","","10.3390/s17020273","","",,,,,376,75.20,94,4,5,"In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","",""
87,"Nicholas Wagner, J. Rondinelli","Theory-Guided Machine Learning in Materials Science",2016,"","","","",77,"2022-07-13 10:06:33","","10.3389/fmats.2016.00028","","",,,,,87,14.50,44,2,6,"Materials scientists are increasingly adopting the use of machine learning tools to discover hidden trends in data and make predictions. Applying concepts from data science without foreknowledge of their limitations and the unique qualities of materials data, however, could lead to errant conclusions. The differences that exist between various kinds of experimental and calculated data require careful choices of data processing and machine learning methods. Here, we outline potential pitfalls involved in using machine learning without robust protocols. We address some problems of overfitting to training data using decision trees as an example, rational descriptor selection in the field of perovskites, and preserving physical interpretability in the application of dimensionality reducing techniques such as principal component analysis. We show how proceeding without the guidance of domain knowledge can lead to both quantitatively and qualitatively incorrect predictive models.","",""
16,"Xiaokai Liu, Cheng-lin Zhao, Pengbiao Wang, Yang Zhang, Tian-le Yang","Blind modulation classification algorithm based on machine learning for spatially correlated MIMO system",2017,"","","","",78,"2022-07-13 10:06:33","","10.1049/iet-com.2015.1222","","",,,,,16,3.20,3,5,5,"Spatial correlation is a decisive factor for pragmatic multiple-input multiple-output (MIMO) system, simultaneously bringing about some problems in the received signal modulation identification respect. In this study, the authors focus on blind digital modulation identification in the spatially correlated MIMO system and deliver a robust signal recognition algorithm based on extreme learning machine (ELM) and higher order statistical features for MIMO signal identification without a priori knowledge of the channel and signal parameters. The superiority of ELM lies in random selections of hidden nodes and ascertains output weights analytically, which result in lower computational complexity. Theoretically, this algorithm has a tendency to supply excellent generalisation performance at staggering learning rate. Further, the simulation results indicate that the ELM could reap a perfectly acceptable recognition performance and thus provides a solid ground structure for tackling MIMO modulation challenges in low signal-to-noise ratio.","",""
28,"Tristan D. McRae, D. Oleksyn, Jim Miller, Yu-Rong Gao","Robust blind spectral unmixing for fluorescence microscopy using unsupervised learning",2019,"","","","",79,"2022-07-13 10:06:33","","10.1371/journal.pone.0225410","","",,,,,28,9.33,7,4,3,"Due to the overlapping emission spectra of fluorophores, fluorescence microscopy images often have bleed-through problems, leading to a false positive detection. This problem is almost unavoidable when the samples are labeled with three or more fluorophores, and the situation is complicated even further when imaged under a multiphoton microscope. Several methods have been developed and commonly used by biologists for fluorescence microscopy spectral unmixing, such as linear unmixing, non-negative matrix factorization, deconvolution, and principal component analysis. However, they either require pre-knowledge of emission spectra or restrict the number of fluorophores to be the same as detection channels, which highly limits the real-world applications of those spectral unmixing methods. In this paper, we developed a robust and flexible spectral unmixing method: Learning Unsupervised Means of Spectra (LUMoS), which uses an unsupervised machine learning clustering method to learn individual fluorophores’ spectral signatures from mixed images, and blindly separate channels without restrictions on the number of fluorophores that can be imaged. This method highly expands the hardware capability of two-photon microscopy to simultaneously image more fluorophores than is possible with instrumentation alone. Experimental and simulated results demonstrated the robustness of LUMoS in multi-channel separations of two-photon microscopy images. We also extended the application of this method to background/autofluorescence removal and colocalization analysis. Lastly, we integrated this tool into ImageJ to offer an easy to use spectral unmixing tool for fluorescence imaging. LUMoS allows us to gain a higher spectral resolution and obtain a cleaner image without the need to upgrade the imaging hardware capabilities.","",""
8,"Marine Carpuat, Cyril Goutte, George F. Foster","Linear Mixture Models for Robust Machine Translation",2014,"","","","",80,"2022-07-13 10:06:33","","10.3115/v1/W14-3363","","",,,,,8,1.00,3,3,8,"As larger and more diverse parallel texts become available, how can we leverage heterogeneous data to train robust machine translation systems that achieve good translation quality on various test domains? This challenge has been addressed so far by repurposing techniques developed for domain adaptation, such as linear mixture models which combine estimates learned on homogeneous subdomains. However, learning from large heterogeneous corpora is quite different from standard adaptation tasks with clear domain distinctions. In this paper, we show that linear mixture models can reliably improve translation quality in very heterogeneous training conditions, even if the mixtures do not use any domain knowledge and attempt to learn generic models rather than adapt them to the target domain. This surprising finding opens new perspectives for using mixture models in machine translation beyond clear cut domain adaptation tasks.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",81,"2022-07-13 10:06:33","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
38,"S. Raschka, R. S. Olson","Python machine learning : unlock deeper insights into machine learning with this vital guide to cutting-edge predictive analytics",2015,"","","","",82,"2022-07-13 10:06:33","","","","",,,,,38,5.43,19,2,7,"Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analytics About This Book * Leverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualization * Learn effective strategies and best practices to improve and optimize machine learning systems and algorithms * Ask and answer tough questions of your data with robust statistical models, built for a range of datasets Who This Book Is For If you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource. What You Will Learn * Explore how to use different machine learning models to ask different questions of your data * Learn how to build neural networks using Keras and Theano * Find out how to write clean and elegant Python code that will optimize the strength of your algorithms * Discover how to embed your machine learning model in a web application for increased accessibility * Predict continuous target outcomes using regression analysis * Uncover hidden patterns and structures in data with clustering * Organize data using effective pre-processing techniques * Get to grips with sentiment analysis to delve deeper into textual and social media data In Detail Machine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success. Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization. Style and approach Python Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.","",""
66,"S. Deeb, S. Tyanova, M. Hummel, M. Schmidt-Supprian, Jüergen Cox, M. Mann","Machine Learning-based Classification of Diffuse Large B-cell Lymphoma Patients by Their Protein Expression Profiles",2015,"","","","",83,"2022-07-13 10:06:33","","10.1074/mcp.M115.050245","","",,,,,66,9.43,11,6,7,"Characterization of tumors at the molecular level has improved our knowledge of cancer causation and progression. Proteomic analysis of their signaling pathways promises to enhance our understanding of cancer aberrations at the functional level, but this requires accurate and robust tools. Here, we develop a state of the art quantitative mass spectrometric pipeline to characterize formalin-fixed paraffin-embedded tissues of patients with closely related subtypes of diffuse large B-cell lymphoma. We combined a super-SILAC approach with label-free quantification (hybrid LFQ) to address situations where the protein is absent in the super-SILAC standard but present in the patient samples. Shotgun proteomic analysis on a quadrupole Orbitrap quantified almost 9,000 tumor proteins in 20 patients. The quantitative accuracy of our approach allowed the segregation of diffuse large B-cell lymphoma patients according to their cell of origin using both their global protein expression patterns and the 55-protein signature obtained previously from patient-derived cell lines (Deeb, S. J., D'Souza, R. C., Cox, J., Schmidt-Supprian, M., and Mann, M. (2012) Mol. Cell. Proteomics 11, 77–89). Expression levels of individual segregation-driving proteins as well as categories such as extracellular matrix proteins behaved consistently with known trends between the subtypes. We used machine learning (support vector machines) to extract candidate proteins with the highest segregating power. A panel of four proteins (PALD1, MME, TNFAIP8, and TBC1D4) is predicted to classify patients with low error rates. Highly ranked proteins from the support vector analysis revealed differential expression of core signaling molecules between the subtypes, elucidating aspects of their pathobiology.","",""
16,"W. MacInnes, Stephanie Santosa, William Wright","Visual Classification: Expert Knowledge Guides Machine Learning",2010,"","","","",84,"2022-07-13 10:06:33","","10.1109/MCG.2010.18","","",,,,,16,1.33,5,3,12,"Humans use intuition and experience to classify everything they perceive, but only if the distinguishing patterns are visible. Machine-learning algorithms can learn class information from data sets, but the created classes' meaning isn't always clear. A proposed mixed-initiative approach combines intuitive visualizations with machine learning to tap into the strengths of human and machine classification. The use of visualizations in an expert-guided clustering technique allows the display of complex data sets in a way that allows human input into machine clustering. Test participants successfully employed this technique to classify analytic activities using behavioral observations of a creative-analysis task. The results demonstrate how visualization of the machine-learned classification can help users create more robust and intuitive categories.","",""
9,"S. Nusser","Robust learning in safety related domains: machine learning methods for solving safety related application problems",2009,"","","","",85,"2022-07-13 10:06:33","","","","",,,,,9,0.69,9,1,13,"Today, machine learning methods are successfully deployed in a wide range of applications. A multitude of different learning algorithms has been developed in order to solve classification and regression problems. These common machine learning approaches are regarded with suspicion by domain experts in safety-related application fields because it is often infeasible to sufficiently interpret and validate the learned solutions. Especially for safety-related applications, it is imperative to guarantee that the learned solution is correct and fulfills all given requirements. The basic idea of the approaches proposed within this thesis is to solve high-dimensional application problems by an ensemble of simple submodels, each of which is allowed to only use two or three dimensions of the complete input space. The restriction of the dimensionality of the submodels allows the visualization of the learned models. Thus a visual interpretation and validation according to the existing domain knowledge becomes feasible. Due to the visualization, an unintended and possibly undesired extraand interpolation behavior can be discovered and avoided by changing the model parameters or selecting other submodels. Since the learned submodels are interpretable the correctness of the learned solution can therefore be guaranteed. The ensemble of the submodels compensates for the limited dimensionality of the individual submodels. The proposed ensemble methods are successfully applied on common benchmark problems as well as on real-world application problems with very high requirements on the functional safety of the learned solution.","",""
19,"Heinrich Dinkel, Mengyue Wu, Kai Yu","Towards Duration Robust Weakly Supervised Sound Event Detection",2021,"","","","",86,"2022-07-13 10:06:33","","10.1109/TASLP.2021.3054313","","",,,,,19,19.00,6,3,1,"Sound event detection (SED) is the task of tagging the absence or presence of audio events and their corresponding interval within a given audio clip. While SED can be done using supervised machine learning, where training data is fully labeled with access to per event timestamps and duration, our work focuses on weakly-supervised sound event detection (WSSED), where prior knowledge about an event's duration is unavailable. Recent research within the field focuses on improving segment- and event-level localization performance for specific datasets regarding specific evaluation metrics. Specifically, well-performing event-level localization requires fully labeled development subsets to obtain event duration estimates, which significantly benefits localization performance. Moreover, well-performing segment-level localization models output predictions at a coarse-scale (e.g., 1 second), hindering their deployment on datasets containing very short events ($< $ 1 second). This work proposes a duration robust CRNN (CDur) framework, which aims to achieve competitive performance in terms of segment- and event-level localization. This paper proposes a new post-processing strategy named “Triple Threshold” and investigates two data augmentation methods along with a label smoothing method within the scope of WSSED. Evaluation of our model is done on the DCASE2017 and 2018 Task 4 datasets, and URBAN-SED. Our model outperforms other approaches on the DCASE2018 and URBAN-SED datasets without requiring prior duration knowledge. In particular, our model is capable of similar performance to strongly-labeled supervised models on the URBAN-SED dataset. Lastly, ablation experiments to reveal that without post-processing, our model's localization performance drop is significantly lower compared with other approaches.","",""
35,"Emir Muñoz, V. Nováček, P. Vandenbussche","Facilitating prediction of adverse drug reactions by using knowledge graphs and multi‐label learning models",2019,"","","","",87,"2022-07-13 10:06:33","","10.1093/bib/bbx099","","",,,,,35,11.67,12,3,3,"Abstract Timely identification of adverse drug reactions (ADRs) is highly important in the domains of public health and pharmacology. Early discovery of potential ADRs can limit their effect on patient lives and also make drug development pipelines more robust and efficient. Reliable in silico prediction of ADRs can be helpful in this context, and thus, it has been intensely studied. Recent works achieved promising results using machine learning. The presented work focuses on machine learning methods that use drug profiles for making predictions and use features from multiple data sources. We argue that despite promising results, existing works have limitations, especially regarding flexibility in experimenting with different data sets and/or predictive models. We suggest to address these limitations by generalization of the key principles used by the state of the art. Namely, we explore effects of: (1) using knowledge graphs—machine‐readable interlinked representations of biomedical knowledge—as a convenient uniform representation of heterogeneous data; and (2) casting ADR prediction as a multi‐label ranking problem. We present a specific way of using knowledge graphs to generate different feature sets and demonstrate favourable performance of selected off‐the‐shelf multi‐label learning models in comparison with existing works. Our experiments suggest better suitability of certain multi‐label learning methods for applications where ranking is preferred. The presented approach can be easily extended to other feature sources or machine learning methods, making it flexible for experiments tuned toward specific requirements of end users. Our work also provides a clearly defined and reproducible baseline for any future related experiments.","",""
381,"Maximilian Nickel, Volker Tresp, H. Kriegel","Factorizing YAGO: scalable machine learning for linked data",2012,"","","","",88,"2022-07-13 10:06:33","","10.1145/2187836.2187874","","",,,,,381,38.10,127,3,10,"Vast amounts of structured information have been published in the Semantic Web's Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD's size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD's data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize non-deterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO~2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 ⋅ 1014 possible triples in the YAGO~2 core ontology.","",""
12,"Stephen Bonner, John Brennan, Ibad Kureshi, G. Theodoropoulos, A. McGough, B. Obara","Temporal Graph Offset Reconstruction: Towards Temporally Robust Graph Representation Learning",2018,"","","","",89,"2022-07-13 10:06:33","","10.1109/BigData.2018.8622636","","",,,,,12,3.00,2,6,4,"Graphs are a commonly used construct for representing relationships between elements in complex high dimensional datasets. Many real-world phenomenon are dynamic in nature, meaning that any graph used to represent them is inherently temporal. However, many of the machine learning models designed to capture knowledge about the structure of these graphs ignore this rich temporal information when creating representations of the graph. This results in models which do not perform well when used to make predictions about the future state of the graph – especially when the delta between time stamps is not small. In this work, we explore a novel training procedure and an associated unsupervised model which creates graph representations optimised to predict the future state of the graph. We make use of graph convo-lutional neural networks to encode the graph into a latent representation, which we then use to train our temporal offset reconstruction method, inspired by auto-encoders, to predict a later time point – multiple time steps into the future. Using our method, we demonstrate superior performance for the task of future link prediction compared with none-temporal state-of-the-art baselines. We show our approach to be capable of outperforming non-temporal baselines by 38% on a real world dataset.","",""
15,"A. Kaur, Kamaldeep Kaur","An Empirical Study of Robustness and Stability of Machine Learning Classifiers in Software Defect Prediction",2014,"","","","",90,"2022-07-13 10:06:33","","10.1007/978-3-319-11218-3_35","","",,,,,15,1.88,8,2,8,"","",""
11,"Gonzalo Marín, P. Casas, G. Capdehourat","Deep in the Dark - Deep Learning-Based Malware Traffic Detection Without Expert Knowledge",2019,"","","","",91,"2022-07-13 10:06:33","","10.1109/SPW.2019.00019","","",,,,,11,3.67,4,3,3,"With the ever-growing occurrence of networking attacks, robust network security systems are essential to prevent and mitigate their harming effects. In recent years, machine learning-based systems have gain popularity for network security applications, usually considering the application of shallow models, where a set of expert handcrafted features are needed to pre-process the data before training. The main problem with this approach is that handcrafted features can fail to perform well given different kinds of scenarios and problems. Deep Learning models can solve this kind of issues using their ability to learn feature representations from input raw or basic, non-processed data. In this paper we explore the power of deep learning models on the specific problem of detection and classification of malware network traffic, using different representations for the input data. As a major advantage as compared to the state of the art, we consider raw measurements coming directly from the stream of monitored bytes as the input to the proposed models, and evaluate different raw-traffic feature representations, including packet and flow-level ones. Our results suggest that deep learning models can better capture the underlying statistics of malicious traffic as compared to classical, shallow-like models, even while operating in the dark, i.e., without any sort of expert handcrafted inputs.","",""
6,"Heng Li, ShiYao Zhou, Wei Yuan, Xiapu Luo, Cuiying Gao, Shuiyan Chen","Robust Android Malware Detection against Adversarial Example Attacks",2021,"","","","",92,"2022-07-13 10:06:33","","10.1145/3442381.3450044","","",,,,,6,6.00,1,6,1,"Adversarial examples pose severe threats to Android malware detection because they can render the machine learning based detection systems useless. How to effectively detect Android malware under various adversarial example attacks becomes an essential but very challenging issue. Existing adversarial example defense mechanisms usually rely heavily on the instances or the knowledge of adversarial examples, and thus their usability and effectiveness are significantly limited because they often cannot resist the unseen-type adversarial examples. In this paper, we propose a novel robust Android malware detection approach that can resist adversarial examples without requiring their instances or knowledge by jointly investigating malware detection and adversarial example defenses. More precisely, our approach employs a new VAE (variational autoencoder) and an MLP (multi-layer perceptron) to detect malware, and combines their detection outcomes to make the final decision. In particular, we share a feature extraction network between the VAE and the MLP to reduce model complexity and design a new loss function to disentangle the features of different classes, hence improving detection performance. Extensive experiments confirm our model’s advantage in accuracy and robustness. Our method outperforms 11 state-of-the-art robust Android malware detection models when resisting 7 kinds of adversarial example attacks.","",""
6,"Weilin Wu, Jianyong Duan, R. Lu, F. Gao, Yuquan Chen","Embedded machine learning systems for robust spoken language parsing",2005,"","","","",93,"2022-07-13 10:06:33","","10.1109/NLPKE.2005.1598729","","",,,,,6,0.35,1,5,17,"In processing ill-formed spontaneous spoken utterance, many state-of-the-art robust parsers achieve robustness by allowing skipping of words and rule symbols. The parser's ability to skip words and rule symbols, however, results in a much bigger search space and greatly increases the parse ambiguity. Previous approaches resolved these issues through manually labeling the types of rule symbols, or by utilizing heuristic scores or statistical probabilities. However, these approaches have certain drawbacks. This paper proposes to exploit embedded machine learning techniques to help with pruning and disambiguation in robust parsers. An embedded machine learning system is integrated with the heuristic score and the strategy of basing the types of rule symbols upon their correspondence to the domain model. This integration can considerably relieve the reliance of robust parser development on linguistic expert handcrafting. Our experiments show that this integration offers stronger capability in ambiguity resolution, thereby enabling the robust parser to achieve better parsing accuracy.","",""
32,"Himabindu Lakkaraju, Nino Arsov, Osbert Bastani","Robust and Stable Black Box Explanations",2020,"","","","",94,"2022-07-13 10:06:33","","","","",,,,,32,16.00,11,3,2,"As machine learning black boxes are increasingly being deployed in real-world applications, there has been a growing interest in developing post hoc explanations that summarize the behaviors of these black boxes. However, existing algorithms for generating such explanations have been shown to lack stability and robustness to distribution shifts. We propose a novel framework for generating robust and stable explanations of black box models based on adversarial training. Our framework optimizes a minimax objective that aims to construct the highest fidelity explanation with respect to the worst-case over a set of adversarial perturbations. We instantiate this algorithm for explanations in the form of linear models and decision sets by devising the required optimization procedures. To the best of our knowledge, this work makes the first attempt at generating post hoc explanations that are robust to a general class of adversarial perturbations that are of practical interest. Experimental evaluation with real-world and synthetic datasets demonstrates that our approach substantially improves robustness of explanations without sacrificing their fidelity on the original data distribution.","",""
17,"R. Dutta, Ahsan Morshed","Performance Evaluation of South Esk Hydrological Sensor Web: Unsupervised Machine Learning and Semantic Linked Data Approach",2013,"","","","",95,"2022-07-13 10:06:33","","10.1109/JSEN.2013.2264666","","",,,,,17,1.89,9,2,9,"Technological progress has lead the sensor network domain to an era where environmental and agricultural domain applications are completely dependent on hydrological sensor networks. Data from the sensor networks are being used for knowledge management and critical decision support system. The quality of data can, however, vary widely. Existing automated quality assurance approach based on simple threshold rulebase could potentially miss serious errors requiring robust and complex domain knowledge to identify. This paper proposes a linked data concept, unsupervised pattern recognition, and semantic ontologies based dynamic framework to assess the reliability of hydrological sensor network and evaluate the performance of the sensor network. Newly designed framework is used successfully to evaluate the South Esk hydrological sensor web in Tasmania, indicating that domain ontology based linked data approach could be a very useful methodology for quality assurance of the complex data.","",""
5,"Konstantinos Konstantinidis, A. Ramamoorthy","ByzShield: An Efficient and Robust System for Distributed Training",2020,"","","","",96,"2022-07-13 10:06:33","","","","",,,,,5,2.50,3,2,2,"Training of large scale models on distributed clusters is a critical component of the machine learning pipeline. However, this training can easily be made to fail if some workers behave in an adversarial (Byzantine) fashion whereby they return arbitrary results to the parameter server (PS). A plethora of existing papers consider a variety of attack models and propose robust aggregation and/or computational redundancy to alleviate the effects of these attacks. In this work we consider an omniscient attack model where the adversary has full knowledge about the gradient computation assignments of the workers and can choose to attack (up to) any q out of n worker nodes to induce maximal damage. Our redundancy-based method ByzShield leverages the properties of bipartite expander graphs for the assignment of tasks to workers; this helps to effectively mitigate the effect of the Byzantine behavior. Specifically, we demonstrate an upper bound on the worst case fraction of corrupted gradients based on the eigenvalues of our constructions which are based on mutually orthogonal Latin squares and Ramanujan graphs. Our numerical experiments indicate over a 36% reduction on average in the fraction of corrupted gradients compared to the state of the art. Likewise, our experiments on training followed by image classification on the CIFAR-10 dataset show that ByzShield has on average a 20% advantage in accuracy under the most sophisticated attacks. ByzShield also tolerates a much larger fraction of adversarial nodes compared to prior work.","",""
5,"Y. Dehbi, André Henn, G. Gröger, Viktor Stroh, L. Plümer","Robust and fast reconstruction of complex roofs with active sampling from 3D point clouds",2020,"","","","",97,"2022-07-13 10:06:33","","10.1111/tgis.12659","","",,,,,5,2.50,1,5,2,"This article proposes a novel method for the 3D reconstruction of LoD2 buildings from LiDAR data. We propose an active sampling strategy which applies a cascade of filters focusing on promising samples at an early stage, thus avoiding the pitfalls of RANSAC‐based approaches. Filters are based on prior knowledge represented by (nonparametric) density distributions. In our approach samples are pairs of surflets—3D points together with normal vectors derived from a plane approximation of their neighborhood. Surflet pairs provide parameters for model candidates such as azimuth, inclination and ridge height, as well as parameters estimating internal precision and consistency. This provides a ranking of roof model candidates and leads to a small number of promising hypotheses. Building footprints are derived in a preprocessing step using machine learning methods, in particular support vector machines.","",""
3,"Agnese Chiatti, E. Motta, E. Daga, G. Bardaro","Fit to Measure: Reasoning about Sizes for Robust Object Recognition",2020,"","","","",98,"2022-07-13 10:06:33","","","","",,,,,3,1.50,1,4,2,"Service robots can help with many of our daily tasks, especially in those cases where it is inconvenient or unsafe for us to intervene: e.g., under extreme weather conditions or when social distance needs to be maintained. However, before we can successfully delegate complex tasks to robots, we need to enhance their ability to make sense of dynamic, real world environments. In this context, the first prerequisite to improving the Visual Intelligence of a robot is building robust and reliable object recognition systems. While object recognition solutions are traditionally based on Machine Learning methods, augmenting them with knowledge based reasoners has been shown to improve their performance. In particular, based on our prior work on identifying the epistemic requirements of Visual Intelligence, we hypothesise that knowledge of the typical size of objects could significantly improve the accuracy of an object recognition system. To verify this hypothesis, in this paper we present an approach to integrating knowledge about object sizes in a ML based architecture. Our experiments in a real world robotic scenario show that this combined approach ensures a significant performance increase over state of the art Machine Learning methods.","",""
3,"Xingchen Zhao, Anthony Sicilia, D. Minhas, Erin E. O’Connor, H. Aizenstein, W. Klunk, D. Tudorascu, Seong Jae Hwang","Robust White Matter Hyperintensity Segmentation On Unseen Domain",2021,"","","","",99,"2022-07-13 10:06:33","","10.1109/ISBI48211.2021.9434034","","",,,,,3,3.00,0,8,1,"Typical machine learning frameworks heavily rely on an underlying assumption that training and test data follow the same distribution. In medical imaging which increasingly begun acquiring datasets from multiple sites or scanners, this identical distribution assumption often fails to hold due to systematic variability induced by site or scanner dependent factors. Therefore, we cannot simply expect a model trained on a given dataset to consistently work well, or generalize, on a dataset from another distribution. In this work, we address this problem, investigating the application of machine learning models to unseen medical imaging data. Specifically, we consider the challenging case of Domain Generalization (DG) where we train a model without any knowledge about the testing distribution. That is, we train on samples from a set of distributions (sources) and test on samples from a new, unseen distribution (target). We focus on the task of white matter hyperintensity (WMH) prediction using the multi-site WMH Segmentation Challenge dataset and our local in-house dataset. We identify how two mechanically distinct DG approaches, namely domain adversarial learning and mix-up, have theoretical synergy. Then, we show drastic improvements of WMH prediction on an unseen target domain.","",""
28,"E. Dobriban, Hamed Hassani, D. Hong, Alexander Robey","Provable tradeoffs in adversarially robust classification",2020,"","","","",100,"2022-07-13 10:06:33","","","","",,,,,28,14.00,7,4,2,"It is well known that machine learning methods can be vulnerable to adversarially-chosen perturbations of their inputs. Despite significant progress in the area, foundational open problems remain. Here we address several of these key questions. We derive exact and approximate Bayes-optimal robust classifiers for the important setting of two- and three-class Gaussian classification problems with arbitrary imbalance, for $\ell_2$ and $\ell_\infty$ adversaries. In contrast to classical Bayes-optimal classifiers, decisions here cannot be made pointwise and new theoretical approaches are needed. We develop and leverage new tools, including recent breakthroughs from probability theory on robust isoperimetry (Cianci et al, 2011, Mossel and Neeman 2015), which, to our knowledge, have not yet been used in the area. Our results reveal tradeoffs between standard and robust accuracy that grow when data is imbalanced. We also show further foundational results, including an analysis of the loss landscape, classification calibration for convex losses in certain models, and finite sample rates for the robust risk.","",""
16,"Ramyar Saeedi, S. Norgaard, A. Gebremedhin","A closed-loop deep learning architecture for robust activity recognition using wearable sensors",2017,"","","","",101,"2022-07-13 10:06:33","","10.1109/BigData.2017.8257960","","",,,,,16,3.20,5,3,5,"Human activity recognition (HAR) plays a central role in health-care, fitness and sport applications because of its potential to enable context-aware human monitoring. With the increase in popularity of wearable devices, we are witnessing a large influx in availability of human activity data. For effective analysis and interpretation of these heterogeneous and high-volume streaming data, we need powerful algorithms. In particular, there is a strong need for developing algorithms for robust classification of human activity data that specifically address challenges associated with dynamic environments (e.g. different users, signal heterogeneity). We use the term robust here in two, orthogonal senses: 1) leveraging related data in such a way that knowledge is transferred to a new context; and 2) actively reconfiguring machine learning algorithms such that they can be applied in a new context. In this paper, we propose an architecture that combines an active learning approach with a novel deep network. Our deep neural network exploits both Convolutional and Long Short-Term Memory (LSTM) layers in order to learn hierarchical representation of features and capture time dependencies from raw-data. The active learning process allows us to choose the best instances for fine-tuning the deep network to the new setting in which the system operates (i.e. a new subject). We demonstrate the efficacy of the architecture using real data of human activity. We show that the accuracy of activity recognition reaches over 90% by annotating less than 20% of unlabeled data.","",""
81,"A. Urieli","Robust French syntax analysis: reconciling statistical methods and linguistic knowledge in the Talismane toolkit. (Analyse syntaxique robuste du français : concilier méthodes statistiques et connaissances linguistiques dans l'outil Talismane)",2013,"","","","",102,"2022-07-13 10:06:33","","","","",,,,,81,9.00,81,1,9,"In this thesis we explore robust statistical syntax analysis for French. Our main concern is to explore methods whereby the linguist can inject linguistic knowledge and/or resources into the robust statistical engine in order to improve results for specific phenomena. We first explore the dependency annotation schema for French, concentrating on certain phenomena. Next, we look into the various algorithms capable of producing this annotation, and in particular on the transition-based parsing algorithm used in the rest of this thesis. After exploring supervised machine learning algorithms for NLP classification problems, we present the Talismane toolkit for syntax analysis, built within the framework of this thesis, including four statistical modules - sentence boundary detection, tokenisation, pos-tagging and parsing - as well as the various linguistic resources used for the baseline model, including corpora, lexicons and feature sets. Our first experiments attempt various machine learning configurations in order to identify the best baseline. We then look into improvements made possible by beam search and beam propagation. Finally, we present a series of experiments aimed at correcting errors related to specific linguistic phenomena, using targeted features. One our innovation is the introduction of rules that can impose or prohibit certain decisions locally, thus bypassing the statistical model. We explore the usage of rules for errors that the features are unable to correct. Finally, we look into the enhancement of targeted features by large scale linguistic resources, and in particular a semi-supervised approach using a distributional semantic resource.","",""
18,"Rui Gao","Finite-Sample Guarantees for Wasserstein Distributionally Robust Optimization: Breaking the Curse of Dimensionality",2020,"","","","",103,"2022-07-13 10:06:33","","","","",,,,,18,9.00,18,1,2,"Wasserstein distributionally robust optimization (DRO) aims to find robust and generalizable solutions by hedging against data perturbations in Wasserstein distance. Despite its recent empirical success in operations research and machine learning, existing performance guarantees for generic loss functions are either overly conservative due to the curse of dimensionality, or plausible only in large sample asymptotics. In this paper, we develop a non-asymptotic framework for analyzing the out-of-sample performance for Wasserstein robust learning and the generalization bound for its related Lipschitz and gradient regularization problems. To the best of our knowledge, this gives the first finite-sample guarantee for generic Wasserstein DRO problems without suffering from the curse of dimensionality. Our results highlight the bias-variation trade-off intrinsic in the Wasserstein DRO, which automatically balances between the empirical mean of the loss and the variation of the loss, measured by the Lipschitz norm or the gradient norm of the loss. Our analysis is based on two novel methodological developments which are of independent interest: 1) a new concentration inequality characterizing the decay rate of large deviation probabilities by the variation of the loss and, 2) a localized Rademacher complexity theory based on the variation of the loss.","",""
37,"Liu Yang, L. Jing, M. Ng","Robust and Non-Negative Collective Matrix Factorization for Text-to-Image Transfer Learning",2015,"","","","",104,"2022-07-13 10:06:33","","10.1109/TIP.2015.2465157","","",,,,,37,5.29,12,3,7,"Heterogeneous transfer learning has recently gained much attention as a new machine learning paradigm in which the knowledge can be transferred from source domains to target domains in different feature spaces. Existing works usually assume that source domains can provide accurate and useful knowledge to be transferred to target domains for learning. In practice, there may be noise appearing in given source (text) and target (image) domains data, and thus, the performance of transfer learning can be seriously degraded. In this paper, we propose a robust and non-negative collective matrix factorization model to handle noise in text-to-image transfer learning, and make a reliable bridge to transfer accurate and useful knowledge from the text domain to the image domain. The proposed matrix factorization model can be solved by an efficient iterative method, and the convergence of the iterative method can be shown. Extensive experiments on real data sets suggest that the proposed model is able to effectively perform transfer learning in noisy text and image domains, and it is superior to the popular existing methods for text-to-image transfer learning.","",""
80,"Zhiqing Sun, Shikhar Vashishth, Soumya Sanyal, P. Talukdar, Yiming Yang","A Re-evaluation of Knowledge Graph Completion Methods",2019,"","","","",105,"2022-07-13 10:06:33","","10.18653/v1/2020.acl-main.489","","",,,,,80,26.67,16,5,3,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available.","",""
35,"I. Bruha","From machine learning to knowledge discovery: Survey of preprocessing and postprocessing",2000,"","","","",106,"2022-07-13 10:06:33","","10.3233/IDA-2000-43-413","","",,,,,35,1.59,35,1,22,"Knowledge Discovery in Databases (KDD) has become a very attractive discipline both for research and industry within last few years. Its goal is to extract pieces of knowledge or `patterns' from usually very large databases. It portrays a robust sequence of procedures or steps that have to be carried out to derive reasonable and understandable results. One of its components symbolizes an inductive process that induces the above pieces of knowledge; usually it is Machine Learning (ML). However, most of the machine learning algorithms require perfect data in a reasonable format. Therefore, some preprocessing routines as well as postprocessing ones should fill the entire chain of data processing.    This paper overviews and discusses the knowledge discovery process and its methodology as a series of several steps which include machine learning, preprocessing of data, and postprocessing of the results induced.","",""
12,"Maximilian Nickel, Volker Tresp, H. Kriegel","S calable Machine Learning for Linked Data",2012,"","","","",107,"2022-07-13 10:06:33","","","","",,,,,12,1.20,4,3,10,"Vast amounts of structured information have been published in the Semantic Web’s Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD’s size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD’s data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize nondeterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO 2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 · 10 14 possible triples in the YAGO 2 core ontology.","",""
3,"Yunhua Hu, Q. Zheng, H. Bai, Xia Sun, Haifeng Dang","Taxonomy Building and Machine Learning Based Automatic Classification for Knowledge-Oriented Chinese Questions",2005,"","","","",108,"2022-07-13 10:06:33","","10.1007/11538059_51","","",,,,,3,0.18,1,5,17,"","",""
66,"David J. Miller, Zhen Xiang, G. Kesidis","Adversarial Learning Targeting Deep Neural Network Classification: A Comprehensive Review of Defenses Against Attacks",2020,"","","","",109,"2022-07-13 10:06:33","","10.1109/JPROC.2020.2970615","","",,,,,66,33.00,22,3,2,"With wide deployment of machine learning (ML)-based systems for a variety of applications including medical, military, automotive, genomic, multimedia, and social networking, there is great potential for damage from adversarial learning (AL) attacks. In this article, we provide a contemporary survey of AL, focused particularly on defenses against attacks on deep neural network classifiers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), backdoor DP, and reverse engineering (RE) attacks and particularly defenses against the same. In so doing, we distinguish robust classification from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis. We also consider several scenarios for detecting backdoors. We provide a technical assessment for reviewed works, including identifying any issues/limitations, required hyperparameters, needed computational complexity, as well as the performance measures evaluated and the obtained quality. We then delve deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: robust classification versus AD as a defense strategy; the belief that attack success increases with attack strength, which ignores susceptibility to AD; small perturbations for TTE attacks: a fallacy or a requirement; validity of the universal assumption that a TTE attacker knows the ground-truth class for the example to be attacked; black, gray, or white-box attacks as the standard for defense evaluation; and susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The article concludes with a discussion of continuing research directions, including the supreme challenge of detecting attacks whose goal is not to alter classification decisions, but rather simply to embed, without detection, “fake news” or other false content.","",""
12,"K. Jablonka, D. Ongari, S. M. Moosavi, B. Smit","Using collective knowledge to assign oxidation states of metal cations in metal–organic frameworks",2021,"","","","",110,"2022-07-13 10:06:33","","10.1038/s41557-021-00717-y","","",,,,,12,12.00,3,4,1,"","",""
11,"S. Tripathi, David Muhr, Manuel Brunner, F. Emmert‐Streib, H. Jodlbauer, M. Dehmer","Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing",2020,"","","","",111,"2022-07-13 10:06:33","","10.3389/frai.2021.576892","","",,,,,11,5.50,2,6,2,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.","",""
10,"Junyu Gao, Tianzhu Zhang, Changsheng Xu","Learning to Model Relationships for Zero-Shot Video Classification",2020,"","","","",112,"2022-07-13 10:06:33","","10.1109/tpami.2020.2985708","","",,,,,10,5.00,3,3,2,"With the explosive growth of video categories, zero-shot learning (ZSL) in video classification has become a promising research direction in pattern analysis and machine learning. Based on some auxiliary information such as word embeddings and attributes, the key to a robust ZSL method is to transfer the learned knowledge from seen classes to unseen classes, which requires relationship modeling between these concepts (e.g., categories and attributes). However, most existing approaches ignore to model the explicit relationships in an end-to-end manner, resulting in low effectiveness of knowledge transfer. To tackle this problem, we reconsider the video ZSL task as a task-driven message passing process to jointly enjoy several merits including alleviated heterogeneity gap, low domain shift, and robust temporal modeling. Specifically, we propose a prototype-sample GNN (PS-GNN) consisting of a prototype branch and a sample branch to directly and adaptively model all the relationships between category-attribute, category-category, and attribute-attribute. The prototype branch aims to learn robust representations of video categories, which takes as input a set of word-embedding vectors corresponding to the concepts. The sample branch is designed to generate features of a video sample by leveraging its object semantics. With the co-adaption and cooperation between both branches, a unified and robust ZSL framework is achieved. Extensive experiments strongly evidence that PS-GNN obtains favorable performance on five popular video benchmarks consistently.","",""
11,"Nami Ashizawa, Naoto Yanai, Jason Paul Cruz, Shingo Okamura","Eth2Vec: Learning Contract-Wide Code Representations for Vulnerability Detection on Ethereum Smart Contracts",2021,"","","","",113,"2022-07-13 10:06:33","","10.1145/3457337.3457841","","",,,,,11,11.00,3,4,1,"Ethereum smart contracts are programs that run on the Ethereum blockchain, and many smart contract vulnerabilities have been discovered in the past decade. Many security analysis tools have been created to detect such vulnerabilities, but their performance decreases drastically when codes to be analyzed are being rewritten. In this paper, we propose Eth2Vec, a machine-learning-based static analysis tool for vulnerability detection in smart contracts. It is also robust against code rewrites, i.e., it can detect vulnerabilities even in rewritten codes. Existing machine-learning-based static analysis tools for vulnerability detection need features, which analysts create manually, as inputs. In contrast, Eth2Vec automatically learns features of vulnerable Ethereum Virtual Machine (EVM) bytecodes with tacit knowledge through a neural network for natural language processing. Therefore, Eth2Vec can detect vulnerabilities in smart contracts by comparing the code similarity between target EVM bytecodes and the EVM bytecodes it already learned. We conducted experiments with existing open databases, such as Etherscan, and our results show that Eth2Vec outperforms a recent model based on support vector machine in terms of well-known metrics, i.e., precision, recall, and F1-score.","",""
55,"Zan Gao, Yinming Li, S. Wan","Exploring Deep Learning for View-Based 3D Model Retrieval",2020,"","","","",114,"2022-07-13 10:06:33","","10.1145/3377876","","",,,,,55,27.50,18,3,2,"In recent years, view-based 3D model retrieval has become one of the research focuses in the field of computer vision and machine learning. In fact, the 3D model retrieval algorithm consists of feature extraction and similarity measurement, and the robust features play a decisive role in the similarity measurement. Although deep learning has achieved comprehensive success in the field of computer vision, deep learning features are used for 3D model retrieval only in a small number of works. To the best of our knowledge, there is no benchmark to evaluate these deep learning features. To tackle this problem, in this work we systematically evaluate the performance of deep learning features in view-based 3D model retrieval on four popular datasets (ETH, NTU60, PSB, and MVRED) by different kinds of similarity measure methods. In detail, the performance of hand-crafted features and deep learning features are compared, and then the robustness of deep learning features is assessed. Finally, the difference between single-view deep learning features and multi-view deep learning features is also evaluated. By quantitatively analyzing the performances on different datasets, it is clear that these deep learning features can consistently outperform all of the hand-crafted features, and they are also more robust than the hand-crafted features when different degrees of noise are added into the image. The exploration of latent relationships among different views in multi-view deep learning network architectures shows that the performance of multi-view deep learning outperforms that of single-view deep learning features with low computational complexity.","",""
8,"S. Boyer, K. Veeramachaneni","Robust Predictive Models on MOOCs : Transferring Knowledge across Courses",2016,"","","","",115,"2022-07-13 10:06:33","","","","",,,,,8,1.33,4,2,6,"As MOOCs become a major player in modern education, questions about how to improve their effectiveness and reach are of increasing importance. If machine learning and predictive analytics techniques promise to help teachers and MOOC providers customize the learning experience for students, differences between platforms, courses and iterations pose specific challenges. In this paper, we develop a framework to define classification problems across courses, provide proof that ensembling methods allow for the development of high-performing predictive models, and show that these techniques can be used across platforms, as well as across courses. We thus build a universal framework to deploy predictive models on MOOCs and demonstrate our case on the dropout prediction problem.","",""
38,"Qi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun, Hao Li","Robust Optimization over Multiple Domains",2018,"","","","",116,"2022-07-13 10:06:33","","10.1609/aaai.v33i01.33014739","","",,,,,38,9.50,6,6,4,"In this work, we study the problem of learning a single model for multiple domains. Unlike the conventional machine learning scenario where each domain can have the corresponding model, multiple domains (i.e., applications/users) may share the same machine learning model due to maintenance loads in cloud computing services. For example, a digit-recognition model should be applicable to hand-written digits, house numbers, car plates, etc. Therefore, an ideal model for cloud computing has to perform well at each applicable domain. To address this new challenge from cloud computing, we develop a framework of robust optimization over multiple domains. In lieu of minimizing the empirical risk, we aim to learn a model optimized to the adversarial distribution over multiple domains. Hence, we propose to learn the model and the adversarial distribution simultaneously with the stochastic algorithm for efficiency. Theoretically, we analyze the convergence rate for convex and non-convex models. To our best knowledge, we first study the convergence rate of learning a robust non-convex model with a practical algorithm. Furthermore, we demonstrate that the robustness of the framework and the convergence rate can be further enhanced by appropriate regularizers over the adversarial distribution. The empirical study on real-world fine-grained visual categorization and digits recognition tasks verifies the effectiveness and efficiency of the proposed framework.","",""
3,"Jihun Hamm","Machine vs Machine: Defending Classifiers Against Learning-based Adversarial Attacks",2017,"","","","",117,"2022-07-13 10:06:33","","","","",,,,,3,0.60,3,1,5,"Recently, researchers have discovered that the state-of-the-art object classifiers can be fooled easily by small perturbations in the input unnoticeable to human eyes. Several methods were proposed to craft adversarial examples, as well as methods of robustifying the classifier against such examples. An attacker with the knowledge of the classifier parameters can generate strong adversarial patterns. Conversely, a classifier with the knowledge of such patterns can be trained to be robust to them. The cat-and-mouse game nature of the attacks and the defenses raises the question of the presence of an equilibrium in the dynamic. In this paper, we propose a game framework to formulate the interaction of attacks and defenses and present the natural notion of the best worst-case defense and attack. We propose simple algorithms to numerically find those solutions motivated by sensitivity penalization. In addition, we show the potentials of learning-based attacks, and present the close relationship between the adversarial attack and the privacy attack problems. The results are demonstrated with MNIST and CIFAR-10 datasets.","",""
9,"Syed Ashiqur Rahman, Peter Giacobbi, L. Pyles, C. Mullett, Gianfranco Doretto, D. Adjeroh","Deep learning for biological age estimation",2020,"","","","",118,"2022-07-13 10:06:33","","10.1093/bib/bbaa021","","",,,,,9,4.50,2,6,2,"Modern machine learning techniques (such as deep learning) offer immense opportunities in the field of human biological aging research. Aging is a complex process, experienced by all living organisms. While traditional machine learning and data mining approaches are still popular in aging research, they typically need feature engineering or feature extraction for robust performance. Explicit feature engineering represents a major challenge, as it requires significant domain knowledge. The latest advances in deep learning provide a paradigm shift in eliciting meaningful knowledge from complex data without performing explicit feature engineering. In this article, we review the recent literature on applying deep learning in biological age estimation. We consider the current data modalities that have been used to study aging and the deep learning architectures that have been applied. We identify four broad classes of measures to quantify the performance of algorithms for biological age estimation and based on these evaluate the current approaches. The paper concludes with a brief discussion on possible future directions in biological aging research using deep learning. This study has significant potentials for improving our understanding of the health status of individuals, for instance, based on their physical activities, blood samples and body shapes. Thus, the results of the study could have implications in different health care settings, from palliative care to public health.","",""
23,"M. Lerasle, Z. Szabó, Guillaume Lecué, Gaspar Massiot, É. Moulines","MONK - Outlier-Robust Mean Embedding Estimation by Median-of-Means",2018,"","","","",119,"2022-07-13 10:06:33","","","","",,,,,23,5.75,5,5,4,"Mean embeddings provide an extremely flexible and powerful tool in machine learning and statistics to represent probability distributions and define a semi-metric (MMD, maximum mean discrepancy; also called N-distance or energy distance), with numerous successful applications. The representation is constructed as the expectation of the feature map defined by a kernel. As a mean, its classical empirical estimator, however, can be arbitrary severely affected even by a single outlier in case of unbounded features. To the best of our knowledge, unfortunately even the consistency of the existing few techniques trying to alleviate this serious sensitivity bottleneck is unknown. In this paper, we show how the recently emerged principle of median-of-means can be used to design estimators for kernel mean embedding and MMD with excessive resistance properties to outliers, and optimal sub-Gaussian deviation bounds under mild assumptions.","",""
5,"Niloofar Bayat, Weston J Jackson, Derrick Liu","Deep Learning for Network Traffic Classification",2021,"","","","",120,"2022-07-13 10:06:33","","","","",,,,,5,5.00,2,3,1,"Monitoring network trafﬁc to identify content, services, and applications is an active research topic in network trafﬁc control systems. While modern ﬁrewalls provide the capa-bility to decrypt packets, this is not appealing for privacy advocates. Hence, identifying any information from encrypted trafﬁc is a challenging task. Nonetheless, previous work has identiﬁed machine learning methods that may enable application and service identiﬁcation. The process involves high level feature extraction from network packet data then training a robust machine learning classiﬁer for trafﬁc identiﬁcation. We propose a classiﬁcation technique using an ensemble of deep learning architectures on packet, payload, and inter-arrival time sequences. To our knowledge, this is the ﬁrst time such deep learning architectures have been applied to the Server Name Indication (SNI) classiﬁcation problem. Our ensemble model beats the state of the art machine learning methods and our up-to-date model can be found on github: https://github.com/niloofarbayat/ NetworkClassification","",""
15,"Xi Chen, A. Krishnamurthy, Yining Wang","Robust Dynamic Assortment Optimization in the Presence of Outlier Customers",2019,"","","","",121,"2022-07-13 10:06:33","","","","",,,,,15,5.00,5,3,3,"We consider the dynamic assortment optimization problem under the multinomial logit model (MNL) with unknown utility parameters. The main question investigated in this paper is model mis-specification under the $\varepsilon$-contamination model, which is a fundamental model in robust statistics and machine learning. In particular, throughout a selling horizon of length $T$, we assume that customers make purchases according to a well specified underlying multinomial logit choice model in a ($1-\varepsilon$)-fraction of the time periods, and make arbitrary purchasing decisions instead in the remaining $\varepsilon$-fraction of the time periods. In this model, we develop a new robust online assortment optimization policy via an active elimination strategy. We establish both upper and lower bounds on the regret, and show that our policy is optimal up to logarithmic factor in T when the assortment capacity is constant. Furthermore, we develop a fully adaptive policy that does not require any prior knowledge of the contamination parameter $\varepsilon$. Our simulation study shows that our policy outperforms the existing policies based on upper confidence bounds (UCB) and Thompson sampling.","",""
10,"Zhijian Liu, Hao Li, Xindong Tang, Xinyu Zhang, Fan Lin, Kewei Cheng","Extreme learning machine: a new alternative for measuring heat collection rate and heat loss coefficient of water-in-glass evacuated tube solar water heaters",2016,"","","","",122,"2022-07-13 10:06:33","","10.1186/s40064-016-2242-1","","",,,,,10,1.67,2,6,6,"","",""
60,"Hang Yan, Qi Shan, Yasutaka Furukawa","RIDI: Robust IMU Double Integration",2017,"","","","",123,"2022-07-13 10:06:33","","10.1007/978-3-030-01261-8_38","","",,,,,60,12.00,20,3,5,"","",""
63,"Nicolas Gillis, S. Vavasis","On the Complexity of Robust PCA and ℓ1-norm Low-Rank Matrix Approximation",2015,"","","","",124,"2022-07-13 10:06:33","","10.1287/moor.2017.0895","","",,,,,63,9.00,32,2,7,"The low-rank matrix approximation problem with respect to the component-wise $\ell_1$-norm ($\ell_1$-LRA), which is closely related to robust principal component analysis (PCA), has become a very popular tool in data mining and machine learning. Robust PCA aims at recovering a low-rank matrix that was perturbed with sparse noise, with applications for example in foreground-background video separation. Although $\ell_1$-LRA is strongly believed to be NP-hard, there is, to the best of our knowledge, no formal proof of this fact. In this paper, we prove that $\ell_1$-LRA is NP-hard, already in the rank-one case, using a reduction from MAX CUT. Our derivations draw interesting connections between $\ell_1$-LRA and several other well-known problems, namely, robust PCA, $\ell_0$-LRA, binary matrix factorization, a particular densest bipartite subgraph problem, the computation of the cut norm of $\{-1,+1\}$ matrices, and the discrete basis problem, which we all prove to be NP-hard.","",""
392,"Dingwen Zhang, Deyu Meng, Junwei Han","Co-Saliency Detection via a Self-Paced Multiple-Instance Learning Framework",2017,"","","","",125,"2022-07-13 10:06:33","","10.1109/TPAMI.2016.2567393","","",,,,,392,78.40,131,3,5,"As an interesting and emerging topic, co-saliency detection aims at simultaneously extracting common salient objects from a group of images. On one hand, traditional co-saliency detection approaches rely heavily on human knowledge for designing hand-crafted metrics to possibly reflect the faithful properties of the co-salient regions. Such strategies, however, always suffer from poor generalization capability to flexibly adapt various scenarios in real applications. On the other hand, most current methods pursue co-saliency detection in unsupervised fashions. This, however, tends to weaken their performance in real complex scenarios because they are lack of robust learning mechanism to make full use of the weak labels of each image. To alleviate these two problems, this paper proposes a new SP-MIL framework for co-saliency detection, which integrates both multiple instance learning (MIL) and self-paced learning (SPL) into a unified learning framework. Specifically, for the first problem, we formulate the co-saliency detection problem as a MIL paradigm to learn the discriminative classifiers to detect the co-saliency object in the “instance-level”. The formulated MIL component facilitates our method capable of automatically producing the proper metrics to measure the intra-image contrast and the inter-image consistency for detecting co-saliency in a purely self-learning way. For the second problem, the embedded SPL paradigm is able to alleviate the data ambiguity under the weak supervision of co-saliency detection and guide a robust learning manner in complex scenarios. Experiments on benchmark datasets together with multiple extended computer vision applications demonstrate the superiority of the proposed framework beyond the state-of-the-arts.","",""
26,"D. Cangelosi, F. Blengio, R. Versteeg, A. Eggert, A. Garaventa, C. Gambini, M. Conte, A. Eva, M. Muselli, L. Varesio","Logic Learning Machine creates explicit and stable rules stratifying neuroblastoma patients",2013,"","","","",126,"2022-07-13 10:06:33","","10.1186/1471-2105-14-S7-S12","","",,,,,26,2.89,3,10,9,"","",""
2,"Lei Zhang, David Zhang","Robust Visual Knowledge Transfer via EDA",2015,"","","","",127,"2022-07-13 10:06:33","","","","",,,,,2,0.29,1,2,7,"We address the problem of visual knowledge adaptation by leveraging labeled patterns from source domain and a very limited number of labeled instances in target domain to learn a robust classifier for visual categorization. This paper proposes a new extreme learning machine based cross-domain network learning framework, that is called Extreme Learning Machine (ELM) based Domain Adaptation (EDA). It allows us to learn a category transformation and an ELM classifier with random projection by minimizing the l_(2,1)-norm of the network output weights and the learning error simultaneously. The unlabeled target data, as useful knowledge, is also integrated as a fidelity term to guarantee the stability during cross domain learning. It minimizes the matching error between the learned classifier and a base classifier, such that many existing classifiers can be readily incorporated as base classifiers. The network output weights cannot only be analytically determined, but also transferrable. Additionally, a manifold regularization with Laplacian graph is incorporated, such that it is beneficial to semi-supervised learning. Extensively, we also propose a model of multiple views, referred as MvEDA. Experiments on benchmark visual datasets for video event recognition and object recognition, demonstrate that our EDA methods outperform existing cross-domain learning methods.","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",128,"2022-07-13 10:06:33","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
14,"Yanshan Xiao, Bo Liu, Philip S. Yu, Z. Hao","A robust one-class transfer learning method with uncertain data",2015,"","","","",129,"2022-07-13 10:06:33","","10.1007/s10115-014-0765-8","","",,,,,14,2.00,4,4,7,"","",""
8,"Brandon M. Booth, Tiantian Feng, Abhishek Jangalwa, Shrikanth S. Narayanan","Toward Robust Interpretable Human Movement Pattern Analysis in a Workplace Setting",2019,"","","","",130,"2022-07-13 10:06:33","","10.1109/ICASSP.2019.8683730","","",,,,,8,2.67,2,4,3,"Gaining a better understanding of how people move about and interact with their environment is an important piece of understanding human behavior. Careful analysis of individuals’ deviations or variations in movement over time can provide an awareness about changes to their physical or mental state and may be helpful in tracking performance and well-being especially in workplace settings. We propose a technique for clustering and discovering patterns in human movement data by extracting motifs from the time series of durations where participants linger at different locations. Using a data set of over 200 participants moving around a hospital for ten weeks, we show this technique intuitively captures local temporal relationships between hospital rooms and also clusters them in a fashion consistent with the room type labels (e.g. lounge, break room, etc.) without using prior knowledge. Machine learning features derived from these clusters are empirically shown to provide information similar to features attained using domain knowledge of the room type labels directly when predicting mental wellness from self-reports.","",""
6,"Prithwish Chakraborty, Faisal Farooq","A Robust Framework for Accelerated Outcome-driven Risk Factor Identification from EHR",2019,"","","","",131,"2022-07-13 10:06:33","","10.1145/3292500.3330718","","",,,,,6,2.00,3,2,3,"Electronic Health Records (EHR) containing longitudinal information about millions of patient lives are increasingly being utilized by organizations across the healthcare spectrum. Studies on EHR data have enabled real world applications like understanding of disease progression, outcomes analysis, and comparative effectiveness research. However, often every study is independently commissioned, data is gathered by surveys or specifically purchased per study by a long and often painful process. This is followed by an arduous repetitive cycle of analysis, model building, and generation of insights. This process can take anywhere between 1 - 3 years. In this paper, we present a robust end-to-end machine learning based SaaS system to perform analysis on a very large EHR dataset. The framework consists of a proprietary EHR datamart spanning ~55 million patient lives in USA and over ~20 billion data points. To the best of our knowledge, this framework is the largest in the industry to analyze medical records at this scale, with such efficacy and ease. We developed an end-to-end ML framework with carefully chosen components to support EHR analysis at scale and suitable for further downstream clinical analysis. Specifically, it consists of a ridge regularized Survival Support Vector Machine (SSVM) with a clinical kernel, coupled with Chi-square distance-based feature selection, to uncover relevant risk factors by exploiting the weak correlations in EHR. Our results on multiple real use cases indicate that the framework identifies relevant factors effectively without expert supervision. The framework is stable, generalizable over outcomes, and also found to contribute to better out-of-bound prediction over known expert features. Importantly, the ML methodologies used are interpretable which is critical for acceptance of our system in the targeted user base. With the system being operational, all of these studies were completed within a time frame of 3-4 weeks compared to the industry standard 12-36 months. As such our system can accelerate analysis and discovery, result in better ROI due to reduced investments as well as quicker turn around of studies.","",""
14,"Li-juan Su, Min Yao","Extreme learning machine with multiple kernels",2013,"","","","",132,"2022-07-13 10:06:33","","10.1109/ICCA.2013.6565148","","",,,,,14,1.56,7,2,9,"Recently a novel learning algorithm called extreme learning machine (ELM) was proposed for efficiently training single-hidden layer feedforward neural networks (SLFNs). Compared with other traditional gradient-descent-based learning algorithms, ELM has shown promising results because it chooses weights and biases of hidden nodes randomly and obtains the output weights and biases analytically. In most cases, ELM is fast and presents good generalization, but we find that the stability and generalization performance still can be improved. In this paper, we propose a hybrid model which combines the advantage of ELM and the advantage of Bayesian “sum of kernels” model, named Extreme Learning Machine with Multiple Kernels (MK-ELM). This method optimizes the kernel function using a weighted sum of kernel functions by a prior knowledge. Experimental results show that this approach is able to make neural networks more robust and generates better generalization performance for both regression and classification applications.","",""
150,"Dipendra Jha, Logan T. Ward, Arindam Paul, W. Liao, A. Choudhary, C. Wolverton, Ankit Agrawal","ElemNet: Deep Learning the Chemistry of Materials From Only Elemental Composition",2018,"","","","",133,"2022-07-13 10:06:33","","10.1038/s41598-018-35934-y","","",,,,,150,37.50,21,7,4,"","",""
46,"Shudong Huang, Hongjun Wang, Tao Li, Tianrui Li, Zenglin Xu","Robust graph regularized nonnegative matrix factorization for clustering",2018,"","","","",134,"2022-07-13 10:06:33","","10.1007/s10618-017-0543-9","","",,,,,46,11.50,9,5,4,"","",""
9,"Chun-Nan Hsu","Learning effective and robust knowledge for semantic query optimization",1996,"","","","",135,"2022-07-13 10:06:33","","","","",,,,,9,0.35,9,1,26,"Optimizing queries to heterogeneous, distributed multidatabases is an important problem. Due to the query complexity and the heterogeneity of databases, it is difficult for conventional optimization approaches to solve the problem satisfactorily. Semantic Query Optimization (SQO) can complement conventional approaches to overcome the heterogeneity and considerably reduce redundant data transmission. SQO optimizers use rules about data regularities to yield significant cost reduction. However, hand coding useful rules for SQO is impracticable. This dissertation presents a machine learning approach to this knowledge bottleneck problem.  Unlike search control rules or classification rules studied extensively in machine learning, two roughly correlated measures must be maximized in the learning of high utility rules for SQO. The first measure is the effectiveness. Effective rules must be applicable in many different queries and yield high cost reduction. The second measure is the robustness against database changes. That is, they must remain valid regardless of database changes. This dissertation presents a new inductive learning approach to learning effective and robust rules. The learning approach considers both applicability and cost-reduction in rule induction to learn effective rules. The learned rules are robust because the learner is able to guide the learning for robust rules with an approach to estimating the probabilities of database changes.  To evaluate the utility of the learning approach, this dissertation also describes an extended SQO approach for query plans that retrieve data from heterogeneous multidatabases. The experimental results show that the learned rules produce significant savings while being robust against database changes. The learning and optimization approaches provide a complete solution for multidatabase information systems to effectively optimize queries using SQO that does not require an expensive coding effort to produce useful rules.","",""
67,"Dingjiang Huang, Junlong Zhou, B. Li, S. Hoi, Shuigeng Zhou","Robust Median Reversion Strategy for Online Portfolio Selection",2013,"","","","",136,"2022-07-13 10:06:33","","10.1109/TKDE.2016.2563433","","",,,,,67,7.44,13,5,9,"Online portfolio selection has attracted increasing attention from data mining and machine learning communities in recent years. An important theory in financial markets is mean reversion, which plays a critical role in some state-of-the-art portfolio selection strategies. Although existing mean reversion strategies have been shown to achieve good empirical performance on certain datasets, they seldom carefully deal with noise and outliers in the data, leading to suboptimal portfolios, and consequently yielding poor performance in practice. In this paper, we propose to exploit the reversion phenomenon by using robust <inline-formula><tex-math notation=""LaTeX""> $L_1$</tex-math><alternatives><inline-graphic xlink:type=""simple"" xlink:href=""huang-ieq1-2563433.gif""/></alternatives> </inline-formula>-median estimators, and design a novel online portfolio selection strategy named “Robust Median Reversion” (RMR), which constructs optimal portfolios based on the improved reversion estimator. We examine the performance of the proposed algorithms on various real markets with extensive experiments. Empirical results show that RMR can overcome the drawbacks of existing mean reversion algorithms and achieve significantly better results. Finally, RMR runs in linear time, and thus is suitable for large-scale real-time algorithmic trading applications.","",""
5,"N. Doan, W. Polifke, L. Magri","Learning Hidden States in a Chaotic System: A Physics-Informed Echo State Network Approach",2020,"","","","",137,"2022-07-13 10:06:33","","10.1007/978-3-030-50433-5_9","","",,,,,5,2.50,2,3,2,"","",""
10,"R. Devidze, Farnam Mansouri, Luis Haug, Yuxin Chen, A. Singla","Understanding the Power and Limitations of Teaching with Imperfect Knowledge",2020,"","","","",138,"2022-07-13 10:06:33","","10.24963/ijcai.2020/363","","",,,,,10,5.00,2,5,2,"Machine teaching studies the interaction between a teacher and a student/learner where the teacher selects training examples for the learner to learn a specific task. The typical assumption is that the teacher has perfect knowledge of the task---this knowledge comprises knowing the desired learning target, having the exact task representation used by the learner, and knowing the parameters capturing the learning dynamics of the learner. Inspired by real-world applications of machine teaching in education, we consider the setting where teacher's knowledge is limited and noisy, and the key research question we study is the following: When does a teacher succeed or fail in effectively teaching a learner using its imperfect knowledge? We answer this question by showing connections to how imperfect knowledge affects the teacher's solution of the corresponding machine teaching problem when constructing optimal teaching sets. Our results have important implications for designing robust teaching algorithms for real-world applications.","",""
24,"Sanaz Nikfalazar, C. Yeh, S. Bedingfield, H. Khorshidi","Missing data imputation using decision trees and fuzzy clustering with iterative learning",2019,"","","","",139,"2022-07-13 10:06:33","","10.1007/s10115-019-01427-1","","",,,,,24,8.00,6,4,3,"","",""
4,"Yonggang Cao, Zuofeng Li, Feifan Liu, S. Agarwal, Qing Zhang, Hong Yu","An IR-Aided Machine Learning Framework for the BioCreative II.5 Challenge",2010,"","","","",140,"2022-07-13 10:06:33","","10.1109/TCBB.2010.56","","",,,,,4,0.33,1,6,12,"The team at the University of Wisconsin-Milwaukee developed an information retrieval and machine learning framework. Our framework requires only the standardized training data and depends upon minimal external knowledge resources and minimal parsing. Within the framework, we built our text mining systems and participated for the first time in all three BioCreative II.5 Challenge tasks. The results show that our systems performed among the top five teams for raw F1 scores in all three tasks and came in third place for the homonym ortholog F1 scores for the INT task. The results demonstrated that our IR-based framework is efficient, robust, and potentially scalable.","",""
39,"Hamdi Altaheri, M. Alsulaiman, G. Muhammad","Date Fruit Classification for Robotic Harvesting in a Natural Environment Using Deep Learning",2019,"","","","",141,"2022-07-13 10:06:33","","10.1109/ACCESS.2019.2936536","","",,,,,39,13.00,13,3,3,"An accurate vision system to classify and analyze fruits in real time is critical for harvesting robots to be cost-effective and efficient. However, practical success in this area is still limited, and to the best of our knowledge, there is no research in the area of machine vision for date fruits in an orchard environment. In this work, we propose an efficient machine vision framework for date fruit harvesting robots. The framework consists of three classification models used to classify date fruit images in real time according to their type, maturity, and harvesting decision. In the classification models, deep convolutional neural networks are utilized with transfer learning and fine-tuning on pre-trained models. To build a robust vision system, we create a rich image dataset of date fruit bunches in an orchard that consists of more than 8000 images of five date types in different pre-maturity and maturity stages. The dataset has a large degree of variations that reflects the challenges in the date orchard environment including variations in angles, scales, illumination conditions, and date bunches covered by bags. The proposed date fruit classification models achieve accuracies of 99.01%, 97.25%, and 98.59% with classification times of 20.6, 20.7, and 35.9 msec for the type, maturity, and harvesting decision classification tasks, respectively.","",""
4,"H. Chaoui, P. Sicard","Robust ANN-based nonlinear speed observer for permanent magnet synchronous machine drives",2011,"","","","",142,"2022-07-13 10:06:33","","10.1109/IEMDC.2011.5994875","","",,,,,4,0.36,2,2,11,"This paper introduces a robust artificial neural network (ANN) based nonlinear speed observer for permanent magnet synchronous machines (PMSMs). A multilayer perception is trained online using back-propagation learning algorithm to estimate the rotor speed without any a priori dynamics knowledge. Thus, the proposed observer is able to cope with higher degrees of nonlinearity since it is not based on a linear-in-parameters model, unlike many neural network observers. Therefore, robustness to parameter variations is achieved. Simulation results for different situations highlight the performance of the proposed observer in the presence of high parametric uncertainties. The proposed observer is reliable and effective for PMSM drives.","",""
23,"David J. Miller, Zhen Xiang, G. Kesidis","Adversarial Learning in Statistical Classification: A Comprehensive Review of Defenses Against Attacks",2019,"","","","",143,"2022-07-13 10:06:33","","","","",,,,,23,7.67,8,3,3,"There is great potential for damage from adversarial learning (AL) attacks on machine-learning based systems. In this paper, we provide a contemporary survey of AL, focused particularly on defenses against attacks on statistical classifiers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), and reverse engineering (RE) attacks and particularly defenses against same. In so doing, we distinguish robust classification from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis; we identify the hyperparameters a particular method requires, its computational complexity, as well as the performance measures on which it was evaluated and the obtained quality. We then dig deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: 1) robust classification versus AD as a defense strategy; 2) the belief that attack success increases with attack strength, which ignores susceptibility to AD; 3) small perturbations for test-time evasion attacks: a fallacy or a requirement?; 4) validity of the universal assumption that a TTE attacker knows the ground-truth class for the example to be attacked; 5) black, grey, or white box attacks as the standard for defense evaluation; 6) susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The paper concludes with a discussion of future work.","",""
13,"Behrooz Hosseini, K. Kiani","A Robust Distributed Big Data Clustering-based on Adaptive Density Partitioning using Apache Spark",2018,"","","","",144,"2022-07-13 10:06:33","","10.3390/sym10080342","","",,,,,13,3.25,7,2,4,"Unsupervised machine learning and knowledge discovery from large-scale datasets have recently attracted a lot of research interest. The present paper proposes a distributed big data clustering approach-based on adaptive density estimation. The proposed method is developed-based on Apache Spark framework and tested on some of the prevalent datasets. In the first step of this algorithm, the input data is divided into partitions using a Bayesian type of Locality Sensitive Hashing (LSH). Partitioning makes the processing fully parallel and much simpler by avoiding unneeded calculations. Each of the proposed algorithm steps is completely independent of the others and no serial bottleneck exists all over the clustering procedure. Locality preservation also filters out the outliers and enhances the robustness of the proposed approach. Density is defined on the basis of Ordered Weighted Averaging (OWA) distance which makes clusters more homogenous. According to the density of each node, the local density peaks will be detected adaptively. By merging the local peaks, final cluster centers will be obtained and other data points will be a member of the cluster with the nearest center. The proposed method has been implemented and compared with similar recently published researches. Cluster validity indexes achieved from the proposed method shows its superiorities in precision and noise robustness in comparison with recent researches. Comparison with similar approaches also shows superiorities of the proposed method in scalability, high performance, and low computation cost. The proposed method is a general clustering approach and it has been used in gene expression clustering as a sample of its application.","",""
7,"Sebastian Berisha","IMAGE CLASSIFICATION USING GABOR FILTERS AND MACHINE LEARNING",2009,"","","","",145,"2022-07-13 10:06:33","","","","",,,,,7,0.54,7,1,13,"Feature extraction and classification are important areas of research in image processing and computer vision with a myriad of applications in science and industry. The focus of this work is on the robust classification of tree and non-tree areas in aerial imagery of the eastern Andes mountains in Peru. Knowledge of this type of information has strong implications in the study of the effect of climate change on the environment and its conservation. Drawing from recent work on human iris pattern identification, we propose a classification methodology based on Gabor feature space representation of aerial imagery, where the two object classes may be well separated. We evaluate two different distance metrics to discern class separation and use the receiver operating characteristic curve to determine an optimum classification threshold. We then build upon our Gabor representation technique by proposing two additional classification methods based on naive Bayes’ and support vector machine classifiers. Mutual information is used for reducing redundant Gabor features not carrying sufficient object information. Extensive experimentation using real aerial imagery of the Peruvian Andes shows that our approach can provide highly accurate classification, even in the presence of variable illumination, different land features and changing topology. The issue of finding an optimal Gabor feature space where object classes are optimally represented is still a challenging problem to be resolved.","",""
223,"Lei Zhang, D. Zhang","Domain Adaptation Extreme Learning Machines for Drift Compensation in E-Nose Systems",2015,"","","","",146,"2022-07-13 10:06:33","","10.1109/TIM.2014.2367775","","",,,,,223,31.86,112,2,7,"This paper addresses an important issue known as sensor drift, which exhibits a nonlinear dynamic property in electronic nose (E-nose), from the viewpoint of machine learning. Traditional methods for drift compensation are laborious and costly owing to the frequent acquisition and labeling process for gas samples' recalibration. Extreme learning machines (ELMs) have been confirmed to be efficient and effective learning techniques for pattern recognition and regression. However, ELMs primarily focus on the supervised, semisupervised, and unsupervised learning problems in single domain (i.e., source domain). To our best knowledge, ELM with cross-domain learning capability has never been studied. This paper proposes a unified framework called domain adaptation extreme learning machine (DAELM), which learns a robust classifier by leveraging a limited number of labeled data from target domain for drift compensation as well as gas recognition in E-nose systems, without losing the computational efficiency and learning ability of traditional ELM. In the unified framework, two algorithms called source DAELM (DAELM-S) and target DAELM (DAELM-T) are proposed in this paper. In order to perceive the differences among ELM, DAELM-S, and DAELM-T, two remarks are provided. Experiments on the popular sensor drift data with multiple batches collected using E-nose system clearly demonstrate that the proposed DAELM significantly outperforms existing drift-compensation methods without cumbersome measures, and also bring new perspectives for ELM.","",""
12,"T. Dharmasiri, Andrew Spek, T. Drummond","ENG: End-to-end Neural Geometry for Robust Depth and Pose Estimation using CNNs",2018,"","","","",147,"2022-07-13 10:06:33","","10.1007/978-3-030-20887-5_39","","",,,,,12,3.00,4,3,4,"","",""
176,"Li Liu, L. Shao, Xuelong Li, K. Lu","Learning Spatio-Temporal Representations for Action Recognition: A Genetic Programming Approach",2016,"","","","",148,"2022-07-13 10:06:33","","10.1109/TCYB.2015.2399172","","",,,,,176,29.33,44,4,6,"Extracting discriminative and robust features from video sequences is the first and most critical step in human action recognition. In this paper, instead of using handcrafted features, we automatically learn spatio-temporal motion features for action recognition. This is achieved via an evolutionary method, i.e., genetic programming (GP), which evolves the motion feature descriptor on a population of primitive 3D operators (e.g., 3D-Gabor and wavelet). In this way, the scale and shift invariant features can be effectively extracted from both color and optical flow sequences. We intend to learn data adaptive descriptors for different datasets with multiple layers, which makes fully use of the knowledge to mimic the physical structure of the human visual cortex for action recognition and simultaneously reduce the GP searching space to effectively accelerate the convergence of optimal solutions. In our evolutionary architecture, the average cross-validation classification error, which is calculated by an support-vector-machine classifier on the training set, is adopted as the evaluation criterion for the GP fitness function. After the entire evolution procedure finishes, the best-so-far solution selected by GP is regarded as the (near-)optimal action descriptor obtained. The GP-evolving feature extraction method is evaluated on four popular action datasets, namely KTH, HMDB51, UCF YouTube, and Hollywood2. Experimental results show that our method significantly outperforms other types of features, either hand-designed or machine-learned.","",""
43,"Zheng Zhang, L. Shao, Yong Xu, Li Liu, Jian Yang","Marginal Representation Learning With Graph Structure Self-Adaptation",2018,"","","","",149,"2022-07-13 10:06:33","","10.1109/TNNLS.2017.2772264","","",,,,,43,10.75,9,5,4,"Learning discriminative feature representations has shown remarkable importance due to its promising performance for machine learning problems. This paper presents a discriminative data representation learning framework by employing a simple yet powerful marginal regression function with probabilistic graphical structure adaptation. A marginally structured representation learning (MSRL) method is proposed by seamlessly incorporating distinguishable regression targets analysis, graph structure adaptation, and robust linear structural learning into a joint framework. Specifically, MSRL learns marginal regression targets from data rather than exploiting the conventional zero–one matrix that greatly hinders the freedom of regression fitness and degrades the performance of regression results. Meanwhile, an optimized graph regularization term with self-improving adaptation is constructed based on probabilistic connection knowledge to improve the compactness of the learned representation. Additionally, the regression targets are further predicted by utilizing the explanatory factors from the latent subspace of data, which can uncover the underlying feature correlations to enhance the reliability. The resulting optimization problem can be elegantly solved by an efficient iterative algorithm. Finally, the proposed method is evaluated by eight diverse but related tasks, including object, face, texture, and scene, categorization data sets. The encouraging experimental results and the explicit theoretical analysis demonstrate the efficacy of the proposed representation learning method in comparison with state-of-the-art algorithms.","",""
5,"Suproteem K. Sarkar, Kojin Oshiba, Daniel Giebisch, Yaron Singer","Robust Classification of Financial Risk",2018,"","","","",150,"2022-07-13 10:06:33","","","","",,,,,5,1.25,1,4,4,"Algorithms are increasingly common components of high-impact decision-making, and a growing body of literature on adversarial examples in laboratory settings indicates that standard machine learning models are not robust. This suggests that real-world systems are also susceptible to manipulation or misclassification, which especially poses a challenge to machine learning models used in financial services. We use the loan grade classification problem to explore how machine learning models are sensitive to small changes in user-reported data, using adversarial attacks documented in the literature and an original, domain-specific attack. Our work shows that a robust optimization algorithm can build models for financial services that are resistant to misclassification on perturbations. To the best of our knowledge, this is the first study of adversarial attacks and defenses for deep learning in financial services.","",""
7,"A. Przepiórkowski","Dealing with Small, Noisy and Imbalanced Data Machine Learning or Manual Grammars?",2008,"","","","",151,"2022-07-13 10:06:33","","","","",,,,,7,0.50,7,1,14,"Abstract. This paper deals with the task of deﬁnition extraction with the train-ing corpus suffering from the problems of small size, high noise and heavy im-balance. A previous approach, based on manually constructed shallow grammars,turns out to be hard to better even by such robust classiﬁers as SVMs, AdaBoostand simple ensembles of classiﬁers. However, a linear combination of varioussuch classiﬁers and manual grammars signiﬁcantly improves the results of thelatter. 1 Introduction Machine learning (ML) methods gave a new stimulus to the ﬁeld of Natural LanguageProcessing and are largelyresponsible forits rapid developmentsince the early 1990ies.Their success is undisputed in the areas where relatively large collections of manuallyannotated and balanced data of reasonably good quality are available; a prototypicalsuch area is part-of-speech tagging.Matters are less clear when only small amounts of noisy and heavily imbalancedtraining data are available; in such cases knowledge-intensive manual approaches maystill turn out to be more effective. One such task is deﬁnition extraction, which may beapproximated by the task of classifying sentences into those containing deﬁnitions ofterms and those not containing such deﬁnitions. Previous approaches to this task usu-ally rely on manually constructed shallow or deep grammars, perhaps with additionalﬁltering by ML methods.In this paper we deal with the task of extracting deﬁnitions from instructive texts inSlavic, as described in Przepiorkowski","",""
73,"Yueting Zhuang, Fei Wu, Chun Chen, Yunhe Pan","Challenges and opportunities: from big data to knowledge in AI 2.0",2017,"","","","",152,"2022-07-13 10:06:33","","10.1631/FITEE.1601883","","",,,,,73,14.60,18,4,5,"In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.","",""
82,"F. Nie, Hua Wang, Heng Huang, C. Ding","Joint Schatten $$p$$p-norm and $$\ell _p$$ℓp-norm robust matrix completion for missing value recovery",2013,"","","","",153,"2022-07-13 10:06:33","","10.1007/s10115-013-0713-z","","",,,,,82,9.11,21,4,9,"","",""
12,"Xinxin Jiang, Shirui Pan, Guodong Long, Fei Xiong, Jing Jiang, Chengqi Zhang","Cost-Sensitive Parallel Learning Framework for Insurance Intelligence Operation",2019,"","","","",154,"2022-07-13 10:06:33","","10.1109/TIE.2018.2873526","","",,,,,12,4.00,2,6,3,"Recent advancements in artificial intelligence are providing the insurance industry with new opportunities to create tailored solutions and services based on newfound knowledge of consumers, and the execution of enhanced operations and business functions. However, insurance data are heterogeneous, and imbalanced class distribution with low frequency and high dimensions, which presents four major challenges to machine learning in real-world business. Traditional machine learning algorithms can typically apply to standard data sets, which are normally homogeneous and balanced. In this paper, we focus on an efficient cost-sensitive parallel learning framework (CPLF) to enhance insurance operations with a deep learning approach that does not require preprocessing. Our approach comprises a novel, unified, end-to-end cost-sensitive parallel neural network that learns real-world heterogeneous data. A specifically designed cost-sensitive matrix then automatically generates a robust model for learning minority classifications, and the parameters of both the cost-sensitive matrix and the hybrid neural network are alternately but jointly optimized during training. We also study the CPLF-based architecture for a real-world insurance intelligence operation system, and demonstrate fraud detection and policy renewal experiments on this system. The results of comparative experiments on real-world insurance data sets reflecting actual business cases demonstrate the effectiveness of our design.","",""
36,"Zijun Wei, Jianming Zhang, Xiaohui Shen, Zhe L. Lin, R. Mech, Minh Hoai, D. Samaras","Good View Hunting: Learning Photo Composition from Dense View Pairs",2018,"","","","",155,"2022-07-13 10:06:33","","10.1109/CVPR.2018.00570","","",,,,,36,9.00,5,7,4,"Finding views with good photo composition is a challenging task for machine learning methods. A key difficulty is the lack of well annotated large scale datasets. Most existing datasets only provide a limited number of annotations for good views, while ignoring the comparative nature of view selection. In this work, we present the first large scale Comparative Photo Composition dataset, which contains over one million comparative view pairs annotated using a cost-effective crowdsourcing workflow. We show that these comparative view annotations are essential for training a robust neural network model for composition. In addition, we propose a novel knowledge transfer framework to train a fast view proposal network, which runs at 75+ FPS and achieves state-of-the-art performance in image cropping and thumbnail generation tasks on three benchmark datasets. The superiority of our method is also demonstrated in a user study on a challenging experiment, where our method significantly outperforms the baseline methods in producing diversified well-composed views.","",""
3,"Todd P. Huster, C. Chiang, R. Chadha, A. Swami","Towards the Development of Robust Deep Neural Networks in Adversarial Settings",2018,"","","","",156,"2022-07-13 10:06:33","","10.1109/MILCOM.2018.8599814","","",,,,,3,0.75,1,4,4,"Building robust deep neural network (DNN) machine learning models in adversarial settings is a problem of great importance to communication and cyber security. We consider white-box attacks in which an adversary has full knowledge of the learning architecture, but the adversary's ability to manipulate is bounded in the Lp norm sense. Given that adversarial examples are generated via small perturbations to the input, we develop a scalable mathematical framework that leads to bounds on the effect of these input perturbations on the network output. We study several typical DNN components: linear transformations, ReLU, sigmoid and double ReLU units. We use the well-calibrated MNIST data for experimental validation, and present results and insights.","",""
11,"Yun Zhao, G. Chetty, D. Tran","Deep Learning with XGBoost for Real Estate Appraisal",2019,"","","","",157,"2022-07-13 10:06:33","","10.1109/SSCI44817.2019.9002790","","",,,,,11,3.67,4,3,3,"Real estate appraisal is an important tool for evaluating property values when purchasing, selling, insuring, lending or taxing on residency properties. The traditional way to do real estate appraisal is to analyse recent sales data with basic information, such as bedrooms, bathrooms, land-size, and suburb to estimate house price prediction by comparing and selecting similar properties to the property that is being evaluated. Real estate agents are widely using this method for their clients to help them determine a price to list when selling a home or a price to offer when buying a home. However, the traditional method is very subjective and depends heavily on the experience and knowledge of real estate agents and two different agents might come up with different estimate prices. Today, machine learning and deep learning techniques provide an objective, advanced and robust option, making the joint analysis of tabular data combined with visual content possible. We are interested in estimating the real estate prices like real estate agents. In this paper, we examine to use deep learning combining with extreme Gradient Boosting (XGBoost) for real estate appraisal, by analysing historical sale records together with visual content, with online house pictures, and by scoring each image from an aesthetic point of view to make a house price prediction. Our experiment shows that an improvement in performance of house price prediction accuracy, with replacing the last output layer with XGBoost.","",""
368,"J. D. Schaffer","Some experiments in machine learning using vector evaluated genetic algorithms (artificial intelligence, optimization, adaptation, pattern recognition)",1984,"","","","",158,"2022-07-13 10:06:33","","","","",,,,,368,9.68,368,1,38,"This dissertation describes experiments conducted to explore the efficacy of using vector-valued feedback with a class of adaptive procedures called genetic algorithms. The software system developed was called VEGA for Vector Evaluated Genetic Algorithm and was first used on multiple objective optimization problems. The principle conclusion of these experiments was that VEGA provided a powerful and robust search technique for complex multiobjective optimization problems of high order when little or no a priori knowledge was available to guide the search. These results were similar to those found by previous researchers using scalar genetic algorithms for scalar optimization problems.  The VEGA technique was then applied to multiclass pattern discrimination tasks. The resulting software system was called LS-2 for Learning System - Two since it followed closely the lead of a scalar-valued learning system called LS-1 developed by Stephen Smith. The experiments revealed that LS-2 was able to evolve high performance production system programs to perform the pattern discrimination tasks it was given. In addition, experiments which varied several of the parameters of LS-2 revealed something of the sensitivity of vector-valued genetic search to the settings of these parameters.  In sum it may be said that the VEGA approach has demonstrated the efficacy of extending the previously demonstrated power of genetic algorithms to vector-valued problems and thereby provides a new approach to machine learning.","",""
30,"Bryan R. Conroy, L. Eshelman, C. Potes, M. Xu-Wilson","A dynamic ensemble approach to robust classification in the presence of missing data",2016,"","","","",159,"2022-07-13 10:06:33","","10.1007/s10994-015-5530-z","","",,,,,30,5.00,8,4,6,"","",""
14,"Quang-Phuoc Nguyen, Anh-Dung Vo, Joon-Choul Shin, Cheolyoung Ock","Effect of Word Sense Disambiguation on Neural Machine Translation: A Case Study in Korean",2018,"","","","",160,"2022-07-13 10:06:33","","10.1109/ACCESS.2018.2851281","","",,,,,14,3.50,4,4,4,"With the advent of robust deep learning, neural machine translation (NMT) has achieved great progress and recently become the dominant paradigm in machine translation (MT). However, it is still confronted with the challenge of word ambiguities that force NMT to choose among several translation candidates that represent different senses of an input word. This research presents a case study using Korean word sense disambiguation (WSD) to improve NMT performance. First, we constructed a Korean lexical semantic network (LSN) as a large-scale lexical semantic knowledge base. Then, based on the Korean LSN, we built a Korean WSD preprocessor that can annotate the correct sense of Korean words in the training corpus. Finally, we conducted a series of translation experiments using Korean-English, Korean-French, Korean-Spanish, and Korean-Japanese language pairs. The experimental results show that our Korean WSD system can significantly improve the translation quality of NMT in terms of the BLEU, TER, and DLRATIO metrics. On average, it improved the precision by 2.94 BLEU points and improved translation error prevention by 4.04 TER points and 4.51 DLRATIO points for all the language pairs.","",""
26,"S. Erfani, Mahsa Baktash, Masud Moshtaghi, Vinh Nguyen, C. Leckie, J. Bailey, K. Ramamohanarao","Robust Domain Generalisation by Enforcing Distribution Invariance",2016,"","","","",161,"2022-07-13 10:06:33","","","","",,,,,26,4.33,4,7,6,"Many conventional statistical machine learning algorithms generalise poorly if distribution bias exists in the datasets. For example, distribution bias arises in the context of domain generalisation, where knowledge acquired from multiple source domains need to be used in a previously unseen target domains. We propose Elliptical Summary Randomisation (ESRand), an efficient domain generalisation approach that comprises of a randomised kernel and elliptical data summarisation. ESRand learns a domain interdependent projection to a latent subspace that minimises the existing biases to the data while maintaining the functional relationship between domains. In the latent subspace, ellipsoidal summaries replace the samples to enhance the generalisation by further removing bias and noise in the data. Moreover, the summarisation enables large-scale data processing by significantly reducing the size of the data. Through comprehensive analysis, we show that our subspace-based approach outperforms state-of-the-art results on several activity recognition benchmark datasets, while keeping the computational complexity significantly low.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",162,"2022-07-13 10:06:33","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
87,"S. Baluja, Vibhu Mittal, R. Sukthankar","Applying Machine Learning for High‐Performance Named‐Entity Extraction",2000,"","","","",163,"2022-07-13 10:06:33","","10.1111/0824-7935.00129","","",,,,,87,3.95,29,3,22,"This paper describes a machine learning approach to building an efficient and accurate name spotting system. Finding names in free text is an important task in many text‐based applications. Most previous approaches were based on hand‐crafted modules encoding language and genre‐specific knowledge. These approaches had at least two shortcomings: They required large amounts of time and expertise to develop and were not easily portable to new languages and genres. This paper describes an extensible system that automatically combines weak evidence from different, easily available sources: parts‐of‐speech tags, dictionaries, and surface‐level syntactic information such as capitalization and punctuation. Individually, each piece of evidence is insufficient for robust name detection. However, the combination of evidence, through standard machine learning techniques, yields a system that achieves performance equivalent to the best existing hand‐crafted approaches.","",""
4,"K. Jablonka, D. Ongari, S. M. Moosavi, B. Smit","Using Collective Knowledge to Assign Oxidation States",2019,"","","","",164,"2022-07-13 10:06:33","","10.26434/chemrxiv.11604129","","",,,,,4,1.33,1,4,3,"Knowledge of the oxidation state of a metal centre in a material is essential to understand its properties. Chemists have developed several theories to predict the oxidation state on the basis of the chemical formula. These methods are quite successful for simple compounds but often fail to describe the oxidation states of more complex systems, such as metal-organic frameworks. In this work, we present a data-driven approach to automatically assign oxidation states, using a machine learning algorithm trained on the assignments by chemists encoded in the chemical names in the Cambridge Crystallographic Database. Our approach only considers the immediate local chemical environment around a metal centre and, in this way, is robust to most of the experimental uncertainties in these structures (like incorrect protonation or unbound solvents). We find such excellent accuracy (> 98 %) in our predictions that we can use our method to identify a large number of incorrect assignments in the database. The predictions of our model follow chemical intuition, without explicitly having taught the model those heuristics. This work nicely illustrates how powerful the collective knowledge of chemists actually is. Machine learning can harvest this knowledge and convert it into a useful tool for chemists.","",""
4,"K. Yazhini, D. Loganathan","A State of Art Approaches on Deep Learning Models in Healthcare: An Application Perspective",2019,"","","","",165,"2022-07-13 10:06:33","","10.1109/ICOEI.2019.8862730","","",,,,,4,1.33,2,2,3,"Acquisition of knowledge and actionable insights from complex, high-dimensional and nonhomogeneous healthcare data still remains a major difficulty in the evolving health care applications. Different data types have been emerged in the advanced healthcare research area such as maintaining patient's records, imaging, sensors data and content that are not simple, nonhomogeneous, badly annotated and normally not structured well. Conventional data mining and machine learning methods has been executing feature engineering to attain efficient and highly robust features from the data, and then constructs a model to predict or cluster data. Several difficulties exist in the situation of complex information and insufficient domain information. The recent advancements in the Deep Learning (DL) models offer novel and efficient end to end frameworks for health care data. In this study, we attempt to survey the recently presented DL models in the advanced medicinal filed in various aspects.","",""
3,"J. C. Porcello","Designing and Implementing SVMs for High-Dimensional Knowledge Discovery Using FPGAs",2019,"","","","",166,"2022-07-13 10:06:33","","10.1109/AERO.2019.8741916","","",,,,,3,1.00,3,1,3,"Support Vector Machines (SVMs)represent a robust and valuable tool for Machine Learning. SVMs are resilient to overfitting and can provide useful information for high-dimensional data when sufficient hyperplane margin can be identified. However, SVMs require substantial computational load for large datasets. This paper discusses SVMs, analyzing SVM results, and classification of high-dimensional data for the purpose of Knowledge Discovery. Furthermore, this paper considers implementation of SVMs using Field Programmable Gate Arrays (FPGAs). The approach described in this paper applies to high performance, high throughput and scalable implementations for big data. The paper provides design data for FPGA implementation of SVMs. Finally, an example is provided is based on the Xilinx UltraScale+ FPGAs to illustrate the concepts in this paper.","",""
3,"Kexin Feng, Theodora Chaspari","Low-Resource Language Identification From Speech Using Transfer Learning",2019,"","","","",167,"2022-07-13 10:06:33","","10.1109/MLSP.2019.8918833","","",,,,,3,1.00,2,2,3,"Identification of low-resource data is a traditionally difficult machine learning problem, since the sparsity of available resources prevents classifiers from being adequately trained. An effective way to address the inevitable data sparsity in certain applications, such as in low-resource speech language identification, is transfer learning, which uses the knowledge learned from tasks with large labeled data in settings of limited data. Motivated by the fact that various languages share common phonetic and phonotactic characteristics, we explore transfer learning systems that employ various neural network architectures. We leverage readily available large datasets for creating robust instantiations of language identification models using feed-forward neural networks. These are further fine-tuned on the low-resource data from a target domain to improve the system performance. We apply the proposed approach to the automatic identification of African languages, which comprises a challenging task due to the low-resource data from such languages. We conduct our experiments using two publicly available datasets: the VoxForge corpus which contains 7 Indo-European languages as source data, and the Lwazi corpus which includes 11 African languages as target data. Our results indicate the effectiveness of transfer learning for the identification of low-resource languages from speech signals.","",""
7,"Ayon Sen, P. Patel, Martina A. Rau, Blake Mason, R. Nowak, T. Rogers, Xiaojin Zhu","Machine Beats Human at Sequencing Visuals for Perceptual-Fluency Practice",2018,"","","","",168,"2022-07-13 10:06:33","","","","",,,,,7,1.75,1,7,4,"In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency: the ability to intuitively and rapidly see which concepts visuals show and to translate among multiple visuals. Instructional problems that engage students in nonverbal, implicit learning processes enhance perceptual fluency. Such processes are highly influenced by sequence effects. Thus far, we lack a principled approach for identifying a sequence of perceptual-fluency problems that promote robust learning. Here, we describe a novel educational data mining approach that uses machine learning to generate an optimal sequence of visuals for perceptual-fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machinegenerated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that an educational data mining approach can induce desirable difficulties for perceptual learning.","",""
95,"Heung-Il Suk, Seong-Whan Lee, D. Shen, T. Initiative","Deep sparse multi-task learning for feature selection in Alzheimer’s disease diagnosis",2016,"","","","",169,"2022-07-13 10:06:33","","10.1007/s00429-015-1059-y","","",,,,,95,15.83,24,4,6,"","",""
8,"Johannes Fürnkranz, T. Scheffer, M. Spiliopoulou","Machine Learning: ECML 2006, 17th European Conference on Machine Learning, Berlin, Germany, September 18-22, 2006, Proceedings",2006,"","","","",170,"2022-07-13 10:06:33","","10.1007/11871842","","",,,,,8,0.50,3,3,16,"","",""
11,"G. Souza, D. F. S. Santos, R. Pires, A. Marana, J. Papa","Deep Boltzmann machines for robust fingerprint spoofing attack detection",2017,"","","","",171,"2022-07-13 10:06:33","","10.1109/IJCNN.2017.7966077","","",,,,,11,2.20,2,5,5,"Biometrie systems present some important advantages over the traditional knowledge-or possess-oriented identification systems, such as a guarantee of authenticity and convenience. However, due to their widespread usage in our society and despite the difficulty in attacking them, nowadays criminals are already developing techniques to simulate physical, physiological and behavioral traits of valid users, the so-called spoofing attacks. In this sense, new countermeasures must be developed and integrated with the traditional biometric systems to prevent such frauds. In this work, we present a novel robust and efficient approach to detect spoofing attacks in biometric systems (fingerprint-based ones) using a deep learning-based model: the Deep Boltzmann Machine (DBM). By extracting and working with high-level features from the original data, DBM can deal with complex patterns and work with features that can not be easily forged. The results show the proposed approach outperforms other state-of-the-art techniques, presenting high accuracy in terms of attack detection and allowing working with less labeled data.","",""
9,"João Gama, Rui Camacho, P. Brazdil, A. Jorge, L. Torgo","Machine Learning: ECML 2005, 16th European Conference on Machine Learning, Porto, Portugal, October 3-7, 2005, Proceedings",2005,"","","","",172,"2022-07-13 10:06:33","","10.1007/11564096","","",,,,,9,0.53,2,5,17,"","",""
9,"Niannan Xue, Yannis Panagakis, S. Zafeiriou","Side Information in Robust Principal Component Analysis: Algorithms and Applications",2017,"","","","",173,"2022-07-13 10:06:33","","10.1109/ICCV.2017.463","","",,,,,9,1.80,3,3,5,"Robust Principal Component Analysis (RPCA) aims at recovering a low-rank subspace from grossly corrupted high-dimensional (often visual) data and is a cornerstone in many machine learning and computer vision applications. Even though RPCA has been shown to be very successful in solving many rank minimisation problems, there are still cases where degenerate or suboptimal solutions are obtained. This is likely to be remedied by taking into account of domain-dependent prior knowledge. In this paper, we propose two models for the RPCA problem with the aid of side information on the low-rank structure of the data. The versatility of the proposed methods is demonstrated by applying them to four applications, namely background subtraction, facial image denoising, face and facial expression recognition. Experimental results on synthetic and five real world datasets indicate the robustness and effectiveness of the proposed methods on these application domains, largely outperforming six previous approaches.","",""
20,"Claire Cardie","Embedded machine learning systems for natural language processing: a general framework",1995,"","","","",174,"2022-07-13 10:06:33","","10.1007/3-540-60925-3_56","","",,,,,20,0.74,20,1,27,"","",""
20,"Zheng Zhang, Ling Shao, Yong Xu, Li Liu, Jian Yang","Marginal Representation Learning With Graph Structure Self-Adaptation.",2018,"","","","",175,"2022-07-13 10:06:33","","10.1109/TNNLS.2017.2772264","","",,,,,20,5.00,4,5,4,"Learning discriminative feature representations has shown remarkable importance due to its promising performance for machine learning problems. This paper presents a discriminative data representation learning framework by employing a simple yet powerful marginal regression function with probabilistic graphical structure adaptation. A marginally structured representation learning (MSRL) method is proposed by seamlessly incorporating distinguishable regression targets analysis, graph structure adaptation, and robust linear structural learning into a joint framework. Specifically, MSRL learns marginal regression targets from data rather than exploiting the conventional zero-one matrix that greatly hinders the freedom of regression fitness and degrades the performance of regression results. Meanwhile, an optimized graph regularization term with self-improving adaptation is constructed based on probabilistic connection knowledge to improve the compactness of the learned representation. Additionally, the regression targets are further predicted by utilizing the explanatory factors from the latent subspace of data, which can uncover the underlying feature correlations to enhance the reliability. The resulting optimization problem can be elegantly solved by an efficient iterative algorithm. Finally, the proposed method is evaluated by eight diverse but related tasks, including object, face, texture, and scene, categorization data sets. The encouraging experimental results and the explicit theoretical analysis demonstrate the efficacy of the proposed representation learning method in comparison with state-of-the-art algorithms.","",""
12,"I. Bruha","Pre- and Post-processing in Machine Learning and Data Mining",2001,"","","","",176,"2022-07-13 10:06:33","","10.1007/3-540-44673-7_13","","",,,,,12,0.57,12,1,21,"","",""
172,"E. Muratov, J. Bajorath, R. Sheridan, I. Tetko, D. Filimonov, V. Poroikov, T. Oprea, I. Baskin, A. Varnek, A. Roitberg, O. Isayev, Stefano Curtalolo, D. Fourches, Y. Cohen, Alán Aspuru-Guzik, D. Winkler, D. Agrafiotis, A. Cherkasov, A. Tropsha","QSAR without borders.",2020,"","","","",177,"2022-07-13 10:06:33","","10.1039/d0cs00098a","","",,,,,172,86.00,17,19,2,"Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge.","",""
6,"P. Langley","Challenges for the Application of Machine Learning",1997,"","","","",178,"2022-07-13 10:06:33","","","","",,,,,6,0.24,6,1,25,"By most accounts, the applied branch of machine learning has been a clear success. Induction techniques have aided the development of elded systems in science and industry, on a range of tasks, including me-searchers in the area can feel genuinely proud that their algorithms have proven so robust and developers deserve major credit for identifying promising applications and seeing them through to completion. The basic development story should by now be quite The developer works with a domain expert or user to understand some problem, and then reformulates the problem into one that can be addressed by well-established methods for supervised learning. He then determines a set of likely features to describe the training cases, and devises an approach to collecting and preparing those data. Once these are available, he runs some induction method over the data. The developer (and possibly the expert) then evaluate the resulting knowledge base along dimensions of interest, such as accuracy, understandability, and consistency with existing domain knowledge. If the result seems acceptable, they attempt to deploy the learned knowledge in the eld. 1 Applied work in machine learning diiers from academic learning research in its acknowledgement of this development process. Most research papers on learning continue to emphasize reenements in the induction technique and ignore the steps that must occur 1 Of course, this process is not linear but iterative. Problems at any step can lead the developer to backtrack to an earlier stage and revisit decisions made there. before and after its invocation. In contrast, applied efforts recognize the importance of problem formulation, representation engineering, data collection and preparation , inspection of the learned knowledge, and the elding process itself. Within the applications community , there is an emerging consensus that these steps play a role at least as important as the induction stage itself. Indeed, there is even a common belief that, once they are handled, the particular induction method one uses has little eeect on the outcome. 2 Automating the Overall Process Clearly, the applied induction community could continue along these lines and be quite successful. The discipline could use its established approach to develop more elded applications and train a cadre of problem and representation engineers to become expert at the overall process. Over time, this new generation of developers would come to replace the knowledge engineers currently charged with creating knowledge-based systems. But this is a limited vision, and …","",""
204,"A. Broder, M. Fontoura, E. Gabrilovich, A. Joshi, V. Josifovski, Tong Zhang","Robust classification of rare queries using web knowledge",2007,"","","","",179,"2022-07-13 10:06:33","","10.1145/1277741.1277783","","",,,,,204,13.60,34,6,15,"We propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy, while dealing in real-time with the query volume of a commercial web search engine. We use a blind feedback technique: given a query, we determine its topic by classifying the web search results retrieved by the query. Motivated by the needs of search advertising, we primarily focus on rare queries, which are the hardest from the point of view of machine learning, yet in aggregation account for a considerable fraction of search engine traffic. Empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported. We believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience.","",""
33,"Alireza Mehrtash, Mehran Pesteie, Jorden Hetherington, Peter A. Behringer, T. Kapur, W. Wells, R. Rohling, A. Fedorov, P. Abolmaesumi","DeepInfer: open-source deep learning deployment toolkit for image-guided therapy",2017,"","","","",180,"2022-07-13 10:06:33","","10.1117/12.2256011","","",,,,,33,6.60,4,9,5,"Deep learning models have outperformed some of the previous state-of-the-art approaches in medical image analysis. Instead of using hand-engineered features, deep models attempt to automatically extract hierarchical representations at multiple levels of abstraction from the data. Therefore, deep models are usually considered to be more flexible and robust solutions for image analysis problems compared to conventional computer vision models. They have demonstrated significant improvements in computer-aided diagnosis and automatic medical image analysis applied to such tasks as image segmentation, classification and registration. However, deploying deep learning models often has a steep learning curve and requires detailed knowledge of various software packages. Thus, many deep models have not been integrated into the clinical research work ows causing a gap between the state-of-the-art machine learning in medical applications and evaluation in clinical research procedures. In this paper, we propose ""DeepInfer"" - an open-source toolkit for developing and deploying deep learning models within the 3D Slicer medical image analysis platform. Utilizing a repository of task-specific models, DeepInfer allows clinical researchers and biomedical engineers to deploy a trained model selected from the public registry, and apply it to new data without the need for software development or configuration. As two practical use cases, we demonstrate the application of DeepInfer in prostate segmentation for targeted MRI-guided biopsy and identification of the target plane in 3D ultrasound for spinal injections.","",""
105,"Jun Wang, T. Jebara, Shih-Fu Chang","Semi-supervised learning using greedy max-cut",2013,"","","","",181,"2022-07-13 10:06:33","","10.5555/2567709.2502605","","",,,,,105,11.67,35,3,9,"Graph-based semi-supervised learning (SSL) methods play an increasingly important role in practical machine learning systems, particularly in agnostic settings when no parametric information or other prior knowledge is available about the data distribution. Given the constructed graph represented by a weight matrix, transductive inference is used to propagate known labels to predict the values of all unlabeled vertices. Designing a robust label diffusion algorithm for such graphs is a widely studied problem and various methods have recently been suggested. Many of these can be formalized as regularized function estimation through the minimization of a quadratic cost. However, most existing label diffusion methods minimize a univariate cost with the classification function as the only variable of interest. Since the observed labels seed the diffusion process, such univariate frameworks are extremely sensitive to the initial label choice and any label noise. To alleviate the dependency on the initial observed labels, this article proposes a bivariate formulation for graph-based SSL, where both the binary label information and a continuous classification function are arguments of the optimization. This bivariate formulation is shown to be equivalent to a linearly constrained Max-Cut problem. Finally an efficient solution via greedy gradient Max-Cut (GGMC) is derived which gradually assigns unlabeled vertices to each class with minimum connectivity. Once convergence guarantees are established, this greedy Max-Cut based SSL is applied on both artificial and standard benchmark data sets where it obtains superior classification accuracy compared to existing state-of-the-art SSL methods. Moreover, GGMC shows robustness with respect to the graph construction method and maintains high accuracy over extensive experiments with various edge linking and weighting schemes.","",""
31,"Junlin Hu, Yongxin Ge, Jiwen Lu, Xin Feng","Makeup-robust face verification",2013,"","","","",182,"2022-07-13 10:06:33","","10.1109/ICASSP.2013.6638073","","",,,,,31,3.44,8,4,9,"We investigate in this paper the problem of face verification in the presence of face makeups. To our knowledge, this problem has less formally addressed in the literature. A key challenge is how to increase the measured similarity between face images of the same person without and with makeups. In this paper, we propose a novel approach for makeup-robust face verification, by measuring correlations between face images in a meta subspace. The meta subspace is learned using canonical correlation analysis (CCA), with the objective that intra-personal sample correlations are maximized. Subsequently, discriminative learning with the support vector machine (SVM) classifier is applied to verify faces based on the low-dimensional features in the learned meta subspace. Experimental results on our dataset are presented to demonstrate the efficacy of our approach.","",""
59,"M. Wimmer, F. Stulp, S. Pietzsch, B. Radig","Learning Local Objective Functions for Robust Face Model Fitting",2008,"","","","",183,"2022-07-13 10:06:33","","10.1109/TPAMI.2007.70793","","",,,,,59,4.21,15,4,14,"Model-based techniques have proven to be successful in interpreting the large amount of information contained in images. Associated fitting algorithms search for the global optimum of an objective function, which should correspond to the best model fit in a given image. Although fitting algorithms have been the subject of intensive research and evaluation, the objective function is usually designed ad hoc, based on implicit and domain-dependent knowledge. In this article, we address the root of the problem by learning more robust objective functions. First, we formulate a set of desirable properties for objective functions and give a concrete example function that has these properties. Then, we propose a novel approach that learns an objective function from training data generated by manual image annotations and this ideal objective function. In this approach, critical decisions such as feature selection are automated, and the remaining manual steps hardly require domain-dependent knowledge. Furthermore, an extensive empirical evaluation demonstrates that the obtained objective functions yield more robustness. Learned objective functions enable fitting algorithms to determine the best model fit more accurately than with designed objective functions.","",""
8,"B. Narayanan, Henry Chan, A. Kinaci, F. Sen, S. Gray, M. Chan, S. Sankaranarayanan","Machine learnt bond order potential to model metal-organic (Co-C) heterostructures.",2017,"","","","",184,"2022-07-13 10:06:33","","10.1039/c7nr06038f","","",,,,,8,1.60,1,7,5,"A fundamental understanding of the inter-relationships between structure, morphology, atomic scale dynamics, chemistry, and physical properties of mixed metallic-covalent systems is essential to design novel functional materials for applications in flexible nano-electronics, energy storage and catalysis. To achieve such knowledge, it is imperative to develop robust and computationally efficient atomistic models that describe atomic interactions accurately within a single framework. Here, we present a unified Tersoff-Brenner type bond order potential (BOP) for a Co-C system, trained against lattice parameters, cohesive energies, equation of state, and elastic constants of different crystalline phases of cobalt as well as orthorhombic Co2C derived from density functional theory (DFT) calculations. The independent BOP parameters are determined using a combination of supervised machine learning (genetic algorithms) and local minimization via the simplex method. Our newly developed BOP accurately describes the structural, thermodynamic, mechanical, and surface properties of both the elemental components as well as the carbide phases, in excellent accordance with DFT calculations and experiments. Using our machine-learnt BOP potential, we performed large-scale molecular dynamics simulations to investigate the effect of metal/carbon concentration on the structure and mechanical properties of porous architectures obtained via self-assembly of cobalt nanoparticles and fullerene molecules. Such porous structures have implications in flexible electronics, where materials with high electrical conductivity and low elastic stiffness are desired. Using unsupervised machine learning (clustering), we identify the pore structure, pore-distribution, and metallic conduction pathways in self-assembled structures at different C/Co ratios. We find that as the C/Co ratio increases, the connectivity between the Co nanoparticles becomes limited, likely resulting in low electrical conductivity; on the other hand, such C-rich hybrid structures are highly flexible (i.e., low stiffness). The BOP model developed in this work is a valuable tool to investigate atomic scale processes, structure-property relationships, and temperature/pressure response of Co-C systems, as well as design organic-inorganic hybrid structures with a desired set of properties.","",""
3,"Marie-Catherine de Marneffe, Trond Grenager, Bill MacCartney, Daniel Matthew Cer, D. Ramage, Chloé Kiddon, Christopher D. Manning","Robust Graph Alignment Methods for Textual Inference and Machine Reading",2007,"","","","",185,"2022-07-13 10:06:33","","","","",,,,,3,0.20,0,7,15,"This paper presents our work on textual inference and situates it within the context of the larger goals of machine reading. The textual inference task is to determine if the meaning of one text can be inferred from the meaning of another combined with background knowledge. Most existing work either provides only very limited text understanding by using bag-of-words lexical similarity models or suffers from the brittleness typical of complex natural language understanding systems. Our system generates semantic graphs as a representation of the meaning of a text. This paper presents new results for aligning pairs of semantic graphs, and proposes the application of natural logic to derive inference decisions from those aligned pairs. We consider this work as first steps toward a system able to demonstrate broad-coverage text understanding and learning","",""
10,"Azin Asgarian, Parinaz Sobhani, J. Zhang, Madalin Mihailescu, Ariel Sibilia, A. Ashraf, B. Taati","A Hybrid Instance-based Transfer Learning Method",2018,"","","","",186,"2022-07-13 10:06:33","","","","",,,,,10,2.50,1,7,4,"In recent years, supervised machine learning models have demonstrated tremendous success in a variety of application domains. Despite the promising results, these successful models are data hungry and their performance relies heavily on the size of training data. However, in many healthcare applications it is difficult to collect sufficiently large training datasets. Transfer learning can help overcome this issue by transferring the knowledge from readily available datasets (source) to a new dataset (target). In this work, we propose a hybrid instance-based transfer learning method that outperforms a set of baselines including state-of-the-art instance-based transfer learning approaches. Our method uses a probabilistic weighting strategy to fuse information from the source domain to the model learned in the target domain. Our method is generic, applicable to multiple source domains, and robust with respect to negative transfer. We demonstrate the effectiveness of our approach through extensive experiments for two different applications.","",""
19,"Chi Ian Tang, I. Perez-Pozuelo, Dimitris Spathis, S. Brage, N. Wareham, C. Mascolo","SelfHAR: Improving Human Activity Recognition through Self-training with Unlabeled Data",2021,"","","","",187,"2022-07-13 10:06:33","","10.1145/3448112","","",,,,,19,19.00,3,6,1,"Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models. In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input. We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.","",""
35,"Lu Jin, Shenghua Gao, Zechao Li, Jinhui Tang","Hand-Crafted Features or Machine Learnt Features? Together They Improve RGB-D Object Recognition",2014,"","","","",188,"2022-07-13 10:06:33","","10.1109/ISM.2014.56","","",,,,,35,4.38,9,4,8,"RGB-D object recognition is an important research topic in computer version, and seeking a robust image representation is the most important sub problem for RGB-D object recognition. On the one hand, the recently emerging deep learning methods, which learns image representations automatically by capturing the data structure, have demonstrated the impressive performance for object recognition. On the other hand, the previously commonly used hand-crafted features also encodes the prior knowledge about the data. By realizing that the hand-crafted features and machine learnt features actually characterize the different aspects of image data, rather than only using one type of feature, we propose to jointly use the machine learnt features and hand-crafted features for RGB-D object recognition. Specifically, we use the Convolution Neural Networks (CNNs) to extract the machine learnt representation, and use Locality-constrained Linear Coding (LLC) based spatial pyramid matching for hand-crafted features. We evaluated our proposed approach on three publicly available RGB-D datasets. Experimental results show that our method achieves the best performance under all the cases, which demonstrates the effectiveness of our method.","",""
16,"Daniel Fernex, B. R. Noack, R. Semaan","Cluster-based network modeling—From snapshots to complex dynamical systems",2021,"","","","",189,"2022-07-13 10:06:33","","10.1126/sciadv.abf5006","","",,,,,16,16.00,5,3,1,"A generally applicable robust data-driven network modeling strategy offers rapid means to predict and control complex systems. We propose a universal method for data-driven modeling of complex nonlinear dynamics from time-resolved snapshot data without prior knowledge. Complex nonlinear dynamics govern many fields of science and engineering. Data-driven dynamic modeling often assumes a low-dimensional subspace or manifold for the state. We liberate ourselves from this assumption by proposing cluster-based network modeling (CNM) bridging machine learning, network science, and statistical physics. CNM describes short- and long-term behavior and is fully automatable, as it does not rely on application-specific knowledge. CNM is demonstrated for the Lorenz attractor, ECG heartbeat signals, Kolmogorov flow, and a high-dimensional actuated turbulent boundary layer. Even the notoriously difficult modeling benchmark of rare events in the Kolmogorov flow is solved. This automatable universal data-driven representation of complex nonlinear dynamics complements and expands network connectivity science and promises new fast-track avenues to understand, estimate, predict, and control complex systems in all scientific fields.","",""
10,"Jaydeep Das, A. Dasgupta, Soumya K. Ghosh, R. Buyya","A Learning Technique for VM Allocation to Resolve Geospatial Queries",2018,"","","","",190,"2022-07-13 10:06:33","","10.1007/978-981-10-8639-7_61","","",,,,,10,2.50,3,4,4,"","",""
51,"A. Garcez, L. Lamb","Neurosymbolic AI: The 3rd Wave",2020,"","","","",191,"2022-07-13 10:06:33","","","","",,,,,51,25.50,26,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
10,"H. Roth, D. Yang, Ziyue Xu, Xiaosong Wang, Daguang Xu","Going to Extremes: Weakly Supervised Medical Image Segmentation",2020,"","","","",192,"2022-07-13 10:06:33","","10.3390/make3020026","","",,,,,10,5.00,2,5,2,"Medical image annotation is a major hurdle for developing precise and robust machine-learning models. Annotation is expensive, time-consuming, and often requires expert knowledge, particularly in the medical field. Here, we suggest using minimal user interaction in the form of extreme point clicks to train a segmentation model which, in effect, can be used to speed up medical image annotation. An initial segmentation is generated based on the extreme points using the random walker algorithm. This initial segmentation is then used as a noisy supervision signal to train a fully convolutional network that can segment the organ of interest, based on the provided user clicks. Through experimentation on several medical imaging datasets, we show that the predictions of the network can be refined using several rounds of training with the prediction from the same weakly annotated data. Further improvements are shown using the clicked points within a custom-designed loss and attention mechanism. Our approach has the potential to speed up the process of generating new training datasets for the development of new machine-learning and deep-learning-based models for, but not exclusively, medical image analysis.","",""
23,"H. Iba, C. Aranha","Practical Applications of Evolutionary Computation to Financial Engineering: Robust Techniques for Forecasting, Trading and Hedging",2012,"","","","",193,"2022-07-13 10:06:33","","10.1007/978-3-642-27648-4","","",,,,,23,2.30,12,2,10,"","",""
47,"P. Hamel, M. Davies, Kazuyoshi Yoshii, Masataka Goto","Transfer Learning In Mir: Sharing Learned Latent Representations For Music Audio Classification And Similarity",2013,"","","","",194,"2022-07-13 10:06:33","","","","",,,,,47,5.22,12,4,9,"This paper discusses the concept of transfer learning and its potential applications to MIR tasks such as music audio classification and similarity. In a traditional supervised machine learning setting, a system can only use labeled data from a single dataset to solve a given task. The labels associated with the dataset define the nature of the task to solve. A key advantage of transfer learning is in leveraging knowledge from related tasks to improve performance on a given target task. One way to transfer knowledge is to learn a shared latent representation across related tasks. This method has shown to be beneficial in many domains of machine learning, but has yet to be explored in MIR. Many MIR datasets for audio classification present a semantic overlap in their labels. Furthermore, these datasets often contain relatively few songs. Thus, there is a strong case for exploring methods to share knowledge between these datasets towards a more general and robust understanding of high level musical concepts such as genre and similarity. Our results show that shared representations can improve classification accuracy. We also show how transfer learning can improve performance for music similarity.","",""
9,"Masahiro Kato, Takeshi Teshima","Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation",2020,"","","","",195,"2022-07-13 10:06:33","","","","",,,,,9,4.50,5,2,2,"The estimation of the ratio of two probability densities has garnered attention as the density ratio is useful in various machine learning tasks, such as anomaly detection and domain adaptation. To estimate the density ratio, methods collectively known as direct density ratio estimation (DRE) have been explored. These methods are based on the minimization of the Bregman (BR) divergence between a density ratio model and the true density ratio. However, existing direct DRE suffers from serious overfitting when using flexible models such as neural networks. In this paper, we introduce a non-negative correction for empirical risk using only the prior knowledge of the upper bound of the density ratio. This correction makes a DRE method more robust against overfitting and enables the use of flexible models. In the theoretical analysis, we discuss the consistency of the empirical risk. In our experiments, the proposed estimators show favorable performance in inlier-based outlier detection and covariate shift adaptation.","",""
257,"C. Kolias, G. Kambourakis, A. Stavrou, S. Gritzalis","Intrusion Detection in 802.11 Networks: Empirical Evaluation of Threats and a Public Dataset",2016,"","","","",196,"2022-07-13 10:06:33","","10.1109/COMST.2015.2402161","","",,,,,257,42.83,64,4,6,"Wi-Fi has become the de facto wireless technology for achieving short- to medium-range device connectivity. While early attempts to secure this technology have been proved inadequate in several respects, the current more robust security amendments will inevitably get outperformed in the future, too. In any case, several security vulnerabilities have been spotted in virtually any version of the protocol rendering the integration of external protection mechanisms a necessity. In this context, the contribution of this paper is multifold. First, it gathers, categorizes, thoroughly evaluates the most popular attacks on 802.11 and analyzes their signatures. Second, it offers a publicly available dataset containing a rich blend of normal and attack traffic against 802.11 networks. A quite extensive first-hand evaluation of this dataset using several machine learning algorithms and data features is also provided. Given that to the best of our knowledge the literature lacks such a rich and well-tailored dataset, it is anticipated that the results of the work at hand will offer a solid basis for intrusion detection in the current as well as next-generation wireless networks.","",""
9,"R. Das Roy, D. Dash","Selection of relevant features from amino acids enables development of robust classifiers",2014,"","","","",197,"2022-07-13 10:06:33","","10.1007/s00726-014-1697-z","","",,,,,9,1.13,5,2,8,"","",""
47,"R. Raina, A. Haghighi, Christopher A. Cox, J. Finkel, J. Michels, Kristina Toutanova, Bill MacCartney, Marie-Catherine de Marneffe, Christopher D. Manning, A. Ng","Robust Textual Inference using Diverse Knowledge Sources",2005,"","","","",198,"2022-07-13 10:06:33","","","","",,,,,47,2.76,5,10,17,"We present a machine learning approach to robust textual inference, in which parses of the text and the hypothesis sentences are used to measure their asymmetric “similarity”, and thereby to decide if the hypothesis can be inferred. This idea is realized in two different ways. In the first, each sentence is represented as a graph (extracted from a dependency parser) in which the nodes are words/phrases, and the links represent dependencies. A learned, asymmetric, graph-matching cost is then computed to measure the similarity between the text and the hypothesis. In the second approach, the text and the hypothesis are parsed into the logical formula-like representation used by (Harabagiu et al., 2000). An abductive theorem prover (using learned costs for making different types of assumptions in the proof) is then applied to try to infer the hypothesis from the text, and the total “cost” of proving the hypothesis is used to decide if the hypothesis is entailed.","",""
32,"Arindam Sengupta, Feng Jin, Renyuan Zhang, Siyang Cao","mm-Pose: Real-Time Human Skeletal Posture Estimation Using mmWave Radars and CNNs",2019,"","","","",199,"2022-07-13 10:06:33","","10.1109/JSEN.2020.2991741","","",,,,,32,10.67,8,4,3,"In this paper, mm-Pose, a novel approach to detect and track human skeletons in real-time using an mmWave radar, is proposed. To the best of the authors’ knowledge, this is the first method to detect >15 distinct skeletal joints using mmWave radar reflection signals. The proposed method would find several applications in traffic monitoring systems, autonomous vehicles, patient monitoring systems and defense forces to detect and track human skeleton for effective and preventive decision making in real-time. The use of radar makes the system operationally robust to scene lighting and adverse weather conditions. The reflected radar point cloud in range, azimuth and elevation are first resolved and projected in Range-Azimuth and Range-Elevation planes. A novel low-size high-resolution radar-to-image representation is also presented, that overcomes the sparsity in traditional point cloud data and offers significant reduction in the subsequent machine learning architecture. The RGB channels were assigned with the normalized values of range, elevation/azimuth and the power level of the reflection signals for each of the points. A forked CNN architecture was used to predict the real-world position of the skeletal joints in 3-D space, using the radar-to-image representation. The proposed method was tested for a single human scenario for four primary motions, (i) Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging both arms to validate accurate predictions for motion in range, azimuth and elevation. The detailed methodology, implementation, challenges, and validation results are presented.","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",200,"2022-07-13 10:06:33","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
