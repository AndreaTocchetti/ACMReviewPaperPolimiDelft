Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
7,"Vinicius M. Alves, S. Auerbach, N. Kleinstreuer, J. Rooney, E. Muratov, I. Rusyn, A. Tropsha, Charles Schmitt","Curated Data In — Trustworthy In Silico Models Out: The Impact of Data Quality on the Reliability of Artificial Intelligence Models as Alternatives to Animal Testing",2021,"","","","",1,"2022-07-13 09:20:45","","10.1177/02611929211029635","","",,,,,7,7.00,1,8,1,"New Approach Methodologies (NAMs) that employ artificial intelligence (AI) for predicting adverse effects of chemicals have generated optimistic expectations as alternatives to animal testing. However, the major underappreciated challenge in developing robust and predictive AI models is the impact of the quality of the input data on the model accuracy. Indeed, poor data reproducibility and quality have been frequently cited as factors contributing to the crisis in biomedical research, as well as similar shortcomings in the fields of toxicology and chemistry. In this article, we review the most recent efforts to improve confidence in the robustness of toxicological data and investigate the impact that data curation has on the confidence in model predictions. We also present two case studies demonstrating the effect of data curation on the performance of AI models for predicting skin sensitisation and skin irritation. We show that, whereas models generated with uncurated data had a 7–24% higher correct classification rate (CCR), the perceived performance was, in fact, inflated owing to the high number of duplicates in the training set. We assert that data curation is a critical step in building computational models, to help ensure that reliable predictions of chemical toxicity are achieved through use of the models.","",""
11,"S. Tripathi, David Muhr, Manuel Brunner, F. Emmert‐Streib, H. Jodlbauer, M. Dehmer","Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing",2020,"","","","",2,"2022-07-13 09:20:45","","10.3389/frai.2021.576892","","",,,,,11,5.50,2,6,2,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.","",""
7,"Efrén Pérez Santín, Raquel Rodríguez Solana, María de las Nieves González García, M. D. García Suárez, Gerardo David Blanco Díaz, María Dolores Cima Cabal, J. Moreno Rojas, J. I. López Sánchez","Toxicity prediction based on artificial intelligence: A multidisciplinary overview",2021,"","","","",3,"2022-07-13 09:20:45","","10.1002/wcms.1516","","",,,,,7,7.00,1,8,1,"The use and production of chemical compounds are subjected to strong legislative pressure. Chemical toxicity and adverse effects derived from exposure to chemicals are key regulatory aspects for a multitude of industries, such as chemical, pharmaceutical, or food, due to direct harm to humans, animals, plants, or the environment. Simultaneously, there are growing demands on the authorities to replace traditional in vivo toxicity tests carried out on laboratory animals (e.g., European Union REACH/3R principles, Tox21 and ToxCast by the U.S. government, etc.) with in silica computational models. This is not only for ethical aspects, but also because of its greater economic and time efficiency, as well as more recently because of their superior reliability and robustness than in vivo tests, mainly since the entry into the scene of artificial intelligence (AI)‐based models, promoting and setting the necessary requirements that these new in silico methodologies must meet. This review offers a multidisciplinary overview of the state of the art in the application of AI‐based methodologies for the fulfillment of regulatory‐related toxicological issues.","",""
5,"Soheyl Khalilpourazari, S. Khalilpourazary, A. O. Çiftçioğlu, G. Weber","Designing energy-efficient high-precision multi-pass turning processes via robust optimization and artificial intelligence",2020,"","","","",4,"2022-07-13 09:20:45","","10.1007/s10845-020-01648-0","","",,,,,5,2.50,1,4,2,"","",""
0,"Rajole Meghana Bhausaheb","Speed Control of SRM for Hybrid Electric Vehicle Using Artificial Intelligence",2021,"","","","",5,"2022-07-13 09:20:45","","10.1109/ICCCNT51525.2021.9579857","","",,,,,0,0.00,0,1,1,"AI for switched reluctance motor (SRM) drive with integration of front end circuit is appealing for electric vehicle. As SRM carries the highlights like simple construction, high reliability, high fault tolerance capability and low production cost. However, the high torque ripples, running vibrations and acoustic noise are the major drawbacks in SRM. In proposed theory of an Artificial Intelligence for SRM drive overcome this drawback and flip it into advantages like high torque range, low torque ripple and vibration free response with flexible speed control. This paper represents an operating theory of AI for SRM drive. A hybrid ANN Controller is proposed in order to control the speed of the SRM motor. This paper mainly focuses on the comparison of the hybrid ANN controller with conventional PID and to prove the proposed controller provides the best performance and high robustness compared to a conventional PID controller alone. MATLAB/ Simulink are used to simulate.","",""
0,"S. Farsoni, S. Simani","Validation of Fault Diagnosis Techniques Based on Artificial Intelligence Tools for a Wind Turbine Benchmark",2021,"","","","",6,"2022-07-13 09:20:45","","10.1109/SysTol52990.2021.9595291","","",,,,,0,0.00,0,2,1,"The fault diagnosis of wind turbines includes extremely challenging aspects that motivate the research issues considered in this paper. In particular, this work studies fault diagnosis solutions that are considered in a viable way and used as advanced techniques for condition monitoring of dynamic processes. To this end, the work proposes the design of fault diagnosis techniques that exploits the estimation of the fault by means of data–driven approaches. To this end, the fuzzy and neural network structures are integrated with auto–regressive with exogenous input regressors, thus making them able to approximate unknown nonlinear dynamic functions with arbitrary degree of accuracy. The capabilities of fault diagnosis schemes are validated by using a simulator of a wind turbine system. Moreover, at this stage the benchmark is also useful to analyse the robustness and the reliability characteristics of the developed tools in the presence of model–reality mismatch and modelling error effects featured by the wind turbine simulator. On the other hand, a hardware–in–the–loop tool is finally implemented for testing the performance of the developed fault diagnosis strategies in a more realistic environment.","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",7,"2022-07-13 09:20:45","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
0,"","Congestion Control in Wireless Sensor Network using Artificial Intelligence Techniques",2020,"","","","",8,"2022-07-13 09:20:45","","10.35940/ijitee.e2796.039520","","",,,,,0,0.00,0,0,2,"Now-a-days, wireless sensor network has many issues and challenges like energy-efficient, congestion control, delay, scalability, reliability, robustness, etc. Communication between the wireless sensor nodes requires minimum response delay and congestion. It also requires disclosure to be energy efficient. Many congestion control protocols are using to control the congestion and improve the energy-efficient in that particular problem. Then the WSN protocol is classified as the protocol based, wired, wireless, frequency-based, and it will give the solution to that problem efficiently. Then the artificial intelligence techniques are used in a wireless sensor network to control the congestion in the systems. However, the primary fact is that the sensor node runs out of energy quickly, and traffic (congestion) has issues in many congestion control protocols. Here, congestion control is detects by hierarchical, distribution, energy-efficient in the way of algorithm in a WSN.This paper Present a Survey on Congestion Control in wireless sensor network using artificial intelligence Techniques.","",""
1,"M. H. Hajialia, M. Mosavi, K. Shahanaghi","A New Decision Support System at Estimation of Project Completion Time Considering the Combination of Artificial Intelligence Methods based on Earn Value Management Framework",2020,"","","","",9,"2022-07-13 09:20:45","","","","",,,,,1,0.50,0,3,2,"One of the important issues in project management is estimation of projects completion time. This paper proposes a model based on ensemble learning using certain features of projects in Earn Value Management (EVM) to estimate project completion time. Proper simulation of the dynamic nature of the project, higher reliability in comparison with individual methods, better robustness against the presence of a weak estimator, and appropriate control of the type and number of the existing regressions in ensemble are the important features of the proposed model. The proposed method is evaluated based on two datasets, which are created by three real projects, and promising results are obtained as compared to the other well-known estimators.","",""
1,"Yue Zhao","Decision Support System for Economic Management of Large Enterprises Based on Artificial Intelligence",2022,"","","","",10,"2022-07-13 09:20:45","","10.1155/2022/9453580","","",,,,,1,1.00,1,1,1,"In order to improve the economic management effect of large enterprises, a decision support system for economic management of large enterprises based on artificial intelligence is designed. The system hardware and software are designed, respectively. The system hardware consists of basic information module, business management module, personnel management module, salary and welfare management module, system management module, and database module. With the support of artificial intelligence technology, build a BP neural network model, and the model was trained, through continuous learning rate adjustment; in the process of training error lower sales forecast results, according to the result of prediction in enterprise comprehensive benefit maximization as the goal, set up large enterprises economic management decision-making model, large enterprise economic management decision-making algorithm design. The test results show that the system has good fault tolerance, reliability, robustness, and high efficiency, the system response time is short, the decision accuracy is high, and the practical application effect is good.","",""
1,"M. Bansal, U. Dinesh, Remica Aggarwal, V. K.","On an attempt to explore challenges for Artificial Intelligence and Machine Learning in Indian Military and Defence Sector and Studying the Possible Inter-relationship amongst them using ISM Methodology",2019,"","","","",11,"2022-07-13 09:20:45","","10.5120/ijca2019919695","","",,,,,1,0.33,0,4,3,"Recent developments in Artificial Intelligence (AI) have resulted in breakthroughs in applications such as computer vision, natural language processing, robotics, and data mining. These breakthroughs have been optimally utilized in various military applications such as surveillance, reconnaissance , threat evaluation, underwater mine warfare, cyber security, intelligence analysis, command and control as well as military education and training . However, it is not easy to achieve these breakthroughs . They are subject to the package of challenges of being prone to high risks ; robustness and reliability crunch or absence of the required training to name a few. Present research work tries to explore such challenges and further attempts to study the possible interrelationships using ISM methodology.","",""
1,"V. Indragandhi, A. L","Artificial Intelligence Based Speed Control of SRM for Hybrid Electric Vehicles",2018,"","","","",12,"2022-07-13 09:20:45","","10.1109/ICPESYS.2018.8626982","","",,,,,1,0.25,1,2,4,"A Switched Reluctance Motor (SRM) is a robust electrical motor which have features that qualifies to be used in electric vehicle and aerospace application due to its simple construction. SRM drive has acquired an expanding enthusiasm in hybrid electric vehicle applications because of its high efficiency, reliability, robust structure and reduced rotor losses. However, current and torque ripples are major drawbacks in this type of motor for electric car application. In order to reduce the ripple contents for controlling the speed of the SRM drive, various control techniques are designed using simulation software. The target of this work is to look at the operation of Fuzzy logic, Adaptive-Neuro Fuzzy Inference Strategy (ANFIS) and Direct Torque Controller (DTC) to highlight performance of effective controller. The result of applying DTC technique to a SRM drive gives the high robustness and better performance than a conventional fuzzy logic and ANFIS design technique. Simulation work is carried out using Simulink environment.","",""
13,"Shamik Kundu, K. Basu, Mehdi Sadi, Twisha Titirsha, Shihao Song, Anup Das, Ujjwal Guin","Special Session: Reliability Analysis for ML/AI Hardware",2021,"","","","",13,"2022-07-13 09:20:45","","","","",,,,,13,13.00,2,7,1,"Artificial intelligence (AI) and Machine Learning (ML) are becoming pervasive in today’s applications, such as autonomous vehicles, healthcare, aerospace, cybersecurity, and many critical applications. Ensuring the reliability and robustness of the underlying AI/ML hardware becomes our paramount importance. In this paper, we explore and evaluate the reliability of different AI/ML hardware. The first section outlines the reliability issues in a commercial systolic array-based ML accelerator in the presence of faults engendering from devicelevel non-idealities in the DRAM. Next, we quantified the impact of circuit-level faults in the MSB and LSB logic cones of the Multiply and Accumulate (MAC) block of the AI accelerator on the AI/ML accuracy. Finally, we present two key reliability issues – circuit aging and endurance in emerging neuromorphic hardware platforms and present our system-level approach to mitigate them.","",""
6,"S. Jaekel, Bastian Scholz","Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft",2015,"","","","",14,"2022-07-13 09:20:45","","10.1109/AERO.2015.7119180","","",,,,,6,0.86,3,2,7,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.","",""
2,"R. Mohamad, Harlisya Harun, M. Mokhtar, W. Adnan, K. Dimyati","On the robustness of measurement of reliability stopping criterion in turbo iterative decoding",2015,"","","","",15,"2022-07-13 09:20:45","","10.1109/SNPD.2015.7176188","","",,,,,2,0.29,0,5,7,"Measurement of reliability (MOR) stopping criterion is able to terminate early in the low and high signal-to-noise ratio (SNR) while maintaining the bit error rate (BER) performance. However, the performance of MOR is only based on one code structure and hence, the robustness of MOR is still unknown in turbo iterative decoding. Thus, this paper will test the robustness of MOR based on the following parameters: frame size, code structure, channel reliability and code rate. Then, we analyse and compare the average iteration number (AIN) and the BER performance of MOR with the benchmark stopping criterion known as Genie to determine the robustness of MOR. From the analysis, MOR has a BER degradation for low code rate. MOR also fails to perform well if the corret channel reliability is not available at the receiver and this results a large degradation in BER performance. However, MOR has close performance to Genie in terms of BER for various frame sizes, code structures and high code rate with the assistance of correct channel reliability. MOR is also able to save AIN at low SNR as compared to Genie and this can reduce delay and complexity of turbo codes.","",""
0,"Chenguang Wang, Zhixiao Sun, Qing Luo, Xinyu Wang, Tao Zhang, QianRu Wei, Jing Cheng, Depeng Gao","A system for Evaluating the Robustness of Embedded Intelligent Chips and Models",2021,"","","","",16,"2022-07-13 09:20:45","","10.1109/QRS-C55045.2021.00052","","",,,,,0,0.00,0,8,1,"After years of research and development, artificial intelligence has become an indispensable strategic technology in the future international competition. With the progress of artificial intelligence algorithms, more and more deep learning models need to be deployed to embedded devices. However, the existing deep learning algorithms have high requirements for hardware computing power, and the performance of some intelligent chips is insufficient, which is bound to affect the performance of the algorithm. Therefore, according to the relevant characteristics of embedded system, this paper designs a set of artificial intelligence chip robustness evaluation system, and builds a task environment for a series of test algorithms. By counting the performance of the same group of algorithms on different chips, we can comprehensively evaluate the robustness of artificial intelligence chip. After testing several mainstream domestic AI chips, the effectiveness of the test method and the differences between chips are verified.","",""
8,"K. Lout, R. Aggarwal","Current transients based phase selection and fault location in active distribution networks with spurs using artificial intelligence",2013,"","","","",17,"2022-07-13 09:20:45","","10.1109/PESMG.2013.6672428","","",,,,,8,0.89,4,2,9,"In electrical distribution networks, short-circuit faults are undesirable since they cause interruption of supply, affect system reliability and influence revenue for distribution companies. This paper investigates the use of current signals to determine the faulted phases during a fault and also proposes a novel approach to distinguish whether the fault lies on the feeder or one of the spurs. The distance of the fault from the substation is also evaluated using artificial neural network techniques and sensitivity tests further demonstrate the robustness of the proposed method.","",""
6,"F. Barber, M. Salido","Robustness, stability, recoverability, and reliability in constraint satisfaction problems",2015,"","","","",18,"2022-07-13 09:20:45","","10.1007/s10115-014-0778-3","","",,,,,6,0.86,3,2,7,"","",""
1,"Shamik Kundu, K. Basu, Mehdi Sadi, Twisha Titirsha, Shihao Song, Anup Das, Ujjwal Guin","Special Session: Reliability Analysis for AI/ML Hardware",2021,"","","","",19,"2022-07-13 09:20:45","","10.1109/VTS50974.2021.9441050","","",,,,,1,1.00,0,7,1,"Artificial intelligence (AI) and Machine Learning (ML) are becoming pervasive in today’s applications, such as autonomous vehicles, healthcare, aerospace, cybersecurity, and many critical applications. Ensuring the reliability and robustness of the underlying AI/ML hardware becomes our paramount importance. In this paper, we explore and evaluate the reliability of different AI/ML hardware. The first section outlines the reliability issues in a commercial systolic array-based ML accelerator in the presence of faults engendering from device-level non-idealities in the DRAM. Next, we quantified the impact of circuit-level faults in the MSB and LSB logic cones of the Multiply and Accumulate (MAC) block of the AI accelerator on the AI/ML accuracy. Finally, we present two key reliability issues- circuit aging and endurance in emerging neuromorphic hardware platforms and present our system-level approach to mitigate them.","",""
0,"P. Lin, M. Yew, S. Yeh, S. M. Chen, C. H. Lin, C. Chen, C. Hsieh, Y. J. Lu, P. Y. Chuang, H. Cheng, S. Jeng","Reliability Performance of Advanced Organic Interposer (CoWoS®-R) Packages",2021,"","","","",20,"2022-07-13 09:20:45","","10.1109/ECTC32696.2021.00125","","",,,,,0,0.00,0,11,1,"Organic interposer (CoWoS®-R) is one of the most promising heterogeneous integration platform solutions for high-speed and artificial intelligence applications. Components such as chiplets, high-bandwidth memory, and passives can be integrated into an organic interposer with excellent yield and reliability. This paper presents reliability results for advanced organic interposer packages. Multiple redistribution layers (RDLs) form an effective stress buffer for reducing the stress induced in the C4 joint and its underfill from the mismatch between the top dies and substrate. Four RDL lines with a minimum line width/spacing of 2/2 µm exhibited excellent robustness, ensuring the long functional lives of highperformance computing products. We successfully demonstrated the outstanding fatigue performance of the C4 joint reliability. Various large packages passed stringent reliability tests, specifically TCC (−65°C to 150°C) up to 1300 cycles for heterogeneous integration package and TCG (−40°C to 125°C) up to 2500 cycles for chiplet integration package. The results of the sanity cross-sectional check indicate no interfacial delamination or crack. In addition, an in-depth analysis conducted using finite-element modeling revealed that the packages had superior reliability performance compared with a large monolithic flip-chip package.","",""
0,"Minah Lee, Xueyuan She, Biswadeep Chakraborty, Saurabh Dash, B. Mudassar, S. Mukhopadhyay","Reliable Edge Intelligence in Unreliable Environment",2021,"","","","",21,"2022-07-13 09:20:45","","10.23919/DATE51398.2021.9474097","","",,,,,0,0.00,0,6,1,"A key challenge for deployment of artificial intelligence (AI) in real-time safety-critical systems at the edge is to ensure reliable performance even in unreliable environments. This paper will present a broad perspective on how to design AI platforms to achieve this unique goal. First, we will present examples of AI architecture and algorithm that can assist in improving robustness against input perturbations. Next, we will discuss examples of how to make AI platforms robust against hardware induced noise and variation. Finally, we will discuss the concept of using lightweight networks as reliability estimators to generate early warning of potential task failures.","",""
0,"Bilel Tarchoun, Anouar Ben Khalifa, M. Mahjoub","Investigating the robustness of multi-view detection to current adversarial patch threats",2022,"","","","",22,"2022-07-13 09:20:45","","10.1109/ATSIP55956.2022.9805870","","",,,,,0,0.00,0,3,1,"As deep neural networks are increasingly integrated in our daily lives, the safety and reliability of their results has become of paramount importance. However, the vulnerability of these networks to adversarial attacks are an obstacle to wider adoption, especially in safety-critical applications: A malicious actor can manipulate the results of a deep neural network by adding a nearly imperceptible noise to the input. And adversarial patch attacks make real-life implementations of these threats easier. Therefore, studying these attacks has become a rapidly growing field of artificial intelligence research. One aspect of this research is studying the behavior of patch attacks in various scenarios to understand their inner workings and find novel method to secure deep neural networks. In this paper, we examine the effectiveness of existing adversarial patch attacks against a multi-view detector. To this aim, we propose an evaluation framework where an adversarial patch is trained against a single view of a multi-view dataset and transfer the patch to the other views of the dataset with the use of perspective geometric transforms. Our results confirm that current single-view adversarial patches struggle against multi-view detectors, especially when only few views are attacked. These observations suggest that multi-view detection methods may be a step forward towards reliable and safe AI.","",""
0,"Anne-Laure Wozniak, S. Segura, Raúl Mazo, Sarah Leroy","Robustness Testing of a Machine Learning-based Road Object Detection System: An Industrial Case",2022,"","","","",23,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,4,1,"With the increasing development of critical systems based on artificial intelligence (AI), methods have been proposed and evaluated in academia to assess the reliability of these systems. In the context of computer vision, some approaches use the generation of images altered by common perturbations and realistic transformations to assess the robustness of systems. To better understand the strengths and limitations of these approaches, we report the results obtained on an industrial case of a road object detection system. By comparing these results with those of reference models, we identify areas for improvement regarding the robustness of the system and the metrics used for this evaluation.CCS CONCEPTS • Computing methodologies → Machine learning.","",""
8,"Nickolaos Koroniotis, Nour Moustafa, F. Schiliro, P. Gauravaram, H. Janicke","A Holistic Review of Cybersecurity and Reliability Perspectives in Smart Airports",2020,"","","","",24,"2022-07-13 09:20:45","","10.1109/ACCESS.2020.3036728","","",,,,,8,4.00,2,5,2,"Advances in the Internet of Things (IoT) and aviation sector have resulted in the emergence of smart airports. Services and systems powered by the IoT enable smart airports to have enhanced robustness, efficiency and control, governed by real-time monitoring and analytics. Smart sensors control the environmental conditions inside the airport, automate passenger-related actions and support airport security. However, these augmentations and automation introduce security threats to network systems of smart airports. Cyber-attackers demonstrated the susceptibility of IoT systems and networks to Advanced Persistent Threats (APT), due to hardware constraints, software flaws or IoT misconfigurations. With the increasing complexity of attacks, it is imperative to safeguard IoT networks of smart airports and ensure reliability of services, as cyber-attacks can have tremendous consequences such as disrupting networks, cancelling travel, or stealing sensitive information. There is a need to adopt and develop new Artificial Intelligence (AI)-enabled cyber-defence techniques for smart airports, which will address the challenges brought about by the incorporation of IoT systems to the airport business processes, and the constantly evolving nature of contemporary cyber-attacks. In this study, we present a holistic review of existing smart airport applications and services enabled by IoT sensors and systems. Additionally, we investigate several types of cyber defence tools including AI and data mining techniques, and analyse their strengths and weaknesses in the context of smart airports. Furthermore, we provide a classification of smart airport sub-systems based on their purpose and criticality and address cyber threats that can affect the security of smart airport’s networks.","",""
2,"F. Barber, M. Salido","Robustness , Stability , Recoverability and Reliability in Dynamic Constraint Satisfaction Problems",2011,"","","","",25,"2022-07-13 09:20:45","","","","",,,,,2,0.18,1,2,11,"1 Many real-world problems in Artificial Intelligence (AI) as well as in other areas of computer science and engineering can be efficiently modeled and solved using constraint programming techniques. In many real-world scenarios the problem is partially known, imprecise and dynamic, so that some effects of actions are undesired and/or several un-foreseen incidences or changes can occur. Whereas expressivity, efficiency, and optimality have been the typical goals in the area, several is-sues regarding robustness appear with a clear relevance in dynamic constraint satisfaction problems (DCSPs). However, there is still no a clear and common definition of robustness-related concepts in CSPs. In this paper, we propose two clearly differentiated definitions for robustness and stability in CSP solutions. We also introduce the concepts of recoverability and reliability which arise in temporal CSPs. All these definitions are based on related wellknown concepts addressed in engineering and other related areas.","",""
0,"Jia Song, Kai Zhao, Huiyan Weng, Xu Wang, Yang Liu","Research on Reliable Path Planning of Manipulator Based on Artificial Beacons",2019,"","","","",26,"2022-07-13 09:20:45","","10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00137","","",,,,,0,0.00,0,5,3,"In order to solve the problem that manipulators can only move in a fixed trajectory in common industrial production at present, we propose a monocular visual positioning method based on artificial beacons, combining visual position technology with the movement of manipulators to complete the reliable path planning of manipulators. When it comes to practicability, the traditional point pair-matching method is equipped with robust factors, to increase the reliability. We adopt a linear predict algorithm and ROI (region of interest) in the solving of PnP (Perspective-n-Point) to ensure the real-time performance and improve the robustness. Finally, the reliability is verified by experiments, which provides theoretical basis and practical reference for the path planning of manipulator based on artificial beacons.","",""
0,"Akintunde Mutairu Oyewale, Oluokun Kasali AGUNLOYE, M. K. Phazamile, M. Abiodun, Eriobu Nkiru Obioma, A. Adeyinka","Forecasting Inflation Rates Using Artificial Neural Networks",2019,"","","","",27,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,6,3,"Accuracy and reliability in forecasting the inflation rates or predicting it trend correctly is very importance for would be investors, academia, and policy makers. The use of intelligence based model have been found to be invaluable for forecasting financial and economic series like inflation rates exchange rates and stock bond so to mention the few. Researchers have used several parametric models in forecasting exchange rates and other financial and economics data. This paper therefore employs the use of non-parametric approach (artificial neural networks) in forecasting inflation rates. It is an indubitable fact that Artificial Neural networks (ANNs), emulates the information processing capabilities of neurons of the human brain. It uses a distributed representation of the information stored in the networks, and thus resulting in robustness against damage and corresponding fault tolerance. A major advantage of neural networks is their ability to provide flexible mapping between inputs and outputs. The arrangement of the simple units into a multi-layer frame works produces a map between inputs and outputs that is consistent with any underlying functional relationship irrespective of the true functional form. This paper therefore, used three artificial neural networks (Standard Backpropagation (SBP), Scaled Conjugate Gradient (SCG) and Backpropagation based forecasting model for Nigerian and American inflation rates. These models were evaluated using five performance series and a comparison was made with traditional ARIMA models. Inflation rates data of United States of America and Federal Republic of Nigeria were used for empirical illustration. The data were analyzed using both statistical programme for social science (SPSS) and Econometrics view (E-view). The results obtained show that all the ANN models outperformed ARIMA models. The implication of this is that ANN based model can be used to forecast the inflation rates market structure.","",""
124,"E. Ebrahimi, M. Monjezi, M. Khalesi, D. J. Armaghani","Prediction and optimization of back-break and rock fragmentation using an artificial neural network and a bee colony algorithm",2016,"","","","",28,"2022-07-13 09:20:45","","10.1007/s10064-015-0720-2","","",,,,,124,20.67,31,4,6,"","",""
45,"M. Ahmadi","Developing a Robust Surrogate Model of Chemical Flooding Based on the Artificial Neural Network for Enhanced Oil Recovery Implications",2015,"","","","",29,"2022-07-13 09:20:45","","10.1155/2015/706897","","",,,,,45,6.43,45,1,7,"Application of chemical flooding in petroleum reservoirs turns into hot topic of the recent researches. Development strategies of the aforementioned technique are more robust and precise when we consider both economical points of view (net present value, NPV) and technical points of view (recovery factor, RF). In current study many attempts have been made to propose predictive model for estimation of efficiency of chemical flooding in oil reservoirs. To gain this end, a couple of swarm intelligence and artificial neural network (ANN) is employed. Also, lucrative and high precise chemical flooding data banks reported in previous attentions are utilized to test and validate proposed intelligent model. According to the mean square error (MSE), correlation coefficient, and average absolute relative deviation, the suggested swarm approach has acceptable reliability, integrity and robustness. Thus, the proposed intelligent model can be considered as an alternative model to predict the efficiency of chemical flooding in oil reservoir when the required experimental data are not available or accessible.","",""
8,"D. Partridge","Engineering artificial intelligence software",2005,"","","","",30,"2022-07-13 09:20:45","","10.1007/BF01988526","","",,,,,8,0.47,8,1,17,"","",""
0,"Jasminder Kaur Sandhu, Anil Kumar Verma, P. Rana","RCDR: Reliability Control Framework for Data Rate Prediction in Wireless Sensor Networks",2018,"","","","",31,"2022-07-13 09:20:45","","10.1109/GUCON.2018.8674978","","",,,,,0,0.00,0,3,4,"Machine learning or popularly known as prediction technique is an application of Artificial Intelligence. It provides network the ability to learn from past experience and make them more efficient. This technique of prediction is being used in diverse fields due to its adaptive nature. In particular, the prediction technique has been proven very useful in the design of reliable Wireless Sensor Networks. This paper proposes a reliability control framework with date rate prediction in Wireless Sensor Network, and provides the community a general view of this vibrant research area. Various, simulations are carried out to generate a primary networking dataset with many performance parameters including the data rate. The data rate is predicted using different prediction techniques. Lastly, to check the robustness of best predictive model, N-fold cross-validation technique is used.","",""
20,"Sheeba Lal, S. Rehman, J. H. Shah, Talha Meraj, Hafiz Tayyab Rauf, Robertas Damaševičius, M. Mohammed, Karrar Hameed Abdulkareem","Adversarial Attack and Defence through Adversarial Training and Feature Fusion for Diabetic Retinopathy Recognition",2021,"","","","",32,"2022-07-13 09:20:45","","10.3390/s21113922","","",,,,,20,20.00,3,8,1,"Due to the rapid growth in artificial intelligence (AI) and deep learning (DL) approaches, the security and robustness of the deployed algorithms need to be guaranteed. The security susceptibility of the DL algorithms to adversarial examples has been widely acknowledged. The artificially created examples will lead to different instances negatively identified by the DL models that are humanly considered benign. Practical application in actual physical scenarios with adversarial threats shows their features. Thus, adversarial attacks and defense, including machine learning and its reliability, have drawn growing interest and, in recent years, has been a hot topic of research. We introduce a framework that provides a defensive model against the adversarial speckle-noise attack, the adversarial training, and a feature fusion strategy, which preserves the classification with correct labelling. We evaluate and analyze the adversarial attacks and defenses on the retinal fundus images for the Diabetic Retinopathy recognition problem, which is considered a state-of-the-art endeavor. Results obtained on the retinal fundus images, which are prone to adversarial attacks, are 99% accurate and prove that the proposed defensive model is robust.","",""
3,"P. Stavroulakis, M. Kolisnyk, V. Kharchenko, N. Doukas, O. Markovskyi, N. Bardis","Reliability, Fault Tolerance and Other Critical Components for Survivability in Information Warfare",2017,"","","","",33,"2022-07-13 09:20:45","","10.1007/978-3-030-11039-0_17","","",,,,,3,0.60,1,6,5,"","",""
9,"Hayat Ullah, Khan Muhammad, Muhammad Irfan, Saeed Anwar, M. Sajjad, Ali Shariq Imran, V. H. C. de Albuquerque","Light-DehazeNet: A Novel Lightweight CNN Architecture for Single Image Dehazing",2021,"","","","",34,"2022-07-13 09:20:45","","10.1109/TIP.2021.3116790","","",,,,,9,9.00,1,7,1,"Due to the rapid development of artificial intelligence technology, industrial sectors are revolutionizing in automation, reliability, and robustness, thereby significantly increasing quality and productivity. Most of the surveillance and industrial sectors are monitored by visual sensor networks capturing different surrounding environment images. However, during tempestuous weather conditions, the visual quality of the images is reduced due to contaminated suspended atmospheric particles that affect the overall surveillance systems. To tackle these challenges, this article presents a computationally efficient lightweight convolutional neural network referred to as Light-DehazeNet (LD-Net) for the reconstruction of hazy images. Unlike other learning-based approaches, which separately measure the transmission map and the atmospheric light, our proposed LD-Net jointly estimates both the transmission map and the atmospheric light using a transformed atmospheric scattering model. Furthermore, a color visibility restoration method is proposed to evade the color distortion in the dehaze image. Finally, we conduct extensive experiments using synthetic and natural hazy images. The quantitative and qualitative evaluation on different benchmark hazy datasets verify the superiority of the proposed method over other state-of-the-art image dehazing techniques. Moreover, additional experimentation validates the applicability of the proposed method in the object detection tasks. Considering the lightweight architecture with minimal computational cost, the proposed system is encouraged to be incorporated as an integral part of the vision-based monitoring systems to improve the overall performance.","",""
2,"Xiaolong Guo, Song Han, X. S. Hu, Xun Jiao, Yier Jin, Fanxin Kong, M. Lemmon","Towards Scalable, Secure, and Smart Mission-Critical IoT Systems: Review and Vision : (Special Session Paper)",2021,"","","","",35,"2022-07-13 09:20:45","","10.1145/3477244.3477624","","",,,,,2,2.00,0,7,1,"Recent emerging technologies such as artificial intelligence and machine learning have been promising enormous economic and societal benefits. While it is desirable to deploy these technologies to Internet-of-Things (IoT) infrastructures in many applications such as medical, energy, transportation, and industrial automation systems, such deployments present daunting challenges in performance, efficiency, and dependability of scaling-up IoT infrastructure, due to the ever-increasing number of edge devices, ever-increasing levels of device and system heterogeneity, and more stringent requirements of reliability, robustness, and security in mission-critical settings. This position paper elaborates the needs for a cross-layer and full hardware/software stack solution for the design and deployment of scalable, secure, and smart mission-critical IoT systems from four different perspectives and research fields. We present a review of recent studies on such issues and identify the potential challenges and gaps, based on which we highlight some important research directions and future works that can be conducted to tackle such challenges.","",""
2,"R. Soklaski, Justin A. Goodwin, Olivia M. Brown, Michael Yee, J. Matterer","Tools and Practices for Responsible AI Engineering",2022,"","","","",36,"2022-07-13 09:20:45","","","","",,,,,2,2.00,0,5,1,"Responsible Artificial Intelligence (AI)—the practice of developing, evaluating, and maintaining accurate AI systems that also exhibit essential properties such as robustness and explainability—represents a multifaceted challenge that often stretches standard machine learning tooling, frameworks, and testing methods beyond their limits. In this paper, we present two new software libraries—hydra-zen and the rAI-toolbox—that address critical needs for responsible AI engineering. hydra-zen dramatically simplifies the process of making complex AI applications configurable, and their behaviors reproducible. The rAI-toolbox is designed to enable methods for evaluating and enhancing the robustness of AI-models in a way that is scalable and that composes naturally with other popular ML frameworks. We describe the design principles and methodologies that make these tools effective, including the use of property-based testing to bolster the reliability of the tools themselves. Finally, we demonstrate the composability and flexibility of the tools by showing how various use cases from adversarial robustness and explainable AI can be concisely implemented with familiar APIs.","",""
1,"G. Vouros","Explainable Deep Reinforcement Learning: State of the Art and Challenges",2022,"","","","",37,"2022-07-13 09:20:45","","10.1145/3527448","","",,,,,1,1.00,1,1,1,"Interpretability, explainability and transparency are key issues to introducing Artificial Intelligence methods in many critical domains: This is important due to ethical concerns and trust issues strongly connected to reliability, robustness, auditability and fairness, and has important consequences towards keeping the human in the loop in high levels of automation, especially in critical cases for decision making, where both (human and the machine) play important roles. While the research community has given much attention to explainability of closed (or black) prediction boxes, there are tremendous needs for explainability of closed-box methods that support agents to act autonomously in the real world. Reinforcement learning methods, and especially their deep versions, are such closed-box methods. In this article we aim to provide a review of state of the art methods for explainable deep reinforcement learning methods, taking also into account the needs of human operators - i.e., of those that take the actual and critical decisions in solving real-world problems. We provide a formal specification of the deep reinforcement learning explainability problems, and we identify the necessary components of a general explainable reinforcement learning framework. Based on these, we provide a comprehensive review of state of the art methods, categorizing them in classes according to the paradigm they follow, the interpretable models they use, and the surface representation of explanations provided. The article concludes identifying open questions and important challenges.","",""
1,"7f185eb0c28241398afd245b87c","Real Time Visual Loop Closure Detection",2022,"","","","",38,"2022-07-13 09:20:45","","","","",,,,,1,1.00,1,1,1,"Visual SensorsTowards Autonomous Robotic SystemsQuality, Reliability, Security and Robustness in Heterogeneous SystemsPattern Recognition and Image AnalysisClose range 3D thermography: real-time reconstruction of high fidelity 3D thermogramsComputer Vision SystemsSensing and Control for Autonomous VehiclesIntelligent Control of Robotic SystemsOCEANS 2019 MarseilleRoboticsAdvances in Harmony Search, Soft Computing and ApplicationsClosing the Loop Around Neural SystemsModelling and Simulation for Autonomous SystemsAdvancements in Mechatronics and Intelligent RoboticsIntelligent VehiclesEfficient Visual Search in Appearancebased SLAMRobot Intelligence Technology and Applications 2Wireless and Satellite SystemsMobile Mapping TechnologiesIntelligent Robotics and ApplicationsComputer Vision in Vehicle TechnologyProgress in Artificial IntelligenceArtificial IntelligenceRobot Intelligence Technology and Applications 4Advances in Visual ComputingAugmented Reality, Virtual Reality, and Computer GraphicsAdvanced Mobile RoboticsIntelligent Imaging and AnalysisComputer Vision SystemsAttention in Cognitive Systems. Theories and Systems from an Interdisciplinary ViewpointUnmanned Driving Systems for Smart TrainsInteraction of BCI with the underlying neurological conditions in patients: pros and consAdvances in Service and Industrial Robotics2008 IEEE International Conference on Robotics and AutomationIntelligent Robotics and ApplicationsAdvances in Intelligent Automation and Soft ComputingIntelligent Autonomous Systems 13Human-Inspired Computing and its ApplicationsMethods for Appearance-based Loop Closure DetectionComputer Vision ECCV 2014 Workshops","",""
19,"G. Zhong, Mengfei Zi, Chuanlai Ren, Q. Xiao, Mingkai Tang, Liyu Wei, F. An, S. Xie, Jinbin Wang, X. Zhong, Mingqiang Huang, Jiangyu Li","Flexible electronic synapse enabled by ferroelectric field effect transistor for robust neuromorphic computing",2020,"","","","",39,"2022-07-13 09:20:45","","10.1063/5.0013638","","",,,,,19,9.50,2,12,2,"Neuromorphic computing has the potential to accelerate high performance parallel and low power in-memory computation, artificial intelligence, and adaptive learning. Despite emulating the basic functions of biological synapses well, the existing artificial electronic synaptic devices have yet to match the softness, robustness, and ultralow power consumption of the brain. Here, we demonstrate an all-inorganic flexible artificial synapse enabled by a ferroelectric field effect transistor based on mica. The device not only exhibits excellent electrical pulse modulated conductance updating for synaptic functions but also shows remarkable mechanical flexibility and high temperature reliability, making robust neuromorphic computation possible under external disturbances such as stress and heating. Based on its linear, repeatable, and stable long-term plasticity, we simulate an artificial neural network for the Modified National Institute of Standards and Technology handwritten digit recognition with an accuracy of 94.4%. This work provides a promising way to enable flexible, low-power, robust, and highly efficient neuromorphic computation that mimics the brain.","",""
0,"Chi Tran, M. G. Valmiki, Guoyan Xu, J. Gao","An Intelligent Mobile Application Testing Experience Report",2021,"","","","",40,"2022-07-13 09:20:45","","10.1088/1742-6596/1828/1/012080","","",,,,,0,0.00,0,4,1,"Artificial intelligence applications provide tremendous opportunities to improve human life and drive innovation. AI systems/applications which operate in a real-world environment have to encounter an infinite set of feasible scenarios. Conventional testing approach to test the AI application allows only limited testing and does not allow taking the different contexts into consideration and may lead to insufficient validation and characterization. Therefore, to ensure robustness, certainty and reliability of AI applications, the authors applied classification-based AI software testing framework and 3D decision tables to generate test cases. Moreover, the authors compared the quality assurance metrics (accuracy, correctness, reliability and consistency) of AI and non-AI functions in the AI mobile application scenario. Our results indicate and confirm that complete AI function validation is not possible with conventional testing methods, but AI software testing strategy proposed based on classification framework and 3D decision tables has a good effect.","",""
0,"R. Nigam, K. Kar","Integrated Energy Storage System",2021,"","","","",41,"2022-07-13 09:20:45","","10.1007/978-3-030-68364-1_9","","",,,,,0,0.00,0,2,1,"","",""
0,"Yufei Zhuang, Xiao Han, Haibin Huang, Yanan Li, Chenxu Wang","Dynamic Area Coverage with Multi-USV in Fully Connected State using Graph Theory",2021,"","","","",42,"2022-07-13 09:20:45","","10.1109/cac53003.2021.9728270","","",,,,,0,0.00,0,5,1,"Exploration of marine resources is becoming increasingly important in both civil and military domains as marine research and technology advance. However, ocean exploration is often accompanied by high-intensity and high-risk missions, so governments of various countries vigorously develop unmanned systems for ocean missions. With the advancement of artificial intelligence technology, the robustness and scalability of multi-unmanned systems have been significantly improved. In recent years, the control technology of Unmanned Surface Vehicle (USV) has become increasingly mature. Based on the monitoring of the area, this article analyzes the multi-USV system to perform coverage control tasks. This article proposes an algorithm based on the idea of virtual potential field, which enables three USVs to achieve 100% coverage of the area of interest (AOI) and maintain full connectivity as much as possible throughout the process, in order to increase the safety and reliability of the system. The algorithm uses the adjacency matrix to limit the path of the USVs from the perspective of graph theory. Once the multi-USV system cannot maintain full connectivity, measures are taken to bring the USVs close to each other to reach full connectivity again, and finally achieve 100% coverage of AOI, with the multi-USV system remaining fully connected to wait for the next instruction.","",""
0,"Xinyu Yin, Xiaojie Fang, Ning Zhang, Peng Yang, X. Sha, Jinghui Qiu","Online Learning Aided Adaptive Multiple Attribute-Based Physical Layer Authentication in Dynamic Environments",2021,"","","","",43,"2022-07-13 09:20:45","","10.1109/tnse.2020.3013232","","",,,,,0,0.00,0,6,1,"Exploiting physical (PHY)-layer characteristics for authentication has great potential to provision underlying trust for low-ended Internet of things (IoT) devices with limited computation resources. In this paper, we propose an online learning aided adaptive PHY-layer authentication framework for enhanced authenticity provisioning. Instead of relying on some preset PHY-layer signatures with scenario-sensitive “thresholds,” multiple PHY-layer attributes are jointly considered by the proposed scheme to improve the reliability and robustness of PHY-layer authentication. Such a dimension extension on PHY-layer signatures can effectively deteriorate the spoofing capability of malicious attackers. However, it also complicates the predicting and authenticating procedure of the legitimate receiver. Therefore, artificial intelligence aided search algorithms are formulated to facilitate adaptive selection of the Most Effective PHY-layer Attributes (MEA) through learning their historical authenticity performance. To be specific, the attributes which are predicted to be effective in maximizing the authentication capability, in terms of low false alarm rate and low miss detection rate, will be dynamically selected by the authenticator in an autonomous manner. Theoretical analysis shows that the proposed learning algorithm achieves asymptotically diminishing regret. Moreover, extensive experiments are conducted using Universal Software Radio Peripherals (USRPs) in a laboratory environment, which further validates the efficiency of the proposed scheme.","",""
0,"M. Hadj-Bachir, P. D. Souza, J. Shaik, G. Dominique","Evaluating Autonomous Functions Performance Through Simulation Using Interoperable Sensor, Vehicle, and Environment Models",2020,"","","","",44,"2022-07-13 09:20:45","","10.46720/f2020-acm-067","","",,,,,0,0.00,0,4,2,"The evaluation, validation, certification, and homologation of connected and automated autonomous vehicles will require more and more virtual testing because of a new level of system complexity the automotive industry has never faced before. Ensuring the robustness, accuracy, and reliability of the perception stages of an ""intelligent"" and automated vehicle is recognized as one of the challenges for the transition of future mobility means to the higher levels of autonomous driving. From a technological perspective, safety is enforced using combinations of sensors systems exploiting different physics principles used by GPS, by optical sensors, by near or thermal infrared sensors, by electromagnetic sensors and by ultrasonic sensors. The consistency of the performance verification, expected for the embedded processing relying on artificial intelligence software stacks, depends on the driving environment's characteristics. It is now obvious that real testing should evolve accordingly and should be completed by virtual testing. Therefore, the industry has embraced the idea of introducing simulation methods to support such validation. At ESI and with our strategic research and development partner University Gustave Eiffel (merge between previously IFSTTAR and 5 other organisms) we are working on the development of new interoperable and interconnected simulation solutions offering the proper agility related to the integration of new methods. In the new generations of simulation platform, the problem is to address a complex multi-layer simulation task not only processed by one software and one computer but by several interoperable remote platforms (i.e Dynamics vehicle modelling, sensors modelling, communication modelling, and traffic modelling). Such a simulation platform must respect important constraints such as the interconnection with real-time data management and processing software, or the capability to share the simulation components, the processing stages, and the driving functions across multiple applications and/or computers. Simulation can evaluate the performance of complex systems from well-defined scenarios and configurations. It intervenes in several phases of system manufacturing in the design and exploitation phases. With virtual prototyping, simulation can be used to predict in real time the system behavior with respect to its control in order to implement optimal strategies. It is also used for verification, validation and improvement of choices in the design phases. Our technical paper aims to present what we did with partners and customers in order to confirm the value brought by such new simulation solution.","",""
0,"Dem Lee, J. Lee","Anti-Corrosion Capacity Validation for Anti-Sulfur Type Electronic Passive Components by Way of Various Flower-of-Sulfur (FoS) Methodologies",2021,"","","","",45,"2022-07-13 09:20:45","","10.1109/IMPACT53160.2021.9696582","","",,,,,0,0.00,0,2,1,"Hardware reliability of Information Technology (IT) equipment can be easily affected by corrosive gases, moisture, contaminants and particulate matter. It can potentially cause electrical open failures due to sulfur corrosion (Ag2S) on the inner electrode of electronic passive components. In order to improve the robustness against sulfur corrosion, many vendors adopted gold-based and silver-palladium-based inner electrode designs (noble metal) as well as other solutions, including passivation cover and reverse structure designs. New IT equipment applications, including Artificial Intelligence (AI), Big Data, 5G, Internet of Things (IoT) and Edge Computing in recent years has proliferated the need of passive electronic components and the industry is facing passive component shortage. Therefore, quality control is becoming more critical in reducing poor quality risk. Flowers of Sulfur (FoS) is a popular method to validate the anti-sulfur corrosion capability of electronic passive components. However, the condition of single corrosive gas (sulfur vapor) is not enough to represent the accelerated corrosion exposure in field environments. It has been stipulated that typical testing methods as outlined in ASTM B809 and EIA-977 may not be totally effective in driving Anti-Sulfur Resistor (ASR) failure occurrence at 105°C/750 hours (test to pass), or even longer duration. Despite testing at those conditions, end-customers have reported sulfur corrosion-related failures. Therefore, it is necessary to develop an effective accelerated method for anti-sulfur corrosion capacity validation for anti-sulfur type electronic passive components. In this paper, three conditions of FoS test were carried out to validate the anti-sulfur corrosion capability of ASR components. We introduced chlorine-gas as another acceleration factor, and benchmarked it against ASTM B809 and EIA-977 FoS tests. Several analytical methods were used in this work, including, high resolution 3D X-Ray Microscope (3D X-Ray), Cross section polisher, (CP), Plasma Focused Ion Beam, (PFIB), Scanning Electron Microscopy (SEM) and Energy-Dispersive X-ray spectroscopy (EDX). Finally, we found that FoS with chlorine-gas condition is the most aggressive of all conditions.","",""
0,"A. Landge, H. Takpire","Energy management System for Hybrid Electrical Vehicle using Soft Computing",2022,"","","","",46,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,2,1,": Because of their great efficiency, low cost, and pollution-free properties, hybrid electric vehicles (HEVs) are becoming more popular. Long-distance driving necessitates the use of hybrid power sources. In electric vehicles that use hybrid power sources, energy management is a crucial issue. Artificial intelligence-based algorithms have made a substantial contribution to hybrid electric car energy management systems. In a hybrid electric car that uses fuel cells, batteries, and internal combustion engines as power sources, this article provides a Fuzzy logic-based energy management strategy. Based on the present battery state of charge, varying vehicle characteristics, and driving situations, the suggested method allows efficient regulation of power flow in HEVs. The proposed fuzzy management technique demonstrates reliability, easiness in implementation and robustness.","",""
0,"W. Harris, A. Gu, M. Terada","Putting AI to Work: A Practical and Simple Application to Improve 3D X-ray FA",2022,"","","","",47,"2022-07-13 09:20:45","","10.1109/IRPS48227.2022.9764574","","",,,,,0,0.00,0,3,1,"This paper presents the demonstration of a deep learning-based reconstruction approach for working with 3D X-ray tomography/microscopy data, focusing on improving workflows in microelectronics failure analysis and reliability applications. Whereas the industry-standard filtered back projection (known as FDK) method of X-ray tomography reconstruction has been used for many years due to its simplicity and robustness, it has constrained the results of 3D X-ray scanning in terms of both image quality and scan speed. Powered by artificial intelligence technologies, the new deep learning high resolution reconstruction (DLHRR) approach discussed here offers broad improvements across diverse sample types including microelectronics, increases scan speed by a factor of 4X or more, is as easy to use as FDK without requirement for a machine learning expert, and is implemented on a desktop workstation PC. Results will be shown on IC packages and commercial battery devices.","",""
0,"Navya Mohan, J. Kurian","Design and implementation of shape-based feature extraction engine for vision systems using Zynq SoC",2022,"","","","",48,"2022-07-13 09:20:45","","10.32985/ijeces.13.2.3","","",,,,,0,0.00,0,2,1,"With the great impact of vision and Artificial Intelligence (AI) technology in the fields of quality control, robotic assembly and robot navigation, the hardware implementation of object detection and classification algorithms on embedded platforms has got ever-increasing attention these days. The real-time performance with optimum resource utilization of the implementation and its reliability as well as the robustness of the underlying algorithm is the overarching challenges in this field. In this work, an approach employing a fast and accurate vision-based shape-detection algorithm has been proposed and its implementation in heterogeneous System on Chip (SoC) is discussed. The proposed system determines centroid distance and its Fourier Transform for the object feature vector extraction and is realized in the Zybo Z7 development board. The ARM processor is responsible for communication with the external systems as well as for writing data to the Block RAM (BRAM), the control signals for efficient execution of the memory operations are designed and implemented using Finite State Machine (FSM) in the Programmable Logic (PL) fabric. Shape feature vector determination has been accelerated using custom modules developed in Verilog, taking full advantage of the possible parallelization and pipeline stages. Meanwhile, industry-standard Advanced Extendable Interface (AXI) buses are adopted for encapsulating standardized IP cores and building high-speed data exchange bridges between units within Zynq-7000. The developed system processes images of size 32 × 64 in real-time and can generate feature descriptors at a clock rate of 62MHz. Moreover, the method yields a shape feature vector that is computationally light, scalable and rotation invariant. The hardware design is validated using MATLAB for comparative studies","",""
0,"G. El-khawaga, Mervat Abu-Elkheir, M. Reichert","XAI in the Context of Predictive Process Monitoring: An Empirical Analysis Framework",2022,"","","","",49,"2022-07-13 09:20:45","","10.3390/a15060199","","",,,,,0,0.00,0,3,1,"Predictive Process Monitoring (PPM) has been integrated into process mining use cases as a value-adding task. PPM provides useful predictions on the future of the running business processes with respect to different perspectives, such as the upcoming activities to be executed next, the final execution outcome, and performance indicators. In the context of PPM, Machine Learning (ML) techniques are widely employed. In order to gain trust of stakeholders regarding the reliability of PPM predictions, eXplainable Artificial Intelligence (XAI) methods have been increasingly used to compensate for the lack of transparency of most of predictive models. Multiple XAI methods exist providing explanations for almost all types of ML models. However, for the same data, as well as, under the same preprocessing settings or same ML models, generated explanations often vary significantly. Corresponding variations might jeopardize the consistency and robustness of the explanations and, subsequently, the utility of the corresponding model and pipeline settings. This paper introduces a framework that enables the analysis of the impact PPM-related settings and ML-model-related choices may have on the characteristics and expressiveness of the generated explanations. Our framework provides a means to examine explanations generated either for the whole reasoning process of an ML model, or for the predictions made on the future of a certain business process instance. Using well-defined experiments with different settings, we uncover how choices made through a PPM workflow affect and can be reflected through explanations. This framework further provides the means to compare how different characteristics of explainability methods can shape the resulting explanations and reflect on the underlying model reasoning process.","",""
0,"Dipanwita Guhathakurta, Pooja Aggarwal, Seema Nagar, Rohan Arora, Bing Zhou","Utilizing Persistence for Post Facto Suppression of Invalid Anomalies Using System Logs",2022,"","","","",50,"2022-07-13 09:20:45","","10.1109/icse-nier55298.2022.9793537","","",,,,,0,0.00,0,5,1,"The robustness and availability of cloud services are becoming increasingly important as more applications migrate to the cloud. The operations landscape today is more complex, than ever. Site reliability engineers (SREs) are expected to handle more incidents than ever before with shorter service-level agreements (SLAs). By exploiting log, tracing, metric, and network data, Artificial Intelligence for IT Operations (AIOps) enables detection of faults and anomalous issues of services. A wide variety of anomaly detection techniques have been incorporated in various AIOps platforms (e.g. PCA and autoencoder), but they all suffer from false positives. In this paper, we propose an unsupervised approach for persistent anomaly detection on top of the traditional anomaly detection approaches, with the goal of reducing false positives and providing more trustworthy alerting signals. We test our method on both simulated and real-world datasets. Our technique reduces false positive anomalies by at least 28%, resulting in more reliable and trustworthy notifications. CCS CONCEPTS • Computing methodologies $\rightarrow$ Anomaly detection;. Software and its engineering $\rightarrow$Maintaining software. ACM Reference Format: Dipanwita Guhathakurta, Pooja Aggarwal, Seema Nagar, and Rohan Arora, Bing Zhou. 2022. Utilizing Persistence for Post Facto Suppression of Invalid Anomalies Using System Logs. In New Ideas and Emerging Results (ICSENIER’22), May 21-29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3510455.3512774","",""
0,"J. Marzo, David Martínez, Sergi Bergillos, E. Calle","Network Research Simulator. An abstract model formulation",2022,"","","","",51,"2022-07-13 09:20:45","","10.1109/DRCN53993.2022.9758023","","",,,,,0,0.00,0,4,1,"This paper presents a novel tool for network analysis and design, the Network Research Simulator (NRS). The NRS structure, main features and network model are described and discussed. The proposed abstract model formulation for the NRS is a flexible low-cost programming approach with which to implement different experiments. A case study to analyze the reliability of a a set of networks in a dynamic (massive attacks) scenario is presented. NRS massive results allows the subsequent use of Artificial Intelligence to predict the robustness of new networks.","",""
0,"F. Marulli, S. Marrone, Laura Verde","Sensitivity of Machine Learning Approaches to Fake and Untrusted Data in Healthcare Domain",2022,"","","","",52,"2022-07-13 09:20:45","","10.3390/jsan11020021","","",,,,,0,0.00,0,3,1,"Machine Learning models are susceptible to attacks, such as noise, privacy invasion, replay, false data injection, and evasion attacks, which affect their reliability and trustworthiness. Evasion attacks, performed to probe and identify potential ML-trained models’ vulnerabilities, and poisoning attacks, performed to obtain skewed models whose behavior could be driven when specific inputs are submitted, represent a severe and open issue to face in order to assure security and reliability to critical domains and systems that rely on ML-based or other AI solutions, such as healthcare and justice, for example. In this study, we aimed to perform a comprehensive analysis of the sensitivity of Artificial Intelligence approaches to corrupted data in order to evaluate their reliability and resilience. These systems need to be able to understand what is wrong, figure out how to overcome the resulting problems, and then leverage what they have learned to overcome those challenges and improve their robustness. The main research goal pursued was the evaluation of the sensitivity and responsiveness of Artificial Intelligence algorithms to poisoned signals by comparing several models solicited with both trusted and corrupted data. A case study from the healthcare domain was provided to support the pursued analyses. The results achieved with the experimental campaign were evaluated in terms of accuracy, specificity, sensitivity, F1-score, and ROC area.","",""
0,"E. Kılıç, Hasan Riza Özçalik, Sami Şit","Artificial Neural Network Based Adaptive Speed Control System Design using Space Vector Pulse Width Modulation for Three-Phase Asynchronous Motor",2016,"","","","",53,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,3,6,"The widespread use of asynchronous motors in today's industry is due to their robustness, high efficiency and operational reliability. However, great difficulties due to the very complex and non-linear structure is experienced in controlling this motor. The recent advances in areas of microprocessors and power electronics, along with the new control strategies based on artificial intelligence has led asynchronous motors to be controlled more efficiently and reliably. Complex calculations such as coordinate transformations, field estimation algorithms and control algorithms used in the motor control can be easily done with digital signal processors which are powerful microcontrollers. As known, artificial neural networks which are among modern tools based on artificial intelligence are widely used for modeling and controlling nonlinear dynamical systems. In this study, a three-phase asynchronous motor speed control system was designed using a microcontroller labeled as dsPIC30F6010A. The rotor flux vector is estimated using the indirect field-oriented control technique, which is the most efficient scheme of vector control. The space vector pulse width modulation technique is used in the switching of the three-phase inverter. In order to improve the performance of the drive system, a speed control algorithm has been developed using a radial basis artificial neural network based model reference adaptive control method. The performance of the proposed control algorithm is experimentally tested by running the asynchronous motor under different speed and load conditions. The experimental results clearly demonstrate the success of the proposed control structure.","",""
103,"F. Granata, S. Papirio, G. Esposito, R. Gargano, G. D. Marinis","Machine Learning Algorithms for the Forecasting of Wastewater Quality Indicators",2017,"","","","",54,"2022-07-13 09:20:45","","10.3390/W9020105","","",,,,,103,20.60,21,5,5,"Stormwater runoff is often contaminated by human activities. Stormwater discharge into water bodies significantly contributes to environmental pollution. The choice of suitable treatment technologies is dependent on the pollutant concentrations. Wastewater quality indicators such as biochemical oxygen demand (BOD5), chemical oxygen demand (COD), total suspended solids (TSS), and total dissolved solids (TDS) give a measure of the main pollutants. The aim of this study is to provide an indirect methodology for the estimation of the main wastewater quality indicators, based on some characteristics of the drainage basin. The catchment is seen as a black box: the physical processes of accumulation, washing, and transport of pollutants are not mathematically described. Two models deriving from studies on artificial intelligence have been used in this research: Support Vector Regression (SVR) and Regression Trees (RT). Both the models showed robustness, reliability, and high generalization capability. However, with reference to coefficient of determination R2 and root‐mean square error, Support Vector Regression showed a better performance than Regression Tree in predicting TSS, TDS, and COD. As regards BOD5, the two models showed a comparable performance. Therefore, the considered machine learning algorithms may be useful for providing an estimation of the values to be considered for the sizing of the treatment units in absence of direct measures.","",""
6,"N. Sepulveda, J. Sinha","Parameter Optimisation in the Vibration-Based Machine Learning Model for Accurate and Reliable Faults Diagnosis in Rotating Machines",2020,"","","","",55,"2022-07-13 09:20:45","","10.3390/machines8040066","","",,,,,6,3.00,3,2,2,"Artificial intelligence (AI)-based machine learning (ML) models seem to be the future for most of the applications. Recent research effort has also been made on the application of these AI and ML methods in the vibration-based faults diagnosis (VFD) in rotating machines. Several research studies have been published over the last decade on this topic. However, most of the studies are data driven, and the vibration-based ML (VML) model is generally developed on a typical machine. The developed VML model may not predict faults accurately if applied on other identical machines or a machine with different operation conditions or both. Therefore, the current research is on the development of a VML model by optimising the vibration parameters based on the dynamics of the machine. The developed model is then blindly tested at different machine operation conditions to show the robustness and reliability of the proposed VML model.","",""
7,"Vasisht Duddu, N. Pillai, D. V. Rao, V. Balas","Fault Tolerance of Neural Networks in Adversarial Settings",2019,"","","","",56,"2022-07-13 09:20:45","","10.3233/JIFS-179677","","",,,,,7,2.33,2,4,3,"Artificial Intelligence systems require a through assessment of different pillars of trust, namely, fairness, interpretability, data and model privacy, reliability (safety) and robustness against against adversarial attacks. While these research problems have been extensively studied in isolation, an understanding of the trade-off between different pillars of trust is lacking. To this extent, the trade-off between fault tolerance, privacy and adversarial robustness is evaluated for the specific case of Deep Neural Networks, by considering two adversarial settings under a security and a privacy threat model. Specifically, this work studies the impact of the fault tolerance of the Neural Network on training the model by adding noise to the input (Adversarial Robustness) and noise to the gradients (Differential Privacy). While training models with noise to inputs, gradients or weights enhances fault tolerance, it is observed that adversarial robustness and fault tolerance are at odds with each other. On the other hand, ($\epsilon,\delta$)-Differentially Private models enhance the fault tolerance, measured using generalisation error, theoretically has an upper bound of $e^{\epsilon} - 1 + \delta$. This novel study of the trade-off between different elements of trust is pivotal for training a model which satisfies the requirements for different pillars of trust simultaneously.","",""
5,"P. Santhanam","Quality Management of Machine Learning Systems",2020,"","","","",57,"2022-07-13 09:20:45","","10.1007/978-3-030-62144-5_1","","",,,,,5,2.50,5,1,2,"","",""
2,"T. Hauer","Machine Ethics, Allostery and Philosophical Anti-Dualism: Will AI Ever Make Ethically Autonomous Decisions?",2020,"","","","",58,"2022-07-13 09:20:45","","10.1007/s12115-020-00506-2","","",,,,,2,1.00,2,1,2,"","",""
2,"Elizabeth J. Chang, Kit Yan Chan, Ponnie Clark, V. Potdar","Guest Editorial: Blockchain and AI Enabled 5G Mobile Edge Computing",2020,"","","","",59,"2022-07-13 09:20:45","","10.1109/TII.2020.2983764","","",,,,,2,1.00,1,4,2,"B IG data is generally captured by sensor networks in various industrial and manufacturing sectors; this big data is transmitted by mobile devices and Internet of Things (IoT) devices through the 5G mobile networks. 5G mobile edge computing is generally integrated with artificial intelligence (AI) in order to perform data mining for big data. 5G mobile edge computing attempts to help the industries to increase product quality, improve robustness and reliability of manufacturing processes, enhance manufacturing productivity and effectiveness, and reduce production costs. All those activities benefit consumers in the marketplace. The 5G mobile networks are connected and interacted within a huge number of industrial and manufacturing sectors. Data flows are interacting within a huge number of network nodes and routers. Therefore, data flow or mobile networks cannot be fully monitored. Fraud or dishonest data can be intentionally integrated or unintentionally contaminated. Although the 5G mobile edge computing is powerful, nevertheless unreliable data mining can only be performed, since wrong data is used. Recently, cryptocurrencies such as Bitcoin and Litecoins are used in virtual transactions by many financial sectors. Blockchain is integrated with the cryptocurrencies. Blockchain attempts to ensure security, trust and privacy of the virtual transactions, while centralized authorities or management are not necessary to be involved. Blockchain connects all transaction parties in order to monitor and verify each transaction. It reduces transaction risks and financial fraud without the involvement of centralized authorities or management. While blockchain is implemented in mobile devices and IoT devices, data trust and honesty can be guaranteed in the 5G mobile networks. When the captured data is more reliable, accurate data mining and analysis can be performed by the 5G mobile edge computing. This special section focus on 5G mobile edge computing methods in order to perform better data analysis, simulations, and predictions for industrial applications when blockchain is integrated in the 5G mobile networks. We received 30 high quality submissions for this special section on “Blockchain and AI Enabled 5G Mobile Edge Computing.” After the review and revision processes, six articles were selected to be published in this valuable document. The article “Efficient QoS Support for Robust Resource Allocation in Blockchain-Based Femtocell Networks” authored by","",""
1,"A. Gotlieb, D. Marijan, Helge Spieker","Testing Industrial Robotic Systems: A New Battlefield!",2020,"","","","",60,"2022-07-13 09:20:45","","10.1007/978-3-030-66494-7_4","","",,,,,1,0.50,0,3,2,"","",""
1,"T. Belbekri, B. Bouchiba, I. K. Bousserhane, H. Becheri","A study of sensorless vector control of IM using neural network luenberger observer",2020,"","","","",61,"2022-07-13 09:20:45","","10.11591/ijpeds.v11.i3.pp1259-1267","","",,,,,1,0.50,0,4,2,"Received Oct 26, 2019 Revised Feb 15, 2020 Accepted May 4, 2020 After the development of electronic components, the elimination of the sensors has become a necessary subject to get good results in the field of speed control, because of the price of the sensors, the strenuous choice of its position and the disturbance of measurement which affects the robustness of control. The luenberger observer showed to be one of the most excellent methods suggested by the researchers; this is due to the best performance, it offers in terms of stability, reliability and less counting effort. In this article, a study of luenberger observer based on neural network-based was discussed. This artificial intelligence method makes it possible to decrease the error of estimated speed for IRFOC control of the induction motor. Simulation results are obtained to show the robustness and stability of the system.","",""
0,"Yufeng Chen, Shaotong Pei, Yunpeng Liu, Yijin Liu, Ying Lin","Summary of Application Research of Deep Learning in Operational Inspection of Transmission and Distribution Equipment",2020,"","","","",62,"2022-07-13 09:20:45","","10.1088/1742-6596/1570/1/012057","","",,,,,0,0.00,0,5,2,"With the continuous expansion of artificial intelligence in power system, the reliability, security and operation ability of power system have been greatly improved. With the massive collection of data for transmission and transformation operation and maintenance, in-depth learning, as a typical representative of data-driven in the system of artificial intelligence methods, is increasingly appearing in the application scenarios of intelligent state assessment of transmission and transformation equipment. Its excellent robustness can eliminate many kinds of interference in complex environment background, accurately identify and evaluate the target points under test, and greatly reduce the detection of transportation and inspection personnel. The workload of data analysis, processing, evaluation and other links can improve work efficiency and accuracy. This paper attempts to summarize the development process of in-depth learning, relevant landmark achievements and typical applications in the operation and inspection of power transmission and transformation equipment. This paper attempts to summarize the research progress of target recognition, target segmentation, image classification algorithms in depth learning in different spectral cameras of visible light, ultraviolet corona imaging and infrared thermal imaging.","",""
0,"Dem Lee, Leo Yao, J. Lee","An Effective Accelerated Method to Verify the Creep Corrosion Failure Occurrence on Electronics",2020,"","","","",63,"2022-07-13 09:20:45","","10.1109/IMPACT50485.2020.9268558","","",,,,,0,0.00,0,3,2,"Due to the proliferation of Information Technology (IT) equipment applications, including Artificial Intelligence (AI), Big Data, 5G, Internet of Things (IoT), Edge Computing and High Performance Computing (HPC) in recent years. Therefore, the hardware reliability of IT equipment is paid more attention in the industry. With the more and more severe environmental pollution, the air quality will also directly or indirectly influence the life of IT equipment wherever indoor and outdoor. In general, the hardware reliability of IT equipment was easily affected by corrosive gases, moisture, contaminants and particulate matter. It can potentially cause the electrical short failure due to creep corrosion occurrence on corrosion sensitive components, Print Circuit Board (PCB) and PCB Assembly (PCBA). Therefore, it is very important to verify the robustness against creep corrosion occurrence for the future electronics. Creep corrosion is a kinds of failure mode of sulfur corrosion, the typical feature of creep corrosion can be observed from PCB and leadframe packages. In environments high in sulfur-bearing gaseous contamination, the major corrosive product; cuprous sulfide (Cu2S) was formed due to the bare copper exposure. The solid corrosion products migrated over a surface of solder mask and molding compound without the influence of an electric field. Besides, the extent of creep corrosion may be so high as to electrically short circuit adjacent pads and traces, causing the electrics to malfunction which be known as the creep corrosion failure. Mixed Flowing-Gas (MFG) and Flower of Sulfur (FoS) were adopted widely for all suppliers in the industry. To consider that traditional testing method: MFG is expensive, long testing duration; and typical FoS testing of ASTM B809 standard is relatively inexpensive, short testing duration, but cannot verify the creep corrosion. In the light of the above, the International Electronics Manufacturing Initiative (iNEMI) has published a White Paper regarding the creep corrosion verification in August, 2018. The iNEMI project team, including the leading 3rd party testing lab for electronics verification: Integrated Service Technology (iST) and international branding system house: IBM, Lenovo, Nokia, Dow. etc. have analyzed the reason of creep corrosion occurrence and also developed a cost-effective and convenient testing method: iNEMI FoS test which is sufficiently well developed for consideration as an industry standard qualification test for creep corrosion To hope that iNEMI FoS test can assist the all suppliers to find out the prevention action and solution of creep corrosion failure occurrence in the industry. In this paper, we will present some case studies as well as solution cases by using iNEMI FoS test.","",""
0,"Antony Fan, Joddv Wang, Vladimir Aptekar","Advanced Circuit Verification for Robust Design",2020,"","","","",64,"2022-07-13 09:20:45","","10.1109/ICSICT49897.2020.9278330","","",,,,,0,0.00,0,3,2,"The growth in Artificial Intelligence, advanced 5G wireless network, cloud computing, safety-critical automotive electronics and mainstream adoption of FinFET technologies have resulted in significant increase in IC design robustness challenges. IC designers must contend with advanced circuit complexity with stringent requirements on performance, low power, design robustness for safety, and reliability such as electro-migration and device-aging. For safety-critical applications such as Autonomous Driving, ADAS, and Connected Car, IC designers are now looking to adopt rigorous and systematic methodologies to meet functional safety standard. In this paper, we will discuss the models used on circuit reliability verification, and application of these models to assess IC reliability and variability for targeted requirements with latest Synopsys' AMS solution for robust design.","",""
0,"J. Filipe, Ashish Ghosh, R. Prates, O. Shehory, E. Farchi, Guy Barash","Engineering Dependable and Secure Machine Learning Systems: Third International Workshop, EDSMLS 2020, New York City, NY, USA, February 7, 2020, Revised Selected Papers",2020,"","","","",65,"2022-07-13 09:20:45","","10.1007/978-3-030-62144-5","","",,,,,0,0.00,0,6,2,"","",""
0,"A. Bilal, Guangmin Sun","Neuro-optimized numerical solution of non-linear problem based on Flierl–Petviashivili equation",2020,"","","","",66,"2022-07-13 09:20:45","","10.1007/s42452-020-2963-1","","",,,,,0,0.00,0,2,2,"","",""
8,"Miriyev","A Focus on Soft Actuation",2019,"","","","",67,"2022-07-13 09:20:45","","10.3390/act8040074","","",,,,,8,2.67,8,1,3,"The present editorial paper analyzes the hundred recent research works on soft actuation to understand the current main research focus in the light of the grand challenges in the field. Two characteristic paper types were obtained: one focuses on soft actuator design, manufacturing and demonstration, while another includes in addition the development of functional materials. Although vast majority of the works showcased soft actuation, evaluation of its robustness by multi-cyclic actuation was reported in less than 50% of the works, while only 10% described successful actuation for more than 1000 cycles. It is suggested that broadening the research focus to include investigation of mechanisms underlying the degradation of soft functional material performance in real cyclic actuation conditions, along with application of artificial intelligence methods for prediction of muscle behavior, may allow overcoming the reliability issues and developing robust soft-material actuators. The outcomes of the present work might be applicable to the entire soft robotics domain.","",""
8,"Tanmoy Bhattacharya, T. Brettin, J. Doroshow, Yvonne A. Evrard, E. Greenspan, A. Gryshuk, T. Hoang, Carolyn B. Lauzon, D. Nissley, Lynne Penberthy, E. Stahlberg, R. Stevens, F. Streitz, G. Tourassi, Fangfang Xia, George F. Zaki","AI Meets Exascale Computing: Advancing Cancer Research With Large-Scale High Performance Computing",2019,"","","","",68,"2022-07-13 09:20:45","","10.3389/fonc.2019.00984","","",,,,,8,2.67,1,16,3,"The application of data science in cancer research has been boosted by major advances in three primary areas: (1) Data: diversity, amount, and availability of biomedical data; (2) Advances in Artificial Intelligence (AI) and Machine Learning (ML) algorithms that enable learning from complex, large-scale data; and (3) Advances in computer architectures allowing unprecedented acceleration of simulation and machine learning algorithms. These advances help build in silico ML models that can provide transformative insights from data including: molecular dynamics simulations, next-generation sequencing, omics, imaging, and unstructured clinical text documents. Unique challenges persist, however, in building ML models related to cancer, including: (1) access, sharing, labeling, and integration of multimodal and multi-institutional data across different cancer types; (2) developing AI models for cancer research capable of scaling on next generation high performance computers; and (3) assessing robustness and reliability in the AI models. In this paper, we review the National Cancer Institute (NCI) -Department of Energy (DOE) collaboration, Joint Design of Advanced Computing Solutions for Cancer (JDACS4C), a multi-institution collaborative effort focused on advancing computing and data technologies to accelerate cancer research on three levels: molecular, cellular, and population. This collaboration integrates various types of generated data, pre-exascale compute resources, and advances in ML models to increase understanding of basic cancer biology, identify promising new treatment options, predict outcomes, and eventually prescribe specialized treatments for patients with cancer.","",""
6,"O. Akinsete, Adebayo Oshingbesan","Leak Detection in Natural Gas Pipelines Using Intelligent Models",2019,"","","","",69,"2022-07-13 09:20:45","","10.2118/198738-MS","","",,,,,6,2.00,3,2,3,"  Detection of small leaks in gas pipelines is an important and persistent problem in the oil and gas industry. However, the industry is beginning to investigate how tools of Machine Learning, Artificial Intelligence, Big Data, etc. can be used to improve current industry processes.  This work aims to study the ability of intelligent models to detect small leaks in a natural gas pipeline using operational parameters such as pressure, temperature and flowrate through existing industry performance metrics (sensitivity, reliability, robustness and accuracy). Observer design technique was applied to detect leaks in a gas pipeline using a regresso-classification hierarchical model where an intelligent model acts as a regressor and a leak detection algorithm acts as a classifier. Five intelligent models (Gradient Boosting, Decision Trees, Random Forest, Support Vector Machine and Artificial Neural Network) were used in this present work.  Results showed that the Random Forest and Decision Tree models are the most sensitive as they can detect a leak of 0.1% of nominal flow in about 2 hours. All the intelligent models had high reliability with zero false alarm rate in testing phase. However, due to this level of reliability, the models had low accuracy with the Artificial Neural Network and Support Vector Machine performing best and better regressors than the others. All the intelligent models are robust. The average time to leak detection for different leak sizes for all the intelligent models were compared to a real time transient model in literature. The intelligent models had a time savings of 25% to 48%.  Results in this present work further suggest that intelligent models could be used alongside a real time transient model to improve leak detection. Also, that the tools of big data, data analytics, artificial intelligence can be harnessed to improving leak detection results.","",""
6,"A. Munawar, G. Fischer","An Asynchronous Multi-Body Simulation Framework for Real-Time Dynamics, Haptics and Learning with Application to Surgical Robots",2019,"","","","",70,"2022-07-13 09:20:45","","10.1109/IROS40897.2019.8968594","","",,,,,6,2.00,3,2,3,"Surgical robots for laparoscopy consist of several patient side slave manipulators that are controlled via surgeon operated master telemanipulators. Commercial surgical robots do not perform any sub-tasks – even of repetitive or noninvasive nature – autonomously or provide intelligent assistance. While this is primarily due to safety and regulatory reasons, the state of such automation intelligence also lacks the reliability and robustness for use in high-risk applications. Recent developments in continuous control using Artificial Intelligence and Reinforcement Learning have prompted growing research interest in automating mundane sub-tasks. To build on this, we present an inspired Asynchronous Framework which incorporates realtime dynamic simulation – manipulable with the masters of a surgical robot and various other input devices – and interfaces with learning agents to train and potentially allow for the execution of shared sub-tasks. The scope of this framework is generic to cater to various surgical (as well as non-surgical) training and control applications. This scope is demonstrated by examples of multi-user and multi-manual applications which allow for realistic interactions by incorporating distributed control, shared task allocation and a well-defined communication pipe-line for learning agents. These examples are discussed in conjunction with the design philosophy, specifications, system-architecture and metrics of the Asynchronous Framework and the accompanying Simulator. We show the stability of Simulator while achieving real-time dynamic simulation and interfacing with several haptic input devices and a training agent at the same time.","",""
1,"Shu Zhang, Ge Yan, Yu Li, Jia Liu","Evaluation of Judicial Imprisonment Term Prediction Model Based on Text Mutation",2019,"","","","",71,"2022-07-13 09:20:45","","10.1109/QRS-C.2019.00025","","",,,,,1,0.33,0,4,3,"In recent years, artificial intelligence has witnessed great advancement, and its application in the legal field has experienced more than 60 years. The use of ""machine learning"" technology to aid the decision-making of legal intelligence systems is no longer far away. However, no comprehensive evaluation methods for predictive models of judicial cases can be found. The performance of the machine learning prediction model not only related to the accuracy but also should be measured in many different aspects. Mutation is a common means of traditional software testing, which can be borrowed in the evaluating of prediction models. This paper introduces the text mutation method, to evaluate the robustness of the judicial case prediction model. The following three evaluation methods are adopted: Classification preference test, Word order variation test and Noise variation test. This paper applies the proposed evaluation method to the judicial imprisonment term prediction model. We use the fastText, TextCNN, and Multi-layer LSTM models. Using the proposed evaluation method to test the above prediction model, and evaluate the robustness of the judicial case prediction model in different aspects.","",""
0,"Christophe Gaston, N. Kosmatov, P. L. Gall","Testing Software and Systems: 31st IFIP WG 6.1 International Conference, ICTSS 2019, Paris, France, October 15–17, 2019, Proceedings",2019,"","","","",72,"2022-07-13 09:20:45","","10.1007/978-3-030-31280-0","","",,,,,0,0.00,0,3,3,"","",""
115,"C. T. Raj, S. P. Srivastava, P. Agarwal","Energy Efficient Control of Three-Phase Induction Motor - A Review",2009,"","","","",73,"2022-07-13 09:20:45","","10.7763/IJCEE.2009.V1.10","","",,,,,115,8.85,38,3,13,"Due to robustness, reliability, low price and maintenance free, induction motors (IMs) used in most of the industrial applications. The influence of these motors (in terms of energy consumption) in energy intensive industries is significant in total input cost. This paper presents a review of the developments in the field of efficiency optimization of three-phase induction motor through optimal control and design techniques. Optimal control covers both the broad approaches namely, loss model control (LMC) and search control (SC). Optimal design covers the design modifications of materials and construction in order to optimize efficiency of the motor. The use of Artificial Intelligence (AI) techniques such as artificial neural network (ANN), fuzzy logic, expert systems and nature inspired algorithms (NIA), Genetic algorithm and differential evolution in optimization are also included in this paper. Experimental and simulation examples on efficiency optimization are illustrated.","",""
0,"C. Rico, Mayerly Paredes, N. Fernández","Modeling of the Hierarchical Structure of Freshwater Macroinvertebrates Using Artificial Neural Networks",2009,"","","","",74,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,3,13,"The study of hierarchical structures of ecological communities has been synthesized in an ordinary way by means of multivariated techniques of ordination or clustering. Currently, analytical tools of bio-inspired computation belonging to the area of artificial intelligence are available to achieve ecological models with desirable characteristics, such as; flexibility, accuracy, robustness and reliability. In this context, this study employed two computational methods useful in ecoinformatics referring to artificial neural networks (RNAR) for the modeling of the hierarchical structure of a benthic macroinvertebrate community in self-organization and prediction terms. The first ANN modeling method consisted of a Kohonen self-organization map (SOM), a nonsupervised learning tool that classify the species of macroinvertebrates; this SOM in the input layer of gets the abundance of each ‘taxa’ from the data matrix, while in the output layer was visualized the computational results. Thus, in the output layer the species are organized in fifteen units and four hierarchical clusters. The second ANN method applied consisted of a multilayer feed-forward perceptron net with back-propagation algorithm to predict the three major insect orders; this means, Ephemeroptera, Coleoptera and Trichoptera (ECT) richness and abundance using a set of nine physical-chemical variables. This ANN architecture included a neuron for each environmental variable, a hidden layer with seven neurons and a neuron in the output layer for ECT prediction. The results suggest that both types of ANN used, SOM and perceptron, were correspondingly related to the hierarchical patterns and with the richness and abundance patterns’ predictions, and gave the data analysis and understanding of the dynamic of the macroinvertebrates community, in a correct way.","",""
4,"A. Soualhi, Sofiane Taleb","Data fusion for fault severity estimation of ball bearings",2018,"","","","",75,"2022-07-13 09:20:45","","10.1109/ICIT.2018.8352514","","",,,,,4,1.00,2,2,4,"Rotating machines, such as asynchronous and synchronous motors, are considered as vital electromechanical systems in the industrial sector because of their low cost and robustness. However, 40% of their failures are due to bearing faults. In order to avoid these failures, monitoring methods need to be developed to ensure the reliability and safety of these machines. The presented paper proposes the use of temporal and frequency analysis to extract degradation indicators. These indicators will be injected into an artificial intelligence system coupled with the fuzzy logic to estimate the fault size of bearings. The system is ANFIS (Adaptive Neuro Fuzzy Inference System) and is used to estimate the fault size of bearings. Vibration signals provided by the Case Western Reserve University laboratory were used to validate the proposed method. The obtained results show the efficiency of the data fusion for estimating the fault size of ball bearings.","",""
0,"N. Homma, K. Fuchigami, M. Sakai, Takakuni Goto, K. Abe","Natural intelligence: noise-resistance of neural spike communication",2008,"","","","",76,"2022-07-13 09:20:45","","10.1007/s10015-007-0485-1","","",,,,,0,0.00,0,5,14,"","",""
0,"G. Nieto, Francisco Javier.","Analysis of radiofrequency-based methods for position and velocity determination of autonomous robots in lunar surface exploration missions",2018,"","","","",77,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,2,4,"The use of distributed systems has been disruptive in almost any industrial sector, from manufacturing to processing plants from environmental monitoring to vehicle control, and many more. It is therefore natural to assess the benefits that such an advantageous engineering paradigm could bring to space exploration. In recent years, we have been witness to the emergence of concepts such as fractionated satellite systems, formation flying, megaconstellations, and femtoswarms. Most of these space missions have evolved from the idea of a decentralization of processes that were formerly performed in platforms conceived as monolithic systems.    The application of this concept to robotic systems is not new, and a great deal of scientific contributions on multi-robot systems exists, focusing on different aspects such as cooperative robotics, behavioural or reactive control, distributed artificial intelligence, swarm multi-agent systems etc. The intrinsic advantages of distribution (improved reliability and efficiency, higher robustness, etc.) has been boosted by the exponential growing of computational power density and a simultaneous miniaturization of technology, leading to smaller and more powerful robotic platforms, which could make a distributed robotic system, made of small robotic agents, a powerful substitute to classical large robotic platforms.    This thesis proposes, in the framework of multi-robot systems, a localization method for robotic agents in planetary surface exploration scenarios based on RF range and Doppler frequency shift analysis. The relevance of spatial localization awareness in agents belonging to a distributed robotic system is defined in the context of the advantages of robotic exploration. Different range determination techniques and, specifically, the advantages of including Doppler Effect in the determination of the relative position within the robotic system deployed are considered and the strengths and weaknesses analysed accordingly. Special attention is devoted to the noise sources present in the lunar environment, related to a practical (i.e. non-ideal) implementation architecture and its influence on the system performance. From this point of view, we develop a theoretical model for localization accuracy estimation, generated from power spectrum characteristics, in accordance with the system architecture proposed, and consolidated with numerical simulations and a parametrical assessment on a set of real references of components playing a key role in the overall performance.    The selected system architecture is then implemented in a representative set-up and tested under laboratory conditions. Algorithms used for carrier frequency generation and frequency measurement are developed, applied and tested in the hardware-on-the-loop breadboard. The results show that Doppler frequency component can be measured with the proposed architecture, yielding a high sensitivity in the determination of relative speed even at standard communication frequencies (UHF), and improving significantly at higher bands (S, C, etc.). This enables the possibility of adding relative speed to relative position determination via sensor fusion techniques, improving the response time and accuracy during navigation through the exploration scenario.","",""
12,"Z. Sabir, M. Raja","Numeric treatment of nonlinear second order multi-point boundary value problems using ANN, GAs and sequential quadratic programming technique",2014,"","","","",78,"2022-07-13 09:20:45","","10.5267/J.IJIEC.2014.3.004","","",,,,,12,1.50,6,2,8,"In this paper, computational intelligence technique are presented for solving multi - point nonlinear boundary value problems based on artificial neural networks, evolutionary computing approach, and active-set technique. The neural network is to provide convenient methods for obtaining useful model based on unsupervised error for the differential equations. The motivation for presenting this work comes actually from the aim of introducing a reliable framework that combines the powerful features of ANN optimized with soft computing frameworks to cope with such challenging system. The applicability and reliability of such methods have been monitored thoroughly for various boundary value problems arises in science, engineering and biotechnology as well. Comprehensive numerical experimentations have been performed to validate the accuracy, convergence, and robustness of the designed scheme. Comparative studies have also been made with available standard solution to analyze the correctness of the proposed scheme.","",""
11,"A. Rawat","Energy Efficient Control of Three-Phase Induction Motor - A Review",2014,"","","","",79,"2022-07-13 09:20:45","","","","",,,,,11,1.38,11,1,8,"Due to robustness, reliability, low price and maintenance free, induction motors (IMs) used in most of the industrial applications. The influence of these motors (in terms of energy consumption) in energy intensive industries is significant in total input cost. This paper presents a review of the developments in the field of efficiency optimization of three-phase induction motor through optimal control and design techniques. Optimal control covers both the broad approaches namely, loss model control (LMC) and search control (SC). Optimal design covers the design modifications of materials and construction in order to optimize efficiency of the motor. The use of Artificial Intelligence (AI) techniques such as artificial neural network (ANN), fuzzy logic, expert systems and nature inspired algorithms (NIA), Genetic algorithm and differential evolution in optimization are also included in this paper. Experimental and simulation examples on efficiency optimization are illustrated.","",""
131,"R. Stengel","Intelligent failure-tolerant control",1990,"","","","",80,"2022-07-13 09:20:45","","10.1109/ISIC.1990.128511","","",,,,,131,4.09,131,1,32,"An overview of failure-tolerant control is presented, beginning with robust control, progressing through parallel and analytical redundancy, and ending with rule-based systems and artificial neural networks. By design or implementation, failure-tolerant control systems are 'intelligent' systems. All failure-tolerant systems require some degree of robustness to protect against catastrophic failure; failure tolerance often can be improved by adaptivity in decision making and control, as well as by redundancy in measurement and actuation. Reliability, maintainability, and survivability can be enhanced by failure tolerance, although each objective poses different goals for control system design. Artificial intelligence concepts are helpful for integrating and codifying failure-tolerant control systems, not as alternatives but as adjuncts to conventional design methods.<<ETX>>","",""
7,"O. Kaynak, E. Grant, G. Honderd","Intelligent Systems: Safety, Reliability and Maintainability Issues",1993,"","","","",81,"2022-07-13 09:20:45","","10.1007/978-3-642-58021-5","","",,,,,7,0.24,2,3,29,"","",""
3,"E. Kılıç, Osman Doğmuş, A. Gani, Sami Şit, Hasan Riza Özçalik","Simulation and Experimental Study of Vector Controlled Induction Motor Drive based on RBFNN-MRAC Controller",2017,"","","","",82,"2022-07-13 09:20:45","","","","",,,,,3,0.60,1,5,5,"This article presents implementation of model reference adaptive control (MRAC) based on radial basis function neural network (RBFNN) for vector controlled induction motor drive at real time. The widespread use of induction motors in today's industry is due to their robustness, high efficiency and operational reliability. However, great difficulties due to the very complex and non-linear structure are experienced in controlling this motor. The recent advances in areas of microprocessors and power electronics, along with the new control strategies based on artificial intelligence has led induction motors to be controlled more efficiently and reliably. Complex calculations such as coordinate transformations, field estimation algorithms and control algorithms used in the motor control can be easily done with digital signal processors which are powerful microcontrollers. In this study, a three-phase induction motor speed control system was designed using a microcontroller labeled as dsPIC30F6010A. The system consists of control board based on dsPIC30F6010A device, power module, three phase induction motor and DC generator that acts as a proper load. The rotor flux vector is estimated using the indirect field-oriented control technique, which is the most efficient scheme of vector control. The space vector pulse width modulation technique (SVPWM) is used in the switching of the three-phase inverter. The results show that the proposed RBFNN based MRAC scheme has better tracking performance than conventional PI controller for different references and loading conditions. The success and superiority of the proposed RBFNN based MRAC controller over the conventional PI controller was demonstrated by simulation and experimental studies.","",""
3,"Tong-Yuen Chai, B. Goi, Yong Haur Tay, Wen-Jet Nyee","A Trainable Method For Iris Recognition Using Random Feature Points",2017,"","","","",83,"2022-07-13 09:20:45","","10.1109/TAAI.2017.39","","",,,,,3,0.60,1,4,5,"Iris feature is widely used in recognition due to its uniqueness and reliability among other biometrics. Iris pattern is generally complex containing randomness and distinctive features such as furrows, freckles and crypts. It is still an uncertainty how useful each of these features will be when it comes to recognition. In this paper, we formulate the recognition problem in a semi-naïve Bayesian classification framework to maintain simplicity and robustness. A nonhierarchical structure is adopted to classify random feature sets in different ferns. Each feature set is a new binary representation and returns the probability that it belongs to any of the classes learned during training. The proposed method can synthesize multiple views of the iris features from a training image as they would appear under different scales and perspectives. The outcomes are then combined in a semi-naïve Bayesian manner. This new approach has been evaluated on CASIA iris database and benchmarked with Random Forest classifier and Hamming distance. The proposed method shows shorter processing time and lower equal error rate compared to other methods.","",""
37,"T. Nanayakkara, F. Sahin, M. Jamshidi","Intelligent Control Systems with an Introduction to System of Systems Engineering",2009,"","","","",84,"2022-07-13 09:20:45","","10.1201/9781315218649","","",,,,,37,2.85,12,3,13,"Apply NASA SoS Innovations to Your Own Work From aeronautics and manufacturing to healthcare and disaster management, systems engineering (SE) now focuses on designing applications that ensure performance optimization, robustness, and reliability while combining an emerging group of heterogeneous systems to realize a common goal. Use SoS to Revolutionize Management of Large Organizations, Factories, and Systems Intelligent Control Systems with an Introduction to System of Systems Engineering integrates the fundamentals of artificial intelligence and systems control in a framework applicable to both simple dynamic systems and large-scale system of systems (SoS). For decades, NASA has used SoS methods, and major manufacturersincluding Boeing, Lockheed-Martin, Northrop-Grumman, Raytheon, BAE Systemsnow make large-scale systems integration and SoS a key part of their business strategies, dedicating entire business units to this remarkably efficient approach. Simulate Novel Robotic Systems and ApplicationsTranscending theory, this book offers a complete and practical review of SoS and some of its fascinating applications, including: Manipulation of robots through neural-based network control Use of robotic swarms, based on ant colonies, to detect mines Other novel systems in which intelligent robots, trained animals, and humans cooperate to achieve humanitarian objectives Training engineers to integrate traditional systems control theory with soft computing techniques further nourishes emerging SoS technology. With this in mind, the authors address the fundamental precepts at the core of SoS, which uses human heuristics to model complex systems, providing a scientific rationale for integrating independent, complex systems into a single coordinated, stabilized, and optimized one. They provide readers with MATLAB code, which can be downloaded from the publisher's website to simulate presented results and projects that offer practical, hands-on experience using concepts discussed throughout the book.","",""
9,"F. Maturana, R. Staron, K. Loparo, D. Carnahan","Agent-based testbed simulator for power grid modeling and control",2012,"","","","",85,"2022-07-13 09:20:45","","10.1109/ENERGYTECH.2012.6304661","","",,,,,9,0.90,2,4,10,"As control systems become more complex, increased levels of testing and validation can lead to improvements in their robustness and reliability. In this paper, the authors describe a testing and validation system in which control and plant algorithms are executed on real-time targets in a multi-agent platform, then mapped to a distributed simulation platform. This simulation platform combines state-of-the-art control automation, simulation and artificial intelligence technology into an integrated testbed simulation platform, allowing different aspects of new generation power grid management and control to be tested and measured. Preliminary results from this testing have provided important advances toward an understanding of information management in highly dynamic distributed power systems.","",""
0,"Youngchul Bae, Yong Soo Kim, F. Rhee, Yong-Tae Kim, C. Tao","Editorial Message: Special Issue on Fuzzy System in Data Mining and Knowledge Discovery: Modelling and Application",2017,"","","","",86,"2022-07-13 09:20:45","","10.1007/S40815-017-0359-1","","",,,,,0,0.00,0,5,5,"","",""
16,"H. Sarvari, K. Zamanifar","Improvement of harmony search algorithm by using statistical analysis",2012,"","","","",87,"2022-07-13 09:20:45","","10.1007/s10462-011-9226-x","","",,,,,16,1.60,8,2,10,"","",""
4,"Ekhlas Mhawi, H. Daniyal, M. Sulaiman","Advanced Techniques in Harmonic Suppression via Active Power Filter: A Review",2015,"","","","",88,"2022-07-13 09:20:45","","10.11591/IJPEDS.V6.I2.PP185-195","","",,,,,4,0.57,1,3,7,"This paper intends to present the recent development of artificial intelligence (AI) applications in active power filter (APF). As a result of the development in power electronic technology, (APF) continues to attract ample attention. Compared with the traditional reactive LC filter, active power filter is considered to be more effective in compensating harmonic current generated by nonlinear loads.APF, can correct the power quality and improve the reliability and stability on power utility. A brief explanation of some important areas in AI and a comprehensive survey of the literature along the main categories of AI is presented to introduce the readers into the wide-ranging topics that AI encompasses. Plenty of relevant literatures have been selected in the review, mostly emphasized on better accuracy, robustness, efficiency, stability and tracking ability of the system.","",""
4,"Ren Feiyi, Yu Jinsong","Fault diagnosis methods for advanced diagnostics and prognostics testbed (ADAPT): A review",2015,"","","","",89,"2022-07-13 09:20:45","","10.1109/ICEMI.2015.7494248","","",,,,,4,0.57,2,2,7,"Nowadays in industrial processes, whether producers or users think highly of performance reliability and robustness of equipments. Therefore, the FDI (Fault detection and isolation) and maintenance techniques have become hot topics for health management of industrial units, as a safety guarantee indeed. As a consequence, researchers have made great efforts to develop, verify and refine diverse diagnosis techniques, meanwhile compare and screening them in order to apply them properly in practice. And then, NASA Ames has built the Advanced Diagnostics and Prognostics Testbed, a real-world system as a general platform for verification and validation (V&V) of diagnosis techniques. Until now, many researchers have developed effective diagnosis algorithms specially applied to this system. In this paper, we introduce the ADAPT and the diagnosis competition around the system, and we review a variety of diagnosis methods divided mainly in three types, model-based, optimization-based and artificial intelligence-based methods, while elaborating the first type in detail by two sorts of model: physical and graphic, of which the second attracts more and more attention of scientists in actual research. Finally, we make a comparison among them based on simplified metrics of qualification, which plays an important role in choosing appropriate methods for diagnosing a special problem.","",""
4,"S. Uckun, R. Mackey, M. Do, R. Zhou, Eric Huang, J. Shah","Measures of product design adaptability for changing requirements",2014,"","","","",90,"2022-07-13 09:20:45","","10.1017/S0890060414000523","","",,,,,4,0.50,1,6,8,"Abstract Adaptability can have many different definitions: reliability, robustness, survivability, and changeability (adaptability to requirements change). In this research, we focused entirely on the last type. We discuss two alternative approaches to requirements change adaptability. One is the valuation approach that is based on utility and cost of design changes in response to modified requirements. The valuation approach is theoretically sound because it is based on utility and decision theory, but it may be difficult to use in the real world. The second approach is based on examining product architecture characteristics that facilitate changes that include modularity, hierarchy, interfaces, performance sensitivity, and design margins. This approach is heuristic in nature but more practical to use. If calibrated, it could serve as a surrogate for real adaptability. These measures were incorporated in a software tool for exploring alternative configurations of fractionated space satellite systems.","",""
0,"José Navarro Alabarta","Evaluación mediante simulación de redes de sensores aplicadas a robots móviles",2016,"","","","",91,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,1,6,"This master thesis presents a study of routing protocols for vehicular networks. These protocols are divided into two main groups: protocols based on routing and protocols based on geographical location. The first group is divided into two groups, proactive and reactive protocols. The difference between these two subtypes of protocols is that the necessary control information is obtained when needed in the reactive protocols while proactive protocols are constantly sending and requesting control information. The most representative reactive protocols are AODV and DSR, and the most representative proactive protocols are OLSR and DSDV. On the other hand, geolocation based protocols are characterized by the necessity of GPS devices to work properly. In recent years, protocols of this last type have been improved applying artificial intelligence techniques to optimize their functioning and increase their robustness and reliability. All these protocols are integrated with intelligent transport systems. In this way, the goal with these systems is to reduce the number of accidents among other factors that affect driving. Regarding the experimental phase, the process is divided into several sub-steps, the first involves the design and development of robust and reliable protocols. Once this step has been passed driving trends should be obtained with the mobility simulators in order to be provided to the network simulators to study and evaluate the behavior and performance. This stage allows iterate over it, so that according to the results you can refine the specification, also allows the evaluation of proposals with a large number of devices without additional costs. Finally, last step consists on the real implementation on physical devices. This TFM covers the first two described stages, being a necessary work that will allow the development of future lines dedicated to improve based on GPS routing protocols that can be applied to both vehicles and mobile robots. Additionally, a complete ecosystem for the design and evaluation of such protocols has been proposed in this thesis. In this line, a model for VANETs routing protocol with new characteristics has been developed and validated. After that, an exhaustive experimentation and evaluation using the proposed ecosystem has been conducted. Finally, early implementations and testing on real hardware that will allow the application of the proposed protocols also have already been carried out, with very interesting results.","",""
0,"R. Doyle, Steve Ankuo Chien, D. Kortenkamp, M. Woods","Introduction to the Special Issue on Intelligent Systems for Space Exploration",2016,"","","","",92,"2022-07-13 09:20:45","","10.2514/1.I010487","","",,,,,0,0.00,0,4,6,"S PACEmissions are faced with numerous challenges, in which the thoughtful application of automation and autonomy and the integration of artificial intelligence (AI) techniques can contribute significantly and directly to mission success. Among these challenges are operating in uncertain and extreme environments, managing scarce resources such as power, communications, and computation under severe constraints, and grappling with light-time delays, as well as accomplishing unprecedented functionality such as precision landing on planetary surfaces and achieving science return supportive of discovery, all thewhile grapplingwith the intricate complexity of systems engineering tied to requirements for reliability, robustness, and safety. This Special Issue of the Journal for Aerospace Information Systems pertains to intelligent systems for space exploration. Its publication was inspired by the International Symposium for Artificial Intelligence, Robotics, and Automation in Space (iSAIRAS) conference series. However, there was no requirement that work collected in this issue be derived specifically from reports at an iSAIRAS conference. As guest editors, we solicited work across the following scope of interest: 1) space-based demonstration or application of intelligent systems concepts, 2) ground-based demonstration of autonomous space systems concepts, 3) ground-based demonstration or application of mission operations automation, and 4) laboratory demonstration of AI-based concepts for space missions. Within this general scope, relevant technical topics included space systems autonomy (onboard software for mission planning and execution; resource management; fault protection; science data analysis; guidance, navigation, and control; smart sensors; testing and validation; and architectures) and mission operations automation (decision support tools for mission planning and scheduling, anomaly detection and fault analysis, innovative operations concepts, data visualization, secure commanding and networking, and human–robotic teaming). Submitters were asked to provide technical descriptions of systems and results and analysis of experimentation. Lessons learned in development and operations were also solicited, as relates to systems engineering, testing, and validation. As a final consideration of scope, we encouraged papers addressing any operating regime for space exploration from Earth orbit to deep space (planetary and small-body orbital environments and surfaces), including both robotic and human–robotic mission concepts. In the end, it is clear that there is an abundance of quality research being conducted internationally within the identified scope. The five articles appearing here represent that scope as aworthy sample, but do not come close to exhausting the relevantwork of high quality that is underway. The following is a summary of the specific content of this Special Issue. An implicit but important challenge in achieving success with autonomy, beyond the critical-path research challenges, involves working with end users and stakeholders tomake the case for the added value andmanaged risk of the new capability, often in the face of initial skepticism. Burl et al. describe not only their technical success to develop an autonomous vision-based capability to detect scientifically interesting phenomena on the surface of Mars, but also provide details of what it takes to successfully deploy such an unprecedented capability. An architecture that has proven useful for supporting autonomous science operations is one that enables event detection and response. Chien et al. report on just such an architecture, hosting capabilities for classifying content and determining salient features within images collected by an Earth observing hyperspectral instrument, integrated with an onboard (re)planning capability for scheduling additional observations, while respecting resource and other operating constraints, all demonstrated on a CubeSat platform. As future space exploration grows in scale, missions will increase in scope and deploy ever greater numbers of assets to other bodies for extended missions of years or more. In this evolution, missions will need robotic explorers to act with increasing autonomy. Yliniemi et al. highlight work in developingmulti-agent learning systems that present a promising approach to addressing learning andmulti-agent coordination for such future missions. A basicmotivation for provisioning a platformwith autonomy capability is to have an effectivemeans of grapplingwith operational uncertainty in a remote environment. Burroughes et al. describe an architectural approach and formalism for responding to the inevitable unforeseen events through informed reconfiguration of the system. They assess the computational efficiency of their approach through experimentation. One persistent challenge in space exploration is onboard data management. Spacecraft have ever-increasing capabilities to acquire large amounts of science data, but limited ability to store and downlink such data. This challenge is complicated by the prevalence of content-dependent compression schemes, which make prediction of the amount of data acquired uncertain. Maillard et al. present an approach that involves both the flight and ground system to adaptively manage the data acquired, stored, and downlinked to optimize spacecraft operations. TheGuest Editors hope that readers will find these articles edifying as to current research topics, as well as state-of-the-art autonomy capability for space systems. The Guest Editors also wish to thank all authors who submitted articles and the set of capable reviewers.","",""
9,"Emilio Ferrara, Robert Baumgartner","Design of Automatically Adaptable Web Wrappers",2011,"","","","",93,"2022-07-13 09:20:45","","10.5220/0003131802110217","","",,,,,9,0.82,5,2,11,"Nowadays, the huge amount of information distributed through the Web motivates studying techniques to  be adopted in order to extract relevant data in an efﬁcient and reliable way. Both academia and enterprises  developed several approaches of Web data extraction, for example using techniques of artiﬁcial intelligence or  machine learning. Some commonly adopted procedures, namely wrappers, ensure a high degree of precision  of information extracted from Web pages, and, at the same time, have to prove robustness in order not to  compromise quality and reliability of data themselves.  In this paper we focus on some experimental aspects related to the robustness of the data extraction process  and the possibility of automatically adapting wrappers. We discuss the implementation of algorithms for  ﬁnding similarities between two different version of a Web page, in order to handle modiﬁcations, avoiding  the failure of data extraction tasks and ensuring reliability of information extracted. Our purpose is to evaluate  performances, advantages and draw-backs of our novel system of automatic wrapper adaptation.","",""
2,"R. Dumitrescu, H. Anacker, F. Bauer, J. Gausemeier","Computer Support for the Identification of Solution Patterns for the Conceptual Design of Advanced Mechatronic Systems",2012,"","","","",94,"2022-07-13 09:20:45","","10.1115/ESDA2012-82350","","",,,,,2,0.20,1,4,10,"Within the last years mechatronics as a self-contained discipline doubtlessly shaped the development of technical systems. Mechatronics means the close interaction of mechanics, electronics, control engineering and software engineering in order to achieve a better systems behavior. Due to the outstanding deployment of information and communication technologies, the functionality of mechatronic systems will go far beyond the known standards with the intention to increase their robustness, flexibility and reliability. The objective is to develop intelligent systems that react autonomously on changing environmental conditions and optimize their behavior during operation. The design of such advanced mechatronic systems is a challenge. Additionally to mechanical, electrical, control and software engineers also expertise from mathematical optimization, artificial intelligence and even cognitive science is necessary. This requires an effective and continuous cooperation and communication between developers from different domains during the whole development process. As a consequence a domain-spanning methodology is necessary in order to guarantee an effective work flow between the participating developers from various domains and their domain-specific methods, terminologies and solutions. For this purpose an ontology-based computer support will be presented, that facilitates the systems engineer by analyzing the functional system model and identifying convenient solutions. This includes the generation and storage of once proven design solutions as well as the search for the effective and domain-spanning reuse.Copyright © 2012 by ASME","",""
1,"L. Jaeger, S. Segonds, C. Bès","Methodology Based on Multiagent for Solving Multidisciplinary Optimization Problem Under Uncertainty",2015,"","","","",95,"2022-07-13 09:20:45","","10.2514/1.I010241","","",,,,,1,0.14,0,3,7,"T HERE are a large number ofmethodologies available inmultidisciplinary design optimization (MDO) for deterministic environments [1–3]. However, to design systems that are both robust and reliable, uncertainties regarding models and parameters have to be catered for to ensure success of the project in terms of timeliness, cost, and performance. This is crucial, especially during the preliminary design phasewhere there are still many uncertainties and decisions have to be compatible with the more detailed analysis of future development phases. To cope with this problem, reliability-based and robust design methods [4] have been developed to assist designers in the decision-making process. A number of relatively time-consuming techniques to solve optimization problems under uncertainty have been devised [5–8]. The main drawback with these methods is the computational burden associated with evaluation of robustness and reliability during design. A powerful methodology stemming from artificial intelligence, the autoadaptive multiagent system (AMAS), has recently been developed to solve complexmultidisciplinary optimization problems, especially in the aeronautical field [9–11]. Due to both its local and parallel approach, the AMAS method allows complex deterministic optimization problems to be solved rapidly, even in multidisciplinary contexts such as aircraft design where thermal engineering, structural, and fluid mechanics issues all interact. However, the said AMASmethodwas developed to respond to a deterministic environment only. The aim of the present Note is to extend theAMASmethodwith its multiagent framework to copewithMDO under conditions of uncertainty, providing a new methodology so it can be effectively used in an uncertain environment. To do so, a strategy to integrate and propagate uncertainties in themultiagent framework is first developed. Then, to optimize computing time,multiagent propagation is combined with a sequential optimization process coupled with the use of AMAS. This Note is organized as follows. Section II gives the approach used to solve a deterministic multidisciplinary optimization problem with a multiagent system. For didactic purposes, this approach is presented through an extremely simple mathematical application. Section III then goes on to describe the proposedmethodology to solveMDOproblems in an uncertain environment. This section is broken down into two subsections. The first describes the integration and propagation of uncertainties in the multiagent framework, whereas the second looks at the interactions between uncertainty propagation, the sequential optimization process, and the AMAS method. More precisely, at each step of the sequential optimization process, the AMAS method is effectively used to solve a deterministic optimization problem. From the given AMAS deterministic optimum, a reliability analysis is than conducted. Violated constraints are shiftedwith the introduction of adaptive safety coefficients as computed from multiagent uncertainty propagation. These coefficients are applied to define a new deterministic optimization problem to be solved by the AMAS over the following cycle. Iterations stop once the safety coefficients have been brought down to a low enough level. Finally, in Sec. IV, this newmethodology is applied to a preliminary aircraft design test case. Results show substantial improvements in terms of robustness and efficiency comparedwith the standard double-loop optimization process used to solve classicalMDOproblems. Conclusions and perspectives are presented in Sec. V.","",""
0,"M. Power","CONTROLLING THE TORQUE OF THREE PHASE INDUCTION MOTOR WITH GENETIC ALGORITHM",2015,"","","","",96,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,1,7,"The induction motor, known for its robustness, relatively low cost, reliability and efficiency, is the vital part in many research works. The advancement in power semiconductor devices, digital data processing and control has led to great improvements in torque response control of AC motors. Direct Torque control principle has been used for Induction Motor (IM) drives with fast dynamics. DTC has been widely recognized for its fast and robust torque and flux control. Novel approach of the Genetic algorithm scheme for direct torque control (DTC) of an Induction Motor (IM) AC drive is the recent area of research. To improve the performance of conventional DTC, artificial intelligence like neural networks, fuzzy(1)(2) are implemented. Though DTC has high dynamic performance, it has few undesirable contents like high ripple in torque, output current and deviations in switching frequency of the inverter. The Z-source converter employs a unique impedance network to couple the converter main circuit to the power source. This provided unique features that cannot be obtained in the traditional voltage-source or current-source converters where a inductor and capacitor are used, respectively.","",""
0,"B. Ramana","SOFTWARE METRIC TRENDS AND EVOLUTION",2015,"","","","",97,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,1,7,"Definition - Software Engineering encompasses a process, methods for managing and engineering software and tools. The role of software has undergone significant change over the past half century. From card readers to scanner, from simple equation to artificial intelligence, kilobytes to terabytes, CPU performance from 1 MHz to 6 GHz, 8 bit to 128 bit operating systems. The evolution happened in terms of space, complexity, quality and ease. Legacy applications are attributed with poor quality later with modern applications it’s eradicated. In fact the need for the evolution may even become obvious even before the new system is deployed. With evolving software, the metrics also evolved to measure the quality, not just in terms of documentation but in availability, reliability and robustness of the applications. Process and product measures have been defined to measure the quality of the engineered/developed product. The quality models and industrial standards – Six Sigma, SEI CMMI, ITIL, ISO, PMBOK, Prince2 and other, have changed the estate of software process in the IT world. Each of these help in improving the software development process. In this paper we analyze the metric evolution and the impact it has on software industry. Agile modeling is the current customer sought after model where the metrics are still evolving to suit the customer and market needs.","",""
10,"X. Guan","Multi-objective PID Controller Based on NSGA-II Algorithm with Application to Main Steam Temperature Control",2009,"","","","",98,"2022-07-13 09:20:45","","10.1109/AICI.2009.388","","",,,,,10,0.77,10,1,13,"PID controller is widely used for main steam temperature control of boiler unit in thermal power plant. To avoid the drawback of current PID design methods, this paper presents a new design method for multi-objective PID controller to synthetically consider system requirement in speediness, reliability and robustness. NSGA-II algorithm with the elite strategy is applied to the parameter optimization design. The simulation results on an actual main steam temperature control system indicate that, the multi-objective PID controller designed by presented method, can improve the dynamic performance of main steam temperature control system, with good robustness and anti-interference ability.","",""
6,"R. Dumitrescu, J. Gausemeier, C. Romaus","Towards the design of cognitive functions in self-optimizing systems exemplified by a hybrid energy storage system",2011,"","","","",99,"2022-07-13 09:20:45","","10.1177/0959651811398851","","",,,,,6,0.55,2,3,11,"Within the last years, mechatronics as a discipline has shaped the development of complex technical systems. Mechatronics consists of the close interaction of mechanics, electronics, control engineering and software engineering in order to achieve a better system behaviour. Due to the advances in deployment of information and communication technologies, the functionality of mechatronic systems will go far beyond the known standards with the intention to increase their robustness, flexibility and reliability. The paradigm that expresses this development is called self-optimization. Self-optimizing systems react autonomously to changing environmental conditions and optimize their behaviour during operation. The design of such systems is an interdisciplinary task. Engineers in the different fields of mechatronics have to work closely with experts from mathematical optimization and artificial intelligence. Furthermore, self-optimizing systems adopt information processing functions, which are known as cognitive functions. Even though more theories of the modelling of cognitive behaviour in technical systems are being developed and published, an applicable support of the system engineers is missing. Already the identification of self-optimization and appropriate cognitive functions area challenge. This contribution presents an approach to design cognitive functions in self-optimizing systems and its example application to a hybrid energy storage system as a subsystem of an innovative railway vehicle.","",""
3,"Tan Guo-zhen, Wang Kai, Wang Yaodong","A coordination feedback adaptive control method of traffic network",2011,"","","","",100,"2022-07-13 09:20:45","","10.1109/ITAIC.2011.6030220","","",,,,,3,0.27,1,3,11,"With the development of information technology and the coming of the internet of things, traffic signal control has brought new opportunities and challenges. This paper presents a method of traffic network signal control, which used to optimize traffic signal timing, reduce the delay of vehicles within the network. The method is divided into two levels: intersection control level and network control level. Intersection control level uses a dynamic programming based adaptive algorithm. Network control level uses an optimization algorithm based on conflict decision tree, using the A∗ algorithm, rolling optimization and feedback control strategies to enhance the real-time, reliability and robustness of the algorithm. The effectiveness of the system has evaluated through an actual traffics network simulation conducted with VISSIM. Results show that the proposed method is significantly better than the time-of-day method in travel time, average delay and other parameters.","",""
4,"Wang Yong-ding, Ni Li-na","Design of Smart Car Speed Control System Based on Fuzzy Control",2010,"","","","",101,"2022-07-13 09:20:45","","10.1109/AICI.2010.228","","",,,,,4,0.33,2,2,12,"The smart car, one kind of mobile robots, is an integrated system which integrates multiple functions such as environment awareness, planning decision and automatic drive. In order to improve the smart car’s performance in tracking and moving, smart car’s speed control system based on FUZZY controller is designed in this paper. Control strategy and control algorithm is researched. Firstly, membership function and control rules are designed in this paper. Secondly, through fuzzy inference and defuzzification, we can get the output control action’s domain of discourse. Finally, a smart car hardware system, where the algorithm is applied in, is designed based on MC9S12XS128 MCU. The algorithms have fast response, small overshoot, and strong robustness and so on. Where after, the reliability of this system is tested, which proved that the control algorithm can imitate the driving behavior of human to control the smart car to track the path accurately and rapidly.","",""
12,"S. Thrun","When Robots Meet People: Research Directions In Mobile Robotics",1999,"","","","",102,"2022-07-13 09:20:45","","","","",,,,,12,0.52,12,1,23,"Recent research in the field of mobile robotics has led to significant progress along various dimensions. Applications such as robots that guide blind or mentally handicapped people, robots that clean large office buildings and department stores, robots that assist people in recreational activities, etc., are clearly in reach, and for many of those target domains prototypes are readily available. This recent, ongoing revolution has been triggered by advances along various dimensions. Robotic hardware has steadily become cheaper and more reliable. Robotic software has matured, reaching critical levels of reliability, robustness, and flexibility. Mobile robots have an enormous potential to change our everyday lives. It is worth noting that an increasing fraction of these robots rely on methods developed in artificial intelligence. Together with researchers at the University of Bonn (W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer, D. Schultz and W. Steiner), and motivated in part by the work of Horswill [3], the author recently installed a mobile tourguide robot in a branch of the Deutsches Museum [1, 4]. The robot’s task was to guide visitors through the museum, explaining to them a subset of the museum’s exhibits. The major challenges that arose in this project can be grouped into two categories: navigation and human robot interaction.","",""
5,"C. Kemke","An architectural framework for natural language interfaces to agent systems",2006,"","","","",103,"2022-07-13 09:20:45","","","","",,,,,5,0.31,5,1,16,"Christel Kemke University of Manitoba Winnipeg, MB, R3T 2N2 Canada ckemke@cs.umanitoba.ca ABSTRACT In this paper, we describe an architectural framework for the development of natural language interfaces to agent systems. Since the communication between human and artificial agents is mostly task-related, the focus of the suggested architecture is on action representations as core structure and thread in the overall processing. The architectural framework we suggest is based on various forms of action representations and consists of a sequence of transformations, which converts the user’s verbal input into a suitable set of agent actions to produce a response to the input. This process reduces stepwise the complexity and ambiguity of the natural language input by using pre-defined sets of interim actions at different levels, and thus increases the robustness and reliability of the natural language interface. The architecture was employed in the design of several natural language interfaces to agent systems. KEY WORDS Natural Language Interfaces, Human-Agent Communication, Human-Machine Interaction, Knowledge Representation, Ontology, Agent Systems, Action Theory, Description Logic","",""
2,"J. Cullmann, G. Schmitz, W. Görner","A new system for online flood forecasting : performance and implications",2007,"","","","",104,"2022-07-13 09:20:45","","","","",,,,,2,0.13,1,3,15,"Flood forecasting, as well as flood risk management at the operational level, become more and more relevant. The required reliability and robustness for operational flood warning systems, which up to now present the basic problems, are accounted for by the PAI-OFF (Process Modelling and Artificial Intelligence for Online Flood Forecasting) approach. It is based on the operational advantages of artificial neural networks. The system integrates all available physical information with the aid of a training procedure, originating from a physically based hydrological model. The forecast reliability of the new approach strongly depends on the catchment models' ability to realistically portray the flood relevant processes. In this paper we present two different approaches for modelling flood peaks with WaSiM-ETH, focusing on the parameterisation strategy. In order to improve model efficiency we propose a dual parameterisation methodology. This approach allows for setting model parameters according to the dominant controls of floods of different magnitudes. Results from the study are demonstrated for a catchment in the Erzgebirge (Ore-mountains) in East Germany (1700 km 2 ). Online flood forecasting of the Zschopau River at the gauge Kriebstein is validated using PAI-OFF to predict the 2002 extreme flood event. This data did not feature in the training process of the PAI-OFF-PoNN (Polynomial Neural Network) forecast tool. The computational efficiency, together with the convincing agreement between the predicted and observed flood hydrographs, underlines the potential of the new PAI-OFF methodology in the context of operational online forecasting.","",""
3,"J. Cullmann, G. Schmitz, W. Görner","PAI-OFF : a new strategy for online flood forecasting in mountainous catchments",2006,"","","","",105,"2022-07-13 09:20:45","","","","",,,,,3,0.19,1,3,16,"We present PAI-OFF (Process Modelling and Artificial Intelligence for Online Flood Forecasting), which combines the reliability of physically based, sophisticated modelling with the operational advantages of Artificial Neural Networks (ANN). Thus we are able to improve ANN performance in the flood forecasting context by detailed process modelling. Low computation times and robustness are the key features of ANN models and also form the basic requirements for flash flood forecasting. After presenting the theory of the new methodology, the results of a catchment related meteorological analysis for generating storm scenarios serve as the input to a coupled hydrological/hydraulic model, which is set up for a mountainous catchment in east Germany. Along these lines we operate the catchment model for all realistically possible constellations of flood formation. This results in a database consisting of corresponding input/output vectors. We complete the database for training the ANN by adding yet more flood relevant data for characterizing the hydrological and meteorological catchment situation prior to a storm event. After this preparatory step, the ANN is applied for online flash flood forecasting in the considered catchment using an unseen storm event, i.e. one which did not feature in the training process. The convincing agreement between the predicted and observed flood hydrograph underlines the application potential of the new PAI-OFF methodology for online flood forecasting even in smaller catchments.","",""
0,"M. Courant, A. Robert","ATheoretical and Applicative Framework for Evolutive Computers",2007,"","","","",106,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,2,15,"With the generalisation of massively parallel systems, computer engineering lifts a new scientific challenge: that of formulating an evolution theory, able to rule the self-organisation of artificial collectivities and individuals, inducing a rise in their performance, ability, reliability, and robustness; in other words, a theory which would ground their viability and intelligence. Towards this goal, genetic algorithms provide a framework both conceptually new and powerful on the computational side. However, this computer engineering prospect for evolution stays insufficient in many respects. The work we present aims at expressing a theory of evolution which counters the weaknesses of genetic algorithms. Essentially, we seek to heighten their operationnality by refining the darwinian model upon which they are based, to enable a fast replay of the history of life over silicon components. In practice, we suggest a reinstatement of Lamarckian laws, leading to a view reconciling constructivism and finalism, and restoring Monod's idea of a project of life. So doing, we propose to move towards the autonomisation of the concept of machine, considering it as an integral part of the living mechanics from which it was born.","",""
1,"Safety for Technical Processes, Hongyue Zhang","Fault detection, supervision and safety of technical processes 2006 : a proceedings volume from the 6th IFAC symposium, SAFEPROCESS 2006, Beijing, P.R., China, August 30-September 1, 2006",2007,"","","","",107,"2022-07-13 09:20:45","","","","",,,,,1,0.07,1,2,15,"Fault Detection, Isolation and Identification Model-based methods: observers, parity relations and identification Statistical approaches Fault modelling Signal analysis Design measures for robustness Pattern recognition Computational Intelligence in Fault Diagnosis Expert systems Fuzzy logic and rough sets Artificial neural networks Neuro-fuzzy approaches Qualitative reasoning Design for Reliability and Safety Reliability and safety analysis Probabilistic safety assessment Testing and evaluation of safety systems Safety standards and qualification Safety evaluation tools Fault Tolerant Systems Design Fault prediction Fault tolerant and fail-safe control Design measures for fault tolerance Reconfigurable and scalable control systems Maintenance and Repair Maintenance and repair strategies Predictive maintenance Operator support information systems Life-cycle considerations Human Factors Human factors in automation Human reliability analysis Support for systems operation and decision making Industrial safety management and safety culture Economic, environmental and ecological aspects of fault diagnosis Industrial Applications and Case Studies Electrical, mechanical and electronic systems Chemical and biomedical processes Transportation, traffic and automotive systems Power systems Marine systems Aeronautics and aerospace Evaluation of benchmark problems","",""
7,"E. Spinosa, A. Pozo","Controlling the Population Size in Genetic Programming",2002,"","","","",108,"2022-07-13 09:20:45","","10.1007/3-540-36127-8_33","","",,,,,7,0.35,4,2,20,"","",""
6,"T. Perkins, A. Barto","Lyapunov methods for safe intelligent agent design",2002,"","","","",109,"2022-07-13 09:20:45","","","","",,,,,6,0.30,3,2,20,"In the many successful applications of artificial intelligence (AI) methods to real-world problems in domains such as medicine, commerce, and manufacturing, the AI system usually plays an advisory or monitoring role. That is, the AI system provides information to a human decision-maker, who has the final say.  However, for applications ranging from space exploration, to e-commerce, to search and rescue missions, there is an increasing need and desire for AI systems that display a much greater degree of autonomy. In designing autonomous AI systems, or agents, issues concerning safety, reliability, and robustness become critical. Does the agent observe appropriate safety constraints? Can we provide performance or goal-achievement guarantees? Does the agent deliberate and/or learn efficiently and in real time?  In this dissertation, we address some of these issues by developing an approach to agent design that integrates control-theoretic techniques, primarily methods based on Lyapunov functions, with planning and learning techniques from AI. Our main approach is to use control-theoretic domain knowledge to formulate, or restrict, the ways in which the agent can interact with its environment. This approach allows one to construct agents that enjoy provable safety and performance guarantees, and that reason and act in real-time or anytime fashion. Because the guarantees are established based on restrictions on the agent's behavior, specialized “safety-oriented” decision-making algorithms are not necessary. Agents can reason using standard AI algorithms; we discuss state-space search and reinforcement learning agents in detail. To a limited degree, we also show that the control-theoretic domain knowledge needed to ensure safe agent behavior can itself be learned by the agent, and need not be known a priori. We demonstrate our theory with simulation experiments on standard problems from robotics and control.","",""
0,"H. Abachi, M. Abdollahian","PERFORMANCE ANALYSIS OF A FLEXIBLE MESH MULTIBUS HIGH PERFORMANCE COMPUTER ARCHITECTURE MANUFACTURING SYSTEM BASED ON MASTER-SLAVE",2002,"","","","",110,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,2,20,"This paper outlines the aspects o f architectural design o f the parallel processing system applicable to llevible manufacturing system (FMS). Incorporating parallel processing systenis design into such an cnvirmnient fulf i ls customers' requirements and results in improvements in speed, accuracy and reliability o f the system. This provides a high level o f capability for achieving high pel-forniance and robustness i n the demanding automation control systems, and machine tool industries. The perforiiiance analysis and the simulation results are included for comparison purposes. Fault tolerance, f lexibil i ty and self-reconfiguribility o f the overall system is further improved by incoiporating artiticial intelligence and expert system i n the hody o f data base management system. Keywjnrds: system multi-robot, artificial intelligence, parallel processing, flexible manufacturing system and expert","",""
1,"M. F. Smith","Intelligent health care information systems: are they appropriate?",1992,"","","","",111,"2022-07-13 09:20:45","","","","",,,,,1,0.03,1,1,30,"The application of artificial intelligence (AI) in health care has had a long history of great promise. Striking success has been claimed in areas such as computer aided diagnosis, although contradictory evidence has also appeared. The progression toward intelligent decision support systems (IDSS) appears to be a logical, and perhaps inevitable, one. The author, however, is not convinced that IDSS is an appropriate technology at this stage in the development of health care systems. The concern is that IDSS may not encourage good software development practice. The enthusiasm for delivering mechanisms of AI may seriously detract from the mundane, but essential, tasks of ensuring: match with user and organisational requirements, good design, reliability, robustness, maintainability, and scaleability. The author recommends the increasing use of DBMS technology for health care ISs before IDSS is considered further.","",""
0,"H. Abachi, M. Abdollahian","Performance analysis of a flexible manufacturing system based on master-slave mesh multibus high performance computer architecture",2002,"","","","",112,"2022-07-13 09:20:45","","10.1109/WAC.2002.1049468","","",,,,,0,0.00,0,2,20,"This paper outlines the aspects of architectural design of the parallel processing system applicable to flexible manufacturing system (FMS). Incorporating parallel processing systems design into such an environment fulfils customers' requirements and results in improvements in speed, accuracy and reliability of the system. This provides a high level of capability for achieving high performance and robustness in the demanding automation control systems, and machine tool industries. The performance analysis and the simulation results are included for comparison purposes. Fault tolerance, flexibility and self-reconfigurability of the overall system is further improved by incorporating artificial intelligence and expert system in the body of data base management system.","",""
50,"M. Ryan","In AI We Trust: Ethics, Artificial Intelligence, and Reliability",2020,"","","","",113,"2022-07-13 09:20:45","","10.1007/s11948-020-00228-y","","",,,,,50,25.00,50,1,2,"","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",114,"2022-07-13 09:20:45","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
0,"Xiuzhuo Wei, Huinan Zhao, Lianlian Liu","Reliability Analysis of Intelligent Big Data Hybrid Information System Based on Artificial Intelligence",2021,"","","","",115,"2022-07-13 09:20:45","","10.1109/PHM-Nanjing52125.2021.9612825","","",,,,,0,0.00,0,3,1,"In the intelligent big data hybrid information system, the index parameters of the binary semantic interval are too few, which leads to large idle parameters in reliability analysis and occupying more system resources. In response to the above problems, intelligent big data mixed information is analyzed based on the reliability of the artificial intelligence system. Use artificial intelligence technology to sort and process information operation tasks, construct homomorphic mapping information relationships, define weight parameters generated by index semantics, control the idleness of indicators generated by reliability algorithms, construct reliability analysis algorithms, and finally complete the analysis process. Prepare the known software and hardware environment of the intelligent big data hybrid information system, and apply the reliability analysis method based on state information, the reliability analysis method based on cloud computing, and the designed reliability analysis method for experiments. The results show that the designed reliability analysis method actually occupies less operating resources of the information system, and the processing time is short. High reliability analysis accuracy.","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",116,"2022-07-13 09:20:45","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
353,"Erico Tjoa, Cuntai Guan","A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",2019,"","","","",117,"2022-07-13 09:20:45","","10.1109/TNNLS.2020.3027314","","",,,,,353,117.67,177,2,3,"Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",118,"2022-07-13 09:20:45","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",119,"2022-07-13 09:20:45","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",120,"2022-07-13 09:20:45","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
51,"T. Dragičević, P. Wheeler, F. Blaabjerg","Artificial Intelligence Aided Automated Design for Reliability of Power Electronic Systems",2019,"","","","",121,"2022-07-13 09:20:45","","10.1109/TPEL.2018.2883947","","",,,,,51,17.00,17,3,3,"This paper proposes a new methodology for automated design of power electronic systems realized through the use of artificial intelligence. Existing approaches do not consider the system's reliability as a performance metric or are limited to reliability evaluation for a certain fixed set of design parameters. The method proposed in this paper establishes a functional relationship between design parameters and reliability metrics, and uses them as the basis for optimal design. The first step in this new framework is to create a nonparametric surrogate model of the power converter that can quickly map the variables characterizing the operating conditions (e.g., ambient temperature and irradiation) and design parameters (e.g., switching frequency and dc link voltage) into variables characterizing the thermal stress of a converter (e.g., mean temperature and temperature variation of its devices). This step can be carried out by training a dedicated artificial neural network (ANN) either on experimental or simulation data. The resulting network is named as $\text{ANN}_{1}$ and can be deployed as an accurate surrogate converter model. This model can then be used to quickly map the yearly mission profile into a thermal stress profile of any selected device for a large set of design parameter values. The resulting data is then used to train $\text{ANN}_{2}$, which becomes an overall system representation that explicitly maps the design parameters into a yearly lifetime consumption. To verify the proposed methodology, $\text{ANN}_{2}$ is deployed in conjunction with the standard converter design tools on an exemplary grid-connected PV converter case study. This study showed how to find the optimal balance between the reliability and output filter size in the system with respect to several design constraints. This paper is also accompanied by a comprehensive dataset that was used for training the ANNs.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",122,"2022-07-13 09:20:45","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",123,"2022-07-13 09:20:45","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",124,"2022-07-13 09:20:45","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
18,"Xinyu Liu, Mingzhe Chen, Yuanwei Liu, Yue Chen, S. Cui, L. Hanzo","Artificial Intelligence Aided Next-Generation Networks Relying on UAVs",2020,"","","","",125,"2022-07-13 09:20:45","","10.1109/MWC.001.2000174","","",,,,,18,9.00,3,6,2,"In this article, we propose artificial intelligence (AI) enabled unmanned aerial vehicle (UAV) aided wireless networks (UAWN) for overcoming the challenges imposed by the random fluctuation of wireless channels, blocking and user mobility effects. In UAWN, multiple UAVs are employed as aerial base stations, which are capable of promptly adapting to the randomly fluctuating environment by collecting information about the users' position and tele-traffic demands, learning from the environment and acting upon the satisfaction level feedback received from the users. Moreover, AI enables the interaction among a swarm of UAVs for cooperative optimization of the system. As a benefit of the AI framework, several challenges of conventional UAWN may be circumvented, leading to enhanced network performance, improved reliability and agile adaptivity. As a further benefit, dynamic trajectory design and resource allocation are demonstrated. Finally, potential research challenges and opportunities are discussed.","",""
24,"David Mhlanga","Artificial Intelligence in the Industry 4.0, and Its Impact on Poverty, Innovation, Infrastructure Development, and the Sustainable Development Goals: Lessons from Emerging Economies?",2021,"","","","",126,"2022-07-13 09:20:45","","10.3390/SU13115788","","",,,,,24,24.00,24,1,1,"Artificial intelligence in the fourth industrial revolution is beginning to live up to its promises of delivering real value necessitated by the availability of relevant data, computational ability, and algorithms. Therefore, this study sought to investigate the influence of artificial intelligence on the attainment of Sustainable Development Goals with a direct focus on poverty reduction, goal one, industry, innovation, and infrastructure development goal 9, in emerging economies. Using content analysis, the result pointed to the fact that artificial intelligence has a strong influence on the attainment of Sustainable Development Goals particularly on poverty reduction, improvement of the certainty and reliability of infrastructure like transport making economic growth and development possible in emerging economies. The results revealed that Artificial intelligence is making poverty reduction possible through improving the collection of poverty-related data through poverty maps, revolutionizing agriculture education and the finance sector through financial inclusion. The study also discovered that AI is also assisting a lot in education, and the financial sector allowing the previously excluded individuals to be able to participate in the mainstream economy. Therefore, it is important that governments in emerging economies need to invest more in the use of AI and increase the research related to it so that the Sustainable Development Goals (SDGs) related to innovation, infrastructure development, poverty reduction are attained.","",""
17,"Rajesh Gupta, Aparna Kumari, S. Tanwar","Fusion of blockchain and artificial intelligence for secure drone networking underlying 5G communications",2020,"","","","",127,"2022-07-13 09:20:45","","10.1002/ett.4176","","",,,,,17,8.50,6,3,2,"Nowadays, the exponential increase in the usage of drones in various realms of societal and military applications necessitates advancements and stability in drone communication. Drones have proven their potential in providing real‐time cost‐efficient solutions for several applications like healthcare, smart grid surveillance, smart city monitoring, and border surveillance. Though it has many security and privacy issues, researchers across the globe have given numerous solutions to protect drone communication from cyber‐attacks. Most of these solutions were based on cryptographic techniques and are highly compute extensive. There exist few blockchain‐based solutions, which suffer from high transaction storage costs with communication reliability, latency, and bandwidth issues. Motivated by these facts, in this paper, we present a comprehensive survey to secure drone communication and propose a blockchain‐based secure and intelligent drone communication architecture underlying 5G communication network and artificial intelligence (AI) techniques. The proposed architecture uses an InterPlanetary File System (IPFS) as a platform for data storage, which ensures improved network performance, communication security and privacy, and reduces transaction storage cost. Further, it facilitates efficient drone communication in providing dynamic, flexible, and on‐the‐fly decisions competencies through 5G and AI technologies. Then, we incorporate a healthcare‐based case study using the proposed architecture. At last, future research challenges and directions are emphasized for improvement in this research area.","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",128,"2022-07-13 09:20:45","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
13,"Hooman Farzaneh, Ladan Malehmirchegini, A. Bejan, Taofeek Afolabi, Alphonce Mulumba, Precious P. Daka","Artificial Intelligence Evolution in Smart Buildings for Energy Efficiency",2021,"","","","",129,"2022-07-13 09:20:45","","10.3390/APP11020763","","",,,,,13,13.00,2,6,1,"The emerging concept of smart buildings, which requires the incorporation of sensors and big data (BD) and utilizes artificial intelligence (AI), promises to usher in a new age of urban energy efficiency. By using AI technologies in smart buildings, energy consumption can be reduced through better control, improved reliability, and automation. This paper is an in-depth review of recent studies on the application of artificial intelligence (AI) technologies in smart buildings through the concept of a building management system (BMS) and demand response programs (DRPs). In addition to elaborating on the principles and applications of the AI-based modeling approaches widely used in building energy use prediction, an evaluation framework is introduced and used for assessing the recent research conducted in this field and across the major AI domains, including energy, comfort, design, and maintenance. Finally, the paper includes a discussion on the open challenges and future directions of research on the application of AI in smart buildings.","",""
0,"Yuan Cao, Yongmao Wang","Reliability analysis of computer adaptive system based on artificial intelligence recognition model",2022,"","","","",130,"2022-07-13 09:20:45","","10.1007/s12652-021-03615-w","","",,,,,0,0.00,0,2,1,"","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",131,"2022-07-13 09:20:45","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
9,"Saeed Askary, Nasser Abu-Ghazaleh, Yasean A. Tahat","Artificial Intelligence and Reliability of Accounting Information",2018,"","","","",132,"2022-07-13 09:20:45","","10.1007/978-3-030-02131-3_28","","",,,,,9,2.25,3,3,4,"","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",133,"2022-07-13 09:20:45","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",134,"2022-07-13 09:20:45","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
51,"C. Nelson, L. Perez-Chada, A. Creadore, S. Li, K. Lo, Priya Manjaly, Ashley B Pournamdari, Elizabeth Tkachenko, J. Barbieri, J. Ko, Alka V. Menon, R. Hartman, A. Mostaghimi","Patient Perspectives on the Use of Artificial Intelligence for Skin Cancer Screening: A Qualitative Study.",2020,"","","","",135,"2022-07-13 09:20:45","","10.1001/jamadermatol.2019.5014","","",,,,,51,25.50,5,13,2,"Importance The use of artificial intelligence (AI) is expanding throughout the field of medicine. In dermatology, researchers are evaluating the potential for direct-to-patient and clinician decision-support AI tools to classify skin lesions. Although AI is poised to change how patients engage in health care, patient perspectives remain poorly understood.   Objective To explore how patients conceptualize AI and perceive the use of AI for skin cancer screening.   Design, Setting, and Participants A qualitative study using a grounded theory approach to semistructured interview analysis was conducted in general dermatology clinics at the Brigham and Women's Hospital and melanoma clinics at the Dana-Farber Cancer Institute. Forty-eight patients were enrolled. Each interview was independently coded by 2 researchers with interrater reliability measurement; reconciled codes were used to assess code frequency. The study was conducted from May 6 to July 8, 2019.   Main Outcomes and Measures Artificial intelligence concept, perceived benefits and risks of AI, strengths and weaknesses of AI, AI implementation, response to conflict between human and AI clinical decision-making, and recommendation for or against AI.   Results Of 48 patients enrolled, 26 participants (54%) were women; mean (SD) age was 53.3 (21.7) years. Sixteen patients (33%) had a history of melanoma, 16 patients (33%) had a history of nonmelanoma skin cancer only, and 16 patients (33%) had no history of skin cancer. Twenty-four patients were interviewed about a direct-to-patient AI tool and 24 patients were interviewed about a clinician decision-support AI tool. Interrater reliability ratings for the 2 coding teams were κ = 0.94 and κ = 0.89. Patients primarily conceptualized AI in terms of cognition. Increased diagnostic speed (29 participants [60%]) and health care access (29 [60%]) were the most commonly perceived benefits of AI for skin cancer screening; increased patient anxiety was the most commonly perceived risk (19 [40%]). Patients perceived both more accurate diagnosis (33 [69%]) and less accurate diagnosis (41 [85%]) to be the greatest strength and weakness of AI, respectively. The dominant theme that emerged was the importance of symbiosis between humans and AI (45 [94%]). Seeking biopsy was the most common response to conflict between human and AI clinical decision-making (32 [67%]). Overall, 36 patients (75%) would recommend AI to family members and friends.   Conclusions and Relevance In this qualitative study, patients appeared to be receptive to the use of AI for skin cancer screening if implemented in a manner that preserves the integrity of the human physician-patient relationship.","",""
7,"Thaísa Pinheiro Silva, Mariana Mendonça Hughes, L. S. Menezes, M. D. de Melo, W. M. Takeshita, Paulo Henrique Luiz de Freitas","Artificial intelligence-based cephalometric landmark annotation and measurements according to Arnett's analysis: can we trust a bot to do that?",2021,"","","","",136,"2022-07-13 09:20:45","","10.1259/dmfr.20200548","","",,,,,7,7.00,1,6,1,"OBJECTIVE To assess the reliability of CEFBOT, an artificial intelligence (AI)-based cephalometry software, for cephalometric landmark annotation and linear and angular measurement according to Arnett's analysis.   METHODS Thirty lateral cephalometric radiographs acquired with a Carestream CS 9000 3D unit (Carestream Health Inc., Rochester/NY) were used in this study. The 66 landmarks and the ten selected linear and angular measurements of Arnett's analysis were identified on each radiograph by a trained human examiner (control) and by CEFBOT (RadioMemory Ltd., Belo Horizonte, Brazil). For both methods, landmark annotations and measurements were duplicated with an interval of 15 days between measurements and the intraclass correlation coefficient (ICC) was calculated to determine reliability. The numerical values obtained with the two methods were compared by a t-test for independent variables.   RESULTS CEFBOT was able to perform all but one of the ten measurements. ICC values > 0.94 were found for the remaining eight measurements, while the Frankfurt horizontal plane - true horizontal line (THL) angular measurement showed the lowest reproducibility (human, ICC = 0.876; CEFBOT, ICC = 0.768). Measurements performed by the human examiner and by CEFBOT were not statistically different.   CONCLUSION Within the limitations of our methodology, we concluded that the AI contained in the CEFBOT software can be considered a promising tool for enhancing the capacities of human Radiologists.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",137,"2022-07-13 09:20:45","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",138,"2022-07-13 09:20:45","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
5,"Ashraf Ahmed, S. Elkatatny, Hany Gamal, A. Abdulraheem","Artificial Intelligence Models for Real-Time Bulk Density Prediction of Vertical Complex Lithology Using the Drilling Parameters",2021,"","","","",139,"2022-07-13 09:20:45","","10.1007/S13369-021-05537-3","","",,,,,5,5.00,1,4,1,"","",""
4,"Jianghua Wu, Changling Liu, Xiaoqing Liu, Wei Sun, Linfeng Li, Nannan Gao, Yajun Zhang, Xin Yang, Junjie Zhang, Hai-Yue Wang, Xinying Liu, Xiaozheng Huang, Yanhui Zhang, Runfen Cheng, K. Chi, Luning Mao, Lixin Zhou, D. Lin, S. Ling","Artificial intelligence-assisted system for precision diagnosis of PD-L1 expression in non-small cell lung cancer",2021,"","","","",140,"2022-07-13 09:20:45","","10.1038/s41379-021-00904-9","","",,,,,4,4.00,0,19,1,"","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",141,"2022-07-13 09:20:45","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
39,"Aditya Chidepatil, Prabhleen Bindra, Devyani Kulkarni, Mustafa Qazi, Meghana Kshirsagar, K. Sankaran","From Trash to Cash: How Blockchain and Multi-Sensor-Driven Artificial Intelligence Can Transform Circular Economy of Plastic Waste?",2020,"","","","",142,"2022-07-13 09:20:45","","10.3390/admsci10020023","","",,,,,39,19.50,7,6,2,"Virgin polymers based on petrochemical feedstock are mainly preferred by most plastic goods manufacturers instead of recycled plastic feedstock. Major reason for this is the lack of reliable information about the quality, suitability, and availability of recycled plastics, which is partly due to lack of proper segregation techniques. In this paper, we present our ongoing efforts to segregate plastics based on its types and improve the reliability of information about recycled plastics using the first-of-its-kind blockchain smart contracts powered by multi-sensor data-fusion algorithms using artificial intelligence. We have demonstrated how different data-fusion modes can be employed to retrieve various physico-chemical parameters of plastic waste for accurate segregation. We have discussed how these smart tools help in efficiently segregating commingled plastics and can be reliably used in the circular economy of plastic. Using these tools, segregators, recyclers, and manufacturers can reliably share data, plan the supply chain, execute purchase orders, and hence, finally increase the use of recycled plastic feedstock.","",""
45,"Tom Kamiel Magda Vercauteren, M. Unberath, N. Padoy, N. Navab","CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer-Assisted Interventions",2019,"","","","",143,"2022-07-13 09:20:45","","10.1109/JPROC.2019.2946993","","",,,,,45,15.00,11,4,3,"Data-driven computational approaches have evolved to enable extraction of information from medical images with reliability, accuracy, and speed, which is already transforming their interpretation and exploitation in clinical practice. While similar benefits are longed for in the field of interventional imaging, this ambition is challenged by a much higher heterogeneity. Clinical workflows within interventional suites and operating theaters are extremely complex and typically rely on poorly integrated intraoperative devices, sensors, and support infrastructures. Taking stock of some of the most exciting developments in machine learning and artificial intelligence for computer-assisted interventions, we highlight the crucial need to take the context and human factors into account in order to address these challenges. Contextual artificial intelligence for computer-assisted intervention (CAI4CAI) arises as an emerging opportunity feeding into the broader field of surgical data science. Central challenges being addressed in CAI4CAI include how to integrate the ensemble of prior knowledge and instantaneous sensory information from experts, sensors, and actuators; how to create and communicate a faithful and actionable shared representation of the surgery among a mixed human–AI actor team; and how to design interventional systems and associated cognitive shared control schemes for online uncertainty-aware collaborative decision-making ultimately producing more precise and reliable interventions.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",144,"2022-07-13 09:20:45","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
33,"S. Ali, B. Choi","State-of-the-Art Artificial Intelligence Techniques for Distributed Smart Grids: A Review",2020,"","","","",145,"2022-07-13 09:20:45","","10.3390/electronics9061030","","",,,,,33,16.50,17,2,2,"The power system worldwide is going through a revolutionary transformation due to the integration with various distributed components, including advanced metering infrastructure, communication infrastructure, distributed energy resources, and electric vehicles, to improve the reliability, energy efficiency, management, and security of the future power system. These components are becoming more tightly integrated with IoT. They are expected to generate a vast amount of data to support various applications in the smart grid, such as distributed energy management, generation forecasting, grid health monitoring, fault detection, home energy management, etc. With these new components and information, artificial intelligence techniques can be applied to automate and further improve the performance of the smart grid. In this paper, we provide a comprehensive review of the state-of-the-art artificial intelligence techniques to support various applications in a distributed smart grid. In particular, we discuss how artificial techniques are applied to support the integration of renewable energy resources, the integration of energy storage systems, demand response, management of the grid and home energy, and security. As the smart grid involves various actors, such as energy produces, markets, and consumers, we also discuss how artificial intelligence and market liberalization can potentially help to increase the overall social welfare of the grid. Finally, we provide further research challenges for large-scale integration and orchestration of automated distributed devices to realize a truly smart grid.","",""
1,"Ke Zhang, Peidong Xu, Tianlu Gao, Jun Zhang","A Trustworthy Framework of Artificial Intelligence for Power Grid Dispatching Systems",2021,"","","","",146,"2022-07-13 09:20:45","","10.1109/DTPI52967.2021.9540198","","",,,,,1,1.00,0,4,1,"With the widespread application of artificial intelligence (AI) technologies in power systems, the properties of lack of reliability and transparency for AI technologies have revealed gradually. Here, how to build a trustworthy-AI framework based on the power system is the focus. Due to the multidimensional and heterogeneous information of power grid data, the heterogeneous graph attention network (HGAT) model of power grid dispatching is established, and the corresponding explainer (HGAT-Explainer) for the model of power equipment faults is proposed to provide more favorable support for the trustworthy-AI systems.","",""
1,"Astha Jain, R. Krishnan, Ashwini Rogye, S. Natarajan","Use of offline artificial intelligence in a smartphone-based fundus camera for community screening of diabetic retinopathy",2021,"","","","",147,"2022-07-13 09:20:45","","10.4103/ijo.IJO_3808_20","","",,,,,1,1.00,0,4,1,"Purpose: The aim of the study was to analyse the reliability of an offline artificial intelligence (AI) algorithm for community screening of diabetic retinopathy. Methods: A total of 1378 patients with diabetes visiting public dispensaries under the administration of the Municipal Corporation of Greater Mumbai between August 2018 and September 2019 were enrolled for the study. Fundus images were captured by non-specialist operators using a smartphone-based camera covering the posterior pole, including the disc and macula, and the nasal and temporal fields. The offline AI algorithm on the smartphone marked the images as referable diabetic retinopathy (RDR) or non-RDR, which were then compared against the grading by two vitreoretinal surgeons to derive upon the sensitivity and specificity of the algorithm. Results: Out of 1378 patients, gradable fundus images were obtained and analysed for 1294 patients. The sensitivity and specificity of diagnosing RDR were 100% (95% CI: 94.72–100.00%) and 89.55% (95% CI: 87.76–91.16%), respectively; the same values for any diabetic retinopathy (DR) were 89.13% (95% CI: 82.71–93.79%) and 94.43% (95% CI: 91.89–94.74%), respectively, with no false-negative results. Conclusion: The robustness of the offline AI algorithm was established in this study making it a reliable tool for community-based DR screening.","",""
2,"P. W. Grimm, Maura R. Grossman, G. Cormack","Artificial Intelligence as Evidence",2021,"","","","",148,"2022-07-13 09:20:45","","","","",,,,,2,2.00,1,3,1,"This article explores issues that govern the admissibility of Artificial Intelligence (“AI”) applications in civil and criminal cases, from the perspective of a federal trial judge and two computer scientists, one of whom also is an experienced attorney. It provides a detailed yet intelligible discussion of what AI is and how it works, a history of its development, and a description of the wide variety of functions that it is designed to accomplish, stressing that AI applications are ubiquitous, both in the private and public sectors. Applications today include: health care, education, employment-related decision-making, finance, law enforcement, and the legal profession. The article underscores the importance of determining the validity of an AI application (i.e., how accurately the AI measures, classifies, or predicts what it is designed to), as well as its reliability (i.e., the consistency with which the AI produces accurate results when applied to the same or substantially similar circumstances), in deciding whether it should be admitted into evidence in civil and criminal cases. The article further discusses factors that can affect the validity and reliability of AI evidence, including bias of various types, “function creep,” lack of transparency and explainability, and the sufficiency of the objective testing of AI applications before they are released for public use. The article next provides an in-depth discussion of the evidentiary principles that govern whether AI evidence should be admitted in court cases, a topic which, at present, is not the subject of comprehensive analysis in decisional law. The focus of this discussion is on providing a step-by-step analysis of the most important issues, and the factors that affect decisions on whether to admit AI evidence. Finally, the article concludes with a discussion of practical suggestions intended to assist lawyers and judges as they are called upon to introduce, object to, or decide on whether to admit AI evidence. 1 Hon. Paul W. Grimm is a United States District Judge for the District of Maryland, and an adjunct professor at both the University of Maryland Carey School of Law and the University of Baltimore School of Law. Maura R. Grossman, J.D., Ph.D., is a Research Professor, and Gordon V. Cormack, Ph.D., is a Professor, in the David R. Cheriton School of Computer Science at the University of Waterloo. Professor Grossman is also an affiliate faculty member at the Vector Institute for Artificial Intelligence. Her work is funded, in part, by the National Sciences and Engineering Council of Canada (“NESERC”). The opinions expressed in this article are the authors’ own, and do not necessarily reflect the views of the institutions or organizations with which they are affiliated. NORTHWESTERN JOURNAL OF TECHNOLOGY AND INTELLECTUAL PROPERTY 10 INTRODUCTION .............................................................................................................. 10 I. WHAT IS “ARTIFICIAL INTELLIGENCE”? .................................................................... 14 II. WHY AI HAS COME TO THE FOREFRONT TODAY ...................................................... 17 III. THE AI TECHNOLOGY LANDSCAPE .......................................................................... 24 IV. USES OF AI IN BUSINESS AND LAW TODAY .............................................................. 32 V. ISSUES RAISED BY THE USE OF AI IN BUSINESS AND LAW TODAY ............................ 41 A. Bias ............................................................................................................... 42 B. Lack of Robust Testing for Validity and Reliability ....................................... 48 C. Failure to Monitor for Function Creep ......................................................... 51 D. Failure to Ensure Data Privacy and Data Protection .................................. 53 E. Lack of Transparency and Explainabilty ....................................................... 60 F. Lack of Accountability ................................................................................... 65 G. Lack of Resilience ......................................................................................... 72 VI. ESTABLISHING VALIDITY AND RELIABILITY ........................................................... 79 A. Testimony, Expert Testimony, or Technology? .............................................. 79 B. Benchmarks and Goodhart’s Law ................................................................. 82 VII. EVIDENTIARY PRINCIPLES THAT SHOULD BE CONSIDERED IN EVALUATING THE ADMISSIBILITY OF AI EVIDENCE IN CIVIL AND CRIMINAL TRIALS .................... 84 A. Adequacy of the Federal Rules of Evidence in Addressing the Admissibility of AI Evidence ......................................................................... 84 B. Relevance ...................................................................................................... 86 C. Authentication of AI Evidence ....................................................................... 90 D. Usefulness of the Daubert Factors in Determining Whether to Admit AI Evidence ....................................................................................................... 95 E. Practice Pointers for Lawyers and Judges .................................................... 97 CONCLUSION ............................................................................................................... 105","",""
0,"Q. Lu, Ling Wei, Wenwen He, Keke Zhang, Jinrui Wang, Yinglei Zhang, X. Rong, Zhennan Zhao, Lei Cai, Xixi He, Jun Wu, Dayong Ding, Yi Lu, Xiangjia Zhu","Lens Opacities Classification System III–based artificial intelligence program for automatic cataract grading",2021,"","","","",149,"2022-07-13 09:20:45","","10.1097/j.jcrs.0000000000000790","","",,,,,0,0.00,0,14,1,"An artificial intelligence-based and LOCS III-based automatic grading system of nuclear and cortical cataract was established, showing satisfactory grading reliability and referral capability. Purpose: To establish and validate an artificial intelligence (AI)-assisted automatic cataract grading program based on the Lens Opacities Classification System III (LOCS III). Setting: Eye and Ear, Nose, and Throat Hospital, Fudan University, Shanghai, China. Design: AI training. Methods: Advanced deep-learning algorithms, including Faster R-CNN and ResNet, were applied to the localization and analysis of the region of interest. An internal dataset from the EENT Hospital of Fudan University and an external dataset from the Pujiang Eye Study were used for AI training, validation, and testing. The datasets were automatically labeled on the AI platform regarding the capture mode and cataract grading based on the LOCS III. Results: The AI program showed reliable capture mode recognition, grading, and referral capability for nuclear and cortical cataract grading. In the internal and external datasets, 99.4% and 100% of automatic nuclear grading, respectively, had an absolute prediction error of ≤1.0, with a satisfactory referral capability (area under the curve [AUC]: 0.983 for the internal dataset; 0.977 for the external dataset); 75.0% (internal dataset) and 93.5% (external dataset) of the automatic cortical grades had an absolute prediction error of ≤1.0, with AUCs of 0.855 and 0.795 for referral, respectively. Good consistency was observed between automatic and manual grading when both nuclear and cortical cataracts were evaluated. However, automatic grading of posterior subcapsular cataracts was impractical. Conclusions: The AI program proposed in this study showed robust grading and diagnostic performance for both nuclear and cortical cataracts, based on LOCS III.","",""
0,"Jianxin Cheng, Haoming Luo, Wenyi Lin, Guopeng Hu","Pros and Cons of Artificial Intelligence—Lessons From E-Government Services in the COVID-19 Pandemic",2021,"","","","",150,"2022-07-13 09:20:45","","10.1109/ICAIE53562.2021.00042","","",,,,,0,0.00,0,4,1,"How to understand the role and impact of information technology and artificial intelligence has triggered a big debate. To explore the pros and cons of artificial intelligence and its applications, this article takes the face mask distribution programs in the COVID-19 pandemic as research objects, conducting a multi-case comparative study of three cities in China. By manual coding of a total of 4560 We Chat official account messages, and by analyzing information related to the distribution process, it was found that: (1) On the demand side, the task complexity, the demand diversity, and the unstructured decision-making process in the public health emergency have exposed some limitations of AI in data collecting and unstructured problem-solving. (2) On the supply side, the procedural and substantive rules designed, together with the reliability of an AI system, will shape the performance of the AI service channel. (3) Though AI and other new technologies are advancing drastically in the pandemic, there is still much room for improvement whether by the optimization of AI systems, or by political control and social participation, and by the supplement of alternative channels such as the community service delivery.","",""
0,"Ashwaq N. Hassan, S. Al-Chlaihawi, Ahlam R. Khekan","Artificial intelligence techniques over the fifth generation mobile networks",2021,"","","","",151,"2022-07-13 09:20:45","","","","",,,,,0,0.00,0,3,1,"Received Jul 15, 2021 Revised Aug 30, 2021 Accepted Sep 2, 2021 A well fifth generation (5G) mobile networks have been a common phrase in recent years. So, 2025 the number of devices based on 5G will reach about 100 billion, about 2.5 billion users are expected to consume more than a gigabyte (GB) of data per month. 5G will play important roles in new areas, from smart cities and mobile augmented reality, and 4,000 pixels (4K) video streaming. Bandwidth higher than the fourth generation (4G), more reliability and less latency are some of the features that distinguish this generation from previous generations. These features are impressive to a mobile network, but will pose serious challenges for operators and communications companies and will lead to complexity. Managing this network, preventing errors and minimizing latency are some of the challenges that 5G of mobile networks will bring. So, the use of artificial intelligence and machine learning is a good way to solve these challenges. In this paper, we will review the artificial intelligence techniques used in communications networks. Creating a robust and efficient communications network using artificial intelligence techniques is an incentive for future research. The importance of this issue is such that sixth generation (6G) of cellular communications. So, much emphasis on the use of artificial intelligence.","",""
0,"Huihui Liang, Chao Tang, Hai Wang, Bo Pang, Linlin Yuan, He Cai","Research on the Security Situation Awareness Method of Ubiquitous Power Internet of Things Network Based on Artificial Intelligence",2021,"","","","",152,"2022-07-13 09:20:45","","10.1109/AINIT54228.2021.00029","","",,,,,0,0.00,0,6,1,"In order to accurately determine the security situation awareness of the power system IoT network, this paper proposes an artificial intelligence-based security situation awareness[1] method, which abstracts the perception problem so that it can be applied to actual scenarios. Input the records of the actual field monitoring equipment as the data source to the classifier to obtain the perceptual results, and then use the processed results as the training input of the RBF neural network[2] to find out the mapping relationship with the network situation value, thereby quantifying the system’s performance Security posture. Finally, the KDD Cup99 data set[3] can be compared with the attack data of the power information network to verify the reliability of the proposed method in the network security situation analysis.","",""
0,"R. Mohanasundaram","Editorial: Special Section on Human-Centered Artificial Intelligence with Big Data Applications",2021,"","","","",153,"2022-07-13 09:20:45","","10.1520/JTE20219999","","",,,,,0,0.00,0,1,1,"In recent years, human-centered artificial intelligence (AI) has become the most promising research domain in both industrial and academic areas worldwide. AI is the next step on the journey from big data to full automation. Human needs are the motivation behind improvements in computing paradigms. In the aforementioned areas, system-generated information such as smart devices, sensors, agents, and meters—as well as human-generated information such as texts, photos, and videos—lead to a tremendous amount of data while new levels of security, performance, and reliability are required. This Special Section aims to highlight the unique areas of human-centered AI with big data applications and various innovations in multidiscipline areas, while also presenting technical evidence and its countermeasure. This Special Section aims to identify the emerging artificial intelligence with big data in all human-centered (HC) related areas. It consists of up-to-date, state-of-the-art research contributions with novel designs and developments of intelligent application, perception, and security methods in human-centered AI, to enhance the reliability and feasibility of HC in real-world applications. The first three papers by Zhang et al., Huang and Liu, and Qing et al. deal with performance and effect analysis of China's financial venture capital development, multimedia-assisted children’s tennis skills, and agglomeration in the middle reach of the Yangtze River. Shree et al. propose a new fusion-based agricultural synthetic aperture radar (SAR) image despeckling by using anisotropic diffusion and discrete wavelet transform method. SAR images have applications in various fields. Speckle noise, which has the characteristic of multiplicative noise, degrades the image quality of SAR images, which causes information loss. This study proposes a speckle noise reduction algorithm while using the speckle reducing anisotropic diffusion filter, discrete wavelet transform to remove speckle noise. The papers by Ren and Cui, Zhang, and Zhang and Li concentrate on the use of multimedia technology in college English reading teaching, gymnastics teaching, and musical drama teaching. They show that multimedia technology has a positive influence on college education, as it promotes scientific, advanced, and vivid development of college physical education. However, there are still problems in the application of multimedia technology in college physical education; for example, the problem in the links between multimedia teaching and traditional teaching and in the great influence of courseware on teaching effects. So it is necessary to accelerate multimedia technology development, strengthen the application of multimedia technology in college education, achieve proper cooperation between traditional and multimedia teaching, and enrich multimedia courseware and its effect. Yao et al. review the general application of multimedia technology in teaching innovation. Li et al. propose a design and implementation of multimedia technology-assisted English vocabulary teaching courseware for industrial engineering majors. Zhang et al. deal with the development and experimental research of multimedia cai courseware for hurdle running. Jena et al. focus on the thermo-mechanical characterization of rice husk filled carbon-reinforced hybrid polymer composites. Rice husk (RH) is a natural sheath that forms around rice grains during their growth. As a type of natural fiber obtained from agro-industrial waste, RH can be used as filler in composites materials in various polymer matrices. Wu addresses the asymmetric impact of inflation in financial development. This study analyzes the asymmetric effects of financial development on economic growth using a model augmented with inflation and asymmetries to inform model specification. The appropriate policies that favor low inflation and reduced expansion of feasibly reformed financial institutions, capital accumulation, and increased resource mobilization should be instituted if real growth is to positively happen. Ouyang et al., Priyadharshini et al., Krithika and Subramani, Gomathi et al., and Thangavel et al. deal with industrial development, such as the study on damage tests based on structure and operating parameters of wire ropes used by conveyors in orchards; development of intelligent smart metering system through remote monitoring and control under robust conditions; neural network-based drive cycle analysis for parallel hybrid electric vehicle; design fabrication and performance analysis of intelligent mesoscale capacitive accelerometer for vibration measurement; and dynamic modeling and control analysis of industrial electro-mechanical servo positioning system using machine learning technique. Pratheep et al. focuses on the genetic algorithm–based robust controller for an inverted pendulum using model order reduction. This paper considered proportional-integral optimized with a genetic algorithm controller on the inverted pendulum for the control of the angle position. The obtained results show that the GA-based PID controller confirms the enhanced performance indexes by holding minimum settling time and peak overshoot on comparing with the conventional PID controller. Tao et al. propose the existence of k-people stable alliance in n-player cooperative games. This paper considers the existence of a stable k-cooperative alliance with a nonempty core in an n-person cooperative game on the premise that the Nash negotiation solution is the distribution criterion. Also, this article provides sufficient conditions for the benefits of all players in a k-man alliance to lie in its internal sub alliance.","",""
26,"Young-Hoon Cho, J. Kwon, Kyung-Hee Kim, J. Medina-Inojosa, K. Jeon, S. Cho, Soo Youn Lee, Jinsik Park, B. Oh","Artificial intelligence algorithm for detecting myocardial infarction using six-lead electrocardiography",2020,"","","","",154,"2022-07-13 09:20:45","","10.1038/s41598-020-77599-6","","",,,,,26,13.00,3,9,2,"","",""
36,"Jens Christian Bjerring, Jacob Busch","Artificial Intelligence and Patient-Centered Decision-Making",2020,"","","","",155,"2022-07-13 09:20:45","","10.1007/s13347-019-00391-6","","",,,,,36,18.00,18,2,2,"","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",156,"2022-07-13 09:20:45","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
31,"M. Hasan, M. Ahmed, A. Hashim, M. Razzaque, S. Islam, B. Pandey","A Novel Artificial Intelligence Based Timing Synchronization Scheme for Smart Grid Applications",2020,"","","","",157,"2022-07-13 09:20:45","","10.1007/s11277-020-07408-w","","",,,,,31,15.50,5,6,2,"","",""
0,"Shuchita Gupta, Ben A. Amaba, M. McMahon, Kunal Gupta","The Evolution of Artificial Intelligence in the Automotive Industry",2021,"","","","",158,"2022-07-13 09:20:45","","10.1109/rams48097.2021.9605795","","",,,,,0,0.00,0,4,1,"For many companies and institutions, the supply chain model for reliability & maintainability (R&M) of systems can either act as their competitive advantage or weakest link. Big data and analytics play an instrumental role within the supply chain, especially for companies using R&M principles, where these practices were born and matured. The automotive industry has led many initiatives to increase the adoption of such supply chain architectures within their vehicle ecosystems allowing big data and analytics to play the driving role to insure the performance of the vehicles. The automotive industry continues to use these practices to deal with disruptions within autonomous driving, self-healing efficient batteries, robotics, insurance risk assessments, and exceptional customer experiences. Whether it be automotive manufacturers, dealers, drivers, or insurance companies, R&M have had positive results. Today, however, another technology is surfacing fast, changing the face of R&M standard practices and applications. Artificial Intelligence (AI) is impacting and changing the entire automotive industry ecosystem. While advancements in chipsets, edge technology, 5th generation mobile network (5G), Internet of Things (IoT) and cloud have been acting as enablers, data and AI is at the heart of R&M future advances. As per VynZ Research, Global Artificial Intelligence (AI) Market for Automotive and Transportation Industry is Set to Reach USD 45.1 billion by 2024, Observing a CAGR of 17.7% during 2019–2024 [1].In this paper, we will share the impact of AI & trust on the auto industries R&M programs, broken down across four pillars: in-vehicle experience, connected vehicles, auto manufacturing, and autonomous vehicle with examples, and use-cases.","",""
0,"Monika Singh","Integrating Artificial Intelligence and 5G in the Era of Next-Generation Computing",2021,"","","","",159,"2022-07-13 09:20:45","","10.1109/ICCMST54943.2021.00017","","",,,,,0,0.00,0,1,1,"The introduction of the 4G/LTE (Long Term Evolution) mobile network has addressed the main obstacle of higher capacity, allowing for the construction of true broadband mobile Internet. This was mainly made possible by a flexible network design and robust physical layer. However, services such as augmented reality (AR), virtual reality (VR), and others that require more bandwidth have been developed in new ways. Furthermore, new services like Internet-of-Vehicles and vehicle communications are putting a substantial demand on mobile networks for enhanced reliability and near-zero-latency performance (IoV). 5G has overcome some of these obstacles by employing a new radio interface based on massive multiple input multiple output (MIMO). However, network operators must consider an advanced level of intelligence in their networks to learn the operational environment and users' behaviours and needs in depth. In order to establish a proactive and efficient self-updatable network, it is also essential to foresee their evolution. We explore the importance of artificial intelligence and machine learning in 5G in order to develop a cost-effective and adaptive next-generation mobile network in this study. In addition, a comparison between the 5G and 4G networks has been done to showcase the capabilities of 5G network over 4G. Further, some practical use cases of AI/ML are also discussed. Although the countries such as China and US have already started working with some of the applications as discussed but in India, 5G technology will take some time to spread its wings in all real-time applications as discussed. This paper can help researchers to start integrating AI and Machine learning with 5G technology.","",""
2,"Mohammed Falah Allawi, I. R. Hussain, Majid Ibrahim Salman, A. El-Shafie","Monthly inflow forecasting utilizing advanced artificial intelligence methods: a case study of Haditha Dam in Iraq",2021,"","","","",160,"2022-07-13 09:20:45","","10.1007/s00477-021-02052-7","","",,,,,2,2.00,1,4,1,"","",""
15,"S. Athey, K. Bryan, J. Gans","The Allocation of Decision Authority to Human and Artificial Intelligence",2020,"","","","",161,"2022-07-13 09:20:45","","10.2139/ssrn.3517287","","",,,,,15,7.50,5,3,2,"The allocation of decision authority by a principal to either a human agent or an artificial intelligence (AI) is examined. The principal trades off an AI's more aligned choice with the need to motivate the human agent to expend effort in learning choice payoffs. When agent effort is desired, it is shown that the principal is more likely to give that agent decision authority, reduce investment in AI reliability, and adopt an AI that may be biased. Organizational design considerations are likely to have an impact on how AIs are trained.","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",162,"2022-07-13 09:20:45","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
0,"Ashwaq N. Hassan, S. Al-Chlaihawi, Ahlam R. Khekan","Artificial intelligence techniques over the fifth generation mobile networks: a review",2021,"","","","",163,"2022-07-13 09:20:45","","10.11591/ijeecs.v24.i1.pp317-328","","",,,,,0,0.00,0,3,1,"A well Fifth generation (5G) mobile networks have been a common phrase in recent years. We have all heard this phrase and know its importance. By 2025, the number of devices based on the fifth generation of mobile networks will reach about 100 billion devices. By then, about 2.5 billion users are expected to consume more than a gigabyte of streamed data per month. 5G will play important roles in a variety of new areas, from smart homes and cars to smart cities, virtual reality and mobile augmented reality, and 4K video streaming. Bandwidth much higher than the fourth generation, more reliability and less latency are some of the features that distinguish this generation of mobile networks from previous generations.  Clearly, at first glance, these features may seem very impressive and useful to a mobile network, but these features will pose serious challenges for operators and communications companies. All of these features will lead to considerable complexity. Managing this network, preventing errors, and minimizing latency are some of the challenges that the 5th generation of mobile networks will bring. Therefore, the use of artificial intelligence and machine learning is a good way to solve these challenges. in other say, in such a situation, proper management of the 5G network must be done using powerful tools such as artificial intelligence. Various researches in this field are currently being carried out. Research that enables automated management and servicing and reduces human error as much as possible. In this paper, we will review the artificial intelligence techniques used in communications networks. Creating a robust and efficient communications network using artificial intelligence techniques is a great incentive for future research. The importance of this issue is such that the sixth generation (6G) of cellular communications; There is a lot of emphasis on the use of artificial intelligence.","",""
0,"Ashwaq N. Hassan, S. Al-Chlaihawi, Ahlam R. Khekan","Artificial intelligence techniques over the fifth generation (5G) mobile networks: a review",2021,"","","","",164,"2022-07-13 09:20:45","","10.11591/IJEECS.V24.I1.PP%P","","",,,,,0,0.00,0,3,1,"A well Fifth generation (5G) mobile networks have been a common phrase in recent years. We have all heard this phrase and know its importance. By 2025, the number of devices based on the fifth generation of mobile networks will reach about 100 billion devices. By then, about 2.5 billion users are expected to consume more than a gigabyte of streamed data per month. 5G will play important roles in a variety of new areas, from smart homes and cars to smart cities, virtual reality and mobile augmented reality, and 4K video streaming. Bandwidth much higher than the fourth generation, more reliability and less latency are some of the features that distinguish this generation of mobile networks from previous generations.  Clearly, at first glance, these features may seem very impressive and useful to a mobile network, but these features will pose serious challenges for operators and communications companies. All of these features will lead to considerable complexity. Managing this network, preventing errors, and minimizing latency are some of the challenges that the 5th generation of mobile networks will bring. Therefore, the use of artificial intelligence and machine learning is a good way to solve these challenges. in other say, in such a situation, proper management of the 5G network must be done using powerful tools such as artificial intelligence. Various researches in this field are currently being carried out. Research that enables automated management and servicing and reduces human error as much as possible. In this paper, we will review the artificial intelligence techniques used in communications networks. Creating a robust and efficient communications network using artificial intelligence techniques is a great incentive for future research. The importance of this issue is such that the sixth generation (6G) of cellular communications; There is a lot of emphasis on the use of artificial intelligence.","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",165,"2022-07-13 09:20:45","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",166,"2022-07-13 09:20:45","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",167,"2022-07-13 09:20:45","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
14,"Linda W. Lee, Amir Dabirian, Ian Paul McCarthy, Jan H. Kietzmann","Making sense of text: artificial intelligence-enabled content analysis",2020,"","","","",168,"2022-07-13 09:20:45","","10.1108/ejm-02-2019-0219","","",,,,,14,7.00,4,4,2,"Purpose: The purpose of this paper is to introduce, apply and compare how artificial intelligence (AI), and specifically the IBM Watson system, can be used for content analysis in marketing research relative to manual and computer-aided (non-AI) approaches to content analysis.    Design/methodology/approach: To illustrate the use of AI-enabled content analysis, this paper examines the text of leadership speeches, content related to organizational brand. The process and results of using AI are compared to manual and computer-aided approaches by using three performance factors for content analysis: reliability, validity and efficiency.    Findings: Relative to manual and computer-aided approaches, AI-enabled content analysis provides clear advantages with high reliability, high validity and moderate efficiency.    Research limitations/implications: This paper offers three contributions. First, it highlights the continued importance of the content analysis research method, particularly with the explosive growth of natural language-based user-generated content. Second, it provides a road map of how to use AI-enabled content analysis. Third, it applies and compares AI-enabled content analysis to manual and computer-aided, using leadership speeches.    Practical implications: For each of the three approaches, nine steps are outlined and described to allow for replicability of this study. The advantages and disadvantages of using AI for content analysis are discussed. Together these are intended to motivate and guide researchers to apply and develop AI-enabled content analysis for research in marketing and other disciplines.    Originality/value: To the best of the authors' knowledge, this paper is among the first to introduce, apply and compare how AI can be used for content analysis.","",""
9,"A. Kevat, Anaath Kalirajah, R. Roseby","Artificial intelligence accuracy in detecting pathological breath sounds in children using digital stethoscopes",2020,"","","","",169,"2022-07-13 09:20:45","","10.1186/s12931-020-01523-9","","",,,,,9,4.50,3,3,2,"","",""
6,"N. Gahungu, Robert Trueick, S. Bhat, P. Sengupta, G. Dwivedi","Current Challenges and Recent Updates in Artificial Intelligence and Echocardiography",2020,"","","","",170,"2022-07-13 09:20:45","","10.1007/s12410-020-9529-x","","",,,,,6,3.00,1,5,2,"","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",171,"2022-07-13 09:20:45","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",172,"2022-07-13 09:20:45","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",173,"2022-07-13 09:20:45","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",174,"2022-07-13 09:20:45","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
2,"S. Atashrouz, M. Rahmani, Zahra Balzadeh, B. Nasernejad","Mathematical modeling of ethylene polymerization over advanced multisite catalysts: an artificial intelligence approach",2020,"","","","",175,"2022-07-13 09:20:45","","10.1007/s42452-020-2096-6","","",,,,,2,1.00,1,4,2,"","",""
4,"I. M. Salte, A. Oestvik, E. Smistad, D. Melichova, T. M. Nguyen, H. Brunvand, T. Edvardsen, L. Loevstakken, B. Grenne","545 Deep learning/artificial intelligence for automatic measurement of global longitudinal strain by echocardiography",2020,"","","","",176,"2022-07-13 09:20:45","","10.1093/ehjci/jez319.279","","",,,,,4,2.00,0,9,2,"      The Norwegian Health Association, South-Eastern Norway regional health Authority and the national program for clinical therapy research (KLINBEFORSK).        Global longitudinal strain (GLS) by echocardiography has incremental prognostic value in patients with acute myocardial infarction and heart failure compared to left ventricular (LV) ejection fraction and provides more reproducible measurements of LV function. Recent advances in machine learning for image analysis now open the possibility for robust fully automated tracing of the LV and measurement of global longitudinal strain (GLS), without any operator input. This could make real-time GLS possible and remove inter-reader variability, thus resulting in saved time and improved test-retest reliability. The aim of the present study was to investigate how measurements by this novel automatic method compares to conventional speckle tracking analyses of GLS.        100 transthoracic echocardiographic examinations were included from a clinical database of patients with acute myocardial infarction or de-novo heart failure. Examinations were included consecutively and regardless of image quality. Simpson biplane LV ejection fraction ranged from 7 to 70%. Images of three standard apical planes from each examination were analysed using our novel and fully automated GLS method based on deep learning technology. The automated GLS measurements were compared to conventional speckle tracking GLS measurements of the same acquisitions using vendor specific format and software (EchoPAC, GE Healthcare), performed by a single experienced observer.        GLS was -11.6 ± 4.5% and -12.8 ± 5.0% for the deep learning method and the conventional method, respectively. Bland-Altman analysis showed a bias of -0.7 ± 1,9% and 95% limits of agreement of -4,6 to 3.1. No clear value dependent bias was found by visual inspection (Figure A). Feasibility for measurement of GLS was 93% for the deep learning based method and 99% for the conventional method. The limits of agreement found in our study is comparable to findings in the intervendor comparison study by the EASCVI/ASE/Industry Task force to standardize deformation imaging.        This novel deep learning based method succeeds without any operator input to automatically identify and classify the three apical standard views, trace the myocardium, perform motion estimation and measure global longitudinal strain. This could further facilitate the clinical use of GLS as an important tool for enhancing clinical decision-making.  Abstract 545 Figure. ","",""
0,"Naser El Naily, S. Saad, S. Abeid, H. Saleh","Improved Over-Current Coordination Using Artificial Intelligence In Benghazi MV-Distribution Network Case Study",2020,"","","","",177,"2022-07-13 09:20:45","","10.1145/3410352.3410809","","",,,,,0,0.00,0,4,2,"Sustaining both of the security and the reliability of modern distribution networks requires high performance of the protection system, the coordination of the protective Over Current Relays (OCRs) optimally plays a key role in the protection of the Distribution Network (DN) in terms of its operations and isolating the affected parts during faults. Many factors force operators to optimally coordinate OCRs such as increasing daily activities of consumers and interconnected systems. In the DN, calculations of the OCRs breakpoint and orderly enumeration of multiple loops are the most important requirements for the coordination of OCR scheme. Consequently, avoiding blackouts and electricity interruption of some feeders from the grid. In this paper, a detailed improved OCR coordination by a mean of an intelligent technique using Benghazi MV-Distribution Network as a case study. The Water Cycle Algorithm (WCA) has been applied as one of the optimization techniques for the Benghazi MV-distribution Network. For validation purposes, Particle Swarm Optimization (PSO) has been implemented to check the applicability of the proposed WCA. A coded WCA and PSO are used in MATLAB to attain the OCR settings, then Benghazi MV-Distribution Network has been utilized in ETAP package to evaluate the robustness of the proposed approach. The proposed approach exhibit improved relay coordination.","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",178,"2022-07-13 09:20:45","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
13,"Valentin Kuleto, Milena P. Ilić, Mihail-Alexandru Dumangiu, Marko Ranković, Oliva M. D. Martins, D. Păun, Larisa Mihoreanu","Exploring Opportunities and Challenges of Artificial Intelligence and Machine Learning in Higher Education Institutions",2021,"","","","",179,"2022-07-13 09:20:45","","10.3390/su131810424","","",,,,,13,13.00,2,7,1,"The way people travel, organise their time, and acquire information has changed due to information technologies. Artificial intelligence (AI) and machine learning (ML) are mechanisms that evolved from data management and developing processes. Incorporating these mechanisms into business is a trend many different industries, including education, have identified as game-changers. As a result, education platforms and applications are more closely aligned with learners’ needs and knowledge, making the educational process more efficient. Therefore, AI and ML have great potential in e-learning and higher education institutions (HEI). Thus, the article aims to determine its potential and use areas in higher education based on secondary research and document analysis (literature review), content analysis, and primary research (survey). As referent points for this research, multiple academic, scientific, and commercial sources were used to obtain a broader picture of the research subject. Furthermore, the survey was implemented among students in the Republic of Serbia, with 103 respondents to generate data and information on how much knowledge of AI and ML is held by the student population, mainly to understand both opportunities and challenges involved in AI and ML in HEI. The study addresses critical issues, like common knowledge and stance of research bases regarding AI and ML in HEI; best practices regarding usage of AI and ML in HEI; students’ knowledge of AI and ML; and students’ attitudes regarding AI and ML opportunities and challenges in HEI. In statistical considerations, aiming to evaluate if the indicators were considered reflexive and, in this case, belong to the same theoretical dimension, the Correlation Matrix was presented, followed by the Composite Reliability. Finally, the results were evaluated by regression analysis. The results indicated that AI and ML are essential technologies that enhance learning, primarily through students’ skills, collaborative learning in HEI, and an accessible research environment.","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",180,"2022-07-13 09:20:45","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
57,"C. Connor","Artificial Intelligence and Machine Learning in Anesthesiology.",2019,"","","","",181,"2022-07-13 09:20:45","","10.1097/ALN.0000000000002694","","",,,,,57,19.00,57,1,3,"Commercial applications of artificial intelligence and machine learning have made remarkable progress recently, particularly in areas such as image recognition, natural speech processing, language translation, textual analysis, and self-learning. Progress had historically languished in these areas, such that these skills had come to seem ineffably bound to intelligence. However, these commercial advances have performed best at single-task applications in which imperfect outputs and occasional frank errors can be tolerated.The practice of anesthesiology is different. It embodies a requirement for high reliability, and a pressured cycle of interpretation, physical action, and response rather than any single cognitive act. This review covers the basics of what is meant by artificial intelligence and machine learning for the practicing anesthesiologist, describing how decision-making behaviors can emerge from simple equations. Relevant clinical questions are introduced to illustrate how machine learning might help solve them-perhaps bringing anesthesiology into an era of machine-assisted discovery.","",""
41,"Y. Ongena, M. Haan, Derya Yakar, T. Kwee","Patients’ views on the implementation of artificial intelligence in radiology: development and validation of a standardized questionnaire",2019,"","","","",182,"2022-07-13 09:20:45","","10.1007/s00330-019-06486-0","","",,,,,41,13.67,10,4,3,"","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",183,"2022-07-13 09:20:45","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
36,"S. Devalla, Zhang Liang, T. H. Pham, C. Boote, N. Strouthidis, Alexandre Hoang Thiery, M. Girard","Glaucoma management in the era of artificial intelligence",2019,"","","","",184,"2022-07-13 09:20:45","","10.1136/bjophthalmol-2019-315016","","",,,,,36,12.00,5,7,3,"Glaucoma is a result of irreversible damage to the retinal ganglion cells. While an early intervention could minimise the risk of vision loss in glaucoma, its asymptomatic nature makes it difficult to diagnose until a late stage. The diagnosis of glaucoma is a complicated and expensive effort that is heavily dependent on the experience and expertise of a clinician. The application of artificial intelligence (AI) algorithms in ophthalmology has improved our understanding of many retinal, macular, choroidal and corneal pathologies. With the advent of deep learning, a number of tools for the classification, segmentation and enhancement of ocular images have been developed. Over the years, several AI techniques have been proposed to help detect glaucoma by analysis of functional and/or structural evaluations of the eye. Moreover, the use of AI has also been explored to improve the reliability of ascribing disease prognosis. This review summarises the role of AI in the diagnosis and prognosis of glaucoma, discusses the advantages and challenges of using AI systems in clinics and predicts likely areas of future progress.","",""
0,"K. Behdinan","Using artificial intelligence to aid measurement accuracy and reliability in coriolis gas flow meters",2014,"","","","",185,"2022-07-13 09:20:45","","10.1049/CP.2014.0555","","",,,,,0,0.00,0,1,8,"Coriolis is one of the fastest growing technologies in the oil and gas flow measurement. Flow sensitivity, pressure drop, temperature changes and increased noise level affects the accuracy and reliability of these types of transmitters. However in most situations those parameters are not constant and not a mathematical model exist to include in the logic for the actual gas flow calculation. AGA Report Number 11 specifically concentrates on the measurement of natural gas and the impact of expanded compositional ranges on the flow calculation. Using Artificial intelligence enables performance characteristics that are much better than traditional metering technologies. Compressibility factors for natural gas and other Hydrocarbon gases are some of the factors that will be considered in artificial intelligence model for gas flow measurement. In this paper uncertain input parameters will be identified as fuzzy variables and will be integrated into fuzzy calculation of the gas flow measurement. It can be argued that Coriolis technology integrated with artificial intelligence greatly increases the accuracy and robustness of flow calculation. Uses of artificial intelligence in these types of Coriolis flow meters can minimize error and extend sensor life. This paper will discuss the appropriate implementation of such expert system with Coriolis flow measurement technology.","",""
23,"B. Chin-Yee, Ross E. G. Upshur","Three Problems with Big Data and Artificial Intelligence in Medicine",2019,"","","","",186,"2022-07-13 09:20:45","","10.1353/pbm.2019.0012","","",,,,,23,7.67,12,2,3,"ABSTRACT:The rise of big data and artificial intelligence (AI) in health care has engendered considerable excitement, claiming to improve approaches to diagnosis, prognosis, and treatment. Amidst the enthusiasm, the philosophical assumptions that underlie the big data and AI movement in medicine are rarely examined. This essay outlines three philosophical challenges faced by this movement: (1) the epistemological-ontological problem arising from the theory-ladenness of big data and measurement; (2) the epistemological-logical problem resulting from the inherent limitations of algorithms and attendant issues of reliability and interpretability; and (3) the phenomenological problem concerning the irreducibility of human experience to quantitative data. These philosophical issues demonstrate several important challenges for these technologies that must be considered prior to their integration into clinical care. Our article aims to initiate a critical dialogue on the impact of big data and AI in health care in order to allow for more robust evaluation of these technologies and to aid in the development of approaches to clinical care that better serve clinicians and their patients.","",""
2,"Neha Gupta, S. Gupta, Rajesh K. Pathak, Vanita Jain, P. Rashidi, J. Suri","Human activity recognition in artificial intelligence framework: a narrative review",2022,"","","","",187,"2022-07-13 09:20:45","","10.1007/s10462-021-10116-x","","",,,,,2,2.00,0,6,1,"","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",188,"2022-07-13 09:20:45","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
17,"Manuel F. Gonzalez, John F. Capman, F. Oswald, E. Theys, David L. Tomczak","“Where’s the I-O?” Artificial Intelligence and Machine Learning in Talent Management Systems",2019,"","","","",189,"2022-07-13 09:20:45","","10.25035/pad.2019.03.005","","",,,,,17,5.67,3,5,3,"Artificial intelligence (AI) and machine learning (ML) have seen widespread adoption by organizations seeking to identify and hire high-quality job applicants. Yet the volume, variety, and velocity of professional involvement among I-O psychologists remains relatively limited when it comes to developing and evaluating AI/ML applications for talent assessment and selection. Furthermore, there is a paucity of empirical research that investigates the reliability, validity, and fairness of AI/ML tools in organizational contexts. To stimulate future involvement and research, we share our review and perspective on the current state of AI/ML in talent assessment as well as its benefits and potential pitfalls; and in addressing the issue of fairness, we present experimental evidence regarding the potential for AI/ML to evoke adverse reactions from job applicants during selection procedures. We close by emphasizing increased collaboration among I-O psychologists, computer scientists, legal scholars, and members of other professional disciplines in developing, implementing, and evaluating AI/ML applications in organizational contexts.","",""
13,"Yu-Yin Wang, Yi-Shun Wang","Development and validation of an artificial intelligence anxiety scale: an initial application in predicting motivated learning behavior",2019,"","","","",190,"2022-07-13 09:20:45","","10.1080/10494820.2019.1674887","","",,,,,13,4.33,7,2,3,"ABSTRACT While increasing productivity and economic growth, the application of artificial intelligence (AI) may ultimately require millions of people around the world to change careers or improve their skills. These disruptive effects contribute to the general public anxiety toward AI development. Despite the rising levels of AI anxiety (AIA) in recent decades, no AI anxiety scale (AIAS) has been developed. Given the limited utility of existing self-report instruments in measuring AIA, the aim of this paper is to develop a standardized tool to measure this phenomenon. Specifically, this paper introduces and defines the construct of AIA, develops a generic AIAS, and discusses the theoretical and practical applications of the instrument. The procedures used to conceptualize the survey, create the measurement items, collect data, and validate the multi-item scale are described. By analyzing data obtained from a sample of 301 respondents, the reliability, criterion-related validity, content validity, discriminant validity, convergent validity, and nomological validity of the constructs and relationships are fully examined. Overall, this empirically validated instrument advances scholarly knowledge regarding AIA and its associated behaviors.","",""
1,"Asaf Tzachor, M. Devare, Brian King, S. Avin, Seán Ó hÉigeartaigh","Responsible artificial intelligence in agriculture requires systemic understanding of risks and externalities",2022,"","","","",191,"2022-07-13 09:20:45","","10.1038/s42256-022-00440-4","","",,,,,1,1.00,0,5,1,"","",""
0,"K. Sfakianoudis, E. Maziotis, S. Grigoriadis, A. Pantou, G. Kokkini, A. Trypidi, I. Angeli, T. Vaxevanoglou, K. Pantos, M. Simopoulou","O-122 Reporting on the value of Artificial Intelligence in predicting the optimal embryo for transfer: A systematic review and meta-analysis",2022,"","","","",192,"2022-07-13 09:20:45","","10.1093/humrep/deac105.022","","",,,,,0,0.00,0,10,1,"      Are Artificial Intelligence (AI) based models effective in robustly predicting in vitro fertilization (IVF) outcome by assessing embryo quality?        The majority of the AI-based models could provide an accurate prediction regarding live birth, clinical pregnancy, clinical pregnancy with fetal heartbeat and embryo ploidy status.        Precision and consistency in embryo quality evaluation are of paramount importance regarding the outcome of an IVF cycle. Numerous embryo grading and evaluation systems, employing morphological and morphokinetical assessment, have been proposed but without reaching a consensus yet. The main limitation of the aforementioned assessment systems is that they depend on human evaluation, which may be subject to subjectivity and interobserver variation. Thus, automated prediction models may be essential to optimize objectivity and reliability of embryo grading. Artificial neural network models may process microscopy images or time-lapse videos as input to predict the embryos’ potential competency.        A systematic review and meta-analysis including 18 published studies. The population consists of preimplantation embryos suitable for embryo transfer in IVF/ICSI cycles following employment of an AI-based prediction model. The outcome measures are prediction of live birth, clinical pregnancy, clinical pregnancy with heartbeat and ploidy status.        A systematic search of the literature was performed in the databases of Pubmed/Medline, Embase, and Cochrane Central Library limited to articles published in English up to August 2021. The initial search yielded a total of 694 studies with 97 of them being duplicates and other 579 being excluded on the grounds of not fulfilling inclusion criteria. Following full-text screening and citation mining a total of 18 studies were identified to be eligible for inclusion.        Four studies reported on prediction of live birth. The sensitivity was 70.6% (95%C.I.: 38.1-90.4%) and specificity was 90.6% (95%C.I.:79.3-96.1%).  The Area Under the Curve (AUC) of the Summary Receiver Operating Characteristics (SROC) curve was 0.905, while the partial AUC (pAUC) was 0.755. Employing the Bayesian approach, the total Observed:Expected ratio (O:E) was 1.12 (95%CI: 0.26–2.37; 95%PI:0.02-6.54). Ten studies reported on prediction of clinical pregnancy. The sensitivity and the specificity were 71% (95%C.I.: 58.1-81.2%) and 62.5% (95%C.I.: 47.4-75.5%) respectively. The AUC was 0.716, while pAUC was 0.693. Moreover, the total O:E ratio was 0.92 (95%CI: 0.61–1.28; 95%PI:0.13-2.43). Eight studies reported on prediction of clinical pregnancy with fetal heartbeat the sensitivity was 75.2% (95%C.I.: 66.8-82%) and the specificity was 55.3% (95%C.I.: 41.2-68.7%). The AUC was 0.722, while the pAUC was 0.774. The O:E ratio was 0.77 (95%CI: 0.54 – 1.05; 95%PI: 0.21-1.62). Four studies reported on the ploidy status of the embryo. The sensitivity and specificity were 59.4% (95%C.I.: 45.0-73.1%) and 79.2% (95%C.I.: 70.1-86.1%) respectively. The AUC was 0.751 and the pAUC was 0.585. The total O:E ratio was 0.86 (95%CI: 0.42 – 1.27; 95%PI: 0.03-1.83).        The limited number of studies fulfilling inclusion criteria, along with the different designs applied when developing AI models which may lead to increased heterogeneity, stand as limitations. Inclusion of women regardless of their age presents as another limitation, as advanced maternal age has been associated with diminished IVF outcomes.        Albeit, our findings support that AI is a highly promising tool in the era of personalized medicine providing precise predictions it does not appear to considerably surpass human prediction capabilities. More studies and more collaborations between the developers are of paramount importance prior to AI becoming the gold standard.        Not applicable ","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",193,"2022-07-13 09:20:45","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
0,"Lei Wang, Yujie Liang, Gaizhen Shang, Zhiyong Song, Pengyu Gao","The Use of Big Data Combined with Artificial Intelligence Neural Network Technology in Urban Spatial Evaluation System",2022,"","","","",194,"2022-07-13 09:20:45","","10.1155/2022/7936522","","",,,,,0,0.00,0,5,1,"This exploration aims to promote the development of urbanization in China and improve the utilization rate of urban resources. First, intensive theory and spatial economics are studied. Next, an input-output urban spatial evaluation system is established based on intensive theory and data envelopment analysis (DEA). Then, deep learning (DL) is adopted for optimization, and an urban space evaluation system based on DL is proposed. Finally, the reliability level of the urban space evaluation system is tested. The results show that the model's input and output index α values are above 0.9, and the overall reliability level is higher than 0.9, indicating that the urban space evaluation system has a high reliability. The training results of the DL model show that the mean absolute error (MAE) of model prediction decreases gradually with the increase of training time and training times. When the training lasts for 5 min, each index' MAE is basically stable between 0.22 and 0.23, and the evaluation accuracy is obvious. The urban space evaluation system based on DL has higher evaluation accuracy, reaching 83.40%. Therefore, this exploration can provide research experience for promoting the effective utilization of urban resources and provide a reference for formulating an urbanization evaluation index system suitable for China's national conditions.","",""
15,"Rav Panchalingam, K. C. Chan","A state-of-the-art review on artificial intelligence for Smart Buildings",2019,"","","","",195,"2022-07-13 09:20:45","","10.1080/17508975.2019.1613219","","",,,,,15,5.00,8,2,3,"ABSTRACT The use of AI technologies in Smart Buildings is increasing as there are wide-scale benefits that can be derived from improving the efficiency of a building's operation and management. Buildings currently account for around 40% of global energy use, with AI technologies offering the opportunity to significantly reduce energy consumption through better automation, control, and reliability. These technologies can also be utilised to improve the safety and comfort of building occupants. This paper provides a literature review of research that has been conducted into AI technologies for use in Smart Buildings across the major AI topics including expert systems, fuzzy logic, genetic algorithms, machine learning, machine vision, natural language processing, neural networks, and pattern recognition. This process resulted in the determination that the volume of research conducted to-date is skewed towards some AI topics such as machine learning, neural networks and pattern recognition over other topics such as deep learning and natural language processing. It has also served to provide insights into which areas are likely to benefit the most from focusing future research efforts in that direction.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",196,"2022-07-13 09:20:45","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",197,"2022-07-13 09:20:45","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
48,"T. Mahmood, Muhammad Arsalan, Muhammad Owais, Min Beom Lee, K. Park","Artificial Intelligence-Based Mitosis Detection in Breast Cancer Histopathology Images Using Faster R-CNN and Deep CNNs",2020,"","","","",198,"2022-07-13 09:20:45","","10.3390/jcm9030749","","",,,,,48,24.00,10,5,2,"Breast cancer is the leading cause of mortality in women. Early diagnosis of breast cancer can reduce the mortality rate. In the diagnosis, the mitotic cell count is an important biomarker for predicting the aggressiveness, prognosis, and grade of breast cancer. In general, pathologists manually examine histopathology images under high-resolution microscopes for the detection of mitotic cells. However, because of the minute differences between the mitotic and normal cells, this process is tiresome, time-consuming, and subjective. To overcome these challenges, artificial-intelligence-based (AI-based) techniques have been developed which automatically detect mitotic cells in the histopathology images. Such AI techniques accelerate the diagnosis and can be used as a second-opinion system for a medical doctor. Previously, conventional image-processing techniques were used for the detection of mitotic cells, which have low accuracy and high computational cost. Therefore, a number of deep-learning techniques that demonstrate outstanding performance and low computational cost were recently developed; however, they still require improvement in terms of accuracy and reliability. Therefore, we present a multistage mitotic-cell-detection method based on Faster region convolutional neural network (Faster R-CNN) and deep CNNs. Two open datasets (international conference on pattern recognition (ICPR) 2012 and ICPR 2014 (MITOS-ATYPIA-14)) of breast cancer histopathology were used in our experiments. The experimental results showed that our method achieves the state-of-the-art results of 0.876 precision, 0.841 recall, and 0.858 F1-measure for the ICPR 2012 dataset, and 0.848 precision, 0.583 recall, and 0.691 F1-measure for the ICPR 2014 dataset, which were higher than those obtained using previous methods. Moreover, we tested the generalization capability of our technique by testing on the tumor proliferation assessment challenge 2016 (TUPAC16) dataset and found that our technique also performs well in a cross-dataset experiment which proved the generalization capability of our proposed technique.","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",199,"2022-07-13 09:20:45","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",200,"2022-07-13 09:20:45","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
