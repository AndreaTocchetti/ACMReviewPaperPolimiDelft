Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
2,"Yue-Huan Wang, Zenan Li, Jingwei Xu, Ping Yu, Taolue Chen, Xiaoxing Ma","Predicted Robustness as QoS for Deep Neural Network Models",2020,"","","","",1,"2022-07-13 09:27:43","","10.1007/s11390-020-0482-6","","",,,,,2,1.00,0,6,2,"","",""
445,"Vincent Tjeng, Kai Y. Xiao, Russ Tedrake","Evaluating Robustness of Neural Networks with Mixed Integer Programming",2017,"","","","",2,"2022-07-13 09:27:43","","","","",,,,,445,89.00,148,3,5,"Neural networks have demonstrated considerable success on a wide variety of real-world problems. However, neural networks can be fooled by adversarial examples  – slightly perturbed inputs that are misclassified with high confidence. Verification of networks enables us to gauge their vulnerability to such adversarial examples. We formulate verification of piecewise-linear neural networks as a mixed integer program. Our verifier finds minimum adversarial distortions two to three orders of magnitude more quickly than the state-of-the-art. We achieve this via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available. The computational speedup enables us to verify properties on convolutional networks with an order of magnitude more ReLUs than had been previously verified by any complete verifier, and we determine for the first time the exact adversarial accuracy of an MNIST classifier to perturbations with bounded l[infinity] norm e = 0:1. On this network, we find an adversarial example for 4.38% of samples, and a certificate of robustness for the remainder. Across a variety of robust training procedures, we are able to certify more samples than the state-of-the-art and find more adversarial examples than a strong first-order attack for every network.","",""
1,"Amrith Rajagopal Setlur","Semi-Supervised Confidence Network aided Gated Attention based Recurrent Neural Network for Clickbait Detection",2018,"","","","",3,"2022-07-13 09:27:43","","","","",,,,,1,0.25,1,1,4,"Clickbaits are catchy headlines that are frequently used by social media outlets in order to allure its viewers into clicking them and thus leading them to dubious content. Such venal schemes thrive on exploiting the curiosity of naive social media users, directing traffic to web pages that won't be visited otherwise. In this paper, we propose a novel, semi-supervised classification based approach, that employs attentions sampled from a Gumbel-Softmax distribution to distill contexts that are fairly important in clickbait detection. An additional loss over the attention weights is used to encode prior knowledge. Furthermore, we propose a confidence network that enables learning over weak labels and improves robustness to noisy labels. We show that with merely 30% of strongly labeled samples we can achieve over 97% of the accuracy, of current state of the art methods in clickbait detection.","",""
4,"Ying Du, Yadong Liu, Xuhong Wang, Jian Fang, G. Sheng, Xiuchen Jiang","Predicting Weather-Related Failure Risk in Distribution Systems Using Bayesian Neural Network",2021,"","","","",4,"2022-07-13 09:27:43","","10.1109/TSG.2020.3019263","","",,,,,4,4.00,1,6,1,"The reliability of distribution systems is often challenged under unfavorable weather conditions, where weather-related failures occur with high probability. Predicting the number of weather-related failures in distribution systems can provide guiding information for operation and maintenance decisions, improving the risk management capability of utility companies. This article proposes a novel Bayesian Neural Network (BNN) based model to predict weather-related failures caused by wind, rain and lightning. Superior prediction performance of the BNN based model is verified by contrast experiments with other advanced prediction models under four different evaluation metrics. BNN based prediction model presents remarkable robustness, especially in the prediction of high failure levels. In addition, compared to most previous used prediction models without any prediction confidence feedback, BNN based prediction model has the capability of uncertainty estimation. The confidence interval of prediction results can be obtained, which provides sufficient information for guiding risk management of utility companies. An effective operation and maintenance guiding scheme based on the analysis of prediction uncertainty is proposed, which fully excavates the interpretability of the proposed model and enrich the application value of the model.","",""
0,"Navid Hashemi, Mahyar Fazlyab, Justin Ruths","Performance Bounds for Neural Network Estimators: Applications in Fault Detection",2021,"","","","",5,"2022-07-13 09:27:43","","10.23919/ACC50511.2021.9482752","","",,,,,0,0.00,0,3,1,"We exploit recent results in quantifying the robustness of neural networks to input variations to construct and tune a model-based anomaly detector, where the data-driven estimator model is provided by an autoregressive neural network. In tuning, we specifically provide upper bounds on the rate of false alarms expected under normal operation. To accomplish this, we provide a theory extension to allow for the propagation of multiple confidence ellipsoids through a neural network. The ellipsoid that bounds the output of the neural network under the input variation informs the sensitivity - and thus the threshold tuning - of the detector. We demonstrate this approach on a linear and nonlinear dynamical system.","",""
0,"F. Arnez, H. Espinoza, Ansgar Radermarcher, François Terrier","Deep Neural Network Uncertainty Estimation with Stochastic Inputs for Robust Aerial Navigation Policies",2021,"","","","",6,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,4,1,"Uncertainty quantification methods are required in autonomous systems that include deep learning (DL) components to assess the confidence of their estimations. However, to successfully deploy DL components in safety-critical autonomous systems, they should also handle uncertainty at the input rather than only at the output of the DL components. Considering a probability distribution in the input enables the propagation of uncertainty through different components to provide a representative measure of the overall system uncertainty. In this position paper, we propose a method to account for uncertainty at the input of Bayesian Deep Learning control policies for Aerial Navigation. Our early experiments show that the proposed method improves the robustness of the navigation policy in Out-of-Distribution (OoD) scenarios.","",""
0,"G. Kishan","Probabilistic Robustness Quantification of Neural Networks",2021,"","","","",7,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,1,"Safety properties of neural networks are critical to their application in safety-critical domains. Quantification of their robustness against uncertainties is an upcoming area of research. In this work, we propose an approach for providing probabilistic guarantees on the performance of a trained neural network. We present two novel metrics for probabilistic verification on training data distribution and test dataset. Given a trained neural network, we quantify the probability of the model to make errors on a random sample drawn from the training data distribution. Second, from the output logits of a sample test point, we measure its p-value on the learned logit distribution to quantify the confidence of the model at this test point. We compare our results with softmax based metric using the black-box adversarial attacks on a simple CNN architecture trained for MNIST digit classification.","",""
1,"Junbin Chen, Longcan Liu, Ruyi Huang, Weihua Li","Deep Feature-aligned Convolutional Neural Network for Machinery Fault Diagnosis",2020,"","","","",8,"2022-07-13 09:27:43","","10.1109/ICSMD50554.2020.9261675","","",,,,,1,0.50,0,4,2,"Convolutional neural network (CNN) has been witness to remarkable development and application over the past decade in the field of fault diagnosis. However, it has an obvious limitation that the property of shift-invariance in CNN is not robust enough, resulting in insufficient robustness of feature extraction, which is manifested by fluctuant prediction accuracy and confidence. Aiming at overcoming such limitation, in this paper, a deep feature alignment method is proposed for extracting aligned features from periodical vibration signals, and applied for the fault diagnosis of rotating machinery. First, considering the periodicity of bearing vibration signals, a feature-aligned CNN (FACNN) architecture is constructed to improve the shift-invariance of CNN. Second, the performance of the proposed structure is compared with the traditional CNN in three aspects: diagnosis accuracy, prediction confidence and feature robustness. Finally, a bearing fault diagnosis case was carried out on an experimental setup of machine tool to validate the effectiveness of FACNN. Experimental results have shown the FACNN outperforms the traditional CNN in the task of fault diagnosis for rotating machinery.","",""
0,"Xiaodong Wei, Yong Li, Xiaowei Qin, Xiaodong Xu, Ximin Li, Mengjie Liu","From Decoupling to Reconstruction: A Robust Graph Neural Network Against Topology Attacks",2020,"","","","",9,"2022-07-13 09:27:43","","10.1109/WCSP49889.2020.9299720","","",,,,,0,0.00,0,6,2,"Graph neural networks (GNNs) are criticized for poor robustness; their performance will decline seriously even with unnoticeable edge perturbations in node classification tasks. To against topology attacks, recent works punish edges based on data and attack characteristics (such as node similarity or SVD), or utilize the graph data distribution to absorb attacks (such as BayesianGCN or RGCN). We propose a robust GNN model based on topology reconstruction, which does not explicitly assume data or attack distributions. Our proposed method decouples graph data into attribute subgraph and topology subgraph and makes classifier cooperate with topology generator to label nodes. The classifier starts training from the attribute subgraph and labels some high-confidence nodes to join the trainset. Meanwhile, the generator reconstructs topology based on classification loss, topology subgraph, and link prediction, providing the classifier with new information. Extensive node classification experiments show that under the same attack conditions, our model has higher classification accuracy and stronger robustness compared with other latest robust GNN models.","",""
0,"Guoxuan Xia, Sangwon Ha, Tiago Azevedo, Partha P. Maji","An Underexplored Dilemma between Confidence and Calibration in Quantized Neural Networks",2021,"","","","",10,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,4,1,"Modern convolutional neural networks (CNNs) are known to be overconﬁdent in terms of their calibration on unseen input data. That is to say, they are more conﬁdent than they are accurate. This is undesirable if the probabilities predicted are to be used for downstream decision making. When considering accuracy, CNNs are also surprisingly robust to compression techniques, such as quantization, which aim to reduce computational and memory costs. We show that this robustness can be partially explained by the calibration behavior of modern CNNs, and may be improved with overconﬁdence. This is due to an intuitive result: low conﬁdence predictions are more likely to change post-quantization, whilst being less accurate. High conﬁdence predictions will be more accurate, but more difﬁcult to change. Thus, a minimal drop in post-quantization accuracy is incurred. This presents a potential conﬂict in neural network design: worse calibration from overconﬁdence may lead to better robustness to quantization. We perform experiments applying post-training quantization to a variety of CNNs, on the CIFAR-100 and ImageNet datasets, and make our code publicly available. 1","",""
19,"Jens Henriksson, C. Berger, Markus Borg, Lars Tornberg, Cristofer Englund, S. Sathyamoorthy, Stig Ursing","Towards Structured Evaluation of Deep Neural Network Supervisors",2019,"","","","",11,"2022-07-13 09:27:43","","10.1109/AITEST.2019.00-12","","",,,,,19,6.33,3,7,3,"Deep Neural Networks (DNN) have improved the quality of several non-safety related products in the past years. However, before DNNs should be deployed to safety-critical applications, their robustness needs to be systematically analyzed. A common challenge for DNNs occurs when input is dissimilar to the training set, which might lead to high confidence predictions despite proper knowledge of the input. Several previous studies have proposed to complement DNNs with a supervisor that detects when inputs are outside the scope of the network. Most of these supervisors, however, are developed and tested for a selected scenario using a specific performance metric. In this work, we emphasize the need to assess and compare the performance of supervisors in a structured way. We present a framework constituted by four datasets organized in six test cases combined with seven evaluation metrics. The test cases provide varying complexity and include data from publicly available sources as well as a novel dataset consisting of images from simulated driving scenarios. The latter we plan to make publicly available. Our framework can be used to support DNN supervisor evaluation, which in turn could be used to motive development, validation, and deployment of DNNs in safety-critical applications.","",""
1,"M. Vowels, S. Akbari, Jalal Etesami, N. C. Camgoz, R. Bowden","A Free Lunch with Influence Functions? Improving Neural Network Estimates with Concepts from Semiparametric Statistics",2022,"","","","",12,"2022-07-13 09:27:43","","","","",,,,,1,1.00,0,5,1,"Parameter estimation in the empirical fields is usually undertaken using parametric models, and such models are convenient because they readily facilitate statistical inference. Unfortunately, they are unlikely to have a sufficiently flexible functional form to be able to adequately model realworld phenomena, and their usage may therefore result in biased estimates and invalid inference. Unfortunately, whilst non-parametric machine learning models may provide the needed flexibility to adapt to the complexity of realworld phenomena, they do not readily facilitate statistical inference, and may still exhibit residual bias. We explore the potential for semiparametric theory (in particular, the Influence Function) to be used to improve neural networks and machine learning algorithms in terms of (a) improving initial estimates without needing more data (b) increasing the robustness of our models, and (c) yielding confidence intervals for statistical inference. We propose a new neural network method ‘MultiNet’, which seeks the flexibility and diversity of an ensemble using a single architecture. Results on causal inference tasks indicate that MultiNet yields better performance than other approaches, and that all considered methods are amenable to improvement from semiparametric techniques under certain conditions. In other words, with these techniques we show that we can improve existing neural networks for ‘free’, without needing more data, and without needing to retrain them. Finally, we provide the expression for deriving influence functions for estimands from a general graph, and the code to do so automatically.","",""
1,"Yang Cui, Shi Yan, Huiquan Zhang, Siyu Huang","Ultra-Short-Term Prediction of Wind Power Based on Chaos Theory and ABC Optimized RBF Neural Network",2019,"","","","",13,"2022-07-13 09:27:43","","10.1109/CIEEC47146.2019.CIEEC-2019517","","",,,,,1,0.33,0,4,3,"Wind energy has strong randomness and volatility, which makes the prediction accuracy of wind power low. In an attempt to improve the accuracy and robustness of ultra-short term prediction of wind power, a wind power prediction method in ultra-short term combining chaos theory and artificial bee colony(ABC) algorithm to optimize RBF neural network is studied in this paper. Firstly, based on chaos theory, the historical wind power data with the highest correlation is found, which is used for RBF neural network training after phase space reconstruction. Then, the artificial bee colony algorithm is used to solve the optimal RBF neural network parameters through multiple iterations to construct the optimized neural network model. Finally, considering the uncertainty of the prediction model and data noise, the prediction results are interval, and the robustness of the prediction results is evaluated by calculating the confidence of the corresponding interval. The results of the example show that the method proposed in this paper has good accuracy and robustness.","",""
0,"Ben Qi, Liguo Zhang, Jin'gang Liang, J. Tong","Combinatorial Techniques for Fault Diagnosis in Nuclear Power Plants Based on Bayesian Neural Network and Simplified Bayesian Network-Artificial Neural Network",2022,"","","","",14,"2022-07-13 09:27:43","","10.3389/fenrg.2022.920194","","",,,,,0,0.00,0,4,1,"Knowledge-driven and data-driven methods are the two representative categories of intelligent technologies used in fault diagnosis in nuclear power plants. Knowledge-driven methods have advantages in interpretability and robustness, while data-driven methods have better performance in ease of modeling and inference efficiency. Given the complementarity of the two methods, a combination of them is a worthwhile investigation. In this work, we introduce two new techniques based on Bayesian theory (knowledge-driven) and artificial neural network (data-driven) for fault diagnosis in nuclear power plants. The first approach exploits an integrated technique, Bayesian Neural Network (BNN), which introduces Bayesian theory into the neural network to provide confidence in diagnosis. The second approach, denoted as Simplified Bayesian Network-Artificial Neural Network (SBN-ANN), adopts a hierarchical diagnosis idea, which firstly uses a simplified Bayesian network to diagnose fault types and then a neural network to diagnose the severity of faults. The two new techniques are implemented and verified with simulated faults data of a typical pressurized water reactor. Compared with single-algorithmic diagnostic approaches such as Bayesian network and neural network, the new combinatorial techniques show better performance in diagnostic precision. The results suggest the feasibility to develop the data and knowledge dual-drive technologies for fault diagnosis.","",""
0,"Roland S. Zimmermann, Wieland Brendel, Florian Tramèr, Nicholas Carlini","Increasing Confidence in Adversarial Robustness Evaluations",2022,"","","","",15,"2022-07-13 09:27:43","","10.48550/arXiv.2206.13991","","",,,,,0,0.00,0,4,1,"Hundreds of defenses have been proposed to make deep neural networks robust against minimal (adversarial) input perturbations. However, only a handful of these defenses held up their claims because correctly evaluating robustness is extremely challenging: Weak attacks often fail to ﬁnd adversarial examples even if they unknowingly exist, thereby making a vulnerable network look robust. In this paper, we propose a test to identify weak attacks, and thus weak defense evaluations. Our test slightly modiﬁes a neural network to guarantee the existence of an adversarial example for every sample. Consequentially, any correct attack must succeed in breaking this modiﬁed network. For eleven out of thirteen previously-published defenses, the original evaluation of the defense fails our test, while stronger attacks that break these defenses pass it. We hope that attack unit tests — such as ours — will be a major component in future robustness evaluations and increase conﬁdence in an empirical ﬁeld that is currently riddled with skepticism. Online version & code: zimmerrol.github.io/active-tests/","",""
0,"Yunlong Zhang, Yuxuan Sun, Honglin Li, S. Zheng, Chenglu Zhu, L. Yang","Benchmarking the Robustness of Deep Neural Networks to Common Corruptions in Digital Pathology",2022,"","","","",16,"2022-07-13 09:27:43","","10.48550/arXiv.2206.14973","","",,,,,0,0.00,0,6,1,". When designing a diagnostic model for a clinical application, it is crucial to guarantee the robustness of the model with respect to a wide range of image corruptions. Herein, an easy-to-use benchmark is established to evaluate how deep neural networks perform on corrupted pathology images. Speciﬁcally, corrupted images are generated by injecting nine types of common corruptions into validation images. Besides, two classiﬁcation and one ranking metrics are designed to evaluate the prediction and conﬁdence performance under corruption. Evaluated on two resulting benchmark datasets, we ﬁnd that (1) a va-riety of deep neural network models suﬀer from a signiﬁcant accuracy decrease (double the error on clean images) and the unreliable conﬁdence estimation on corrupted images; (2) A low correlation between the validation and test errors while replacing the validation set with our benchmark can increase the correlation. Our codes are available on https://github.com/superjamessyx/robustness_benchmark .","",""
0,"Prabakaran Balasubramanian, Vikram Kaushik, Sumaya Altamimi, M. Amabili, Mohamed Alteneiji","Comparison of neural networks based on accuracy and robustness in identifying impact location for structural health monitoring applications",2022,"","","","",17,"2022-07-13 09:27:43","","10.1177/14759217221098569","","",,,,,0,0.00,0,5,1,"Structural health monitoring systems must provide accuracy and robustness in predicting the structure’s health using the minimum intervention to ensure commercial viability. Characterization of impact is useful in assessing its severity, deciding if detailed damage analysis is necessary, and re-evaluating the present health of the structure under monitoring with better confidence. In this characterization process, the impact location is significant since some positions within a structure are more sensitive to damage. The inherent noise and uncertainties present in the sensor response pose a substantial hurdle to estimating the external impact correctly. This paper quantitatively compares three of the widely used neural networks, namely, Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Long Short-Term Memory network (LSTM), to estimate impact location from the lead zirconate titanate (PZT) sensor response. For this purpose, a square aluminum plate of 500 × 500 mm was equipped with four PZT sensors; each placed 100 mm away in both the plate directions from a corner and impact loads were given on a grid covering the whole plate. The PZT responses were used to train the three neural networks under study here, and their estimations were compared based on the Mean Absolute Error (MAE). In addition, increasing Gaussian noise was added to the PZT responses, and the robustness of the three neural networks was monitored. It was found that the ANN gives better accuracy with a Mean Absolute Error of 22 mm compared to Convolutional Neural Network (MAE = 31 mm) and Long Short-Term Memory (MAE = 25 mm). However, CNN is more robust when encountering noise with a 2% reduction in accuracy, while LSTM and ANN lost 7% and 11% accuracy, respectively.","",""
5,"A. Murthy, Himel Das, Md. Ariful Islam","Robustness of Neural Networks to Parameter Quantization",2019,"","","","",18,"2022-07-13 09:27:43","","10.1007/978-3-030-31514-6_9","","",,,,,5,1.67,2,3,3,"","",""
14,"Weiwen Liu, Ruiming Tang, Jiajin Li, Jinkai Yu, Huifeng Guo, Xiuqiang He, Shengyu Zhang","Field-aware probabilistic embedding neural network for CTR prediction",2018,"","","","",19,"2022-07-13 09:27:43","","10.1145/3240323.3240396","","",,,,,14,3.50,2,7,4,"For Click-Through Rate (CTR) prediction, Field-aware Factorization Machines (FFM) have exhibited great effectiveness by considering field information. However, it is also observed that FFM suffers from the overfitting problem in many practical scenarios. In this paper, we propose a Field-aware Probabilistic Embedding Neural Network (FPENN) model with both good generalization ability and high accuracy. FPENN estimates the probability distribution of the field-aware embedding rather than using the single point estimation (the maximum a posteriori estimation) to prevent overfitting. Both low-order and high-order feature interactions are considered to improve the accuracy. FPENN consists of three components, i.e., FPE component, Quadratic component and Deep component. FPE component outputs probabilistic embedding to the other two components, where various confidence levels for feature embeddings are incorporated to enhance the robustness and the accuracy. Quadratic component is designed for extracting low-order feature interactions, while Deep component aims at capturing high-order feature interactions. Experiments are conducted on two benchmark datasets, Avazu and Criteo. The results confirm that our model alleviates the overfitting problem while having a higher accuracy.","",""
0,"R. Cornish, George Deligiannidis, A. Doucet","Robust Predictive Uncertainty for Neural Networks via Confidence Densities",2019,"","","","",20,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,3,3,"Neural networks are known to make incorrect predictions with high confidence when given inputs that are unlike their training set. This creates problems when a trained network is deployed on real-world data, since covariate shift away from the training set is usually inevitable. We propose confidence densities for explicitly controlling the predictions made by a network on out-ofsample inputs. Intuitively, our method makes confidence a finite resource for our network, which encourages making uniform predictions in regions away from the training data. Confidence densities may be used in conjunction with any offthe-shelf network architecture and can be trained using stochastic gradient descent. We show empirically that our method significantly improves outof-sample robustness while maintaining the same classification accuracy across several datasets. 1. Problem setting We consider the task of learning a predictive distribution p(y|x) given n i.i.d. data points (xi, yi) ∼ p(x, y), where the xi ∈ X are data and the yi ∈ {1, . . . ,K} are discrete labels. Here, given some x, p(y|x) denotes the full distribution over labels. We will denote the probability that y specifically takes label k by p(y = k|x). At present, neural networks provide state-of-the-art classification performance for a wide variety of different p(x, y). Standard methods use a given network architecture to parameterise a family of predictive distributions q(y|x) (often by attaching a softmax output layer), and then try to choose q(y|x) as close as possible to p(y|x) as measured by some loss function. A widely used choice of loss function is the Department of Engineering Science, University of Oxford, Oxford, UK Department of Statistics, University of Oxford, Oxford, UK. Correspondence to: Rob Cornish <rcornish@robots.ox.ac.uk>. Presented at the ICML 2019 Workshop on Uncertainty and Robustness in Deep Learning. Copyright 2019 by the author(s). Standard neural network D ec is io n re gi on s Monte Carlo dropout Our method En tro py o f p re di ct io ns","",""
1,"Wenxia Bao, Yaping Yang, Dong Liang, Ming Zhu","Human Pose Estimation Based on Step Deep Convolution Neural Network",2018,"","","","",21,"2022-07-13 09:27:43","","10.1109/CISP-BMEI.2018.8633110","","",,,,,1,0.25,0,4,4,"To improve the accuracy and robustness of human pose estimation, a step deep convolution neural network is proposed, which consists of a feed forward module and several step modules. Image features output from the last four layers of feed forward module are fused with the context features, the fused features are used as the input of the first step module; Image features of each step module fused with context features are used as the input of the next step module; The confidence map output from the last step module is used to predict joint position. This stepwise approach increases the receptive fields, which is good to learn the long-distance relationship between joints and predicting the position of occluded joints. At the same time, the confidence calculated by the previous module provides more and more accurate estimation of the position of each joint in the subsequent modules. In addition, the network also provides a way to strengthen the intermediate supervision by learning the objective function, so as to supplement the gradient of back-propagation and adjust the learning process, which effectively solves problem that the gradient disappears during training. Our approach is tested on two standard datasets of Leeds Sports Poses (LSP) and Frames Labeled In Cinema (FLIC), whose results indicate that our network has better performance in pose estimation of human body.","",""
1,"Mahdieh Abbasi, Christian Gagné","Out-distribution training confers robustness to deep neural networks",2018,"","","","",22,"2022-07-13 09:27:43","","","","",,,,,1,0.25,1,2,4,"The easiness at which adversarial instances can be generated in deep neural networks raises some fundamental questions on their functioning and concerns on their use in critical systems. In this paper, we draw a connection between over-generalization and adversaries: a possible cause of adversaries lies in models designed to make decisions all over the input space, leading to inappropriate high-confidence decisions in parts of the input space not represented in the training set. We empirically show an augmented neural network, which is not trained on any types of adversaries, can increase the robustness by detecting black-box one-step adversaries, i.e. assimilated to out-distribution samples, and making generation of white-box one-step adversaries harder.","",""
0,"D. Franks, G. Ruxton","Robustness of Neural Network Models",2010,"","","","",23,"2022-07-13 09:27:43","","10.1007/978-1-4419-5797-9_13","","",,,,,0,0.00,0,2,12,"","",""
12,"Jun Jiang, Renato Miyagusuku, A. Yamashita, H. Asama","Glass confidence maps building based on neural networks using laser range-finders for mobile robots",2017,"","","","",24,"2022-07-13 09:27:43","","10.1109/SII.2017.8279246","","",,,,,12,2.40,3,4,5,"In this paper, we propose a method to classify glass and non-glass objects and build glass confidence maps for indoor mobile robots using laser range-finders (LRFs). The glass confidence map is aimed to improve robot localization systems' robustness and accuracy in glass environments. For most LRF-based localization systems, objects are assumed to be detectable from all incident angles, which is true for non-reflective and non-transparent objects, like walls. However, glass can only be detected by LRFs in certain incident angles. This glass detection failure decreases robots' localization accuracy. Exhibiting glass' position in the map and taking its detection failure into consideration can increase the localization accuracy. We propose the usage of a neural network to classify glass and non-glass objects, with LRF's measured intensity, distance and incident angles as inputs. We verified our method experimentally, and experimental results show that our method can successfully distinguish glass from non-glass objects and accurately construct a glass confidence map with high confidence.","",""
0,"Hongmei Liu, Lianfeng Li, Chen Lu, Wanli Zhao, Xuan Wang","Performance assessment for aileron actuators based on MF-DFA and SOM neural network",2016,"","","","",25,"2022-07-13 09:27:43","","10.1109/WCICA.2016.7578342","","",,,,,0,0.00,0,5,6,"To improve the robustness of performance assessment for aileron actuators, a novel performance assessment for aileron actuators using multi-fractal detrended fluctuation analysis (MF-DFA) and self-organizing mapping (SOM) neural network is first proposed. First, a generalized regression neural network (GRNN) is employed to establish a fault observer, then the residue is generated by subtracting the actual actuator system output from the observer output. Second, the residue's feature is extracted by MF-DFA. Third, SOM neural network, trained only by the normal residue's feature, is used to obtain the minimum quantization error (MQE) between the current feature and the normal feature, and the health confidence value (CV) is obtained by normalizing MQE. Lastly, four types of faults, namely electronic amplifier gain abrupt change, electronic amplifier gain gradual change, sensor gain change and cylinder leakage, are applied to validate the effectiveness of the proposed method.","",""
22,"Sahar Ghannay, Y. Estève, Nathalie Camelin","Word embeddings combination and neural networks for robustness in ASR error detection",2015,"","","","",26,"2022-07-13 09:27:43","","10.1109/EUSIPCO.2015.7362668","","",,,,,22,3.14,7,3,7,"This study focuses on error detection in Automatic Speech Recognition (ASR) output. We propose to build a confidence classifier based on a neural network architecture, which is in charge to attribute a label (error or correct) for each word within an ASR hypothesis. This classifier uses word embed-dings as inputs, in addition to ASR confidence-based, lexical and syntactic features. We propose to evaluate the impact of three different kinds of word embeddings on this error detection approach, and we present a solution to combine these three different types of word embeddings in order to take advantage of their complementarity. In our experiments, different approaches are evaluated on the automatic transcriptions generated by two different ASR systems applied on the ETAPE corpus (French broadcast news). Experimental results show that the proposed neural architectures achieve a CER reduction comprised between 4% and 5.8% in error detection, depending on test dataset, in comparison with a state-of-the-art CRF approach.","",""
4,"Ping-Ting Hu, Weiqiang Wang, K. Lu","Video text detection with text edges and convolutional neural network",2015,"","","","",27,"2022-07-13 09:27:43","","10.1109/ACPR.2015.7486588","","",,,,,4,0.57,1,3,7,"Text and captions in videos provide useful information for content analysis and understanding. In this paper, we present an approach to detecting video text in a coarse-to-fine strategy. In the coarse phase we propose an efficient method to detect multi-scale candidate text regions with high recall. Then the candidate text regions are segmented and sent to the fine phase where a convolutional neural network(CNN) is applied to generate a confidence map for each candidate text region. Finally, the candidate text regions are further refined and partitioned into text lines by projection analysis. The CNN classifier in the fine phase enables feature sharing and robustly identifies text regions. The coarse phase sharply reduce the number of windows needed to be scanned by the CNN. The combination endows the proposed method with both efficiency and robustness when detecting video text. It was verified by experiment results on two publicly testing datasets and a dataset created by us.","",""
4,"Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, R. Venkatesh Babu","Boosting Adversarial Robustness using Feature Level Stochastic Smoothing",2021,"","","","",28,"2022-07-13 09:27:43","","10.1109/CVPRW53098.2021.00019","","",,,,,4,4.00,1,4,1,"Advances in adversarial defenses have led to a significant improvement in the robustness of Deep Neural Networks. However, the robust accuracy of present state-of-the-art defenses is far from the requirements in critical applications such as robotics and autonomous navigation systems. Further, in practical use cases, network prediction alone might not suffice, and assignment of a confidence value for the prediction can prove crucial. In this work, we propose a generic method for introducing stochasticity in the network predictions, and utilize this for smoothing decision boundaries and rejecting low confidence predictions, thereby boosting the robustness on accepted samples. The proposed Feature Level Stochastic Smoothing based classification also results in a boost in robustness without rejection over existing adversarial training methods. Finally, we combine the proposed method with adversarial detection methods, to achieve the benefits of both approaches.","",""
4,"Xin Huang, Stephen G. McGill, Jonathan A. DeCastro, B. Williams, L. Fletcher, J. Leonard, G. Rosman","CARPAL: Confidence-Aware Intent Recognition for Parallel Autonomy",2020,"","","","",29,"2022-07-13 09:27:43","","10.1109/LRA.2021.3068894","","",,,,,4,2.00,1,7,2,"Predicting driver intentions is a difficult and crucial task for advanced driver assistance systems. Traditional confidence measures on predictions often ignore the way predicted trajectories affect downstream decisions for safe driving. In this letter, we propose a novel multi-task intent recognition neural network that predicts not only probabilistic driver trajectories, but also utility statistics associated with the predictions for a given downstream task. We establish a decision criterion for parallel autonomy that takes into account the role of driver trajectory prediction in real-time decision making by reasoning about estimated task-specific utility statistics. We further improve the robustness of our system by considering uncertainties in downstream planning tasks that may lead to unsafe decisions. We test our online system on a realistic urban driving dataset, and demonstrate its advantage in terms of recall and fall-out metrics compared to baseline methods, and demonstrate its effectiveness in intervention and warning use cases.","",""
0,"Joonhyuk Yoo","Adversarial-Mixup : Increasing Robustness to Out-of-Distribution Data and Reliability of Inference )",2021,"","","","",30,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,1,"Detecting Out-of-Distribution (OOD) data is fundamentally required when Deep Neural Network (DNN) is applied to real-world AI such as autonomous driving. However, modern DNNs are quite vulnerable to the over-confidence problem even if the test data are far away from the trained data distribution. To solve the problem, this paper proposes a novel Adversarial-Mixup training method to let the DNN model be more robust by detecting OOD data effectively. Experimental results show that the proposed Adversarial-Mixup method improves the overall performance of OOD detection by 78% comparing with the State-of-the-Art methods. Furthermore, we show that the proposed method can alleviate the over-confidence problem by reducing the confidence score of OOD data than the previous methods, resulting in more reliable and robust DNNs.","",""
0,"Simon Wagner, Chandana Panati, Stefan Brüggenwirth","Fool the COOL - On the Robustness of Deep Learning SAR ATR Systems",2021,"","","","",31,"2022-07-13 09:27:43","","10.1109/RadarConf2147009.2021.9455231","","",,,,,0,0.00,0,3,1,"Over the last years, deep learning automatic target recognition systems have become very popular for synthetic aperture radar images. These systems achieve very high classification rates with common datasets, like the Moving and Stationary Target Acquisition and Recognition (MSTAR) data. A point that is normally not considered is the robustness of these systems, which typically use a softmax layer without rejection class for classification. It has been reported in the past that small variations in the training and test data of deep neural networks might lead to a change in the result. To avoid this situation, several methods to increase the robustness are presented in this paper. These methods vary from simple, like training with noisy samples, to changes in the network structure, particularly the Competitive Overcomplete Output Layer (COOL) is proposed. The COOL gives an output value that also represents a confidence, but with a larger variation than the softmax output. To evaluate the robustness, the DeepFool algorithm is used to creates adversarial examples, i.e. images that look similar to the original data, but cause a wrong classification result. This algorithm is applied to the known training data of the different networks.","",""
18,"Aounon Kumar, Alexander Levine, S. Feizi, T. Goldstein","Certifying Confidence via Randomized Smoothing",2020,"","","","",32,"2022-07-13 09:27:43","","","","",,,,,18,9.00,5,4,2,"Randomized smoothing has been shown to provide good certified-robustness guarantees for high-dimensional classification problems. It uses the probabilities of predicting the top two most-likely classes around an input point under a smoothing distribution to generate a certified radius for a classifier's prediction. However, most smoothing methods do not give us any information about the \emph{confidence} with which the underlying classifier (e.g., deep neural network) makes a prediction. In this work, we propose a method to generate certified radii for the prediction confidence of the smoothed classifier. We consider two notions for quantifying confidence: average prediction score of a class and the margin by which the average prediction score of one class exceeds that of another. We modify the Neyman-Pearson lemma (a key theorem in randomized smoothing) to design a procedure for computing the certified radius where the confidence is guaranteed to stay above a certain threshold. Our experimental results on CIFAR-10 and ImageNet datasets show that using information about the distribution of the confidence scores allows us to achieve a significantly better certified radius than ignoring it. Thus, we demonstrate that extra information about the base classifier at the input point can help improve certified guarantees for the smoothed classifier.","",""
5,"Isaac Dunn, Laura Hanu, Hadrien Pouget, D. Kroening, T. Melham","Evaluating Robustness to Context-Sensitive Feature Perturbations of Different Granularities",2020,"","","","",33,"2022-07-13 09:27:43","","","","",,,,,5,2.50,1,5,2,"We cannot guarantee that training datasets are representative of the distribution of inputs that will be encountered during deployment. So we must have confidence that our models do not over-rely on this assumption. To this end, we introduce a new method that identifies context-sensitive feature perturbations (e.g. shape, location, texture, colour) to the inputs of image classifiers. We produce these changes by performing small adjustments to the activation values of different layers of a trained generative neural network. Perturbing at layers earlier in the generator causes changes to coarser-grained features; perturbations further on cause finer-grained changes. Unsurprisingly, we find that state-of-the-art classifiers are not robust to any such changes. More surprisingly, when it comes to coarse-grained feature changes, we find that adversarial training against pixel-space perturbations is not just unhelpful: it is counterproductive.","",""
2,"Ryne Roady, Tyler L. Hayes, Christopher Kanan","Improved Robustness to Open Set Inputs via Tempered Mixup",2020,"","","","",34,"2022-07-13 09:27:43","","10.1007/978-3-030-66415-2_12","","",,,,,2,1.00,1,3,2,"","",""
1,"S. Tuli, G. Casale, N. Jennings","CAROL: Confidence-Aware Resilience Model for Edge Federations",2022,"","","","",35,"2022-07-13 09:27:43","","10.48550/arXiv.2203.07140","","",,,,,1,1.00,0,3,1,"In recent years, the deployment of large-scale Internet of Things (IoT) applications has given rise to edge federations that seamlessly interconnect and leverage resources from multiple edge service providers. The requirement of supporting both latency-sensitive and compute-intensive IoT tasks necessitates service resilience, especially for the broker nodes in typical brokerworker deployment designs. Existing fault-tolerance or resilience schemes often lack robustness and generalization capability in non-stationary workload settings. This is typically due to the expensive periodic fine-tuning of models required to adapt them in dynamic scenarios. To address this, we present a confidence aware resilience model, CAROL, that utilizes a memory-efficient generative neural network to predict the Quality of Service (QoS) for a future state and a confidence score for each prediction. Thus, whenever a broker fails, we quickly recover the system by executing a local-search over the broker-worker topology space and optimize future QoS. The confidence score enables us to keep track of the prediction performance and run parsimonious neural network fine-tuning to avoid excessive overheads, further improving the QoS of the system. Experiments on a RaspberryPi based edge testbed with IoT benchmark applications show that CAROL outperforms state-of-the-art resilience schemes by reducing the energy consumption, deadline violation rates and resilience overheads by up to 16, 17 and 36 percent, respectively.","",""
140,"Daniel Jakubovitz, R. Giryes","Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization",2018,"","","","",36,"2022-07-13 09:27:43","","10.1007/978-3-030-01258-8_32","","",,,,,140,35.00,70,2,4,"","",""
39,"Sunok Kim, Dongbo Min, Seungryong Kim, K. Sohn","Unified Confidence Estimation Networks for Robust Stereo Matching",2019,"","","","",37,"2022-07-13 09:27:43","","10.1109/TIP.2018.2878325","","",,,,,39,13.00,10,4,3,"We present a deep architecture that estimates a stereo confidence, which is essential for improving the accuracy of stereo matching algorithms. In contrast to existing methods based on deep convolutional neural networks (CNNs) that rely on only one of the matching cost volume or estimated disparity map, our network estimates the stereo confidence by using the two heterogeneous inputs simultaneously. Specifically, the matching probability volume is first computed from the matching cost volume with residual networks and a pooling module in a manner that yields greater robustness. The confidence is then estimated through a unified deep network that combines confidence features extracted both from the matching probability volume and its corresponding disparity. In addition, our method extracts the confidence features of the disparity map by applying multiple convolutional filters with varying sizes to an input disparity map. To learn our networks in a semi-supervised manner, we propose a novel loss function that use confident points to compute the image reconstruction loss. To validate the effectiveness of our method in a disparity post-processing step, we employ three post-processing approaches; cost modulation, ground control points-based propagation, and aggregated ground control points-based propagation. Experimental results demonstrate that our method outperforms state-of-the-art confidence estimation methods on various benchmarks.","",""
1,"S. Booth, Ankit J. Shah, Yilun Zhou, J. Shah","Sampling Prediction-Matching Examples in Neural Networks: A Probabilistic Programming Approach",2020,"","","","",38,"2022-07-13 09:27:43","","","","",,,,,1,0.50,0,4,2,"Though neural network models demonstrate impressive performance, we do not understand exactly how these black-box models make individual predictions. This drawback has led to substantial research devoted to understand these models in areas such as robustness, interpretability, and generalization ability. In this paper, we consider the problem of exploring the prediction level sets of a classifier using probabilistic programming. We define a prediction level set to be the set of examples for which the predictor has the same specified prediction confidence with respect to some arbitrary data distribution. Notably, our sampling-based method does not require the classifier to be differentiable, making it compatible with arbitrary classifiers. As a specific instantiation, if we take the classifier to be a neural network and the data distribution to be that of the training data, we can obtain examples that will result in specified predictions by the neural network. We demonstrate this technique with experiments on a synthetic dataset and MNIST. Such level sets in classification may facilitate human understanding of classification behaviors.","",""
11,"Andreas Bär, Fabian Hüger, Peter Schlicht, T. Fingscheidt","On the Robustness of Redundant Teacher-Student Frameworks for Semantic Segmentation",2019,"","","","",39,"2022-07-13 09:27:43","","10.1109/CVPRW.2019.00178","","",,,,,11,3.67,3,4,3,"The trend towards autonomous systems in today's technology comes with the need for environment perception. Deep neural networks (DNNs) constantly showed state-of-the-art performance over the last few years in visual machine perception, e.g., semantic segmentation. While DNNs work fine on uncorrupted data, recently introduced adversarial examples (AEs) led to misclassification with high confidence. This lack of robustness against such adversarial attacks questions the use of DNNs in safety-critical autonomous systems, e.g., autonomous driving vehicles. In this work, we address the mentioned problem with the use of a redundant teacher-student framework, consisting of a static teacher network (T), a static student network (S), and a constantly adapting student network (A). By using this triplet in combination with a novel inverse feature matching (IFM) loss, we show that a significant robustness increase of student DNNs against adversarial attacks is achieveable, while maintaining semantic segmentation quality at a reasonably high level. With our approach, we manage to increase the mean intersection over union (mean IoU) ratio between static student adversarial examples and clean images from about 35 % to about 80 % on the Cityscapes dataset. Moreover, our proposed method can be integrated into any DNN-based perception mechanism to increase the (online) robustness in an adversarial environment, created from static model knowledge.","",""
20,"Mahyar Fazlyab, M. Morari, George J. Pappas","Probabilistic Verification and Reachability Analysis of Neural Networks via Semidefinite Programming",2019,"","","","",40,"2022-07-13 09:27:43","","10.1109/CDC40024.2019.9029310","","",,,,,20,6.67,7,3,3,"Quantifying the robustness of neural networks or verifying their safety properties against input uncertainties or adversarial attacks have become an important research area in learning-enabled systems. Most results concentrate around the worst-case scenario where the input of the neural network is perturbed within a norm-bounded uncertainty set. In this paper, we consider a probabilistic setting in which the uncertainty is random with known first two moments. In this context, we discuss two relevant problems: (i) probabilistic safety verification, in which the goal is to find an upper bound on the probability of violating a safety specification; and (ii) confidence ellipsoid estimation, in which given a confidence ellipsoid for the input of the neural network, our goal is to compute a confidence ellipsoid for the output. Due to the presence of nonlinear activation functions, these two problems are very difficult to solve exactly. To simplify the analysis, our main idea is to abstract the nonlinear activation functions by a combination of affine and quadratic constraints they impose on their input-output pairs. We then show that the safety of the abstracted network, which is sufficient for the safety of the original network, can be analyzed using semidefinite programming. We illustrate the performance of our approach with numerical experiments.","",""
66,"Z. Zheng, Pengyu Hong","Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks",2018,"","","","",41,"2022-07-13 09:27:43","","","","",,,,,66,16.50,33,2,4,"It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategy to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks.","",""
13,"Koby Bibas, Yaniv Fogel, M. Feder","Deep pNML: Predictive Normalized Maximum Likelihood for Deep Neural Networks",2019,"","","","",42,"2022-07-13 09:27:43","","","","",,,,,13,4.33,4,3,3,"The Predictive Normalized Maximum Likelihood (pNML) scheme has been recently suggested for universal learning in the individual setting, where both the training and test samples are individual data. The goal of universal learning is to compete with a ``genie'' or reference learner that knows the data values, but is restricted to use a learner from a given model class. The pNML minimizes the associated regret for any possible value of the unknown label. Furthermore, its min-max regret can serve as a pointwise measure of learnability for the specific training and data sample. In this work we examine the pNML and its associated learnability measure for the Deep Neural Network (DNN) model class. As shown, the pNML outperforms the commonly used Empirical Risk Minimization (ERM) approach and provides robustness against adversarial attacks. Together with its learnability measure it can detect out of distribution test examples, be tolerant to noisy labels and serve as a confidence measure for the ERM. Finally, we extend the pNML to a ``twice universal'' solution, that provides universality for model class selection and generates a learner competing with the best one from all model classes.","",""
17,"Chen Zeno, Itay Golan, Elad Hoffer, Daniel Soudry","Bayesian Gradient Descent: Online Variational Bayes Learning with Increased Robustness to Catastrophic Forgetting and Weight Pruning",2018,"","","","",43,"2022-07-13 09:27:43","","","","",,,,,17,4.25,4,4,4,"We suggest a novel approach for the estimation of the posterior distribution of the weights of a neural network, using an online version of the variational Bayes method. Having a confidence measure of the weights allows to combat several shortcomings of neural networks, such as their parameter redundancy, and their notorious vulnerability to the change of input distribution (""catastrophic forgetting""). Specifically, We show that this approach helps alleviate the catastrophic forgetting phenomenon - even without the knowledge of when the tasks are been switched. Furthermore, it improves the robustness of the network to weight pruning - even without re-training.","",""
0,"Yenan Liu, Xiangqian Zhou, Feng Zhang, Li Zhao, Mengyang Zhang","Optimized Radial Basis Function Network Based on Beetle Antenna Search for Indoor Localization Algorithm",2021,"","","","",44,"2022-07-13 09:27:43","","10.1109/icicn52636.2021.9673902","","",,,,,0,0.00,0,5,1,"In order to improve the accuracy and robustness of Bluetooth indoor localization, an improved fusion hybrid filter and radial basis function neural network (RBFNN) indoor localization method is proposed, which effectively improves the accuracy of received signal strength (RSS) by combining various filtering algorithms, and introduces a radial basis neural network in machine learning algorithm to map the nonlinear relationship between RSS and anchor node to signal receiver localization. RBFNN is optimized using the algorithm of beetle antenna search to further improve the stability of localization. An experimental platform based on NRF52810 and a smart phone is built to verify the proposed method. Theoretical analysis and experimental results show that the average positioning error of the proposed method is 0. 63m, the confidence probability of less than lm is 75%, and the confidence probability of less than 2m is 96%. It can effectively reduce the positioning error and improve the positioning accuracy, and is easy deploy, which has high application value.","",""
0,"Chao Qiu, Ping Zhang, Zheng Zheng, Junbo Wu","Power Communication Network Bandwidth Prediction Based On NSS-DBA Model",2021,"","","","",45,"2022-07-13 09:27:43","","10.1109/CEI52496.2021.9574468","","",,,,,0,0.00,0,4,1,"With the development of power communication network, the service data carried by power communication network increases exponentially, which puts forward higher requirements for the processing capacity of power communication network. In order to guarantee the service quality of the communication network, a deep confidence-based power communication bandwidth prediction algorithm is proposed in this paper, which has good robustness for nonstationary sequences. The experimental results show that, compared with the traditional neural network algorithm, the proposed algorithm has more advantages in predicting accuracy and robustness, can improve the carrying capacity of the power communication network, and provide a strong guarantee for the safe and stable operation of the power system.","",""
4,"Xing-yi Li, Cunqing Wang, Huaji Shi","A travel time prediction method: Bayesian reasoning state-space neural network",2010,"","","","",46,"2022-07-13 09:27:43","","10.1109/ICISE.2010.5689258","","",,,,,4,0.33,1,3,12,"According to the prediction model of neural network training methods to slow convergence speed, training for a long time and difficult to control the complexity of weights updating, this paper puts forward Bayesian reasoning state-space neural network, using termination conditions control its training and the confidence interval restrained by control factor standard the results. Using this method can accelerate convergence, shorten the training time and maintain stability. With traffic data by Bin He road of Shenzhen in September 2007 to verify this model, the experiments show that this model can shorten the time of training, and has good robustness and accuracy.","",""
7,"Vanessa Buhrmester, David Münch, D. Bulatov, Michael Arens","Evaluating the Impact of Color Information in Deep Neural Networks",2019,"","","","",47,"2022-07-13 09:27:43","","10.1007/978-3-030-31332-6_27","","",,,,,7,2.33,2,4,3,"","",""
15,"Tianyu Guo, Chang Xu, Shiyi He, Boxin Shi, Chao Xu, D. Tao","Robust Student Network Learning",2018,"","","","",48,"2022-07-13 09:27:43","","10.1109/TNNLS.2019.2929114","","",,,,,15,3.75,3,6,4,"Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher–student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.","",""
0,"Fan Zhang, Tianying Meng, D. Xiang, Fei Ma, Xiaokun Sun, Yongsheng Zhou","Adversarial Deception Against SAR Target Recognition Network",2022,"","","","",49,"2022-07-13 09:27:43","","10.1109/jstars.2022.3179171","","",,,,,0,0.00,0,6,1,"Synthetic aperture radar (SAR) automatic target recognition (ATR) technology is one of the key technologies to achieve intelligent interpretation for SAR images. With the rapid development of deep learning, deep neural networks have been successively used in SAR ATR and show priority in comparison with the conventional methods. Recently, more and more attention is paid to the robustness of deep learning-based SAR ATR methods. The reason is that maliciously modified and imperceptible adversarial images can deceive the SAR ATR methods, which are based on the deep neural networks. In this article, we propose a novel SAR ATR adversarial deception algorithm, which fully considers the characteristics of SAR data. Our method can obtain the satisfactory perturbations with a higher deception success rate, higher recognition confidence, and smaller perturbation coverage than other state-of-the-art methods for the SAR images. Experimental results using the MSTAR dataset and OpenSARShip dataset demonstrate the effectiveness of our method. The proposed adversarial deception method can be used in the applications, such as SAR dataset protection, SAR sensor design, and SAR image quality evaluation.","",""
5,"S. P. Harisubramanyabalaji, S. Réhman, M. Nyberg, J. Gustavsson","Improving Image Classification Robustness Using Predictive Data Augmentation",2018,"","","","",50,"2022-07-13 09:27:43","","10.1007/978-3-319-99229-7_49","","",,,,,5,1.25,1,4,4,"","",""
28,"Adam Knowles, A. Hussain, W. E. Deredy, P. Lisboa, C. Dunis","Higher Order Neural Networks with Bayesian Confidence Measure for the Prediction of the EUR/USD Exchange Rate",2009,"","","","",51,"2022-07-13 09:27:43","","10.4018/978-1-59904-897-0.CH002","","",,,,,28,2.15,6,5,13,"Multi-layer perceptrons (MLP) are the most common type of neural network in use, and their ability to perform complex non-linear mappings and tolerance to noise in data is well documented. However, MLPs also suffer long training times and often reach only local optima. Another type of network is the higher-order neural network (HONN) where joint activation terms are used, relieving the network of the task of learning the relationships between the inputs. The predictive performance of the network is tested with the EUR/USD exchange rate and evaluated using standard financial criteria including the annualized return on investment, which shows a 8% increase in the return compared with the MLP. The output of the networks that give the highest annualized return in each category was subjected to a Bayesian based confidence measure. This performance improvement may be explained by the explicit and parsimonious representation of high order terms in higher-order neural networks, which combines robustness against noise typical of distributed models together with the ability to accurately model higher-order interactions for long-term forecasting. The effectiveness of the confidence measure is explained by examining the distribution of each network's output. We speculate the distribution could be taken into account during training, thus enabling us to produce neural networks with the properties to take advantage of the confidence measure.","",""
0,"Amirata Ghorbani, Abubakar Abid, James Y. Zou","“ Llama ” : Confidence 99 . 8 “ Llama ” : Confidence 71 . 1 Feature-Importance Map Feature-Importance Map Feature-Importance Map “ Monarch ” : Confidence 99 . 9 “ Monarch ” : Confidence",2018,"","","","",52,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,3,4,"In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.","",""
5,"Arnold Salas, S. Zohren, Stephen J. Roberts","Practical Bayesian Learning of Neural Networks via Adaptive Subgradient Methods",2018,"","","","",53,"2022-07-13 09:27:43","","","","",,,,,5,1.25,2,3,4,"We introduce a novel framework for the estimation of the posterior distribution of the weights of a neural network, based on a new probabilistic interpretation of adaptive subgradient algorithms such as AdaGrad and Adam. Having a confidence measure of the weights allows several shortcomings of neural networks to be addressed. In particular, the robustness of the network can be improved by performing weight pruning based on signal-to-noise ratios from the weight posterior distribution. Using the MNIST dataset, we demonstrate that the empirical performance of Badam, a particular instance of our framework based on Adam, is competitive in comparison to related Bayesian approaches such as Bayes By Backprop.","",""
4,"Jie Zhang","Batch Process Modelling and Optimal Control Based on Neural Network Models",2005,"","","","",54,"2022-07-13 09:27:43","","","","",,,,,4,0.24,4,1,17,"This paper presents several neural network based modelling, reliable optimal control, and iterative learning control methods for batch processes. In order to overcome the lack of robustness of a single neural network, bootstrap aggregated neural networks are used to build reliable data based empirical models. Apart from improving the model generalisation capability, a bootstrap aggregated neural network can also provide model prediction confidence bounds. A reliable optimal control method by incorporating model prediction confidence bounds into the optimisation objective function is presented. A neural network based iterative learning control strategy is presented to overcome the problem due to unknown disturbances and model-plant mismatches. The proposed methods are demonstrated on a simulated batch polymerisation process.","",""
10,"P. Marino, M. Milano, F. Vasca","Robust neural network observer for induction motor control",1997,"","","","",55,"2022-07-13 09:27:43","","10.1109/PESC.1997.616797","","",,,,,10,0.40,3,3,25,"A neural network observer for induction motor state estimation, which is robust with respect to parameter variations is presented. Robustness is obtained using a suitable training set based on a stochastic model of the motor obtained by the Price algorithm. This algorithm is used to obtain the confidence ellipsoid for the model parameters, which are then modeled as Gaussian random variables strictly contained in the ellipsoid. Simulation results show that the resulting neural observer provides a good trade off between estimates accuracy and robustness.","",""
0,"Jiezhang","Batch Process Modelling and Optimal Control Based on Neural Network Models",2005,"","","","",56,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,17,"This paper presents several neural network based modelling, reliable optimal control, and iterative learning control methods for batch processes. In order to overcome the lack of robustness of a single neural network, bootstrap aggregated neural networks are used to build reliable data based empirical models. Apart from improving the model generalisation capability, a bootstrap aggregated neural network can also provide model prediction confidence bounds. A reliable optimal control method by incorporating model prediction confidence bounds into the optimisation objective function is presented. A neural network based iterative learning control strategy is presented to overcome the problem due to unknown disturbances and model-plant mismatches. The proposed methods are demonstrated on a simulated batch polymerisation process.","",""
1,"Derek Wang, Chaoran Li, S. Wen, Yang Xiang, Wanlei Zhou, S. Nepal","Defensive Collaborative Multi-task Training - Defending against Adversarial Attack towards Deep Neural Networks",2018,"","","","",57,"2022-07-13 09:27:43","","","","",,,,,1,0.25,0,6,4,"Deep neural network (DNNs) has shown impressive performance on hard perceptual problems. However, researchers found that DNN-based systems are vulnerable to adversarial examples which contain specially crafted humans-imperceptible perturbations. Such perturbations cause DNN-based systems to misclassify the adversarial examples, with potentially disastrous consequences where safety or security is crucial. As a major security concern, state-of-the-art attacks can still bypass the existing defensive methods. In this paper, we propose a novel defensive framework based on collaborative multi-task training to address the above problem. The proposed defence first incorporates specific label pairs into adversarial training process to enhance model robustness in black-box setting. Then a novel collaborative multi-task training framework is proposed to construct a detector which identifies adversarial examples based on the pairwise relationship of the label pairs. The detector can identify and reject high confidence adversarial examples that bypass black-box defence. The model whose robustness has been enhanced work reciprocally with the detector on the false-negative adversarial examples. Importantly, the proposed collaborative architecture can prevent the adversary from finding valid adversarial examples in a nearly-white-box setting.","",""
14,"David Flatow Stanford","On the Robustness of ConvNets to Training on Noisy Labels",2015,"","","","",58,"2022-07-13 09:27:43","","","","",,,,,14,2.00,14,1,7,"In this work, we examine how sensitive the convolutional neural network model is to noise in the training set, particularly when the training set contains mislabeled or subjectively-labeled examples. We first test the robustness of the standard convolutional model by randomly permuting the labels of the training set with increasing frequency, and plotting the corresponding change in classification accuracy. Next, we implement a robust loss function proposed recently by Reed et al., which attempts to account for weak labeling in the training set by mixing the observed training targets with the model’s predicted class probabilities. Finally, we implement an extension of the robust model which dynamically adjusts the mixing parameter, to increase our confidence in the model’s predictions as they become more accurate.","",""
4,"A. Kostrzewski, Dai Hyun Kim, Jeongdal Kim, T. Jannson, G. Savant","Fuzzified neural network for similar/dissimilar sensor fusion",1996,"","","","",59,"2022-07-13 09:27:43","","10.1109/ICNN.1996.549023","","",,,,,4,0.15,1,5,26,"We explore the robustness of a sensor fusion system as a function of failed sensors. Neural networks are applied to classify data from a sensor suite. Two dissimilar sensor types are used to produce three spectral patterns (in red, green, and blue wavelength regions) per sensor location (three sensor locations were used). The main goal of this effort is to improve the sensor fusion confidence level by introducing several realizations of a neural network. Each specific neural network realization is activated upon a specific sensor failure configuration during the recognition stage. In such a case, the number of NN realization is equal to the number of failed sensor combinations. To reduce the number of NN realizations, fuzzification of the NN weights is proposed. An experimental demonstration of the proposed concept is also included.","",""
0,"Lee A. Uvanni, T. G. Rainey, U. Balasubramanian, D. Brettle, F. Weingard, R. Sibert, E. Birnbaum","Neural network for intelligent query of an FBI forensic database",1997,"","","","",60,"2022-07-13 09:27:43","","10.1117/12.266749","","",,,,,0,0.00,0,7,25,"Examiner is an automated fired cartridge case identification system utilizing a dual-use neural network pattern recognition technology, called the statistical-multiple object detection and location system (S-MODALS) developed by Booz(DOT)Allen & Hamilton, Inc. in conjunction with Rome Laboratory. S-MODALS was originally designed for automatic target recognition (ATR) of tactical and strategic military targets using multisensor fusion [electro-optical (EO), infrared (IR), and synthetic aperture radar (SAR)] sensors. Since S-MODALS is a learning system readily adaptable to problem domains other than automatic target recognition, the pattern matching problem of microscopic marks for firearms evidence was analyzed using S-MODALS. The physics; phenomenology; discrimination and search strategies; robustness requirements; error level and confidence level propagation that apply to the pattern matching problem of military targets were found to be applicable to the ballistic domain as well. The Examiner system uses S-MODALS to rank a set of queried cartridge case images from the most similar to the least similar image in reference to an investigative fired cartridge case image. The paper presents three independent tests and evaluation studies of the Examiner system utilizing the S-MODALS technology for the Federal Bureau of Investigation.","",""
377,"H. Dai, Hui Li, Tian Tian, Xin Huang, L. Wang, Jun Zhu, Le Song","Adversarial Attack on Graph Structured Data",2018,"","","","",61,"2022-07-13 09:27:43","","","","",,,,,377,94.25,54,7,4,"Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.","",""
8,"C. Alippi","A Perturbation Size-Independent Analysis of Robustness in Neural Networks by Randomized Algorithms",2003,"","","","",62,"2022-07-13 09:27:43","","10.4018/978-1-59140-037-0.CH002","","",,,,,8,0.42,8,1,19,"This chapter presents a general methodology for evaluating the loss in performance of a generic neural network once its weights are affected by perturbations. Since weights represent the “kn wledge space” of the neural model, the robustness analysis can be used to study the weights/performance relationship. The perturbation analysis, which is closely related to sensitivity issues, relaxes all assumptions made in the related literature, such as the small perturbation hypothesis, specific requirements on the distribution of perturbations and neural variables, the number of hidden units and a given neural structure. The methodology, based on Randomized Algorithms, allows reformulating the computationally intractable problem of robustness/sensitivity analysis in a robabilistic framework characterised by a polynomial time solution in the accuracy and confidence degrees. This chapter appears in the book, Computational Intelligence in Control, edited by Masoud Mahammadian. Copyright © 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written permission of Idea Group Inc. is prohibited. 701 E. Chocolate Avenue, Hershey PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.idea-group.com ITB8617 IDEA GROUP PUBLISHING Robustness in Neural Networks 23 Copyright Idea Grou p Inc. Copy right Idea Grou p Inc. Copy right Idea Grou p Inc. Copy right Idea Grou p Inc. INTRODUCTION The evaluation of the effects induced by perturbations affecting a neural computation is relevant from the theoretical point of view and in developing an embedded device dedicated to a specific application. In the first case, the interest is in obtaining a reliable and easy to be generated measure of the performance loss induced by perturbations affecting the weights of a neural network. The relevance of the analysis is obvious since weights characterise the “knowledge space” of the neural model and, hence, its inner nature. In this direction, a study of the evolution of the network’s weights over training time allows for understanding the mechanism behind the generation of the knowledge space. Conversely, the analysis of a specific knowledge space (fixed configuration for weights) provides hints about the relationship between the weights space and the performance function. The latter aspect is of primary interest in recurrent neural networks where even small modifications of the weight values are critical to performance (e.g., think of the stability of an intelligent controller comprising a neural network and issues leading to robust control). The second case is somehow strictly related to the first one and covers the situation where the neural network must be implemented in a physical device. The optimally trained neural network becomes the “golden unit” to be implemented within a finite precision representation environment as it happens in mission-critical applications and embedded systems. In these applications, behavioural perturbations affecting the weights of a neural network abstract uncertainties associated with the implementation process, such as finite precision representations (e.g., truncation or rounding in a digital hardware, fixed or low resolution floating point representations), fluctuations of the parameters representing the weights in analog s lutions (e.g., associated with the production process of a physical component), ageing effects, or more complex and subtle uncertainties in mixe implementations. The sensitivity/robustness issue has been widely addressed in the neural network community with a particular focus on specific neural topologies. More in detail, when the neural network is composed of linear units, the analysis is straightforward and the relationship between perturbations and the induced performance loss can be obtained in a closed form (Alippi & Briozzo, 1998). Conversely, when the neural topology is non-linear, which is mostly the case, several authors assume the small perturbation hypothesis or particular hypothesis about the stochastic nature of the neural computation. In both cases, the assumptions make the mathematics more amenable with the positive consequence that a relationship between perturbations and performance loss can be derived (e.g., see Alippi & Briozzo, 1998; Pichè, 1995). Unfortunately, these analyses introduce hypotheses which are not always satisfied in all real applications. 17 more pages are available in the full version of this document, which may be purchased using the ""Add to Cart"" button on the product's webpage: www.igi-global.com/chapter/perturbation-size-independentanalysis-robustness/6830?camid=4v1 This title is available in InfoSci-Books, InfoSci-Intelligent Technologies, Science, Engineering, and Information Technology, InfoSci-Computer Science and Information Technology, InfoSci-Select, InfoSci-Select. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=1","",""
12,"Jianming Zhang, Yang Liu, Hehua Liu, Jin Wang, Yudong Zhang","Distractor-aware visual tracking using hierarchical correlation filters adaptive selection",2021,"","","","",63,"2022-07-13 09:27:43","","10.1007/s10489-021-02694-8","","",,,,,12,12.00,2,5,1,"","",""
287,"Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel","Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise",2018,"","","","",64,"2022-07-13 09:27:43","","","","",,,,,287,71.75,72,4,4,"The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling for large datasets, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.","",""
4,"Jie Zhang, Rory Fisher","Reliable Multi-objective On-Line Re-optimisation Control of a Fed-Batch Fermentation Process Using Bootstrap Aggregated Neural Networks",2017,"","","","",65,"2022-07-13 09:27:43","","10.1109/ISCSIC.2017.23","","",,,,,4,0.80,2,2,5,"This paper presents reliable multi-objective on-linere-optimisation control of a fed-batch fermentation processusing bootstrap aggregated neural networks. To overcome thedifficulty in developing mechanistic models, data driven neuralnetwork models are developed from process operational data.However, a single neural network can lack robustness in thatits performance on unseen data might be unsatisfactoryespecially when the amount of training data is limited. Toovercome this problem, multiple neural networks aredeveloped from bootstrap re-sampling replications of theoriginal training data and they are combined. A furtheradvantage of bootstrap aggregated neural networks is thatmodel prediction confidence bounds can be obtained fromindividual network predictions. Model prediction confidencebounds are incorporated into a multi-objective optimisationframework in order to enhance the reliability of optimisationresults. In order to further reduce the effect of model plantmismatches and unknown disturbances on the optimisationresults, on-line re-optimisation is used in this study. Theproposed method is applied to a simulated industrial scale fed-batch fermentation process for producing baker’s yeast.","",""
13,"Yeming Wen, Ghassen Jerfel, Rafael Muller, Michael W. Dusenberry, Jasper Snoek, Balaji Lakshminarayanan, Dustin Tran","Combining Ensembles and Data Augmentation can Harm your Calibration",2020,"","","","",66,"2022-07-13 09:27:43","","","","",,,,,13,6.50,2,7,2,"Ensemble methods which average over multiple neural network predictions are a simple approach to improve a model's calibration and robustness. Similarly, data augmentation techniques, which encode prior information in the form of invariant feature transformations, are effective for improving calibration and robustness. In this paper, we show a surprising pathology: combining ensembles and data augmentation can harm model calibration. This leads to a trade-off in practice, whereby improved accuracy by combining the two techniques comes at the expense of calibration. On the other hand, selecting only one of the techniques ensures good uncertainty estimates at the expense of accuracy. We investigate this pathology and identify a compounding under-confidence among methods which marginalize over sets of weights and data augmentation techniques which soften labels. Finally, we propose a simple correction, achieving the best of both worlds with significant accuracy and calibration gains over using only ensembles or data augmentation individually. Applying the correction produces new state-of-the art in uncertainty calibration across CIFAR-10, CIFAR-100, and ImageNet.","",""
6,"V. Chernozhukov, W. Newey, Rahul Singh","A Simple and General Debiased Machine Learning Theorem with Finite Sample Guarantees",2021,"","","","",67,"2022-07-13 09:27:43","","10.1093/biomet/asac033","","",,,,,6,6.00,2,3,1,"  Debiased machine learning is a meta algorithm based on bias correction and sample splitting to calculate confidence intervals for functionals, i.e., scalar summaries, of machine learning algorithms. For example, an analyst may desire the confidence interval for a treatment effect estimated with a neural network. We provide a non-asymptotic debiased machine learning theorem that encompasses any global or local functional of any machine learning algorithm that satisfies a few simple, interpretable conditions. Formally, we prove consistency, Gaussian approximation, and semiparametric efficiency by finite sample arguments. The rate of convergence is n−1/2 for global functionals, and it degrades gracefully for local functionals. Our results culminate in a simple set of conditions that an analyst can use to translate modern learning theory rates into traditional statistical inference. The conditions reveal a general double robustness property for ill-posed inverse problems.","",""
9,"E. Mueller, M. Rezaie, W. Percival, A. Ross, R. Ruggeri, H. Seo, H. Gil-Marín, J. Bautista, J. Brownstein, K. Dawson, A. D. L. Macorra, N. Palanque-Delabrouille, G. Rossi, D. Schneider, C. Yèche","The clustering of galaxies in the completed SDSS-IV extended Baryon Oscillation Spectroscopic Survey: Primordial non-Gaussianity in Fourier Space",2021,"","","","",68,"2022-07-13 09:27:43","","","","",,,,,9,9.00,1,15,1,"We present measurements of the local primordial non-Gaussianity parameter f local NL from the clustering of 343,708 quasars with redshifts 0.8 < z < 2.2 distributed over 4808 square degrees from the final data release (DR16) of the extended Baryon acoustic Oscillation Spectroscopic Survey (eBOSS), the largest volume spectroscopic survey up to date. Our analysis is performed in Fourier space, using the power spectrum monopole at very large scales to constrain the scale dependent halo bias. We carefully assess the impact of systematics on our measurement and test multiple contamination removal methods. We demonstrate the robustness of our analysis pipeline with EZ-mock catalogues that simulate the eBOSS DR16 target selection. We find fNL = −12 ± 21 (68% confidence) for the main clustering sample including quasars with redshifts between 0.8 and 2.2, after exploiting a novel neural network scheme for cleaning the DR16 sample and in particular after applying redshift weighting techniques, designed for non-Gaussianity measurement from large scales structure, to optimize our analysis, which improve our results by 37%.","",""
30,"Keyang Luo, T. Guan, L. Ju, Yuesong Wang, Zhu Chen, Yawei Luo","Attention-Aware Multi-View Stereo",2020,"","","","",69,"2022-07-13 09:27:43","","10.1109/cvpr42600.2020.00166","","",,,,,30,15.00,5,6,2,"Multi-view stereo is a crucial task in computer vision, that requires accurate and robust photo-consistency among input images for depth estimation. Recent studies have shown that learning-based feature matching and confidence regularization can play a vital role in this task. Nevertheless, how to design good matching confidence volumes as well as effective regularizers for them are still under in-depth study. In this paper, we propose an attention-aware deep neural network “AttMVS” for learning multi-view stereo. In particular, we propose a novel attention-enhanced matching confidence volume, that combines the raw pixel-wise matching confidence from the extracted perceptual features with the contextual information of local scenes, to improve the matching robustness. Furthermore, we develop an attention-guided regularization module, which consists of multilevel ray fusion modules, to hierarchically aggregate and regularize the matching confidence volume into a latent depth probability volume.Experimental results show that our approach achieves the best overall performance on the DTU dataset and the intermediate sequences of Tanks & Temples benchmark over many state-of-the-art MVS algorithms.","",""
3,"Felix Nobis, Felix Fent, Johannes Betz, M. Lienkamp","Kernel Point Convolution LSTM Networks for Radar Point Cloud Segmentation",2021,"","","","",70,"2022-07-13 09:27:43","","10.3390/APP11062599","","",,,,,3,3.00,1,4,1,"State-of-the-art 3D object detection for autonomous driving is achieved by processing lidar sensor data with deep-learning methods. However, the detection quality of the state of the art is still far from enabling safe driving in all conditions. Additional sensor modalities need to be used to increase the confidence and robustness of the overall detection result. Researchers have recently explored radar data as an additional input source for universal 3D object detection. This paper proposes artificial neural network architectures to segment sparse radar point cloud data. Segmentation is an intermediate step towards radar object detection as a complementary concept to lidar object detection. Conceptually, we adapt Kernel Point Convolution (KPConv) layers for radar data. Additionally, we introduce a long short-term memory (LSTM) variant based on KPConv layers to make use of the information content in the time dimension of radar data. This is motivated by classical radar processing, where tracking of features over time is imperative to generate confident object proposals. We benchmark several variants of the network on the public nuScenes data set against a state-of-the-art pointnet-based approach. The performance of the networks is limited by the quality of the publicly available data. The radar data and radar-label quality is of great importance to the training and evaluation of machine learning models. Therefore, the advantages and disadvantages of the available data set, regarding its radar data, are discussed in detail. The need for a radar-focused data set for object detection is expressed. We assume that higher segmentation scores should be achievable with better-quality data for all models compared, and differences between the models should manifest more clearly. To facilitate research with additional radar data, the modular code for this research will be made available to the public.","",""
2,"C. Remy, D. Ahumada, A. Labine, J. Côté, M. Lachaine, H. Bouchard","Potential of a probabilistic framework for target prediction from surrogate respiratory motion during lung radiotherapy",2021,"","","","",71,"2022-07-13 09:27:43","","10.1088/1361-6560/abf1b8","","",,,,,2,2.00,0,6,1,"Purpose. Respiration-induced motion introduces significant positioning uncertainties in radiotherapy treatments for thoracic sites. Accounting for this motion is a non-trivial task commonly addressed with surrogate-based strategies and latency compensating techniques. This study investigates the potential of a new unified probabilistic framework to predict both future target motion in real-time from a surrogate signal and associated uncertainty. Method. A Bayesian approach is developed, based on a Kalman filter theory adapted specifically for surrogate measurements. Breathing motions are collected simultaneously from a lung target, two external surrogates (abdominal and thoracic markers) and an internal surrogate (liver structure) for 9 volunteers during 4 min, in which severe breathing changes occur to assess the robustness of the method. A comparison with an artificial non-linear neural network (NN) is performed, although no confidence interval prediction is provided. A static worst-case scenario and a simple static design are investigated. Results. Although the NN can reduce the prediction errors from thoracic surrogate in some cases, the Bayesian framework outperforms in most cases the NN when using the other surrogates: bias on predictions is reduced by 38% and 16% on average when using respectively the liver and the abdomen for the simple scenario, and by respectively 40% and 31% for the worst-case scenario. The standard deviation of residuals is reduced on average by up to 42%. The Bayesian method is also found to be more robust to increasing latencies. The thoracic marker appears to be less reliable to predict the target position, while the liver shows to be a better surrogate. A statistical test confirms the significance of both observations. Conclusion. The proposed framework predicts both the future target position and the associated uncertainty, which can be valuably used to further assist motion management decisions. Further investigation is required to improve the predictions by using an adaptive version of the proposed framework.","",""
2,"Bin Zhang, Dongheng Zhang, Yadong Li, Yang Hu, Yan Chen","Unsupervised Domain Adaptation for Device-free Gesture Recognition",2021,"","","","",72,"2022-07-13 09:27:43","","","","",,,,,2,2.00,0,5,1,"—Device-free human gesture recognition with Radio Frequency (RF) signals has attained acclaim due to the omnipresence, privacy protection, and broad coverage nature of RF signals. However, neural network models trained for recognition with data collected from a speciﬁc domain suffer from signiﬁcant performance degradation when applied to a new domain. To tackle this challenge, we propose an unsupervised domain adaptation framework for RF-based gesture recognition by making effective use of the unlabeled target domain data. Speciﬁcally, we apply pseudo-labeling and consistency regularization with elaborated design on target domain data to produce pseudo-label and align instance’s feature of the target domain. Then, we design two data augmentation methods by randomly erasing the input data to enhance the robustness of the model. Furthermore, we apply a conﬁdence control constraint to tackle the overconﬁdence problem. We conduct extensive experiments on a public Wi-Fi dataset and a public millimeter wave (mmWave) radar dataset. The experimental results demonstrate the superior effectiveness of the proposed framework.","",""
1,"Lixuan Zhou, Caijun Xu","Inversion of Fault Geometric Parameters Based on Mixture Density Networks: A Case Study of the 2013 Ms7.0 Lushan Earthquake in China",2021,"","","","",73,"2022-07-13 09:27:43","","10.1007/s00024-020-02639-1","","",,,,,1,1.00,1,2,1,"","",""
1,"Ying Zheng, Haoyu Chen, Qingyang Duan, Lixiang Lin, Yiyang Shao, Wei Wang, Xin Wang, Yuedong Xu","Leveraging Domain Knowledge for Robust Deep Reinforcement Learning in Networking",2021,"","","","",74,"2022-07-13 09:27:43","","10.1109/INFOCOM42981.2021.9488863","","",,,,,1,1.00,0,8,1,"The past few years has witnessed a surge of interest towards deep reinforcement learning (Deep RL) in computer networks. With extraordinary ability of feature extraction, Deep RL has the potential to re-engineer the fundamental resource allocation problems in networking without relying on pre-programmed models or assumptions about dynamic environments. However, such black-box systems suffer from poor robustness, showing high performance variance and poor tail performance. In this work, we propose a unified Teacher-Student learning framework that harnesses rich domain knowledge to improve robustness. The domain-specific algorithms, less performant but more trustable than Deep RL, play the role of teachers providing advice at critical states; the student neural network is steered to maximize the expected reward as usual and mimic the teacher’s advice meanwhile. The Teacher-Student method comprises of three modules where the confidence check module locates wrong decisions and risky decisions, the reward shaping module designs a new updating function to incentive the learning of student network, and the prioritized experience replay module to effectively utilize the advised actions. We further implement our Teacher-Student framework in existing video streaming (Pensieve), load balancing (DeepLB) and TCP congestion control (Aurora). Experimental results manifest that the proposed approach reduces the performance standard deviation of DeepLB by 37%; it improves the 90th, 95th and 99th tail performance of Pensieve by 7.6%, 8.8%, 10.7% respectively; and it accelerates the rate of growth of Aurora by 2x at the initial stage, and achieves a more stable performance in dynamic environments.","",""
1,"Baogang Wang, Chunmei Yang, Yucheng Ding, Guangyi Qin","Detection of wood surface defects based on improved YOLOv3 algorithm",2021,"","","","",75,"2022-07-13 09:27:43","","10.15376/biores.16.4.6766-6780","","",,,,,1,1.00,0,4,1,"For the detection of wood surface defects, a convolutional neural network has a low detection efficiency and insufficient generalization ability, so it does not meet the requirements of online detection. Aiming to solve the above problems, the YOLOv3 baseline model, which has the advantage of multi-objective dynamic detection, was improved and applied to the online detection of wood surface defects. To solve the problem of the poor generalization ability of the network, GridMask was used to enhance the data and improve the robustness of the network. In order to solve the problem of the considerable amount of network parameter calculations and insufficient real-time performance, the residual block of the backbone network was changed to a Ghost block structure to achieve a lightweight model. Finally, the confidence loss function of the network was improved to reduce the influence of simple samples and negative samples on model convergence. The experimental results showed that, compared with the original network, the improved algorithm increased the mean average precision by 5.73% and the detection speed was increased to 28 frames per second (an increase of 11), which met the requirements for real-time industrial detection.","",""
14,"G. Costante, Michele Mancini","Uncertainty Estimation for Data-Driven Visual Odometry",2020,"","","","",76,"2022-07-13 09:27:43","","10.1109/TRO.2020.3001674","","",,,,,14,7.00,7,2,2,"Over the past few years, we have witnessed a considerable diffusion of data-driven visual odometry (VO) approaches as viable alternatives to standard geometric-based strategies. Their success is mainly related to the improved robustness to image nonideal conditions (e.g., blur, high or low contrast, texture-poor scenarios). However, most of the data-driven State-of-the-Art (SotA) approaches do not provide any kind of information about the uncertainty of their estimates, which is crucial to effectively integrate them into robotic navigation systems. Inspired by this considerations, we propose uncertainty-aware VO (UA-VO), a novel deep neural network (DNN) architecture that computes relative pose predictions by processing sequence of images and, at the same time, provides uncertainty measures about those estimations. The confidence measure computed by UA-VO considers both epistemic and aleatoric uncertainties and accounts for heteroscedasticity, i.e., it is sample-dependent. We assess the benefits of UA-VO with different typology of experiments on three publicly available datasets and on a brand new set of sequences, we gathered to extend the evaluation.","",""
0,"Ziyu Yao, Jiaquan Gao","Adversarial Example Defense Based on the Supervision",2021,"","","","",77,"2022-07-13 09:27:43","","10.1109/IJCNN52387.2021.9533561","","",,,,,0,0.00,0,2,1,"In recent years, deep learning has developed rapidly and has shown great performance on many challenging machine learning tasks, such as image classification, natural language processing, and speech recognition. However, researchers have recently discovered that deep learning models have security risks and are easily affected by adversarial examples. The adversarial example is a sample formed by deliberately adding subtle perturbation that is invisible to the human in the dataset. It can make the classification classify incorrectly with a high degree of confidence, which poses more challenges for deep learning research. In this paper, we propose a defense model based on the supervision mechanism. The model adds supervision layers to the original convolutional neural network and improves the robustness and defense ability of the model by improving the loss function. The LeNet-5 and VGG networks are used as the original network models. The experimental results on MNIST and CIFAR-10 confirm that the method proposed in this paper will effectively increase the difficulty of the attackers.","",""
0,"Mehrdad Yaghoobi","FROB: FEW-SHOT ROBUST MODEL",2021,"","","","",78,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,1,"Nowadays, classification and Out-of-Distribution (OoD) detection in the few-shot setting remain challenging aims mainly due to rarity and the limited samples in the few-shot setting, and because of adversarial attacks. Accomplishing these aims is important for critical systems in safety, security, and defence. In parallel, OoD detection is challenging since deep neural network classifiers set high confidence to OoD samples away from the training data. To address such limitations, we propose the Few-shot ROBust (FROB) model for classification and few-shot OoD detection. We devise a methodology for improved robustness and reliable confidence prediction for few-shot OoD detection. We generate the support boundary of the normal class distribution and combine it with few-shot Outlier Exposure (OE). We propose a self-supervised learning few-shot confidence boundary methodology based on generative and discriminative models, including classification. The main contribution of FROB is the combination of the generated boundary in a selfsupervised learning manner and the imposition of low confidence at this learned boundary. FROB implicitly generates strong adversarial samples on the boundary and forces samples from OoD, including our boundary, to be less confident by the classifier. FROB achieves generalization to unseen anomalies and adversarial attacks, with applicability to unknown, in the wild, test sets that do not correlate to the training datasets. To improve robustness, FROB redesigns and streamlines OE to work even for zero-shots. By including our learned boundary, FROB effectively reduces the threshold linked to the model’s few-shot robustness, and maintains the OoD performance approximately constant and independent of the number of fewshot samples. The few-shot robustness analysis evaluation of FROB on different image sets and on One-Class Classification (OCC) data shows that FROB achieves competitive state-of-the-art performance and outperforms benchmarks in terms of robustness to the outlier OoD few-shot sample population and variability.","",""
0,"Nikolaos Dionelis","FROB: Few-shot ROBust Model for Classification and Out-of-Distribution Detection",2021,"","","","",79,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,1,"Nowadays, classification and Out-of-Distribution (OoD) detection in the few-shot setting remain challenging aims mainly due to rarity and the limited samples in the few-shot setting, and because of adversarial attacks. Accomplishing these aims is important for critical systems in safety, security, and defence. In parallel, OoD detection is challenging since deep neural network classifiers set high confidence to OoD samples away from the training data. To address such limitations, we propose the Few-shot ROBust (FROB) model for classification and few-shot OoD detection. We devise a methodology for improved robustness and reliable confidence prediction for few-shot OoD detection. We generate the support boundary of the normal class distribution and combine it with few-shot Outlier Exposure (OE). We propose a self-supervised learning few-shot confidence boundary methodology based on generative and discriminative models, including classification. The main contribution of FROB is the combination of the generated boundary in a selfsupervised learning manner and the imposition of low confidence at this learned boundary. FROB implicitly generates strong adversarial samples on the boundary and forces samples from OoD, including our boundary, to be less confident by the classifier. FROB achieves generalization to unseen anomalies and adversarial attacks, with applicability to unknown, in the wild, test sets that do not correlate to the training datasets. To improve robustness, FROB redesigns and streamlines OE to work even for zero-shots. By including our learned boundary, FROB effectively reduces the threshold linked to the model’s few-shot robustness, and maintains the OoD performance approximately constant and independent of the number of fewshot samples. The few-shot robustness analysis evaluation of FROB on different image sets and on One-Class Classification (OCC) data shows that FROB achieves competitive state-of-the-art performance and outperforms benchmarks in terms of robustness to the outlier OoD few-shot sample population and variability.","",""
0,"Kun Fang, Jie Yang","Robust Deep Facial Attribute Prediction against Adversarial Attacks",2021,"","","","",80,"2022-07-13 09:27:43","","10.1145/3467707.3467737","","",,,,,0,0.00,0,2,1,"Face recognition has always been a hot topic in research, and has also widely been applied in industry areas and daily life. Nowadays, face recognition models with excellent performance are mostly based on deep neural networks (DNN). However, recently researchers find that images added invisible perturbations could successfully fool neural networks, which is known as the so-called adversarial attack. The perturbed images, also known as adversarial examples, are almost the same as the original images, but neural network could give different and wrong predictions with high confidence on these adversarial examples. Such a phenomenon indicates the vulnerable robustness of neural network and thus casts a shadow on the security of DNN-based face recognition models. Therefore, in this paper, we focus on the facial attribute prediction task in face recognition, investigate the influence of adversarial attack on facial attribute prediction and give a solution on improving the robustness of facial attribute prediction models. Extensive experiment results illustrate that the solution could indeed produce much more robust results in facial attribute prediction against adversarial attacks.","",""
1,"Ismail Elezi, Zhiding Yu, Anima Anandkumar, L. Leal-Taixé, J. Álvarez","Not All Labels Are Equal: Rationalizing The Labeling Costs for Training Object Detection",2021,"","","","",81,"2022-07-13 09:27:43","","","","",,,,,1,1.00,0,5,1,"Deep neural networks have reached high accuracy on object detection but their success hinges on large amounts of labeled data. To reduce the labels dependency, various active learning strategies have been proposed, based on the confidence of the detector. However, these methods are biased towards high-performing classes and lead to acquired datasets that are not good representatives of the testing set data. In this work, we propose a unified framework for active learning, that considers both the uncertainty and the robustness of the detector, ensuring that the network performs well in all classes. Furthermore, our method leverages auto-labeling to suppress a potential distribution drift while boosting the performance of the model. Experiments on PASCAL VOC07+12 and MS-COCO show that our method consistently outperforms a wide range of active learning methods, yielding up to a 7.7% improvement in mAP, or up to 82% reduction in labeling cost. Code is available at https://github.com/NVlabs/AL-SSL.","",""
1,"Ismail Elezi, Zhiding Yu, Anima Anandkumar, L. Leal-Taixé, J. Álvarez","Towards Reducing Labeling Cost in Deep Object Detection",2021,"","","","",82,"2022-07-13 09:27:43","","","","",,,,,1,1.00,0,5,1,"Deep neural networks have reached very high accuracy on object detection but their success hinges on large amounts of labeled data. To reduce the dependency on labels, various active-learning strategies have been proposed, typically based on the confidence of the detector. However, these methods are biased towards best-performing classes and can lead to acquired datasets that are not good representatives of the data in the testing set. In this work, we propose a unified framework for active learning, that considers both the uncertainty and the robustness of the detector, ensuring that the network performs accurately in all classes. Furthermore, our method is able to pseudo-label the very confident predictions, suppressing a potential distribution drift while further boosting the performance of the model. Experiments on PASCAL VOC07+12 and MS-COCO show that our method consistently outperforms a wide range of active-learning methods, yielding up to a 7.7% relative improvement in mAP, or up to a 82% reduction in labeling cost.","",""
0,"Ke Zou, Xuedong Yuan, Xiaojing Shen, Meng Wang, H. Fu","TBraTS: Trusted Brain Tumor Segmentation",2022,"","","","",83,"2022-07-13 09:27:43","","10.48550/arXiv.2206.09309","","",,,,,0,0.00,0,5,1,". Despite recent improvements in the accuracy of brain tumor segmentation, the results still exhibit low levels of conﬁdence and robustness. Uncertainty estimation is one eﬀective way to change this sit-uation, as it provides a measure of conﬁdence in the segmentation results. In this paper, we propose a trusted brain tumor segmentation network which can generate robust segmentation results and reliable uncertainty estimations without excessive computational burden and modiﬁcation of the backbone network. In our method, uncertainty is modeled explicitly using subjective logic theory, which treats the predictions of backbone neural network as subjective opinions by parameterizing the class probabilities of the segmentation as a Dirichlet distribution. Meanwhile, the trusted segmentation framework learns the function that gathers reliable evidence from the feature leading to the ﬁnal segmentation results. Overall, our uniﬁed trusted segmentation framework endows the model with reliability and robustness to out-of-distribution samples. To evaluate the eﬀectiveness of our model in robustness and reliability, qualitative and quantitative experiments are conducted on the BraTS 2019 dataset.","",""
113,"Michael Hertneck, J. Köhler, S. Trimpe, F. Allgöwer","Learning an Approximate Model Predictive Controller With Guarantees",2018,"","","","",84,"2022-07-13 09:27:43","","10.1109/LCSYS.2018.2843682","","",,,,,113,28.25,28,4,4,"A supervised learning framework is proposed to approximate a model predictive controller (MPC) with reduced computational complexity and guarantees on stability and constraint satisfaction. The framework can be used for a wide class of nonlinear systems. Any standard supervised learning technique (e.g., neural networks) can be employed to approximate the MPC from samples. In order to obtain closed-loop guarantees for the learned MPC, a robust MPC design is combined with statistical learning bounds. The MPC design ensures robustness to inaccurate inputs within given bounds, and Hoeffding’s Inequality is used to validate that the learned MPC satisfies these bounds with high confidence. The result is a closed-loop statistical guarantee on stability and constraint satisfaction for the learned MPC. The proposed learning-based MPC framework is illustrated on a nonlinear benchmark problem, for which we learn a neural network controller with guarantees.","",""
0,"Motasem Alfarra, Juan C. P'erez, Ali K. Thabet, Adel Bibi, Philip H. S. Torr, Bernard Ghanem","Combating Adversaries with Anti-Adversaries",2021,"","","","",85,"2022-07-13 09:27:43","","10.1609/aaai.v36i6.20545","","",,,,,0,0.00,0,6,1,"Deep neural networks are vulnerable to small input perturbations known as adversarial attacks. Inspired by the fact that these adversaries are constructed by iteratively minimizing the confidence of a network for the true class label, we propose the anti-adversary layer, aimed at countering this effect. In particular, our layer generates an input perturbation in the opposite direction of the adversarial one and feeds the classifier a perturbed version of the input. Our approach is training-free and theoretically supported. We verify the effectiveness of our approach by combining our layer with both nominally and robustly trained models and conduct large-scale experiments from black-box to adaptive attacks on CIFAR10, CIFAR100, and ImageNet. Our layer significantly enhances model robustness while coming at no cost on clean accuracy.","",""
0,"Liangyu Ji, Tian Yao, Ge Wu, Liquan Chen, Zhongyuan Qin","ERGA: An Effective Region Gradient Algorithm for Adversarial Example Generation",2021,"","","","",86,"2022-07-13 09:27:43","","10.1145/3501409.3501611","","",,,,,0,0.00,0,5,1,"In recent years, with the rapid development of deep neural networks in the field of artificial intelligence, some of the security issues involved have gradually attracted attention in the industry, one of which is adversarial sample attacks. The attacker inputs carefully designed adversarial samples to the deep learning model, causing the attacked model to output misclassification results with high confidence, which seriously threatens the robustness of the deep learning model. Based on the commonly used deep learning network model, combined with the interpretability research of neural networks, we propose an effective region generation algorithm (ERGA) for adversarial sample generation, which can overcome the defects of the current commonly used algorithms. In our approach, the effective region selection step is added in the adversarial sample generation process, which overcomes the limitation of common adversarial sample generation algorithms that are limited to global pixel perturbation. We try to limit the number of pixels to be changed while maintaining a higher attack success. The algorithm also optimizes the process of counter disturbance generation, solves the uncertainty of the gradient update direction and amplitude in the iterative process. In addition, it also introduces the interpretability research of counter samples, which can be used to a certain extent in the deep learning network. At the same time, ERGA can improve the ability of supervision and self-examination of the classification results.","",""
43,"Chen Kong, S. Lucey","Deep Non-Rigid Structure From Motion",2019,"","","","",87,"2022-07-13 09:27:43","","10.1109/ICCV.2019.00164","","",,,,,43,14.33,22,2,3,"Current non-rigid structure from motion (NRSfM) algorithms are mainly limited with respect to: (i) the number of images, and (ii) the type of shape variability they can handle. This has hampered the practical utility of NRSfM for many applications within vision. In this paper we propose a novel deep neural network to recover camera poses and 3D points solely from an ensemble of 2D image coordinates. The proposed neural network is mathematically interpretable as a multi-layer block sparse dictionary learning problem, and can handle problems of unprecedented scale and shape complexity. Extensive experiments demonstrate the impressive performance of our approach where we exhibit superior precision and robustness against all available state-of-the-art works in the order of magnitude. We further propose a quality measure (based on the network weights) which circumvents the need for 3D ground-truth to ascertain the confidence we have in the reconstruction.","",""
5,"Hassan Ali, S. Nepal, S. Kanhere, S. Jha","HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor Attacks for Data Collection Scenarios",2020,"","","","",88,"2022-07-13 09:27:43","","","","",,,,,5,2.50,1,4,2,"We have witnessed the continuing arms race between backdoor attacks and the corresponding defense strategies on Deep Neural Networks (DNNs). Most state-of-the-art defenses rely on the statistical sanitization of the ""inputs"" or ""latent DNN representations"" to capture trojan behaviour. In this paper, we first challenge the robustness of such recently reported defenses by introducing a novel variant of targeted backdoor attack, called ""low-confidence backdoor attack"". We also propose a novel defense technique, called ""HaS-Nets"".  ""Low-confidence backdoor attack"" exploits the confidence labels assigned to poisoned training samples by giving low values to hide their presence from the defender, both during training and inference. We evaluate the attack against four state-of-the-art defense methods, viz., STRIP, Gradient-Shaping, Februus and ULP-defense, and achieve Attack Success Rate (ASR) of 99%, 63.73%, 91.2% and 80%, respectively.  We next present ""HaS-Nets"" to resist backdoor insertion in the network during training, using a reasonably small healing dataset, approximately 2% to 15% of full training data, to heal the network at each iteration. We evaluate it for different datasets - Fashion-MNIST, CIFAR-10, Consumer Complaint and Urban Sound - and network architectures - MLPs, 2D-CNNs, 1D-CNNs. Our experiments show that ""HaS-Nets"" can decrease ASRs from over 90% to less than 15%, independent of the dataset, attack configuration and network architecture.","",""
17,"Fan Yang, Houjin Chen, Jupeng Li, Feng Li, Lei Wang, Xiaomiao Yan","Single Shot Multibox Detector With Kalman Filter for Online Pedestrian Detection in Video",2019,"","","","",89,"2022-07-13 09:27:43","","10.1109/ACCESS.2019.2895376","","",,,,,17,5.67,3,6,3,"Pedestrian detection is a valuable and challenging problem in computer vision. To fully exploit the interframe information to improve the detector’s performance, many frameworks with high complexity for offline detection have been proposed. These methods cannot provide spontaneous responses or alerts. In this paper, we present a Kalman filter-based convolutional neural network (CNN) for online pedestrian detection in videos. First, the single shot multibox detector is implemented as the CNN detector, which incorporates the pedestrian’s aspect ratios. Fusion modules are implemented to improve the detector’s robustness for medium and far scale pedestrians. Then, bounding boxes are propagated according to the prediction from the Kalman filter. Finally, the location and confidence of the bounding boxes are refined by the Kalman filter. Our method is evaluated on two datasets with respect to both the miss rate and speed, and the results show that our method has a lower miss rate, more stable confidence, and a much higher speed.","",""
39,"Mara Graziani, V. Andrearczyk, H. Müller","Regression Concept Vectors for Bidirectional Explanations in Histopathology",2018,"","","","",90,"2022-07-13 09:27:43","","10.1007/978-3-030-02628-8_14","","",,,,,39,9.75,13,3,4,"","",""
0,"Naigong Yu, J. Lv","Human body posture recognition algorithm for still images",2020,"","","","",91,"2022-07-13 09:27:43","","10.1049/joe.2019.1146","","",,,,,0,0.00,0,2,2,"Aiming at the low accuracy and poor robustness of the current algorithm based on manual features, this study proposed a posture recognition method combining joint point information with convolutional neural network. The deformable convolution is used in the proposed method to improve the stacked hourglass model, so that it can extract the position of the human joint point accurately. At the same time, the convolutional neural network structure is designed to analyse the position information and confidence of the joint point autonomously, and extract the intrinsic link of the joint point of the human body. Finally, the softmax classifier is used to determine the pose category. Experimental verification has been carried out on the Willow data set. Moreover, the recognition accuracy demonstrates the effectiveness and superiority of the improved method.","",""
12,"Wenqiang Zhan, Changshi Xiao, Y. Wen, Chunhui Zhou, Haiwen Yuan, Supu Xiu, Yimeng Zhang, Xiong Zou, Xin Liu, Qiliang Li","Autonomous Visual Perception for Unmanned Surface Vehicle Navigation in an Unknown Environment",2019,"","","","",92,"2022-07-13 09:27:43","","10.3390/s19102216","","",,,,,12,4.00,1,10,3,"Robust detection and recognition of water surfaces are critical for autonomous navigation of unmanned surface vehicles (USVs), since any none-water region is likely an obstacle posing a potential danger to the sailing vehicle. A novel water region visual detection method is proposed in this paper. First, the input image pixels are clustered into different regions and each pixel is assigned a label tag and a confidence value by adaptive multistage segmentation algorithm. Then the resulting label map and associated confidence map are fed into a convolutional neural network (CNN) as training samples to train the network online. Finally, the online trained CNN is used to segment the input image again but with greater precision and stronger robustness. Compared with other deep-learning image segmentation algorithms, the proposed method has two advantages. Firstly, it dispenses with the need of manual labeling training samples which is a costly and painful task. Secondly, it allows real-time online training for CNN, making the network adaptive to the navigational environment. Another contribution of this work relates to the training process of neuro network. An effective network training method is designed to learn from the imperfect training data. We present the experiments in the lake with a various scene and demonstrate that our proposed method could be applied to recognize the water region in the unknown navigation environment automatically.","",""
6,"Xia Fang, Wang Jie, Tao Feng","An Industrial Micro-Defect Diagnosis System via Intelligent Segmentation Region",2019,"","","","",93,"2022-07-13 09:27:43","","10.3390/s19112636","","",,,,,6,2.00,2,3,3,"In the field of machine vision defect detection for a micro workpiece, it is very important to make the neural network realize the integrity of the mask in analyte segmentation regions. In the process of the recognition of small workpieces, fatal defects are always contained in borderline areas that are difficult to demarcate. The non-maximum suppression (NMS) of intersection over union (IOU) will lose crucial texture information especially in the clutter and occlusion detection areas. In this paper, simple linear iterative clustering (SLIC) is used to augment the mask as well as calibrate the score of the mask. We propose an SLIC head of object instance segmentation in proposal regions (Mask R-CNN) containing a network block to learn the quality of the predict masks. It is found that parallel K-means in the limited region mechanism in the SLIC head improved the confidence of the mask score, in the context of our workpiece. A continuous fine-tune mechanism was utilized to continuously improve the model robustness in a large-scale production line. We established a detection system, which included an optical fiber locator, telecentric lens system, matrix stereoscopic light, a rotating platform, and a neural network with an SLIC head. The accuracy of defect detection is effectively improved for micro workpieces with clutter and borderline areas.","",""
6,"Chen Kong, S. Lucey","Deep Interpretable Non-Rigid Structure from Motion",2019,"","","","",94,"2022-07-13 09:27:43","","","","",,,,,6,2.00,3,2,3,"All current non-rigid structure from motion (NRSfM) algorithms are limited with respect to: (i) the number of images, and (ii) the type of shape variability they can handle. This has hampered the practical utility of NRSfM for many applications within vision. In this paper we propose a novel deep neural network to recover camera poses and 3D points solely from an ensemble of 2D image coordinates. The proposed neural network is mathematically interpretable as a multi-layer block sparse dictionary learning problem, and can handle problems of unprecedented scale and shape complexity. Extensive experiments demonstrate the impressive performance of our approach where we exhibit superior precision and robustness against all available state-of-the-art works. The considerable model capacity of our approach affords remarkable generalization to unseen data. We propose a quality measure (based on the network weights) which circumvents the need for 3D ground-truth to ascertain the confidence we have in the reconstruction. Once the network's weights are estimated (for a non-rigid object) we show how our approach can effectively recover 3D shape from a single image -- outperforming comparable methods that rely on direct 3D supervision.","",""
4,"S. M. Sahraeian, L. Fang, M. Mohiyuddin, H. Hong, W. Xiao","Robust Cancer Mutation Detection with Deep Learning Models Derived from Tumor-Normal Sequencing Data",2019,"","","","",95,"2022-07-13 09:27:43","","10.1101/667261","","",,,,,4,1.33,1,5,3,"Accurate detection of somatic mutations is challenging but critical to the understanding of cancer formation, progression, and treatment. We recently proposed NeuSomatic, the first deep convolutional neural network based somatic mutation detection approach and demonstrated performance advantages on in silico data. In this study, we used the first comprehensive and well-characterized somatic reference samples from the SEQC-II consortium to investigate best practices for utilizing deep learning framework in cancer mutation detection. Using the high-confidence somatic mutations established for these reference samples by the consortium, we identified strategies for building robust models on multiple datasets derived from samples representing real scenarios. The proposed strategies achieved high robustness across multiple sequencing technologies such as WGS, WES, AmpliSeq target sequencing for fresh and FFPE DNA input, varying tumor/normal purities, and different coverages (ranging from 10× - 2000×). NeuSomatic significantly outperformed conventional detection approaches in general, as well as in challenging situations such as low coverage, low mutation frequency, DNA damage, and difficult genomic regions.","",""
13,"Erik Blasch, Shuo Liu, Zheng Liu, Yufeng Zheng","Deep Learning Measures of Effectiveness",2018,"","","","",96,"2022-07-13 09:27:43","","10.1109/NAECON.2018.8556808","","",,,,,13,3.25,3,4,4,"The resurgence of interest in artificial intelligence (AI) stem from impressive deep learning (DL) performance such as hierarchical supervised training using a Convolutional Neural Network (CNN). Current DL needs to focus on contextual reasoning, explainable results, and repeatable understanding that require evaluation methods. This paper presents measures of effectiveness (MOE) for DL techniques that extend measures of performance (MOP). MOPs include: Timeliness: computational efficiency, Accuracy: operational robustness, and Confidence: semi-supervised representation. MOE concerns include Throughput: data efficiency, Security: adversarial robustness, and Completeness: problem representation. DL evaluation requires verification and validation testing in realistic environments. An example is shown for Deep Multimodal Image Fusion (DMIF) that evaluates MOEs of information gain, robustness, and quality.","",""
0,"M. Kocián, M. Pilát","Using Local Convolutional Units to Defend Against Adversarial Examples",2019,"","","","",97,"2022-07-13 09:27:43","","10.1109/IJCNN.2019.8852393","","",,,,,0,0.00,0,2,3,"Deep neural networks are known to be sensitive to adversarial examples – inputs that are created in such a way that they are similar (if viewed by people) to clean inputs, but the neural network has high confidence that they belong to another class.In this paper, we study a new type of neural network unit similar to the convolutional units, but with a more local behavior. The unit is based on the Gaussian radial basis function. We show that if we replace the first convolutional layer in a convolutional network by the new layer (called RBFolutional), we obtain better robustness towards adversarial samples on the MNIST and CIFAR10 datasets, without sacrificing the performance on the clean examples.","",""
79,"Dong Zhao, D. Xue","A comparative study of metamodeling methods considering sample quality merits",2010,"","","","",98,"2022-07-13 09:27:43","","10.1007/S00158-010-0529-3","","",,,,,79,6.58,40,2,12,"","",""
3,"Vincent Billaut, Matthieu de Rochemonteix, Marc Thibault","ColorUNet: A convolutional classification approach to colorization",2018,"","","","",99,"2022-07-13 09:27:43","","","","",,,,,3,0.75,1,3,4,"This paper tackles the challenge of colorizing grayscale images. We take a deep convolutional neural network approach, and choose to take the angle of classification, working on a finite set of possible colors. Similarly to a recent paper, we implement a loss and a prediction function that favor realistic, colorful images rather than ""true"" ones.  We show that a rather lightweight architecture inspired by the U-Net, and trained on a reasonable amount of pictures of landscapes, achieves satisfactory results on this specific subset of pictures. We show that data augmentation significantly improves the performance and robustness of the model, and provide visual analysis of the prediction confidence.  We show an application of our model, extending the task to video colorization. We suggest a way to smooth color predictions across frames, without the need to train a recurrent network designed for sequential inputs.","",""
2,"Donghui Li, M. Azimi-Sadjadi, A. Jamshidi, G. Dobeck","Comparison of confidence level of different classification paradigms for underwater target discrimination",2001,"","","","",100,"2022-07-13 09:27:43","","10.1117/12.445443","","",,,,,2,0.10,1,4,21,"The problem of classification of underwater targets from the acoustic backscattered signals is considered. A wavelet packet-based feature extraction scheme is used in conjunction with the linear prediction coding (LPC) scheme as the front-end processor. Selected features with higher discriminatory power are then fed to a neural network classifier. Several different classification system are benchmarked in this paper. These include: an ellipsoidal K- nearest neighbor classifier, probabilistic neural networks and support vector machines. The performance of these classifiers are examined on a wideband 80 kHz acoustic backscattered data set collected for six different objects. These systems are then benchmarked with the previously used Back propagation Neural Network in terms of their receiver operating characteristics and robustness with respect to reverberation.","",""
94,"M. Roemer, G. Kacprzynski, R. Orsagh","Assessment of data and knowledge fusion strategies for prognostics and health management",2001,"","","","",101,"2022-07-13 09:27:43","","10.1109/AERO.2001.931318","","",,,,,94,4.48,31,3,21,"Various data, feature and knowledge fusion strategies and architectures have been developed over the last several years for improving upon the accuracy, robustness and overall effectiveness of anomaly, diagnostic and prognostic technologies. Fusion of relevant sensor data, maintenance database information, and outputs from various diagnostic and prognostic technologies has proven effective in reducing false alarm rates, increasing confidence levels in early fault detection, and predicting time to failure or degraded condition requiring maintenance action. The data fusion strategies discussed are principally probabilistic in nature and are used to aid in directly identifying confidence bounds associated with specific component fault identifications and predictions. Dempster-Shafer fusion, Bayesian inference, fuzzy-logic inference, neural network fusion and simple weighting/voting are the algorithmic approaches that are discussed. Data fusion architectures such as centralized fusion, autonomous fusion, and hybrid fusion are described in terms of their applicability to fault diagnosis and prognosis. The final goal is to find the optimal combination of measured system data, data fusion algorithms, and associated architectures for obtaining the highest overall prediction/detection confidence levels associated with a specific application. To achieve this goal, a set of metrics has been developed for gauging the performance and effectiveness of a fusion strategy. Specifically, this paper demonstrates how various metrics are used for assessing individual and fused vibration-based diagnostic algorithms. Evaluation of the diagnostic strategies was performed using gearbox seeded-fault and accelerated failure data.","",""
5,"J. Zhang, A. Morris, E. Martin, C. Kiparissides","Estimation of impurity and fouling in batch polymerisation reactors using stacked neural networks",1997,"","","","",102,"2022-07-13 09:27:43","","10.1109/ACC.1997.611795","","",,,,,5,0.20,1,4,25,"A robust method for the estimation of reactive impurities and reactor fouling during the early stage of batch polymerisation using stacked neural networks is reported. Data for building neural network models are resampled using the bootstrap re-sampling technique to form several sets of training data. For each set of training data, a neural network model is developed. Predictions from individual networks are combined to form the final model prediction in order to improve model accuracy and robustness. A further benefit of bootstrap aggregated neural network is that confidence bounds for model predictions can be formulated. Stacked neural networks are used to build an inverse model of the reactor. The amounts of impurities and fouling can be worked out by comparing the predicted effective initial reaction conditions with the nominal initial conditions. The proposed techniques have been successfully applied to a pilot scale batch methyl methacrylate polymerisation reactor.","",""
8,"J. Nagi, A. Giusti, F. Nagi, L. Gambardella, G. D. Caro","Online feature extraction for the incremental learning of gestures in human-swarm interaction",2014,"","","","",103,"2022-07-13 09:27:43","","10.1109/ICRA.2014.6907338","","",,,,,8,1.00,2,5,8,"We present a novel approach for the online learning of hand gestures in swarm robotic (multi-robot) systems. We address the problem of online feature learning by proposing Convolutional Max-Pooling (CMP), a simple feed-forward two-layer network derived from the deep hierarchical Max-Pooling Convolutional Neural Network (MPCNN). To learn and classify gestures in an online and incremental fashion, we employ a 2nd order online learning method, namely the Soft-Confidence Weighted (SCW) learning scheme. In order for all robots to collectively take part in the learning and recognition task and obtain a swarm-level classification, we build a distributed consensus by fusing the individual decision opinions of robots together with the individual weights generated from multiple classifiers. Accuracy, robustness, and scalability of obtained solutions have been verified through emulation experiments performed on a large data set of real data acquired by a networked swarm of robots.","",""
4,"Nan Ren, Junping Du, Suguo Zhu, Linghui Li, Dan Fan, Jangmyung Lee","Robust visual tracking based on scale invariance and deep learning",2017,"","","","",104,"2022-07-13 09:27:43","","10.1007/s11704-016-6050-0","","",,,,,4,0.80,1,6,5,"","",""
4,"Jiayan Qiu, Yuchao Dai, Yuhang Zhang, J. Álvarez","Hierarchical Aggregation Based Deep Aging Feature for Age Prediction",2015,"","","","",105,"2022-07-13 09:27:43","","10.1109/DICTA.2015.7371264","","",,,,,4,0.57,1,4,7,"We propose a new, hierarchical, aggregation-based deep neural network to learn aging features from facial images. Our deep-aging feature vector is designed to capture both local and global aging cues from facial images. A Convolutional Neural Network (CNN) is employed to extract region- specific features at the lowest level of our hierarchy. These features are then hierarchically aggregated to consecutive higher levels and the resultant aging feature vector, of dimensionality 110, achieves both good discriminative ability and efficiency. Experimental results of age prediction on the MORPH-II databases show that our method outperforms state-of-the-art aging features by a clear margin. Experimental trails of our method across race and gender provide further confidence in its performance and robustness.","",""
2,"Yizheng Xu, J. Milanović","Estimation of percentage of controllable load in total demand at bulk supply point",2014,"","","","",106,"2022-07-13 09:27:43","","10.1049/CP.2014.1695","","",,,,,2,0.25,1,2,8,"This paper presents an Artificial Neural Network (ANN) based approach to estimate percentage of controllable load in overall demand at bulk supply point at any given time based on standard voltage, real and reactive power measurements at the substation. Monte Carlo Simulation (MCS) is used to generate the training and validation data. The estimated controllable and uncontrollable load percentages are compared with the targets in the validation process, and the probability distribution and the confidence levels of load participation estimation errors are obtained. When all inputs are available, the most probable absolute error of estimation of controllable and uncontrollable load percentage is approximately 4.3%, with about 60% of all estimations having absolute errors below 10%. The robustness of the methodology with respect to missing input data is also evaluated. It demonstrates that the absence of an input, especially the absence of the reactive power, can reduce the confidence level of estimation with the same estimation error.","",""
33,"M. Roemer, G. Kacprzynski, M. Schoeller","Improved diagnostic and prognostic assessments using health management information fusion",2001,"","","","",107,"2022-07-13 09:27:43","","10.1109/AUTEST.2001.948984","","",,,,,33,1.57,11,3,21,"Various data, feature and knowledge fusion strategies and architectures have been developed over the last several years for improving upon the accuracy, robustness and overall effectiveness of anomaly, diagnostic and prognostic technologies. Fusion of relevant sensor data, maintenance database information, and outputs from various diagnostic and prognostic technologies has proven effective in reducing false alarm rates, increasing confidence levels in early fault detection, and predicting time to failure or degraded condition requiring maintenance action. The data fusion strategies discussed in this paper are principally probabilistic or AI-based in nature and are used to aid in directly identifying confidence bounds associated with specific component fault identifications and predictions. Dempster-Shafer fusion, Bayesian inference, fuzzy-logic inference, neural network fusion and simple weighting/voting are the algorithmic approaches that are discussed in this paper. Data fusion architectures such as centralized fusion, autonomous fusion, and hybrid fusion are described in terms of their applicability to fault diagnosis and prognosis. The final goal is to find the optimal combination of measured system data, data fusion algorithms, and associated architectures for obtaining the highest overall prediction/detection confidence levels associated with a specific application. A gas turbine engine test cell sensor validation example is provided in the paper that is specifically related data fusion approaches for test cell sensor validation using Dempster-Shafer fusion.","",""
0,"W. Jianjun","Research of Failure Detection and Data Accommodation Algorithm of Sensor for Liquid-Propellant Rocket Engine",2012,"","","","",108,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,10,"Based on the back propagation neural network,the failure detection and data accommodation algorithm of sensor for liquid-propellant rocket engine is developed according to the failure characteristics of sensor.The confidence level is defined to detect the failure of sensor and identify the failure sensor,and the trained neural network structure is used to accommodate it.Regarding the research,the failure detection,identification,and accommodation of sensor can be realized and the reliability and robustness of fault detection method of engine are improved.","",""
6,"Dong Zhao, D. Xue","Performance Comparison of Metamodeling Methods From the Perspective of Sample Quality Merits",2009,"","","","",109,"2022-07-13 09:27:43","","10.1115/DETC2009-86270","","",,,,,6,0.46,3,2,13,"Although many metamodeling methods have been developed in the past decades to model the relationships between input and output parameters, selection of an appropriate or the optimal metamodel for solving a certain engineering problem is not a trivial task. Various performance measures of different metamodels are strongly influenced by the characteristics of sample data. This research focuses on the study of the relationships between sample data characteristics and metamodel performance measures considering different types of metamodeling methods. In this research, sample quality merits are introduced to quantitatively model the characteristics of sample data. In this work, four types of metamodeling methods, including multivariate polynomial model, radial basis function model, kriging model and Bayesian neural network model, three sample quality merits, including sample size, uniformity and noise, and four performance evaluation measures, including accuracy, confidence, robustness and efficiency, are considered to study the relationships between the sample quality merits and the performance measures of the metamodeling methods.Copyright © 2009 by ASME","",""
1,"Субботин Сергей Александрович","Модели показателей для анализа и сравнения свойств нейронных и нейронечетких сетей при решении задач диагностики и прогнозирования",2009,"","","","",110,"2022-07-13 09:27:43","","","","",,,,,1,0.08,1,1,13,"A set of indicator models is developed to measure such neural and neuro-fuzzy model properties, as the nonlinearity, autonomy, generalization, robustness, symmetry, decision confidence, equivalence, adaptability, sensitivity. The proposed indicators can be used for neural network model comparison and selection in diagnosis and prediction problems.","",""
3,"G. Kacprzynski, M. Roemer, R. Orsagh","Assessment of Data and Knowledge Fusion Strategies for Diagnostics and Prognostics",2001,"","","","",111,"2022-07-13 09:27:43","","","","",,,,,3,0.14,1,3,21,"Abstract : Various data, feature and knowledge fusion strategies and architectures have been developed over the last several years for improving upon the accuracy, robustness and overall effectiveness of anomaly, diagnostic and prognostic technologies. Fusion of relevant sensor data, maintenance database information, and outputs from various diagnostic and prognostic technologies has proven effective in reducing false alarm rates, increasing confidence levels in early fault detection, and predicting time to failure or degraded condition requiring maintenance action. The data fusion strategies discussed in this paper are principally probabilistic in nature and are used to aid in directly identifying confidence bounds associated with specific component fault identifications and predictions. Dempster-Shafer fusion, Bayesian inference, fuzzy-logic inference, neural network fusion and simple weighting/voting are the algorithmic approaches that are discussed in this paper. Data fusion architectures such as centralized fusion, autonomous fusion, and hybrid fusion are described in terms of their applicability to fault diagnosis and prognosis. The final goal is to find the optimal combination of measured system data, data fusion algorithms, and associated architectures for obtaining the highest overall prediction/detection confidence levels associated with a specific application Evaluation of the fusion and diagnostic strategies was performed using gearbox seeded- fault and accelerated failure data taken with the MDTB (Mechanical Diagnostic Test Bed) at the ARL Lab at Penn State University.","",""
4721,"Nicholas Carlini, D. Wagner","Towards Evaluating the Robustness of Neural Networks",2016,"","","","",112,"2022-07-13 09:27:43","","10.1109/SP.2017.49","","",,,,,4721,786.83,2361,2,6,"Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input x and any target classification t, it is possible to find a new input x' that is similar to x but classified as t. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from 95% to 0.5%.In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with 100% probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.","",""
2,"Yue-Huan Wang, Zenan Li, Jingwei Xu, Ping Yu, Xiaoxing Ma","Fast Robustness Prediction for Deep Neural Network",2019,"","","","",113,"2022-07-13 09:27:43","","10.1145/3361242.3361243","","",,,,,2,0.67,0,5,3,"Deep neural networks (DNNs) have achieved impressive performance in many difficult tasks. However, DNN models are essentially uninterpretable to humans, and unfortunately prone to adversarial attacks, which hinders their adoption in security and safety-critical scenarios. The robustness of a DNN model, which measures its stableness against adversarial attacks, becomes an important topic in both the machine learning and the software engineering communities. Analytical evaluation of DNN robustness is difficult due to the high-dimensionality of inputs, the huge amount of parameters, and the nonlinear network structure. In practice, the degree of robustness of DNNs is empirically approximated with adversarial searching, which is computationally expensive and cannot be applied in resource constrained settings such as embedded computing. In this paper, we propose to predict the robustness of a DNN model for each input with another DNN model, which takes the output of neurons of the former model as input. We train a regression model to encode the connections between output of the penultimate layer of a DNN model and its robustness. With this trained model, the robustness for an input can be predicted instantaneously. Experiments with MNIST and CIFAR10 datasets and LeNet, VGG and ResNet DNN models were conducted to evaluate the efficacy of the proposed approach. The results indicated that our approach achieved 0.05-0.21 mean absolute errors and significantly outperformed confidence and surprise adequacy-based approaches.","",""
3,"Jiantao Liu, Xiaoxiang Yang, Mingzhu Zhu","Neural Network with Confidence Kernel for Robust Vibration Frequency Prediction",2019,"","","","",114,"2022-07-13 09:27:43","","10.1155/2019/6573513","","",,,,,3,1.00,1,3,3,"Image-based measurement has received increasing attention as it can substantially reduce the cost of labor, measurement equipment, and installation process. Instead of using optical flow, pattern, or marker tracking to extract a displacement signal, in this study, a novel noncontact machine learning-based system was proposed to directly predict vibration frequency with high accuracy and good reliability by using image sequences acquired from a single camera. The performance of the proposed method was demonstrated through experiments conducted in a laboratory and under real-field conditions and compared with those obtained using a contacted sensor. The vibration frequency prediction results of the proposed method are compared with industry-level vibration sensor results in the frequency domain, demonstrating that the proposed method could predict the target-object-vibration frequency as accurately as an industry-level vibration sensor, even under uncontrollable real-field conditions with no additional enhancement or extra signal processing techniques. However, only the principal vibration frequency of a measurement target is predicted, and the measurement range is limited by the trained model. Nonetheless, if these limitations are resolved, this method can potentially be used in real engineering applications in mechanical or civil structural health monitoring thanks to the simple deployment and concise pipeline of this method.","",""
9,"Michael Everett, Golnaz Habibi, J. How","Robustness Analysis of Neural Networks via Efficient Partitioning With Applications in Control Systems",2021,"","","","",115,"2022-07-13 09:27:43","","10.1109/LCSYS.2020.3045323","","",,,,,9,9.00,3,3,1,"Neural networks (NNs) are now routinely implemented on systems that must operate in uncertain environments, but the tools for formally analyzing how this uncertainty propagates to NN outputs are not yet commonplace. Computing tight bounds on NN output sets (given an input set) provides a measure of confidence associated with the NN decisions and is essential to deploy NNs on safety-critical systems. Recent works approximate the propagation of sets through nonlinear activations or partition the uncertainty set to provide a guaranteed outer bound on the set of possible NN outputs. However, the bound looseness causes excessive conservatism and/or the computation is too slow for online analysis. This letter unifies propagation and partition approaches to provide a family of robustness analysis algorithms that give tighter bounds than existing works for the same amount of computation time (or reduced computational effort for a desired accuracy level). Moreover, we provide new partitioning techniques that are aware of their current bound estimates and desired boundary shape (e.g., lower bounds, weighted $\ell _{\infty }$ -ball, convex hull), leading to further improvements in the computation-tightness tradeoff. The letter demonstrates the tighter bounds and reduced conservatism of the proposed robustness analysis framework with examples from model-free RL and forward kinematics learning.","",""
6,"Jongheon Jeong, Sejun Park, Minkyu Kim, Heung-Chang Lee, Do-Guk Kim, Jinwoo Shin","SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness",2021,"","","","",116,"2022-07-13 09:27:43","","","","",,,,,6,6.00,1,6,1,"Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against l2-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of a smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains on convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified l2-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.","",""
2,"F. Arnez, H. Espinoza, A. Radermacher, F. Terrier","Improving Robustness of Deep Neural Networks for Aerial Navigation by Incorporating Input Uncertainty",2021,"","","","",117,"2022-07-13 09:27:43","","10.1007/978-3-030-83906-2_17","","",,,,,2,2.00,1,4,1,"","",""
0,"M. Everett, Golnaz Habibi, J. How","Robustness Analysis of Neural Networks via Efficient Partitioning with Applications in Control Systems",2021,"","","","",118,"2022-07-13 09:27:43","","10.23919/ACC50511.2021.9483033","","",,,,,0,0.00,0,3,1,"Neural networks (NNs) are now routinely implemented on systems that must operate in uncertain environments, but the tools for formally analyzing how this uncertainty propagates to NN outputs are not yet commonplace. Computing tight bounds on NN output sets (given an input set) provides a measure of confidence associated with the NN decisions and is essential to deploy NNs on safety-critical systems. Recent works approximate the propagation of sets through nonlinear activations or partition the uncertainty set to provide a guaranteed outer bound on the set of possible NN outputs. However, the bound looseness causes excessive conservatism and/or the computation is too slow for online analysis. This paper unifies propagation and partition approaches to provide a family of robustness analysis algorithms that give tighter bounds than existing works for the same amount of computation time (or reduced computational effort for a desired accuracy level). Moreover, we provide new partitioning techniques that are aware of their current bound estimates and desired boundary shape (e.g., lower bounds, weighted $\ell_{\infty}$-ball, convex hull), leading to further improvements in the computation-tightness tradeoff. The paper demonstrates the tighter bounds and reduced conservatism of the proposed robustness analysis framework with examples from model-free RL and forward kinematics learning.","",""
3,"Nuowen Kan, Chenglin Li, Caiyi Yang, Wenrui Dai, Junni Zou, H. Xiong","Uncertainty-aware robust adaptive video streaming with bayesian neural network and model predictive control",2021,"","","","",119,"2022-07-13 09:27:43","","10.1145/3458306.3458872","","",,,,,3,3.00,1,6,1,"In this paper, we propose BayesMPC, an uncertainty-aware robust adaptive bitrate (ABR) algorithm on the basis of Bayesian neural network (BNN) and model predictive control (MPC). Specifically, to improve the capacity of learning transition probability of the network throughput, we adopt a BNN-based predictor that is able to predict the statistical distribution of future throughput from the past throughput by not only considering the aleatoric uncertainty (e.g., noise), but also capturing the epistemic uncertainty incurred by lack of adequate training samples. We further show that by using the negative log-likelihood loss function to train this BNN-based throughput predictor, the generalization error can be minimized with the guarantee of PAC-Bayesian theorem. Rather than a point estimate, the learnt uncertainty can contribute to a confidence region for the future throughput, the lower bound of which then leads to an uncertainty-aware robust MPC strategy to maximize the worst-case user quality-of-experience (QoE) w.r.t. this confidence region. Finally, experimental results on three real-world network trace datasets validate the efficiency of both the proposed BNN-based predictor and uncertainty-aware robust MPC strategy, and demonstrate the superior performance compared to other baselines, in terms of both the overall QoE performance and generalization across all ranges of heterogeneous network and user conditions.","",""
3,"Xu Wang, Tianyang Wang, A. Ming, Q. Han, F. Chu, Wei Zhang, Aihua Li","Deep Spatiotemporal Convolutional-Neural-Network-Based Remaining Useful Life Estimation of Bearings",2021,"","","","",120,"2022-07-13 09:27:43","","10.1186/s10033-021-00576-1","","",,,,,3,3.00,0,7,1,"","",""
2,"Hu Cao, Guang Chen, Zhijun Li, Jianjie Lin, A. Knoll","Lightweight Convolutional Neural Network with Gaussian-based Grasping Representation for Robotic Grasping Detection",2021,"","","","",121,"2022-07-13 09:27:43","","","","",,,,,2,2.00,0,5,1,"The method of deep learning has achieved excellent results in improving the performance of robotic grasping detection. However, the deep learning methods used in general object detection are not suitable for robotic grasping detection. Current modern object detectors are difficult to strike a balance between high accuracy and fast inference speed. In this paper, we present an efficient and robust fully convolutional neural network model to perform robotic grasping pose estimation from n-channel input image of the real grasping scene. The proposed network is a lightweight generative architecture for grasping detection in one stage. Specifically, a grasping representation based on Guassian kernel is introduced to encode training samples, which embodies the principle of maximum central point grasping confidence. Meanwhile, to extract multiscale information and enhance the feature discriminability, a receptive field block (RFB) is assembled to the bottleneck of our grasping detection architecture. Besides, pixel attention and channel attention are combined to automatically learn to focus on fusing context information of varying shapes and sizes by suppressing the noise feature and highlighting the grasping object feature. Extensive experiments on two public grasping datasets, Cornell and Jacquard demonstrate the state-of-the-art performance of our method in balancing accuracy and inference speed. The network is an order of magnitude smaller than other excellent algorithms, while achieving better performance with accuracy of 98.9% and 95.6% on the Cornell and Jacquard datasets, respectively.","",""
0,"Yi Han, Xubin Wang, Zheng Lu","Research on facial expression recognition based on Multimodal data fusion and neural network",2021,"","","","",122,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,3,1,"Facial expression recognition is a challenging task when neural network is applied to pattern recognition. Most of the current recognition research is based on single source facial data, which generally has the disadvantages of low accuracy and low robustness. In this paper, a neural network algorithm of facial expression recognition based on multimodal data fusion is proposed. The algorithm is based on the multimodal data, and it takes the facial image, the histogram of oriented gradient of the image and the facial landmarks as the input, and establishes CNN, LNN and HNN three sub neural networks to extract data features, using multimodal data feature fusion mechanism to improve the accuracy of facial expression recognition. Experimental results show that, benefiting by the complementarity of multimodal data, the algorithm has a great improvement in accuracy, robustness and detection speed compared with the traditional facial expression recognition algorithm. Especially in the case of partial occlusion, illumination and head posture transformation, the algorithm also shows a high confidence.","",""
0,"Yongho Kim, Hanna Lukashonak, Paweena Tarepakdee, Klavdia Zavalich, Mofassir ul Islam Arif","Disturbing Target Values for Neural Network Regularization",2021,"","","","",123,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,5,1,"Given the increasing computational capabilities of modern computing systems, we are seeing bigger and more complex neural networks being used. However with this increase the models have shown to perform well on training data but suffering on unseen test data, this problem is known as overfitting. This phenomenon is well recognized in recent researches that the model tends to become overparameterized when the networks get more complex. Diverse regularization techniques have been developed such as L2 regularization, Dropout, DisturbLabel (DL) to prevent overfitting. DL, a newcomer on the scene, regularizes the loss layer by flipping a small share of the target labels at random and training the neural network on this distorted data so as to not learn the training data. It is observed that high confidence labels during training cause the overfitting problem and DL selects disturb labels at random regardless of the confidence of labels. To solve this shortcoming of DL, we propose Directional DisturbLabel (DDL) a novel regularization technique that makes use of the class probabilities to infer the confident labels and using these labels to regularize the model. This active regularization makes use of the model behavior during training to regularize it in a more directed manner. To address regression problems, we also propose DisturbValue (DV), and DisturbError (DE). DE uses only predefined confident labels to disturb target values. DV injects noise into a portion of target values at random similar to DL. In this paper, 6 and 8 datasets are used to validate the robustness of our methods in classification and regression tasks respectively. Finally, we demonstrate that our methods are either comparable to or outperform DisturbLabel, L2 regularization, and Dropout. Also, we achieve the best performance in more than half the datasets by combining our methods with either L2 regularization or Dropout.","",""
0,"C. Pasareanu","Analysis of neural network takeover-time predictions for shared-control autonomous driving",2021,"","","","",124,"2022-07-13 09:27:43","","10.1145/3459086.3459630","","",,,,,0,0.00,0,1,1,"Autonomous driving systems may encounter situations where it is necessary to transfer control to the human driver, for instance when encountering unpredictable dangerous road conditions. To be able to do so safely, the autonomous system needs an estimate of how long it will take for the human driver to take control of the vehicle. A neural network can be used for making such predictions. However ensuring that such a neural network can be used in safety-critical situations is very challenging. We discuss our recent efforts for building, analysing and formally verifying a neural network built for predicting takeover time in a shared-control autonomous driving system. The network was trained on data collected from a (semi-) autonomous driving simulator. We evaluated several techniques for the analysis of the neural network as follows. We performed robustness and sensitivity analysis for the neural network, using the Marabou formal verification tool. We evaluated off-the-shelf attribution tools to determine the important features upon which the neural network makes its predictions. We investigated trust and confidence analysis to better understand the neural network outputs. And finally, we performed adversarial training to improve the quality of the neural network. We discuss our results and outline directions for future work.","",""
0,"Ruixu Liu, Theus H. Aspiras, V. Asari","Deep neural network based approach for robust aerial surveillance",2021,"","","","",125,"2022-07-13 09:27:43","","10.1117/12.2591194","","",,,,,0,0.00,0,3,1,"Aerial object detection is one of the most important applications in computer vision. We propose a deep learning strategy for detection and classification of objects on the pipeline right of ways by analyzing aerial images captured by flying aircrafts or drones. Due to the limitation of sufficient aerial datasets for accurately training the deep learning systems, it is necessary to create an efficient methodology for object data augmentation of the training dataset to achieve robust performance in various environmental conditions. Another limitation is the computing hardware that could be installed on the aircraft, especially when it is a drone. Hence a balance between the effectiveness and efficiency of object detector needs to be considered. We propose an efficient weighted IOU NMS (intersection over union non-maxima suppression) method to speed up the post-processing time that satisfies the onboard processing requirement. Weighted IOU NMS utilizes confidence scores of all proposed bounding boxes to regenerate a mean box in parallel. It processes the bounding box score at the same instant without removing the bounding box or decreasing the bounding box score. We perform both quantitative and qualitative evaluations of our network architecture on multiple aerial datasets. The experimental results show that our proposed framework achieves better accuracy than the state-of-the-art methods for aerial object detection in various environmental conditions.","",""
4,"Tao Bai, Jinqi Luo, Jun Zhao","Recent Advances in Understanding Adversarial Robustness of Deep Neural Networks",2020,"","","","",126,"2022-07-13 09:27:43","","","","",,,,,4,2.00,1,3,2,"Adversarial examples are inevitable on the road of pervasive applications of deep neural networks (DNN). Imperceptible perturbations applied on natural samples can lead DNN-based classifiers to output wrong prediction with fair confidence score. It is increasingly important to obtain models with high robustness that are resistant to adversarial examples. In this paper, we survey recent advances in how to understand such intriguing property, i.e. adversarial robustness, from different perspectives. We give preliminary definitions on what adversarial attacks and robustness are. After that, we study frequently-used benchmarks and mention theoretically-proved bounds for adversarial robustness. We then provide an overview on analyzing correlations among adversarial robustness and other critical indicators of DNN models. Lastly, we introduce recent arguments on potential costs of adversarial training which have attracted wide attention from the research community.","",""
2,"Michael Everett, Golnaz Habibi, J. How","Robustness Analysis of Neural Networks via Efficient Partitioning: Theory and Applications in Control Systems",2020,"","","","",127,"2022-07-13 09:27:43","","","","",,,,,2,1.00,1,3,2,"Neural networks (NNs) are now routinely implemented on systems that must operate in uncertain environments, but the tools for formally analyzing how this uncertainty propagates to NN outputs are not yet commonplace. Computing tight bounds on NN output sets (given an input set) provides a measure of confidence associated with the NN decisions and is essential to deploy NNs on safety-critical systems. Recent works approximate the propagation of sets through nonlinear activations or partition the uncertainty set to provide a guaranteed outer bound on the set of possible NN outputs. However, the bound looseness causes excessive conservatism and/or the computation is too slow for online analysis. This paper unifies propagation and partition approaches to provide a family of robustness analysis algorithms that give tighter bounds than existing works for the same amount of computation time (or reduced computational effort for a desired accuracy level). Moreover, we provide new partitioning techniques that are aware of their current bound estimates and desired boundary shape (e.g., lower bounds, weighted $\ell_\infty$-ball, convex hull), leading to further improvements in the computation-tightness tradeoff. The paper demonstrates the tighter bounds and reduced conservatism of the proposed robustness analysis framework with examples from model-free RL and forward kinematics learning.","",""
1,"J. Dickey, B. Borghetti, W. Junek","BazNet: A Deep Neural Network for Confident Three-component Backazimuth Prediction",2020,"","","","",128,"2022-07-13 09:27:43","","10.1007/s00024-020-02578-x","","",,,,,1,0.50,0,3,2,"","",""
0,"Shuyin Zhang, Xudong Jing, Hongming Zhang, Huan Chen, Jianbang Zhao","Recursive Convolution Neural Network for PolSAR Image Classification",2020,"","","","",129,"2022-07-13 09:27:43","","10.1109/YAC51587.2020.9337661","","",,,,,0,0.00,0,5,2,"Considering the limited of the training samples and the effect of speckle noise in PolSAR images, which further affects the learning performance of the classifier, a recursive convolution neural network model (CNN) is proposed. Samples with high confidence of each classification result will be used as the training samples of the next training. Then, a semi-supervised model is obtained for PolSAR image classification. This model is independent of the dependence of supervised classification on manual calibration samples. Furthermore, the model is an end-to-end classification framework based on discriminative feature learning which can learn the spatial texture features of polarized SAR images automatically while performing convolution operations in CNN. In addition, this model tries to learn features that are beneficial to classification from highly confident samples. There are three advantages of the proposed model: firstly, the problem of small samples is solved by increasing the training samples from each iterative classification result. Secondly, the low confidence samples are removed in each iteration to reduce the impact of noise samples on the robustness of the model. Finally, the initialization of CNN parameters in each iteration process is based on the results of the previous learning. As a result, the parameters will be set more and more robustly, so that the entire model will not have poor performance due to random initialization.","",""
3,"Dimah Dera, G. Rasool, N. Bouaynaya, Adam Eichen, Stephen Shanko, J. Cammerata, S. Arnold","Bayes-SAR Net: Robust SAR Image Classification with Uncertainty Estimation Using Bayesian Convolutional Neural Network",2020,"","","","",130,"2022-07-13 09:27:43","","10.1109/RADAR42522.2020.9114737","","",,,,,3,1.50,0,7,2,"Synthetic aperture radar (SAR) image classification is a challenging problem due to the complex imaging mechanism as well as the random speckle noise, which affects radar image interpretation. Recently, convolutional neural networks (CNNs) have been shown to outperform previous state-of-the-art techniques in computer vision tasks owing to their ability to learn relevant features from the data. However, CNNs in particular and neural networks, in general, lack uncertainty quantification and can be easily deceived by adversarial attacks. This paper proposes Bayes-SAR Net, a Bayesian CNN that can perform robust SAR image classification while quantifying the uncertainty or confidence of the network in its decision. Bayes-SAR Net propagates the first two moments (mean and covariance) of the approximate posterior distribution of the network parameters given the data and obtains a predictive mean and covariance of the classification output. Experiments, using the benchmark datasets Flevoland and Oberpfaffenhofen, show superior performance and robustness to Gaussian noise and adversarial attacks, as compared to the SAR-Net homologue. Bayes-SAR Net achieves a test accuracy that is around 10% higher in the case of adversarial perturbation (levels ≽ 0.05).","",""
2,"Abhishek Moitra, P. Panda","Exposing the Robustness and Vulnerability of Hybrid 8T-6T SRAM Memory Architectures to Adversarial Attacks in Deep Neural Networks",2020,"","","","",131,"2022-07-13 09:27:43","","","","",,,,,2,1.00,1,2,2,"Deep Learning is able to solve a plethora of once impossible problems. However, they are vulnerable to input adversarial attacks preventing them from being autonomously deployed in critical applications. Several algorithm-centered works have discussed methods to cause adversarial attacks and improve adversarial robustness of a Deep Neural Network (DNN). In this work, we elicit the advantages and vulnerabilities of hybrid 6T-8T memories to improve the adversarial robustness and cause adversarial attacks on DNNs. We show that bit-error noise in hybrid memories due to erroneous 6T-SRAM cells have deterministic behaviour based on the hybrid memory configurations (V_DD, 8T-6T ratio). This controlled noise (surgical noise) can be strategically introduced into specific DNN layers to improve the adversarial accuracy of DNNs. At the same time, surgical noise can be carefully injected into the DNN parameters stored in hybrid memory to cause adversarial attacks. To improve the adversarial robustness of DNNs using surgical noise, we propose a methodology to select appropriate DNN layers and their corresponding hybrid memory configurations to introduce the required surgical noise. Using this, we achieve 2-8% higher adversarial accuracy without re-training against white-box attacks like FGSM, than the baseline models (with no surgical noise introduced). To demonstrate adversarial attacks using surgical noise, we design a novel, white-box attack on DNN parameters stored in hybrid memory banks that causes the DNN inference accuracy to drop by more than 60% with over 90% confidence value. We support our claims with experiments, performed using benchmark datasets-CIFAR10 and CIFAR100 on VGG19 and ResNet18 networks.","",""
3,"Yuchen Liu, Mingxing Xu, Lianhong Cai","Improved keyword spotting system by optimizing posterior confidence measure vector using feed-forward neural network",2014,"","","","",132,"2022-07-13 09:27:43","","10.1109/IJCNN.2014.6889823","","",,,,,3,0.38,1,3,8,"In this paper, a novel method based on feedforward neural network is proposed to optimize the confidence measure for improving a mandarine keyword spotting system. Keyword spotting is to detect the occurrences of a pre-defined list of keywords in the input speech, and confidence measure is an critical part in the verification stage of keyword spotting. Posterior confidence has been widely used and was verified to be effective. In some previous works, the optimization of posterior confidence has been proposed, which linearly transforms the phone-level confidence into the word-level confidence. On this basis, we propose a neural network based method that make a non-linear transformation. In addition, a sparse activation and back-propagation strategy is proposed to make this method feasible and work fast. In the experiments, the proposed method is compared to other two previous methods. To evaluate performance, two most commonly used measures are considered: AUC and EER. The experimental result shows that the proposed method is effective and achieved the best performance among three methods.","",""
35,"L. Cardelli, M. Kwiatkowska, L. Laurenti, Nicola Paoletti, A. Patané, Matthew Wicker","Statistical Guarantees for the Robustness of Bayesian Neural Networks",2019,"","","","",133,"2022-07-13 09:27:43","","10.24963/ijcai.2019/789","","",,,,,35,11.67,6,6,3,"We introduce a probabilistic robustness measure for Bayesian Neural Networks (BNNs), defined as the probability that, given a test point, there exists a point within a bounded set such that the BNN prediction differs between the two. Such a measure can be used, for instance, to quantify the probability of the existence of adversarial examples. Building on statistical verification techniques for probabilistic models, we develop a framework that allows us to estimate probabilistic robustness for a BNN with statistical guarantees, i.e., with a priori error and confidence bounds. We provide experimental comparison for several approximate BNN inference techniques on image classification tasks associated to MNIST and a two-class subset of the GTSRB dataset. Our results enable quantification of uncertainty of BNN predictions in adversarial settings.","",""
8,"Naresh Balaji Ravichandran, A. Lansner, P. Herman","Learning representations in Bayesian Confidence Propagation neural networks",2020,"","","","",134,"2022-07-13 09:27:43","","10.1109/IJCNN48605.2020.9207061","","",,,,,8,4.00,3,3,2,"Unsupervised learning of hierarchical representations has been one of the most vibrant research directions in deep learning during recent years. In this work we study biologically inspired unsupervised strategies in neural networks based on local Hebbian learning. We propose new mechanisms to extend the Bayesian Confidence Propagating Neural Network (BCPNN) architecture, and demonstrate their capability for unsupervised learning of salient hidden representations when tested on the MNIST dataset.","",""
47,"Tsui-Wei Weng, Pin-Yu Chen, Lam M. Nguyen, M. Squillante, I. Oseledets, L. Daniel","PROVEN: Certifying Robustness of Neural Networks with a Probabilistic Approach",2018,"","","","",135,"2022-07-13 09:27:43","","","","",,,,,47,11.75,8,6,4,"With deep neural networks providing state-of-the-art machine learning models for numerous machine learning tasks, quantifying the robustness of these models has become an important area of research. However, most of the research literature merely focuses on the \textit{worst-case} setting where the input of the neural network is perturbed with noises that are constrained within an $\ell_p$ ball; and several algorithms have been proposed to compute certified lower bounds of minimum adversarial distortion based on such worst-case analysis. In this paper, we address these limitations and extend the approach to a \textit{probabilistic} setting where the additive noises can follow a given distributional characterization. We propose a novel probabilistic framework PROVEN to PRObabilistically VErify Neural networks with statistical guarantees -- i.e., PROVEN certifies the probability that the classifier's top-1 prediction cannot be altered under any constrained $\ell_p$ norm perturbation to a given input. Importantly, we show that it is possible to derive closed-form probabilistic certificates based on current state-of-the-art neural network robustness verification frameworks. Hence, the probabilistic certificates provided by PROVEN come naturally and with almost no overhead when obtaining the worst-case certified lower bounds from existing methods such as Fast-Lin, CROWN and CNN-Cert. Experiments on small and large MNIST and CIFAR neural network models demonstrate our probabilistic approach can achieve up to around $75\%$ improvement in the robustness certification with at least a $99.99\%$ confidence compared with the worst-case robustness certificate delivered by CROWN.","",""
0,"Giulio Pagnotta, Dorjan Hitaj, B. Hitaj, F. Pérez-Cruz, L. Mancini","TATTOOED: A Robust Deep Neural Network Watermarking Scheme based on Spread-Spectrum Channel Coding",2022,"","","","",136,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,5,1,"The proliferation of deep learning applications in several areas has led to the rapid adoption of such solutions from an ever-growing number of institutions and companies. These entities’ deep neural network (DNN) models are often trained on proprietary data. They require powerful computational resources, with the resulting DNN models being incorporated in the company’s work pipeline or provided as a service. Being trained on proprietary information, these models provide a competitive edge for the owner company. At the same time, these models can be attractive to competitors (or malicious entities), which can employ state-of-the-art security attacks to obtain and use these models for their benefit. As these attacks are hard to prevent, it becomes imperative to have mechanisms that enable an affected entity to verify the ownership of its DNN with high confidence. This paper presents TATTOOED, a robust and efficient DNN watermarking technique based on spread-spectrum channel coding. TATTOOED has a negligible effect on the performance of the DNN model and is robust against several state-of-the-art mechanisms used to remove watermarks from DNNs. Our results show that TATTOOED is robust to such removal techniques even in extreme scenarios. For example, if the removal techniques such as fine-tuning and parameter pruning change as much as 99% of the model parameters, the TATTOOED watermark is still present in full in the DNN model and ensures ownership verification.","",""
0,"Rong Zhu, W. Peng, Yu Han, Cheng-Geng Huang","Intelligent Health Monitoring of Machine Tools Using a Bayesian Multibranch Neural Network",2022,"","","","",137,"2022-07-13 09:27:43","","10.1109/jsen.2022.3175722","","",,,,,0,0.00,0,4,1,"Online health monitoring of machine tools is an essential technique for tool life extension, manufacturing productivity improvement and product quality improvement. In the era of industrial big data, numerous deep learning (DL)-based methods have been proposed to achieve these goals. However, in complex and dynamic manufacturing processes, practical concerns such as uncertainty quantification and anti-noise capabilities of the DL-based methods are rarely considered. Thus, in this study, a novel multi-branch Bayesian Neural Network (BNN) is developed for the reliable and robust online health monitoring of Computer Numerical Control (CNC) machine tools. With the proposed model, the heterogeneous fault information extracted from multiple sensors can be simultaneously integrated in a deep convolutional neural network (DCNN)-multiple layer perceptron (MLP)-based multi-branch neural network to enhance the health monitoring accuracy and robustness. Furthermore, the proposed multi-branch neural network is extended into a BNN to improve its uncertainty quantification capabilities. The proposed method is evaluated on the tool wear tests of three cutting tools. Tool wear estimation results indicate that the proposed method outperforms comparative methods and achieves the best prediction accuracy and robustness on all three health monitoring tasks investigated in this study. We also found that the proposed method can accurately classify tool wear stages and reach up to 95% mean classification accuracy, which is the best among comparative methods. Also, measures, such as coverage probability of estimation interval (EICP) and normalized mean estimation interval width (NMEIW), are used to assess the capability of quantifying the confidence intervals (CIs) of the tool wear estimations. Results show that the proposed method achieves superior CIs quantification performance with the average EICP and NMEIW values of 95.77% and 0.27 on all three health monitoring tasks.","",""
8,"Can Li, Lei Bai, Wei Liu, Lina Yao, S. Waller","Graph Neural Network for Robust Public Transit Demand Prediction",2020,"","","","",138,"2022-07-13 09:27:43","","10.1109/tits.2020.3041234","","",,,,,8,4.00,2,5,2,"Understanding and forecasting mobility patterns and travel demand are fundamental and critical to efficient transport infrastructure planning and service operation. However, most existing studies focused on deterministic demand estimation/prediction/analytics. Differently, this study provides confidence interval based demand forecasting, which can help transport planning and operation authorities to better accommodate demand uncertainty/variability. The proposed Origin-Destination (OD) demand prediction approach well captures and utilizes the correlations among spatial and temporal information. In particular, the proposed Probabilistic Graph Convolution Model (PGCM) consists of two components: (i) a prediction module based on Graph Convolution Network and combined with the gated mechanism to predict OD demand by utilizing spatio-temporal relations; (ii) a Bayesian-based approximation module to measure the confidence interval of demand prediction by evaluating the graph-based model uncertainty. We use a large-scale real-world public transit dataset from the Greater Sydney area to test and evaluate the proposed approach. The experimental results demonstrate that the proposed method is capable of capturing the spatial-temporal correlations for more robust demand prediction against several established tools in the literature.","",""
3,"Giulio Rossolini, Alessandro Biondi, G. Buttazzo","Increasing the Confidence of Deep Neural Networks by Coverage Analysis",2021,"","","","",139,"2022-07-13 09:27:43","","10.1109/tse.2022.3163682","","",,,,,3,3.00,1,3,1,"The great performance of machine learning algorithms and deep neural networks in several perception and control tasks is pushing the industry to adopt such technologies in safety-critical applications, as autonomous robots and self-driving vehicles. At present, however, several issues need to be solved to make deep learning methods more trustworthy, predictable, safe, and secure against adversarial attacks. Although several methods have been proposed to improve the trustworthiness of deep neural networks, most of them are tailored for specific classes of adversarial examples, hence failing to detect other corner cases or unsafe inputs that heavily deviate from the training samples. This paper presents a lightweight monitoring architecture based on coverage paradigms to enhance the model robustness against different unsafe inputs. In particular, four coverage analysis methods are proposed and tested in the architecture for evaluating multiple detection logic. Experimental results show that the proposed approach is effective in detecting both powerful adversarial examples and out-of-distribution inputs, introducing limited extra-execution time and memory requirements.","",""
8,"M. Ibrahim, S. A. Al‐Sobhi, R. Mukherjee, A. AlNouss","Impact of Sampling Technique on the Performance of Surrogate Models Generated with Artificial Neural Network (ANN): A Case Study for a Natural Gas Stabilization Unit",2019,"","","","",140,"2022-07-13 09:27:43","","10.3390/EN12101906","","",,,,,8,2.67,2,4,3,"Data-driven models are essential tools for the development of surrogate models that can be used for the design, operation, and optimization of industrial processes. One approach of developing surrogate models is through the use of input–output data obtained from a process simulator. To enhance the model robustness, proper sampling techniques are required to cover the entire domain of the process variables uniformly. In the present work, Monte Carlo with pseudo-random samples as well as Latin hypercube samples and quasi-Monte Carlo samples with Hammersley Sequence Sampling (HSS) are generated. The sampled data obtained from the process simulator are fitted to neural networks for generating a surrogate model. An illustrative case study is solved to predict the gas stabilization unit performance. From the developed surrogate models to predict process data, it can be concluded that of the different sampling methods, Latin hypercube sampling and HSS have better performance than the pseudo-random sampling method for designing the surrogate model. This argument is based on the maximum absolute value, standard deviation, and the confidence interval for the relative average error as obtained from different sampling techniques.","",""
5,"Wei Wang, Siyuan Hao, Yunchao Wei, Shengtao Xiao, Jiashi Feng, N. Sebe","Temporal Spiking Recurrent Neural Network for Action Recognition",2019,"","","","",141,"2022-07-13 09:27:43","","10.1109/ACCESS.2019.2936604","","",,,,,5,1.67,1,6,3,"In this paper, we propose a novel temporal spiking recurrent neural network (TSRNN) to perform robust action recognition in videos. The proposed TSRNN employs a novel spiking architecture which utilizes the local discriminative features from high-confidence reliable frames as spiking signals. The conventional CNN-RNNs typically used for this problem treat all the frames equally important such that they are error-prone to noisy frames. The TSRNN solves this problem by employing a temporal pooling architecture which can help RNN select sparse and reliable frames and enhances its capability in modelling long-range temporal information. Besides, a message passing bridge is added between the spiking signals and the recurrent unit. In this way, the spiking signals can guide RNN to correct its long-term memory across multiple frames from contamination caused by noisy frames with distracting factors (e.g., occlusion, rapid scene transition). With these two novel components, TSRNN achieves competitive performance compared with the state-of-the-art CNN-RNN architectures on two large scale public benchmarks, UCF101 and HMDB51.","",""
1,"Geoffroy Dubourg-Felonneau, Omar A. Darwish, C. Parsons, D. Rebergen, J. Cassidy, Nirmesh Patel, Harry W. Clifford","Safety and Robustness in Decision Making: Deep Bayesian Recurrent Neural Networks for Somatic Variant Calling in Cancer",2019,"","","","",142,"2022-07-13 09:27:43","","","","",,,,,1,0.33,0,7,3,"The emerging field of precision oncology relies on the accurate pinpointing of alterations in the molecular profile of a tumor to provide personalized targeted treatments. Current methodologies in the field commonly include the application of next generation sequencing technologies to a tumor sample, followed by the identification of mutations in the DNA known as somatic variants. The differentiation of these variants from sequencing error poses a classic classification problem, which has traditionally been approached with Bayesian statistics, and more recently with supervised machine learning methods such as neural networks. Although these methods provide greater accuracy, classic neural networks lack the ability to indicate the confidence of a variant call. In this paper, we explore the performance of deep Bayesian neural networks on next generation sequencing data, and their ability to give probability estimates for somatic variant calls. In addition to demonstrating similar performance in comparison to standard neural networks, we show that the resultant output probabilities make these better suited to the disparate and highly-variable sequencing data-sets these models are likely to encounter in the real world. We aim to deliver algorithms to oncologists for which model certainty better reflects accuracy, for improved clinical application. By moving away from point estimates to reliable confidence intervals, we expect the resultant clinical and treatment decisions to be more robust and more informed by the underlying reality of the tumor molecular profile.","",""
144,"Tong Yang, Ning Sun, He Chen, Yongchun Fang","Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones",2020,"","","","",143,"2022-07-13 09:27:43","","10.1109/TNNLS.2019.2910580","","",,,,,144,72.00,36,4,2,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.","",""
1,"S. Samarasinghe","Order in the Black Box: Consistency and Robustness of Hidden Neuron Activation of Feed Forward Neural Networks and Its Use in Efficient Optimization of Network Structure",2016,"","","","",144,"2022-07-13 09:27:43","","10.1007/978-3-319-28495-8_2","","",,,,,1,0.17,1,1,6,"","",""
7,"M. Cranmer, D. Tamayo, H. Rein, P. Battaglia, S. Hadden, P. Armitage, S. Ho, D. Spergel","A Bayesian neural network predicts the dissolution of compact planetary systems",2021,"","","","",145,"2022-07-13 09:27:43","","10.1073/pnas.2026053118","","",,,,,7,7.00,1,8,1,"Significance Despite over 300 y of effort, no solutions exist for predicting when a general planetary configuration will become unstable. We introduce a deep learning architecture to push forward this problem for compact systems. While current machine learning algorithms in this area rely on scientist-derived instability metrics, our new technique learns its own metrics from scratch, enabled by a internal structure inspired from dynamics theory. Our model can quickly and accurately predict instability timescales in compact multiplanet systems, and does so with an accurate uncertainty estimate for unfamiliar systems. This opens up the development of fast terrestrial planet formation models, and enables the efficient exploration of stable regions in parameter space for multiplanet systems. We introduce a Bayesian neural network model that can accurately predict not only if, but also when a compact planetary system with three or more planets will go unstable. Our model, trained directly from short N-body time series of raw orbital elements, is more than two orders of magnitude more accurate at predicting instability times than analytical estimators, while also reducing the bias of existing machine learning algorithms by nearly a factor of three. Despite being trained on compact resonant and near-resonant three-planet configurations, the model demonstrates robust generalization to both nonresonant and higher multiplicity configurations, in the latter case outperforming models fit to that specific set of integrations. The model computes instability estimates up to 105 times faster than a numerical integrator, and unlike previous efforts provides confidence intervals on its predictions. Our inference model is publicly available in the SPOCK (https://github.com/dtamayo/spock) package, with training code open sourced (https://github.com/MilesCranmer/bnn_chaos_model).","",""
0,"P. L. Vidal, J. D. Moura, J. Novo, M. Ortega","Intraretinal Fluid Detection by Means of a Densely Connected Convolutional Neural Network Using Optical Coherence Tomography Images",2019,"","","","",146,"2022-07-13 09:27:43","","10.3390/PROCEEDINGS2019021034","","",,,,,0,0.00,0,4,3,"Hereby we present a methodology with the objective of detecting retinal fluid accumulations in between the retinal layers. The methodology uses a robust Densely Connected Neural Network to classify thousands of subsamples, extracted from a given Optical Coherence Tomography image. Posteriorly, using the detected regions, it satisfactorily generates a coherent and intuitive confidence map by means of a voting strategy.","",""
2,"N. Benjamin Erichson, D. Taylor, Qixuan Wu, M. Mahoney","Noise-Response Analysis of Deep Neural Networks Quantifies Robustness and Fingerprints Structural Malware",2021,"","","","",147,"2022-07-13 09:27:43","","10.1137/1.9781611976700.12","","",,,,,2,2.00,1,4,1,"The ubiquity of deep neural networks (DNNs), cloud-based training, and transfer learning is giving rise to a new cybersecurity frontier in which unsecure DNNs have ‘structural malware’ (i.e., compromised weights and activation pathways). In particular, DNNs can be designed to have backdoors that allow an adversary to easily and reliably fool an image classifier by adding a pattern of pixels called a trigger. It is generally difficult to detect backdoors, and existing detection methods are computationally expensive and require extensive resources (e.g., access to the training data). Here, we propose a rapid feature-generation technique that quantifies the robustness of a DNN, ‘fingerprints’ its nonlinearity, and allows us to detect backdoors (if present). Our approach involves studying how a DNN responds to noise-infused images with varying noise intensity, which we summarize with titration curves. We find that DNNs with backdoors are more sensitive to input noise and respond in a characteristic way that reveals the backdoor and where it leads (its ‘target’). Our empirical results demonstrate that we can accurately detect backdoors with high confidence orders-of-magnitude faster than existing approaches (seconds versus hours).","",""
36,"T. Roshni, M. Jha, J. Drisya","Neural network modeling for groundwater-level forecasting in coastal aquifers",2020,"","","","",148,"2022-07-13 09:27:43","","10.1007/s00521-020-04722-z","","",,,,,36,18.00,12,3,2,"","",""
2,"Q. Kim, Joon-Hyuk Ko, Sunghoon Kim, Nojun Park, W. Jhe","Bayesian neural network with pretrained protein embedding enhances prediction accuracy of drug-protein interaction",2020,"","","","",149,"2022-07-13 09:27:43","","10.1093/bioinformatics/btab346","","",,,,,2,1.00,0,5,2,"Abstract Motivation Characterizing drug–protein interactions (DPIs) is crucial to the high-throughput screening for drug discovery. The deep learning-based approaches have attracted attention because they can predict DPIs without human trial and error. However, because data labeling requires significant resources, the available protein data size is relatively small, which consequently decreases model performance. Here, we propose two methods to construct a deep learning framework that exhibits superior performance with a small labeled dataset. Results At first, we use transfer learning in encoding protein sequences with a pretrained model, which trains general sequence representations in an unsupervised manner. Second, we use a Bayesian neural network to make a robust model by estimating the data uncertainty. Our resulting model performs better than the previous baselines at predicting interactions between molecules and proteins. We also show that the quantified uncertainty from the Bayesian inference is related to confidence and can be used for screening DPI data points. Availability and implementation The code is available at https://github.com/QHwan/PretrainDPI. Supplementary information Supplementary data are available at Bioinformatics online.","",""
0,"H. Simiyu, A. Waititu, J. Akinyi","A Hybrid Artificial Neural Network Model for Option Pricing",2019,"","","","",150,"2022-07-13 09:27:43","","10.3844/JMSSP.2019.185.195","","",,,,,0,0.00,0,3,3,"In the absence of a well-defined input selection technique associated with the pure ANN models, Option pricing using pure ANN models while relaxing the assumption of constant volatility remains a challenge. The conservative drill espoused has been to make allowances for a large number of input lags with the confidence that the ability of ANN to integrate suppleness and redundancy generates a more robust model. This is to say that the nonexistence of input selection criteria notwithstanding, the models have been developed without due consideration to the effect that the choice of input selection technique would have on model complexity, learning difficulty and performance measures. In this study, we deviate from the conventional techniques applied by the pure ANN option price models and adopt the hybrid model in which the volatility component is handled using some celebrated time series models, with speci?city to the ANN-GJR-GARCH model - a hybrid of the ANN and a time series hybrid. The hybrid ANN option pricing model is then framed and tested with the forecasts of the ANN-GJR-GARCH model as a volatility input alongside two other inputs - time to maturity and moneyness. Finally, we compare the performance of the hybrid model developed with that of a pure ANN model. Results indicate that the hybrid model outperforms the pure ANN model not only in forecasting but also in the training time and model complexity.","",""
324,"Terrance Devries, Graham W. Taylor","Learning Confidence for Out-of-Distribution Detection in Neural Networks",2018,"","","","",151,"2022-07-13 09:27:43","","","","",,,,,324,81.00,162,2,4,"Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.","",""
54,"Z. Eaton-Rosen, Felix J. S. Bragman, S. Bisdas, S. Ourselin, M. Jorge Cardoso","Towards safe deep learning: accurately quantifying biomarker uncertainty in neural network predictions",2018,"","","","",152,"2022-07-13 09:27:43","","10.1007/978-3-030-00928-1_78","","",,,,,54,13.50,11,5,4,"","",""
225,"Xianzhi Du, Mostafa El-Khamy, Jungwon Lee, L. Davis","Fused DNN: A Deep Neural Network Fusion Approach to Fast and Robust Pedestrian Detection",2016,"","","","",153,"2022-07-13 09:27:43","","10.1109/WACV.2017.111","","",,,,,225,37.50,56,4,6,"We propose a deep neural network fusion architecture for fast and robust pedestrian detection. The proposed network fusion architecture allows for parallel processing of multiple networks for speed. A single shot deep convolutional network is trained as a object detector to generate all possible pedestrian candidates of different sizes and occlusions. This network outputs a large variety of pedestrian candidates to cover the majority of ground-truth pedestrians while also introducing a large number of false positives. Next, multiple deep neural networks are used in parallel for further refinement of these pedestrian candidates. We introduce a soft-rejection based network fusion method to fuse the soft metrics from all networks together to generate the final confidence scores. Our method performs better than existing state-of-the-arts, especially when detecting small-size and occluded pedestrians. Furthermore, we propose a method for integrating pixel-wise semantic segmentation network into the network fusion architecture as a reinforcement to the pedestrian detector. The approach outperforms state-of-the-art methods on most protocols on Caltech Pedestrian dataset, with significant boosts on several protocols. It is also faster than all other methods.","",""
19,"T. Yin, Hong-ping Zhu","An efficient algorithm for architecture design of Bayesian neural network in structural model updating",2019,"","","","",154,"2022-07-13 09:27:43","","10.1111/mice.12492","","",,,,,19,6.33,10,2,3,"There has been growing interest in applying the artificial neural network (ANN) approach in structural system identification and health monitoring. The learning process of neural network can be more robust when presented in the Bayesian framework, and rational architecture of the Bayesian neural network is critical to its performance. Apart from number of hidden neurons, the specific forms of the transfer functions in both hidden and output layers are also crucially important. To the best of our knowledge, however, the simultaneous design of proper number of hidden neurons, and specific forms of hidden‐ and output‐layer transfer functions has not yet been reported in terms of the Bayesian neural network. It is even more challenging when the transfer functions of both layers are parameterized instead of using fixed shape forms. This paper proposes a tailor‐made algorithm for efficiently designing the appropriate architecture of Bayesian neural network with simultaneously optimized hidden neuron number and custom transfer functions in both hidden and output layers. To cooperate with the proposed algorithm, both the Jacobian of the network function and Hessian of the negative logarithm of weight posterior are derived analytically by matrix calculus. This is much more accurate and efficient than the finite difference approximation, and also vital for properly designing the Bayesian neural network architecture as well as further quantifying the confidence interval of network prediction. The validity and efficiency of the proposed methodology is verified through probabilistic finite element (FE) model updating of a pedestrian bridge by using the field measurement data.","",""
5,"T. Tanimura, T. Hoshida, Tomoyuki Kato, S. Watanabe","OSNR Estimation Providing Self-Confidence Level as Auxiliary Output From Neural Networks",2019,"","","","",155,"2022-07-13 09:27:43","","10.1109/JLT.2019.2895730","","",,,,,5,1.67,1,4,3,"Accurate optical monitors are critical for automating operations of fiber-optic networks. Deep neural network (DNN) based optical monitors have been investigated as accurate optical monitors to leverage a large amount of data obtained from fiber-optic networks. Although DNN-based optical monitors have been trained and tested to ensure the given accuracy criteria, this does not ensure sufficient accuracy under unexpected conditions, that is, out of test conditions, e.g., a newly developed modulation format that is not included in the test dataset. Thus, it is necessary to prepare a monitor to assess the current accuracy of a DNN-based optical monitor's output for robust automation of networks. We present a DNN-based optical monitor that simultaneously outputs an optical signal-to-noise ratio and its uncertainty information using a dropout method at the inference phase. This monitor was evaluated in cases in which the DNNs were trained with either a limited number of records or partially missing records in a training dataset. The proposed monitor successfully informed that own output has large uncertainties due to a limited amount of training data or a missing part in training dataset. Additionally, to improve an accuracy of estimated uncertainty, the number of partial neural networks by dropout at the inference phase was optimized. This is a valuable step toward designing robust “self-driving” optical networks.","",""
11,"B. Mathison, J. Kohan, John F Walker, Richard Boyd Smith, O. Ardon, M. Couturier","Detection of Intestinal Protozoa in Trichrome-Stained Stool Specimens by Use of a Deep Convolutional Neural Network",2020,"","","","",156,"2022-07-13 09:27:43","","10.1128/JCM.02053-19","","",,,,,11,5.50,2,6,2,"Intestinal protozoa are responsible for relatively few infections in the developed world, but the testing volume is disproportionately high. Manual light microscopy of stool remains the gold standard but can be insensitive, time-consuming, and difficult to maintain competency. Artificial intelligence and digital slide scanning show promise for revolutionizing the clinical parasitology laboratory by augmenting the detection of parasites and slide interpretation using a convolutional neural network (CNN) model. ABSTRACT Intestinal protozoa are responsible for relatively few infections in the developed world, but the testing volume is disproportionately high. Manual light microscopy of stool remains the gold standard but can be insensitive, time-consuming, and difficult to maintain competency. Artificial intelligence and digital slide scanning show promise for revolutionizing the clinical parasitology laboratory by augmenting the detection of parasites and slide interpretation using a convolutional neural network (CNN) model. The goal of this study was to develop a sensitive model that could screen out negative trichrome slides, while flagging potential parasites for manual confirmation. Conventional protozoa were trained as “classes” in a deep CNN. Between 1,394 and 23,566 exemplars per class were used for training, based on specimen availability, from a minimum of 10 unique slides per class. Scanning was performed using a 40× dry lens objective automated slide scanner. Data labeling was performed using a proprietary Web interface. Clinical validation of the model was performed using 10 unique positive slides per class and 125 negative slides. Accuracy was calculated as slide-level agreement (e.g., parasite present or absent) with microscopy. Positive agreement was 98.88% (95% confidence interval [CI], 93.76% to 99.98%), and negative agreement was 98.11% (95% CI, 93.35% to 99.77%). The model showed excellent reproducibility using slides containing multiple classes, a single class, or no parasites. The limit of detection of the model and scanner using serially diluted stool was 5-fold more sensitive than manual examinations by multiple parasitologists using 4 unique slide sets. Digital slide scanning and a CNN model are robust tools for augmenting the conventional detection of intestinal protozoa.","",""
6,"Chao Huang, Jing Zhang, L. Cao, Long Wang, Xiong Luo, Jenq-Haur Wang, A. Bensoussan","Robust Forecasting of River-Flow Based on Convolutional Neural Network",2020,"","","","",157,"2022-07-13 09:27:43","","10.1109/TSUSC.2020.2983097","","",,,,,6,3.00,1,7,2,"In this paper, a novel method is developed for day-ahead daily river-flow forecasting based on convolutional neural network (CNN). The proposed method incorporates both spatial and temporal information to improve the forecasting performance. A CNN model is usually trained by minimizing the mean squared error which is, however, sensitive to few particularly large errors. This character of squared error loss function will result in a poor estimator. To tackle the problem, a robust loss function is proposed to train the CNN. To facilitate the training of CNNs for multiple sites forecasting, transfer learning is also applied in this study. With transfer learning, a new CNN inherits the structure and partial learnable parameters from a well-trained CNN to reduce the training complexity. The forecasting performance of the proposed method is validated with real data of four rivers by comparing with widely used benchmarking models including the autoregressive model, multilayer perception network, kernel ridge regression, radial basis function neural network, and generic CNN. Numerical results show that the proposed method performs best in terms of the root mean squared error, mean absolute error, and mean absolute percentage error. The two-sample Kolmogorov-Smirnov test is further applied to assess the confidence on the conclusion.","",""
2,"P. Nikulin, F. Hofheinz, J. Maus, Yi-min Li, R. Bütof, C. Lange, C. Furth, S. Zschaeck, M. Kreissl, J. Kotzerke, J. van den Hoff","A convolutional neural network for fully automated blood SUV determination to facilitate SUR computation in oncological FDG-PET",2020,"","","","",158,"2022-07-13 09:27:43","","10.1007/s00259-020-04991-9","","",,,,,2,1.00,0,11,2,"","",""
5,"Ece Ayli","Modeling of mixed convection in an enclosure using multiple regression, artificial neural network, and adaptive neuro-fuzzy interface system models",2020,"","","","",159,"2022-07-13 09:27:43","","10.1177/0954406220914330","","",,,,,5,2.50,5,1,2,"In this study, the heat transfer characteristics of laminar combined forced convection through a horizontal duct are obtained with the help of the numerical methods. The effect of the geometrical parameters of the cavity and Reynolds number on the heat transfer is investigated. New heat transfer correlation for hydrodynamically fully developed, laminar combined forced convection through a horizontal duct is proposed with an average error of 6.98% and R2 of 0.8625. The obtained correlation results are compared with the artificial neural network and adaptive neuro-fuzzy interface system models. Due to the obtained results, good agreement is identified between the numerical results and predicted adaptive neuro-fuzzy interface system results. In conclusion, it is seen that adaptive neuro-fuzzy interface system can predict the Nusselt number distribution with a higher accuracy than the developed correlation and the artificial neural network model. The developed adaptive neuro-fuzzy interface system model predicts the Nusselt number with 1.07% mean average percentage error and 0.9983 R2 value. The effect of the different training algorithms and their ability to predict Nusselt number distribution are examined. According to the results, the Bayesian regulation algorithm gives the best approach with a 2.235% error. According to the examination that is performed in this study, the adaptive neuro-fuzzy interface system is a powerful, robust tool that can be used with confidence for predicting the thermal performance.","",""
5,"Jie Li, Runran Li, Yu-hua Jia, Zhixin Zhang","Prediction of I–V Characteristic Curve for Photovoltaic Modules Based on Convolutional Neural Network",2020,"","","","",160,"2022-07-13 09:27:43","","10.3390/s20072119","","",,,,,5,2.50,1,4,2,"Photovoltaic (PV) modules are exposed to the outside, which is affected by radiation, the temperature of the PV module back-surface, relative humidity, atmospheric pressure and other factors, which makes it difficult to test and analyze the performance of photovoltaic modules. Traditionally, the equivalent circuit method is used to analyze the performance of PV modules, but there are large errors. In this paper—based on machine learning methods and large amounts of photovoltaic test data—convolutional neural network (CNN) and multilayer perceptron (MLP) neural network models are established to predict the I–V curve of photovoltaic modules. Furthermore, the accuracy and the fitting degree of these methods for current–voltage (I–V) curve prediction are compared in detail. The results show that the prediction accuracy of the CNN and MLP neural network model is significantly better than that of the traditional equivalent circuit models. Compared with MLP models, the CNN model has better accuracy and fitting degree. In addition, the error distribution concentration of CNN has better robustness and the pre-test curve is smoother and has better nonlinear segment fitting effects. Thus, the CNN is superior to MLP model and the traditional equivalent circuit model in complex climate conditions. CNN is a high-confidence method to predict the performance of PV modules.","",""
10,"Mahdieh Abbasi, Arezoo Rajabi, Christian Gagné, R. Bobba","Toward Adversarial Robustness by Diversity in an Ensemble of Specialized Deep Neural Networks",2020,"","","","",161,"2022-07-13 09:27:43","","10.1007/978-3-030-47358-7_1","","",,,,,10,5.00,3,4,2,"","",""
2,"Joshua B. Cohen, M. Simi, F. Campagne","GenotypeTensors: Efficient Neural Network Genotype Callers",2018,"","","","",162,"2022-07-13 09:27:43","","10.1101/338780","","",,,,,2,0.50,1,3,4,"We studied the problem of calling genotypes using neural networks. A machine learning approach to calling genotypes requires a training set, an approach to convert genomic sites into tensors and robust model development and evaluation protocols. We discuss each of these components of our approach and compare four types of neural network training protocols, two fully supervised and two semi-supervised approaches. Semi-supervised approaches use unlabeled data to supplement limited quantities of labeled data. Random hyper-parameter searches identified highly performing models that reach indel F1 of 99.4% on a chromosomes 20, 21, 22 and X of NA12878/HG001. We further validate these models by evaluating performance on HG002, an independent sample used in the PrecisionFDA challenge. We apply GenotypeTensors to evaluate the impact of (1) training with small datasets, (2) training models only with sites inside confidence regions, or (3) training with improved true label annotations. A PyTorch open-source implementation of GenotypeTensors is available at https://github.com/CampagneLaboratory/GenotypeTensors. DNANexus cloud applications are provided to help process new datasets both to train model or call genotypes with trained models.","",""
3,"Hammad Tariq, Hassan Ali, Muhammad Abdullah Hanif, Faiq Khalid, Semeen Rehman, Rehan Ahmed, M. Shafique","SSCNets: A Selective Sobel Convolution-based Technique to Enhance the Robustness of Deep Neural Networks against Security Attacks",2018,"","","","",163,"2022-07-13 09:27:43","","","","",,,,,3,0.75,0,7,4,"Recent studies have shown that slight perturbations in the input data can significantly affect the robustness of Deep Neural Networks (DNNs), leading to misclassification and confidence reduction. In this paper, we introduce a novel technique based on the Selective Sobel Convolution (SSC) operation in the training loop, that increases the robustness of a given DNN by allowing it to learn important edges in the input in a controlled fashion. This is achieved by introducing a trainable parameter, which acts as a threshold for eliminating the weaker edges. We validate our technique against the attacks of Cleverhans library on Convolutional DNNs against adversarial attacks. Our experimental results on the MNIST and CIFAR10 datasets illustrate that this controlled learning considerably increases the accuracy of the DNNs by 1.53% even when subjected to adversarial attacks.","",""
3,"Jiawei Su, Danilo Vasconcellos Vargas, K. Sakurai","Empirical Evaluation on Robustness of Deep Convolutional Neural Networks Activation Functions Against Adversarial Perturbation",2018,"","","","",164,"2022-07-13 09:27:43","","10.1109/CANDARW.2018.00049","","",,,,,3,0.75,1,3,4,"Recent research has shown that deep convolutional neural networks (DCNN) are vulnerable to several different types of attacks while the reasons of such vulnerability are still under investigation. For instance, the adversarial perturbations can conduct a slight change on a natural image to make the target DCNN make the wrong recognition, while the reasons that DCNN is sensitive to such small modification are divergent from one research to another. In this paper, we evaluate the robustness of two commonly used activation functions of DCNN, namely the sigmoid and ReLu, against the recently proposed low-dimensional one-pixel attack. We show that the choosing of activation functions can be an important factor that influences the robustness of DCNN. The results show that comparing with sigmoid, the ReLu non-linearity is more vulnerable which allows the low dimensional one-pixel attack exploit much higher success rate and confidence of launching the attack. The results give insights on designing new activation functions to enhance the security of DCNN.","",""
1,"P. Kishor, P. Sammulal","Association Rule Mining Using an Unsupervised Neural Network with an Optimized Genetic Algorithm",2018,"","","","",165,"2022-07-13 09:27:43","","10.1007/978-981-13-0212-1_67","","",,,,,1,0.25,1,2,4,"","",""
34,"Maxime Cauchois, Suyash Gupta, John C. Duchi","Knowing what You Know: valid and validated confidence sets in multiclass and multilabel prediction",2020,"","","","",166,"2022-07-13 09:27:43","","","","",,,,,34,17.00,11,3,2,"We develop conformal prediction methods for constructing valid predictive confidence sets in multiclass and multilabel problems without assumptions on the data generating distribution. A challenge here is that typical conformal prediction methods---which give marginal validity (coverage) guarantees---provide uneven coverage, in that they address easy examples at the expense of essentially ignoring difficult examples. By leveraging ideas from quantile regression, we build methods that always guarantee correct coverage but additionally provide (asymptotically optimal) conditional coverage for both multiclass and multilabel prediction problems. To address the potential challenge of exponentially large confidence sets in multilabel prediction, we build tree-structured classifiers that efficiently account for interactions between labels. Our methods can be bolted on top of any classification model---neural network, random forest, boosted tree---to guarantee its validity. We also provide an empirical evaluation, simultaneously providing new validation methods, that suggests the more robust coverage of our confidence sets.","",""
0,"H. Palanisamy","Risk Assessment based Data Augmentation for Robust Image Classification using Convolutional Neural Network",2018,"","","","",167,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,1,4,"Autonomous driving is increasingly popular among people and automotive industries in realizing their presence both in passenger and goods transportation. Safer autonomous navigation might be very challenging if there is a failure in sensing system. Among several sensing systems, image classification plays a major role in understanding the road signs and to regulate the vehicle control based on urban road rules. Hence, a robust classifier algorithm irrespective of camera position, view angles, environmental condition, different vehicle size & type (Car, Bus, Truck, etc.,) of an autonomous platform is of prime importance. In this study, Convolutional Neural Network (CNN) based classifier algorithm has been implemented to ensure improved robustness for recognizing traffic signs. As training data play a crucial role in supervised learning algorithms, there come an effective dataset requirement which can handle dynamic environmental conditions and other variations caused due to the vehicle motion (will be referred as challenges). Since the collected training data might not contain all the dynamic variations, the model weakness can be identified by exposing it to variations (Blur, Darkness, Shadow, etc.,) faced by the vehicles in real-time as a initial testing sequence. To overcome the weakness caused due to the training data itself, an effective augmentation technique enriching the training data in order to increase the model capacity for withstanding the variations prevalent in urban environment has been proposed. As a major contribution, a framework has been developed to identify model weakness and successively introduce a targeted augmentation methodology for classification improvement. Targeted augmentation is based on estimated weakness caused due to the challenges with difficulty levels, only those necessary for better classification were then augmented further. Predictive Augmentation (PA) and Predictive Multiple Augmentation (PMA) are the two proposed methods to adapt the model based on targeted challenges by delivering with high numerical value of confidence. We validated our framework on two different training datasets (German Traffic Sign Recognition Benchmark (GTSRB) and Heavy Vehicle data collected from bus) and with 5 generated test groups containing varying levels of challenge (simple to extreme). The results show impressive improvement by ≈ 5-20% in overall classification accuracy thereby keeping their high confidence.","",""
24,"Chengjiang Long, Eric Smith, Arslan Basharat, A. Hoogs","A C3D-Based Convolutional Neural Network for Frame Dropping Detection in a Single Video Shot",2017,"","","","",168,"2022-07-13 09:27:43","","10.1109/CVPRW.2017.237","","",,,,,24,4.80,6,4,5,"Frame dropping is a type of video manipulation where consecutive frames are deleted to omit content from the original video. Automatically detecting dropped frames across a large archive of videos while maintaining a low false alarm rate is a challenging task in digital video forensics. We propose a new approach for forensic analysis by exploiting the local spatio-temporal relationships within a portion of a video to robustly detect frame removals. In this paper, we propose to adapt the Convolutional 3D Neural Network (C3D) for frame drop detection. In order to further suppress the errors due by the network, we produce a refined video-level confidence score and demonstrate that it is superior to the raw output scores from the network. We conduct experiments on two challenging video datasets containing rapid camera motion and zoom changes. The experimental results clearly demonstrate the efficacy of the proposed approach.","",""
35,"Guiguang Ding, Yuchen Guo, Kai Chen, Chaoqun Chu, J. Han, Qionghai Dai","DECODE: Deep Confidence Network for Robust Image Classification",2019,"","","","",169,"2022-07-13 09:27:43","","10.1109/TIP.2019.2902115","","",,,,,35,11.67,6,6,3,"Recent years have witnessed the success of deep convolutional neural networks for image classification and many related tasks. It should be pointed out that the existing training strategies assume that there is a clean dataset for model learning. In elaborately constructed benchmark datasets, deep network has yielded promising performance under the assumption. However, in real-world applications, it is burdensome and expensive to collect sufficient clean training samples. On the other hand, collecting noisy labeled samples is very economical and practical, especially with the rapidly increasing amount of visual data in the web. Unfortunately, the accuracy of current deep models may drop dramatically even with 5%–10% label noise. Therefore, enabling label noise resistant classification has become a crucial issue in the data driven deep learning approaches. In this paper, we propose a DEep COnfiDEnce network (DECODE) to address this issue. In particular, based on the distribution of mislabeled data, we adopt a confidence evaluation module that is able to determine the confidence that a sample is mislabeled. With the confidence, we further use a weighting strategy to assign different weights to different samples so that the model pays less attention to low confidence data, which is more likely to be noise. In this way, the deep model is more robust to label noise. DECODE is designed to be general, such that it can be easily combined with existing studies. We conduct extensive experiments on several datasets, and the results validate that DECODE can improve the accuracy of deep models trained with noisy data.","",""
170,"Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, D. Boning, Cho-Jui Hsieh","Towards Stable and Efficient Training of Verifiably Robust Neural Networks",2019,"","","","",170,"2022-07-13 09:27:43","","","","",,,,,170,56.67,28,6,3,"Training neural networks with verifiable robustness guarantees is challenging. Several existing approaches utilize linear relaxation based neural network output bounds under perturbation, but they can slow down training by a factor of hundreds depending on the underlying network architectures. Meanwhile, interval bound propagation (IBP) based training is efficient and significantly outperforms linear relaxation based methods on many tasks, yet it may suffer from stability issues since the bounds are much looser especially at the beginning of training. In this paper, we propose a new certified adversarial training method, CROWN-IBP, by combining the fast IBP bounds in a forward bounding pass and a tight linear relaxation based bound, CROWN, in a backward bounding pass. CROWN-IBP is computationally efficient and consistently outperforms IBP baselines on training verifiably robust neural networks. We conduct large scale experiments on MNIST and CIFAR datasets, and outperform all previous linear relaxation and bound propagation based certified defenses in $\ell_\infty$ robustness. Notably, we achieve 7.02% verified test error on MNIST at $\epsilon=0.3$, and 66.94% on CIFAR-10 with $\epsilon=8/255$. Code is available at this https URL (TensorFlow) and this https URL (PyTorch).","",""
4,"U. Oparaji, R. Sheu, E. Patelli","Robust artificial neural network for reliability analysis",2017,"","","","",171,"2022-07-13 09:27:43","","10.7712/120217.5400.17104","","",,,,,4,0.80,1,3,5,"Artificial Neural Networks (ANN) are used in place of expensive models to reduce the computational burden required for reliability analysis. Often, ANNs with selected architecture are trained with the back-propagation algorithm from few data representatives of the input/output relationship of the underlying model of interest. However, different performing ANNs might be obtained from the same training data, leading to an uncertainty in selecting the best performing ANN. On the other hand, using cross-validation to select the best performing ANN based on the highest R2 value can lead to a biassing in terms of the prediction made by the selected ANN. This is due to the fact that the use of R2 cannot determine if the prediction made by ANN is biased. Additionally, R2 does not indicate if a model is adequate, as it is possible to have a low R2 for a good model and a high R2 for a bad model. Hence we propose an approach to improve the prediction robustness of an ANN based on coupling Bayesian framework and model averaging technique into a unified framework. The model uncertainties propagated to the robust prediction is quantified in terms of confidence intervals. Two examples are used to demonstrate the applicability of the approach.","",""
37,"C. Pham, Yaonan Wang","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",172,"2022-07-13 09:27:43","","10.1007/s00521-015-1873-4","","",,,,,37,6.17,19,2,6,"","",""
3,"Liping Chen, Zhiqiang Yao, Licong Chen, Jiazhen Chen","A Novel Watermarking Detector Based on Confidence Evaluation and Neural Network",2009,"","","","",173,"2022-07-13 09:27:43","","10.1109/ICISE.2009.127","","",,,,,3,0.23,1,4,13,"Digital watermark is an effective copyright protection method. A new robust public watermarking algorithm is proposed with the base of the method of confidence evaluation and neural network data fusion. First a special addition formula is applied to later evaluate the confidence of each extracted watermarked bit in the extraction. Then a normalization is used to accord with the approximate distortion rate. Moreover the neural network is applied to extract the watermark. The algorithm doesn't need the original image during the extraction. The new watermark confidence evaluation relatively reduces the volume of the embedding watermark compared with the normal method. Finally the experiments show that the watermarking algorithm is imperceptive and more robust than the normal detector and average detector.","",""
88,"Zhuanzhe Zhao, Qingsong Xu, M. Jia","Improved shuffled frog leaping algorithm-based BP neural network and its application in bearing early fault diagnosis",2016,"","","","",174,"2022-07-13 09:27:43","","10.1007/s00521-015-1850-y","","",,,,,88,14.67,29,3,6,"","",""
15,"K. Fernando, Cris P Tsokos","Dynamically Weighted Balanced Loss: Class Imbalanced Learning and Confidence Calibration of Deep Neural Networks",2021,"","","","",175,"2022-07-13 09:27:43","","10.1109/TNNLS.2020.3047335","","",,,,,15,15.00,8,2,1,"Imbalanced class distribution is an inherent problem in many real-world classification tasks where the minority class is the class of interest. Many conventional statistical and machine learning classification algorithms are subject to frequency bias, and learning discriminating boundaries between the minority and majority classes could be challenging. To address the class distribution imbalance in deep learning, we propose a class rebalancing strategy based on a class-balanced dynamically weighted loss function where weights are assigned based on the class frequency and predicted probability of ground-truth class. The ability of dynamic weighting scheme to self-adapt its weights depending on the prediction scores allows the model to adjust for instances with varying levels of difficulty resulting in gradient updates driven by hard minority class samples. We further show that the proposed loss function is classification calibrated. Experiments conducted on highly imbalanced data across different applications of cyber intrusion detection (CICIDS2017 data set) and medical imaging (ISIC2019 data set) show robust generalization. Theoretical results supported by superior empirical performance provide justification for the validity of the proposed dynamically weighted balanced (DWB) loss function.","",""
1,"Cedrique Rovile Njieutcheu Tassi","Bayesian Convolutional Neural Network: Robustly Quantify Uncertainty for Misclassifications Detection",2019,"","","","",176,"2022-07-13 09:27:43","","10.1007/978-3-030-37548-5_10","","",,,,,1,0.33,1,1,3,"","",""
48,"P. D. Cuong, W. Nan","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",177,"2022-07-13 09:27:43","","10.1007/s00521-015-1873-4","","",,,,,48,8.00,24,2,6,"","",""
92,"Xiaojian Li, Guanghong Yang","Neural-Network-Based Adaptive Decentralized Fault-Tolerant Control for a Class of Interconnected Nonlinear Systems",2018,"","","","",178,"2022-07-13 09:27:43","","10.1109/TNNLS.2016.2616906","","",,,,,92,23.00,46,2,4,"This paper is concerned with the adaptive decentralized fault-tolerant tracking control problem for a class of uncertain interconnected nonlinear systems with unknown strong interconnections. An algebraic graph theory result is introduced to address the considered interconnections. In addition, to achieve the desirable tracking performance, a neural-network-based robust adaptive decentralized fault-tolerant control (FTC) scheme is given to compensate the actuator faults and system uncertainties. Furthermore, via the Lyapunov analysis method, it is proven that all the signals of the resulting closed-loop system are semiglobally bounded, and the tracking errors of each subsystem exponentially converge to a compact set, whose radius is adjustable by choosing different controller design parameters. Finally, the effectiveness and advantages of the proposed FTC approach are illustrated with two simulated examples.","",""
104,"Liu Yang, Hanxin Chen","Fault diagnosis of gearbox based on RBF-PF and particle swarm optimization wavelet neural network",2019,"","","","",179,"2022-07-13 09:27:43","","10.1007/s00521-018-3525-y","","",,,,,104,34.67,52,2,3,"","",""
37,"Maximilian Augustin, Alexander Meinke, Matthias Hein","Adversarial Robustness on In- and Out-Distribution Improves Explainability",2020,"","","","",180,"2022-07-13 09:27:43","","10.1007/978-3-030-58574-7_14","","",,,,,37,18.50,12,3,2,"","",""
7,"Zhuolin Yang, Linyi Li, Xiaojun Xu, B. Kailkhura, Tao Xie, Bo Li","On the Certified Robustness for Ensemble Models and Beyond",2021,"","","","",181,"2022-07-13 09:27:43","","","","",,,,,7,7.00,1,6,1,"show deep neural networks (DNN) are vulnerable to adversarial which aim to mislead DNNs by adding perturbations with small magnitude. To defend against such attacks, both empirical and theoretical defense approaches have been extensively studied for a single ML model . In this work, we aim to analyze and provide the certiﬁed robustness for ensemble ML models , together with the sufﬁcient and necessary conditions of robustness for different ensemble protocols. Although ensemble models are shown more robust than a single model empirically; surprisingly, we ﬁnd that in terms of the certiﬁed robustness the standard ensemble models only achieve marginal improvement compared to a single model. Thus, to explore the conditions that guarantee to provide certiﬁably robust ensemble ML models, we ﬁrst prove that diversiﬁed gradient and large conﬁdence margin are sufﬁcient and necessary conditions for certiﬁably robust ensemble models under the model-smoothness assumption. We then provide the bounded model-smoothness analysis based on the proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble model can always achieve higher certiﬁed robustness than a single base model under mild conditions. Inspired by the theoretical ﬁndings, we propose the lightweight Diversity Regularized Training (DRT) to train certiﬁably robust ensemble ML models. Extensive experiments show that our DRT enhanced ensembles can consistently achieve higher certiﬁed robustness than existing single and ensemble ML models, demonstrating the state-of-the-art certiﬁed L 2 -robustness on MNIST, CIFAR-10, base justiﬁcation of the regularization-based training approach DRT. Extensive experiments showed that DRT-enhanced ensembles achieve the highest certiﬁed robustness compared with existing baselines.","",""
42,"G. Basalyga, E. Salinas","When Response Variability Increases Neural Network Robustness to Synaptic Noise",2005,"","","","",182,"2022-07-13 09:27:43","","10.1162/neco.2006.18.6.1349","","",,,,,42,2.47,21,2,17,"Cortical sensory neurons are known to be highly variable, in the sense that responses evoked by identical stimuli often change dramatically from trial to trial. The origin of this variability is uncertain, but it is usually interpreted as detrimental noise that reduces the computational accuracy of neural circuits. Here we investigate the possibility that such response variability might in fact be beneficial, because it may partially compensate for a decrease in accuracy due to stochastic changes in the synaptic strengths of a network. We study the interplay between two kinds of noise, response (or neuronal) noise and synaptic noise, by analyzing their joint influence on the accuracy of neural networks trained to perform various tasks. We find an interesting, generic interaction: when fluctuations in the synaptic connections are proportional to their strengths (multiplicative noise), a certain amount of response noise in the input neurons can significantly improve network performance, compared to the same network without response noise. Performance is enhanced because response noise and multiplicative synaptic noise are in some ways equivalent. So if the algorithm used to find the optimal synaptic weights can take into account the variability of the model neurons, it can also take into account the variability of the synapses. Thus, the connection patterns generated with response noise are typically more resistant to synaptic degradation than those obtained without response noise. As a consequence of this interplay, if multiplicative synaptic noise is present, it is better to have response noise in the network than not to have it. These results are demonstrated analytically for the most basic network consisting of two input neurons and one output neuron performing a simple classification task, but computer simulations show that the phenomenon persists in a wide range of architectures, including recurrent (attractor) networks and sensorimotor networks that perform coordinate transformations. The results suggest that response variability could play an important dynamic role in networks that continuously learn.","",""
2336,"Anh M Nguyen, J. Yosinski, J. Clune","Deep neural networks are easily fooled: High confidence predictions for unrecognizable images",2014,"","","","",183,"2022-07-13 09:27:43","","10.1109/CVPR.2015.7298640","","",,,,,2336,292.00,779,3,8,"Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.","",""
227,"R. Mohammad, F. Thabtah, T. McCluskey","Predicting phishing websites based on self-structuring neural network",2014,"","","","",184,"2022-07-13 09:27:43","","10.1007/s00521-013-1490-z","","",,,,,227,28.38,76,3,8,"","",""
6,"C. Billovits","Hitting Depth : Investigating Robustness to Adversarial Examples in Deep Convolutional Neural Networks",2016,"","","","",185,"2022-07-13 09:27:43","","","","",,,,,6,1.00,6,1,6,"Machine learning models, including Convolutional Neural Networks (CNN) are susceptible to adversarial examples input images that have been perturbed to deliberately fool a model into an incorrect, high-confidence prediction without a visually perceptible change. Previous work shows that high-dimensional linearities cause these adversarial pockets of space. We first validate assumptions about the generalization of gradient-based and pattern-based adversarial examples using VGGNet. We show a process for visualizing and identifying changes in activations between adversarial images and their regular counterparts. Finally, we leverage information from these two approaches in a novel Bayesian framework to increase l2 robustness to adversarial examples. Using this framework, we successfully improve the prediction accuracy on adversarial examples.","",""
1,"Enzo Casamassima, A. Herbert, Cory E. Merkel","Exploring CNN features in the context of adversarial robustness and human perception",2021,"","","","",186,"2022-07-13 09:27:43","","10.1117/12.2594363","","",,,,,1,1.00,0,3,1,"Recent studies in the field of adversarial machine learning have highlighted the poor robustness of convolutional neural networks (CNNs) to small, carefully crafted variations of the inputs. Previous work in this area has largely been focused on very small image perturbations and how these completely throw off the classifier output and cause CNNs to make high-confidence misclassifications while leaving the image visually unchanged for a human observer. These attacks modify individual pixels of each image and are unlikely to exist in a natural environment. More recent work has demonstrated that CNNs are also vulnerable to simple transformations of the input image, such as rotations and translations. These ‘natural’ transformations are much more likely to occur, either accidentally or intentionally, in a real-world scenario. In fact, humans experience and successfully recognize countless objects under these types of transformations every day. In this paper, we study the effect of these transformations on CNN accuracy when classifying 3D face-like objects (Greebles). Furthermore, we visualize the learned feature representations by CNNs and analyze how robust these learned representations are and how they compare to the human visual system. This work serves as a basis for future research into understanding the differences between CNN and human object recognition, particularly in the context of adversarial examples.","",""
140,"R. Wai, Rajkumar Muthusamy","Fuzzy-Neural-Network Inherited Sliding-Mode Control for Robot Manipulator Including Actuator Dynamics",2013,"","","","",187,"2022-07-13 09:27:43","","10.1109/TNNLS.2012.2228230","","",,,,,140,15.56,70,2,9,"This paper presents the design and analysis of an intelligent control system that inherits the robust properties of sliding-mode control (SMC) for an n-link robot manipulator, including actuator dynamics in order to achieve a high-precision position tracking with a firm robustness. First, the coupled higher order dynamic model of an n-link robot manipulator is briefy introduced. Then, a conventional SMC scheme is developed for the joint position tracking of robot manipulators. Moreover, a fuzzy-neural-network inherited SMC (FNNISMC) scheme is proposed to relax the requirement of detailed system information and deal with chattering control efforts in the SMC system. In the FNNISMC strategy, the FNN framework is designed to mimic the SMC law, and adaptive tuning algorithms for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. Numerical simulations and experimental results of a two-link robot manipulator actuated by DC servo motors are provided to justify the claims of the proposed FNNISMC system, and the superiority of the proposed FNNISMC scheme is also evaluated by quantitative comparison with previous intelligent control schemes.","",""
20,"Xujie Li, Hui Huang, Hanli Zhao, Yandan Wang, Mingxiao Hu","Learning a convolutional neural network for propagation-based stereo image segmentation",2018,"","","","",188,"2022-07-13 09:27:43","","10.1007/s00371-018-1582-y","","",,,,,20,5.00,4,5,4,"","",""
5,"A. R. Deepa, W. Emmanuel","Identification and classification of brain tumor through mixture model based on magnetic resonance imaging segmentation and artificial neural network",2016,"","","","",189,"2022-07-13 09:27:43","","10.1002/CMR.A.21390","","",,,,,5,0.83,3,2,6,"Detection of brain tumor in Magnetic Resonance Imaging (MRI) is vital as it delivers data about unusual tissues which is essential for planning treatment. Automating this method is challenging due to the high variety in appearance of tumor tissue among dissimilar patients and in many circumstances, comparison between tumor and normal tissue. In this article, we presented a mixture model based segmentation and classification of brain MRI for tumor identification. The proposed robust mixture estimator combining trimming of the outliers is based on component wise confidence level ordering of observations. The proposed method consists of three stages. In the first stage, the brain MRI is segmented into white matter (WM), gray matter (GM), Cerebrospinal fluid (CSF), and outliers by ordering of observations. In second stage, outliers consists of tumor cells in which eight type of features Contrast, Correlation, Homogeneity, Energy, Entropy, Standard deviation, Skewness, and Kurtosis are extracted. In the third stage, the extracted features are trained by Artificial Neural Network (ANN)and based on this a brain tumor identification scheme is established to examine those features to judge whether brain tumor is present in the given image or not. Experimental results indicate that the proposed classification method has achieved 93.47% in sensitivity, 100% in specificity, and 96.34% accuracy with less computational time based on the number of extracted features when compared to earlier classification methods.","",""
6,"F. Cordeiro, Ragav Sachdeva, Vasileios Belagiannis, I. Reid, G. Carneiro","LongReMix: Robust Learning with High Confidence Samples in a Noisy Label Environment",2021,"","","","",190,"2022-07-13 09:27:43","","","","",,,,,6,6.00,1,5,1,"Deep neural network models are robust to a limited amount of label noise, but their ability to memorise noisy labels in high noise rate problems is still an open issue. The most competitive noisy-label learning algorithms rely on a 2-stage process comprising an unsupervised learning to classify training samples as clean or noisy, followed by a semi-supervised learning that minimises the empirical vicinal risk (EVR) using a labelled set formed by samples classified as clean, and an unlabelled set with samples classified as noisy. In this paper, we hypothesise that the generalisation of such 2-stage noisy-label learning methods depends on the precision of the unsupervised classifier and the size of the training set to minimise the EVR. We empirically validate these two hypotheses and propose the new 2stage noisy-label training algorithm LongReMix. We test LongReMix on the noisy-label benchmarks CIFAR-10, CIFAR-100, WebVision, Clothing1M, and Food101-N. The results show that our LongReMix generalises better than competing approaches, particularly in high label noise problems. Furthermore, our approach achieves state-of-the-art performance in most datasets. The code will be available upon paper acceptance.","",""
11,"Chaithanya Kumar Mummadi, Robin Hutmacher, K. Rambach, Evgeny Levinkov, T. Brox, J. H. Metzen","Test-Time Adaptation to Distribution Shift by Confidence Maximization and Input Transformation",2021,"","","","",191,"2022-07-13 09:27:43","","","","",,,,,11,11.00,2,6,1,"Deep neural networks often exhibit poor performance on data that is unlikely under the train-time data distribution, for instance data affected by corruptions. Previous works demonstrate that test-time adaptation to data shift, for instance using entropy minimization [1], effectively improves performance on such shifted distributions. This paper focuses on the fully test-time adaptation setting, where only unlabeled data from the target distribution is required. This allows adapting arbitrary pretrained networks. Specifically, we propose a novel loss that improves test-time adaptation by addressing both premature convergence and instability of entropy minimization. This is achieved by replacing the entropy by a non-saturating surrogate and adding a diversity regularizer based on batch-wise entropy maximization that prevents convergence to trivial collapsed solutions. Moreover, we propose to prepend an input transformation module to the network that can partially undo test-time distribution shifts. Surprisingly, this preprocessing can be learned solely using the fully test-time adaptation loss in an end-to-end fashion without any target domain labels or source domain data. We show that our approach outperforms previous work in improving the robustness of publicly available pretrained image classifiers to common corruptions on such challenging benchmarks as ImageNet-C.","",""
206,"G. Chryssolouris, Moshin Lee, Alvin Ramsey","Confidence interval prediction for neural network models",1996,"","","","",192,"2022-07-13 09:27:43","","10.1109/72.478409","","",,,,,206,7.92,69,3,26,"To derive an estimate of a neural network's accuracy as an empirical modeling tool, a method to quantify the confidence intervals of a neural network model of a physical system is desired. In general, a model of a physical system has error associated with its predictions due to the dependence of the physical system's output on uncontrollable or unobservable quantities. A confidence interval can be computed for a neural network model with the assumption of normally distributed error for the neural network. The proposed method accounts for the accuracy of the data with which the neural network model is trained.","",""
101,"John Carney, P. Cunningham, Umesh Bhagwan","Confidence and prediction intervals for neural network ensembles",1999,"","","","",193,"2022-07-13 09:27:43","","10.1109/IJCNN.1999.831133","","",,,,,101,4.39,34,3,23,"We propose a technique that uses the bootstrap method to estimate confidence and prediction intervals for neural network (regression) ensembles. Our proposed technique can be applied to any ensemble technique that uses the bootstrap to generate the training sets for the ensemble, such as bagging and balancing. Confidence and prediction intervals are estimated that include a significantly improved estimate of underlying model uncertainty (i.e.) the uncertainty of our estimate of the ""true"" regression. Unlike existing techniques, this estimate of uncertainty will vary according to which ensemble technique is used if the effect of using a specific ensemble technique is to produce less model uncertainty than using another ensemble technique, then this will be reflected in the confidence and prediction intervals. Preliminary results illustrate how our technique can provide more accurate confidence and prediction intervals (intervals that better reflect the desired level of confidence (e.g.) 90%, 95%, etc.) for neural network ensembles than previous attempts.","",""
5,"Simone Wenkel, Khaled Alhazmi, Tanel Liiv, Saud R. Alrshoud, Martin Simon","Confidence Score: The Forgotten Dimension of Object Detection Performance Evaluation",2021,"","","","",194,"2022-07-13 09:27:43","","10.3390/s21134350","","",,,,,5,5.00,1,5,1,"When deploying a model for object detection, a confidence score threshold is chosen to filter out false positives and ensure that a predicted bounding box has a certain minimum score. To achieve state-of-the-art performance on benchmark datasets, most neural networks use a rather low threshold as a high number of false positives is not penalized by standard evaluation metrics. However, in scenarios of Artificial Intelligence (AI) applications that require high confidence scores (e.g., due to legal requirements or consequences of incorrect detections are severe) or a certain level of model robustness is required, it is unclear which base model to use since they were mainly optimized for benchmark scores. In this paper, we propose a method to find the optimum performance point of a model as a basis for fairer comparison and deeper insights into the trade-offs caused by selecting a confidence score threshold.","",""
2,"Yangdi Lu, Yang Bo, Wenbo He","Confidence Adaptive Regularization for Deep Learning with Noisy Labels",2021,"","","","",195,"2022-07-13 09:27:43","","","","",,,,,2,2.00,1,3,1,"Recent studies on the memorization effects of deep neural networks on noisy labels show that the networks first fit the correctly-labeled training samples before memorizing the mislabeled samples. Motivated by this early-learning phenomenon, we propose a novel method to prevent memorization of the mislabeled samples. Unlike the existing approaches which use the model output to identify or ignore the mislabeled samples, we introduce an indicator branch to the original model and enable the model to produce a confidence value for each sample. The confidence values are incorporated in our loss function which is learned to assign large confidence values to correctly-labeled samples and small confidence values to mislabeled samples. We also propose an auxiliary regularization term to further improve the robustness of the model. To improve the performance, we gradually correct the noisy labels with a well-designed target estimation strategy. We provide the theoretical analysis and conduct the experiments on synthetic and real-world datasets, demonstrating that our approach achieves comparable results to the state-of-the-art methods.","",""
76,"Yong Xu, Qiuqiang Kong, Qiang Huang, Wenwu Wang, Mark D. Plumbley","Convolutional gated recurrent neural network incorporating spatial features for audio tagging",2017,"","","","",196,"2022-07-13 09:27:43","","10.1109/IJCNN.2017.7966291","","",,,,,76,15.20,15,5,5,"Environmental audio tagging is a newly proposed task to predict the presence or absence of a specific audio event in a chunk. Deep neural network (DNN) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene. In this paper, we propose to use a convolutional neural network (CNN) to extract robust features from mel-filter banks (MFBs), spectrograms or even raw waveforms for audio tagging. Gated recurrent unit (GRU) based recurrent neural networks (RNNs) are then cascaded to model the long-term temporal structure of the audio signal. To complement the input information, an auxiliary CNN is designed to learn on the spatial features of stereo recordings. We evaluate our proposed methods on Task 4 (audio tagging) of the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE 2016) challenge. Compared with our recent DNN-based method, the proposed structure can reduce the equal error rate (EER) from 0.13 to 0.11 on the development set. The spatial features can further reduce the EER to 0.10. The performance of the end-to-end learning on raw waveforms is also comparable. Finally, on the evaluation set, we get the state-of-the-art performance with 0.12 EER while the performance of the best existing system is 0.15 EER.","",""
0,"R. Shao, Jie Zhang, E. Martin, A. Morris","Novel approaches to confidence bound generation for neural network representations",1997,"","","","",197,"2022-07-13 09:27:43","","10.1049/CP:19970705","","",,,,,0,0.00,0,4,25,"With the continuing strategic interest in the application of neural networks for inferential estimation and control, it is essential that confidence bounds are placed around the resulting predictions. In this paper, two alternative approaches for the development of confidence bounds for neural network models are described. The first approach focuses upon the conjunction of two important aspects that determine model accuracy: the ability of the neural network to predict an output and the influence of the availability of the training data. In contrast, in the second approach, the confidence bounds result from the development of a robust neural network representations through the conjunction of multiple neural networks. Utilising the bootstrap technique, a number of training and test data sets are created from which neural network representations are developed and the models combined using principal component regression. Confidence bands for the model predictions are automatically produced as a result of the technique. The two approaches are compared by application to a batch polymerisation reactor.","",""
40,"J. Dethier, P. Nuyujukian, S. Ryu, K. Shenoy, K. Boahen","Design and validation of a real-time spiking-neural-network decoder for brain-machine interfaces.",2013,"","","","",198,"2022-07-13 09:27:43","","10.1088/1741-2560/10/3/036008","","",,,,,40,4.44,8,5,9,"OBJECTIVE Cortically-controlled motor prostheses aim to restore functions lost to neurological disease and injury. Several proof of concept demonstrations have shown encouraging results, but barriers to clinical translation still remain. In particular, intracortical prostheses must satisfy stringent power dissipation constraints so as not to damage cortex.   APPROACH One possible solution is to use ultra-low power neuromorphic chips to decode neural signals for these intracortical implants. The first step is to explore in simulation the feasibility of translating decoding algorithms for brain-machine interface (BMI) applications into spiking neural networks (SNNs).   MAIN RESULTS Here we demonstrate the validity of the approach by implementing an existing Kalman-filter-based decoder in a simulated SNN using the Neural Engineering Framework (NEF), a general method for mapping control algorithms onto SNNs. To measure this system's robustness and generalization, we tested it online in closed-loop BMI experiments with two rhesus monkeys. Across both monkeys, a Kalman filter implemented using a 2000-neuron SNN has comparable performance to that of a Kalman filter implemented using standard floating point techniques.   SIGNIFICANCE These results demonstrate the tractability of SNN implementations of statistical signal processing algorithms on different monkeys and for several tasks, suggesting that a SNN decoder, implemented on a neuromorphic chip, may be a feasible computational platform for low-power fully-implanted prostheses. The validation of this closed-loop decoder system and the demonstration of its robustness and generalization hold promise for SNN implementations on an ultra-low power neuromorphic chip using the NEF.","",""
7,"Leo Schwinn, René Raab, A. Nguyen, Dario Zanca, B. Eskofier","Exploring Misclassifications of Robust Neural Networks to Enhance Adversarial Attacks",2021,"","","","",199,"2022-07-13 09:27:43","","","","",,,,,7,7.00,1,5,1,"Progress in making neural networks more robust against adversarial attacks is mostly marginal, despite the great efforts of the research community. Moreover, the robustness evaluation is often imprecise, making it difficult to identify promising approaches. We analyze the classification decisions of 19 different state-of-the-art neural networks trained to be robust against adversarial attacks. Our findings suggest that current untargeted adversarial attacks induce misclassification towards only a limited amount of different classes. Additionally, we observe that both overand under-confidence in model predictions result in an inaccurate assessment of model robustness. Based on these observations, we propose a novel loss function for adversarial attacks that consistently improves attack success rate compared to prior loss functions for 19 out of 19 analyzed models.","",""
0,"Thomas Eiter, N. Higuera, J. Oetsch, Michael Pritz","A Confidence-Based Interface for Neuro-Symbolic Visual Question Answering",2021,"","","","",200,"2022-07-13 09:27:43","","","","",,,,,0,0.00,0,4,1,"We present a neuro-symbolic visual question answering (VQA) approach for the CLEVR dataset that is based on the combination of deep neural networks and answer-set program- ming (ASP), a logic-based paradigm for declarative problem solving. We provide a translation mechanism for the questions included in CLEVR to ASP programs. By exploiting choice rules, we consider deterministic and non-deterministic scene encodings. In addition, we introduce a confidence-based interface between the ASP module and the neural network which allows us to restrict the non-determinism to objects classified by the network with high confidence. Our experiments show that the non-deterministic scene encoding achieves good results even if the neural networks are trained rather poorly in comparison with the deterministic approach. This is important for building robust VQA systems if network predictions are less-than perfect.","",""
