Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
23,"J. Gröhl, T. Kirchner, T. Adler, L. Maier-Hein","Confidence Estimation for Machine Learning-Based Quantitative Photoacoustics",2018,"","","","",1,"2022-07-13 09:23:47","","10.3390/jimaging4120147","","",,,,,23,5.75,6,4,4,"In medical applications, the accuracy and robustness of imaging methods are of crucial importance to ensure optimal patient care. While photoacoustic imaging (PAI) is an emerging modality with promising clinical applicability, state-of-the-art approaches to quantitative photoacoustic imaging (qPAI), which aim to solve the ill-posed inverse problem of recovering optical absorption from the measurements obtained, currently cannot comply with these high standards. This can be attributed to the fact that existing methods often rely on several simplifying a priori assumptions of the underlying physical tissue properties or cannot deal with realistic noise levels. In this manuscript, we address this issue with a new method for estimating an indicator of the uncertainty of an estimated optical property. Specifically, our method uses a deep learning model to compute error estimates for optical parameter estimations of a qPAI algorithm. Functional tissue parameters, such as blood oxygen saturation, are usually derived by averaging over entire signal intensity-based regions of interest (ROIs). Therefore, we propose to reduce the systematic error of the ROI samples by additionally discarding those pixels for which our method estimates a high error and thus a low confidence. In silico experiments show an improvement in the accuracy of optical absorption quantification when applying our method to refine the ROI, and it might thus become a valuable tool for increasing the robustness of qPAI methods.","",""
4,"Rahul Singh","A Finite Sample Theorem for Longitudinal Causal Inference with Machine Learning: Long Term, Dynamic, and Mediated Effects",2021,"","","","",2,"2022-07-13 09:23:47","","","","",,,,,4,4.00,4,1,1,"I construct and justify confidence intervals for longitudinal causal parameters estimated with machine learning. Longitudinal parameters include long term, dynamic, and mediated effects. I provide a nonasymptotic theorem for any longitudinal causal parameter estimated with any machine learning algorithm that satisfies a few simple, interpretable conditions. The main result encompasses local parameters defined for specific demographics as well as proximal parameters defined in the presence of unobserved confounding. Formally, I prove consistency, Gaussian approximation, and semiparametric efficiency. The rate of convergence is n for global parameters, and it degrades gracefully for local parameters. I articulate a simple set of conditions to translate mean square rates into statistical inference. A key feature of the main result is a new multiple robustness to ill posedness for proximal causal inference in longitudinal settings.","",""
1,"M. Frizzarin, T. O’Callaghan, T. Murphy, D. Hennessy, A. Casa","Application of machine-learning methods to milk mid-infrared spectra for discrimination of cow milk from pasture or total mixed ration diets.",2021,"","","","",3,"2022-07-13 09:23:47","","10.3168/jds.2021-20812","","",,,,,1,1.00,0,5,1,"The prevalence of ""grass-fed"" labeled food products on the market has increased in recent years, often commanding a premium price. To date, the majority of methods used for the authentication of grass-fed source products are driven by auditing and inspection of farm records. As such, the ability to verify grass-fed source claims to ensure consumer confidence will be important in the future. Mid-infrared (MIR) spectroscopy is widely used in the dairy industry as a rapid method for the routine monitoring of individual herd milk composition and quality. Further harnessing the data from individual spectra offers a promising and readily implementable strategy to authenticate the milk source at both farm and processor levels. Herein, a comprehensive comparison of the robustness, specificity, and accuracy of 11 machine-learning statistical analysis methods were tested for the discrimination of grass-fed versus non-grass-fed milks based on the MIR spectra of 4,320 milk samples collected from cows on pasture or indoor total mixed ration-based feeding systems over a 3-yr period. Linear discriminant analysis and partial least squares discriminant analysis (PLS-DA) were demonstrated to offer the greatest level of accuracy for the prediction of cow diet from MIR spectra. Parsimonious strategies for the selection of the most discriminating wavelengths within the spectra are also highlighted.","",""
0,"Weiqi Chen, Qi Wu, Chen Yu, Haiming Wang, W. Hong, Weishuang Yin","Multipath Machine Learning Assisted Optimization and Its Application for Antenna Design",2021,"","","","",4,"2022-07-13 09:23:47","","10.1109/APS/URSI47566.2021.9704532","","",,,,,0,0.00,0,6,1,"A multipath machine learning assisted optimization (MP-MLAO) method is proposed for antenna applications. In practical antenna design tasks, the modulation of the balance between exploration and exploitation of the conventional MLAO method always relies on experience of designers, which largely impacts the performance and robustness of the algorithm. A multipath strategy is introduced based on the implementation of multiple lower confidence bound constants to enhance the robustness of the MLAO algorithm. Moreover, with the aid of variable-fidelity-based modeling, the increase of the computational burden is largely avoided. Compared with the conventional MLAO method, the proposed MP-MLAO achieves obvious performance improvement, which is validated by applying it to design a practical cavity-backed slot antenna.","",""
0,"Snehal Prabhudesai, Nicholas C. Wang, Vinayak S. Ahluwalia, X. Huan, J. Bapuraj, Nikola Banovic, A. Rao","Stratification by Tumor Grade Groups in a Holistic Evaluation of Machine Learning for Brain Tumor Segmentation",2021,"","","","",5,"2022-07-13 09:23:47","","10.3389/fnins.2021.740353","","",,,,,0,0.00,0,7,1,"Accurate and consistent segmentation plays an important role in the diagnosis, treatment planning, and monitoring of both High Grade Glioma (HGG), including Glioblastoma Multiforme (GBM), and Low Grade Glioma (LGG). Accuracy of segmentation can be affected by the imaging presentation of glioma, which greatly varies between the two tumor grade groups. In recent years, researchers have used Machine Learning (ML) to segment tumor rapidly and consistently, as compared to manual segmentation. However, existing ML validation relies heavily on computing summary statistics and rarely tests the generalizability of an algorithm on clinically heterogeneous data. In this work, our goal is to investigate how to holistically evaluate the performance of ML algorithms on a brain tumor segmentation task. We address the need for rigorous evaluation of ML algorithms and present four axes of model evaluation—diagnostic performance, model confidence, robustness, and data quality. We perform a comprehensive evaluation of a glioma segmentation ML algorithm by stratifying data by specific tumor grade groups (GBM and LGG) and evaluate these algorithms on each of the four axes. The main takeaways of our work are—(1) ML algorithms need to be evaluated on out-of-distribution data to assess generalizability, reflective of tumor heterogeneity. (2) Segmentation metrics alone are limited to evaluate the errors made by ML algorithms and their describe their consequences. (3) Adoption of tools in other domains such as robustness (adversarial attacks) and model uncertainty (prediction intervals) lead to a more comprehensive performance evaluation. Such a holistic evaluation framework could shed light on an algorithm's clinical utility and help it evolve into a more clinically valuable tool.","",""
0,"Aurélien Olivier, C. Hoffmann, A. Mansour, L. Bressollette, Benoit Clement","Survey on machine learning applied to medical image analysis",2021,"","","","",6,"2022-07-13 09:23:47","","10.1109/CISP-BMEI53629.2021.9624442","","",,,,,0,0.00,0,5,1,"This paper presents a selective survey on recent advances in machine learning applied to medical imaging. It aims to highlight both innovations that increase the performance of the models and methods that ensure certainty, interpretability and robustness of the trained models. The paper focuses particularly on new concepts such as attention modules that allow to gather specific features considering global context. Its second main focus is given to domain adaptation methods to enhance model robustness to distribution shifts. Finally, we discuss uncertainty estimation and interpretability methods to evaluate confidence in a trained model.","",""
0,"Byung-June Kim, Taeyoon Kim, Bong-Gyu Jang","Forecasting Realized Volatility of the Oil Future Prices Via Machine Learning",2020,"","","","",7,"2022-07-13 09:23:47","","10.2139/ssrn.3708014","","",,,,,0,0.00,0,3,2,"This paper explores the possibility of the potential usage of machine learning models in the field of realized volatility forecasting of crude oil with a vast variety of empirical analyses and robustness checks. Although the conventional heterogeneous autoregressive (HAR) model is widely accepted, it failed in out-of-sample recently. However, machine learning models with the HAR factors can improve forecasting performance significantly. The model confidence set test, Diebold-Mariano test, and Pesaran-Timmermann test support the empirical results statistically.","",""
0,"J. Z. Pan, Nicholas Zufelt","On Intrinsic Dataset Properties for Adversarial Machine Learning",2020,"","","","",8,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,2,2,"Deep neural networks (DNNs) have played a key role in a wide range of machine learning applications. However, DNN classifiers are vulnerable to human-imperceptible adversarial perturbations, which can cause them to misclassify inputs with high confidence. Thus, creating robust DNNs which can defend against malicious examples is critical in applications where security plays a major role. In this paper, we study the effect of intrinsic dataset properties on the performance of adversarial attack and defense methods, testing on five popular image classification datasets - MNIST, Fashion-MNIST, CIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play key roles in attack and defense success. Our discoveries highlight that dataset design and data preprocessing steps are important to boost the adversarial robustness of DNNs. To our best knowledge, this is the first comprehensive work that studies the effect of intrinsic dataset properties on adversarial machine learning.","",""
0,"","An integrated Machine Learning framework for fraud detection",2022,"","","","",9,"2022-07-13 09:23:47","","10.4018/ijisp.300314","","",,,,,0,0.00,0,0,1,"The research develops a practical Machine Learning framework with a comparative and comprehensive approach to sequence-learn and then detect the online banking payment fraud. The integrated framework introduces exploratory analysis and feature engineering, multiple modelling and performance comparison, and model robustness, uncertainty and sensitivity analysis toward a systematic approach for Machine Learning applications. For demonstration purpose, the framework is implemented on a set of real-life online banking transaction datasets obtained from a UK-based bank through three models, i.e., Support Vector Machine, Markov Model and LSTM model, with various combinational features of the datasets evidenced in the exploratory analysis and modelling with noise ratios of datasets, range values of model parameters and confidence intervals of prediction results. The modelling results show that overall, the LSTM model achieves the best performance, with outcome accuracy of 97.7%, indicating its advantage in modelling sequential data such as customer behaviours.","",""
4,"Jiming Chen, Xiangshan Gao, Ruilong Deng, Yang He, Chongrong Fang, P. Cheng","Generating Adversarial Examples Against Machine Learning-Based Intrusion Detector in Industrial Control Systems",2022,"","","","",10,"2022-07-13 09:23:47","","10.1109/tdsc.2020.3037500","","",,,,,4,4.00,1,6,1,"Deploying machine learning (ML)-based intrusion detection systems (IDS) is an effective way to improve the security of industrial control systems (ICS). However, ML models themselves are vulnerable to adversarial examples, generated by deliberately adding subtle perturbation to the input sample that some people are not aware of, causing the model to give a false output with high confidence. In this article, our goal is to investigate the possibility of stealthy cyber attacks towards IDS, including injection attack, function code attack and reconnaissance attack, and enhance its robustness to adversarial attack. However, adversarial algorithms are subject to communication protocol and legal range of data in ICS, unlike only limited by the distance between original samples and newly generated samples in image domain. We propose two strategies - optimal solution attack and GAN attack - oriented to flexibility and volume of data, formulating an optimization problem to find stealthy attacks, where the former is appropriate for not too large and more flexible samples while the latter provides a more efficient solution for larger and not too flexible samples. Finally, we conduct experiments on a semi-physical ICS testbed with a high detection performance ensemble ML-based detector to show the effectiveness of our attacks. The results indicate that new samples of reconnaissance and function code attack produced by both optimal solution and GAN algorithm possess 80 percent higher probability to evade the detector, still maintaining the same attack effect. In the meantime, we adopt adversarial training as a method to defend against adversarial attack. After training on the mixture of orginal dataset and newly generated samples, the detector becomes more robust to adversarial examples.","",""
6,"V. Chernozhukov, W. Newey, Rahul Singh","A Simple and General Debiased Machine Learning Theorem with Finite Sample Guarantees",2021,"","","","",11,"2022-07-13 09:23:47","","10.1093/biomet/asac033","","",,,,,6,6.00,2,3,1,"  Debiased machine learning is a meta algorithm based on bias correction and sample splitting to calculate confidence intervals for functionals, i.e., scalar summaries, of machine learning algorithms. For example, an analyst may desire the confidence interval for a treatment effect estimated with a neural network. We provide a non-asymptotic debiased machine learning theorem that encompasses any global or local functional of any machine learning algorithm that satisfies a few simple, interpretable conditions. Formally, we prove consistency, Gaussian approximation, and semiparametric efficiency by finite sample arguments. The rate of convergence is n−1/2 for global functionals, and it degrades gracefully for local functionals. Our results culminate in a simple set of conditions that an analyst can use to translate modern learning theory rates into traditional statistical inference. The conditions reveal a general double robustness property for ill-posed inverse problems.","",""
1,"Tianzhe Bao, Shengquan Xie, Pengfei Yang, P. Zhou, Zhiqiang Zhang","Towards Robust, Adaptive and Reliable Upper-limb Motion Estimation Using Machine Learning and Deep Learning--A Survey in Myoelectric Control.",2022,"","","","",12,"2022-07-13 09:23:47","","10.1109/JBHI.2022.3159792","","",,,,,1,1.00,0,5,1,"To develop multi-functional human-machine interfaces that can help disabled people reconstruct lost functions of upper-limbs, machine learning (ML) and deep learning (DL) techniques have been widely implemented to decode human movement intentions from surface electromyography (sEMG) signals. However, due to the high complexity of upper-limb movements and the inherent non-stable characteristics of sEMG, the usability of ML/DL based control schemes is still greatly limited in practical scenarios. To this end, tremendous efforts have been made to improve model robustness, adaptation, and reliability. In this article, we provide a systematic review on recent achievements, mainly from three categories: multi-modal sensing fusion to gain additional information of the user, transfer learning (TL) methods to eliminate domain shift impacts on estimation models, and post-processing approaches to obtain more reliable outcomes. Special attention is given to fusion strategies, deep TL frameworks, and confidence estimation. \textcolor{red}{Research challenges and emerging opportunities, with respect to hardware development, public resources, and decoding strategies, are also analysed to provide perspectives for future developments.","",""
2,"Bogdan Adamyk, Andriy Skirka, K. Snihur, O. Adamyk","Analysis of Trust in Ukrainian banks based on Machine Learning Algorithms",2019,"","","","",13,"2022-07-13 09:23:47","","10.1109/ACITT.2019.8779974","","",,,,,2,0.67,1,4,3,"Purpose: This paper aims to conduct a thorough analysis to determine the influence of several possible factors on the level of confidence in Ukrainian banks. This scientific research project is based on data from the World Values Survey (WVS). The paper also aims to empirically investigate a number of independent variables, that creates trust in banks, based on Machine Learning Algorithms. Besides that, use some of the predictive analytics techniques to anticipate the level of trust in Ukrainian banks. Methodology: to calculate the index of Confidence in Banks var., by using linear regression, logistic regression (as a robustness check), Random Forrest, Decision Tree and XGBoost Models. Verify the output and results by using the Residual graphs, Cross-validation, Confusion matrix, ROC and model accuracy estimations. Main Findings: age, level of financial satisfaction, scale income and life satisfaction, general trust, lack of cash and other indicators has a significant impact on the the level of trust in Ukrainian banks. This paper represents a number and probability value of the variables spectrum; effect plots and other visualization graphs.","",""
3,"Sicheng Jiang, Sirui Lu, D. Deng","Vulnerability of Machine Learning Phases of Matter",2019,"","","","",14,"2022-07-13 09:23:47","","","","",,,,,3,1.00,1,3,3,"Classifying different phases and the transitions between them is a major task in condensed matter physics. Machine learning, which has achieved dramatic success recently in a broad range of artificial intelligence applications, may bring an unprecedented perspective for this challenging task. In this paper, we study the robustness of this intriguing machine-learning approach to adversarial perturbations, with a focus on supervised learning scenarios. We find that typical phase classifiers based on deep neural networks are extremely vulnerable to adversarial examples: adding a tiny amount of carefully-crafted noises, which are imperceptible to human eyes and ineffective to traditional methods, into the original legitimate data obtained from numerical simulations or real experiments will cause the classifiers to make incorrect predictions at a notably high confidence level. Our results reveal a novel vulnerability aspect in applying machine learning techniques to condensed matter physics, which provides a valuable guidance for both theoretical and experimental future studies along this direction.","",""
1,"Sicheng Jiang, Sirui Lu, D. Deng","Adversarial Machine Learning Phases of Matter",2019,"","","","",15,"2022-07-13 09:23:47","","","","",,,,,1,0.33,0,3,3,"We study the robustness of machine learning approaches to adversarial perturbations, with a focus on supervised learning scenarios. We find that typical phase classifiers based on deep neural networks are extremely vulnerable to adversarial perturbations: adding a tiny amount of carefully crafted noises into the original legitimate examples will cause the classifiers to make incorrect predictions at a notably high confidence level. Through the lens of activation maps, we find that some important underlying physical principles and symmetries remain to be adequately captured for classifiers with even near-perfect performance. This explains why adversarial perturbations exist for fooling these classifiers. In addition, we find that, after adversarial training the classifiers will become more consistent with physical laws and consequently more robust to certain kinds of adversarial perturbations. Our results provide valuable guidance for both theoretical and experimental future studies on applying machine learning techniques to condensed matter physics.","",""
1,"Jiashuo Liu, Zheyan Shen, Peng Cui, Linjun Zhou, Kun Kuang, Bo Li, Yishi Lin","Invariant Adversarial Learning for Distributional Robustness",2020,"","","","",16,"2022-07-13 09:23:47","","","","",,,,,1,0.50,0,7,2,"Machine learning algorithms with empirical risk minimization are vulnerable to distributional shifts due to the greedy adoption of all the correlations found in training data. Recently, there are robust learning methods aiming at this problem by minimizing the worst-case risk over an uncertainty set. However, they equally treat all covariates to form the uncertainty sets regardless of the stability of their correlations with the target, resulting in the overwhelmingly large set and low confidence of the learner. In this paper, we propose the Invariant Adversarial Learning (IAL) algorithm that leverages heterogeneous data sources to construct a more practical uncertainty set and conduct robustness optimization, where covariates are differentiated according to the stability of their correlations with the target. We theoretically show that our method is tractable for stochastic gradient-based optimization and provide the performance guarantees for our method. Empirical studies on both simulation and real datasets validate the effectiveness of our method in terms of robust performance across unknown distributional shifts.","",""
5,"Hanbin Hu, Qingran Zheng, Ya Wang, P. Li","HFMV: Hybridizing Formal Methods and Machine Learning for Verification of Analog and Mixed-Signal Circuits",2018,"","","","",17,"2022-07-13 09:23:47","","10.1145/3195970.3196059","","",,,,,5,1.25,1,4,4,"With increasing design complexity and robustness requirement, analog and mixed-signal (AMS) verification manifests itself as a key bottleneck. While formal methods and machine learning have been proposed for AMS verification, these two techniques suffer from their own limitations, with the former being specifically limited by scalability and the latter by the inherent uncertainty in learning-based models. We present a new direction in AMS verification by proposing a hybrid formal/machine-learning verification technique (HFMV) to combine the best of the two worlds. HFMV adds formalism on the top of a probabilistic learning model while providing a sense of coverage for extremely rare failure detection. HFMV intelligently and iteratively reduces uncertainty of the learning model by a proposed formally-guided active learning strategy and discovers potential rare failure regions in complex high-dimensional parameter spaces. It leads to reliable failure prediction in the case of a failing circuit, or a high-confidence pass decision in the case of a good circuit. We demonstrate that HFMV is able to employ a modest amount of data to identify hard-to-find rare failures which are completely missed by state-of-the-art sampling methods even with high volume sampling data.","",""
15,"Indrajit Mandal","Machine learning algorithms for the creation of clinical healthcare enterprise systems",2016,"","","","",18,"2022-07-13 09:23:47","","10.1080/17517575.2016.1251617","","",,,,,15,2.50,15,1,6,"ABSTRACT Clinical recommender systems are increasingly becoming popular for improving modern healthcare systems. Enterprise systems are persuasively used for creating effective nurse care plans to provide nurse training, clinical recommendations and clinical quality control. A novel design of a reliable clinical recommender system based on multiple classifier system (MCS) is implemented. A hybrid machine learning (ML) ensemble based on random subspace method and random forest is presented. The performance accuracy and robustness of proposed enterprise architecture are quantitatively estimated to be above 99% and 97%, respectively (above 95% confidence interval). The study then extends to experimental analysis of the clinical recommender system with respect to the noisy data environment. The ranking of items in nurse care plan is demonstrated using machine learning algorithms (MLAs) to overcome the drawback of the traditional association rule method. The promising experimental results are compared against the sate-of-the-art approaches to highlight the advancement in recommendation technology. The proposed recommender system is experimentally validated using five benchmark clinical data to reinforce the research findings.","",""
11,"M. Park, Kuk-jin Yoon","Learning and Selecting Confidence Measures for Robust Stereo Matching",2019,"","","","",19,"2022-07-13 09:23:47","","10.1109/TPAMI.2018.2837760","","",,,,,11,3.67,6,2,3,"We present a robust approach for computing disparity maps with a supervised learning-based confidence prediction. This approach takes into consideration following features. First, we analyze the characteristics of various confidence measures in the random forest framework to select effective confidence measures depending on the characteristics of the training data and matching strategies, such as similarity measures and parameters. We then train a random forest using the selected confidence measures to improve the efficiency of confidence prediction and to build a better prediction model. Second, we present a confidence-based matching cost modulation scheme, based on predicted confidence values, to improve the robustness and accuracy of the (semi-) global stereo matching algorithms. Finally, we apply the proposed modulation scheme to popularly used algorithms to make them robust against unexpected difficulties that could occur in an uncontrolled environment using challenging outdoor datasets. The proposed confidence measure selection and cost modulation schemes are experimentally verified from various perspectives using the KITTI and Middlebury datasets.","",""
9,"Min-Gyu Park, Kuk-Jin Yoon","Learning and Selecting Confidence Measures for Robust Stereo Matching.",2019,"","","","",20,"2022-07-13 09:23:47","","10.1109/TPAMI.2018.2837760","","",,,,,9,3.00,5,2,3,"We present a robust approach for computing disparity maps with a supervised learning-based confidence prediction. This approach takes into consideration following features. First, we analyze the characteristics of various confidence measures in the random forest framework to select effective confidence measures depending on the characteristics of the training data and matching strategies, such as similarity measures and parameters. We then train a random forest using the selected confidence measures to improve the efficiency of confidence prediction and to build a better prediction model. Second, we present a confidence-based matching cost modulation scheme, based on predicted confidence values, to improve the robustness and accuracy of the (semi-) global stereo matching algorithms. Finally, we apply the proposed modulation scheme to popularly used algorithms to make them robust against unexpected difficulties that could occur in an uncontrolled environment using challenging outdoor datasets. The proposed confidence measure selection and cost modulation schemes are experimentally verified from various perspectives using the KITTI and Middlebury datasets.","",""
36,"M. Doert, M. Errando","SEARCH FOR GAMMA-RAY-EMITTING ACTIVE GALACTIC NUCLEI IN THE FERMI-LAT UNASSOCIATED SAMPLE USING MACHINE LEARNING",2013,"","","","",21,"2022-07-13 09:23:47","","10.1088/0004-637X/782/1/41","","",,,,,36,4.00,18,2,9,"The second Fermi-LAT source catalog (2FGL) is the deepest all-sky survey available in the gamma-ray band. It contains 1873 sources, of which 576 remain unassociated. Machine-learning algorithms can be trained on the gamma-ray properties of known active galactic nuclei (AGNs) to find objects with AGN-like properties in the unassociated sample. This analysis finds 231 high-confidence AGN candidates, with increased robustness provided by intersecting two complementary algorithms. A method to estimate the performance of the classification algorithm is also presented, that takes into account the differences between associated and unassociated gamma-ray sources. Follow-up observations targeting AGN candidates, or studies of multiwavelength archival data, will reduce the number of unassociated gamma-ray sources and contribute to a more complete characterization of the population of gamma-ray emitting AGNs.","",""
42,"E. Cosatto, P. Laquerre, Christopher Malon, H. Graf, A. Saito, T. Kiyuna, Atsushi Marugame, Ken'ichi Kamijo","Automated gastric cancer diagnosis on H&E-stained sections; ltraining a classifier on a large scale with multiple instance machine learning",2013,"","","","",22,"2022-07-13 09:23:47","","10.1117/12.2007047","","",,,,,42,4.67,5,8,9,"We present a system that detects cancer on slides of gastric tissue sections stained with hematoxylin and eosin (H&E). At its heart is a classifier trained using the semi-supervised multi-instance learning framework (MIL) where each tissue is represented by a set of regions-of-interest (ROI) and a single label. Such labels are readily obtained because pathologists diagnose each tissue independently as part of the normal clinical workflow. From a large dataset of over 26K gastric tissue sections from over 12K patients obtained from a clinical load spanning several months, we train a MIL classifier on a patient-level partition of the dataset (2/3 of the patients) and obtain a very high performance of 96% (AUC), tested on the remaining 1/3 never-seen before patients (over 8K tissues). We show this level of performance to match the more costly supervised approach where individual ROIs need to be labeled manually. The large amount of data used to train this system gives us confidence in its robustness and that it can be safely used in a clinical setting. We demonstrate how it can improve the clinical workflow when used for pre-screening or quality control. For pre-screening, the system can diagnose 47% of the tissues with a very low likelihood (< 1%) of missing cancers, thus halving the clinicians' caseload. For quality control, compared to random rechecking of 33% of the cases, the system achieves a three-fold increase in the likelihood of catching cancers missed by pathologists. The system is currently in regular use at independent pathology labs in Japan where it is used to double-check clinician's diagnoses. At the end of 2012 it will have analyzed over 80,000 slides of gastric and colorectal samples (200,000 tissues).","",""
9,"Dan Oneață, Alexandru Caranica, Adriana Stan, H. Cucu","An Evaluation of Word-Level Confidence Estimation for End-to-End Automatic Speech Recognition",2021,"","","","",23,"2022-07-13 09:23:47","","10.1109/SLT48900.2021.9383570","","",,,,,9,9.00,2,4,1,"Quantifying the confidence (or conversely the uncertainty) of a prediction is a highly desirable trait of an automatic system, as it improves the robustness and usefulness in downstream tasks. In this paper we investigate confidence estimation for end-to-end automatic speech recognition (ASR). Previous work has addressed confidence measures for lattice-based ASR, while current machine learning research mostly focuses on confidence measures for unstructured deep learning. However, as the ASR systems are increasingly being built upon deep end-to-end methods, there is little work that tries to develop confidence measures in this context. We fill this gap by providing an extensive benchmark of popular confidence methods on four well-known speech datasets. There are two challenges we overcome in adapting existing methods: working on structured data (sequences) and obtaining confidences at a coarser level than the predictions (words instead of tokens). Our results suggest that a strong baseline can be obtained by scaling the logits by a learnt temperature, followed by estimating the confidence as the negative entropy of the predictive distribution and, finally, sum pooling to aggregate at word level.","",""
2,"Matthew J. Holland","Robustness and scalability under heavy tails, without strong convexity",2021,"","","","",24,"2022-07-13 09:23:47","","","","",,,,,2,2.00,2,1,1,"Real-world data is laden with outlying values. The challenge for machine learning is that the learner typically has no prior knowledge of whether the feedback it receives (losses, gradients, etc.) will be heavy-tailed or not. In this work, we study a simple, cost-efficient algorithmic strategy that can be leveraged when both losses and gradients can be heavy-tailed. The core technique introduces a simple robust validation sub-routine, which is used to boost the confidence of inexpensive gradient-based sub-processes. Compared with recent robust gradient descent methods from the literature, dimension dependence (both risk bounds and cost) is substantially improved, without relying upon strong convexity or expensive perstep robustification. We also empirically show that the proposed procedure cannot simply be replaced with naive cross-validation.","",""
1,"Enzo Casamassima, A. Herbert, Cory E. Merkel","Exploring CNN features in the context of adversarial robustness and human perception",2021,"","","","",25,"2022-07-13 09:23:47","","10.1117/12.2594363","","",,,,,1,1.00,0,3,1,"Recent studies in the field of adversarial machine learning have highlighted the poor robustness of convolutional neural networks (CNNs) to small, carefully crafted variations of the inputs. Previous work in this area has largely been focused on very small image perturbations and how these completely throw off the classifier output and cause CNNs to make high-confidence misclassifications while leaving the image visually unchanged for a human observer. These attacks modify individual pixels of each image and are unlikely to exist in a natural environment. More recent work has demonstrated that CNNs are also vulnerable to simple transformations of the input image, such as rotations and translations. These ‘natural’ transformations are much more likely to occur, either accidentally or intentionally, in a real-world scenario. In fact, humans experience and successfully recognize countless objects under these types of transformations every day. In this paper, we study the effect of these transformations on CNN accuracy when classifying 3D face-like objects (Greebles). Furthermore, we visualize the learned feature representations by CNNs and analyze how robust these learned representations are and how they compare to the human visual system. This work serves as a basis for future research into understanding the differences between CNN and human object recognition, particularly in the context of adversarial examples.","",""
1,"Tongxin Li, Ruixiao Yang, Guannan Qu, Guanya Shi, Chenkai Yu, A. Wierman, S. Low","Robustness and Consistency in Linear Quadratic Control with Predictions",2021,"","","","",26,"2022-07-13 09:23:47","","","","",,,,,1,1.00,0,7,1,"We study the problem of learning-augmented predictive linear quadratic control. Our goal is to design a controller that balances consistency, which measures the competitive ratio when predictions are accurate, and robustness, which bounds the competitive ratio when predictions are inaccurate. We propose a novel λ-confident controller and prove that it maintains a competitive ratio upper bound of 1 + min{O(λε) + O(1 − λ), O(1) + O(λ)} where λ ∈ [0, 1] is a trust parameter set based on the confidence in the predictions, and ε is the prediction error. Further, we design a self-tuning policy that adaptively learns the trust parameter λ with a competitive ratio that depends on ε and the variation of system perturbations and predictions. We study a classical online linear quadratic control problem where the controller has access to untrusted predictions/advice during each round, potentially from a black-box AI tool. One consequence of the success of machine learning is that accurate predictions are available for many online decision and control problems. For example, the development of deep learning has enabled generic prediction models in various domains, e.g. weather, demand forecast, and user behaviors. Such predictions are powerful because future information plays a significant role in optimizing the current control decision. The availability of accurate future predictions can potentially lead to order-of-magnitude performance improvement in decision and control problems, where one can simply plug-in the predictions and achieve near optimal performance when compared to the best control actions in hindsight, a.k.a., consistency. However, an important caveat is that the predictions are helpful only when they are accurate, which is not guaranteed in many scenarios. Since many predictions are obtained from black box AI models like neural networks, there is no uncertainty quantification and it is unclear whether the predictions are accurate. In the case when the predictions are not accurate, the consequences can be catastrophic, leading to unbounded worst-case performance, e.g., an unbounded competitive ratio. The possibility of such worst-case unbounded competitive ratio prevents the use of ML predictions in safety-critical applications that are adverse to potential risks. The use of predictions described above is a sharp contrast to the approaches developed by the online algorithm community, where the algorithms have access to no future prediction, yet can be robust to all future variations and achieve a finite competitive ratio. While such algorithms miss out on the improvements possible when accurate predictions are available, their robustness properties are necessary in safety-critical settings. Therefore, a natural question arises: Can such adversarial guarantees be provided for control policies that use black-box AI predictions? To provide adversarial guarantees necessarily means not precisely following the black-box AI predictions. Thus, there must be a trade-off between the performance in the typical case (consistency) and the quality of the adversarial guarantee (robustness). Trade-offs between consistency and robustness have received considerable 1 ar X iv :2 10 6. 09 65 9v 2 [ ee ss .S Y ] 2 0 Ja n 20 22 attention in recent years in the online algorithms community, starting with the work of [20], but our work represents the first work in the context of control. Contributions. In this paper, we answer the question above in the affirmative, in the context of linear quadratic control, providing an novel algorithm that trades off consistency and robustness to provide adversarial gaurantees on the use of untrusted predictions. Our first result provides a novel online control algorithm, termed λ-confident control, that provides a competitive ratio of 1 + min{O(λ2ε) +O(1− λ)2, O(1) +O(λ2)}, where λ ∈ [0, 1] is a trust parameter set based on the confidence in the predictions, and ε is the prediction error (Theorem 2.2). When the predictions are accurate (ε ≈ 0), setting λ close to 1 will obtain a competitive ratio close to 1, and hence the power of the predictions is fully utilized; on the other hand, when the predictions are inaccurate (ε very large), setting λ ≈ 0 will still guarantee a constant competitive ratio, meaning the algorithm will still have good robustness guarantees when the predictions turn out to be bad. Therefore, our approach can get the best of both worlds, effectively using black-box predictions but still guaranteeing robustness. The above discussion highlights that the optimal choice of λ depends on the prediction error, which may not be known a priori. Therefore, we further provide an adaptive, self-tuning learning policy (Algorithm 3) that selects λ so as to learn the optimal parameter for the actual prediction error; thus selecting the optimal balance between robustness and consistency. Our main result proves that the self-tuning policy maintains a competitive ratio bound that is always bounded regardless of the prediction error ε (Theorem 3.1). This result is informally presented below. Theorem (Informal). Under our model assumptions, there is a self-tuning online control algorithm that selects some λt ∈ [0, 1] for all t = 0, . . . , T − 1 and achieves a competitive ratio CR(ε) ≤ 1 + O(ε) Θ(1) + Θ(ε) +O(μVar) as a function of the prediction error ε where μVar measures the variation of perturbations and predictions. This result provides a worst-case performance bound for the use of untrusted predictions, e.g., the predictions from a black-box AI tool, regardless of the accuracy of the predictions. The second term in the competitive ratio upper bound indicates a nontrivial non-linear dependency of CR(ε) and the prediction error ε, matching our experimental results shown in Section 4. The third term measures the variation of perturbations and predictions. Such a term is common in regret analysis based on the “Follow The Leader” (FTL) approach [14, 15]. For example, the regret analysis of the Follow the Optimal Steady State (FOSS) method in [19] contains a similar “path length” term that captures the variation of the state trajectory. Proving our main result is complex due to the fact that, different from classical online learning models, the cost function in our problem depends on previous actions via a linear dynamical system (see (1)). The time coupling can even be exponentially large if the dynamical system is unstable. To tackle this time-coupling structure, we develop a new proof technique that relates the regret and competitive ratio with the convergence rate of the trust parameter. Finally, in Section 4 we demonstrate the effectiveness of our self-tuning approach using three examples: a robotic tracking problem, an adaptive battery-buffered EV charging problem and the Cart-Pole problem. For the robotic tracking and adaptive battery-buffered EV charging cases, we illustrate that the competitive ratio of the self-tuning policy performs nearly as well as the lower envelope formed by picking multiple trust parameters optimally offline. We also validate the practicality of our self-tuning policy by showing that it not only works well for linear quadratic control problems; it also performs well in the nonlinear Cart-Pole problem. Related Work. Our work contributes to the growing literature on learning-augmented online algorithm design. There has been significant interest in the goal of trading-off consistency and robustness in order to ensure worst-case performance bounds for black-box AI tools in online problems. As discussed earlier, prediction based algorithms can achieve consistency, while online algorithms can have robustness. These two classes of algorithms can be viewed as two extremes, and a number of works attempt to develop algorithms that balance 2 between consistency and robustness in settings like online caching [20], ski-rental [4, 22, 27, 7], online set cover [7], secretary and online matching [6], and metric task systems [5]. For example, in the ski rental problem, [22] proposes an algorithm that achieves 1 + λ consistency and 1 + 1 λ robustness for a tuning parameter λ ∈ (0, 1). Compared to these works, our setting is fundamentally more challenging because of the existence of dynamics in the control problem couples all decision points, and a mistake at one time can be magnified and propagated to all future time steps. Our work is also closely related to a broad literature on regret and competitive ratio analysis for Linear Quadratic Control (LQC) and Linear Quadratic Regulator (LQR) systems with predictions. In [29], LQR regret analysis for Model Predictive Control (MPC) is given, assuming accurate predictions of perturbations. Inaccurate predictions are considered in [28], with competitive results provided. It is proven in [29, 28] that the action generated by MPC can be explicitly written as the action of optimal linear control plus a linear combination of inaccurate predictions. The competitive analysis of the consistent and robust control scheme in this work makes use of this fact in the analysis of the more challenging case of untrusted predictions. Other related regret and competitive ratio results for MPC include [24, 18, 30]. While our work is the first to study learning-augmented control via the lens of robustness and consistency, there are two classical communities in control that are related to the goals of our work: robust control and adaptive control. Robust control is a large area that concerns the design of controllers with performance guarantees that are robust against model uncertainty or adversarial disturbances [13]. Tools of robust control include H∞ synthesis [12, 31] and robust MPC [8]. Like the robust control literature, our work also considers robustness, but our main focus is on balancing between robustness and consistency in a predictive control setting. Consistency is not a focus of the robust control literature. Further, we focus on the metrics ","",""
0,"M. Glenski, Ellyn Ayton, Robin Cosbey, Dustin L. Arendt, Svitlana Volkova","Evaluating Deception Detection Model Robustness To Linguistic Variation",2021,"","","","",27,"2022-07-13 09:23:47","","10.18653/V1/2021.SOCIALNLP-1.6","","",,,,,0,0.00,0,5,1,"With the increasing use of machine-learning driven algorithmic judgements, it is critical to develop models that are robust to evolving or manipulated inputs. We propose an extensive analysis of model robustness against linguistic variation in the setting of deceptive news detection, an important task in the context of misinformation spread online. We consider two prediction tasks and compare three state-of-the-art embeddings to highlight consistent trends in model performance, high confidence misclassifications, and high impact failures. By measuring the effectiveness of adversarial defense strategies and evaluating model susceptibility to adversarial attacks using character- and word-perturbed text, we find that character or mixed ensemble models are the most effective defenses and that character perturbation-based attack tactics are more successful.","",""
4,"Utkarsh Dwivedi, Jaina Gandhi, R. Parikh, Merijke Coenraad, Elizabeth M. Bonsignore, Hernisa Kacorri","Exploring Machine Teaching with Children",2021,"","","","",28,"2022-07-13 09:23:47","","10.1109/VL/HCC51201.2021.9576171","","",,,,,4,4.00,1,6,1,"Iteratively building and testing machine learning models can help children develop creativity, flexibility, and comfort with machine learning and artificial intelligence. We explore how children use machine teaching interfaces with a team of 14 children (aged 7–13 years) and adult co-designers. Children trained image classifiers and tested each other's models for robustness. Our study illuminates how children reason about ML concepts, offering these insights for designing machine teaching experiences for children: (i) ML metrics (e.g. confidence scores) should be visible for experimentation; (ii) ML activities should enable children to exchange models for promoting reflection and pattern recognition; and (iii) the interface should allow quick data inspection (e.g. images vs. gestures).","",""
3,"Giulio Rossolini, Alessandro Biondi, G. Buttazzo","Increasing the Confidence of Deep Neural Networks by Coverage Analysis",2021,"","","","",29,"2022-07-13 09:23:47","","10.1109/tse.2022.3163682","","",,,,,3,3.00,1,3,1,"The great performance of machine learning algorithms and deep neural networks in several perception and control tasks is pushing the industry to adopt such technologies in safety-critical applications, as autonomous robots and self-driving vehicles. At present, however, several issues need to be solved to make deep learning methods more trustworthy, predictable, safe, and secure against adversarial attacks. Although several methods have been proposed to improve the trustworthiness of deep neural networks, most of them are tailored for specific classes of adversarial examples, hence failing to detect other corner cases or unsafe inputs that heavily deviate from the training samples. This paper presents a lightweight monitoring architecture based on coverage paradigms to enhance the model robustness against different unsafe inputs. In particular, four coverage analysis methods are proposed and tested in the architecture for evaluating multiple detection logic. Experimental results show that the proposed approach is effective in detecting both powerful adversarial examples and out-of-distribution inputs, introducing limited extra-execution time and memory requirements.","",""
0,"K. Kavitha, M. Singh","Design of efficient classifier integration and performance evaluation in machine learning",2012,"","","","",30,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,2,10,"Characteristics of any classifier heavily depend upon the nature of data set taken for training and verification. Area of app lications like health care suffered from having the large and suitable dataset. Classifier designed for health care should show a better generalization and robustness characteristics so that end results presented by classifier can consider with high reliability and confidence. In this paper consistency problem associated with classifier has presented, which is a big issue from practical point of view. Defining committee of experts is one of natural way to increase the reliability in classifier design but at the same time, way of integration rules the end performance. To overcome problem of generalization and consistency of classifier, two methods for developing the mixture of classifier namely TMQD and MVFD are presented. Estimation of quality associated with a classifier is very challenging task for researcher, because there is no single parameter which could alone represents the absolute performance .To measure the quality of classifier rather than having the conventional parameters like sensitivity and specificity, receiver operating characteristics is always a better choice. But in practical environment of health care use of ROC hardly has seen. In this paper detail understanding of ROC and estimation of area under curve has also presented. Selection of threshold value is one of the most important factor to determine the performance of classifier. Dependency of threshold value with population and geographical area making difficult to decide a optimal value. A graphical approach has presented to select the best threshold value as according to environment and need.","",""
2,"C. Baron, Jie Zhang","Reliable On-Line Re-Optimization Control of a Fed-Batch Fermentation Process Using Bootstrap Aggregated Extreme Learning Machine",2017,"","","","",31,"2022-07-13 09:23:47","","10.1007/978-3-030-11292-9_14","","",,,,,2,0.40,1,2,5,"","",""
2,"C. Baron, Jie Zhang","Re-optimisation Control of a Fed-batch Fermentation Process using Bootstrap Aggregated Extreme Learning Machine",2017,"","","","",32,"2022-07-13 09:23:47","","10.5220/0006477601650176","","",,,,,2,0.40,1,2,5,"This paper presents using bootstrap aggregated extreme learning machine for the on-line re-optimisation control of a fed-batch fermentation process. In order to overcome the difficulty in developing mechanistic model, data driven models are developed using extreme learning machine (ELM). ELM has the advantage of fast training in that the hidden layer weights are randomly assigned. A single ELM model can lack of robustness due the randomly assigned hidden layer weights. To overcome this problem, multiple ELM models are developed from bootstrap re-sampling replications of the original training data and are then combined. In addition to enhanced model accuracy, bootstrap aggregated ELM can also give model prediction confidence bounds. A reliable optimal control policy is achieved by means of the inclusion of model prediction confidence bounds within the optimisation objective function to penalise wide model prediction confidence bounds which are associated with uncertain predictions as a consequence of plant model-mismatch. Finally, in order to deal with process disturbances, an on-line re-optimisation strategy is developed and successfully implemented.","",""
7,"Jiashuo Liu, Zheyan Shen, Peng Cui, Linjun Zhou, Kun Kuang, B. Li, Yishi Lin","Stable Adversarial Learning under Distributional Shifts",2020,"","","","",33,"2022-07-13 09:23:47","","","","",,,,,7,3.50,1,7,2,"Machine learning algorithms with empirical risk minimization are vulnerable under distributional shifts due to the greedy adoption of all the correlations found in training data. Recently, there are robust learning methods aiming at this problem by minimizing the worst-case risk over an uncertainty set. However, they equally treat all covariates to form the decision sets regardless of the stability of their correlations with the target, resulting in the overwhelmingly large set and low confidence of the learner. In this paper, we propose Stable Adversarial Learning (SAL) algorithm that leverages heterogeneous data sources to construct a more practical uncertainty set and conduct differentiated robustness optimization, where covariates are differentiated according to the stability of their correlations with the target. We theoretically show that our method is tractable for stochastic gradientbased optimization and provide the performance guarantees for our method. Empirical studies on both simulation and real datasets validate the effectiveness of our method in terms of uniformly good performance across unknown distributional shifts.","",""
327,"Nicolas Papernot, P. Mcdaniel","Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning",2018,"","","","",34,"2022-07-13 09:23:47","","","","",,,,,327,81.75,164,2,4,"Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.","",""
16,"Baoxian Wang, Linbo Tang, Jinglin Yang, Baojun Zhao, Shuigen Wang","Visual Tracking Based on Extreme Learning Machine and Sparse Representation",2015,"","","","",35,"2022-07-13 09:23:47","","10.3390/s151026877","","",,,,,16,2.29,3,5,7,"The existing sparse representation-based visual trackers mostly suffer from both being time consuming and having poor robustness problems. To address these issues, a novel tracking method is presented via combining sparse representation and an emerging learning technique, namely extreme learning machine (ELM). Specifically, visual tracking can be divided into two consecutive processes. Firstly, ELM is utilized to find the optimal separate hyperplane between the target observations and background ones. Thus, the trained ELM classification function is able to remove most of the candidate samples related to background contents efficiently, thereby reducing the total computational cost of the following sparse representation. Secondly, to further combine ELM and sparse representation, the resultant confidence values (i.e., probabilities to be a target) of samples on the ELM classification function are used to construct a new manifold learning constraint term of the sparse representation framework, which tends to achieve robuster results. Moreover, the accelerated proximal gradient method is used for deriving the optimal solution (in matrix form) of the constrained sparse tracking model. Additionally, the matrix form solution allows the candidate samples to be calculated in parallel, thereby leading to a higher efficiency. Experiments demonstrate the effectiveness of the proposed tracker.","",""
1,"Michael Austin Langford, B. Cheng","“Know What You Know”: Predicting Behavior for Learning-Enabled Systems When Facing Uncertainty",2021,"","","","",36,"2022-07-13 09:23:47","","10.1109/SEAMS51251.2021.00020","","",,,,,1,1.00,1,2,1,"Since deep learning systems do not generalize well when training data is incomplete and missing coverage of corner cases, it is difficult to ensure the robustness of safety-critical self-adaptive systems with deep learning components. Stakeholders require a reasonable level of confidence that a safety-critical system will behave as expected in all contexts. However, uncertainty in the behavior of safety-critical Learning-Enabled Systems (LESs) arises when run-time contexts deviate from training and validation data. To this end, this paper proposes an approach to develop a more robust safety-critical LES by predicting its learned behavior when exposed to uncertainty and thereby enabling mitigating countermeasures for predicted failures. By combining evolutionary computation with machine learning, an automated method is introduced to assess and predict the behavior of an LES when faced with previously unseen environmental conditions. By experimenting with Deep Neural Networks (DNNs) under a variety of adverse environmental changes, the proposed method is compared to a Monte Carlo (i.e., random sampling) method. Results indicate that when Monte Carlo sampling fails to capture uncommon system behavior, the proposed method is better at training behavior models with fewer training examples required.","",""
0,"Jiashuo Liu, Zheyan Shen, Peng Cui, Linjun Zhou, Kun Kuang, B. Li","Distributionally Robust Learning with Stable Adversarial Training",2021,"","","","",37,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,6,1,"Machine learning algorithms with empirical risk minimization are vulnerable under distributional shifts due to the greedy adoption of all the correlations found in training data. There is an emerging literature on tackling this problem by minimizing the worst-case risk over an uncertainty set. However, existing methods mostly construct ambiguity sets by treating all variables equally regardless of the stability of their correlations with the target, resulting in the overwhelmingly-large uncertainty set and low confidence of the learner. In this paper, we propose a novel Stable Adversarial Learning (SAL) algorithm that leverages heterogeneous data sources to construct a more practical uncertainty set and conduct differentiated robustness optimization, where covariates are differentiated according to the stability of their correlations with the target. We theoretically show that our method is tractable for stochastic gradient-based optimization and provide the performance guarantees for our method. Empirical studies on both simulation and real datasets validate the effectiveness of our method in terms of uniformly good performance across unknown distributional shifts.","",""
7,"B. A. Miller, Mustafa Çamurcu, Alexander J. Gomez, K. Chan, Tina Eliassi-Rad","Improving Robustness to Attacks Against Vertex Classification",2019,"","","","",38,"2022-07-13 09:23:47","","","","",,,,,7,2.33,1,5,3,"Vertex classification—the problem of identifying the class labels of nodes in a graph—has applicability in a wide variety of domains. Examples include classifying subject areas of papers in citation networks or roles of machines in a computer network. Recent work has demonstrated that vertex classification using graph convolutional networks is susceptible to targeted poisoning attacks, in which both graph structure and node attributes can be changed in an attempt to misclassify a target node. This vulnerability decreases users’ confidence in the learning method and can prevent adoption in high-stakes contexts. This paper presents work in progress aiming to make vertex classification robust to these types of attacks. We investigate two aspects of this problem: (1) the classification model and (2) themethod for selecting training data. Our alternative classifier is a support vector machine (with a radial basis function kernel), which is applied to an augmented node feature-vector obtained by appending the node’s attributes to a Euclidean vector representing the node based on the graph structure. Our alternative methods of selecting training data are (1) to select the highestdegree nodes in each class and (2) to iteratively select the node with the most neighbors minimally connected to the training set. In the datasets on which the original attack was demonstrated, we show that changing the training set can make the network much harder to attack. To maintain a given probability of attack success, the adversary must use far more perturbations; often a factor of 2–4 over the random training baseline. Even in cases where success is relatively easy for the attacker, we show that the classification and training alternatives allow classification performance to degrade much more gradually, with weaker incorrect predictions for the attacked nodes.","",""
1,"Geoffroy Dubourg-Felonneau, Omar A. Darwish, C. Parsons, D. Rebergen, J. Cassidy, Nirmesh Patel, Harry W. Clifford","Safety and Robustness in Decision Making: Deep Bayesian Recurrent Neural Networks for Somatic Variant Calling in Cancer",2019,"","","","",39,"2022-07-13 09:23:47","","","","",,,,,1,0.33,0,7,3,"The emerging field of precision oncology relies on the accurate pinpointing of alterations in the molecular profile of a tumor to provide personalized targeted treatments. Current methodologies in the field commonly include the application of next generation sequencing technologies to a tumor sample, followed by the identification of mutations in the DNA known as somatic variants. The differentiation of these variants from sequencing error poses a classic classification problem, which has traditionally been approached with Bayesian statistics, and more recently with supervised machine learning methods such as neural networks. Although these methods provide greater accuracy, classic neural networks lack the ability to indicate the confidence of a variant call. In this paper, we explore the performance of deep Bayesian neural networks on next generation sequencing data, and their ability to give probability estimates for somatic variant calls. In addition to demonstrating similar performance in comparison to standard neural networks, we show that the resultant output probabilities make these better suited to the disparate and highly-variable sequencing data-sets these models are likely to encounter in the real world. We aim to deliver algorithms to oncologists for which model certainty better reflects accuracy, for improved clinical application. By moving away from point estimates to reliable confidence intervals, we expect the resultant clinical and treatment decisions to be more robust and more informed by the underlying reality of the tumor molecular profile.","",""
140,"John C. Duchi, Hongseok Namkoong","Learning Models with Uniform Performance via Distributionally Robust Optimization",2018,"","","","",40,"2022-07-13 09:23:47","","10.1214/20-aos2004","","",,,,,140,35.00,70,2,4,"A common goal in statistics and machine learning is to learn models that can perform well against distributional shifts, such as latent heterogeneous subpopulations, unknown covariate shifts, or unmodeled temporal effects. We develop and analyze a distributionally robust stochastic optimization (DRO) framework that learns a model providing good performance against perturbations to the data-generating distribution. We give a convex formulation for the problem, providing several convergence guarantees. We prove finite-sample minimax upper and lower bounds, showing that distributional robustness sometimes comes at a cost in convergence rates. We give limit theorems for the learned parameters, where we fully specify the limiting distribution so that confidence intervals can be computed. On real tasks including generalizing to unknown subpopulations, fine-grained recognition, and providing good tail performance, the distributionally robust approach often exhibits improved performance.","",""
4,"Chunwu Yin, Zhanbo Chen","Developing Sustainable Classification of Diseases via Deep Learning and Semi-Supervised Learning",2020,"","","","",41,"2022-07-13 09:23:47","","10.3390/healthcare8030291","","",,,,,4,2.00,2,2,2,"Disease classification based on machine learning has become a crucial research topic in the fields of genetics and molecular biology. Generally, disease classification involves a supervised learning style; i.e., it requires a large number of labelled samples to achieve good classification performance. However, in the majority of the cases, labelled samples are hard to obtain, so the amount of training data are limited. However, many unclassified (unlabelled) sequences have been deposited in public databases, which may help the training procedure. This method is called semi-supervised learning and is very useful in many applications. Self-training can be implemented using high- to low-confidence samples to prevent noisy samples from affecting the robustness of semi-supervised learning in the training process. The deep forest method with the hyperparameter settings used in this paper can achieve excellent performance. Therefore, in this work, we propose a novel combined deep learning model and semi-supervised learning with self-training approach to improve the performance in disease classification, which utilizes unlabelled samples to update a mechanism designed to increase the number of high-confidence pseudo-labelled samples. The experimental results show that our proposed model can achieve good performance in disease classification and disease-causing gene identification.","",""
0,"Luiz F. O. Chamon, Santiago Paternain, Alejandro Ribeiro","Trust but Verify: Assigning Prediction Credibility by Counterfactual Constrained Learning",2020,"","","","",42,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,3,2,"Prediction credibility measures, in the form of confidence intervals or probability distributions, are fundamental in statistics and machine learning to characterize model robustness, detect out-of-distribution samples (outliers), and protect against adversarial attacks. To be effective, these measures should (i) account for the wide variety of models used in practice, (ii) be computable for trained models or at least avoid modifying established training procedures, (iii) forgo the use of data, which can expose them to the same robustness issues and attacks as the underlying model, and (iv) be followed by theoretical guarantees. These principles underly the framework developed in this work, which expresses the credibility as a risk-fit trade-off, i.e., a compromise between how much can fit be improved by perturbing the model input and the magnitude of this perturbation (risk). Using a constrained optimization formulation and duality theory, we analyze this compromise and show that this balance can be determined counterfactually, without having to test multiple perturbations. This results in an unsupervised, a posteriori method of assigning prediction credibility for any (possibly non-convex) differentiable model, from RKHS-based solutions to any architecture of (feedforward, convolutional, graph) neural network. Its use is illustrated in data filtering and defense against adversarial attacks.","",""
13,"A. Naimi, Edward H. Kennedy","Nonparametric Double Robustness",2017,"","","","",43,"2022-07-13 09:23:47","","","","",,,,,13,2.60,7,2,5,"Use of nonparametric techniques (e.g., machine learning, kernel smoothing, stacking) are increasingly appealing because they do not require precise knowledge of the true underlying models that generated the data under study. Indeed, numerous authors have advocated for their use with standard methods (e.g., regression, inverse probability weighting) in epidemiology. However, when used in the context of such singly robust approaches, nonparametric methods can lead to suboptimal statistical properties, including inefficiency and no valid confidence intervals. Using extensive Monte Carlo simulations, we show how doubly robust methods offer improvements over singly robust approaches when implemented via nonparametric methods. We use 10,000 simulated samples and 50, 100, 200, 600, and 1200 observations to investigate the bias and mean squared error of singly robust (g Computation, inverse probability weighting) and doubly robust (augmented inverse probability weighting, targeted maximum likelihood estimation) estimators under four scenarios: correct and incorrect model specification; and parametric and nonparametric estimation. As expected, results show best performance with g computation under correctly specified parametric models. However, even when based on complex transformed covariates, double robust estimation performs better than singly robust estimators when nonparametric methods are used. Our results suggest that nonparametric methods should be used with doubly instead of singly robust estimation techniques.","",""
97,"Christopher A. Choquette-Choo, Florian Tramèr, Nicholas Carlini, Nicolas Papernot","Label-Only Membership Inference Attacks",2020,"","","","",44,"2022-07-13 09:23:47","","","","",,,,,97,48.50,24,4,2,"Membership inference attacks are one of the simplest forms of privacy leakage for machine learning models: given a data point and model, determine whether the point was used to train the model. Existing membership inference attacks exploit models' abnormal confidence when queried on their training data. These attacks do not apply if the adversary only gets access to models' predicted labels, without a confidence measure. In this paper, we introduce label-only membership inference attacks. Instead of relying on confidence scores, our attacks evaluate the robustness of a model's predicted labels under perturbations to obtain a fine-grained membership signal. These perturbations include common data augmentations or adversarial examples. We empirically show that our label-only membership inference attacks perform on par with prior attacks that required access to model confidences. We further demonstrate that label-only attacks break multiple defenses against membership inference attacks that (implicitly or explicitly) rely on a phenomenon we call confidence masking. These defenses modify a model's confidence scores in order to thwart attacks, but leave the model's predicted labels unchanged. Our label-only attacks demonstrate that confidence-masking is not a viable defense strategy against membership inference. Finally, we investigate worst-case label-only attacks, that infer membership for a small number of outlier data points. We show that label-only attacks also match confidence-based attacks in this setting. We find that training models with differential privacy and (strong) L2 regularization are the only known defense strategies that successfully prevents all attacks. This remains true even when the differential privacy budget is too high to offer meaningful provable guarantees.","",""
0,"Amirata Ghorbani, Abubakar Abid, James Y. Zou","“ Llama ” : Confidence 99 . 8 “ Llama ” : Confidence 71 . 1 Feature-Importance Map Feature-Importance Map Feature-Importance Map “ Monarch ” : Confidence 99 . 9 “ Monarch ” : Confidence",2018,"","","","",45,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,3,4,"In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.","",""
142,"Kaihua Zhang, Lei Zhang, Ming-Hsuan Yang, David Zhang","Fast Tracking via Spatio-Temporal Context Learning",2013,"","","","",46,"2022-07-13 09:23:47","","","","",,,,,142,15.78,36,4,9,"In this paper, we present a simple yet fast and robust algorithm which exploits the spatio-temporal context for visual tracking. Our approach formulates the spatio-temporal relationships between the object of interest and its local context based on a Bayesian framework, which models the statistical correlation between the low-level features (i.e., image intensity and position) from the target and its surrounding regions. The tracking problem is posed by computing a confidence map, and obtaining the best target location by maximizing an object location likelihood function. The Fast Fourier Transform is adopted for fast learning and detection in this work. Implemented in MATLAB without code optimization, the proposed tracker runs at 350 frames per second on an i7 machine. Extensive experimental results show that the proposed algorithm performs favorably against state-of-the-art methods in terms of efficiency, accuracy and robustness.","",""
0,"Iwao Maeda","Importance of Uncertainty Estimation in Deep Learning",2019,"","","","",47,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,1,3,"In recent years, predictions by machine learning and deep learning methods are utilized in various scenes of society. A model trained with deep learning methods can predict the target with high accuracy, but can not consider the predictive confidence sufficiently, and may predict high confident for extrapolated data which is hard to predict. In this study, we applied ordinary deep learning methods and methods considering predictive uncertainty, proposed in recent years, to an image classification task, and verified the robustness of trained models against extrapolated data. Models trained with the ordinary deep learning methods predicted high confidence values for data having characteristics not existing in the training data, but models trained with the methods considering uncertainty predicted low confidence values for such data. By using methods considering uncertainty, it is possible to avoid mispredictions for extrapolated data. Experimental results suggest the importance of uncertainty estimation in deep learning.","",""
6,"C. Billovits","Hitting Depth : Investigating Robustness to Adversarial Examples in Deep Convolutional Neural Networks",2016,"","","","",48,"2022-07-13 09:23:47","","","","",,,,,6,1.00,6,1,6,"Machine learning models, including Convolutional Neural Networks (CNN) are susceptible to adversarial examples input images that have been perturbed to deliberately fool a model into an incorrect, high-confidence prediction without a visually perceptible change. Previous work shows that high-dimensional linearities cause these adversarial pockets of space. We first validate assumptions about the generalization of gradient-based and pattern-based adversarial examples using VGGNet. We show a process for visualizing and identifying changes in activations between adversarial images and their regular counterparts. Finally, we leverage information from these two approaches in a novel Bayesian framework to increase l2 robustness to adversarial examples. Using this framework, we successfully improve the prediction accuracy on adversarial examples.","",""
28,"Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander Ororbia, Xinyu Xing, C. Lee Giles, Xue Liu","Learning Adversary-Resistant Deep Neural Networks",2016,"","","","",49,"2022-07-13 09:23:47","","","","",,,,,28,4.67,4,7,6,"Deep neural networks (DNNs) have proven to be quite effective in a vast array of machine learning tasks, with recent examples in cyber security and autonomous vehicles. Despite the superior performance of DNNs in these applications, it has been recently shown that these models are susceptible to a particular type of attack that exploits a fundamental flaw in their design. This attack consists of generating particular synthetic examples referred to as adversarial samples. These samples are constructed by slightly manipulating real data-points in order to ""fool"" the original DNN model, forcing it to mis-classify previously correctly classified samples with high confidence. Addressing this flaw in the model is essential if DNNs are to be used in critical applications such as those in cyber security.  Previous work has provided various learning algorithms to enhance the robustness of DNN models, and they all fall into the tactic of ""security through obscurity"". This means security can be guaranteed only if one can obscure the learning algorithms from adversaries. Once the learning technique is disclosed, DNNs protected by these defense mechanisms are still susceptible to adversarial samples. In this work, we investigate this issue shared across previous research work and propose a generic approach to escalate a DNN's resistance to adversarial samples. More specifically, our approach integrates a data transformation module with a DNN, making it robust even if we reveal the underlying learning algorithm. To demonstrate the generality of our proposed approach and its potential for handling cyber security applications, we evaluate our method and several other existing solutions on datasets publicly available. Our results indicate that our approach typically provides superior classification performance and resistance in comparison with state-of-art solutions.","",""
357,"K. Crammer, Alex Kulesza, Mark Dredze","Adaptive regularization of weight vectors",2009,"","","","",50,"2022-07-13 09:23:47","","10.1007/s10994-013-5327-x","","",,,,,357,27.46,119,3,13,"","",""
3,"Zhanbo Chen, Xiaojun Sun, Li Shen","An Effective Tumor Classification With Deep Forest and Self-Training",2021,"","","","",51,"2022-07-13 09:23:47","","10.1109/ACCESS.2021.3096241","","",,,,,3,3.00,1,3,1,"In recent years, tumor classification based on the gene expression omnibus has become a continuous attention field in the area of bioinformatics. Integration machine learning techniques are an efficient methods to solve these problems. Generally, in order to obtain good performance in the supervised learning tasks, a large number of labelled samples will be required. However, in many cases, only a few labelled samples and abundant unlabelled samples exist in the training database. The process of labelling these unlabelled samples manually is difficult and expensive. Therefore, semi-supervised learning approaches have been proposed to utilize unlabelled samples to improve the performance of a model. However, noisy samples decrease the robustness of model in semi-supervised learning. We wish training style that samples can be implemented to train by from high- to low-confidence, self-training can meet this requirement, and the deep forest approach with the hyper-parameter settings used in this work can obtain good accuracy. Therefore, in this paper, we present a novel semi-supervised learning approach with a deep forest model to increase the performance of tumor classification, which employs unlabelled samples and minimizes the cost; that is, a updated unlabelled sample mechanism is investigated to expand the number of high-confidence pseudo-labelled samples. Multiple real-world experiments indicate that our proposed approach can obtain results up 0.96 accuracy and F1-Score, and 0.9798 AUCs.","",""
2,"Domen Vrevs, Marko Robnik vSikonja","Better sampling in explanation methods can prevent dieselgate-like deception",2021,"","","","",52,"2022-07-13 09:23:47","","","","",,,,,2,2.00,1,2,1,"Machine learning models are used in many sensitive areas where, besides predictive accuracy, their comprehensibility is also important. Interpretability of prediction models is necessary to determine their biases and causes of errors and is a prerequisite for users’ confidence. For complex state-of-the-art black-box models, post-hoc model-independent explanation techniques are an established solution. Popular and effective techniques, such as IME, LIME, and SHAP, use perturbation of instance features to explain individual predictions. Recently, Slack et al. (2020) put their robustness into question by showing that their outcomes can be manipulated due to poor perturbation sampling employed. This weakness would allow dieselgate type cheating of owners of sensitive models who could deceive inspection and hide potentially unethical or illegal biases existing in their predictive models. This could undermine public trust in machine learning models and give rise to legal restrictions on their use. We show that better sampling in these explanation methods prevents malicious manipulations. The proposed sampling uses data generators that learn the training set distribution and generate new perturbation instances much more similar to the training set. We show that the improved sampling increases the LIME and SHAP’s robustness, while the previously untested method IME is already the most robust of all.","",""
7,"Min-You Chen, Xuemin Tan, Li Zhang","An iterative self-training support vector machine algorithm in brain-computer interfaces",2016,"","","","",53,"2022-07-13 09:23:47","","10.3233/IDA-150794","","",,,,,7,1.17,2,3,6,"In this paper, an iterative self-training Support Vector Machine (SVM) algorithm combined feature re-extraction is proposed for semi-supervised learning, which only needs a small set of labeled samples to train classifier and is thus very useful in Brain-Computer Interface (BCI) design. Two methods, the model selection based self-training and the confidence criterion, respectively, is also proposed for searching the best parameter pair of SVM and selecting the most useful unlabeled data to expand the labeled training data set. The Dataset IVa of BCI Competition III, is presented to demonstrate the validity of our algorithm with statistical significance test. As an iterative algorithm, experimental results of the proposed algorithm show the validity of re-extracting feature and the robustness of the feature to the noise. In addition, the convergence of the proposed algorithm and the validity of the method measuring the consistency of the feature are also demonstrated in experiments.","",""
1,"ChiChun Zhou, Yizhou Gu, Guanwen Fang, Zesen Lin","Automatic Morphological Classification of Galaxies: Convolutional Autoencoder and Bagging-based Multiclustering Model",2021,"","","","",54,"2022-07-13 09:23:47","","10.3847/1538-3881/ac4245","","",,,,,1,1.00,0,4,1,"In order to obtain morphological information of unlabeled galaxies, we present an unsupervised machine-learning (UML) method for morphological classification of galaxies, which can be summarized as two aspects: (1) the methodology of convolutional autoencoder (CAE) is used to reduce the dimensions and extract features from the imaging data; (2) the bagging-based multiclustering model is proposed to obtain the classifications with high confidence at the cost of rejecting the disputed sources that are inconsistently voted. We apply this method on the sample of galaxies with H < 24.5 in CANDELS. Galaxies are clustered into 100 groups, each contains galaxies with analogous characteristics. To explore the robustness of the morphological classifications, we merge 100 groups into five categories by visual verification, including spheroid, early-type disk, late-type disk, irregular, and unclassifiable. After eliminating the unclassifiable category and the sources with inconsistent voting, the purity of the remaining four subclasses are significantly improved. Massive galaxies (M * > 1010 M ⊙) are selected to investigate the connection with other physical properties. The classification scheme separates galaxies well in the U − V and V − J color space and Gini–M 20 space. The gradual tendency of Sérsic indexes and effective radii is shown from the spheroid subclass to the irregular subclass. It suggests that the combination of CAE and multiclustering strategy is an effective method to cluster galaxies with similar features and can yield high-quality morphological classifications. Our study demonstrates the feasibility of UML in morphological analysis that would develop and serve the future observations made with China Space Station telescope.","",""
1,"M. Vowels, S. Akbari, Jalal Etesami, N. C. Camgoz, R. Bowden","A Free Lunch with Influence Functions? Improving Neural Network Estimates with Concepts from Semiparametric Statistics",2022,"","","","",55,"2022-07-13 09:23:47","","","","",,,,,1,1.00,0,5,1,"Parameter estimation in the empirical fields is usually undertaken using parametric models, and such models are convenient because they readily facilitate statistical inference. Unfortunately, they are unlikely to have a sufficiently flexible functional form to be able to adequately model realworld phenomena, and their usage may therefore result in biased estimates and invalid inference. Unfortunately, whilst non-parametric machine learning models may provide the needed flexibility to adapt to the complexity of realworld phenomena, they do not readily facilitate statistical inference, and may still exhibit residual bias. We explore the potential for semiparametric theory (in particular, the Influence Function) to be used to improve neural networks and machine learning algorithms in terms of (a) improving initial estimates without needing more data (b) increasing the robustness of our models, and (c) yielding confidence intervals for statistical inference. We propose a new neural network method ‘MultiNet’, which seeks the flexibility and diversity of an ensemble using a single architecture. Results on causal inference tasks indicate that MultiNet yields better performance than other approaches, and that all considered methods are amenable to improvement from semiparametric techniques under certain conditions. In other words, with these techniques we show that we can improve existing neural networks for ‘free’, without needing more data, and without needing to retrain them. Finally, we provide the expression for deriving influence functions for estimands from a general graph, and the code to do so automatically.","",""
1,"A. Avati, Martin G. Seneviratne, Emily Xue, Zhen Xu, Balaji Lakshminarayanan, Andrew M. Dai","BEDS-Bench: Behavior of EHR-models under Distributional Shift-A Benchmark",2021,"","","","",56,"2022-07-13 09:23:47","","","","",,,,,1,1.00,0,6,1,"Machine learning (ML) has recently demonstrated impressive progress in predictive accuracy across a wide array of tasks. Most ML approaches focus on generalization performance on unseen data that are “similar” to the training data (a.k.a. In-Distribution, or IND). However, real world applications and deployments of ML rarely enjoy the comfort of encountering examples that are always IND. In such situations, most ML models commonly display erratic behavior on Out-of-Distribution (OOD) examples, such as assigning high confidence to wrong predictions, or vice-versa. Implications of such unusual model behavior are further exacerbated in the healthcare setting, where patient health can potentially be put at risk. It is crucial to study the behavior and robustness properties of models under distributional shift, understand common failure modes, and take mitigation steps before the model is deployed. Having a benchmark that shines light upon these aspects of a model is a first and necessary step in addressing the issue. Recent work and interest in increasing model robustness in OOD settings have focused more on image modality, both in terms of methods as well as benchmarks, while the Electronic Health Record (EHR) modality is still largely under-explored. We aim to bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the behavior of ML models over EHR data under OOD settings. We use two open access, de-identified EHR datasets to construct several OOD data settings to run tests on. The benchmark exercises several clinical prediction tasks, OOD data settings, and measures relevant metrics that characterize crucial aspects of a model’s OOD behavior. We evaluate several learning algorithms under BEDS-Bench and find that all of them show poor generalization performance under distributional shift in general. Our results highlight the need and the potential to improve robustness of EHR models under distributional shift, and BEDS-Bench provides one way to measure progress towards that goal. Code to reproduce the results in this paper and evaluate new algorithms against BEDS-Bench is made available at https://github.com/Google-Health/records-research/tree/master/beds-bench. ar X iv :2 10 7. 08 18 9v 1 [ cs .L G ] 1 7 Ju l 2 02 1","",""
0,"Jie Zhao, Lei Wang, H. Ji, Shuangyue Chen, Danping Li","Fuzzy locality preserving projection twin support vector machine for classification",2017,"","","","",57,"2022-07-13 09:23:47","","10.1109/CAC.2017.8243831","","",,,,,0,0.00,0,5,5,"Recursive projection twin support vector machine (PTSVM) and Locality preserving projection twin support vector machine (LPPTSVM) are two extensions of traditional support vector machine (SVM). However, they may lead to a weak classifier in the application where some data points may not be fully assigned to one class. In this paper, we introduce the basic idea of fuzzy membership into LPPTSVM and propose a fuzzy LPPTSVM (FLPPTSVM) algorithm. Through fuzzy weighting technique, input points with different confidence degrees can make different contributions to the learning of decision surface. In this way, FLPPTSVM not only maintains the advantages of LPPTSVM which considers the local geometrical structure of the data and enhances the generalization ability of the algorithm, but also decreases the influence of outliers and noises. We construct experiments on artificial and UCI benchmark datasets and the results show the effectiveness and robustness of the proposed FLPPTSVM method.","",""
0,"Yenan Liu, Xiangqian Zhou, Feng Zhang, Li Zhao, Mengyang Zhang","Optimized Radial Basis Function Network Based on Beetle Antenna Search for Indoor Localization Algorithm",2021,"","","","",58,"2022-07-13 09:23:47","","10.1109/icicn52636.2021.9673902","","",,,,,0,0.00,0,5,1,"In order to improve the accuracy and robustness of Bluetooth indoor localization, an improved fusion hybrid filter and radial basis function neural network (RBFNN) indoor localization method is proposed, which effectively improves the accuracy of received signal strength (RSS) by combining various filtering algorithms, and introduces a radial basis neural network in machine learning algorithm to map the nonlinear relationship between RSS and anchor node to signal receiver localization. RBFNN is optimized using the algorithm of beetle antenna search to further improve the stability of localization. An experimental platform based on NRF52810 and a smart phone is built to verify the proposed method. Theoretical analysis and experimental results show that the average positioning error of the proposed method is 0. 63m, the confidence probability of less than lm is 75%, and the confidence probability of less than 2m is 96%. It can effectively reduce the positioning error and improve the positioning accuracy, and is easy deploy, which has high application value.","",""
0,"Ziyu Yao, Jiaquan Gao","Adversarial Example Defense Based on the Supervision",2021,"","","","",59,"2022-07-13 09:23:47","","10.1109/IJCNN52387.2021.9533561","","",,,,,0,0.00,0,2,1,"In recent years, deep learning has developed rapidly and has shown great performance on many challenging machine learning tasks, such as image classification, natural language processing, and speech recognition. However, researchers have recently discovered that deep learning models have security risks and are easily affected by adversarial examples. The adversarial example is a sample formed by deliberately adding subtle perturbation that is invisible to the human in the dataset. It can make the classification classify incorrectly with a high degree of confidence, which poses more challenges for deep learning research. In this paper, we propose a defense model based on the supervision mechanism. The model adds supervision layers to the original convolutional neural network and improves the robustness and defense ability of the model by improving the loss function. The LeNet-5 and VGG networks are used as the original network models. The experimental results on MNIST and CIFAR-10 confirm that the method proposed in this paper will effectively increase the difficulty of the attackers.","",""
0,"Weizhong Yan, Zhaoyuan Yang, Jianwei Qiu","On Adversarial Vulnerability of PHM algorithms: An Initial Study",2021,"","","","",60,"2022-07-13 09:23:47","","10.36001/phmconf.2021.v13i1.3057","","",,,,,0,0.00,0,3,1,"In almost all PHM applications, driving highest possible performance (prediction accuracy and robustness) of PHM models (fault detection, fault diagnosis and prognostics) has been the top development priority, since PHM models’ performance directly impacts how much business value the PHM models can bring. However, recent research work in other domains, e.g., computer vision (CV), has shown that machine learning (ML) models, especially deep learning models, are vulnerable to adversarial attacks; that is, small deliberately-designed perturbations to the original samples can cause the model to make false predictions with high confidence. In fact, adversarial machine learning (AML) targeting security of ML algorithms against adversaries, has become an emerging ML topic and has attracted tremendous research attention in CV and NLP.     Yet, in the PHM community, not much attention has been paid to adversarial vulnerability or security of PHM models. We contend that the economic impact of adversarial attacks to a PHM model might be even bigger than that to hard perceptual problems and thus securing PHM models from adversarial attacks is as important as the PHM models themselves. Also, PHM models, since the data used by the models are primarily time-series sensor measurements, have their own unique characteristics and deserve special attention in securing them.       In this paper we attempt to explore the adversarial vulnerability of PHM models by conducting an initial case study. More specifically, we consider several unique characteristics associated with streaming time-series sensor measurements data in developing attack strategies for attacking PHM models. We hope our initial study here can shed some light on and stimulate more research interests in the area of PHM models’ security.","",""
0,"Tianyu Pang, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen, Jun Zhu, Tie-Yan Liu","Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart",2021,"","","","",61,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,8,1,"Correctly classifying adversarial examples is an essential but challenging requirement for safely deploying machine learning models. As reported in RobustBench, even the state-of-the-art adversarially trained models struggle to exceed 67% robust test accuracy on CIFAR-10, which is far from practical. A complementary way towards robustness is to introduce a rejection option, allowing the model to not return predictions on uncertain inputs, where conﬁdence is a commonly used certainty proxy. Along with this routine, we ﬁnd that conﬁdence and a rectiﬁed conﬁdence (R-Con) can form two coupled rejection metrics, which could provably distinguish wrongly classiﬁed inputs from correctly classiﬁed ones. This intriguing property sheds light on using coupling strategies to better detect and reject adversarial examples. We evaluate our rectiﬁed rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several attacks including adaptive ones, and demonstrate that the RR module is compatible with different adversarial training frameworks on improving robustness, with little extra computation.","",""
0,"Erick Galinkin","Who's Afraid of Thomas Bayes?",2021,"","","","",62,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,1,1,"In many cases, neural networks perform well on test data, but tend to overestimate their confidence on out-of-distribution data. This has led to adoption of Bayesian neural networks, which better capture uncertainty and therefore more accurately reflect the model’s confidence. For machine learning security researchers, this raises the natural question of how making a model Bayesian affects the security of the model. In this work, we explore the interplay between Bayesianism and two measures of security: model privacy and adversarial robustness. We demonstrate that Bayesian neural networks are more vulnerable to membership inference attacks in general, but are at least as robust as their non-Bayesian counterparts to adversarial examples.","",""
0,"Shu Yao, Stanislav Minsker","Median of Means Principle for Bayesian Inference",2022,"","","","",63,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,2,1,"The topic of robustness is experiencing a resurgence of interest in the statistical and machine learning communities. In particular, robust algorithms making use of the so-called median of means estimator were shown to satisfy strong performance guarantees for many problems, including estimation of the mean, covariance structure as well as linear regression. In this work, we propose an extension of the median of means principle to the Bayesian framework, leading to the notion of the robust posterior distribution. In particular, we (a) quantify robustness of this posterior to outliers, (b) show that it satisﬁes a version of the Bernstein-von Mises theorem that con-nects Bayesian credible sets to the traditional conﬁdence intervals, and (c) demonstrate that our approach performs well in applications.","",""
0,"Gregory Scafarto, Nicolas Posocco, Antoine Bonnefoy","Calibrate to Interpret",2022,"","","","",64,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,3,1,". Trustworthy machine learning is driving a large number of ML community works in order to improve ML acceptance and adoption. The main aspect of trustworthy machine learning are the followings: fairness, uncertainty, robustness, explainability and formal guaranties. Each of these individual domains gains the ML community interest, visible by the number of related publications. However few works tackle the inter-connection between these ﬁelds. In this paper we show a ﬁrst link between uncertainty and explainability, by studying the relation between calibration and interpretation. As the calibration of a given model changes the way it scores samples, and interpretation approaches often rely on these scores, it seems safe to assume that the conﬁdence-calibration of a model interacts with our ability to interpret such model. In this paper, we show, in the context of networks trained on image classiﬁcation tasks, to what extent interpretations are sensitive to conﬁdence-calibration. It leads us to suggest a simple practice to improve the interpretation outcomes : Calibrate to Interpret .","",""
0,"Inkyoo Park, Jong-Jin Park, G. Choi","Using Bayesian posterior probability in confidence of attributes for feature selection",2015,"","","","",65,"2022-07-13 09:23:47","","10.1504/IJSN.2015.070418","","",,,,,0,0.00,0,3,7,"Rough set theory is an efficient reduction technique to deal with vagueness and uncertainty. Many studies have been accomplished for the feature selection while they have been carried out to trade off the sophisticated process of feature selection algorithm against the robustness and accuracy of reducts. In this paper, a new Bayesian posterior probability-based QuickReduct BPPQR measure is introduced to determine the optimal attributes with the accurate strength of the association among the indiscernible subsets. Therefore, a new rough entropy-based QuickReduct algorithm which focuses on the reduction of redundant attributes is proposed in order to extract the optimal reduct and the core. The performance of the system is evaluated in MATLAB on several benchmark datasets with resides in UCI machine learning repository. The proposed heuristic approach can cope with the drawbacks of the conventional one, and the satisfying performances have been carried out in the process of feature selection in decision systems.","",""
77,"Tom B. Brown, Nicholas Carlini, Chiyuan Zhang, Catherine Olsson, P. Christiano, Ian J. Goodfellow","Unrestricted Adversarial Examples",2018,"","","","",66,"2022-07-13 09:23:47","","","","",,,,,77,19.25,13,6,4,"We introduce a two-player contest for evaluating the safety and robustness of machine learning systems, with a large prize pool. Unlike most prior work in ML robustness, which studies norm-constrained adversaries, we shift our focus to unconstrained adversaries. Defenders submit machine learning models, and try to achieve high accuracy and coverage on non-adversarial data while making no confident mistakes on adversarial inputs. Attackers try to subvert defenses by finding arbitrary unambiguous inputs where the model assigns an incorrect label with high confidence. We propose a simple unambiguous dataset (""bird-or- bicycle"") to use as part of this contest. We hope this contest will help to more comprehensively evaluate the worst-case adversarial risk of machine learning models.","",""
6,"Pedro Cisneros-Velarde, Sang-Yun Oh, Alexander Petersen","Distributionally Robust Formulation and Model Selection for the Graphical Lasso",2019,"","","","",67,"2022-07-13 09:23:47","","","","",,,,,6,2.00,2,3,3,"Building on a recent framework for distributionally robust optimization in machine learning, we develop a similar framework for estimation of the inverse covariance matrix for multivariate data. We provide a novel notion of a Wasserstein ambiguity set specifically tailored to this estimation problem, from which we obtain a representation for a tractable class of regularized estimators. Special cases include penalized likelihood estimators for Gaussian data, specifically the graphical lasso estimator. As a consequence of this formulation, a natural relationship arises between the radius of the Wasserstein ambiguity set and the regularization parameter in the estimation problem. Using this relationship, one can directly control the level of robustness of the estimation procedure by specifying a desired level of confidence with which the ambiguity set contains a distribution with the true population covariance. Furthermore, a unique feature of our formulation is that the radius can be expressed in closed-form as a function of the ordinary sample covariance matrix. Taking advantage of this finding, we develop a simple algorithm to determine a regularization parameter for graphical lasso, using only the bootstrapped sample covariance matrices, meaning that computationally expensive repeated evaluation of the graphical lasso algorithm is not necessary. Alternatively, the distributionally robust formulation can also quantify the robustness of the corresponding estimator if one uses an off-the-shelf method such as cross-validation. Finally, we numerically study the obtained regularization criterion and analyze the robustness of other automated tuning procedures used in practice.","",""
8,"D. Benkeser, Jialu Ran","Nonparametric inference for interventional effects with multiple mediators",2020,"","","","",68,"2022-07-13 09:23:47","","10.1515/jci-2020-0018","","",,,,,8,4.00,4,2,2,"Abstract Understanding the pathways whereby an intervention has an effect on an outcome is a common scientific goal. A rich body of literature provides various decompositions of the total intervention effect into pathway-specific effects. Interventional direct and indirect effects provide one such decomposition. Existing estimators of these effects are based on parametric models with confidence interval estimation facilitated via the nonparametric bootstrap. We provide theory that allows for more flexible, possibly machine learning-based, estimation techniques to be considered. In particular, we establish weak convergence results that facilitate the construction of closed-form confidence intervals and hypothesis tests and prove multiple robustness properties of the proposed estimators. Simulations show that inference based on large-sample theory has adequate small-sample performance. Our work thus provides a means of leveraging modern statistical learning techniques in estimation of interventional mediation effects.","",""
5,"Xiaofeng Yang, Feng Zhao","Echo State Network and Echo State Gaussian Process for Non-Line-of-Sight Target Tracking",2020,"","","","",69,"2022-07-13 09:23:47","","10.1109/JSYST.2020.2982516","","",,,,,5,2.50,3,2,2,"Non-line-of-sight (NLOS) propagation blocks the direct path between the anchors and the agent, therefore, results in large positive bias in localization. Mobile target tracking in a NLOS scenario is much more challenging than static localization because of the need of not only dynamic modeling but also NLOS error mitigation. Gaussian Process (GP) regression is the state-of-the-art machine learning approach that resolves the issue. This article proposes two novel nonparametric strategies for NLOS target tracking, namely Echo State Network (ESN) and Echo State Gaussian Process (ESGP), both of which offers significant enhancement to the tracking performance compared to GP regression. Moreover, ESN is much more computationally efficient than GP regression and ESGP also provides a measure of confidence on the tracking results. Monte Carlo simulations and experiments prove the robustness and effectiveness of ESN and ESGP.","",""
16,"A. M. Ticlavilca, M. McKee, W. Walker","Real-time forecasting of short-term irrigation canal demands using a robust multivariate Bayesian learning model",2013,"","","","",70,"2022-07-13 09:23:47","","10.1007/s00271-011-0300-6","","",,,,,16,1.78,5,3,9,"","",""
63,"Nishant Uniyal, H. Eskandari, P. Abolmaesumi, Samira Sojoudi, P. Gordon, L. Warren, R. Rohling, S. Salcudean, Mehdi Moradi","Ultrasound RF Time Series for Classification of Breast Lesions",2015,"","","","",71,"2022-07-13 09:23:47","","10.1109/TMI.2014.2365030","","",,,,,63,9.00,7,9,7,"This work reports the use of ultrasound radio frequency (RF) time series analysis as a method for ultrasound-based classification of malignant breast lesions. The RF time series method is versatile and requires only a few seconds of raw ultrasound data with no need for additional instrumentation. Using the RF time series features, and a machine learning framework, we have generated malignancy maps, from the estimated cancer likelihood, for decision support in biopsy recommendation. These maps depict the likelihood of malignancy for regions of size 1 mm2 within the suspicious lesions. We report an area under receiver operating characteristics curve of 0.86 (95% confidence interval [CI]: 0.84%-0.90%) using support vector machines and 0.81 (95% CI: 0.78-0.85) using Random Forests classification algorithms, on 22 subjects with leave-one-subject-out cross-validation. Changing the classification method yielded consistent results which indicates the robustness of this tissue typing method. The findings of this report suggest that ultrasound RF time series, along with the developed machine learning framework, can help in differentiating malignant from benign breast lesions, subsequently reducing the number of unnecessary biopsies after mammography screening.","",""
37,"D. Bohus, Alexander I. Rudnicky","Integrating Multiple Knowledge Sources for Utterance-Level Confidence Annotation in the CMU Communicator Spoken Dialog System",2002,"","","","",72,"2022-07-13 09:23:47","","10.21236/ada461099","","",,,,,37,1.85,19,2,20,"Abstract : In the recent years, automated speech recognition has been the main drive behind the advent of spoken language interfaces, but at the same a time a severe limiting factor in the development of these systems. We believe that increased robustness in the face of recognition errors can be achieved by making the systems aware of their own misunderstandings, and employing appropriate recovery techniques when breakdowns in interacted occur. In this paper we address the first problem: the development of an utterance-level confidence annotator for a spoken dialog system. After a brief introduction to the CMU Communicator spoken dialog system (which provided the target platform for the developed annotator), we cast the confidence annotation problem as a machine learning classification task, and focus on selecting relevant features and on empirically identifying the best classification techniques for this task. The results indicate that significant reductions in classification error rate can be obtained using several different classifiers. Furthermore, we propose a data driven approach to assessing the impact of the errors committed by the confidence annotator on dialog performance, with a view to optimally fine-tuning the annotator. Several models were constructed, and the resulting error costs were in accordance with our intuition. We found, surprisingly, that, at least for a mixed-initiative spoken dialog system as the CMU Communicator, these errors trade-all equally over a wide operating characteristic range.","",""
1,"I. Kulikovskikh, S. Prokhorov, T. Lipić, T. Legovic, T. Šmuc","BioGD: Bio-inspired robust gradient descent",2019,"","","","",73,"2022-07-13 09:23:47","","10.1371/journal.pone.0219004","","",,,,,1,0.33,0,5,3,"Recent research in machine learning pointed to the core problem of state-of-the-art models which impedes their widespread adoption in different domains. The models’ inability to differentiate between noise and subtle, yet significant variation in data leads to their vulnerability to adversarial perturbations that cause wrong predictions with high confidence. The study is aimed at identifying whether the algorithms inspired by biological evolution may achieve better results in cases where brittle robustness properties are highly sensitive to the slight noise. To answer this question, we introduce the new robust gradient descent inspired by the stability and adaptability of biological systems to unknown and changing environments. The proposed optimization technique involves an open-ended adaptation process with regard to two hyperparameters inherited from the generalized Verhulst population growth equation. The hyperparameters increase robustness to adversarial noise by penalizing the degree to which hardly visible changes in gradients impact prediction. The empirical evidence on synthetic and experimental datasets confirmed the viability of the bio-inspired gradient descent and suggested promising directions for future research. The code used for computational experiments is provided in a repository at https://github.com/yukinoi/bio_gradient_descent.","",""
14,"Ishai Rosenberg, A. Shabtai, Y. Elovici, L. Rokach","Low Resource Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers",2018,"","","","",74,"2022-07-13 09:23:47","","","","",,,,,14,3.50,4,4,4,"In this paper, we present a black-box attack against API call based machine learning malware classifiers. We generate adversarial examples combining API call sequences and static features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. Our attack only requires access to the predicted label of the attacked model (without the confidence level) and minimizes the number of target classifier queries. We evaluate the attack's effectiveness against many classifiers such as RNN variants, DNN, SVM, GBDT, etc. We show that the attack requires fewer queries and less knowledge about the attacked model's architecture than other existing black-box attacks. We also implement BADGER, a software framework to recraft any malware binary so that it won't be detected by classifiers, without access to the malware source code. Finally, we discuss the robustness of this attack to existing defense mechanisms.","",""
0,"S. Haddad","Specification and Verification of Properties of Neural Networks",2019,"","","","",75,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,1,3,"With the development of machine learning and its daily applications, gaining confidence in the systems produced by such techniques has become a critical issue. A first problem consists in formalizing what is expected from the systems. Such requirements may be either generic or specific to the task to be achieved. For instance, adversarial robustness is a generic property [1]. It measures how much information is needed by an attacker to “falsify” the answer of a classifying system. On the other hand, assume the system proposes actions to be performed in the presence of an intruder, a specific property would be that there is no action to be proposed when no intruder is detected. In the internship, we will focus on neural networks since this is the most widely used and moreover it presents similar features to hybrid systems letting the possibility to adapt efficient techniques from this domain. Let us illustrate an example of specification formula:","",""
9,"A. Mencattini, P. Casti, G. Fazio, L. Ghibelli, M. Luce, A. Cricenti, E. Martinelli, C. Natale","Uncertainty Evaluation of a VBM System for AFM Study of Cell-Cerium Oxide Nanoparticles Interactions",2018,"","","","",76,"2022-07-13 09:23:47","","10.1109/TIM.2018.2799118","","",,,,,9,2.25,1,8,4,"Nowadays, visual-based measurement (VBM) systems offer new possibilities of investigation for researchers and clinicians, using noninvasive–nondestructive approaches. In this paper, we present an atomic force microscopy (AFM)-based VBM for the study of cell-cerium oxide nanoparticle interactions. To provide a metrological characterization of the results obtained and with the aim to compare different strategies, we modeled four artifacts effects occurring in AFM acquisition within the random process theory and implemented a Monte Carlo simulation to repeatedly inject such variability in the original image. Empirical cumulative distribution function, confidence intervals, and average representative values, following Supplement 1 guidelines, were estimated for the final scores assigned by the operations unit to each cell. Area under the roc curve and accuracy of classification for two different machine learning approaches were compared in a metrological compliant methodology. Results clearly demonstrate the robustness of the presented VBM system and quantify the uncertainty expected for such kind of results.","",""
8,"Johannes Schneider, J. Handali, J. Brocke","Increasing Trust in (Big) Data Analytics",2018,"","","","",77,"2022-07-13 09:23:47","","10.1007/978-3-319-92898-2_6","","",,,,,8,2.00,3,3,4,"","",""
6,"E. Chatzilari, G. Liaros, K. Georgiadis, S. Nikolopoulos, Y. Kompatsiaris","Combining the Benefits of CCA and SVMs for SSVEP-based BCIs in Real-world Conditions",2017,"","","","",78,"2022-07-13 09:23:47","","10.1145/3132635.3132636","","",,,,,6,1.20,1,5,5,"In this paper we propose a novel method for SSVEP classification that combines the benefits of the inherently multi-channel CCA, the state-of-the-art method for detecting SSVEPs, with the robust SVMs, one of the most popular machine learning algorithms. The employment of SVMs, except for the benefit of robustness, provides us also with a confidence score allowing to dynamically trade-off the trial length with the accuracy of the classifier, and vice versa. By balancing this trade-off we are able to offer personalized self-paced BCIs that maximize the ITR of the system. Furthermore, we propose to perturb the template frequencies of CCA so as to accommodate with real world BCI applications requirements, where the environmental conditions may not be ideal compared to existing methods that rely on the assumption of soundproof and distraction-free environments.","",""
6,"Xuefei Yang, W. Siu","Vehicle detection under tough conditions using prioritized feature extraction with shadow recognition",2017,"","","","",79,"2022-07-13 09:23:47","","10.1109/ICDSP.2017.8096060","","",,,,,6,1.20,3,2,5,"Vehicle detection is the core function in any Driver Assistant System. Besides the challenge in various environmental conditions, the limitation in execution time and computing power is also critical. This paper proposes a shadow detection step that aims at recognizing the shadow part of the train in various environments (including very tough cases) to accelerate the detection process. We propose two shadow recognition approaches for railway trains. In our first approach, we propose a prioritized feature extraction scheme that examines multiple features such as HOG and Color Histogram hierarchically to achieve high robustness as well as preserve the fast detecting speed. Experiments show satisfying results. Subsequently we propose a second approach using machine learning that automatically learns the features and decisions via a modified decision tree classifier with a novel confidence measuring scheme. Experiments show further improvements in both accuracy and execution time.","",""
4,"Antoine Tran, A. Manzanera","Mixing Hough and Color Histogram Models for Accurate Real-Time Object Tracking",2017,"","","","",80,"2022-07-13 09:23:47","","10.1007/978-3-319-64689-3_4","","",,,,,4,0.80,2,2,5,"","",""
3,"T. Lane, J. Burge","Learning bayesian networks from hierarchically related data with a neuroimaging application",2007,"","","","",81,"2022-07-13 09:23:47","","","","",,,,,3,0.20,2,2,15,"My primary contributions are twofold. First, I propose a novel application of discrete Bayesian networks—a modeling framework often employed in Machine Learning—to the challenging task of eliciting correlations among neuroanatomical regions of interest from a corpus of functional magnetic resonance imaging data. I demonstrate an application of this method on a dataset consisting of healthy and demented elderly adults, resulting in descriptive models for both populations of subjects. I show how the results of the models can be validated via robustness and confidence testing. Second, I propose three extensions to Bayesian network structure search that can be used to improve the results from the dementia experiment. These extensions include a method for learning networks which identifies correlations that change between classes of data and methods for improving both structure and parameter learning given a hierarchical relationship among modeled random variables (RVs). To validate these extensions, I perform a wide variety of experiments on both simulated datasets and five neuroimaging data sets. Overall, I show that incorporating my proposed methods allows for learned models to identify class-discriminative structures more effectively than traditional methods and, for domains with hierarchically related RVs, I demonstrate that higher scoring models can be found with parameters that generalize more effectively.","",""
33,"O. Debeir, Ivan Adanja, N. Warzée, P. V. Ham, C. Decaestecker","Phase contrast image segmentation by weak watershed transform assembly",2008,"","","","",82,"2022-07-13 09:23:47","","10.1109/ISBI.2008.4541098","","",,,,,33,2.36,7,5,14,"We present here a method giving a robust segmentation for in vitro cells observed under standard phase-contrast microscopy. We tackle the problem using the watershed transform. Watershed transform is known for its ability to generate closed contours and its extreme sensitivity to image borders. One main drawback of this method is over- segmentation. In order to circumvent this, marked watershed based on the ""modified gradient"" method has been developed. However, the choice of the watershed mark locations is critical and their inadequacy may cause wrong results. Similarly to randomization and combination procedures used in the machine learning field, the present paper promotes the use of an assembly of marked watershed transforms, in order to increase the segmentation robustness. This results in the definition of candidate segmentations margins (expressed in terms of object border confidence) from which final segmentation can be chosen by means of thresholding.","",""
6,"Jing Peng, B. Bhanu","Learning to Perceive Objects for Autonomous Navigation",1999,"","","","",83,"2022-07-13 09:23:47","","10.1023/A:1008887511945","","",,,,,6,0.26,3,2,23,"","",""
2,"A. Murari, J. Vega, D. Mazon, T. Courregelongue","Preliminary numerical investigations of conformal predictors based on fuzzy logic classifiers",2015,"","","","",84,"2022-07-13 09:23:47","","10.1007/s10472-014-9399-5","","",,,,,2,0.29,1,4,7,"","",""
26,"Junxian Wang, G. Bebis, M. Nicolescu, M. Nicolescu, Ronald Miller","Improving target detection by coupling it with tracking",2009,"","","","",85,"2022-07-13 09:23:47","","10.1007/s00138-007-0118-7","","",,,,,26,2.00,5,5,13,"","",""
1,"Huaining Cheng, Dustin A. Bruening, Darrell F. Lochtefeld, Z. Cheng","Gender and Ethnicity Classification from Small Subsets of Human Body Measurements",2014,"","","","",86,"2022-07-13 09:23:47","","","","",,,,,1,0.13,0,4,8,"Abstract : This paper investigates and compares machine learning models for classifying gender and ethnicity with human anthropometric measurements as input attributes. Optimal attribute sets are identified through individual measurement ranking and subset selection. These sets are further down-selected by taking into consideration the acquirability of measurements. Using the Civilian American and European Surface Anthropometry Resource (CAESAR) database as training and test datasets, the investigation has achieved a classification rate over 96% for gender (male/female) and 80% for ethnicity (White American/African American), respectively. Furthermore, the effect of random measurement noise on the classification performance is investigated to find a preliminary performance boundary for the classifiers. This study shows that gender can be predicted with high confidence and robustness from a few torso dimensions, while ethnicity can only be estimated roughly from limb dimensions under real-world conditions. The approach developed in this paper can be used with other image analysis software to achieve better understanding of human attributes contained in video imagery and to facilitate automated content analysis and decision making.","",""
0,"D. Alfano, E. Tu","A New Look at NASA: Strategic Research In Information Technology",2002,"","","","",87,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,2,20,"This viewgraph presentation provides information on research undertaken by NASA to facilitate the development of information technologies. Specific ideas covered here include: 1) Bio/nano technologies: biomolecular and nanoscale systems and tools for assembly and computing; 2) Evolvable hardware: autonomous self-improving, self-repairing hardware and software for survivable space systems in extreme environments; 3) High Confidence Software Technologies: formal methods, high-assurance software design, and program synthesis; 4) Intelligent Controls and Diagnostics: Next generation machine learning, adaptive control, and health management technologies; 5) Revolutionary computing: New computational models to increase capability and robustness to enable future NASA space missions.","",""
2,"M. Matsuoka","An Application Of Bernstein Polynomials in PAC Model",1992,"","","","",88,"2022-07-13 09:23:47","","10.1007/3-540-57369-0_41","","",,,,,2,0.07,2,1,30,"","",""
0,"Wei Chen, Xiangkui Li, Lu Ma, Dong Li","Enhancing Robustness of Machine Learning Integration With Routine Laboratory Blood Tests to Predict Inpatient Mortality After Intracerebral Hemorrhage",2022,"","","","",89,"2022-07-13 09:23:47","","10.3389/fneur.2021.790682","","",,,,,0,0.00,0,4,1,"Objective: The accurate evaluation of outcomes at a personalized level in patients with intracerebral hemorrhage (ICH) is critical clinical implications. This study aims to evaluate how machine learning integrates with routine laboratory tests and electronic health records (EHRs) data to predict inpatient mortality after ICH. Methods: In this machine learning-based prognostic study, we included 1,835 consecutive patients with acute ICH between October 2010 and December 2018. The model building process incorporated five pre-implant ICH score variables (clinical features) and 13 out of 59 available routine laboratory parameters. We assessed model performance according to a range of learning metrics, such as the mean area under the receiver operating characteristic curve [AUROC]. We also used the Shapley additive explanation algorithm to explain the prediction model. Results: Machine learning models using laboratory data achieved AUROCs of 0.71–0.82 in a split-by-year development/testing scheme. The non-linear eXtreme Gradient Boosting model yielded the highest prediction accuracy. In the held-out validation set of development cohort, the predictive model using comprehensive clinical and laboratory parameters outperformed those using clinical alone in predicting in-hospital mortality (AUROC [95% bootstrap confidence interval], 0.899 [0.897–0.901] vs. 0.875 [0.872–0.877]; P <0.001), with over 81% accuracy, sensitivity, and specificity. We observed similar performance in the testing set. Conclusions: Machine learning integrated with routine laboratory tests and EHRs could significantly promote the accuracy of inpatient ICH mortality prediction. This multidimensional composite prediction strategy might become an intelligent assistive prediction for ICH risk reclassification and offer an example for precision medicine.","",""
1,"Edward H. Kennedy, Sivaraman Balakrishnan, L. Wasserman","Discussion of “On Nearly Assumption-Free Tests of Nominal Confidence Interval Coverage for Causal Parameters Estimated by Machine Learning”",2020,"","","","",90,"2022-07-13 09:23:47","","10.1214/20-sts796","","",,,,,1,0.50,0,3,2,"We congratulate the authors on their exciting paper, which introduces a novel idea for assessing the estimation bias in causal estimates. Doubly robust estimators are now part of the standard set of tools in causal inference, but a typical analysis stops with an estimate and a confidence interval. The authors give an approach for a unique type of model-checking that allows the user to check whether the bias is sufficiently small with respect to the standard error, which is generally required for confidence intervals to be reliable.","",""
7,"Lin Liu, R. Mukherjee, J. Robins","On Nearly Assumption-Free Tests of Nominal Confidence Interval Coverage for Causal Parameters Estimated by Machine Learning",2019,"","","","",91,"2022-07-13 09:23:47","","10.1214/20-sts786","","",,,,,7,2.33,2,3,3,"For many causal effect parameters of interest, doubly robust machine learning (DRML) estimators ψ^1 are the state-of-the-art, incorporating the good prediction performance of machine learning; the decreased bias of doubly robust estimators; and the analytic tractability and bias reduction of sample splitting with cross-fitting. Nonetheless, even in the absence of confounding by unmeasured factors, the nominal (1−α) Wald confidence interval ψ^1±zα/2s.e.ˆ[ψ^1] may still undercover even in large samples, because the bias of ψ^1 may be of the same or even larger order than its standard error of order n−1/2.  In this paper, we introduce essentially assumption-free tests that (i) can falsify the null hypothesis that the bias of ψ^1  is of smaller order than its standard error, (ii) can provide a upper confidence bound on the true coverage of the Wald interval, and (iii) are valid under the null under no smoothness/sparsity assumptions on the nuisance parameters. The tests, which we refer to as Assumption Free Empirical Coverage Tests (AFECTs), are based on a U-statistic that estimates part of the bias of ψ^1.  Our claims need to be tempered in several important ways. First no test, including ours, of the null hypothesis that the ratio of the bias to its standard error is smaller than some threshold δ  can be consistent [without additional assumptions (e.g., smoothness or sparsity) that may be incorrect]. Second, the above claims only apply to certain parameters in a particular class. For most of the others, our results are unavoidably less sharp. In particular, for these parameters, we cannot directly test whether the nominal Wald interval ψ^1±zα/2s.e.ˆ[ψ^1] undercovers. However, we can often test the validity of the smoothness and/or sparsity assumptions used by an analyst to justify a claim that the reported Wald interval’s actual coverage is no less than nominal. Third, in the main text, with the exception of the simulation study in Section 1, we assume we are in the semisupervised data setting (wherein there is a much larger dataset with information only on the covariates), allowing us to regard the covariance matrix of the covariates as known. In the simulation in Section 1, we consider the setting in which estimation of the covariance matrix is required. In the simulation, we used a data adaptive estimator which performs very well in our simulations, but the estimator’s theoretical sampling behavior remains unknown.","",""
6,"C. Yeomans, R. Shail, S. Grebby, V. Nykänen, M. Middleton, P. Lusty","A machine learning approach to tungsten prospectivity modelling using knowledge-driven feature extraction and model confidence",2019,"","","","",92,"2022-07-13 09:23:47","","10.31223/osf.io/9fet8","","",,,,,6,2.00,1,6,3,"Abstract Novel mineral prospectivity modelling presented here applies knowledge-driven feature extraction to a data-driven machine learning approach for tungsten mineralisation. The method emphasises the importance of appropriate model evaluation and develops a new Confidence Metric to generate spatially refined and robust exploration targets. The data-driven Random Forest™ algorithm is employed to model tungsten mineralisation in SW England using a range of geological, geochemical and geophysical evidence layers which include a depth to granite evidence layer. Two models are presented, one using standardised input variables and a second that implements fuzzy set theory as part of an augmented feature extraction step. The use of fuzzy data transformations mean feature extraction can incorporate some user-knowledge about the mineralisation into the model. The typically subjective approach is guided using the Receiver Operating Characteristics (ROC) curve tool where transformed data are compared to known training samples. The modelling is conducted using 34 known true positive samples with 10 sets of randomly generated true negative samples to test the random effect on the model. The two models have similar accuracy but show different spatial distributions when identifying highly prospective targets. Areal analysis shows that the fuzzy-transformed model is a better discriminator and highlights three areas of high prospectivity that were not previously known. The Confidence Metric, derived from model variance, is employed to further evaluate the models. The new metric is useful for refining exploration targets and highlighting the most robust areas for follow-up investigation. The fuzzy-transformed model is shown to contain larger areas of high model confidence compared to the model using standardised variables. Finally, legacy mining data, from drilling reports and mine descriptions, is used to further validate the fuzzy-transformed model and gauge the depth of potential deposits. Descriptions of mineralisation corroborate that the targets generated in these models could be undercover at depths of less than 300 ​m. In summary, the modelling workflow presented herein provides a novel integration of knowledge-driven feature extraction with data-driven machine learning modelling, while the newly derived Confidence Metric generates reliable mineral exploration targets.","",""
2,"Lin Liu, R. Mukherjee, J. Robins","On assumption-free tests and confidence intervals for causal effects estimated by machine learning",2019,"","","","",93,"2022-07-13 09:23:47","","","","",,,,,2,0.67,1,3,3,"For many causal effect parameters $\psi$ of interest doubly robust machine learning estimators $\widehat\psi_1$ are the state-of-the-art, incorporating the benefits of the low prediction error of machine learning algorithms; the decreased bias of doubly robust estimators; and.the analytic tractability and bias reduction of cross fitting. When the potential confounders is high dimensional, the associated $(1 - \alpha)$ Wald intervals may still undercover even in large samples, because the bias may be of the same or even larger order than its standard error. In this paper, we introduce tests that can have the power to detect whether the bias of $\widehat\psi_1$ is of the same or even larger order than its standard error of order $n^{-1/2}$, can provide a lower confidence limit on the degree of under coverage of the interval and strikingly, are valid under essentially no assumptions. We also introduce an estimator with bias generally less than that of $\widehat\psi_1$, yet whose standard error is not much greater than $\widehat\psi_1$'s. The tests, as well as the estimator $\widehat\psi_2$, are based on a U-statistic that is the second-order influence function for the parameter that encodes the estimable part of the bias of $\widehat\psi_1$. Our impressive claims need to be tempered in several important ways. First no test, including ours, of the null hypothesis that the ratio of the bias to its standard error can be consistent [without making additional assumptions that may be incorrect]. Furthermore the above claims only apply to parameters in a particular class. For the others, our results are less sharp and require more careful interpretation.","",""
21,"A. Naimi, Alan Mishler, Edward H. Kennedy","Challenges in Obtaining Valid Causal Effect Estimates with Machine Learning Algorithms.",2017,"","","","",94,"2022-07-13 09:23:47","","10.1093/aje/kwab201","","",,,,,21,4.20,7,3,5,"Unlike parametric regression, machine learning (ML) methods do not generally require precise knowledge of the true data generating mechanisms. As such, numerous authors have advocated for ML methods to estimate causal effects. Unfortunately, ML algorithmscan perform worse than parametric regression. We demonstrate the performance of ML-based single- and double-robust estimators. We use 100 Monte Carlo samples with sample sizes of 200, 1200, and 5000 to investigate bias and confidence interval coverage under several scenarios. In a simple confounding scenario, confounders were related to the treatment and the outcome via parametric models. In a complex confounding scenario, the simple confounders were transformed to induce complicated nonlinear relationships. In the simple scenario, when ML algorithms were used, double-robust estimators were superior to single-robust estimators. In the complex scenario, single-robust estimators with ML algorithms were at least as biased as estimators using misspecified parametric models. Double-robust estimators were less biased, but coverage was well below nominal. The use of sample splitting, inclusion of confounder interactions, reliance on a richly specified ML algorithm, and use of doubly robust estimators was the only explored approach that yielded negligible bias and nominal coverage. Our results suggest that ML based singly robust methods should be avoided.","",""
0,"Junbo Wang, Amitangshu Pal, Qinglin Yang, K. Kant, Kaiming Zhu, Song Guo","Collaborative Machine Learning: Schemes, Robustness, and Privacy.",2022,"","","","",95,"2022-07-13 09:23:47","","10.1109/TNNLS.2022.3169347","","",,,,,0,0.00,0,6,1,"Distributed machine learning (ML) was originally introduced to solve a complex ML problem in a parallel way for more efficient usage of computation resources. In recent years, such learning has been extended to satisfy other objectives, namely, performing learning in situ on the training data at multiple locations and keeping the training datasets private while still allowing sharing of the model. However, these objectives have led to considerable research on the vulnerabilities of distributed learning both in terms of privacy concerns of the training data and the robustness of the learned overall model due to bad or maliciously crafted training data. This article provides a comprehensive survey of various privacy, security, and robustness issues in distributed ML.","",""
0,"Tareq Aziz AL-Qutami, M. A. Ishak, Lars Wollebaek, W. A. W. Ahmad","Combining Physics and Machine Learning for Multimodal Virtual Flow Metering with Confidence",2022,"","","","",96,"2022-07-13 09:23:47","","10.2523/iptc-22431-ms","","",,,,,0,0.00,0,4,1,"  This paper introduces a multimodal virtual flow meter (VFM) that merges physics-driven multiphase flow simulations with machine learning models to accurately estimate flow rates in oil and gas wells. The combining algorithm takes advantage of the confidence decay and historical performance factors to assign confidence and contribution weights to the base estimators and then aggregates their estimates to arrive at more accurate flow rate estimates. Furthermore, the proposed multimodal VFM provides an indication of the confidence level for each estimate based on the underlying agreement of the base estimates and the historical performance. The proposed VFM was tested in a 6 months online pilot in two oil wells. The proposed multimodal algorithm resulted in almost 50% improvements in performance compared to individual VFMs. The proposed robust multimodal approach can provide a complimentary benefit as an optimal VFM and reduce the overall system uncertainty. The developed VFM can be used for real-time production monitoring, verification and backup of physical meters, and well-test validation.","",""
62,"Matteo Poggi, F. Tosi, S. Mattoccia","Quantitative Evaluation of Confidence Measures in a Machine Learning World",2017,"","","","",97,"2022-07-13 09:23:47","","10.1109/ICCV.2017.559","","",,,,,62,12.40,21,3,5,"Confidence measures aim at detecting unreliable depth measurements and play an important role for many purposes and in particular, as recently shown, to improve stereo accuracy. This topic has been thoroughly investigated by Hu and Mordohai in 2010 (and 2012) considering 17 confidence measures and two local algorithms on the two datasets available at that time. However, since then major breakthroughs happened in this field: the availability of much larger and challenging datasets, novel and more effective stereo algorithms including ones based on deep learning and confidence measures leveraging on machine learning techniques. Therefore, this paper aims at providing an exhaustive and updated review and quantitative evaluation of 52 (actually, 76 considering variants) stateof- the-art confidence measures - focusing on recent ones mostly based on random-forests and deep learning - with three algorithms on the challenging datasets available today. Moreover we deal with problems inherently induced by learning-based confidence measures. How are these methods able to generalize to new data? How a specific training improves their effectiveness? How more effective confidence measures can actually improve the overall stereo accurac?","",""
0,"Jianlong Zhou, Kun Yu, Fang Chen","Revealing User Confidence in Machine Learning-Based Decision Making",2018,"","","","",98,"2022-07-13 09:23:47","","10.1007/978-3-319-90403-0_11","","",,,,,0,0.00,0,3,4,"","",""
16,"Phil Legg, Jim E. Smith, A. Downing","Visual analytics for collaborative human-machine confidence in human-centric active learning tasks",2019,"","","","",99,"2022-07-13 09:23:47","","10.1186/s13673-019-0167-8","","",,,,,16,5.33,5,3,3,"","",""
1,"W. Weinzierl","Attribute Assisted Interpretation Confidence Classification Using Machine Learning",2017,"","","","",100,"2022-07-13 09:23:47","","10.1109/ICMLA.2017.0-178","","",,,,,1,0.20,1,1,5,"An attribute assisted classification deriving estimates of interpretation confidence was performed. Instantaneous and coherency attributes were used in a supervised followed by an unsupervised classification resulting in an error envelope of the interpretation. In an initial approximation, confidence weights for a signal and background response are estimated using support vector machine learning. Subsequently, a weighted discrimination based on several coherency attributes using self-organizing maps is obtained. The resulting quantization is used as additional input and constraint in a final probability assessment of signal confidence using instantaneous attributes in support vector machine learning. The additional input in the form of quantization vectors and possible reduction in dimensionality of the input attribute vector space, allows to combine highly non-linear correlations in a multivariate discrimination. The trained classification is used to assign signal confidence probabilities to an interpreted seismic horizon. The proposed methodology is applied to an onshore data set from Wyoming, USA, revealing how single- and multi-trace attributes can be used to quantitatively assess the uncertainty of an interpretation often lost during project maturation.","",""
3,"O. Dukes, S. Vansteelandt, D. Whitney","On doubly robust inference for double machine learning",2021,"","","","",101,"2022-07-13 09:23:47","","","","",,,,,3,3.00,1,3,1,"Due to concerns about parametric model misspecification, there is interest in using machine learning to adjust for confounding when evaluating the causal effect of an exposure on an outcome. Unfortunately, exposure effect estimators that rely on machine learning predictions are generally subject to so-called plug-in bias, which can render naive p-values and confidence intervals invalid. Progress has been made via proposals like targeted maximum likelihood estimation and more recently double machine learning, which rely on learning the conditional mean of both the outcome and exposure. Valid inference can then be obtained so long as both predictions converge (sufficiently fast) to the truth. Focusing on partially linear regression models, we show that a specific implementation of the machine learning techniques can yield exposure effect estimators that have small bias even when one of the firststage predictions does not converge to the truth. The resulting tests and confidence intervals are doubly robust. We also show that the proposed estimators may fail to be regular when only one nuisance parameter is consistently estimated; nevertheless, we observe in simulation studies that our proposal leads to reduced bias and improved confidence interval coverage in moderate samples.","",""
2,"Jiayi Tang, Alex Henderson, P. Gardner","Exploring AdaBoost and Random Forests machine learning approaches for infrared pathology on unbalanced data sets.",2021,"","","","",102,"2022-07-13 09:23:47","","10.1039/D0AN02155E","","",,,,,2,2.00,1,3,1,"The use of infrared spectroscopy to augment decision-making in histopathology is a promising direction for the diagnosis of many disease types. Hyperspectral images of healthy and diseased tissue, generated by infrared spectroscopy, are used to build chemometric models that can provide objective metrics of disease state. It is important to build robust and stable models to provide confidence to the end user. The data used to develop such models can have a variety of characteristics which can pose problems to many model-building approaches. Here we have compared the performance of two machine learning algorithms - AdaBoost and Random Forests - on a variety of non-uniform data sets. Using samples of breast cancer tissue, we devised a range of training data capable of describing the problem space. Models were constructed from these training sets and their characteristics compared. In terms of separating infrared spectra of cancerous epithelium tissue from normal-associated tissue on the tissue microarray, both AdaBoost and Random Forests algorithms were shown to give excellent classification performance (over 95% accuracy) in this study. AdaBoost models were more robust when datasets with large imbalance were provided. The outcomes of this work are a measure of classification accuracy as a function of training data available, and a clear recommendation for choice of machine learning approach.","",""
1,"Nicolas Jourdan, S. Sen, E. J. Husom, Enrique Garcia-Ceja, Tobias Biegel, J. Metternich","On The Reliability Of Machine Learning Applications In Manufacturing Environments",2021,"","","","",103,"2022-07-13 09:23:47","","","","",,,,,1,1.00,0,6,1,"The increasing deployment of advanced digital technologies such as Internet of Things (IoT) devices and Cyber-Physical Systems (CPS) in industrial environments is enabling the productive use of machine learning (ML) algorithms in the manufacturing domain. As ML applications transcend from research to productive use in real-world industrial environments, the question of reliability arises. Since the majority of ML models are trained and evaluated on static datasets, continuous online monitoring of their performance is required to build reliable systems. Furthermore, concept and sensor drift can lead to degrading accuracy of the algorithm over time, thus compromising safety, acceptance and economics if undetected and not properly addressed. In this work, we exemplarily highlight the severity of the issue on a publicly available industrial dataset which was recorded over the course of 36 months and explain possible sources of drift. We assess the robustness of ML algorithms commonly used in manufacturing and show, that the accuracy strongly declines with increasing drift for all tested algorithms. We further investigate how uncertainty estimation may be leveraged for online performance estimation as well as drift detection as a first step towards continually learning applications. The results indicate, that ensemble algorithms like random forests show the least decay of confidence calibration under drift.","",""
1,"Khaled A. Ismail, M. A. E. Ghany","Survey on Machine Learning Algorithms Enhancing the Functional Verification Process",2021,"","","","",104,"2022-07-13 09:23:47","","10.3390/electronics10212688","","",,,,,1,1.00,1,2,1,"The continuing increase in functional requirements of modern hardware designs means the traditional functional verification process becomes inefficient in meeting the time-to-market goal with sufficient level of confidence in the design. Therefore, the need for enhancing the process is evident. Machine learning (ML) models proved to be valuable for automating major parts of the process, which have typically occupied the bandwidth of engineers; diverting them from adding new coverage metrics to make the designs more robust. Current research of deploying different (ML) models prove to be promising in areas such as stimulus constraining, test generation, coverage collection and bug detection and localization. An example of deploying artificial neural network (ANN) in test generation shows 24.5× speed up in functionally verifying a dual-core RISC processor specification. Another study demonstrates how k-means clustering can reduce redundancy of simulation trace dump of an AHB-to-WHISHBONE bridge by 21%, thus reducing the debugging effort by not having to inspect unnecessary waveforms. The surveyed work demonstrates a comprehensive overview of current (ML) models enhancing the functional verification process from which an insight of promising future research areas is inferred.","",""
0,"Chi-ting Ho, Dawei Wang","Robust identification of topological phase transition by self-supervised machine learning approach",2021,"","","","",105,"2022-07-13 09:23:47","","10.1088/1367-2630/ac1709","","",,,,,0,0.00,0,2,1,"We propose a systematic methodology to identify the topological phase transition through a self-supervised machine learning model, which is trained to correlate system parameters to the non-local observables in time-of-flight experiments of ultracold atoms. Different from the conventional supervised learning approach, where the predicted phase transition point is very sensitive to the training region and data labeling, our self-supervised learning approach identifies the phase transition point by the largest deviation of the predicted results from the known system parameters and by the highest confidence through a systematic shift of the training regions. We demonstrate the robust application of this approach results in various 1D and 2D exactly solvable models, using different input features (time-of-flight images, spatial correlation function or density–density correlation function). As a result, our self-supervised approach should be a very general and reliable method for many condensed matter or solid state systems to observe new states of matters solely based on experimental measurements, even without a priori knowledge of the phase transition models.","",""
0,"Luyu Zeng, Zhong Zheng, Rui Zhang","Pneumonia X-ray Imaging Classification Based on an Interpretable Machine Learning Model",2021,"","","","",106,"2022-07-13 09:23:47","","10.1109/CONF-SPML54095.2021.00067","","",,,,,0,0.00,0,3,1,"The outbreak of Covld-19 has put tremendous pressure on medical systems around the world. The highly infectious nature of this respiratory disease challenges advanced diagnostic technology to achieve rapid, scalable, affordable, and high-precision testing. In previous studies, Tsiknakis used Convolutional Neural Network (CNN) and transfer learning to achieved high accuracy in distinguishing the lung X-ray images of Covid-19 infectors and healthy people. However, its accuracy is not so high in quaternary classification (Bacterial Pneumonia, Covidl9, Normal, and Viral Pneumonia). It can hardly distinguish between bacterial pneumonia and viral pneumonia. Based on CNN, transfer learning, and interpretable machine learning methods, this work precisely implements data processing and augmentation and adds a second binary classifier following a confidence level. In this way, the accuracy and recall rate of the quaternary classification are significantly improved, especially for bacterial pneumonia and viral pneumonia, and the model also becomes more interpretable.","",""
0,"Chao An, Hongcai Yang, Xiaoling Yu, Zhi-yu Han, Zhigang Cheng, Fang-yi Liu, J. Dou, Bin Li, Yichao Li, Yansheng Li, Jie Yu, P. Liang","A Machine Learning Model Based on Electronic Health Records for Predicting Recurrence after Microwave Ablation of Hepatocellular Carcinoma",2021,"","","","",107,"2022-07-13 09:23:47","","10.2139/ssrn.3901789","","",,,,,0,0.00,0,12,1,"Purpose: To investigate the accuracy and robustness of machine learning(ML) model using clinical data extracted directly from electronic health records for predicting the recurrence risk after microwave ablation(MWA).    Methods: Between August 2005 and December 2019, 1574 HCC patients who subsequently underwent MWA from four hospitals were reviewed. Data were assigned to the training, internal and external validation set, respectively. Apart from traditional logistic regression(LR), three ML models including (Random Forest, Support Vector Machine and eXtreme Gradient Boosting[XGBoost]) were built and validated in the predictive ability with area under receiving operator characteristic (AUC). SHapley Additive exPlanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME) algorithm were performed to realize their interpretability.    Results: After 26.2 months of median follow-up period(interquartile range, 6.3, 160.7 months), 51.9%(817/1574) patients occur recurrence. The predictive abilities of three ML models outperformed LR (P < 0.05 for all). When 9 variables were trained simultaneouly using recursive feature elimination with cross-validation, the XGBoost model achieved top predictive ability with AUC value (0.75, 95% CI [confidence interval]: 0.72-0.78) in training set, (0.74, 95% CI: 0.69-0.80) in internal set and (0.76, 95% CI: 0.70-0.82) in external validation set among all models, and it was interpreted depending on the visualization of risk factors by the SHAP and LIME algorithms. The predictive system of post-ablation recurrence risk stratification was provided on online (http://114.251.235.51:8001/) based on XGboost analysis.    Conclusions: The XGBoost model based on clinical data can effectively predict recurrence risk after MWA, which can contribute to surveillance, prevention and treatment strategies for HCC.    Funding: None to declare.    Declaration of Interest: None to declare.    Ethical Approval: This retrospective, multi-center study protocol was approved by the Ethics Committee of all participating institutions","",""
0,"W. Zong, Yang-Wai Chow, W. Susilo","Visual Analysis of Adversarial Examples in Machine Learning",2021,"","","","",108,"2022-07-13 09:23:47","","10.1007/978-981-33-6726-5_4","","",,,,,0,0.00,0,3,1,"","",""
0,"S. Saha, H. Singh, A. Soliman, S. Rajasekaran","A novel computational methodology for GWAS multi-locus analysis based on graph theory and machine learning",2021,"","","","",109,"2022-07-13 09:23:47","","10.1101/2021.10.22.21265388","","",,,,,0,0.00,0,4,1,"Background: Current form of genome-wide association studies (GWAS) is inadequate to accurately explain the genetics of complex traits due to the lack of sufficient statistical power. It explores each variant individually, but current studies show that multiple variants with varying effect sizes actually act in a concerted way to develop a complex disease. To address this issue, we have developed an algorithmic framework that can effectively solve the multi-locus problem in GWAS with a very high level of confidence. Our methodology consists of three novel algorithms based on graph theory and machine learning. It identifies a set of highly discriminating variants that are stable and robust with little (if any) spuriousness. Consequently, likely these variants should be able to interpret missing heritability of a convoluted disease as an entity. Results: To demonstrate the efficacy of our proposed algorithms, we have considered astigmatism case-control GWAS dataset. Astigmatism is a common eye condition that causes blurred vision because of an error in the shape of the cornea. The cause of astigmatism is not entirely known but a sizable inheritability is assumed. Clinical studies show that developmental disorders (such as, autism) and astigmatism co-occur in a statistically significant number of individuals. By performing classical GWAS analysis, we didn't find any genome-wide statistically significant variants. Conversely, we have identified a set of stable, robust, and highly predictive variants that can together explain the genetics of astigmatism. We have performed a set of biological enrichment analyses based on gene ontology (GO) terms, disease ontology (DO) terms, biological pathways, network of pathways, and so forth to manifest the accuracy and novelty of our findings. Conclusions: Rigorous experimental evaluations show that our proposed methodology can solve GWAS multi-locus problem effectively and efficiently. It can identify signals from the GWAS dataset having small number of samples with a high level of accuracy. We believe that the proposed methodology based on graph theory and machine learning is the most comprehensive one compared to any other machine learning based tools in this domain.","",""
0,"Kuan-Chen Chin, Yujie Cheng, Jen-Tang Sun, Chih-Yen Ou, Chun-Hua Hu, Ming-Chi Tsai, M. Ma, Albert Y. Chen, Wen-Chu Chiang","Accuracy Enhancement of Early Triage for Severely Injured Patients in Emergency Medical Dispatch through Machine Learning Based Text Analysis (Preprint)",2021,"","","","",110,"2022-07-13 09:23:47","","10.2196/preprints.30210","","",,,,,0,0.00,0,9,1,"  BACKGROUND  Early recognition of severely injured patients in prehospital settings is of paramount importance for timely treatment and patient transport. The accuracy of dispatching has seldom been addressed in previous studies.      OBJECTIVE  In this study, we aimed to build a machine learning-based model through text mining of emergency calls for automated identification of severely injured patients in road accidents.      METHODS  Audio recordings of road accidents in Taipei City in 2018 were retrieved and randomly sampled. Data on transferring calls or non-Mandarin speech were excluded. All the included cases were evaluated by both humans (six dispatchers) and a machine learning model (prehospital activated major trauma (PAMT) model) to predict the major trauma cases identified by emergency medical technicians at the scene. The PAMT model was developed using frequency–inverse document frequency (TF-IDF), rule-based classification, and Bernoulli Naïve Bayes (BNB) classifier, and bootstrapping was applied to evaluate the robustness. The tests of prediction, including sensitivity (SENS), specificity (SPEC), positive predictive value (PPV), negative predictive value (NPV), and accuracy (ACC), for dispatchers and the PAMT model were performed, and the results were compared in terms of the overall performance and among different certainty levels.      RESULTS  The means for dispatchers vs. the PAMT model were SENS 63.1% vs. 68.0%, SPEC 85.0% vs. 78.0%, PPV 71.7% vs. 60.6%, NPV 80.3% vs. 85.8%, and ACC 76.8% vs. 75.0%, respectively. The mean ACC of dispatchers vs. the PAMT model in the cases from certainty level 0 (the lowest certainty) to 6 (the highest certainty) were 66.7% vs. 83.3%, 64.3% vs. 70.4%, 68.2% vs. 72.7%, 76.4% vs. 91.7%, 56.9% vs. 58.3%, 79.8% vs. 64.3%, and 87.1% vs. 81.3%, respectively. The overall performances of dispatchers and the PAMT model were similar, but the PAMT model had higher accuracy when the dispatchers were less certain of their judgments.      CONCLUSIONS  The results of our study suggest that the machine learning model is not superior to dispatchers in identifying road accident calls with severe trauma cases; however, the model can assist dispatchers when they lack confidence in the judgment of the calls. ","",""
0,"A. Rathore, Anumeet Saini, Navjot Kaur, Aparna Singh, Ojasvi Dutta, Mrinal Bamhotra, A. Saini, Sandeep Saini","Amino Acid Composition and Charge Based Prediction of Antisepsis Peptides by Random Forest Machine Learning Algorithm",2021,"","","","",111,"2022-07-13 09:23:47","","10.1101/2021.09.26.461860","","",,,,,0,0.00,0,8,1,"Sepsis is a severe infectious disease with high mortality, and it occurs when chemicals released in the bloodstream to fight an infection trigger inflammation throughout the body and it can cause a cascade of changes that damage multiple organ systems, leading them to fail, even resulting in death. In order to reduce the possibility of sepsis or infection antiseptics are used and process is known as antisepsis. Antiseptic peptides (ASPs) show properties similar to antigram-negative peptides, antigram-positive peptides and many more. Machine learning algorithms are useful in screening and identification of therapeutic peptides and thus provide initial filters or built confidence before using time consuming and laborious experimental approaches. In this study, various machine learning algorithms like Support Vector Machine (SVM), Random Forest (RF), K-Nearest Neighbour (KNN) and Logistic Regression (LR) were evaluated for prediction of ASPs. Moreover, the characteristics physicochemical features of ASPs were also explored to use them in machine learning. Both manual and automatic feature selection methodology was employed to achieve best performance of machine learning algorithms. A 5-fold cross validation and independent data set validation proved RF as the best model for prediction of ASPs. Our RF model showed an accuracy of 97%, Matthew’s Correlation Coefficient (MCC) of 0.93, which are indication of a robust and good model. To our knowledge this is the first attempt to build a machine learning classifier for prediction of ASPs.","",""
0,"S. Taha-Mehlitz, L. Wentzler, F. Angehrn, A. Hendie, V. Ochs, V. Staartjes, M. von Fluee, A. Taha, D. Steinemann","Machine-learning based preoperative analytics for the prediction of anastomotic insufficiency in colorectal surgery: a single-centre pilot study",2021,"","","","",112,"2022-07-13 09:23:47","","10.1101/2021.12.11.21267569","","",,,,,0,0.00,0,9,1,"Background: Anastomotic insufficiency (AI) is a relatively common but grave complication after colorectal surgery. This study aims to determine whether AI can be predicted from simple preoperative data using machine learning (ML) algorithms. Methods: In this retrospective analysis, patients undergoing colorectal surgery with creation of a bowel anastomosis from the University Hospital of Basel were included. Data was split into a training set (80%) and a test set (20%). The group of patients with AI was oversampled to a ratio of 50:50 in the training set and missing values were imputed. Known predictors of AI were included as inputs: age, gender, BMI, smoking status, alcohol abuse, prior abdominal surgery, leukocytosis, haemoglobin and albumin levels, steroid use, the Charlson Comorbidity Index, the American Society of Anesthesiologists score, and renal function. Results: Of the 593 included patients, 88 experienced AI. At internal validation on unseen patients from the test set, area under the curve (AUC) was 0.64 (95% confidence interval [CI]: 0.44-0.82), calibration slope was 0.21 (95% CI: -0.02-0.46) and calibration intercept was 0.06 (95% CI: 0.01-0.1). We observed a specificity of 0.76 (95% CI: 0.68-0.84), sensitivity of 0.36 (95% CI: 0.08-0.7), and accuracy of 0.72 (95% CI: 0.65-0.8). Conclusion: By using 13 patient-related risk factors associated with AI, we demonstrate the feasibility of ML-based prediction of AI after colorectal surgery. Nevertheless, it is crucial to include multicenter data and higher sample sizes to develop a robust and generalizable model, which will subsequently allow for deployment of the algorithm in a web-based application.","",""
0,"M. Ntampaka, Matthew Ho, B. Nord","Building Trustworthy Machine Learning Models for Astronomy",2021,"","","","",113,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,3,1,". Astronomy is entering an era of data-driven discovery, due in part to modern machine learning (ML) techniques enabling powerful new ways to interpret observations. This shift in our scientiﬁc approach requires us to consider whether we can trust the black box. Here, we overview methods for an often-overlooked step in the development of ML models: building community trust in the algorithms. Trust is an essential ingredient not just for creating more robust data analysis techniques, but also for building conﬁdence within the astronomy community to embrace machine learning methods and results.","",""
0,"L. Gallagher, Jill M. Williams, Drew Lazzeri, Calla Chennault, S. Jourdain, P. O'Leary, L. Condon, R. Maxwell","Sandtank-ML: An Educational Tool at the Interface of Hydrology and Machine Learning",2021,"","","","",114,"2022-07-13 09:23:47","","10.3390/w13233328","","",,,,,0,0.00,0,8,1,"Hydrologists and water managers increasingly face challenges associated with extreme climatic events. At the same time, historic datasets for modeling contemporary and future hydrologic conditions are increasingly inadequate. Machine learning is one promising technological tool for navigating the challenges of understanding and managing contemporary hydrological systems. However, in addition to the technical challenges associated with effectively leveraging ML for understanding subsurface hydrological processes, practitioner skepticism and hesitancy surrounding ML presents a significant barrier to adoption of ML technologies among practitioners. In this paper, we discuss an educational application we have developed—Sandtank-ML—to be used as a training and educational tool aimed at building user confidence and supporting adoption of ML technologies among water managers. We argue that supporting the adoption of ML methods and technologies for subsurface hydrological investigations and management requires not only the development of robust technologic tools and approaches, but educational strategies and tools capable of building confidence among diverse users.","",""
0,"Yan Zhou, Murat Kantarcioglu, B. Xi","A Game Theoretic Perspective on Adversarial Machine Learning and Related Cybersecurity Applications",2021,"","","","",115,"2022-07-13 09:23:47","","10.1002/9781119723950.ch13","","",,,,,0,0.00,0,3,1,"In cybersecurity applications where machine learning algorithms are increasingly used to detect vulnerabilities, a somewhat unique challenge arises as exploits targeting machine learning models are constantly devised by the attackers. Traditional machine learning models are no longer robust and reliable when they are under attack. The action and reaction between machine learning systems and the adversary can be modeled as a game between two or more players. Under well‐defined attack models, game theory can provide robustness guarantee for machine learning models that are otherwise vulnerable to application‐time data corruption. We review two cases of game theory‐based machine learning techniques: in one case, players play a zero sum game by following a minimax strategy, while in the other case, players play a sequential game with one player as the leader and the rest as the followers. Experimental results on e‐mail spam and web spam datasets are presented. In the zero sum game, we demonstrate that an adversarial SVM model built upon the minimax strategy is much more resilient to adversarial attacks than standard SVM and one‐class SVM models. We also show that optimal learning strategies derived to counter overly pessimistic attack models can produce unsatisfactory results when the real attacks are much weaker. In the sequential game, we demonstrate that the mixed strategy, allowing a player to randomize over available strategies, is the best solution in general without knowing what types of adversaries machine learning applications are facing in the wild. We also discuss scenarios where players' behavior may derail rational decision making and models that consider such decision risks.","",""
0,"Murilo Cruz Lopes, Marília de Matos Amorim, V. S. Freitas, R. Calumby","Survival Prediction for Oral Cancer Patients: A Machine Learning Approach",2021,"","","","",116,"2022-07-13 09:23:47","","10.5753/kdmile.2021.17466","","",,,,,0,0.00,0,4,1,"There is a high incidence of oral cancer in Brazil, with 150,000 new cases estimated for 2020-2022. In most cases, it is diagnosed at an advanced stage and are related to many risk factors. The Registro Hospitalar de Câncer (RHC), managed by Instituto Nacional de Câncer (INCA), is a nation-wide database that integrates cancer registers from several hospitals in Brazil. RHC is mostly an administrative database but also include clinical, socioeconomic and hospitalization data for each patient with a cancer diagnostic in the country. For these patients, prognostication is always a difficult task a demand multi-dimensional analysis. Therefore, exploiting large-scale data and machine intelligence approaches emerge as promising tool for computer-aided decision support on death risk estimation. Given the importance of this context, some works have reported high prognostication effectiveness, however with extremely limited data collections, relying on weak validation protocols or simple robustness analysis. Hence, this work describes a detailed workflow and experimental analysis for oral cancer patient survival prediction considering careful data curation and strict validation procedures. By exploiting multiple machine learning algorithms and optimization techniques the proposed approach allowed promising survival prediction effectiveness with F1 and AuC-ROC over 0.78 and 0.80, respectively. Moreover, a detailed analysis have shown that the minimization of different types of prediction errors were achieved by different models, which highlights the importance of the rigour in this kind of validation.","",""
33,"A. Samarakoon, K. Barros, Y. Li, M. Eisenbach, Qiang Zhang, F. Ye, V. Sharma, Z. Dun, Haidong Zhou, S. A. Grigera, C. Batista, D. Tennant","Machine-learning-assisted insight into spin ice Dy2Ti2O7",2019,"","","","",117,"2022-07-13 09:23:47","","10.1038/s41467-020-14660-y","","",,,,,33,11.00,3,12,3,"","",""
0,"X. Ruan, Ning Ding","Personal credit risk identification based on combined machine learning model",2021,"","","","",118,"2022-07-13 09:23:47","","10.1109/MLISE54096.2021.00008","","",,,,,0,0.00,0,2,1,"Personal credit risk assessment is essentially based on the classification of indicators or characteristic variables related to personal credit. Currently, a single model is often used to classify normal customers and defaulting customers. However, the single model may face the risk of a higher type II error rate, that is, defaulting customers are misjudged as normal customers. From the perspective of the combined model, this paper uses the confidence-weighted voting strategy to give a single model different weights to construct a C5.0-SVM combined model. The study finds that the total classification accuracy of the C5.0-SVM combined model is higher than that of the single model, and the type II error rate is lower than that of the single model.","",""
299,"J Zhang, M. Harman, Lei Ma, Yang Liu","Machine Learning Testing: Survey, Landscapes and Horizons",2019,"","","","",119,"2022-07-13 09:23:47","","10.1109/tse.2019.2962027","","",,,,,299,99.67,75,4,3,"This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.","",""
15,"Lin Li, X. Guo, N. Ansari","SmartLoc: Smart Wireless Indoor Localization Empowered by Machine Learning",2020,"","","","",120,"2022-07-13 09:23:47","","10.1109/TIE.2019.2931261","","",,,,,15,7.50,5,3,2,"Recently, machine learning (ML) has been widely adopted for fingerprint-based indoor localization because of its potency in delineating relationships between received signal strength (RSS) information and labels accurately. Existing ML-based indoor localization systems are less robust because they only adopt the output with the highest probability. This affects the final location estimate, hence compromising accuracy due to the severity of RSS fluctuations. Since different ML algorithms (MLAs) yield different performances, it is therefore intuitive to fuse predictions from multiple MLAs to improve the positioning performance in the presence of signal fluctuation. In this article, we propose SmartLoc, a smart wireless indoor localization framework to enhance indoor localization. In the offline phase, multiple MLAs are trained by utilizing an offline database. We further apply probability alignment to guarantee the predicted probabilities of each MLA at the same confidence level. In the online phase, given a testing RSS sample of a user at an unknown location, we extract the labels with probabilities greater than a certain threshold from each MLA to construct the space of candidate labels (SCL). The size of SCL can be adaptively determined by using our proposed dynamic size determination algorithm. Based on the SCL, we propose a probabilistic model to intelligently estimate the user's location by evaluating the label credibility simultaneously. A high label credibility indicates that the frequently occurred label is more likely to be true. Experimental results in a real changing environment verify the superiority of SmartLoc, outperforming the best among comparative methods by 10.8% in 75th percentile accuracy.","",""
24,"P. Zivich, A. Breskin","Machine Learning for Causal Inference: On the Use of Cross-fit Estimators",2020,"","","","",121,"2022-07-13 09:23:47","","10.1097/EDE.0000000000001332","","",,,,,24,12.00,12,2,2,"Supplemental Digital Content is available in the text. Background: Modern causal inference methods allow machine learning to be used to weaken parametric modeling assumptions. However, the use of machine learning may result in complications for inference. Doubly robust cross-fit estimators have been proposed to yield better statistical properties. Methods: We conducted a simulation study to assess the performance of several different estimators for the average causal effect. The data generating mechanisms for the simulated treatment and outcome included log-transforms, polynomial terms, and discontinuities. We compared singly robust estimators (g-computation, inverse probability weighting) and doubly robust estimators (augmented inverse probability weighting, targeted maximum likelihood estimation). We estimated nuisance functions with parametric models and ensemble machine learning separately. We further assessed doubly robust cross-fit estimators. Results: With correctly specified parametric models, all of the estimators were unbiased and confidence intervals achieved nominal coverage. When used with machine learning, the doubly robust cross-fit estimators substantially outperformed all of the other estimators in terms of bias, variance, and confidence interval coverage. Conclusions: Due to the difficulty of properly specifying parametric models in high-dimensional data, doubly robust estimators with ensemble learning and cross-fitting may be the preferred approach for estimation of the average causal effect in most epidemiologic studies. However, these approaches may require larger sample sizes to avoid finite-sample issues.","",""
3,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantitative comparison of Drosophila behavior annotations by human observers and a machine learning algorithm",2020,"","","","",122,"2022-07-13 09:23:47","","10.1101/2020.06.16.153130","","",,,,,3,1.50,1,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications. Significance Statement Accurate quantification of animal behaviors is fundamental to neuroscience. Here, we quantitatively assess how human choices influence the performance of automated classifiers trained by a machine-learning algorithm. We found that human decisions about the computational tracking method, the training images, and the images used for performance evaluation impact both the classifier outputs and how human observers interpret the results. These factors are sometimes overlooked but are critical, especially because animal behavior is itself inherently variable. Automated quantification of animal behavior is becoming increasingly prevalent: our results provide a model for bridging the gap between traditional human annotations and computer-based annotations. Systematic assessment of human choices is important for developing behavior classifiers that perform robustly in a variety of experimental conditions.","",""
4,"G. Whelan, D. McDowell","Machine Learning-Enabled Uncertainty Quantification for Modeling Structure–Property Linkages for Fatigue Critical Engineering Alloys Using an ICME Workflow",2020,"","","","",123,"2022-07-13 09:23:47","","10.1007/s40192-020-00192-2","","",,,,,4,2.00,2,2,2,"","",""
3,"Kyoung Sik Park, Seong Hoon Kim, J. Oh, Sung Young Kim","Highly accurate diagnosis of papillary thyroid carcinomas based on personalized pathways coupled with machine learning.",2020,"","","","",124,"2022-07-13 09:23:47","","10.1093/bib/bbaa336","","",,,,,3,1.50,1,4,2,"Thyroid nodules are neoplasms commonly found among adults, with papillary thyroid carcinoma (PTC) being the most prevalent malignancy. However, current diagnostic methods often subject patients to unnecessary surgical burden. In this study, we developed and validated an automated, highly accurate multi-study-derived diagnostic model for PTCs using personalized biological pathways coupled with a sophisticated machine learning algorithm. Surprisingly, the algorithm achieved near-perfect performance in discriminating PTCs from non-tumoral thyroid samples with an overall cross-study-validated area under the receiver operating characteristic curve (AUROC) of 0.999 (95% confidence interval [CI]: 0.995-1) and a Brier score of 0.013 on three independent development cohorts. In addition, the algorithm showed excellent generalizability and transferability on two large-scale external blind PTC cohorts consisting of The Cancer Genome Atlas (TCGA), which is the largest genomic PTC cohort studied to date, and the post-Chernobyl cohort, which includes PTCs reported after exposure to radiation from the Chernobyl accident. When applied to the TCGA cohort, the model yielded an AUROC of 0.969 (95% CI: 0.950-0.987) and a Brier score of 0.109. On the post-Chernobyl cohort, it yielded an AUROC of 0.962 (95% CI: 0.918-1) and a Brier score of 0.073. This algorithm also is robust against other various types of clinical scenarios, discriminating malignant from benign lesions as well as clinically aggressive thyroid cancer with poor prognosis from indolent ones. Furthermore, we discovered novel pathway alterations and prognostic signatures for PTC, which can provide directions for follow-up studies.","",""
2,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantifying influence of human choice on the automated detection of Drosophila behavior by a supervised machine learning algorithm",2020,"","","","",125,"2022-07-13 09:23:47","","10.1371/journal.pone.0241696","","",,,,,2,1.00,0,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications.","",""
4,"Peng Kang, P. Lama","Robust Resource Scaling of Containerized Microservices with Probabilistic Machine learning",2020,"","","","",126,"2022-07-13 09:23:47","","10.1109/UCC48980.2020.00031","","",,,,,4,2.00,2,2,2,"Large-scale web services are increasingly being built with many small modular components (microservices), which can be deployed, updated and scaled seamlessly. These microservices are packaged to run in a lightweight isolated execution environment (containers) and deployed on computing resources rented from cloud providers. However, the complex interactions and the contention of shared hardware resources in cloud data centers pose significant challenges in managing web service performance. In this paper, we present RScale, a robust resource scaling system that provides end-to-end performance guarantee for containerized microservices deployed in the cloud. RScale employs a probabilistic machine learning-based performance model, which can quickly adapt to changing system dynamics and directly provide confidence bounds in the predictions with minimal overhead. It leverages multi-layered data collected from container-level resource usage metrics and virtual machine-level hardware performance counter metrics to capture changing resource demands in the presence of multi-tenant performance interference. We implemented and evaluated RScale on NSF Cloud's Chameleon testbed using KVM for virtualization, Docker Engine for containerization and Kubernetes for container orchestration. Experimental results with an open-source microservices benchmark, Robot Shop, demonstrate the superior prediction accuracy and adaptiveness of our modeling approach compared to popular machine learning techniques. RScale meets the performance SLO (service-level-objective) targets for various microservice workflows even in the presence of multi-tenant performance interference and changing system dynamics.","",""
0,"E. Kondrateva, Polina Belozerova, M. Sharaev, Evgeny Burnaev, A. Bernstein, I. Samotaeva","Machine learning models reproducibility and validation for MR images recognition",2020,"","","","",127,"2022-07-13 09:23:47","","10.1117/12.2559525","","",,,,,0,0.00,0,6,2,"In the present work, we introduce a data processing and analysis pipeline, which ensures the reproducibility of machine learning models chosen for MR image recognition. The proposed pipeline is applied to solve the binary classification problems: epilepsy and depression diagnostics based on vectorized features from MR images. This model is then assessed in terms of classification performance, robustness and reliability of the results, including predictive accuracy on unseen data. The classification performance achieved with our approach compares favorably to ones reported in the literature, where usually no thorough model evaluation is performed.","",""
12,"Samuel Ackerman, E. Farchi, O. Raz, Marcel Zalmanovici, Parijat Dube","Detection of data drift and outliers affecting machine learning model performance over time",2020,"","","","",128,"2022-07-13 09:23:47","","","","",,,,,12,6.00,2,5,2,"A trained ML model is deployed on another `test' dataset where target feature values (labels) are unknown. Drift is distribution change between the training and deployment data, which is concerning if model performance changes. For a cat/dog image classifier, for instance, drift during deployment could be rabbit images (new class) or cat/dog images with changed characteristics (change in distribution). We wish to detect these changes but can't measure accuracy without deployment data labels. We instead detect drift indirectly by nonparametrically testing the distribution of model prediction confidence for changes. This generalizes our method and sidesteps domain-specific feature representation.  We address important statistical issues, particularly Type-1 error control in sequential testing, using Change Point Models (CPMs; see Adams and Ross 2012). We also use nonparametric outlier methods to show the user suspicious observations for model diagnosis, since the before/after change confidence distributions overlap significantly. In experiments to demonstrate robustness, we train on a subset of MNIST digit classes, then insert drift (e.g., unseen digit class) in deployment data in various settings (gradual/sudden changes in the drift proportion). A novel loss function is introduced to compare the performance (detection delay, Type-1 and 2 errors) of a drift detector under different levels of drift class contamination.","",""
0,"A. Chakrabarty, K. Berntorp, S. D. Cairano","Learning-based Parameter-Adaptive Reference Governors /Author=Chakrabarty, Ankush; Berntorp, Karl; Di Cairano, Stefano /CreationDate=July 3, 2020 /Subject=Control, Machine Learning",2020,"","","","",129,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,3,2,"Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example. American Control Conference (ACC) This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2020 201 Broadway, Cambridge, Massachusetts 02139 Learning-based Parameter-Adaptive Reference Governors Ankush Chakrabarty†, Karl Berntorp, Stefano Di Cairano Abstract—Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example.","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",130,"2022-07-13 09:23:47","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
2,"Victor Venturi, Holden L Parks, Zeeshan Ahmad, V. Viswanathan","Machine Learning Enabled Discovery of Application Dependent Design Principles for Two-dimensional Materials",2020,"","","","",131,"2022-07-13 09:23:47","","10.1088/2632-2153/ABA002","","",,,,,2,1.00,1,4,2,"The large-scale search for high-performing candidate 2D materials is limited to calculating a few simple descriptors, usually with first-principles density functional theory calculations. In this work, we alleviate this issue by extending and generalizing crystal graph convolutional neural networks to systems with planar periodicity, and train an ensemble of models to predict thermodynamic, mechanical, and electronic properties. To demonstrate the utility of this approach, we carry out a screening of nearly 45,000 structures for two largely disjoint applications: namely, mechanically robust composites and photovoltaics. An analysis of the uncertainty associated with our methods indicates the ensemble of neural networks is well-calibrated and has errors comparable with those from accurate first-principles density functional theory calculations. The ensemble of models allows us to gauge the confidence of our predictions, and to find the candidates most likely to exhibit effective performance in their applications. Since the datasets used in our screening were combinatorically generated, we are also able to investigate, using an innovative method, structural and compositional design principles that impact the properties of the structures surveyed and which can act as a generative model basis for future material discovery through reverse engineering. Our approach allowed us to recover some well-accepted design principles: for instance, we find that hybrid organic-inorganic perovskites with lead and tin tend to be good candidates for solar cell applications.","",""
0,"D. Efremenko, Himani Jain, Jian Xu","Two Machine Learning Based Schemes for Solving Direct and Inverse Problems of Radiative Transfer Theory",2020,"","","","",132,"2022-07-13 09:23:47","","10.51130/graphicon-2020-2-3-45","","",,,,,0,0.00,0,3,2,"Artificial neural networks (ANNs) are used to substitute computationally expensive radiative transfer models (RTMs) and inverse operators (IO) for retrieving optical parameters of the medium. However, the direct parametrization of RTMs and IOs by means of ANNs has certain drawbacks, such as loss of generality, computations of huge training datasets, robustness issues etc. This paper provides an analysis of different ANN-related methods, based on our results and those published by other authors. In particular, two techniques are proposed. In the first method, the ANN substitutes the eigenvalue solver in the discrete ordinate RTM, thereby reducing the computational time. Unlike classical RTM parametrization schemes based on ANN, in this method the resulting ANN can be used for arbitrary geometry and layer optical thicknesses. In the second method, the IO is trained by using the real measurements (preprocessed Level-2 TROPOMI data) to improve the stability of the inverse operator. This method provides robust results even without applying the Tikhonov regularization method.","",""
0,"Hany Ragab, Shaza I. Kaoud Abdelaziz, M. Elhabiby, S. Givigi, A. Noureldin","Machine Learning-based Visual Odometry Uncertainty Estimation for Low-cost Integrated Land Vehicle Navigation",2020,"","","","",133,"2022-07-13 09:23:47","","10.33012/2020.17740","","",,,,,0,0.00,0,5,2,"The reliability and robustness of an integrated positioning system are crucial in the fields of robotics and autonomous navigation. Utilizing inertial navigation systems (INS) with Real-Time Kinematic (RTK) Global Navigation Satellite System (GNSS) is not sufficient as the integrated navigation performance inevitably degrades in urban areas due to extended GNSS outages. For these reasons, multiple variants of visual odometry (VO) have been developed in hope to correct INS position, attitude, and bias estimates under challenging GNSS environments. However, state-of-the-art visual-inertial odometry (VIO) algorithms lack well-defined uncertainty estimations. The tuning of the noise covariance is done heuristically, which implies that data-dependent tuning is needed to achieve high performance or even convergence of the navigation filters. To tackle this issue, we propose Voronoi Diagram-aided Visual Inertial Odometry (VD-VIO), which makes use of Voronoi Diagrams by exploiting the impact of feature distribution to the end positioning and navigation solution. To model this error, we engineer a feature set specifically designed to provide insight into the VO performance. A multi-layer perceptron neural network (MLPNN) is then adopted to obtain positional and attitudinal confidence metrics, which are then used to adjust the error covariance matrix coefficients dynamically, thus enabling a better correction of IMU PVA and bias errors, hence improving the overall integrated navigation solution in case of GNSS outages. We illustrate the efficacy of the proposed method by showing the VIO/GNSS system’s performance with and without learned uncertainties.","",""
657,"Wieland Brendel, Jonas Rauber, M. Bethge","Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",2017,"","","","",134,"2022-07-13 09:23:47","","","","",,,,,657,131.40,219,3,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .","",""
34,"Narathip Reamaroon, M. Sjoding, Kaiwen Lin, T. Iwashyna, K. Najarian","Accounting for Label Uncertainty in Machine Learning for Detection of Acute Respiratory Distress Syndrome",2019,"","","","",135,"2022-07-13 09:23:47","","10.1109/JBHI.2018.2810820","","",,,,,34,11.33,7,5,3,"When training a machine learning algorithm for a supervised-learning task in some clinical applications, uncertainty in the correct labels of some patients may adversely affect the performance of the algorithm. For example, even clinical experts may have less confidence when assigning a medical diagnosis to some patients because of ambiguity in the patient's case or imperfect reliability of the diagnostic criteria. As a result, some cases used in algorithm training may be mislabeled, adversely affecting the algorithm's performance. However, experts may also be able to quantify their diagnostic uncertainty in these cases. We present a robust method implemented with support vector machines (SVM) to account for such clinical diagnostic uncertainty when training an algorithm to detect patients who develop the acute respiratory distress syndrome (ARDS). ARDS is a syndrome of the critically ill that is diagnosed using clinical criteria known to be imperfect. We represent uncertainty in the diagnosis of ARDS as a graded weight of confidence associated with each training label. We also performed a novel time-series sampling method to address the problem of intercorrelation among the longitudinal clinical data from each patient used in model training to limit overfitting. Preliminary results show that we can achieve meaningful improvement in the performance of algorithm to detect patients with ARDS on a hold-out sample, when we compare our method that accounts for the uncertainty of training labels with a conventional SVM algorithm.","",""
20,"Sae Won Choi, T. Ko, K. Hong, K. Kim","Machine Learning-Based Prediction of Korean Triage and Acuity Scale Level in Emergency Department Patients",2019,"","","","",136,"2022-07-13 09:23:47","","10.4258/hir.2019.25.4.305","","",,,,,20,6.67,5,4,3,"Objectives Triage is a process to accurately assess and classify symptoms to identify and provide rapid treatment to patients. The Korean Triage and Acuity Scale (KTAS) is used as a triage instrument in all emergency centers. The aim of this study was to train and compare machine learning models to predict KTAS levels. Methods This was a cross-sectional study using data from a single emergency department of a tertiary university hospital. Information collected during triage was used in the analysis. Logistic regression, random forest, and XGBoost were used to predict the KTAS level. Results The models with the highest area under the receiver operating characteristic curve (AUROC) were the random forest and XGBoost models trained on the entire dataset (AUROC = 0.922, 95% confidence interval 0.917–0.925 and AUROC = 0.922, 95% confidence interval 0.918–0.925, respectively). The AUROC of the models trained on the clinical data was higher than that of models trained on text data only, but the models trained on all variables had the highest AUROC among similar machine learning models. Conclusions Machine learning can robustly predict the KTAS level at triage, which may have many possibilities for use, and the addition of text data improves the predictive performance compared to that achieved by using structured data alone.","",""
17,"Vijay Kumar Pounraja, Gopal Jayakar, Matthew Jensen, Neil Kelkar, S. Girirajan","A machine-learning approach for accurate detection of copy number variants from exome sequencing",2019,"","","","",137,"2022-07-13 09:23:47","","10.1101/gr.245928.118","","",,,,,17,5.67,3,5,3,"Copy number variants (CNVs) are a major cause of several genetic disorders, making their detection an essential component of genetic analysis pipelines. Current methods for detecting CNVs from exome-sequencing data are limited by high false-positive rates and low concordance because of inherent biases of individual algorithms. To overcome these issues, calls generated by two or more algorithms are often intersected using Venn diagram approaches to identify “high-confidence” CNVs. However, this approach is inadequate, because it misses potentially true calls that do not have consensus from multiple callers. Here, we present CN-Learn, a machine-learning framework that integrates calls from multiple CNV detection algorithms and learns to accurately identify true CNVs using caller-specific and genomic features from a small subset of validated CNVs. Using CNVs predicted by four exome-based CNV callers (CANOES, CODEX, XHMM, and CLAMMS) from 503 samples, we demonstrate that CN-Learn identifies true CNVs at higher precision (∼90%) and recall (∼85%) rates while maintaining robust performance even when trained with minimal data (∼30 samples). CN-Learn recovers twice as many CNVs compared to individual callers or Venn diagram–based approaches, with features such as exome capture probe count, caller concordance, and GC content providing the most discriminatory power. In fact, ∼58% of all true CNVs recovered by CN-Learn were either singletons or calls that lacked support from at least one caller. Our study underscores the limitations of current approaches for CNV identification and provides an effective method that yields high-quality CNVs for application in clinical diagnostics.","",""
14,"Ihab S. Mohamed, A. Capitanelli, F. Mastrogiovanni, S. Rovetta, R. Zaccaria","Detection, localisation and tracking of pallets using machine learning techniques and 2D range data",2018,"","","","",138,"2022-07-13 09:23:47","","10.1007/s00521-019-04352-0","","",,,,,14,3.50,3,5,4,"","",""
0,"James Hammond, Nick Pepper, F. Montomoli, V. Michelassi","Machine Learning Methods in CFD for Turbomachinery: A Review",2022,"","","","",139,"2022-07-13 09:23:47","","10.3390/ijtpp7020016","","",,,,,0,0.00,0,4,1,"Computational Fluid Dynamics is one of the most relied upon tools in the design and analysis of components in turbomachines. From the propulsion fan at the inlet, through the compressor and combustion sections, to the turbines at the outlet, CFD is used to perform fluid flow and heat transfer analyses to help designers extract the highest performance out of each component. In some cases, such as the design point performance of the axial compressor, current methods are capable of delivering good predictive accuracy. However, many areas require improved methods to give reliable predictions in order for the relevant design spaces to be further explored with confidence. This paper illustrates recent developments in CFD for turbomachinery which make use of machine learning techniques to augment prediction accuracy, speed up prediction times, analyse and manage uncertainty and reconcile simulations with available data. Such techniques facilitate faster and more robust searches of the design space, with or without the help of optimization methods, and enable innovative designs which keep pace with the demand for improved efficiency and sustainability as well as parts and asset operation cost reduction.","",""
0,"Xin Li, Bo Liu, P. Cui, Xingxing Zhao, Zhao Liu, Yan-hong Qi, Gangling Zhang","Integrative Analysis of Peripheral Blood Indices for the Renal Sinus Invasion Prediction of T1 Renal Cell Carcinoma: An Ensemble Study Using Machine Learning-Assisted Decision-Support Models",2022,"","","","",140,"2022-07-13 09:23:47","","10.2147/CMAR.S348694","","",,,,,0,0.00,0,7,1,"Purpose Renal sinus invasion is an attributive factor affecting the prognosis of renal cell carcinoma (RCC). This study aimed to construct a risk prediction model that could stratify patients with RCC and predict renal sinus invasion with the help of a machine learning (ML) algorithm. Patients and Methods We retrospectively recruited 1229 patients diagnosed with T1 stage RCC at the Baotou Cancer Hospital between November 2013 and August 2021. Iterative analysis was used to screen out predictors related to renal sinus invasion, after which ML-based models were developed to predict renal sinus invasion in patients with T1 stage RCC. The receiver operating characteristic curve (ROC), decision curve analysis (DCA), and clinical impact curve (CIC) were performed to evaluate the robustness and clinical practicability of each model. Results A total of 21 candidate variables were shortlisted for model building. Iterative analysis screened that neutrophil to albumin ratio (NAR), hemoglobin level * albumin level * lymphocyte count/platelet count ratio (HALP), prognostic nutrition index (PNI), body mass index*serum albumin/neutrophil-lymphocyte ratio (AKI), NAR, and fibrinogen (FIB) concentration (NARFIB), platelet to lymphocyte ratio (PLR), and R.E.N.A.L score was related to renal sinus invasion and contributed significantly to ML-based algorithm. The areas under the ROC curve (AUCs) of the random forest classifier (RFC) model, support vector machine (SVM), eXtreme gradient boosting (XGBoost), artificial neural network (ANN), and decision tree (DT) ranged from 0.797 to 0.924. The optimal risk probability of renal sinus invasion predicted was RFC (AUC = 0.924, 95% confidence interval [CI]: 0.414–1.434), which showed robust discrimination for identifying high-risk patients. Conclusion We successfully develop practical models for renal sinus invasion prediction, particularly the RFC, which could contribute to early detection via integrating systemic inflammatory factors and nutritional parameters.","",""
0,"ShanShan Hu, Shengying Gu, Shuowen Wang, C. Qi, Chenyang Shi, Feng-huan Qian, G. Fan","Robust Prediction of Prognosis and Immunotherapy Response for Bladder Cancer through Machine Learning Algorithm",2022,"","","","",141,"2022-07-13 09:23:47","","10.3390/genes13061073","","",,,,,0,0.00,0,7,1,"The important roles of machine learning and ferroptosis in bladder cancer (BCa) are still poorly understood. In this study, a comprehensive analysis of 19 ferroptosis-related genes (FRGs) was performed in 1322 patients with BCa from four independent patient cohorts and a pan-cancer cohort of 9824 patients. Twelve FRGs were selected through machine learning algorithm to construct the prognosis model. Significantly differential survival outcomes (hazard ratio (HR) = 2.09, 95% confidence interval (CI): 1.55–2.82, p < 0.0001) were observed between patients with high and low ferroptosis scores in the TCGA cohort, which was also verified in the E-MTAB-4321 cohort (HR = 4.71, 95% CI: 1.58–14.03, p < 0.0001), the GSE31684 cohort (HR = 1.76, 95% CI: 1.08–2.87, p = 0.02), and the pan-cancer cohort (HR = 1.15, 95% CI: 1.07–1.24, p < 0.0001). Tumor immunity-related pathways, including the IL-17 signaling pathway and JAK-STAT signaling pathway, were found to be associated with the ferroptosis score in BCa through a functional enrichment analysis. Further verification in the IMvigor210 cohort revealed the BCa patients with high ferroptosis scores tended to have worse survival outcome after receiving tumor immunotherapy. Significantly different ferroptosis scores could also be found between BCa patients with different reactions to treatment with immune checkpoint inhibitors.","",""
0,"S. Mordensky, J. Lipor, J. DeAngelo, E. Burns, Cary R. Lindsey","Predicting Geothermal Favorability in the Western United States by Using Machine Learning: Addressing Challenges and Developing Solutions",2022,"","","","",142,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,5,1,"Previous moderate- and high-temperature geothermal resource assessments of the western United States utilized weight-of-evidence and logistic regression methods to estimate resource favorability, but these analyses relied upon some expert decisions. While expert decisions can add confidence to aspects of the modeling process by ensuring only reasonable models are employed, expert decisions also introduce human bias into assessments. This bias presents a source of error that may affect the performance of the models and resulting resource estimates. Our study aims to reduce expert input through robust data-driven analyses and better-suited data science techniques, with the goals of saving time, reducing bias, and improving predictive ability. We present six favorability maps for geothermal resources in the western United States created using two strategies applied to three modern machine learning algorithms (logistic regression, support-vector machines, and XGBoost). To provide a direct comparison to previous assessments, we use the same input data as the 2008 U.S. Geological Survey (USGS) conventional moderate- to high-temperature geothermal resource assessment. The six new favorability maps required far less expert decision-making, but broadly agree with the previous assessment. Despite the fact that the 2008 assessment results employed linear methods, the non-linear machine learning algorithms ( i.e., support-vector machines and XGBoost) produced greater agreement with the previous assessment than the linear machine learning algorithm ( i.e., logistic regression). It is not surprising that geothermal systems depend on non-linear combinations of features, and we postulate that the expert decisions during the 2008 assessment accounted for system non-linearities. Substantial challenges to applying machine learning algorithms to predict geothermal resource favorability include severe class imbalance ( i.e., there are very few known geothermal systems compared to the large area considered), and while there are known geothermal systems ( i.e., positive labels), all other sites have an unknown status ( i.e., they are unlabeled), instead of receiving a negative label ( i.e., the known/proven absence of a geothermal resource). We address both challenges through a custom undersampling strategy that can be used with any algorithm and then evaluated using F1 scores. for XGBoost: class weight, learning rate, number of estimators, and maximum depth of estimators. Class weight in XGBoost differs in exact implementation compared with logistic regression and SVMs, but this hyperparameter serves much the same purpose: a greater class weight places greater emphasis on accurately predicting positive labels ( i.e., known geothermal systems) than non-positive labels ( i.e., unknown resource potential). The other parameters are used to maximize prediction performance while also avoiding overfitting (Chen and Guestrin, 2016). We leave the other parameters of XGBoost at the default values found in Python’s XGBoost module as they pertain to the specifics of the optimization routine and have only a modest impact on performance (Chen and Guestrin, 2016).","",""
9,"Ayman Yafouz, A. Ahmed, N. Zaini, M. Sherif, Ahmed Sefelnasr, A. El-Shafie","Hybrid deep learning model for ozone concentration prediction: comprehensive evaluation and comparison with various machine and deep learning algorithms",2021,"","","","",143,"2022-07-13 09:23:47","","10.1080/19942060.2021.1926328","","",,,,,9,9.00,2,6,1,"To accurately predict tropospheric ozone concentration(O3), it is needed to investigate the variety of artificial intelligence techniques’ performance, such as machine learning, deep learning and hybrid models. This research aims to effectively predict the hourly ozone trend via fewer input variables. This ozone prediction attempt is performed on diversity data of air pollutants (NO2, NOx, CO, SO2) and meteorological parameters (wind-speed and humidity). The historical datasets are collected from 3 sites in Malaysia. The study’s methodology progressed in two paths: standalone and hybrid models where hourly-averaged datasets are applied based on 5-time horizon analysis scenario, with different inputs’ combinations. For evaluation, all models are tested throughout 5-performance indicator and illustrated on Modified Taylor diagram. Sensitivity analysis of input variables is quantified. Additionally, uncertainty analysis is conducted to assess their confidence level associated with Willmott Index. Based on R 2, results indicated that XGBoost has higher accuracy compared to MLP and SVR; meanwhile, LSTM and CNN outweighs XGBoost. In terms of robustness and accuracy, the proposed hybrid model possesses superlative performance compared to all above-mentioned techniques. The proposed model achieved exceptional results as the highest R 2, the highest 95% confidence degree, and narrower confidence interval width, are 93.48%, 98.16%, and 0.0014195, respectively.","",""
11,"B. Celik, J. Vanschoren","Adaptation Strategies for Automated Machine Learning on Evolving Data",2020,"","","","",144,"2022-07-13 09:23:47","","10.1109/TPAMI.2021.3062900","","",,,,,11,5.50,6,2,2,"Automated Machine Learning (AutoML) systems have been shown to efficiently build good models for new datasets. However, it is often not clear how well they can adapt when the data evolves over time. The main goal of this study is to understand the effect of concept drift on the performance of AutoML methods, and which adaptation strategies can be employed to make them more robust to changes in the underlying data. To that end, we propose 6 concept drift adaptation strategies and evaluate their effectiveness on a variety of AutoML approaches for building machine learning pipelines, including Bayesian optimization, genetic programming, and random search with automated stacking. These are evaluated empirically on real-world and synthetic data streams with different types of concept drift. Based on this analysis, we propose ways to develop more sophisticated and robust AutoML techniques.","",""
320,"S. Raschka","Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning",2018,"","","","",145,"2022-07-13 09:23:47","","","","",,,,,320,80.00,320,1,4,"The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.","",""
14,"B. Ansell, B. Pope, P. Georgeson, Samantha J. Emery-Corbin, A. Jex","Annotation of the Giardia proteome through structure-based homology and machine learning",2018,"","","","",146,"2022-07-13 09:23:47","","10.1093/gigascience/giy150","","",,,,,14,3.50,3,5,4,"Abstract Background Large-scale computational prediction of protein structures represents a cost-effective alternative to empirical structure determination with particular promise for non-model organisms and neglected pathogens. Conventional sequence-based tools are insufficient to annotate the genomes of such divergent biological systems. Conversely, protein structure tolerates substantial variation in primary amino acid sequence and is thus a robust indicator of biochemical function. Structural proteomics is poised to become a standard part of pathogen genomics research; however, informatic methods are now required to assign confidence in large volumes of predicted structures. Aims Our aim was to predict the proteome of a neglected human pathogen, Giardia duodenalis, and stratify predicted structures into high- and lower-confidence categories using a variety of metrics in isolation and combination. Methods We used the I-TASSER suite to predict structural models for ∼5,000 proteins encoded in G. duodenalis and identify their closest empirically-determined structural homologues in the Protein Data Bank. Models were assigned to high- or lower-confidence categories depending on the presence of matching protein family (Pfam) domains in query and reference peptides. Metrics output from the suite and derived metrics were assessed for their ability to predict the high-confidence category individually, and in combination through development of a random forest classifier. Results We identified 1,095 high-confidence models including 212 hypothetical proteins. Amino acid identity between query and reference peptides was the greatest individual predictor of high-confidence status; however, the random forest classifier outperformed any metric in isolation (area under the receiver operating characteristic curve = 0.976) and identified a subset of 305 high-confidence-like models, corresponding to false-positive predictions. High-confidence models exhibited greater transcriptional abundance, and the classifier generalized across species, indicating the broad utility of this approach for automatically stratifying predicted structures. Additional structure-based clustering was used to cross-check confidence predictions in an expanded family of Nek kinases. Several high-confidence-like proteins yielded substantial new insight into mechanisms of redox balance in G. duodenalis—a system central to the efficacy of limited anti-giardial drugs. Conclusion Structural proteomics combined with machine learning can aid genome annotation for genetically divergent organisms, including human pathogens, and stratify predicted structures to promote efficient allocation of limited resources for experimental investigation.","",""
3,"Minsung Hong, R. Akerkar","Analytics and Evolving Landscape of Machine Learning for Emergency Response",2019,"","","","",147,"2022-07-13 09:23:47","","10.1007/978-3-030-15628-2_11","","",,,,,3,1.00,2,2,3,"","",""
3,"F. Lécué, B. Abeloos, Jonathan Anctil, Manuel Bergeron, Damien Dalla-Rosa, Simon Corbeil-Letourneau, Florian Martet, Tanguy Pommellet, L. Salvan, Simon Veilleux, M. Ziaeefard","Thales XAI Platform: Adaptable Explanation of Machine Learning Systems - A Knowledge Graphs Perspective",2019,"","","","",148,"2022-07-13 09:23:47","","","","",,,,,3,1.00,0,11,3,"Explanation in Machine Learning systems has been identified to be the main asset to have for large scale deployment of Artificial Intelligence (AI) in critical systems. Explanations could be example-, features-, semantics-based or even counterfactual to potentially action on an AI system; they could be represented in many different ways e.g., textual, graphical, or visual. All representations serve different means, purpose and operators. We built the first-of-its-kind XAI (eXplainable AI) platform for critical systems i.e., Thales XAI Platform which aims at serving explanations through various forms. This paper emphasizes on the semantics-based explanations for Machine Learning systems. 1 Explainable AI in Critical Systems Motivation: The current hype of Artificial Intelligence (AI) mostly refers to the success of Machine Learning (ML) and its sub-domain of deep learning. However industries operating with critical systems are either highly regulated, or require high level of certification and robustness. Therefore, such industry constraints do limit the adoption of non deterministic and ML systems. Answers to the question of explainability will be intrinsically connected to the adoption of AI in industry at scale. Indeed explanation, which could be used for debugging intelligent systems or deciding to follow a recommendation in real-time, will increase acceptance and (business) user trust. Explainable AI (XAI) is now referring to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. Focus: Thales XAI Platform is designed to provide explanation for a ML task (classification, regression, object detection, segmentation). Although Thales XAI Platform does provide different levels of explanation e.g., example-based, featuresbased, counterfactual using textual and visual representations, we emphasis only on the semantics-based explanation through knowledge graphs. ? Copyright c © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Critical Applications: From adapting a plane trajectory, stopping a train, refitting a boat to reconfiguring a satellite, all are examples of critical situations where explanation is a must-to-have to follow an AI system decision. 2 Why Knowledge Graphs for Explainable AI? State-of-the-Art Limitations: Most approaches limits explanation of ML systems to features involved in the data and model, or at best to examples, prototypes or counterfactuals. Explanation should go beyond correlation (features importance) and numerical similarity (local explanation). Opportunity: By expanding and linking initial (training, validation and test) data with entities in knowledge graphs, (i) context is encoded, (ii) connections and relations are exposed, and (iii) inference and causation are natively supported. Knowledge graphs are used for encoding better representation of data, structuring a ML model in a more interpretable way, and adopt a semantic similarity for local (instance-based) and global (model-based) explanation. 3 Thales XAI Platform: A Knowledge Graph Perspective (Semantic) Perspective: The platform is combining ML and reasoning functionalities to expose a human-like rational as explanation when (i) recognizing an object (in a raw image) of any class in a knowledge graph, (ii) predicting a link in a knowledge graph. Thales XAI Platform is using state-of-the-art Semantic Web tools for enriching input, output (class) data with DBpedia (4, 233, 000 resources) and domain-specific knowledge graphs, usually enterprise knowledge graphs. This is a crucial step for contextualizing training, validation, test data. Explainable ML Classifications: Starting from raw images, as unstructured data, but with class labels augmented with a domain knowledge graph, Thales XAI Platform relies on existing neural network architectures to build the most appropriate models. All confidence scores of output classes on any input image are updated based on the semantic description of the output classes. For instance, an input classified as a car will have a higher overall confidence score in case some properties of car in the knowledge graph are retrieved e.g., having wheels, being on a road. In addition the platform is embedding naturally explanation i.e., properties of the objects retrieved in both the raw data and knowledge graph. Explainable Relational Learning: Starting from relational data, structured as graph, and augmented with a domain knowledge graph, Thales XAI Platform relies on existing knowledge graph embeddings frameworks to build the most appropriate models. Explanation of any link prediction is retrieved by identifying representative hotspots in the knowledge graph i.e., connected parts of the graphs that negatively impact prediction accuracy when removed.","",""
3,"Yuanyuan Pu, D. Apel, Jie Chen, Chong Wei","A Gaussian process machine learning model for cemented rockfill strength prediction at a diamond mine",2019,"","","","",149,"2022-07-13 09:23:47","","10.1007/s00521-019-04517-x","","",,,,,3,1.00,1,4,3,"","",""
3,"Haoyu Yang, Wen Chen, P. Pathak, Frank Gennari, Ya-Chieh Lai, Bei Yu","Automatic Layout Generation with Applications in Machine Learning Engine Evaluation",2019,"","","","",150,"2022-07-13 09:23:47","","10.1109/MLCAD48534.2019.9142121","","",,,,,3,1.00,1,6,3,"Machine learning-based lithography hotspot detection has been deeply studied recently, from varies feature extraction techniques to efficient learning models. It has been observed that such machine learning-based frameworks are providing satisfactory metal layer hotspot prediction results on known public metal layer benchmarks. In this work, we seek to evaluate how these machine learning-based hotspot detectors generalize to complicated patterns. We first introduce a automatic layout generation tool that can synthesize varies layout patterns given a set of design rules. The tool currently supports both metal layer and via layer generation. As a case study, we conduct hotspot detection on the generated via layer layouts with representative machine learning-based hotspot detectors, which shows that continuous study on model robustness and generality is necessary to prototype and integrate the learning engines in DFM flows. The source code of the layout generation tool will be available at https://github.com/phdyang007/layout-generation.","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",151,"2022-07-13 09:23:47","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",152,"2022-07-13 09:23:47","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
0,"M. Little","Nonparametric Bayesian machine learning and signal processing",2019,"","","","",153,"2022-07-13 09:23:47","","10.1093/oso/9780198714934.003.0010","","",,,,,0,0.00,0,1,3,"We have seen that stochastic processes play an important foundational role in a wide range of methods in DSP. For example, we treat a discrete-time signal as a Gaussian process, and thereby obtain many mathematically simplified algorithms, particularly based on the power spectral density. At the same time, in machine learning, it has generally been observed that nonparametric methods outperform parametric methods in terms of predictive accuracy since they can adapt to data with arbitrary complexity. However, these techniques are not Bayesian so we are unable to do important inferential procedures such as draw samples from the underlying probabilistic model or compute posterior confidence intervals. But, Bayesian models are often only mathematically tractable if parametric, with the corresponding loss of predictive accuracy. An alternative, discussed in this section, is to extend the mathematical tractability of stochastic processes to Bayesian methods. This leads to so-called Bayesian nonparametrics exemplified by techniques such as Gaussian process regression and Dirichlet process mixture modelling that have been shown to be extremely useful in practical DSP and machine learning applications.","",""
3,"R. Brummelhuis, Zhongmin Luo","Bank Net Interest Margin Forecasting and Capital Adequacy Stress Testing by Machine Learning Techniques",2019,"","","","",154,"2022-07-13 09:23:47","","10.2139/ssrn.3282408","","",,,,,3,1.00,2,2,3,"The 2007-09 financial crisis revealed that the investors in the financial market were more concerned about the future as opposed to the current capital adequacy for banks. Stress testing promises to complement the regulatory capital adequacy regimes, which assess a bank's current capital adequacy, with the ability to assess its future capital adequacy based on the projected asset-losses and incomes from the forecasting models from regulators and banks. The effectiveness of stress-test rests on its ability to inform the financial market, which depends on whether or not the market has confidence in the model-projected asset-losses and incomes for banks. Post-crisis studies found that the stress-test results are uninformative and receive insignificant market reactions; others question its validity on the grounds of the poor forecast accuracy using linear regression models which forecast the banking-industry incomes measured by Aggregate Net Interest Margin. Instead, our study focuses on NIM forecasting at an individual bank's level and employs both linear regression and non-linear Machine Learning techniques. First, we present both the linear and non-linear Machine Learning regression techniques used in our study. Then, based on out-of-sample tests and literature-recommended forecasting techniques, we compare the NIM forecast accuracy by 162 models based on 11 different regression techniques, finding that some Machine Learning techniques as well as some linear ones can achieve significantly higher accuracy than the random-walk benchmark, which invalidates the grounds used by the literature to challenge the validity of stress-test. Last, our results from forecast accuracy comparisons are either consistent with or complement those from existing forecasting literature. We believe that the paper is the first systematic study on forecasting bank-specific NIM by Machine Learning Techniques; also, it is a first systematic study on forecast accuracy comparison including both linear and non-linear Machine Learning techniques using financial data for a critical real-world problem; it is a multi-step forecasting example involving iterative forecasting, rolling-origins, recalibration with forecast accuracy measure being scale-independent; robust regression proved to be beneficial for forecasting in presence of outliers. It concludes with policy suggestions and future research directions.","",""
3,"D. Priyanka, J. Nayak","Empirical Analysis of Absenteeism at Work Place Using Machine Learning",2019,"","","","",155,"2022-07-13 09:23:47","","10.1007/978-3-030-30271-9_15","","",,,,,3,1.00,2,2,3,"","",""
4,"Alexandra Renouard, A. Maggi, M. Grunberg, C. Doubre, C. Hibert","Toward False Event Detection and Quarry Blast versus Earthquake Discrimination in an Operational Setting Using Semiautomated Machine Learning",2021,"","","","",156,"2022-07-13 09:23:47","","10.1785/0220200305","","",,,,,4,4.00,1,5,1,"  Small-magnitude earthquakes shed light on the spatial and magnitude distribution of natural seismicity, as well as its rate and occurrence, especially in stable continental regions where natural seismicity remains difficult to explain under slow strain-rate conditions. However, capturing them in catalogs is strongly hindered by signal-to-noise ratio issues, resulting in high rates of false and man-made events also being detected. Accurate and robust discrimination of these events is critical for optimally detecting small earthquakes. This requires uncovering recurrent salient features that can rapidly distinguish first false events from real events, then earthquakes from man-made events (mainly quarry blasts), despite high signal variability and noise content. In this study, we combined the complementary strengths of human and interpretable rule-based machine-learning algorithms for solving this classification problem. We used human expert knowledge to co-create two reliable machine-learning classifiers through human-assisted selection of classification features and review of events with uncertain classifier predictions. The two classifiers are integrated into the SeisComP3 operational monitoring system. The first one discards false events from the set of events obtained with a low short-term average/long-term average threshold; the second one labels the remaining events as either earthquakes or quarry blasts. When run in an operational setting, the first classifier correctly detected more than 99% of false events and just over 93% of earthquakes; the second classifier correctly labeled 95% of quarry blasts and 96% of earthquakes. After a manual review of the second classifier low-confidence outputs, the final catalog contained fewer than 2% of misclassified events. These results confirm that machine learning strengthens the quality of earthquake catalogs and that the performance of machine-learning classifiers can be improved through human expertise. Our study promotes a broader implication of hybrid intelligence monitoring within seismological observatories.","",""
4,"Tonghua Liu, Shuo Cao, Sixuan Zhang, Xiaolong Gong, Wuzheng Guo, C. Zheng","Revisiting the cosmic distance duality relation with machine learning reconstruction methods: the combination of HII galaxies and ultra-compact radio quasars",2021,"","","","",157,"2022-07-13 09:23:47","","10.1140/epjc/s10052-021-09713-5","","",,,,,4,4.00,1,6,1,"","",""
20,"Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae","Engineering problems in machine learning systems",2019,"","","","",158,"2022-07-13 09:23:47","","10.1007/s10994-020-05872-w","","",,,,,20,6.67,7,3,3,"","",""
2,"Somayah Albaradei, Mahmut Uludag, Maha A. Thafar, T. Gojobori, M. Essack, Xin Gao","Predicting Bone Metastasis Using Gene Expression-Based Machine Learning Models",2021,"","","","",159,"2022-07-13 09:23:47","","10.3389/fgene.2021.771092","","",,,,,2,2.00,0,6,1,"Bone is the most common site of distant metastasis from malignant tumors, with the highest prevalence observed in breast and prostate cancers. Such bone metastases (BM) cause many painful skeletal-related events, such as severe bone pain, pathological fractures, spinal cord compression, and hypercalcemia, with adverse effects on life quality. Many bone-targeting agents developed based on the current understanding of BM onset’s molecular mechanisms dull these adverse effects. However, only a few studies investigated potential predictors of high risk for developing BM, despite such knowledge being critical for early interventions to prevent or delay BM. This work proposes a computational network-based pipeline that incorporates a ML/DL component to predict BM development. Based on the proposed pipeline we constructed several machine learning models. The deep neural network (DNN) model exhibited the highest prediction accuracy (AUC of 92.11%) using the top 34 featured genes ranked by betweenness centrality scores. We further used an entirely separate, “external” TCGA dataset to evaluate the robustness of this DNN model and achieved sensitivity of 85%, specificity of 80%, positive predictive value of 78.10%, negative predictive value of 80%, and AUC of 85.78%. The result shows the models’ way of learning allowed it to zoom in on the featured genes that provide the added benefit of the model displaying generic capabilities, that is, to predict BM for samples from different primary sites. Furthermore, existing experimental evidence provides confidence that about 50% of the 34 hub genes have BM-related functionality, which suggests that these common genetic markers provide vital insight about BM drivers. These findings may prompt the transformation of such a method into an artificial intelligence (AI) diagnostic tool and direct us towards mechanisms that underlie metastasis to bone events.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",160,"2022-07-13 09:23:47","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
1,"Yue Gao, Kassem Fawaz","Scale-Adv: A Joint Attack on Image-Scaling and Machine Learning Classifiers",2021,"","","","",161,"2022-07-13 09:23:47","","","","",,,,,1,1.00,1,2,1,"As real-world images come in varying sizes, the machine learning model is part of a larger system that includes an upstream image scaling algorithm. In this system, the model and the scaling algorithm have become attractive targets for numerous attacks, such as adversarial examples and the recent imagescaling attack. In response to these attacks, researchers have developed defense approaches that are tailored to attacks at each processing stage. As these defenses are developed in isolation, their underlying assumptions become questionable when viewing them from the perspective of an end-to-end machine learning system. In this paper, we investigate whether defenses against scaling attacks and adversarial examples are still robust when an adversary targets the entire machine learning system. In particular, we propose Scale-Adv, a novel attack framework that jointly targets the image-scaling and classification stages. This framework packs several novel techniques, including novel representations of the scaling defenses. It also defines two integrations that allow for attacking the machine learning system pipeline in the white-box and black-box settings. Based on this framework, we evaluate cutting-edge defenses at each processing stage. For scaling attacks, we show that Scale-Adv can evade four out of five state-of-the-art defenses by incorporating adversarial examples. For classification, we show that Scale-Adv can significantly improve the performance of machine learning attacks by leveraging weaknesses in the scaling algorithm. We empirically observe that Scale-Adv can produce adversarial examples with less perturbation and higher confidence than vanilla black-box and white-box attacks. We further demonstrate the transferability of Scale-Adv on a commercial online API.","",""
1,"F. Damen, David Newton, G. Lin, C. Goergen","Machine Learning Driven Contouring of High-Frequency Four-Dimensional Cardiac Ultrasound Data",2020,"","","","",162,"2022-07-13 09:23:47","","10.3390/app11041690","","",,,,,1,0.50,0,4,2,"Automatic boundary detection of 4D ultrasound (4DUS) cardiac data is a promising yet challenging application at the intersection of machine learning and medicine. Using recently developed murine 4DUS cardiac imaging data, we demonstrate here a set of three machine learning models that predict left ventricular wall kinematics along both the endo- and epi-cardial boundaries. Each model is fundamentally built on three key features: (1) the projection of raw US data to a lower dimensional subspace, (2) a smoothing spline basis across time, and (3) a strategic parameterization of the left ventricular boundaries. Model 1 is constructed such that boundary predictions are based on individual short-axis images, regardless of their relative position in the ventricle. Model 2 simultaneously incorporates parallel short-axis image data into their predictions. Model 3 builds on the multi-slice approach of model 2, but assists predictions with a single ground-truth position at end-diastole. To assess the performance of each model, Monte Carlo cross validation was used to assess the performance of each model on unseen data. For predicting the radial distance of the endocardium, models 1, 2, and 3 yielded average R2 values of 0.41, 0.49, and 0.71, respectively. Monte Carlo simulations of the endocardial wall showed significantly closer predictions when using model 2 versus model 1 at a rate of 48.67%, and using model 3 versus model 2 at a rate of 83.50%. These finding suggest that a machine learning approach where multi-slice data are simultaneously used as input and predictions are aided by a single user input yields the most robust performance. Subsequently, we explore the how metrics of cardiac kinematics compare between ground-truth contours and predicted boundaries. We observed negligible deviations from ground-truth when using predicted boundaries alone, except in the case of early diastolic strain rate, providing confidence for the use of such machine learning models for rapid and reliable assessments of murine cardiac function. To our knowledge, this is the first application of machine learning to murine left ventricular 4DUS data. Future work will be needed to strengthen both model performance and applicability to different cardiac disease models.","",""
1,"Bappaditya Dey, Stewart Wu, Sayantan Das, Kasem Khalil, S. Halder, P. Leray, Samir Bhamidipati, Kiarash Ahi, Mark Pereira, G. Fenger, M. Bayoumi","Unsupervised machine learning based SEM image denoising for robust contour detection",2021,"","","","",163,"2022-07-13 09:23:47","","10.1117/12.2600945","","",,,,,1,1.00,0,11,1,"Contour detection of an object is a fundamental computer vision problem in image processing domain. The goal is to find a concrete boundary for pixel ownership between an OOI (object-of-interest) and its corresponding background. However, contour extraction from low SN SEM images is a very challenging problem as different sources of noise shadow the estimation of underlying structural geometries. As device scaling continues to 3nm node and below, the extraction of accurate CD contour geometries from SEM images especially ADI (after developed inspection) is of utmost importance for a qualitative lithographic process as well as to verify device characterization in aggressive pitches. In this paper, we have applied a U-Net architecture based unsupervised machine learning approach for de-noising CD-SEM images. Unlike other discriminative deep-learning based de-noising approaches, the proposed method does not require any ground-truth as clean/noiseless images or synthetic noiseless images for training. Simultaneously, we have also attempted to demonstrate how de-noising is helping to improve the contour detection accuracy. We have analyzed and validated our result by using a programmable tool (SEMSuiteTM) for contour extraction. We have de-noised SEM images with categorically different geometrical patterns such as L/S (line-space), T2T (tip-to-tip), pillars with different scan types etc. and extracted the contours in both noisy and de-noised images. The comparative analysis demonstrates that de-noised images have higher confidence contour metric than their noisy twins while keeping the same parameter settings for both data input. When the ML algorithm is applied, the contour extraction results would have higher confidence numbers comparing with the ones only applied the conventional Gaussian or Median blur de-noise method. The final goal of this work is to establish a robust de-noising method to reduce the dependency of SEM image acquisition settings and provide more accurate metrology data for OPC calibration.","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",164,"2022-07-13 09:23:47","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
1,"Xiang Meng","Doubly robust, machine learning effect estimation in real-world clinical sciences: A practical evaluation of performance in molecular epidemiology cohort settings",2021,"","","","",165,"2022-07-13 09:23:47","","","","",,,,,1,1.00,1,1,1,"Modern efficient, semi-parametric estimators such as AIPW and TMLE facilitate the application of flexible (e.g. data-adaptive, non-smooth, machine learning) algorithms to improve treatment and outcome model fit, allowing for some model misspecification while still maintaining desired bias and variance properties. Recent simulation work has pointed to essential conditions for effective application including: the need for sample splitting (Chernozhukov et al. (2018), Naimi et al. (2021)), cross-fitting (Newey and Robins (2018), Zivich and Breskin (2021)), using of a broad library of well-tuned, flexible learners (Naimi et al. (2021), Balzer and Westling (2021)), and sufficiently large sample sizes (Benkeser et al. (2017), Pang et al. (2016), Balzer and Westling (2021)). In these settings, cross-fit, efficient estimators fit with ensemble flexible learning appear to be broadly superior to conventional alternatives, as theorized. However, commonly simulated conditions differ in important ways from settings in which these estimators may be most useful (Balzer and Westling (2021)) namely in high-dimensional, observational settings (Pang et al. (2016)). In such settings, such computationally-intensive and challenging to optimize estimators may have less of a practical advantage over simpler approaches. Here we present extensive simulation results drawing data on 331 covariates from 1178 subjects of a multi-omic, longitudinal birth cohort while fixing treatment and outcome effects. We attempt to estimate average causal effects under various misspecification conditions. In real-world data structures, we find in nearly every scenario that efficient estimators fit with smooth learners outperform those that include non-smooth, data-adaptive learners on the basis of bias and confidence interval coverage. For the typical setting where correct model specification is unlikely, it is possible that the use of double-cross-fit efficient estimators fit with ensembles of smooth learners may be a generally practical choice, taking 2-5 times less computation time than models fit with non-smooth algorithms while having equal or better performance.","",""
29,"Debbie Rankin, Michaela M. Black, R. Bond, J. Wallace, M. Mulvenna, G. Epelde","Reliability of Supervised Machine Learning Using Synthetic Data in Health Care: Model to Preserve Privacy for Data Sharing",2020,"","","","",166,"2022-07-13 09:23:47","","10.2196/18910","","",,,,,29,14.50,5,6,2,"Background The exploitation of synthetic data in health care is at an early stage. Synthetic data could unlock the potential within health care datasets that are too sensitive for release. Several synthetic data generators have been developed to date; however, studies evaluating their efficacy and generalizability are scarce. Objective This work sets out to understand the difference in performance of supervised machine learning models trained on synthetic data compared with those trained on real data. Methods A total of 19 open health datasets were selected for experimental work. Synthetic data were generated using three synthetic data generators that apply classification and regression trees, parametric, and Bayesian network approaches. Real and synthetic data were used (separately) to train five supervised machine learning models: stochastic gradient descent, decision tree, k-nearest neighbors, random forest, and support vector machine. Models were tested only on real data to determine whether a model developed by training on synthetic data can used to accurately classify new, real examples. The impact of statistical disclosure control on model performance was also assessed. Results A total of 92% of models trained on synthetic data have lower accuracy than those trained on real data. Tree-based models trained on synthetic data have deviations in accuracy from models trained on real data of 0.177 (18%) to 0.193 (19%), while other models have lower deviations of 0.058 (6%) to 0.072 (7%). The winning classifier when trained and tested on real data versus models trained on synthetic data and tested on real data is the same in 26% (5/19) of cases for classification and regression tree and parametric synthetic data and in 21% (4/19) of cases for Bayesian network-generated synthetic data. Tree-based models perform best with real data and are the winning classifier in 95% (18/19) of cases. This is not the case for models trained on synthetic data. When tree-based models are not considered, the winning classifier for real and synthetic data is matched in 74% (14/19), 53% (10/19), and 68% (13/19) of cases for classification and regression tree, parametric, and Bayesian network synthetic data, respectively. Statistical disclosure control methods did not have a notable impact on data utility. Conclusions The results of this study are promising with small decreases in accuracy observed in models trained with synthetic data compared with models trained with real data, where both are tested on real data. Such deviations are expected and manageable. Tree-based classifiers have some sensitivity to synthetic data, and the underlying cause requires further investigation. This study highlights the potential of synthetic data and the need for further evaluation of their robustness. Synthetic data must ensure individual privacy and data utility are preserved in order to instill confidence in health care departments when using such data to inform policy decision-making.","",""
0,"A. Nair, F. Yu, P. C. Jost, P. DeMott, E. Levin, J. Jimenez, J. Peischl, I. Pollack, C. Fredrickson, A. Beyersdorf, B. Nault, Minsu Park, S. Yum, B. Palm, Lu Xu, I. Bourgeois, B. Anderson, A. Nenes, L. Ziemba, R. Moore, Taehyoung Lee, T. Park, C. Thompson, F. Flocke, L. Huey, Michelle J. Kim, Q. Peng","Machine learning uncovers aerosol size information from chemistry and meteorology to quantify potential cloud-forming particles",2021,"","","","",167,"2022-07-13 09:23:47","","10.21203/rs.3.rs-244416/v1","","",,,,,0,0.00,0,27,1,"  Cloud condensation nuclei (CCN) are mediators of aerosol–cloud interactions, which contribute to the largest uncertainty in climate change prediction. Here, we present a machine learning/artificial intelligence model that quantifies CCN from variables of aerosol composition, atmospheric trace gases, and meteorology. Comprehensive multi-campaign airborne measurements, covering varied physicochemical regimes in the troposphere, confirm the validity of and help probe the inner workings of this machine learning model: revealing for the first time that different ranges of atmospheric aerosol composition and mass correspond to distinct aerosol number size distributions. Machine learning extracts this information, important for accurate quantification of CCN, additionally from both chemistry and meteorology. This can provide a physicochemically explainable, computationally efficient, robust machine learning pathway in global climate models that only resolve aerosol composition; potentially mitigating the uncertainty of effective radiative forcing due to aerosol–cloud interactions (ERFaci) and improving confidence in assessment of anthropogenic contributions and climate change projections.","",""
0,"Richard Brown, G. Bendiab, S. Shiaeles, B. Ghita","A Novel Multimodal Biometric Authentication System using Machine Learning and Blockchain",2021,"","","","",168,"2022-07-13 09:23:47","","10.1007/978-3-030-64758-2_3","","",,,,,0,0.00,0,4,1,"","",""
0,"A. Nair, F. Yu, P. Campuzano‐Jost, P. DeMott, E. Levin, J. Jimenez, J. Peischl, I. Pollack, C. Fredrickson, A. Beyersdorf, B. Nault, Minsu Park, S. Yum, B. Palm, Lu Xu, I. Bourgeois, B. Anderson, A. Nenes, L. Ziemba, R. Moore, Taehyoung Lee, T. Park, C. Thompson, F. Flocke, L. G. Huey, Michelle J. Kim, Q. Peng","Machine Learning Uncovers Aerosol Size Information From Chemistry and Meteorology to Quantify Potential Cloud‐Forming Particles",2021,"","","","",169,"2022-07-13 09:23:47","","10.1029/2021GL094133","","",,,,,0,0.00,0,27,1,"Cloud condensation nuclei (CCN) are mediators of aerosol‐cloud interactions, which contribute to the largest uncertainty in climate change prediction. Here, we present a machine learning (ML)/artificial intelligence (AI) model that quantifies CCN from model‐simulated aerosol composition, atmospheric trace gas, and meteorological variables. Comprehensive multi‐campaign airborne measurements, covering varied physicochemical regimes in the troposphere, confirm the validity of and help probe the inner workings of this ML model: revealing for the first time that different ranges of atmospheric aerosol composition and mass correspond to distinct aerosol number size distributions. ML extracts this information, important for accurate quantification of CCN, additionally from both chemistry and meteorology. This can provide a physicochemically explainable, computationally efficient, robust ML pathway in global climate models that only resolve aerosol composition; potentially mitigating the uncertainty of effective radiative forcing due to aerosol‐cloud interactions (ERFaci) and improving confidence in assessment of anthropogenic contributions and climate change projections.","",""
0,"J. Huang, Xiang Meng","521Performance of doubly-robust, machine learning effect estimators in realistic epidemiologic data settings and practical recommendations",2021,"","","","",170,"2022-07-13 09:23:47","","10.1093/ije/dyab168.293","","",,,,,0,0.00,0,2,1,"      Flexible, data-adaptive algorithms (machine learning; ML) for nuisance parameter estimation in epidemiologic causal inference have promising asymptotic properties for complex, high-dimensional data. However, recently proposed applications (e.g. targeted maximum likelihood estimation; TMLE) may produce biases parameter and standard error estimates in common real-world cohort settings. The relative performance of these novel estimators over simpler approaches in such settings is unclear.        We apply double-crossfit TMLE, augmented inverse probability weighting (AIPW), and standard IPW to simple simulations (5 covariates) and “real-world” data using covariate-structure-preserving (“plasmode”) simulations of 1,178 subjects and 331 covariates from a longitudinal birth cohort. We evaluate various data generating and estimation scenarios including: under- and over- (e.g. excess orthogonal covariates) identification, poor data support, near-instruments, and mis-specified biological interactions. We also track representative computation times.        We replicate optimal performance of cross-fit, doubly robust estimators in simple data generating processes. However, in nearly every real world-based scenario, estimators fit with parametric learners outperform those that include non-parametric learners in terms of mean bias and confidence interval coverage. Even when correctly specified, estimators fit with non-parametric algorithms (xgboost, random forest) performed poorly (e.g. 24% bias, 57% coverage vs. 10% bias, 79% coverage for parametric fit), at times underperforming simple IPW.        In typical epidemiologic data sets, double-crossfit estimators fit with simple smooth, parametric learners may be the optimal solution, taking 2-5 times less computation time than flexible non-parametric models, while having equal or better performance. No approaches are optimal, and estimators should be compared on simulations close to the source data.        In epidemiologic studies, use of flexible non-parametric algorithms for effect estimation should be strongly justified (i.e. high-dimensional covariates) and performed with care. Parametric learners may be a safer option with few drawbacks. ","",""
0,"Olivier Zanier, M. Zoli, V. Staartjes, F. Guaraldi, S. Asioli, A. Rustici, Valentino Marino Picciola, E. Pasquini, M. Faustini-Fustini, Z. Erlic, L. Regli, D. Mazzatenta, C. Serra","Machine learning-based clinical outcome prediction in surgery for acromegaly",2021,"","","","",171,"2022-07-13 09:23:47","","10.1007/s12020-021-02890-z","","",,,,,0,0.00,0,13,1,"","",""
0,"Janghwan Lee, Shuhui Qu, Yan Kang, Wonhyouk Jang","Multimodal Machine Learning for Display Panel Defect Layer Identification",2021,"","","","",172,"2022-07-13 09:23:47","","10.1109/ASMC51741.2021.9435664","","",,,,,0,0.00,0,4,1,"Process control in display mass production needs defect layer identification to estimate the process that causes fault conditions, which is crucial for quality fault prediction and monitoring. Defect layer identification is a labor-intensive task that requires domain knowledge of experts to make consistent decisions over multiple datasets. Sometimes, it also requires examining multiple sources of inspection images to make the final identification. In this paper, we propose a multimodal machine learning model for defect layer identification as a classification problem from multiple sources of input images. After training two single modal models from each input source, we develop a final joint fusion model to achieve the best classification performance. This work also demonstrates how to estimate the final fusion model performance without exhaustively trying all possible combinations of single modal models. In order to integrate the approach into an industrial display manufacturing defect data analytic, we propose the data coverage model, which guarantees human-level classification performance within a certain portion of data. The data coverage model improves the robustness of the multimodal model, utilizing confident learning to make a high-confidence predictions for the particle defect layer identification and adding a filter to assess whether data samples are within the coverage based on the model’s latent space density estimation. This work uses particle defects data samples in 8 different layers as a combination of TEM and STEM images from display manufacturing fabrication lines. Our experimental results show that the classification accuracy improves substantially by deploying the proposed multimodal model. The results also show that it is possible to implement the data coverage model to achieve the human expert level of defect layer classification for a portion of data to automate the task.","",""
0,"Salvatore Tedesco, Martina Andrulli, Markus Åkerlund Larsson, D. Kelly, Antti Alamäki, S. Timmons, J. Barton, J. Condell, B. O’Flynn, A. Nordström","Comparison of Machine Learning Techniques for Mortality Prediction in a Prospective Cohort of Older Adults",2021,"","","","",173,"2022-07-13 09:23:47","","10.3390/ijerph182312806","","",,,,,0,0.00,0,10,1,"As global demographics change, ageing is a global phenomenon which is increasingly of interest in our modern and rapidly changing society. Thus, the application of proper prognostic indices in clinical decisions regarding mortality prediction has assumed a significant importance for personalized risk management (i.e., identifying patients who are at high or low risk of death) and to help ensure effective healthcare services to patients. Consequently, prognostic modelling expressed as all-cause mortality prediction is an important step for effective patient management. Machine learning has the potential to transform prognostic modelling. In this paper, results on the development of machine learning models for all-cause mortality prediction in a cohort of healthy older adults are reported. The models are based on features covering anthropometric variables, physical and lab examinations, questionnaires, and lifestyles, as well as wearable data collected in free-living settings, obtained for the “Healthy Ageing Initiative” study conducted on 2291 recruited participants. Several machine learning techniques including feature engineering, feature selection, data augmentation and resampling were investigated for this purpose. A detailed empirical comparison of the impact of the different techniques is presented and discussed. The achieved performances were also compared with a standard epidemiological model. This investigation showed that, for the dataset under consideration, the best results were achieved with Random UnderSampling in conjunction with Random Forest (either with or without probability calibration). However, while including probability calibration slightly reduced the average performance, it increased the model robustness, as indicated by the lower 95% confidence intervals. The analysis showed that machine learning models could provide comparable results to standard epidemiological models while being completely data-driven and disease-agnostic, thus demonstrating the opportunity for building machine learning models on health records data for research and clinical practice. However, further testing is required to significantly improve the model performance and its robustness.","",""
0,"Yue Gao, X. Xiong, X. Jiao, Yanqiu Yu, J. Chi, Lingxi Chen, Shuaicheng Li, Qinglei Gao","Development and Validation of a Machine Learning Model for Prediction of Response to Corticosteroid Therapy In COVID-19 Patients",2021,"","","","",174,"2022-07-13 09:23:47","","10.2139/SSRN.3834263","","",,,,,0,0.00,0,8,1,"Background: Corticosteroid has been proved to be one of the few effective treatments for COVID-19 patients. However, not all the patients were suitable for corticosteroid therapy. In this study, we aimed to propose a machine learning model to forecast the response to corticosteroid therapy in COVID-19 patients.    Methods: We retrospectively collected 666 COVID-19 patients receiving corticosteroid therapy between January 27, 2020, and March 30, 2020, from two hospitals in China. The response to corticosteroid therapy was evaluated by hospitalization time, oxygen supply duration, and the outcomes of patients. Least Absolute Shrinkage and Selection Operator (LASSO) was applied for feature selection. Five machine learning algorithms were applied in the training cohort and assessed in an internal and an external validation dataset, respectively.    Findings: Two (C reactive protein, lymphocyte percent) of 36 candidate immune/inflammatory features were finally used for model development. All five models displayed promising predictive performance. Notably, the ensemble model, PRCTC (prediction of response to corticosteroid therapy in COVID-19 patients), derived from Support Vector Machine (SVM), Gradient Boosted Decision Tree (GBDT), and Neural Network (NN) achieved the best performance with an area under the curve (AUC) of 0·810 (95% confidence interval [CI] 0·760–0·861) in internal validation cohort and 0·845 (95% CI 0·779–0·911) in external validation cohort to predict patients’ response to corticosteroid therapy.    Interpretation: PRCTC proposed with robustness, universality, and scalability is hopeful to provide tangible and prompt clinical decision support in management of COVID-19 patients, and potentially extends to other medication prediction.    Funding: Natural Science Foundation of China.    Declaration of Interests: All authors declared no competing interest.    Ethics Approval Statement: This study was approved by the Research Ethics Commission of Tongji Medical College, Huazhong University of Science and Technology (TJIRB20200406) with waived informed consent by the Ethics Commission mentioned above.","",""
0,"J. Figuerêdo, V. T. Sarinho, R. Calumby","Low-Cost Machine Learning for Effective and Efficient Bad Smells Detection",2021,"","","","",175,"2022-07-13 09:23:47","","10.5753/kdmile.2021.17468","","",,,,,0,0.00,0,3,1,"Bad smells are characteristics of software that indicate a code or design problem which can make information system hard to understand, evolve, and maintain. To address this problem, different approaches, manual and automated, have been proposed over the years, including more recently machine learning alternatives. However, despite the advances achieved, some machine learning techniques have not yet been effectively explored, such as the use of feature selection techniques. Moreover, it is not clear to what extent the use of numerous source-code features are necessary for reasonable bad smell detection success. Therefore, in this work we propose an approach using low-cost machine learning for effective and efficient detection of bad smells, through explicit feature selection. Our results showed that the selection allowed to statistically improve the effectiveness of the models. For some cases, the models achieved statistical equivalence, but relying on a highly reduced set of features. Indeed, by using explicit feature selection, simpler models such as Naive Bayes became statistically equivalent to robust models such as Random Forest. Therefore, the selection of features allowed keeping competitive or even superior effectiveness while also improving the efficiency of the models, demanding less computational resources for source-code preprocessing, model training and bad smell detection.","",""
0,"Yinyihong Liu","Airbnb Pricing Based on Statistical Machine Learning Models",2021,"","","","",176,"2022-07-13 09:23:47","","10.1109/CONF-SPML54095.2021.00042","","",,,,,0,0.00,0,1,1,"Being one of the largest online accommodation booking platforms, Airbnb has many hosts who are seeking for more proper prices to increase their booking rate. To develop a good pricing prediction model, this paper has employed machine learning models including KNN, MLR, LASSO regression, Ridge regression, Random Forest, Gradient Boosting and XGBoost etc. While past studies on Airbnb pricing have applied quantitative pricing, some face the problems that the models are not robust enough and some face the problem of not training the model plentily. To fill this gap, we give careful consideration in exploratory data analysis to make the dataset more reasonable, apply many robust models ranging from regularized regression to ensemble models and use cross validation and random search to tune each parameter in each model. In this way, we not only select XGBoost as the best model for price prediction with R2 score 0.6321, but also uncover the features which have statistical significance with the target price.","",""
0,"Uma Gunasilan","Debate as a learning activity for teaching programming: a case in the subject of machine learning",2021,"","","","",177,"2022-07-13 09:23:47","","10.1108/heswbl-01-2021-0006","","",,,,,0,0.00,0,1,1,"PurposeDebates are well known to encompass a variety of skills we would like higher education candidates to embody when they graduate.Design/methodology/approachDebates in a classroom with computer science as the main subject has been popular in high schools particularly with emerging issues around the area, however it does not have as an extensive similar documented outreach in tertiary education, particularly in the area of hard computer sciences and more recent concentrations of computer science, such as machine learning, artificial intelligence and cloud computing.FindingsTo explore further, the debate dataset had more methodologies applied and was split into training and testing sets, whose results were then compared by a standardized measure: Root Mean Square Error (RMSE) which is currently standard in the industry. The rationale of the approach is to quantify that debate activities have an immensely positive impact towards both the teaching and learning in technical subjects and needs to be more often and robustly used within higher education.Originality/valueThe rationale of the approach is that classroom debate activities equip students with verbal and social learning styles and an opportunity to engage with content in a way that is more comfortable than working with traditional lecture-and-laboratory style learning.","",""
8,"Mustafa Anil Koçak, David Ramirez, E. Erkip, D. Shasha","SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness",2017,"","","","",178,"2022-07-13 09:23:47","","10.1109/TPAMI.2019.2932415","","",,,,,8,1.60,2,4,5,"<italic>SafePredict</italic> is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, <inline-formula><tex-math notation=""LaTeX"">$1-\epsilon$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""kocak-ieq1-2932415.gif""/></alternatives></inline-formula>, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm so that the error rate on non-refused predictions does not exceed <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq2-2932415.gif""/></alternatives></inline-formula>. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq3-2932415.gif""/></alternatives></inline-formula>, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the-art confidence-based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software is included in the supplementary material, which can be found on the Computer Society Digital Library at <uri>http://doi.ieeecomputersociety.org/10.1109/TPAMI.2019.2932415</uri>.","",""
22,"F. Plisson, O. Ramírez-Sánchez, Cristina Martínez-Hernández","Machine learning-guided discovery and design of non-hemolytic peptides",2020,"","","","",179,"2022-07-13 09:23:47","","10.1038/s41598-020-73644-6","","",,,,,22,11.00,7,3,2,"","",""
0,"Ransalu Senanayake, Daniel J. Fremont, Mykel J. Kochenderfer, A. Lomuscio, D. Margineantu, Cheng Soon Ong","Guest Editorial: Special issue on robust machine learning",2021,"","","","",180,"2022-07-13 09:23:47","","10.1007/s10994-021-06113-4","","",,,,,0,0.00,0,6,1,"","",""
1,"Wanjun Zhao, Yong Zhang, Xinming Li, Yonghong Mao, Changwei Wu, Lijun Zhao, Fang Liu, Jingqiang Zhu, Jingqiu Cheng, Hao Yang, Guisen Li","KDClassifier: A urinary proteomic spectra analysis tool based on machine learning for the classification of kidney diseases",2021,"","","","",181,"2022-07-13 09:23:47","","10.31491/apt.2021.09.064","","",,,,,1,1.00,0,11,1,"Background: We aimed to establish a novel diagnostic model for kidney diseases by combining artificial intelligence with complete mass spectrum information from urinary proteomics. Methods: We enrolled 134 patients (IgA nephropathy, membranous nephropathy, and diabetic kidney disease) and 68 healthy participants as controls, with a total of 610,102 mass spectra from their urinary proteomic profiles. The training data set (80%) was used to create a diagnostic model using XGBoost, random forest (RF), a support vector machine (SVM), and artificial neural networks (ANNs). The diagnostic accuracy was evaluated using a confusion matrix with a test dataset (20%). We also constructed receiver operating-characteristic, Lorenz, and gain curves to evaluate the diagnostic model. Results: Compared with the RF, SVM, and ANNs, the modified XGBoost model, called Kidney Disease Classifier (KDClassifier), showed the best performance. The accuracy of the XGBoost diagnostic model was 96.03%. The area under the curve of the extreme gradient boosting (XGBoost) model was 0.952 (95% confidence interval, 0.9307–0.9733). The Kolmogorov-Smirnov (KS) value of the Lorenz curve was 0.8514. The Lorenz and gain curves showed the strong robustness of the developed model. Conclusions: The KDClassifier achieved high accuracy and robustness and thus provides a potential tool for the classification of kidney diseases","",""
1,"Jonathan Koss, Anthony Jiang, Patrick W Sweeney, N. Rios, A. Dollar","Robust Machine Learning Classification of Unlabeled Biological Data: A case study with herbaria sheets",2021,"","","","",182,"2022-07-13 09:23:47","","10.3897/biss.5.73833","","",,,,,1,1.00,0,5,1,"There is much excitement across a broad range of biological disciplines over the prospect of using deep learning and similar modern statistical methods to label research data. The extensive time, effort, and cost required for humans to label a dataset drastically limits the type and amount of data that can be reasonably utilized, and is currently a major bottleneck to the extensive application of biological datasets such as specimen imagery, video and audio recordings. While a number of researchers have shown how deep convolutional neural networks (CNN) can be trained to classify image data with 80-90% accuracy, that range of accuracy is still too low for most research applications. Furthermore, applying these classifiers to new, unlabeled data from a dataset other than the one used for training the classifier would likely result in even lower accuracy. As a result, these classifiers have still not generally been applied to unlabeled data—which is where they could be most useful.  In this talk, we will present a method for determining a confidence metric on predicted classifications (i.e. ""labels"") from a deep CNN classifier that can inform a user whether to trust a particular automatic label or to discard it, thereby giving a reasonable and straight-forward method to label a previously unlabeled dataset with high confidence.  Essentially, it is an approach that allows an imperfect method of classification to be used in a useful way that can save an enormous amount of time and effort and/or greatly increase the amount of data that can be reasonably utilized.  In this work, the training dataset consisted of a set of records of flowering plant species that collectively exhibited a range of reproductive morphologies, represented multiple taxonomic groups, and could be easily scored by humans for reproductive condition by examination of specimen images. The records were labeled as reproductive, budding, flowering and/or fruiting. All of the data and images were obtained from the Consortium of Northeastern Herbaria portal (CNH). There were two unscored datasets that were used to evaluate the classifiers. One dataset contained the same taxa that were in the training dataset and the second dataset contained all remaining flowering plant taxa in the CNH portal database that were not included in the other two datasets. Records of families with flowers that are obscure (i.e., they lack petals & sepals or have vestigial structures) were excluded.   To label the reproductive state of the plants, we trained one deep CNN classifier using the XCeption architecture for the binary classification of each state (e.g., budding vs. not budding). This method and architecture was chosen because of its success in similar image-classification tasks.   Each of these networks takes an image of a herbarium sheet as input, and outputs a value in the interval [0,1]. In these networks, the output is typically thresholded to generate a binary label, but we found it could also be used to approximate a measure of confidence in the network’s classification. By treating this value as a confidence metric, we are able to input a large unlabeled dataset into the classifier and then trust the labels that were assigned a “high confidence” and leave the remainder unlabeled.   After training the network, the performance of the four classifiers (reproductive, budding, flowering, fruiting) achieved 85-90% accuracy compared to expert-labeled data. However, as described above, the real value of these approaches comes from their prospects for labelling previously unlabeled data, thus helping to replace expensive and time-consuming human labor. We then applied our confidence-interval-based approach to a collection of 600k images and were able to label 35-70% of the samples with a chosen confidence threshold of 95%. In other words, we could then use the high-confidence labels and simply not automatically label the remaining unclassifiable samples. The data from these samples could then be labeled manually, or, if appropriate, not labeled at all.","",""
150,"I. Nouretdinov, S. Costafreda, A. Gammerman, A. Chervonenkis, V. Vovk, V. Vapnik, C. H. Fu","Machine learning classification with confidence: Application of transductive conformal predictors to MRI-based diagnostic and prognostic markers in depression",2011,"","","","",183,"2022-07-13 09:23:47","","10.1016/j.neuroimage.2010.05.023","","",,,,,150,13.64,21,7,11,"","",""
18,"Ményssa Cherifa, A. Blet, A. Chambaz, E. Gayat, M. Resche-Rigon, R. Pirracchio","Prediction of an Acute Hypotensive Episode During an ICU Hospitalization With a Super Learner Machine-Learning Algorithm",2020,"","","","",184,"2022-07-13 09:23:47","","10.1213/ANE.0000000000004539","","",,,,,18,9.00,3,6,2,"BACKGROUND: Acute hypotensive episodes (AHE), defined as a drop in the mean arterial pressure (MAP) <65 mm Hg lasting at least 5 consecutive minutes, are among the most critical events in the intensive care unit (ICU). They are known to be associated with adverse outcome in critically ill patients. AHE prediction is of prime interest because it could allow for treatment adjustment to predict or shorten AHE. METHODS: The Super Learner (SL) algorithm is an ensemble machine-learning algorithm that we specifically trained to predict an AHE 10 minutes in advance. Potential predictors included age, sex, type of care unit, severity scores, and time-evolving characteristics such as mechanical ventilation, vasopressors, or sedation medication as well as features extracted from physiological signals: heart rate, pulse oximetry, and arterial blood pressure. The algorithm was trained on the Medical Information Mart for Intensive Care dataset (MIMIC II) database. Internal validation was based on the area under the receiver operating characteristic curve (AUROC) and the Brier score (BS). External validation was performed using an external dataset from Lariboisière hospital, Paris, France. RESULTS: Among 1151 patients included, 826 (72%) patients had at least 1 AHE during their ICU stay. Using 1 single random period per patient, the SL algorithm with Haar wavelets transform preprocessing was associated with an AUROC of 0.929 (95% confidence interval [CI], 0.899–0.958) and a BS of 0.08. Using all available periods for each patient, SL with Haar wavelets transform preprocessing was associated with an AUROC of 0.890 (95% CI, 0.886–0.895) and a BS of 0.11. In the external validation cohort, the AUROC reached 0.884 (95% CI, 0.775–0.993) with 1 random period per patient and 0.889 (0.768–1) with all available periods and BSs <0.1. CONCLUSIONS: The SL algorithm exhibits good performance for the prediction of an AHE 10 minutes ahead of time. It allows an efficient, robust, and rapid evaluation of the risk of hypotension that opens the way to routine use.","",""
1,"Francesco Pomponi, Maria Luque Anguita, M. Lange, Bernardino D’Amico, E. Hart","Enhancing the Practicality of Tools to Estimate the Whole Life Embodied Carbon of Building Structures via Machine Learning Models",2021,"","","","",185,"2022-07-13 09:23:47","","10.3389/fbuil.2021.745598","","",,,,,1,1.00,0,5,1,"The construction and operation of buildings account for significant environmental impacts, including greenhouse gas (GHG) emissions, energy demand, resource consumption and waste generation. While the operation of buildings is fairly well regulated and globally considered in the pathways to net-zero mid-century targets, a different picture emerges when looking at the other life cycle stages, which incur the so-called embodied impacts. These cover raw material extraction and product manufacturing through to construction and end of life activities. Only a handful of examples exist where such embodied carbon (EC) emissions are enshrined in law with most of the ongoing debate still around estimating and understanding where such emissions occur and how to mitigate them. Building structures account for a significant share of a building’s embodied emissions and they also are the building element with the longest service life, thus presenting potential lock-in challenges for choices made today. To support the ongoing global effort to mitigate embodied carbon and equip engineers and designers worldwide with easy-to-use and robust calculation tools, we describe a real-time decision-support tool to aid building design that leverages machine learning (ML) methods from computer science to speed-up the computationally expensive process of finite element analysis (FEA) traditionally exploited in structural engineering. We demonstrate that replacing FEA calculations with a model learnt using ML from a large dataset offers real time decision support while guaranteeing the same level of confidence and accuracy that a traditional FEA-based method would offer at the design stage. The tool has been developed both as a standalone version and as a plugin for Trimble SketchUp to maximise its usability and diffusion. It offers results correlated with uncertainty analysis in the form of probability density functions to account for the inherent variability of input data that characterises early stages in the design process. This research contributes to the ongoing global efforts to decarbonising the built environment and offers an immediately implementable method and tool for doing so.","",""
0,"E. Akimova, A. Bersenev, Artem A. Deikov, Konstantin S. Kobylkin, A. V. Konygin, I. P. Mezentsev, V. Misilov","PyTraceBugs: A Large Python Code Dataset for Supervised Machine Learning in Software Defect Prediction",2021,"","","","",186,"2022-07-13 09:23:47","","10.1109/APSEC53868.2021.00022","","",,,,,0,0.00,0,7,1,"Contemporary software engineering tools employ deep learning methods to identify bugs and defects in source code. Being data-hungry, supervised deep neural network models require large labeled datasets for their robust and accurate training. In distinction to, say, Java, there is lack of such datasets for Python. Most of the known datasets containing the labeled Python source code are of relatively small size. Those datasets are suitable for testing built deep learning models, but not for their training. Therefore, larger labeled datasets have to be created based on some well-received algorithmic principles to select relevant source code from the available public codebases. In this work, a large dataset of the labeled Python source code is created named PyTraceBugs. It is intended for training, validating, and evaluating large deep learning models to identify a special class of low-level bugs in source code snippets manifested by throwing error exceptions, reported in standard traceback messages. Here, a code snippet is assumed to be either a function or a method implementation. The dataset contains 5.7 million correct source code snippets and 24 thousands buggy snippets from the Github public repositories. Most represented bugs are: absence of attribute, empty object, index out of range, and text encoding/decoding errors. The dataset is split into training, validation and test samples. Confidence in labeling of the snippets into buggy and correct is about 85% according to our estimates. Labeling of the snippets in the test sample is additionally manually validated to be almost 100% confident. To demonstrate advantages of our dataset, it is used to train a binary classification model for distinguishing the buggy and correct source code. This model employs the pretrained BERT-like contextual embeddings. Its performances are as follows: precision on the test set is 96 % for the buggy source code and 61 % for the correct source code whereas recall is 34 % and 99 % respectively. The model performance is also estimated on the known BugsInPy dataset: here, it reports approximately 14% of buggy snippets.","",""
0,"T. Martin, S. Areibi, G. Grewal","Effective Machine-Learning Models for Predicting Routability During FPGA Placement",2021,"","","","",187,"2022-07-13 09:23:47","","10.1109/MLCAD52597.2021.9531243","","",,,,,0,0.00,0,3,1,"The ability to efficiently and accurately predict placement routability, while avoiding the large computational cost of performing routing, is an asset when seeking to reduce total placement and routing runtime. In this paper, we present a series of simple ML models and ensembles to predict the routability of a placement solution. Ensembles based on Bagging, Boosting and Stack of classifiers are introduced to produce more accurate and robust solutions than single/simple models. Our results show an improvement in prediction accuracy and runtime compared to the best published results in the literature.","",""
0,"M. Dabbah, A. Reed, A. Booth, A. Yassaee, A. Despotovic, B. Klasmer, Emily Binning, M. Aral, D. Plans, A. Labrique, D. Mohan","Machine learning approach to dynamic risk modeling of mortality in COVID-19: a UK Biobank cohort study",2021,"","","","",188,"2022-07-13 09:23:47","","10.1101/2021.02.08.21251343","","",,,,,0,0.00,0,11,1,"The COVID19 pandemic has resulted in over two million deaths globally. There is an urgent need for robust, scalable monitoring tools supporting resource allocation and stratification of high-risk patients. This research aims to develop and validate prediction models, using the UK Biobank to estimate COVID19 mortality risk in confirmed cases. We developed a random forest classification model using baseline characteristics, pre-existing conditions, symptoms, and vital signs, such that the score could dynamically assess risk of mortality with disease deterioration (AUC: 0.92). The design and feature selection of the framework lends itself to deployment in remote settings. Possible applications include supporting individual-level risk profiling and monitoring disease progression across high volumes of patients with COVID19, especially in hospital-at-home settings. The COVID19 pandemic has precipitated over 100 million confirmed cases and 2.3 million deaths globally. The impact of the pandemic has not been limited to healthcare systems: a ripple effect has resulted in wide-ranging economic and social disruption. Interventions to reduce transmission, such as lockdowns, travel restrictions, and re-allocation of health resources, are critical to limiting the impact. Although large-scale vaccination programmes have begun, many countries globally will not have widespread access to vaccines until 2023, meaning that non-pharmaceutical interventions are likely to remain indispensable national strategies for some time. COVID19 shows highly varied clinical presentation. A significant proportion (17 to 45%) of cases are asymptomatic and require no specific care. Conversely, reviews of severe complications have found that up to 32% of hospitalized COVID19 patients are admitted to ICU7. Between these two extremes, typical symptoms include fever, continuous cough, anosmia, and dyspnoea, which may range from requiring only self-management at home to inpatient care. Understanding which individuals are most vulnerable to severe disease, and thereby in most need of resources, is critical to limit the impact of the virus. Decision-making at all levels requires an understanding of individuals risk of severe disease. Various patient characteristics, comorbidities, and lifestyle factors have been linked to greater risk of death and/or severe illness following infection. Furthermore, socioeconomic factors have also been linked as risk factors for COVID19 mortality. Once patients are infected with SARS CoV 2, additional physiological parameters, such as symptoms and vital signs, can inform real-time prognostication13. Laboratory testing and imaging can also inform risk stratification for early, aggressive intervention, though this data is only accessible to hospital inpatients, who are likely to be already severely affected. Robust, predictive models for acquisition and prognosis of COVID 1916 18 and resource management have been developed to support risk stratification and population management at scale, offering important insights for organizational decision-making. However, the individual is currently overlooked, and granular, patient-specific risk-scoring could potentially unify decision-making at all levels. Existing individualized risk scores, however, often conflate risk of COVID19 acquisition with risk of mortality following infection, which can limit their utility in patient management. For prediction models to achieve impact at scale, assessment of risk factors should be inexpensive and accessible to the general population, ideally without the need for specialized testing or hospital visits. Such risk prediction tools, enabling improved patient triage, could be used to further increase the efficiency of, and confidence in, hospital at home solutions, which have shown promise in reducing hospital burden throughout the pandemic. Risk scores in these circumstances need to be dynamic and contemporaneous, ideally incorporating symptoms and vital sign data to maximise utility to clinical and research teams. Therefore, the primary aim of this study is to develop and validate a population-based prediction model, using a large, rich dataset and a selective, clinically informed approach, which dynamically estimates the COVID19 mortality risk in confirmed diagnoses.","",""
0,"A. Tritt","Title: An Integrated Machine-Learning Framework for Reliable Host Prediction of Uncultivated Phages",2021,"","","","",189,"2022-07-13 09:23:47","","","","",,,,,0,0.00,0,1,1,"text: Viruses are critical components of soil microbial ecosystems. By shaping microbial communities’ structure and altering host cell metabolism during infection, viruses exert strong constraints on microbiomes, with downstream effects on nutrient cycling and metabolic outputs. Viral genomic diversity in the environment, especially in soil, is progressively being mapped primarily through the assembly of novel viral genomes from metagenomes. In the last five years alone, the number of such “uncultivated virus genomes” available in public databases has increased by more than 3 orders of magnitudes (from a few hundreds to several millions). These genomes have enabled multiple discoveries on the diversity and distribution of viruses across different ecosystems, yet one limitation inherent to these datasets is the lack of host information for these viruses. Linking novel uncultivated viruses to their host(s) is a critical step towards understanding the influence and potential impacts of these viruses on microbiomes and ecosystems. Accordingly, more than 15 different tools have been released over the last few years aiming at predicting virus:host pairs and/or host taxonomy for uncultivated viruses. Overall, these rely on four major types of genomic signal: (i) sequence similarity to known viruses, (ii) sequence similarity to putative host genomes, including due to host-encoded CRISPR-Cas systems, horizontal gene transfer, and provirus integration, and (iii) similarity in terms of nucleotide composition (i.e., kmer frequency) between virus and host genome. These different approaches differ greatly in their recall (i.e., ability to predict host taxonomy for as many viruses as possible) and falsediscovery rate (i.e., frequency at which the predicted taxonomy correspond to the correct host), so that aggregating the results obtained from different tools on a single virus is challenging. We describe here the prototype of a machine-learning framework taking as input multiple results of host prediction tools and using a deep neural network structure to provide as output a single host taxonomy prediction, at the genus rank, along with a confidence score. We illustrate how this integration step maximizes both recall and precision, enabling robust host prediction for more input sequences than any individual tool. In addition, rather than directly predicting a host taxonomy, the neural network is designed to learn to distinguish patterns of “reliable” and “unreliable” host prediction based on a combination of all signals considered. Hence, it is not limited by the virus-host pairs currently described, and could be applied to entirely novel virus and host communities. Overall, integrating independent signals for host prediction appears to be a promising approach to progressively populate uncultivated virus genome databases with reliable host information at a satisfactory taxonomic resolution (i.e., genus rank). Coupled with a continuing expansion of the global collection of isolated phages and innovative experimental methods to link uncultivated viruses to hosts, these pave the way towards a more comprehensive reconstruction of virus:host network from complex microbial communities. References/Publications 1. Roux, Simon, David Páez-Espino, I-Min A Chen, Krishna Palaniappan, Anna Ratner, Ken Chu, T B K Reddy, et al. 2020. “IMG/VR v3: An Integrated Ecological and Evolutionary Framework for Interrogating Genomes of Uncultivated Viruses.” Nucleic Acids Research, 1–12. https://doi.org/10.1093/nar/gkaa946. 2. Edwards, Robert A., Katelyn McNair, Karoline Faust, Jeroen Raes, and Bas E. Dutilh. 2016. “Computational Approaches to Predict Bacteriophage-Host Relationships.” FEMS Microbiology Reviews 40 (2): 258–72. https://doi.org/10.1093/femsre/fuv048. 3. Galiez, Clovis, Matthias Siebert, François Enault, Jonathan Vincent, and Johannes Söding. 2017. “WIsH: Who Is the Host? Predicting Prokaryotic Hosts from Metagenomic Phage Contigs.” Bioinformatics 33 (19): 3113–14. https://doi.org/10.1093/bioinformatics/btx383. 4. Ahlgren, NA, Jie Ren, Yang Young Lu, Jed A. Fuhrman, and Fengzhu Sun. 2016. “Alignment-Free d2 ∗ Oligonucleotide Frequency Dissimilarity Measure Improves Prediction of Hosts from MetagenomicallyDerived Viral Sequences.” Nucleic Acids Research 45 (1): 39–53. https://doi.org/10.1093/nar/gkw1002. 5. Zhang, Ruoshi, Milot Mirdita, Eli Levy Karin, Clovis Norroy, Clovis Galiez, and Johannes Soeding. 2020. “SpacePHARER: Sensitive Identification of Phages from CRISPR Spacers in Prokaryotic Hosts.” BioRxiv, 2020.05.15.090266. https://doi.org/10.1101/2020.05.15.090266. 6. Wang, Weili, Jie Ren, Kujin Tang, Emily Dart, Julio Cesar Ignacio-Espinoza, Jed A Fuhrman, Jonathan Braun, Fengzhu Sun, and Nathan A Ahlgren. 2020. “A Network-Based Integrated Framework for Predicting Virus–Prokaryote Interactions.” NAR Genomics and Bioinformatics 2 (2): 1–19. https://doi.org/10.1093/nargab/lqaa044. 7. Zhang, Fan, Fengxia Zhou, Rui Gan, Chunyan Ren, Yuqiang Jia, Ling Yu, and Zhiwei Huang. 2019. “PHISDetector: A Web Tool to Detect Diverse in Silico Phage-Host Interaction Signals.” BioRxiv. https://doi.org/10.1101/661074. Funding statement: This work was supported by the U.S. Department of Energy, Office of Science, Biological and Environmental Research, Early Career Research Program awarded under UC-DOE Prime Contract DE-AC02-05CH11231. The work conducted by the U.S. Department of Energy Joint Genome Institute is supported by the Office of Science of the U.S. Department of Energy under contract no. DE-AC02-05CH11231.","",""
1002,"Florian Tramèr, Fan Zhang, A. Juels, M. Reiter, T. Ristenpart","Stealing Machine Learning Models via Prediction APIs",2016,"","","","",190,"2022-07-13 09:23:47","","","","",,,,,1002,167.00,200,5,6,"Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (""predictive analytics"") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.  The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., ""steal"") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.","",""
89,"Huichen Lihuichen","DECISION-BASED ADVERSARIAL ATTACKS: RELIABLE ATTACKS AGAINST BLACK-BOX MACHINE LEARNING MODELS",2017,"","","","",191,"2022-07-13 09:23:47","","","","",,,,,89,17.80,89,1,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradientor score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available at XXXXXX. Gradient-based Model M Untargeted Flip to any label Targeted Flip to target label FGSM, DeepFool L-BFGS-B, Houdini, JSMA, Carlini & Wagner, Iterative Gradient Descent Score-based Detailed Model Prediction Y (e.g. probabilities or logits) ZOO Local Search Decision-based Final Model Prediction Ymax (e.g. max class label) this work (Boundary Attack) Transfer-based Training Data T","",""
2,"S. Tonekaboni, Andrew E. Brereton, Z. Safikhani, A. Windemuth, B. Haibe-Kains, Stephen S Mackinnon","Learning across label confidence distributions using Filtered Transfer Learning",2020,"","","","",192,"2022-07-13 09:23:47","","10.1109/ICMLA51294.2020.00180","","",,,,,2,1.00,0,6,2,"Performance of neural network models relies on the availability of large datasets with minimal levels of uncertainty. Transfer Learning (TL) models have been proposed to resolve the issue of small dataset size by letting the model train on a bigger, task-related reference dataset and then fine-tune on a smaller, task-specific dataset. In this work, we apply a transfer learning approach to improve predictive power in noisy data systems with large variable confidence datasets. We propose a deep neural network method called Filtered Transfer Learning (FTL) that defines multiple tiers of data confidence as separate tasks in a transfer learning setting. The deep neural network is fine-tuned in a hierarchical process by iteratively removing (filtering) data points with lower label confidence, and retraining. In this report we use FTL for predicting the interaction of drugs and proteins. We demonstrate that using FTL to learn stepwise, across the label confidence distribution, results in higher performance compared to deep neural network models trained on a single confidence range. We anticipate that this approach will enable the machine learning community to benefit from large datasets with uncertain labels in fields such as biology and medicine.","",""
10,"A. Mondal, Md Abul Ehsan Bhuiyan, Feifei Yang","Advancement of weather-related crash prediction model using nonparametric machine learning algorithms",2020,"","","","",193,"2022-07-13 09:23:47","","10.1007/s42452-020-03196-x","","",,,,,10,5.00,3,3,2,"","",""
297,"Andrius Vabalas, E. Gowen, E. Poliakoff, A. Casson","Machine learning algorithm validation with a limited sample size",2019,"","","","",194,"2022-07-13 09:23:47","","10.1371/journal.pone.0224365","","",,,,,297,99.00,74,4,3,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.","",""
13,"Rajnish Kumar, Anju Sharma, M. H. Siddiqui, R. Tiwari","Promises of Machine Learning Approaches in Prediction of Absorption of Compounds.",2018,"","","","",195,"2022-07-13 09:23:47","","10.2174/1389557517666170315150116","","",,,,,13,3.25,3,4,4,"The Machine Learning (ML) is one of the fastest developing techniques in the prediction and evaluation of important pharmacokinetic properties such as absorption, distribution, metabolism and excretion. The availability of a large number of robust validation techniques for prediction models devoted to pharmacokinetics has significantly enhanced the trust and authenticity in ML approaches. There is a series of prediction models generated and used for rapid screening of compounds on the basis of absorption in last one decade. Prediction of absorption of compounds using ML models has great potential across the pharmaceutical industry as a non-animal alternative to predict absorption. However, these prediction models still have to go far ahead to develop the confidence similar to conventional experimental methods for estimation of drug absorption. Some of the general concerns are selection of appropriate ML methods and validation techniques in addition to selecting relevant descriptors and authentic data sets for the generation of prediction models. The current review explores published models of ML for the prediction of absorption using physicochemical properties as descriptors and their important conclusions. In addition, some critical challenges in acceptance of ML models for absorption are also discussed.","",""
7,"Nadine Körtel, Cornelia Rücklé, You Zhou, A. Busch, Peter Hoch-Kraft, F. R. Sutandy, Jacob Haase, Mihika Pradhan, M. Musheev, D. Ostareck, A. Ostareck-Lederer, C. Dieterich, S. Hüttelmaier, C. Niehrs, O. Rausch, D. Dominissini, J. König, Kathi Zarnack","Deep and accurate detection of m6A RNA modifications using miCLIP2 and m6Aboost machine learning",2020,"","","","",196,"2022-07-13 09:23:47","","10.1093/nar/gkab485","","",,,,,7,3.50,1,18,2,"N6-methyladenosine (m6A) is the most abundant internal RNA modification in eukaryotic mRNAs and influences many aspects of RNA processing. miCLIP (m6A individual-nucleotide resolution UV crosslinking and immunoprecipitation) is an antibody-based approach to map m6A sites with single-nucleotide resolution. However, due to broad antibody reactivity, reliable identification of m6A sites from miCLIP data remains challenging. Here, we present miCLIP2 in combination with machine learning to significantly improve m6A detection. The optimised miCLIP2 results in high-complexity libraries from less input material. Importantly, we established a robust computational pipeline to tackle the inherent issue of false positives in antibody-based m6A detection. The analyses are calibrated with Mettl3 knockout cells to learn the characteristics of m6A deposition, including m6A sites outside of DRACH motifs. To make our results universally applicable, we trained a machine learning model, m6Aboost, based on the experimental and RNA sequence features. Importantly, m6Aboost allows prediction of genuine m6A sites in miCLIP2 data without filtering for DRACH motifs or the need for Mettl3 depletion. Using m6Aboost, we identify thousands of high-confidence m6A sites in different murine and human cell lines, which provide a rich resource for future analysis. Collectively, our combined experimental and computational methodology greatly improves m6A identification. Highlights miCLIP2 produces complex libraries to map m6A RNA modifications Mettl3 KO miCLIP2 allows to identify Mettl3-dependent RNA modification sites Machine learning predicts genuine m6A sites from human and mouse miCLIP2 data without Mettl3 KO m6A modifications occur outside of DRACH motifs and associate with alternative splicing","",""
189,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, F. Hutter","Auto-sklearn: Efficient and Robust Automated Machine Learning",2019,"","","","",197,"2022-07-13 09:23:47","","10.1007/978-3-030-05318-5_6","","",,,,,189,63.00,32,6,3,"","",""
3,"A. Curth, A. Alaa, M. Schaar","Semiparametric Estimation and Inference on Structural Target Functions using Machine Learning and Influence Functions",2020,"","","","",198,"2022-07-13 09:23:47","","","","",,,,,3,1.50,1,3,2,"We aim to construct a class of learning algorithms that are of practical value to applied researchers in fields such as biostatistics, epidemiology and econometrics, where the need to learn from incompletely observed information is ubiquitous. To do so, we propose a new framework for statistical machine learning, which we call 'IF-learning' due to its reliance on influence functions (IFs). To characterise the fundamental limits of what is achievable within this framework, we need to enable semiparametric estimation and inference on structural target parameters that are functions of continuous inputs arising as identifiable functionals from statistical models. Therefore, we introduce a pointwise IF to replace the true IF when it does not exist and propose learning its uncentered pointwise expected value from data. This allows us to give provable guarantees, leveraging existing general results from statistics. Our framework is problem- and model-agnostic and can be used to estimate a broad variety of target parameters of interest in applied statistics: we can consider any target function for which an IF of a population-averaged version exists in analytic form. Throughout, we put particular focus on so-called coarsening at random/doubly robust problems with partially unobserved information. This includes problems such as treatment effect estimation and inference in the presence of missing outcome data. Within this framework, we then propose two general learning algorithms that leverage ideas from the theoretical analysis: the 'IF-learner' which relies on large samples and outputs entire target functions without confidence bands, and the 'Group-IF-learner', which outputs only approximations to a function but can give confidence estimates if sufficient information on coarsening mechanisms is available. We close with a simulation study on inferring treatment effects.","",""
2,"Lei Wang, Mingliang Liu, Arlybek Altazhanov, Bekassyl Syzdykov, J. Yan, Xinli Meng, Kai Jin","Data Driven Machine Learning Models for Shale Gas Adsorption Estimation",2020,"","","","",199,"2022-07-13 09:23:47","","10.2118/200621-ms","","",,,,,2,1.00,0,7,2,"Abstract Accurate calculation of adsorbed shale gas content is critical for gas reserve evaluation and development. However, gas adsorption and desorption experiments are expensive and time-consuming, while physics-based models and empirical correlations are unable to accurately capture the adsorption characteristics for different shales. Langmuir adsorption is one of the most commonly used model for calculating the adsorbed gas content in shale gas reservoirs. However, most existing correlations for the Langmuir pressure and Langmuir volume in the model are oversimplified based on limited experimental data points. Thus they are not representative of key geological parameters and are far from accurate for prediction in many cases. We developed a variety of machine learning models that are multivariable controlled to quantify shale gas adsorption. The data-driven method subdivides into two procedures: data compilation and machine learning regression. Over 700 data entries, composed of reservoir temperature (T, °C), total organic carbon (TOC, wt%), vitrinite reflectance (Ro,%), Langmuir pressure, and Langmuir volume are compiled from shale gas plays mainly in USA, Canada, and China. Data have been consistently curated, then machine learning approaches, including multiple linear regression (MLR), support vector machine (SVM), random forest (RF) and artificial neural network (ANN), have been built, trained and tested by partitioning the data into 75%:25%. For SVM, RF and NN models, 1000 simulations were run and averaged for performance comparison. MLR identifies non-negligible parameters and general trends for shale gas adsorption. Nonetheless, the correlation coefficients from MLR are far from satisfactory. For Langmuir pressure, RF models fit best to the data entries and the other models follow the order of SVM > ANN > MLR. Particularly, RF models show the highest performance stability with the averaged R-squared value of 0.84 and the maximum of 0.87, indicating a very strong relationship constructed for these 213 data entries. For 485 Langmuir volume data entries, RF models also perform best while the other three regression methods are comparable. It should be noted that altering machine learning model structure and parameters could significantly affect the regression results. Robust and universal machine learning models for estimating adsorbed shale gas content with high confidence level are established, which not only provide more accurate estimation and broader parameter adaptation than physics-based and empirical models, but also circumvent the high-cost and time-consuming deficiency of experimental measurements. These machine learning models can be used to estimate adsorbed gas content for shale plays with limited experimental measurements. Moreover, they can be incorporated into reservoir simulators to improve the simulation performance.","",""
3,"Dee H. Wu, Zhongning Chen, J. North, Mainak Biswas, J. Vo, J. Suri","Machine learning paradigm for dynamic contrast-enhanced MRI evaluation of expanding bladder.",2020,"","","","",200,"2022-07-13 09:23:47","","10.2741/4876","","",,,,,3,1.50,1,6,2,"Delineation of the bladder under a dynamic contrast enhanced (DCE)-MRI protocol requires robust segmentation. However, this method is subject to errors due to variations in the content of fluid within the bladder, as well as presence of air and similarity of signal intensity in adjacent organs. Introduction of the contrast media into the bladder also causes signal errors due to alterations in the shape of the bladder. To circumvent such errors, and to improve the accuracy, we adapted a machine learning paradigm that utilizes the global bladder shape. The ML system first uses the combination of low level image processing tools such as filtering, and mathematical morphology as preprocessing step. We use neural network for training the network using extracted features and application of trained model on test slices to compute the delineated bladder shapes. This ML-based integrated system has an accuracy of 90.73% and time reduction of 65.2% in over manual delineation and can be used in clinical settings for IC/BPS patient care. Finally, we apply Jaccard Similarity Measure which we report to have a mean score of 0.933 (95% Confidence Interval 0.923, 0.944).","",""
