Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
7,"Vinicius M. Alves, S. Auerbach, N. Kleinstreuer, J. Rooney, E. Muratov, I. Rusyn, A. Tropsha, Charles Schmitt","Curated Data In — Trustworthy In Silico Models Out: The Impact of Data Quality on the Reliability of Artificial Intelligence Models as Alternatives to Animal Testing",2021,"","","","",1,"2022-07-13 09:21:26","","10.1177/02611929211029635","","",,,,,7,7.00,1,8,1,"New Approach Methodologies (NAMs) that employ artificial intelligence (AI) for predicting adverse effects of chemicals have generated optimistic expectations as alternatives to animal testing. However, the major underappreciated challenge in developing robust and predictive AI models is the impact of the quality of the input data on the model accuracy. Indeed, poor data reproducibility and quality have been frequently cited as factors contributing to the crisis in biomedical research, as well as similar shortcomings in the fields of toxicology and chemistry. In this article, we review the most recent efforts to improve confidence in the robustness of toxicological data and investigate the impact that data curation has on the confidence in model predictions. We also present two case studies demonstrating the effect of data curation on the performance of AI models for predicting skin sensitisation and skin irritation. We show that, whereas models generated with uncurated data had a 7–24% higher correct classification rate (CCR), the perceived performance was, in fact, inflated owing to the high number of duplicates in the training set. We assert that data curation is a critical step in building computational models, to help ensure that reliable predictions of chemical toxicity are achieved through use of the models.","",""
0,"Migle Laukyte","TRUSTWORTHY ARTIFICIAL INTELLIGENCE AND HUMAN RIGHTS",2020,"","","","",2,"2022-07-13 09:21:26","","10.2307/j.ctv102bm6p.8","","",,,,,0,0.00,0,1,2,"In April 2019, High-Level Expert Group on Artificial Intelligence, set up by the European Commission, has published its Ethics Guidelines for Trustworthy Artificial Intelligence (AI), which addresses the future of AI development in Europe. In particular, these Guidelines work out a vision of AI that Europe should foster and indicates the features that any AI-based system should have: the framework is composed of three parts, namely, lawful, ethical and robust AI. The Guidelines do not deal with the first of these parts—lawful AI—where, among other things, authors include the necessity that AI would respect fundamental human rights: this is the so called “fundamental-rights based approach” which is the approach that EU promotes with respect to AI.  As the Expert Group prefers to focus on ethics and robustness of AI, this paper will focus on lawfulness of AI. In particular, I will focus on the impact that AI could have on human rights, established in the Charter of the Fundamental Rights of the European Union (EU), other relevant international treaties, and specific regulations such as General Data Protection Regulation. The Guidelines list some of the human rights that should be the foundational stones for any AI within the EU, namely, protection of human dignity and human freedoms in the broad sense of the term, respect for democracy, justice and the rule of law, equality and non discrimination and citizenship-related rights, such as the right to vote. These rights also reverberate in the discussion on ethical AI, where specific ethical principles are being discussed.  The aim of this paper is to address the aforementioned human rights and see in what ways AI could have an impact on them: how could AI not only respect (passive stance) but also support and help to bring into being (active stance) some of these rights? In particular I will look at the existing AI applications and discuss whether we are approaching the challenge to make AI work for (and not against) human rights in the right way. Furthermore, the paper will also raise the question whether AI could advance any kind of new human rights that we might consider to be fundamental in the future. For instance, do we have a right to know when we interact with an AI on telecommunication networks and not with a human being? Do we have a right to explicability of algorithms?","",""
0,"","Patients set to benefit from new guidelines on artificial intelligence health solutions",2020,"","","","",3,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,0,2,"The use of these international guidelines will enable patients, health care professionals and policy-makers to be more confident on whether an AI intervention is safe and effective. This is a key step towards trustworthy AI in health. Development of new reporting guidelines which expand on the current SPIRIT 2013 and CONSORT 2010 reporting frameworks will boost transparency and robustness for clinical trials evaluating AI health solutions.","",""
0,"","Comments of the Center for Democracy & Technology on European Commission’s High Level Expert Group on Artificial Intelligence (AI HLEG)’s Draft Ethics Guidelines for Trustworthy AI Introduction: Rationale and Foresight of the Guidelines",,"","","","",4,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,0,,"The Center for Democracy & Technology supports the High-Level Expert Group (HLEG)’s efforts to develop guidelines for trustworthy AI and appreciates the opportunity to comment on this draft. In particular, we commend the group for affirming a rights-based approach to governing AI, for moving beyond the development of principles, and for acknowledging the need for a contextand domain-specific implementation of the values discussed in these guidelines. While we agree that trustworthiness is a key objective for any system, the HLEG must also acknowledge the limitations of current methods for mitigating bias in machine learning models. In many contexts and applications, truly trustworthy AI remains hypothetical. Moreover, trustworthiness depends not only on the ethical purpose and technical robustness of the model or application but also on the governance of the entire societal context or legal system within which an AI application sits (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913). We recommend that the HLEG place greater emphasis on (1) the importance of mechanisms and processes for continually interrogating and challenging AI systems from both the inside and the outside and (2) the importance of assessing the entire system (including underlying policies, laws, and human-technology interactions) that surround the AI.","",""
4,"Bo Li, Peng Qi, Bo Liu, Shuai Di, Jingen Liu, Jiquan Pei, Jinfeng Yi, Bowen Zhou","Trustworthy AI: From Principles to Practices",2021,"","","","",5,"2022-07-13 09:21:26","","","","",,,,,4,4.00,1,8,1,"The rapid development of Artificial Intelligence (AI) technology has enabled the deployment of various systems based on it. However, many current AI systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. These shortcomings degrade user experience and erode people’s trust in all AI systems. In this review, we provide AI practitioners with a comprehensive guide for building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. To unify currently available but fragmented approaches toward trustworthy AI, we organize them in a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges for the future development of trustworthy AI systems, where we identify the need for a paradigm shift toward comprehensively trustworthy AI systems.","",""
0,"","Active anomaly detection and forecasting approaches to achieve safe and trustworthy interactions between human operators and intelligent cyber-physical systems",2021,"","","","",6,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,0,1,"Ensuring correct and safe operations for intelligent systems means ensuring that robots, cyber‐physical systems and autonomous agents in general operate according to a certain protocol without harming the environment or causing harm to people. This is a key challenge in building reliable artificial intelligence (AI) systems. This is particularly important when such systems can be implemented in real‐world environments, where interaction with humans sees humans as non‐robotics experts, unaware of possible operational criticalities (for example, avoiding being within a robotic arm as long as it moves an object). An important element in improving robustness and consequently building trust in these systems is their ability to predict and adapt to human behavior. Another key ingredient is the ability to monitor the operations of autonomous agents by detecting abnormal behavior and avoiding unsafe actions or risky decisions.","",""
0,"Stefka Schmid, Thea Riebe, Christian Reuter","Dual-Use and Trustworthy? A Mixed Methods Analysis of AI Diffusion Between Civilian and Defense R&D",2022,"","","","",7,"2022-07-13 09:21:26","","10.1007/s11948-022-00364-7","","",,,,,0,0.00,0,3,1,"","",""
0,"Dongfang Li, Dongfang Li, Baotian Hu, Qingcai Chen, Tujie Xu, Jingcong Tao, Yunan Zhang","Unifying Model Explainability and Robustness for Joint Text Classification and Rationale Extraction",2021,"","","","",8,"2022-07-13 09:21:26","","10.1609/aaai.v36i10.21342","","",,,,,0,0.00,0,7,1,"Recent works have shown explainability and robustness are two crucial ingredients of trustworthy and reliable text classification. However, previous works usually address one of two aspects: i) how to extract accurate rationales for explainability while being beneficial to prediction; ii) how to make the predictive model robust to different types of adversarial attacks. Intuitively, a model that produces helpful explanations should be more robust against adversarial attacks, because we cannot trust the model that outputs explanations but changes its prediction under small perturbations. To this end, we propose a joint classification and rationale extraction model named AT-BMC. It includes two key mechanisms: mixed Adversarial Training (AT) is designed to use various perturbations in discrete and embedding space to improve the model’s robustness, and Boundary Match Constraint (BMC) helps to locate rationales more precisely with the guidance of boundary information. Performances on benchmark datasets demonstrate that the proposed AT-BMC outperforms baselines on both classification and rationale extraction by a large margin. Robustness analysis shows that the proposed AT-BMC decreases the attack success rate effectively by up to 69%. The results indicate that there are connections between robust models and better explanations.","",""
0,"A. Ramanathan, Sumit Kumar Jha","Adversarial Attacks against AI-driven Experimental Peptide Design Workflows",2021,"","","","",9,"2022-07-13 09:21:26","","10.1109/xloop54565.2021.00010","","",,,,,0,0.00,0,2,1,"Artificial intelligence and machine learning (AI/ML) techniques are fueling a revolution in how scientific experiments are designed, implemented and automated. Specifically, increasing high-bandwidth instruments coupled to new hardware and software systems can significantly improve the throughput of experimental results, while AI/ML techniques can provide insights into novel science and theories that were hitherto inaccessible. Despite recent progress in such “self-driving labs”, these automated platforms are susceptible to adversarial attacks as well as more traditional cybersecurity attacks. Using a motivating example of an automated approach to design anti-microbial peptides (AMP), our position paper seeks to demonstrate how a lack of adversarial robustness of AI systems such as protein folding networks may affect the execution of such experimental workflows. We highlight important problems in adversarial robustness that may need to be resolved in order to establish a trustworthy and safe AI -driven AMP synthesis system.","",""
0,"Anas Al-Tirawi, R. Reynolds","How to Design a Trustable Cultural Algorithm Using Common Value Auctions",2021,"","","","",10,"2022-07-13 09:21:26","","10.1109/TransAI51903.2021.00022","","",,,,,0,0.00,0,2,1,"One of the major challenges facing Artificial Intelligence in the future is the design of trustworthy algorithms. In this paper four basic features of trustworthy algorithms are presented. A Cultural Algorithm based upon Common Value Auctions is presented. It is demonstrated that this framework is able to support each of these fundamental principles. The basic principles are: fairness, explainability, responsibility, and sustainability. The first three are features that are part of the Cultural Algorithm configuration used here. The fourth properties was established experimentally. It was shown that the CVA based Cultural Algorithm exhibited improved sustainability in terms of both resilience and robustness over the of a Cultural Algorithm based upon a Wisdom of the Crowds or voting approach..","",""
0,"Lijie Wang, Hao Liu, Shu-ping Peng, Hongxuan Tang, Xinyan Xiao, Ying Chen, Hua Wu, Haifeng Wang","DuTrust: A Sentiment Analysis Dataset for Trustworthiness Evaluation",2021,"","","","",11,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,8,1,"While deep learning models have greatly improved the performance of most artificial intelligence tasks, they are often criticized to be untrustworthy due to the black-box problem. Consequently, many works have been proposed to study the trustworthiness of deep learning. However, as most open datasets are designed for evaluating the accuracy of model outputs, there is still a lack of appropriate datasets for evaluating the inner workings of neural networks. The lack of datasets obviously hinders the development of trustworthiness research. Therefore, in order to systematically evaluate the factors for building trustworthy systems, we propose a novel and well-annotated sentiment analysis dataset to evaluate robustness and interpretability. To evaluate these factors, our dataset contains diverse annotations about the challenging distribution of instances, manual adversarial instances and sentiment explanations. Several evaluation metrics are further proposed for interpretability and robustness. Based on the dataset and metrics, we conduct comprehensive comparisons for the trustworthiness of three typical models, and also study the relations between accuracy, robustness and interpretability. We release this trustworthiness evaluation dataset at https://github/xyz and hope our work can facilitate the progress on building more trustworthy systems for real-world applications.","",""
0,"Dipanwita Guhathakurta, Pooja Aggarwal, Seema Nagar, Rohan Arora, Bing Zhou","Utilizing Persistence for Post Facto Suppression of Invalid Anomalies Using System Logs",2022,"","","","",12,"2022-07-13 09:21:26","","10.1109/icse-nier55298.2022.9793537","","",,,,,0,0.00,0,5,1,"The robustness and availability of cloud services are becoming increasingly important as more applications migrate to the cloud. The operations landscape today is more complex, than ever. Site reliability engineers (SREs) are expected to handle more incidents than ever before with shorter service-level agreements (SLAs). By exploiting log, tracing, metric, and network data, Artificial Intelligence for IT Operations (AIOps) enables detection of faults and anomalous issues of services. A wide variety of anomaly detection techniques have been incorporated in various AIOps platforms (e.g. PCA and autoencoder), but they all suffer from false positives. In this paper, we propose an unsupervised approach for persistent anomaly detection on top of the traditional anomaly detection approaches, with the goal of reducing false positives and providing more trustworthy alerting signals. We test our method on both simulated and real-world datasets. Our technique reduces false positive anomalies by at least 28%, resulting in more reliable and trustworthy notifications. CCS CONCEPTS • Computing methodologies $\rightarrow$ Anomaly detection;. Software and its engineering $\rightarrow$Maintaining software. ACM Reference Format: Dipanwita Guhathakurta, Pooja Aggarwal, Seema Nagar, and Rohan Arora, Bing Zhou. 2022. Utilizing Persistence for Post Facto Suppression of Invalid Anomalies Using System Logs. In New Ideas and Emerging Results (ICSENIER’22), May 21-29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3510455.3512774","",""
5,"Blake Ruprecht, Wenlong Wu, M. Islam, Derek T. Anderson, James M. Keller, G. Scott, Curt Davis, F. Petry, P. Elmore, Kristen Nock, Elizabeth Gilmour","Possibilistic Clustering Enabled Neuro Fuzzy Logic",2020,"","","","",13,"2022-07-13 09:21:26","","10.1109/FUZZ48607.2020.9177593","","",,,,,5,2.50,1,11,2,"Artificial neural networks are a dominant force in our modern era of data-driven artificial intelligence. The adaptive neuro fuzzy inference system (ANFIS) is a neural network based on fuzzy logic versus a more traditional premise like convolution. Advantages of ANFIS include the ability to encode and potentially understand machine learned neural information in the pursuit of explainable, interpretable, and ultimately trustworthy artificial intelligence. However, real-world data is almost always imperfect, e.g., incomplete or noisy, and ANFIS is not naturally robust. Specifically, ANFIS is susceptible to over inflated uncertainty, poor antecedent (fuzzy set) data alignment, degenerate optimization conditions, and hard to interpret logic, to name a few factors. Herein, we explore the use of possibilistic clustering to identify outliers, specifically typicality degrees, to increase the robustness of ANFIS; or any fuzzy logic neuron/network. Experiments are presented that demonstrate the need and quality of the proposed solutions in the pursuit of robust interpretable machine learned neuro fuzzy logic solutions.","",""
3,"J. Cirera, J. Carino, D. Zurita, J. Ortega","Data Analytics for Performance Evaluation Under Uncertainties Applied to an Industrial Refrigeration Plant",2019,"","","","",14,"2022-07-13 09:21:26","","10.1109/ACCESS.2019.2917079","","",,,,,3,1.00,1,4,3,"Artificial intelligence has bounced into industrial applications contributing several advantages to the field and have led to the possibility to open new ways to solve many actual problems. In this paper, a data-driven performance evaluation methodology is presented and applied to an industrial refrigeration system. The strategy takes advantage of the Multivariate Kernel Density Estimation technique and Self-Organizing Maps to develop a robust method, which is able to determine a near-optimal performance map, taking into account the system uncertainties and the multiple signals involved in the process. A normality model is used to detect and filter non-representative operating samples to subsequently develop a reliable performance map. The performance map allows comparing the plant assessment under the same operating conditions and permits to identify the potential system improvement capabilities. To ensure that the resulting evaluation is trustworthy, a robustness strategy is developed to identify either possible new operation conditions or abnormal situations in order to avoid uncertain assessments. Furthermore, the proposed approach is tested with real industrial plant data to validate the suitability of the method.","",""
1,"Geoffrey Rockwell, Emily Black, Evan Selinger, Antonio Davola, Elana Seide, K. Gulson","From Shortcut to Sleight of Hand: Why the Checklist Approach in the EU Guidelines Does Not Work",2019,"","","","",15,"2022-07-13 09:21:26","","","","",,,,,1,0.33,0,6,3,"Author(s): Rockwell, Geoffrey; Black, Emily; Selinger, Evan; Davola, Antonio; Seide, Elana; Gulson, Kalervo | Abstract: In April 2019, the High-Level Expert Group on Artificial Intelligence (AI) nominated by the EU Commission presented “Ethics Guidelines for Trustworthy Artificial Intelligence,” followed in June 2019 by a second “Policy and investment recommendations” Document.The Guidelines establish three characteristics (lawful, ethical, and robust) and seven key requirements (Human agency and oversight; Technical Robustness and safety; Privacy and data governance; Transparency; Diversity, non-discrimination and fairness; Societal and environmental well-being; and Accountability) that the development of AI should follow.The Guidelines are of utmost significance for the international debate over the regulation of AI. Firstly, they aspire to set a universal standard of care for the development of AI in the future. Secondly, they have been developed within a group of experts nominated by a regulatory body, and therefore will shape the normative approach in the EU regulation of AI and in its interaction with foreign countries. As the GDPR has shown, the effect of this normative activity goes way past the European Union territory.One of the most debated aspects of the Guidelines was the need to find an objective methodology to evaluate conformity with the key requirements. For this purpose, the Expert Group drafted an “assessment checklist” in the last part of the document: the list is supposed to be incorporated into existing practices, as a way for technology developers to consider relevant ethical issues and create more “trustworthy” AI. Our group undertook a critical assessment of the proposed tool from a multidisciplinary perspective, to assess its implications and limitations for global AI development.","",""
0,"Joshua A. Kroll","RFI : Developing a Federal AI Standards Engagement Plan",2019,"","","","",16,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,1,3,"I wish to submit the attached article, ""Data Science Data Governance"" for the NIST RFI on Artificial Intelligence Standards (Docket Number: 190312229-9229-01). While it was published in IEEE Security and Privacy, I hold an independent copyright and so can submit it for public posting here. The article, which describes high level approaches to data governance and software system governance I've encountered during my research on the governance of software systems, speaks most closely to question (8) on ""Technical standards and guidance that are needed to establish and advance trustworthy aspects (e.g., accuracy, transparency, security, privacy, and robustness) of AI technologies.""","",""
60,"A. Markus, J. Kors, P. Rijnbeek","The role of explainability in creating trustworthy artificial intelligence for health care: a comprehensive survey of the terminology, design choices, and evaluation strategies",2020,"","","","",17,"2022-07-13 09:21:26","","10.1016/j.jbi.2020.103655","","",,,,,60,30.00,20,3,2,"","",""
36,"Scott Thiebes, S. Lins, A. Sunyaev","Trustworthy artificial intelligence",2020,"","","","",18,"2022-07-13 09:21:26","","10.1007/S12525-020-00441-4","","",,,,,36,18.00,12,3,2,"","",""
171,"B. Shneiderman","Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",2020,"","","","",19,"2022-07-13 09:21:26","","10.1080/10447318.2020.1741118","","",,,,,171,85.50,171,1,2,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.","",""
9,"Nathalie A. Smuha, Emma Ahmed-Rengers, Adam Harkens, Wenlong Li, J. Maclaren, Riccardo Piselli, K. Yeung","How the EU Can Achieve Legally Trustworthy AI: A Response to the European Commission’s Proposal for an Artificial Intelligence Act",2021,"","","","",20,"2022-07-13 09:21:26","","10.2139/ssrn.3899991","","",,,,,9,9.00,1,7,1,"This document contains the response to the European Commission’s Proposal for an Artificial Intelligence Act from members of the Legal, Ethical & Accountable Digital Society (LEADS) Lab at the University of Birmingham. The Proposal seeks to give expression to the concept of ‘Lawful AI.’ This concept was mentioned, but not developed in the Commission’s High-Level Expert Group on AI’s Ethics Guidelines for Trustworthy AI (2019), which instead confined its discussion to the concepts of ‘Ethical’ and ‘Robust’ AI. After a brief introduction (Chapter 1), we set out the many aspects of the Proposal which we welcome, and stress our wholehearted support for its aim to protect fundamental rights (Chapter 2). Subsequently, we develop the concept of ‘Legally Trustworthy AI,’ arguing that it should be grounded in respect for three pillars on which contemporary liberal democratic societies are founded, namely: fundamental rights, the rule of law, and democracy (Chapter 3). Drawing on this conceptual framework, we first argue that the Proposal fails to reflect fundamental rights as claims with enhanced moral and legal status, which subjects any rights interventions to a demanding regime of scrutiny and must satisfy tests of necessity and proportionality. Moreover, the Proposal does not always accurately recognise the wrongs and harms associated with different kinds of AI systems and appropriately allocates responsibility for them. Second, the Proposal does not provide an effective framework for the enforcement of legal rights and duties, and does not ensure legal certainty and consistency, which are essential for the rule of law. Third, the Proposal neglects to ensure meaningful transparency, accountability, and rights of public participation, thereby failing to reflect adequate protection for democracy (Chapter 4). Based on these shortcomings in respecting and promoting the three pillars of Legally Trustworthy AI, we provide detailed recommendations for the Proposal’s revision (Chapter 5).","",""
8,"J. Lötsch, D. Kringel, A. Ultsch","Explainable Artificial Intelligence (XAI) in Biomedicine: Making AI Decisions Trustworthy for Physicians and Patients",2021,"","","","",21,"2022-07-13 09:21:26","","10.3390/biomedinformatics2010001","","",,,,,8,8.00,3,3,1,"The use of artificial intelligence (AI) systems in biomedical and clinical settings can disrupt the traditional doctor–patient relationship, which is based on trust and transparency in medical advice and therapeutic decisions. When the diagnosis or selection of a therapy is no longer made solely by the physician, but to a significant extent by a machine using algorithms, decisions become nontransparent. Skill learning is the most common application of machine learning algorithms in clinical decision making. These are a class of very general algorithms (artificial neural networks, classifiers, etc.), which are tuned based on examples to optimize the classification of new, unseen cases. It is pointless to ask for an explanation for a decision. A detailed understanding of the mathematical details of an AI algorithm may be possible for experts in statistics or computer science. However, when it comes to the fate of human beings, this “developer’s explanation” is not sufficient. The concept of explainable AI (XAI) as a solution to this problem is attracting increasing scientific and regulatory interest. This review focuses on the requirement that XAIs must be able to explain in detail the decisions made by the AI to the experts in the field.","",""
7,"A. Rawal, J. Mccoy, D. Rawat, Brian M. Sadler, R. Amant","Recent Advances in Trustworthy Explainable Artificial Intelligence: Status, Challenges and Perspectives",2021,"","","","",22,"2022-07-13 09:21:26","","10.36227/techrxiv.17054396.v1","","",,,,,7,7.00,1,5,1,"This is a survey paper on Explainable Artificial Intelligence (XAI).","",""
42,"M. Nassar, K. Salah, M. H. Rehman, D. Svetinovic","Blockchain for explainable and trustworthy artificial intelligence",2019,"","","","",23,"2022-07-13 09:21:26","","10.1002/widm.1340","","",,,,,42,14.00,11,4,3,"The increasing computational power and proliferation of big data are now empowering Artificial Intelligence (AI) to achieve massive adoption and applicability in many fields. The lack of explanation when it comes to the decisions made by today's AI algorithms is a major drawback in critical decision‐making systems. For example, deep learning does not offer control or reasoning over its internal processes or outputs. More importantly, current black‐box AI implementations are subject to bias and adversarial attacks that may poison the learning or the inference processes. Explainable AI (XAI) is a new trend of AI algorithms that provide explanations of their AI decisions. In this paper, we propose a framework for achieving a more trustworthy and XAI by leveraging features of blockchain, smart contracts, trusted oracles, and decentralized storage. We specify a framework for complex AI systems in which the decision outcomes are reached based on decentralized consensuses of multiple AI and XAI predictors. The paper discusses how our proposed framework can be utilized in key application areas with practical use cases.","",""
4,"Kristi Joamets, Archil Chochia","Access to Artificial Intelligence for Persons with Disabilities: Legal and Ethical Questions Concerning the Application of Trustworthy AI",2021,"","","","",24,"2022-07-13 09:21:26","","10.11590/ABHPS.2021.1.04","","",,,,,4,4.00,2,2,1,"Digitalisation and emerging technologies affect our lives and are increasingly present in a growing number of fields. Ethical implications of the digitalisation process have therefore long been discussed by the scholars. The rapid development of artificial intelligence (AI) has taken the legal and ethical discussion to another level. There is no doubt that AI can have a positive impact on the society. The focus here, however, is on its more negative impact. This article will specifically consider how the law and ethics in their interaction can be applied in a situation where a disabled person needs some kind of assistive technology to participate in the society as an equal member. This article intends to investigate whether the EU Guidelines for Trustworthy AI, as a milestone of ethics concerning technology, has the power to change the current practice of how social and economic rights are applied. The main focus of the article is the ethical requirements ‘Human agency and oversight’ and, more specifically, fundamental rights.","",""
5,"Silverio Mart'inez-Fern'andez, X. Franch, Andreas Jedlitschka, Marc Oriol, Adam Trendowicz","Research Directions for Developing and Operating Artificial Intelligence Models in Trustworthy Autonomous Systems",2020,"","","","",25,"2022-07-13 09:21:26","","10.1007/978-3-030-75018-3_14","","",,,,,5,2.50,1,5,2,"","",""
4,"Karim Lekadira, Richard Osuala, C. Gallin, Noussair Lazrak, Kaisar Kushibar, G. Tsakou, Susanna Auss'o, Leonor Cerd'a Alberich, K. Marias, Manolis Tskinakis, S. Colantonio, Nickolas Papanikolaou, Zohaib Salahuddin, H. Woodruff, P. Lambin, L. Mart'i-Bonmat'i","FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Medical Imaging",2021,"","","","",26,"2022-07-13 09:21:26","","","","",,,,,4,4.00,0,16,1,"The recent advancements in artificial intelligence (AI) combined with the extensive amount of data generated by today’s clinical systems, has led to the development of imaging AI solutions across the whole value chain of medical imaging, including image reconstruction, medical image segmentation, image-based diagnosis and treatment planning. Notwithstanding the successes and future potential of AI in medical imaging, many stakeholders are concerned of the potential risks and ethical implications of imaging AI solutions, which are perceived as complex, opaque, and difficult to comprehend, utilise, and trust in critical clinical applications. Despite these concerns and risks, there are currently no concrete guidelines and best practices for guiding future AI developments in medical imaging towards increased trust, safety and adoption. To bridge this gap, this paper introduces a careful selection of guiding principles drawn from the accumulated experiences, consensus, and best practices from five large European projects on AI in Health Imaging. These guiding principles are named FUTURE-AI and its building blocks consist of (i) Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness and (vi) Explainability. In a step-by-step approach, these guidelines are further translated into a framework of concrete recommendations for specifying, developing, evaluating, and deploying technically, clinically and ethically trustworthy AI solutions into clinical practice.","",""
1,"Ke Zhang, Peidong Xu, Tianlu Gao, Jun Zhang","A Trustworthy Framework of Artificial Intelligence for Power Grid Dispatching Systems",2021,"","","","",27,"2022-07-13 09:21:26","","10.1109/DTPI52967.2021.9540198","","",,,,,1,1.00,0,4,1,"With the widespread application of artificial intelligence (AI) technologies in power systems, the properties of lack of reliability and transparency for AI technologies have revealed gradually. Here, how to build a trustworthy-AI framework based on the power system is the focus. Due to the multidimensional and heterogeneous information of power grid data, the heterogeneous graph attention network (HGAT) model of power grid dispatching is established, and the corresponding explainer (HGAT-Explainer) for the model of power equipment faults is proposed to provide more favorable support for the trustworthy-AI systems.","",""
2,"D. Rawat","Secure and trustworthy machine learning/artificial intelligence for multi-domain operations",2021,"","","","",28,"2022-07-13 09:21:26","","10.1117/12.2592860","","",,,,,2,2.00,2,1,1,"Machine Learning (ML) algorithms and Artificial Intelligence (AI) are now regarded as very useful for data-driven applications including resilient multi-domain operations. However, ML algorithms and AI systems can be controlled, dodged, biased, and misled through flawed learning models and input data, they need robust security features and trust. Furthermore, ML algorithms and AI systems add challenges when we have (unlabeled/labeled) sparse/small data or big data for training and evaluation. It is very important to design, evaluate and test ML algorithms and AI systems that produce reliable, robust, trustworthy, explainable, and fair/unbiased outcomes to make them acceptable and reliable in mission critical multi-domain operations. ML algorithms rely on data and work on the principle of ``Garbage In, Garbage Out,"" which means that if the input data to learning model is corrupted or compromised, the outcomes of the ML/AI would not be optimal, reliable and trustworthy.","",""
1,"E. Manziuk, O. Barmak, I. Krak, O. Mazurets, T. Skrypnyk","Formal Model of Trustworthy Artificial Intelligence Based on Standardization",2021,"","","","",29,"2022-07-13 09:21:26","","","","",,,,,1,1.00,0,5,1,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.","",""
0,"Bern Beckert","The European way of doing Artificial Intelligence: The state of play implementing Trustworthy AI",2021,"","","","",30,"2022-07-13 09:21:26","","10.1109/fitce53297.2021.9588560","","",,,,,0,0.00,0,1,1,"“Trustworthy AI” is the concept of the European Commission to facilitate acceptance and diffusion of Artificial Intelligence in Europe. The concept claims that European AI applications shall be lawful, ethical and robust, both from a technical and societal perspective. The contribution asks for the state of play of implementing the concept of Trustworthy AI. More concretely, it sets out to identify concrete cases of implementing Trustworthy AI in order to analyse approaches and experiences. However, it turns out that such projects currently only exist in a research context and at neither large companies nor start-ups or medium-sized companies provide suitable examples, with only a few exceptions. This gives rise to the question, why companies today ignore or even avoid the carefully worked out guidelines to implement Trustworthy AI. Three answers are given which refer to time-to-market considerations, different mindsets of software engineers and social scientists, and the fact that implementing Trustworthy AI requires of firms to go the extra mile with additional expertise and governance structures. Following this, two possibilities are presented to increase in the number of companies actually picking up on the guidelines and concretely implementing Trustworthy AI. These possibilities are firstly to break down existing implementation guidelines to the requirements of software engineers, computer scientists and managers, and secondly to embed social scientists and stakeholders in the implementation process.","",""
80,"M. Janssen, P. Brous, Elsa Estevez, L. Barbosa, T. Janowski","Data governance: Organizing data for trustworthy Artificial Intelligence",2020,"","","","",31,"2022-07-13 09:21:26","","10.1016/j.giq.2020.101493","","",,,,,80,40.00,16,5,2,"","",""
4,"Eleanore Hickman, M. Petrin","Trustworthy AI and Corporate Governance: The EU’s Ethics Guidelines for Trustworthy Artificial Intelligence from a Company Law Perspective",2021,"","","","",32,"2022-07-13 09:21:26","","10.1007/s40804-021-00224-0","","",,,,,4,4.00,2,2,1,"","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",33,"2022-07-13 09:21:26","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
19,"Kristine Bærøe, Ainar Miyata-Sturm, Edmund Henden","How to achieve trustworthy artificial intelligence for health",2020,"","","","",34,"2022-07-13 09:21:26","","10.2471/BLT.19.237289","","",,,,,19,9.50,6,3,2,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.","",""
2,"Suleyman Uslu, Davinder Kaur, S. Rivera, A. Durresi, M. Durresi, M. Babbar‐Sebens","Trustworthy Acceptance: A New Metric for Trustworthy Artificial Intelligence Used in Decision Making in Food-Energy-Water Sectors",2021,"","","","",35,"2022-07-13 09:21:26","","10.1007/978-3-030-75100-5_19","","",,,,,2,2.00,0,6,1,"","",""
14,"L. Robert, G. Bansal, C. Lütge","ICIS 2019 SIGHCI Workshop Panel Report: Human– Computer Interaction Challenges and Opportunities for Fair, Trustworthy and Ethical Artificial Intelligence",2020,"","","","",36,"2022-07-13 09:21:26","","10.17705/1thci.00130","","",,,,,14,7.00,5,3,2,"Artificial Intelligence (AI) is rapidly changing every aspect of our society—including amplifying our biases. Fairness, trust and ethics are at the core of many of the issues underlying the implications of AI. Despite this, research on AI with relation to fairness, trust and ethics in the information systems (IS) field is still scarce. This panel brought together academia, business and government perspectives to discuss the challenges and identify potential solutions to address such challenges. This panel report presents eight themes based around the discussion of two questions: (1) What are the biggest challenges to designing, implementing and deploying fair, ethical and trustworthy AI?; and (2) What are the biggest challenges to policy and governance for fair, ethical and trustworthy AI? The eight themes are: (1) identifying AI biases; (2) drawing attention to AI biases; (3) addressing AI biases; (4) designing transparent and explainable AI; (5) AI fairness, trust, ethics: old wine in a new bottle?; (6) AI accountability; (7) AI laws, policies, regulations and standards; and (8) frameworks for fair, ethical and trustworthy AI. Based on the results of the panel discussion, we present research questions for each theme to guide future research in the area of human–computer interaction.","",""
14,"Stéphan Vincent-Lancrin, R. V. D. Vlies","Trustworthy artificial intelligence (AI) in education",2020,"","","","",37,"2022-07-13 09:21:26","","10.1787/a6c90fa9-en","","",,,,,14,7.00,7,2,2,"This paper was written to support the G20 artificial intelligence (AI) dialogue. With the rise of artificial intelligence (AI), education faces two challenges: reaping the benefits of AI to improve education processes, both in the classroom and at the system level; and preparing students for new skillsets for increasingly automated economies and societies. AI applications are often still nascent, but there are many examples of promising uses that foreshadow how AI might transform education. With regard to the classroom, this paper highlights how AI can accelerate personalised learning, the support of students with special needs. At the system level, promising uses include predictive analysis to reduce dropout, and assessing new skillsets. A new demand for complex skills that are less easy to automate (e.g. higher cognitive skills like creativity and critical thinking) is also the consequence of AI and digitalisation. Reaching the full potential of AI requires that stakeholders trust not only the technology, but also its use by humans. This raises new policy challenges around “trustworthy AI”, encompassing the privacy and security of data, but also possible wrongful uses of data leading to biases against individuals or groups.","",""
14,"Jinchao Feng, J. L. Lansford, M. Katsoulakis, D. Vlachos","Explainable and trustworthy artificial intelligence for correctable modeling in chemical sciences",2020,"","","","",38,"2022-07-13 09:21:26","","10.1126/sciadv.abc3204","","",,,,,14,7.00,4,4,2,"The developed framework apportions model error to inputs, computes predictive guarantees, and enables model correctability. Data science has primarily focused on big data, but for many physics, chemistry, and engineering applications, data are often small, correlated and, thus, low dimensional, and sourced from both computations and experiments with various levels of noise. Typical statistics and machine learning methods do not work for these cases. Expert knowledge is essential, but a systematic framework for incorporating it into physics-based models under uncertainty is lacking. Here, we develop a mathematical and computational framework for probabilistic artificial intelligence (AI)–based predictive modeling combining data, expert knowledge, multiscale models, and information theory through uncertainty quantification and probabilistic graphical models (PGMs). We apply PGMs to chemistry specifically and develop predictive guarantees for PGMs generally. Our proposed framework, combining AI and uncertainty quantification, provides explainable results leading to correctable and, eventually, trustworthy models. The proposed framework is demonstrated on a microkinetic model of the oxygen reduction reaction.","",""
10,"Davinder Kaur, Suleyman Uslu, A. Durresi","Requirements for Trustworthy Artificial Intelligence - A Review",2020,"","","","",39,"2022-07-13 09:21:26","","10.1007/978-3-030-57811-4_11","","",,,,,10,5.00,3,3,2,"","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",40,"2022-07-13 09:21:26","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
8,"Banu Buruk, P. Ekmekci, B. Arda","A critical perspective on guidelines for responsible and trustworthy artificial intelligence",2020,"","","","",41,"2022-07-13 09:21:26","","10.1007/s11019-020-09948-1","","",,,,,8,4.00,3,3,2,"","",""
6,"T. M. Harrison, L. F. Luna-Reyes","Cultivating Trustworthy Artificial Intelligence in Digital Government",2020,"","","","",42,"2022-07-13 09:21:26","","10.1177/0894439320980122","","",,,,,6,3.00,3,2,2,"While there is growing consensus that the analytical and cognitive tools of artificial intelligence (AI) have the potential to transform government in positive ways, it is also clear that AI challenges traditional government decision-making processes and threatens the democratic values within which they are framed. These conditions argue for conservative approaches to AI that focus on cultivating and sustaining public trust. We use the extended Brunswik lens model as a framework to illustrate the distinctions between policy analysis and decision making as we have traditionally understood and practiced them and how they are evolving in the current AI context along with the challenges this poses for the use of trustworthy AI. We offer a set of recommendations for practices, processes, and governance structures in government to provide for trust in AI and suggest lines of research that support them.","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",43,"2022-07-13 09:21:26","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
8,"Eleanore Hickman, M. Petrin","Trustworthy AI and Corporate Governance – The EU’s Ethics Guidelines For Trustworthy Artificial Intelligence from a Company Law Perspective",2020,"","","","",44,"2022-07-13 09:21:26","","10.2139/ssrn.3607225","","",,,,,8,4.00,4,2,2,"AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even ‘rogue AI’. To address these dangers, the EU published its 'Ethics Guidelines for Trustworthy AI’. The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness and explicability.     If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered but, because the Guidelines only address the former without much reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles, it is clear that the Guidelines' general nature leaves many questions and concerns unanswered.     In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance practices. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.","",""
3,"Hongmei He, J. Gray, A. Cangelosi, Q. Meng, T. McGinnity, J. Mehnen","The Challenges and Opportunities of Artificial Intelligence for Trustworthy Robots and Autonomous Systems",2020,"","","","",45,"2022-07-13 09:21:26","","10.1109/IRCE50905.2020.9199244","","",,,,,3,1.50,1,6,2,"Trust is essential in designing autonomous and semiautonomous Robots and Autonomous Systems (RAS), because of the “No trust, no use” concept. RAS should provide high quality services, with four key properties that make them trustworthy: they must be (i) robust with regards to any system health related issues, (ii) safe for any matters in their surrounding environments, (iii) secure against any threats from cyber spaces, and (iv) trusted for human-machine interaction. This article thoroughly analyses the challenges in implementing the trustworthy RAS in respects of the four properties, and addresses the power of AI in improving the trustworthiness of RAS. While we focus on the benefits that AI brings to human, we should realize the potential risks that could be caused by AI. This article introduces for the first time the set of key aspects of human-centered AI for RAS, which can serve as a cornerstone for implementing trustworthy RAS by design in the future.","",""
3,"Hongmei He, J. Gray, A. Cangelosi, Q. Meng, T. McGinnity, J. Mehnen","The challenges and opportunities of artificial intelligence in implementing trustworthy robotics and autonomous systems",2020,"","","","",46,"2022-07-13 09:21:26","","","","",,,,,3,1.50,1,6,2,"Effective Robots and Autonomous Systems (RAS) must be trustworthy. Trust is essential in designing autonomous and semi-autonomous technologies, because “No trust, no use”. RAS should provide high quality of services, with the four key properties that make it trust, i.e. they must be (i) robust for any health issues, (ii) safe for any matters in their surrounding environments, (iii) secure for any threats from cyber spaces, and (iv) trusted for human-machine interaction. We have thoroughly analysed the challenges in implementing the trustworthy RAS in respects of the four properties, and addressed the power of AI in improving the trustworthiness of RAS. While we put our eyes on the beneﬁts that AI brings to human, we should realise the potential risks that could be caused by AI. The new concept of human-centred AI will be the core in implementing the trustworthy RAS. This review could provide a brief reference for the research on AI for trustworthy RAS.","",""
74,"Nathalie A. Smuha","The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence",2019,"","","","",47,"2022-07-13 09:21:26","","10.9785/cri-2019-200402","","",,,,,74,24.67,74,1,3,"As part of its European strategy for Artificial Intelligence (AI), and as a response to the increasing ethical questions raised by this technology, the European Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG) in June 2018. The group was tasked to draft two deliverables: AI Ethics Guidelines and Policy and Investment Recommendations. Nine months later, its first deliverable was published, putting forward a comprehensive framework to achieve “Trustworthy AI” by offering ethical guidance to AI practitioners. This paper dives into the work carried out by the group, focusing in particular on its AI Ethics Guidelines. First, this paper clarifies the context that led to the creation of the AI HLEG and its mandate (I.). Subsequently, it elaborates on the Guidelines’ aim and purpose (II.), and analyses the Guidelines’ drafting process (III.). Particular focus is given to the questions surrounding the respective role played by ethics and law in the AI governance landscape (IV.), as well as some of the challenges that had to be overcome throughout the process (V.). Finally, this paper places the Guidelines in an international context, and sets out the next steps (VI.) ahead on the journey towards an appropriate governance framework for AI (VII.).","",""
48,"","High-Level Expert Group on Artificial Intelligence – Draft Ethics Guidelines for Trustworthy AI",2019,"","","","",48,"2022-07-13 09:21:26","","","","",,,,,48,16.00,0,0,3,"","",""
4,"N. Gillespie, Caitlin Curtis, Rossana Bianchi, A. Akbari, Rita Fentener van Vlissingen","Achieving Trustworthy AI: A Model for Trustworthy Artificial Intelligence",2020,"","","","",49,"2022-07-13 09:21:26","","10.14264/ca0819d","","",,,,,4,2.00,1,5,2,"","",""
49,"Ninja Marnau","Comments on the “Draft Ethics Guidelines for Trustworthy AI” by the High-LevelExpert Group on Artificial Intelligence.",2019,"","","","",50,"2022-07-13 09:21:26","","","","",,,,,49,16.33,49,1,3,"The European Commission appointed the High-Level Expert Group on Artificial Intelligence (AI HLEG). The AI HLEG has the objective to support the implementation of the European strategy on Artificial Intelligence. This will include the elaboration of recommendations on future-related policy development and on ethical, legal and societal issues related to AI. In January 2019, the Commission asked stakeholders for comments on the AI HLEG’s “Draft Ethics Guidelines for Trustworthy AI”. CISPA submitted the following comments and remarks in the Stakeholders’ Consultation.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",51,"2022-07-13 09:21:26","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",52,"2022-07-13 09:21:26","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
1,"","RECOMMENDATIONS TO THE EU HIGH LEVEL EXPERT GROUP ON ARTIFICIAL INTELLIGENCE ON ITS DRAFT AI ETHICS GUIDELINES FOR TRUSTWORTHY AI",2019,"","","","",53,"2022-07-13 09:21:26","","","","",,,,,1,0.33,0,0,3,"RECOMMENDATIONS TO THE EU HIGH LEVEL EXPERT GROUP ON ARTIFICIAL INTELLIGENCE ON ITS DRAFT AI ETHICS GUIDELINES FOR TRUSTWORTHY AI The Center for Data Innovation is pleased to submit feedback to the High-Level Expert Group (HLEG) on AI on its draft AI Ethics Guidelines for Trustworthy AI. The Center is a nonprofit research institute focused on the intersection of data, technology, and public policy. With staff in Washington, DC and Brussels, the Center formulates and promotes pragmatic public policies designed to maximize the benefits of data-driven innovation in the public and private sectors. It educates policymakers and the public about the opportunities and challenges associated with data, as well as technology trends such as artificial intelligence, open data, and the Internet of Things. The Center is affiliated with the Information Technology and Innovation Foundation (ITIF), the top-ranked science and technology policy think tank in the world.","",""
25,"K. Varshney","Trustworthy machine learning and artificial intelligence",2019,"","","","",54,"2022-07-13 09:21:26","","10.1145/3313109","","",,,,,25,8.33,25,1,3,"How can we add the most important ingredient to our relationship with machine learning?","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",55,"2022-07-13 09:21:26","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
6,"Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier, A. Durresi","Trustworthy Artificial Intelligence: A Review",2022,"","","","",56,"2022-07-13 09:21:26","","10.1145/3491209","","",,,,,6,6.00,2,4,1,"Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.","",""
6,"A. McGovern, I. Ebert‐Uphoff, D. Gagne, A. Bostrom","The Need for Ethical, Responsible, and Trustworthy Artificial Intelligence for Environmental Sciences",2021,"","","","",57,"2022-07-13 09:21:26","","10.1017/eds.2022.5","","",,,,,6,6.00,2,4,1,"  Given the growing use of Artificial intelligence (AI) and machine learning (ML) methods across all aspects of environmental sciences, it is imperative that we initiate a discussion about the ethical and responsible use of AI. In fact, much can be learned from other domains where AI was introduced, often with the best of intentions, yet often led to unintended societal consequences, such as hard coding racial bias in the criminal justice system or increasing economic inequality through the financial system. A common misconception is that the environmental sciences are immune to such unintended consequences when AI is being used, as most data come from observations, and AI algorithms are based on mathematical formulas, which are often seen as objective. In this article, we argue the opposite can be the case. Using specific examples, we demonstrate many ways in which the use of AI can introduce similar consequences in the environmental sciences. This article will stimulate discussion and research efforts in this direction. As a community, we should avoid repeating any foreseeable mistakes made in other domains through the introduction of AI. In fact, with proper precautions, AI can be a great tool to help reduce climate and environmental injustice. We primarily focus on weather and climate examples but the conclusions apply broadly across the environmental sciences.","",""
16,"C. Stix","Actionable Principles for Artificial Intelligence Policy: Three Pathways",2021,"","","","",58,"2022-07-13 09:21:26","","10.1007/s11948-020-00277-3","","",,,,,16,16.00,16,1,1,"","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",59,"2022-07-13 09:21:26","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
11,"A. Holzinger, M. Dehmer, F. Emmert‐Streib, N. Díaz-Rodríguez, R. Cucchiara, Isabelle Augenstein, J. Ser, W. Samek, I. Jurisica","Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence",2021,"","","","",60,"2022-07-13 09:21:26","","10.1016/j.inffus.2021.10.007","","",,,,,11,11.00,1,9,1,"","",""
13,"S. Haupt, W. Chapman, Samantha V. Adams, Charlie Kirkwood, J. Hosking, Nial H. Robinson, S. Lerch, A. Subramanian","Towards implementing artificial intelligence post-processing in weather and climate: proposed actions from the Oxford 2019 workshop",2021,"","","","",61,"2022-07-13 09:21:26","","10.1098/rsta.2020.0091","","",,,,,13,13.00,2,8,1,"The most mature aspect of applying artificial intelligence (AI)/machine learning (ML) to problems in the atmospheric sciences is likely post-processing of model output. This article provides some history and current state of the science of post-processing with AI for weather and climate models. Deriving from the discussion at the 2019 Oxford workshop on Machine Learning for Weather and Climate, this paper also presents thoughts on medium-term goals to advance such use of AI, which include assuring that algorithms are trustworthy and interpretable, adherence to FAIR data practices to promote usability, and development of techniques that leverage our physical knowledge of the atmosphere. The coauthors propose several actionable items and have initiated one of those: a repository for datasets from various real weather and climate problems that can be addressed using AI. Five such datasets are presented and permanently archived, together with Jupyter notebooks to process them and assess the results in comparison with a baseline technique. The coauthors invite the readers to test their own algorithms in comparison with the baseline and to archive their results. This article is part of the theme issue ‘Machine learning for weather and climate modelling’.","",""
43,"V. C. Vivoli","Trustworthy Artificial Intelligence",2018,"","","","",62,"2022-07-13 09:21:26","","","","",,,,,43,10.75,43,1,4,"","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",63,"2022-07-13 09:21:26","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
12,"Nathalie A. Smuha","From a ‘race to AI’ to a ‘race to AI regulation’: regulatory competition for artificial intelligence",2021,"","","","",64,"2022-07-13 09:21:26","","10.1080/17579961.2021.1898300","","",,,,,12,12.00,12,1,1,"ABSTRACT Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is a possibility, a reality and a desirability.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",65,"2022-07-13 09:21:26","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
133,"K. Yeung","Recommendation of the Council on Artificial Intelligence (OECD)",2020,"","","","",66,"2022-07-13 09:21:26","","10.1017/ilm.2020.5","","",,,,,133,66.50,133,1,2,"On May 22, 2019, the Organisation for Economic Co-operation and Development (OECD) Ministerial Council Meeting adopted the Recommendation on Artificial Intelligence, signed by all 36 OECD member countries and non-member countries Argentina, Brazil, Columbia, Costa Rica, Peru, and Romania. Its aim is to foster innovation and trust in artificial intelligence (AI) by promoting the “responsible stewardship of trustworthy AI.”","",""
129,"Arun Das, P. Rad","Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",2020,"","","","",67,"2022-07-13 09:21:26","","","","",,,,,129,64.50,65,2,2,"Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",68,"2022-07-13 09:21:26","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
50,"M. Ryan","In AI We Trust: Ethics, Artificial Intelligence, and Reliability",2020,"","","","",69,"2022-07-13 09:21:26","","10.1007/s11948-020-00228-y","","",,,,,50,25.00,50,1,2,"","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",70,"2022-07-13 09:21:26","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
74,"E. Neri, F. Coppola, V. Miele, C. Bibbolino, R. Grassi","Artificial intelligence: Who is responsible for the diagnosis?",2020,"","","","",71,"2022-07-13 09:21:26","","10.1007/s11547-020-01135-9","","",,,,,74,37.00,15,5,2,"","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",72,"2022-07-13 09:21:26","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
5,"R. Medaglia, J. Gil-Garcia, T. Pardo","Artificial Intelligence in Government: Taking Stock and Moving Forward",2021,"","","","",73,"2022-07-13 09:21:26","","10.1177/08944393211034087","","",,,,,5,5.00,2,3,1,"The use of artificial intelligence (AI) applications in government is receiving increasing attention from global research and practice communities. This article, introducing a Special Issue on Artificial Intelligence in Government published in the Social Science Computer Review, presents an overview of some of the main policy initiatives across the world in relation to AI in government and discusses the state of the art of existing research. Based on an analysis of current trends in research and practice, we highlight four areas to be the focus of future research on AI in government: governance of AI, trustworthy AI, impact assessment methodologies, and data governance.","",""
4,"B. Weber-Lewerenz","Corporate digital responsibility (CDR) in construction engineering—ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",2021,"","","","",74,"2022-07-13 09:21:26","","10.1007/s42452-021-04776-1","","",,,,,4,4.00,4,1,1,"","",""
23,"S. Larsson","On the Governance of Artificial Intelligence through Ethics Guidelines",2020,"","","","",75,"2022-07-13 09:21:26","","10.1017/als.2020.19","","",,,,,23,11.50,23,1,2,"Abstract This article uses a socio-legal perspective to analyze the use of ethics guidelines as a governance tool in the development and use of artificial intelligence (AI). This has become a central policy area in several large jurisdictions, including China and Japan, as well as the EU, focused on here. Particular emphasis in this article is placed on the Ethics Guidelines for Trustworthy AI published by the EU Commission’s High-Level Expert Group on Artificial Intelligence in April 2019, as well as the White Paper on AI, published by the EU Commission in February 2020. The guidelines are reflected against partially overlapping and already-existing legislation as well as the ephemeral concept construct surrounding AI as such. The article concludes by pointing to (1) the challenges of a temporal discrepancy between technological and legal change, (2) the need for moving from principle to process in the governance of AI, and (3) the multidisciplinary needs in the study of contemporary applications of data-dependent AI.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",76,"2022-07-13 09:21:26","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
3,"Rüdiger Schmitz, R. Werner, A. Repici, R. Bisschops, A. Meining, Michael Zornow, H. Messmann, C. Hassan, Prateek Sharma, T. Rösch","Artificial intelligence in GI endoscopy: stumbling blocks, gold standards and the role of endoscopy societies",2021,"","","","",77,"2022-07-13 09:21:26","","10.1136/gutjnl-2020-323115","","",,,,,3,3.00,0,10,1,"Artificial intelligence has been portrayed as a silver bullet for a number of challenges encountered in gastrointestinal (GI) endoscopy and beyond. Intense research, commercial and media focus have led to the publication of studies with modest patient numbers and comparatively simple technology. There is no doubt that machine learning (ML) will be a determining medical development for the years to come. However, now that the dust has begun to settle, we are at a critical juncture where the focus is shifting from preclinical work toward the role of ML in clinical practice. Current issues relate to the evaluation and testing of AI and ML systems, especially regarding patient outcomes, and to regulatory issues surrounding implementation. Many of these aspects pertain to one overarching question: how can we ensure that preclinical results translate into trustworthy clinical reality? For the endoscopist, whether as a reader, a reviewer or a potential user of AI, it becomes increasingly important to understand the technical aspects of the systems and their performance measurements in order to realistically assess their practical value. Therefore, with GI endoscopy ML at the jumpoff point from proofofprinciple studies to clinical trials, van der Sommen et al provided us with an accessible guide to understand, assess and critically review the current ML endoscopy literature. Our commentary highlights selected aspects of this review and AI as a whole and elaborates on the role of the GI endoscopy community and how it may both experience and frame the way ahead. In particular, we advocate a close collaboration of technology scientists and clinicians from early development phases onward to allow for the development of welltailored AI algorithms and realistic preclinical testing. More transparency is needed with respect to the training data and the algorithm development process. In addition, in the legislative debates, the endoscopy societies need to play a critical role in defining the research priorities, minimum standards and quality metrics by having a strong voice and presence in this field. Furthermore, we propose the establishment of a ‘rolling gold standard’ to meet requirements for continuous retesting and benchmarking of AI systems.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",78,"2022-07-13 09:21:26","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
0,"Feng Xiaohua, Conrad Marc, E. Elias, Hussein Khalid","Artificial Intelligence and Blockchain for Future Cyber Security Application",2021,"","","","",79,"2022-07-13 09:21:26","","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00133","","",,,,,0,0.00,0,4,1,"AI (Artificial intelligence) application on Big Data had been developed fast. AI cyber security defense for the facing threats were required. Blockchain technology was invented in 2008 with BTC (Bit coin. This technology could be benefited alongside the custom of Blockchain, AI, Big Data and so on. There were a rapid progress in the advancement of Blockchain. This subject had recently become a discussion topic in the ICT (Information and Communications Technology) world. In this paper, AI security is discussed from the initial stage. Suggestion: In this paper, we discussed the impact of AI security from the initial stage and its impact and benefits to IT engineers, ICT students and CS (Computer Sciences) academic researchers, using a case study of medical records with personal recognizable identification privacy information that needs strict access control security. We considered its need for trustworthy cyber security, anti-fake, anti-alteration and transaction accounting transparency reputation to be applied to the NHS (National Health Service). Lastly, the paper provided some necessarily analysis. Blockchain technology had trustworthy cyber security, anti-fake, anti-alteration and transaction accounting transparency reputation to be considered to be applied to NHS (National Health Service). This short paper provided some analysis necessarily.","",""
0,"F. Filip","AI vs AI (Augmenting [Human] Intellect vs Artificial Intelligence) : Plenary Talk",2021,"","","","",80,"2022-07-13 09:21:26","","10.1109/SACI51354.2021.9465578","","",,,,,0,0.00,0,1,1,"Almost six decades ago, when proposing the scientific programme of Stanford Research Institute (SRI), Engelbart (1962) stated: “…By augmenting human intellect we mean increasing the capability of a man to approach a complex problem situation, to gain comprehension to suit his particular needs, and to derive solutions to problems.” More than twenty-five years, later Engelbart and Lehtman (1988) noticed that “In the optimum design [of a CSCW system], either a tool system or a human system is dependent on the match it must make with the other. The high degree of dependence implies that balanced co-evolution of both is necessary.” This paper aims at presenting how the usage of AI (Artificial Intelligence) has evolved towards a trustworthy discipline and set of tools and facilitated the augmenting the human intellect in order to enable the human to approach and solve complex problems of the day.","",""
0,"Victoria Tucci, J. Saary, Thomas E. Doyle","Factors influencing trust in medical artificial intelligence for healthcare professionals: a narrative review",2021,"","","","",81,"2022-07-13 09:21:26","","10.21037/jmai-21-25","","",,,,,0,0.00,0,3,1,"Objective: We performed a comprehensive review of the literature to better understand the trust dynamics between medical artificial intelligence (AI) and healthcare expert end-users. We explored the factors that influence trust in these technologies and how they compare to established concepts of trust in the engineering discipline. By identifying the qualitatively and quantitatively assessed factors that influence trust in medical AI, we gain insight into understanding how autonomous systems can be optimized during the development phase to improve decision-making support and clinician-machine teaming. This facilitates an enhanced understanding of the qualities that healthcare professional users seek in AI to consider it trustworthy. We also highlight key considerations for promoting on-going improvement of trust in autonomous medical systems to support the adoption of medical technologies into practice. Background: decision support systems introduces challenges and barriers to adoption and implementation into clinical practice. Methods: We searched databases including, Ovid MEDLINE, Ovid EMBASE, Clarivate Web of Science, and Google Scholar, as well as gray literature, for publications from 2000 to July 15, 2021, that reported features of AI-based diagnostic and clinical decision support systems that contribute to enhanced end-user trust. Papers discussing implications and applications of medical AI in clinical practice were also recorded. Results were based on the quantity of papers that discussed each trust concept, either quantitatively or qualitatively, using frequency of concept commentary as a proxy for importance of a respective concept. Conclusions: Explainability, transparency, interpretability, usability, and education are among the key identified factors thought to influence a healthcare professionals’ trust in medical AI and enhance clinician-machine teaming in critical decision-making healthcare environments. We also identified the need to better evaluate and incorporate other critical factors to promote trust by consulting medical professionals when developing AI systems for clinical decision-making and diagnostic support.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",82,"2022-07-13 09:21:26","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
27,"Angeliki Kerasidou","Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare",2020,"","","","",83,"2022-07-13 09:21:26","","10.2471/BLT.19.237198","","",,,,,27,13.50,27,1,2,"Abstract Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, society needs to re-examine what kind of health care it ought to promote.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",84,"2022-07-13 09:21:26","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
21,"Ala Ekramifard, H. Amintoosi, Amin Hosseini Seno, A. Dehghantanha, R. Parizi","A Systematic Literature Review of Integration of Blockchain and Artificial Intelligence",2020,"","","","",85,"2022-07-13 09:21:26","","10.1007/978-3-030-38181-3_8","","",,,,,21,10.50,4,5,2,"","",""
1,"Michael Tsang, James Enouen, Yan Liu","Interpretable Artificial Intelligence through the Lens of Feature Interaction",2021,"","","","",86,"2022-07-13 09:21:26","","","","",,,,,1,1.00,0,3,1,"Deep learning, alongside other modern machine learning techniques, has become the state of the art solution for a diverse range of real-world tasks. These include a variety of sensitive applications such as healthcare, finance, autonomous driving, criminal justice, and others which all pose significant concerns for fairness, robustness, safety, and trustworthiness. Despite these applications to critical tasks, deep networks are infamously referred to as black-box models because of their total lack of transparency in decision-making. If we are able to gain insight into how a model is coming to its conclusions, we are able to more clearly assess the trustworthiness and validity of its decisions. Consequently, an abundance of ongoing research is attempting to address model interpretability as the key problem to resolving these issues. There are many methods which are currently used to provide explanations of complex model predictions. LIME (Ribeiro et al., 2016) fits a local linear model around a data point, showing which features positively and negatively influence the prediction results. Despite the overall model being nonlinear, the local model gets an interpretable picture of how the model looks at small scales around the data point. Extensions of this method use other interpretable models like small decision tress. Shapley Values and SHAP follows a similar idea to assign a score to each feature, using a gametheoretic formulation which treats each feature as a player causing the final prediction (Lundberg and Lee, 2017). Its more rigorous formulation yields guarantees of its explanations summing up to the prediction score, but practically it usually must be estimated because of its high computational cost. Shuffle-based feature importance permutes the data of each feature to ascertain its importance in the final prediction in comparison to its normal prediction (Fisher et al., 2018). IG uses the fundamental theorem of calculus to provide additive explanations of a prediction (Sundararajan et al., 2017). This method is very popular in computer vision where its computational efficiency and saliency are prized, even though other work has exposed some of its shortcomings in providing an interpretation (Adebayo et al., 2018). Other methods are specifically designed for computer vision like TCAV (Kim et al., 2018) which finds a ‘concept direction’ corresponding to a large sample of concept images from the user. Surprisingly, all of these most popular interpretability methods share the same one limitation. None of these methods consider the shared importance of groups of two or more features; they only look at the effects had by each of the features individually. A feature interaction between two variables broadly describes a situation where both of the features/ variables are simultaneously important for a model’s prediction. In text applications for sentiment, ”not good” is a very simple example of two words strongly interacting with one another to create a negative sentiment. In modern-day applications, neural networks are usually hailed as amazing function approximators exactly because of their incredible ability to automatically uncover these kinds of complex relationships between the variables of the dataset. In many ways, however,","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",87,"2022-07-13 09:21:26","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",88,"2022-07-13 09:21:26","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",89,"2022-07-13 09:21:26","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",90,"2022-07-13 09:21:26","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
13,"Yuanbin Wang, P. Zheng, Tao Peng, Huayong Yang, J. Zou","Smart additive manufacturing: Current artificial intelligence-enabled methods and future perspectives",2020,"","","","",91,"2022-07-13 09:21:26","","10.1007/s11431-020-1581-2","","",,,,,13,6.50,3,5,2,"","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",92,"2022-07-13 09:21:26","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",93,"2022-07-13 09:21:26","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
8,"Kehua Guo, Sheng Ren, Md Zakirul Alam Bhuiyan, Ting-Bo Li, Dengchao Liu, Zhonghe Liang, Xiang Chen","MDMaaS: Medical-Assisted Diagnosis Model as a Service With Artificial Intelligence and Trust",2020,"","","","",94,"2022-07-13 09:21:26","","10.1109/TII.2019.2937547","","",,,,,8,4.00,1,7,2,"Artificial intelligence has achieved great success in the field of medical-assisted diagnosis, and a deep learning technology plays a very important role in medical image recognition. However, it usually takes medical institutions extra time, energy, and cost to obtain a credible and efficient deep learning model, which is not conducive to a wide range of applications, including medical image recognition and medical decision making. In this article, we propose a novel medical-assisted diagnosis model as a service (MDMaaS). Medical institutions can obtain and use the medical-assisted diagnosis models from the service providers directly; a model training and a model application in machine learning are assigned to a service provider and a consumer, respectively. We have designed a model acquisition method based on the conventional samples and small samples for MDMaaS providers, and we have also developed a trustworthy model-based recommendation method for MDMaaS consumers, which would help the medical institutions to obtain the reliable medical-assisted diagnosis models quickly and efficiently. Based on the MDMaaS, extensive experiments are performed to verify the effectiveness of the proposed method.","",""
8,"Steven Lockey, N. Gillespie, Caitlin Curtis","Trust in Artificial Intelligence: Australian Insights",2020,"","","","",95,"2022-07-13 09:21:26","","10.14264/b32f129","","",,,,,8,4.00,3,3,2,"Artificial Intelligence (AI) is the cornerstone technology of the Fourth Industrial Revolution and is enabling rapid innovation with many potential benefits for Australian society (e.g. enhanced healthcare diagnostics, transportation optimisation) and business (e.g. enhanced efficiency and competitiveness). The COVID-19 pandemic has accelerated the uptake of advanced technology, and investment in AI continues to grow exponentially.AI also poses considerable risks and challenges to society which raises concerns about whether AI systems are worthy of trust. These concerns have been fuelled by high profile cases of AI use that were biased, discriminatory, manipulative, unlawful, or violated privacy or other human rights. Without public confidence that AI is being developed and used in an ethical and trustworthy manner, it will not be trusted and its full potential will not be realised. To echo the sentiment of Dr Alan Finkel AO, Australia’s Chief Scientist, acceptance of AI rests on “the essential foundation of trust”. Are we capable of extending our trust to AI?This national survey is the first to take a deep dive into answering this question and understanding community trust and expectations in relation to AI. To do this, we surveyed a nationally representative sample of over 2,500 Australian citizens in June to July 2020. Our findings provide important and timely research insights into the public’s trust and attitudes towards AI and lay out a pathway for strengthening trust and acceptance of AI systems.Key findings include:              - Trust is central to the acceptance of AI, and is influenced by four key drivers;              - Australians have low trust in AI systems but generally ‘accept’ or ‘tolerate’ AI;              - Australians expect AI to be regulated and carefully managed;              - Australians expect organisations to uphold the principles of trustworthy AI;              - Australians feel comfortable with some but not all uses of AI at work;              - Australians want to know more about AI but currently have low awareness and understanding of AI and its uses.We draw out the implications of the findings for government, business and NGOs and provide a roadmap to enhancing public trust in AI highlighting three key actions:              - Live up to Australian’s expectations of trustworthy AI              - Strengthen the regulatory framework for governing AI              - Strengthen Australia’s AI literacy","",""
7,"Sonal Jain, Manan Luthra, Shagun Sharma, Mehtab Fatima","Trustworthiness of Artificial Intelligence",2020,"","","","",96,"2022-07-13 09:21:26","","10.1109/ICACCS48705.2020.9074237","","",,,,,7,3.50,2,4,2,"This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",97,"2022-07-13 09:21:26","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
6,"I. B. Ajenaghughrure, S. Sousa, D. Lamas","Risk and Trust in artificial intelligence technologies: A case study of Autonomous Vehicles",2020,"","","","",98,"2022-07-13 09:21:26","","10.1109/HSI49210.2020.9142686","","",,,,,6,3.00,2,3,2,"This study investigates how risk influences users’ trust before and after interactions with technologies such as autonomous vehicles (AVs’). Also, the psychophysiological correlates of users’ trust from users” eletrodermal activity responses. Eighteen (18) carefully selected participants embark on a hypothetical trip playing an autonomous vehicle driving game. In order to stay safe, throughout the drive experience under four risk conditions (very high risk, high risk, low risk and no risk) that are based on automotive safety and integrity levels (ASIL D, C, B, A), participants exhibit either high or low trust by evaluating the AVs’ to be highly or less trustworthy and consequently relying on the Artificial intelligence or the joystick to control the vehicle. The result of the experiment shows that there is significant increase in users’ trust and user's delegation of controls to AVs’ as risk decreases and vice-versa. In addition, there was a significant difference between user's initial trust before and after interacting with AVs’ under varying risk conditions. Finally, there was a significant correlation in users’ psychophysiological responses (electrodermal activity) when exhibiting higher and lower trust levels towards AVs’. The implications of these results and future research opportunities are discussed.","",""
6,"P. Almeida, Carlos Denner dos Santos, Josivânia Silva Farias","Artificial Intelligence Regulation: A Meta-Framework for Formulation and Governance",2020,"","","","",99,"2022-07-13 09:21:26","","10.24251/hicss.2020.647","","",,,,,6,3.00,2,3,2,"This article presents a meta-framework for Artificial Intelligence (AI) regulation that encompasses all stages of international public policy-making, from formulation to sustainable governance. Based on a vast systematic review of the literature on Artificial Intelligence Regulation (AIR) published between 2009 and 2019, a dispersed body of knowledge organized under the label “framework” was identified, containing 15 unique frameworks and several different theories that created a complex scientific scenario for research and practice. Theories and principles as diverse as Agile and Ethics were found. Thus, a structured analytical method was followed to integrate this bulk of knowledge into a cohesive, synthetic, and generic theoretical tool. The resulting “AIR framework” provides a trustworthy lens for societies to think collectively and make informed policy decisions related to what, when, and how the uses and applications of AI should be regulated. Moreover, the novel framework organizes the latest developments in the area in a format that allows future research to be framed in and added to the published literature. The (potential) impacts of AI on society are immense, and therefore the discourses, social negotiations, and applications of this technology should be guided by common grounds in terms of terminology, governance, and social values.","",""
2,"Sylwester Bejger, Stephan Elster","Artificial Intelligence in economic decision making: how to assure a trust?",2020,"","","","",100,"2022-07-13 09:21:26","","10.12775/EIP.2020.028","","",,,,,2,1.00,1,2,2,"Motivation: The decisions made by modern ‘black box’ artificial intelligence models are not understandable and therefore people do not trust them. This limits down the potential power of usage of Artificial Intelligence. Aim: The idea of this text is to show the different initiatives in different countries how AI, especially black box AI, can be made transparent and trustworthy and what kind of regulations will be implemented or discussed to be implemented. We also show up how a commonly used development process within Machine Learning can be enriched to fulfil the requirements e.g. of the Ethics guidelines for trustworthy AI of the High-Level Expert Group of the European Union. We support our discussion with a proposition of empirical tools providing interpretability. Results: The full potential of AI or products using AI can only be raised if the decision of AI models are transparent and trustworthy. Regulations which are followed over the whole life cycle of AI models, algorithms or the products they using these are therefore necessary as well as understandability or explainability of the decisions these models and algorithms made. Initiatives on every level of stakeholders started, e.g. international level on the European Union, country level, USA, China etc. as well on a company level. The post-hoc local interpretability methods could and should be implemented by economic decision makers to provide compliance with the regulations.","",""
2,"Sylwester Bejger, Stephan Elster","Artificial Intelligence in economic decision making: how to assure a trust?",2020,"","","","",101,"2022-07-13 09:21:26","","10.12775/EIP.2020.028","","",,,,,2,1.00,1,2,2,"Motivation: The decisions made by modern ‘black box’ artificial intelligence models are not understandable and therefore people do not trust them. This limits down the potential power of usage of Artificial Intelligence. Aim: The idea of this text is to show the different initiatives in different countries how AI, especially black box AI, can be made transparent and trustworthy and what kind of regulations will be implemented or discussed to be implemented. We also show up how a commonly used development process within Machine Learning can be enriched to fulfil the requirements e.g. of the Ethics guidelines for trustworthy AI of the High-Level Expert Group of the European Union. We support our discussion with a proposition of empirical tools providing interpretability. Results: The full potential of AI or products using AI can only be raised if the decision of AI models are transparent and trustworthy. Regulations which are followed over the whole life cycle of AI models, algorithms or the products they using these are therefore necessary as well as understandability or explainability of the decisions these models and algorithms made. Initiatives on every level of stakeholders started, e.g. international level on the European Union, country level, USA, China etc. as well on a company level. The post-hoc local interpretability methods could and should be implemented by economic decision makers to provide compliance with the regulations.","",""
2,"M. Maciejewski, Christina E. M. Ratcliff","Artificial Intelligence (AI): new developments and innovations applied to e-commerce",2020,"","","","",102,"2022-07-13 09:21:26","","","","",,,,,2,1.00,1,2,2,"This in-depth analysis discusses the opportunities and challenges brought by the recent and the foreseeable developments of Artificial Intelligence into online platforms and marketplaces. The paper advocates the importance to support trustworthy, explainable AI (in order to fight discrimination and manipulation, and empower citizens), and societal-aware AI (in order to fight polarisation, monopolistic concentration and excessive inequality, and pursue diversity and openness). This document was provided by the Policy Department for Economic, Scientific and Quality of Life Policies at the request of the committee on the Internal Market and Consumer Protection (IMCO). Artificial Intelligence (AI): new developments and innovations applied to e-commerce Challenges to the functioning of the Internal Market This document was requested by the European Parliament's committee on the Internal Market and Consumer Protection. AUTHORS Dino PEDRESCHI, University of Pisa, Italy Ioanna MILIOU, University of Pisa, Italy ADMINISTRATORS RESPONSIBLE Mariusz MACIEJEWSKI Christina RATCLIFF EDITORIAL ASSISTANT Roberto BIANCHINI LINGUISTIC VERSIONS Original: EN ABOUT THE EDITOR Policy departments provide in-house and external expertise to support EP committees and other parliamentary bodies in shaping legislation and exercising democratic scrutiny over EU internal policies. To contact the Policy Department or to subscribe for updates, please write to: Policy Department for Economic, Scientific and Quality of Life Policies European Parliament L-2929 Luxembourg Email: Poldep-Economy-Science@ep.europa.eu Manuscript completed: May 2020 Date of publication: May 2020 © European Union, 2020 This document is available on the internet at: http://www.europarl.europa.eu/supporting-analyses DISCLAIMER AND COPYRIGHT The opinions expressed in this document are the sole responsibility of the authors and do not necessarily represent the official position of the European Parliament. Reproduction and translation for non-commercial purposes are authorised, provided the source is acknowledged and the European Parliament is given prior notice and sent a copy. For citation purposes, the study should be referenced as: Pedreschi, D., Artificial Intelligence (AI): new developments and innovations applied to e-commerce, Study for the committee on the Internal Market and Consumer Protection, Policy Department for Economic, Scientific and Quality of Life Policies, European Parliament, Luxembourg, 2020. © Cover image used under licence from Shutterstock.com Artificial Intelligence (AI): new developments and innovations applied to e-commerce 3 PE 648.791 CONTENTS LIST OF FIGURES 5 EXECUTIVE SUMMARY 6 1. ARTIFICIAL INTELLIGENCE, BIG DATA, MACHINE LEARNING 9 2. AI-RISKS AND CHALLENGES 11","",""
2,"Angeliki Kerasidou","Empathy, compassion and trust balancing artificial intelligence in health care",2020,"","","","",103,"2022-07-13 09:21:26","","","","",,,,,2,1.00,2,1,2,"Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, there is a need to re-examine what kind of health care society ought to promote is needed. Introduction Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the pursuit of greater efficiency in health care, including economic efficiency, has often resulted in these values being side-lined, making it difficult or even impossible for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care and promises greater efficiency and effectiveness and a level of personalization not possible before. Artificial intelligence could help improve diagnosis and treatment accuracy, streamline workflow processes and speed up the operation of clinics and hospital departments. The hope is that by improving efficiency, time will be freed for health-care professionals to focus more fully on the human side of care, which involves fostering trust relationships and engaging with patients with empathy and Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 2 of 11 compassion. However, the transformative force of artificial intelligence has the potential to disrupt the relationship between health-care professionals and patients as it is currently understood, and challenge both the role and nature of empathy, compassion and trust in health care. In a time of increasing use of artificial intelligence in health care, it is important to re-evaluate whether and how these values could be incorporated and exercised, but most importantly to re-examine what kind of health care society ought to promote. Empathy, compassion and trust Over the past decades, the rise of patient-centred care has shifted the culture of clinical medicine away from paternalism, in which the therapeutic relationship, the relationship between the health-care professional and the patient, is led by medical expertise, towards a more active engagement of patients in shared medical decision-making. This model of engagement requires the health-care professional to understand the patient’s perspective and guide the patient in making the right decision; a decision which reflects the patient’s needs, desires and ideals, and also promotes health-related values. The central point of the patientcentred model of doctor–patient relationship is that medical competency should not be reduced to technical expertise, but must include relational moral competency, particularly empathy, compassion and trust. Empathy, compassion and trust are broadly recognized as fundamental values of good health-care practice. Empathy allows health-care professionals to understand and share the patient’s feelings and perspective. Compassion is the desire to help that is instigated by the empathetic engagement with the patient. Patients seek out and prefer to engage with health professionals who are competent, but also have the right interpersonal and emotional skills. The belief and confidence in the professional’s competency, understanding and desire to help is what underpins patient trust. Research has demonstrated the benefits of trust and empathetic care, including improved patient satisfaction, increased treatment adherence and improved health outcomes. Despite their importance, empathy and compassion in health care are often side-lined. In recent years, for example, socioeconomic factors, including an ageing population and austerity policies in Europe that followed the 2008 economic collapse, have led to the marginalization of these values. As health-care systems struggle with resourcing, the space for empathy and compassion has shrunk while the need for efficiency has grown. In the United Kingdom of Great Britain and Northern Ireland, high-profile cases and reports, such Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 3 of 11 as the Francis report which followed the Mid Staffordshire scandal, the report by the Health Service Ombudsman entitled Dying without dignity and the Leadership Alliance for the Care of Dying People report, all pointed at lack of empathy as a major problem in clinical care. What these cases also showed was a conflicting relationship between the need for empathy and the pursuit of greater economic efficiency and of meeting operational targets. In 2017, Sir Robert Francis, who chaired the inquiry into the Mid Staffordshire scandal, mentioned in an interview that “at the time at Mid Staffordshire there was huge pressure on organizations to balance their books, to make productivity improvements, and matters of that nature. It all became about figures in the books, rather than outcomes for the patient. And I do believe there’s a danger of that happening again.” Research in 2017 in accident and emergency departments in England on the effect of austerity policies on the everyday experiences of health-care professionals found that the pressure to meet targets negatively affected the doctors’ and nurses’ ability and opportunity to practise empathetic and holistic care, which led to moral distress and burnout among these professionals. Against this backdrop, artificial intelligence has been heralded as a way to save struggling national health-care systems and transform the future of health care by providing greater efficiency, effectiveness and high levels of personalized care. Artificial intelligence in health care Artificial intelligence is broadly defined as “computing technologies that resemble processes associated with human intelligence, such as reasoning, learning and adaptation, sensory understanding, and interaction.” The hope is that these technologies will transform healthcare delivery “from streamlining workflow processes to improving the accuracy of diagnosis and personalizing treatment, as well as helping staff work more efficiently and effectively.” Artificial intelligence could help health-care systems achieve greater efficiency, including economic efficiency, in two ways: (i) by improving time to and accuracy of diagnosis and treatment for patients, and where possible assisting with early prevention; and (ii) by using health-care staff more efficiently. A report published in 2018 in the United Kingdom suggested that the national health system could save up to 10% of its running costs by outsourcing repetitive and administrative tasks to artificial intelligence technologies. The same report also envisaged bedside robots performing social-care tasks such helping patients to eat, wash and dress, thus reducing the workload on care staff by 30%. But it is not only nursing and administrative tasks that Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 4 of 11 artificial intelligence can help with. With regard to effectiveness, artificial intelligence systems could be used to deliver better clinical services both by assisting with the diagnosis and management of patients, and by providing the diagnosis and prescribing treatments. Research conducted so far has shown that machines can perform as well as, or even better than, humans in detecting skin cancer, heart arrhythmia and Alzheimer disease. Furthermore, human–machine partnerships can provide far better results than either humans or machines alone. In these examples, the principal benefits of artificial intelligence stem from its ability to improve efficiency and effectiveness by guiding diagnoses, delivering more accurate results and thus eliminating human error. With regard to greater efficiency through prevention, artificial intelligence technologies that track and analyse the movement of individuals could be used to detect people at risk of stroke and eliminate that risk through early intervention. Health care is already using technology to improve its efficiency and effectiveness. From scalpels and syringes to stethoscopes and X-ray machines, the list of technologies used in medicine to facilitate and improve patient care is long. However, artificial intelligence differs from previous medical technological advances. Whereas previous technologies were used to increase the senses and physical capacities of health-care professionals – consider, for example, how the stethoscope enhanced the hearing of doctors and X-rays their vision – the main role of artificial intelligence is to increase their reasoning and decision-making capacities. In this way, artificial intelligence is entering the health-care arena as another morally relevant actor that assists, guides or makes independent decisions regarding the treatment and management of patients. Proponents of artificial intelligence technology in health care maintain that outsourcing tasks and decisions to r","",""
5,"David Abele, Sara D’Onofrio","Artificial Intelligence – The Big Picture",2020,"","","","",104,"2022-07-13 09:21:26","","10.1007/978-3-658-27941-7_2","","",,,,,5,2.50,3,2,2,"","",""
77,"Alon Jacovi, Ana Marasović, Tim Miller, Yoav Goldberg","Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",2020,"","","","",105,"2022-07-13 09:21:26","","10.1145/3442188.3445923","","",,,,,77,38.50,19,4,2,"Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",106,"2022-07-13 09:21:26","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
10,"N. Rodríguez, G. Pisoni","Accessible Cultural Heritage through Explainable Artificial Intelligence",2020,"","","","",107,"2022-07-13 09:21:26","","10.1145/3386392.3399276","","",,,,,10,5.00,5,2,2,"Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy.","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",108,"2022-07-13 09:21:26","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",109,"2022-07-13 09:21:26","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",110,"2022-07-13 09:21:26","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",111,"2022-07-13 09:21:26","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
16,"J. Korteling, G. V. D. Boer-Visschedijk, R. Blankendaal, R. Boonekamp, A. Eikelboom","Human- versus Artificial Intelligence",2021,"","","","",112,"2022-07-13 09:21:26","","10.3389/frai.2021.622364","","",,,,,16,16.00,3,5,1,"AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",113,"2022-07-13 09:21:26","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
141,"S. Seshia, Dorsa Sadigh","Toward verified artificial intelligence",2016,"","","","",114,"2022-07-13 09:21:26","","10.1145/3503914","","",,,,,141,23.50,71,2,6,"Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",115,"2022-07-13 09:21:26","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",116,"2022-07-13 09:21:26","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
32,"Y. Gil, B. Selman","A 20-Year Community Roadmap for Artificial Intelligence Research in the US",2019,"","","","",117,"2022-07-13 09:21:26","","","","",,,,,32,10.67,16,2,3,"Decades of research in artificial intelligence (AI) have produced formidable technologies that are providing immense benefit to industry, government, and society. AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars. The deployment of AI systems has not only created a trillion-dollar industry that is projected to quadruple in three years, but has also exposed the need to make AI systems fair, explainable, trustworthy, and secure. Future AI systems will rightfully be expected to reason effectively about the world in which they (and people) operate, handling complex tasks and responsibilities effectively and ethically, engaging in meaningful communication, and improving their awareness through experience.  Achieving the full potential of AI technologies poses research challenges that require a radical transformation of the AI research enterprise, facilitated by significant and sustained investment. These are the major recommendations of a recent community effort coordinated by the Computing Community Consortium and the Association for the Advancement of Artificial Intelligence to formulate a Roadmap for AI research and development over the next two decades.","",""
32,"K. Letaief, Yuanming Shi, Jianmin Lu, Jianhua Lu","Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications",2021,"","","","",118,"2022-07-13 09:21:26","","10.1109/jsac.2021.3126076","","",,,,,32,32.00,8,4,1,"The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from “connected things” to “connected intelligence”. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",119,"2022-07-13 09:21:26","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
28,"Jian Guan","Artificial Intelligence in Healthcare and Medicine: Promises, Ethical Challenges and Governance.",2019,"","","","",120,"2022-07-13 09:21:26","","10.24920/003611","","",,,,,28,9.33,28,1,3,"Artificial intelligence (AI) is rapidly being applied to a wide range of fields, including medicine, and has been considered as an approach that may augment or substitute human professionals in primary healthcare. However, AI also raises several challenges and ethical concerns. In this article, the author investigates and discusses three aspects of AI in medicine and healthcare: the application and promises of AI, special ethical concerns pertaining to AI in some frontier fields, and suggestive ethical governance systems. Despite great potentials of frontier AI research and development in the field of medical care, the ethical challenges induced by its applications has put forward new requirements for governance. To ensure ""trustworthy"" AI applications in healthcare and medicine, the creation of an ethical global governance framework and system as well as special guidelines for frontier AI applications in medicine are suggested. The most important aspects include the roles of governments in ethical auditing and the responsibilities of stakeholders in the ethical governance system.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",121,"2022-07-13 09:21:26","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
20,"O. Al-Mushayt","Automating E-Government Services With Artificial Intelligence",2019,"","","","",122,"2022-07-13 09:21:26","","10.1109/ACCESS.2019.2946204","","",,,,,20,6.67,20,1,3,"Artificial Intelligence (AI) has recently advanced the state-of-art results in an ever-growing number of domains. However, it still faces several challenges that hinder its deployment in the e-government applications–both for improving the e-government systems and the e-government-citizens interactions. In this paper, we address the challenges of e-government systems and propose a framework that utilizes AI technologies to automate and facilitate e-government services. Specifically, we first outline a framework for the management of e-government information resources. Second, we develop a set of deep learning models that aim to automate several e-government services. Third, we propose a smart e-government platform architecture that supports the development and implementation of AI applications of e-government. Our overarching goal is to utilize trustworthy AI techniques in advancing the current state of e-government services in order to minimize processing times, reduce costs, and improve citizens’ satisfaction.","",""
2,"Jeroen Ooge, G. Štiglic, K. Verbert","Explaining artificial intelligence with visual analytics in healthcare",2021,"","","","",123,"2022-07-13 09:21:26","","10.1002/widm.1427","","",,,,,2,2.00,1,3,1,"To make predictions and explore large datasets, healthcare is increasingly applying advanced algorithms of artificial intelligence. However, to make well‐considered and trustworthy decisions, healthcare professionals require ways to gain insights in these algorithms' outputs. One approach is visual analytics, which integrates humans in decision‐making through visualizations that facilitate interaction with algorithms. Although many visual analytics systems have been developed for healthcare, a clear overview of their explanation techniques is lacking. Therefore, we review 71 visual analytics systems for healthcare, and analyze how they explain advanced algorithms through visualization, interaction, shepherding, and direct explanation. Based on our analysis, we outline research opportunities and challenges to further guide the exciting rapprochement of visual analytics and healthcare.","",""
17,"Nathalie A. Smuha","From a 'Race to AI' to a 'Race to AI Regulation' - Regulatory Competition for Artificial Intelligence",2019,"","","","",124,"2022-07-13 09:21:26","","10.2139/ssrn.3501410","","",,,,,17,5.67,17,1,3,"Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising those risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is (1) a possibility, (2) a reality and (3) a desirability.","",""
0,"Renata Guizzardi, Jennifer Horkoff, A. Perini, A. Susi","Preface: 3rd Workshop on Requirements Engineering for Artificial Intelligence (RE4AI)",2022,"","","","",125,"2022-07-13 09:21:26","","","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) is embedded in software systems used in everyday life, such as cars, household appliances, wearable devices, healthcare chatbots, as well as in a variety of software applications that support data-driven decisions, e.g. business intelligence services for insurance companies. For several years, AI researchers have manifested their worries and recommendations for the responsible use of data, employment of discrimination-free algorithms, alignment of AI-based systems and technologies with human values and transparency. Awareness for the need of approaches for “Responsible AI” has rapidly increased and motivated attention by normative and standardisation organisations (e.g. EU Ethics Guidelines for Trustworthy AI1, and the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems2), software technology big players, and diverse research communities, including Software Engineering and Requirements Engineering research communities. The Requirements Engineering for Artificial Intelligence (RE4AI) workshop aims to provide a forum for discussing how Requirements Engineering methods, techniques and tools may be used to support the development of Artificial Intelligence systems that are lawful, ethical and robust. The main goals of the RE4AI workshop are as follows: raising awareness in the RE community about the importance of RE in realizing Trustworthy AI systems; bringing in the same room people from AI and RE industry and academia to discuss pressing issues, such as how RE can contribute to prevent AI systems to fail or to go rogue; setting up the basis for collaboratively producing a report on the challenges, candidate solution paths, and research","",""
0,"L. Martí-Bonmatí, D. Koh, K. Riklund, Maciej Bobowicz, Y. Roussakis, J. Vilanova, J. Fütterer, J. Rimola, Pedro Mallol, Gloria Ribas, A. Miguel, M. Tsiknakis, K. Lekadir, G. Tsakou","Considerations for artificial intelligence clinical impact in oncologic imaging: an AI4HI position paper",2022,"","","","",126,"2022-07-13 09:21:26","","10.1186/s13244-022-01220-9","","",,,,,0,0.00,0,14,1,"","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",127,"2022-07-13 09:21:26","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
11,"R. Fusco, Adele Piccirillo, M. Sansone, V. Granata, M. Rubulotta, T. Petrosino, M. L. Barretta, P. Vallone, R. di Giacomo, E. Esposito, M. di Bonito, A. Petrillo","Radiomics and Artificial Intelligence Analysis with Textural Metrics Extracted by Contrast-Enhanced Mammography in the Breast Lesions Classification",2021,"","","","",128,"2022-07-13 09:21:26","","10.3390/diagnostics11050815","","",,,,,11,11.00,1,12,1,"The aim of the study was to estimate the diagnostic accuracy of textural features extracted by dual-energy contrast-enhanced mammography (CEM) images, by carrying out univariate and multivariate statistical analyses including artificial intelligence approaches. In total, 80 patients with known breast lesion were enrolled in this prospective study according to regulations issued by the local Institutional Review Board. All patients underwent dual-energy CEM examination in both craniocaudally (CC) and double acquisition of mediolateral oblique (MLO) projections (early and late). The reference standard was pathology from a surgical specimen for malignant lesions and pathology from a surgical specimen or fine needle aspiration cytology, core or Tru-Cut needle biopsy, and vacuum assisted breast biopsy for benign lesions. In total, 104 samples of 80 patients were analyzed. Furthermore, 48 textural parameters were extracted by manually segmenting regions of interest. Univariate and multivariate approaches were performed: non-parametric Wilcoxon–Mann–Whitney test; receiver operating characteristic (ROC), linear classifier (LDA), decision tree (DT), k-nearest neighbors (KNN), artificial neural network (NNET), and support vector machine (SVM) were utilized. A balancing approach and feature selection methods were used. The univariate analysis showed low accuracy and area under the curve (AUC) for all considered features. Instead, in the multivariate textural analysis, the best performance considering the CC view (accuracy (ACC) = 0.75; AUC = 0.82) was reached with a DT trained with leave-one-out cross-variation (LOOCV) and balanced data (with adaptive synthetic (ADASYN) function) and a subset of three robust textural features (MAD, VARIANCE, and LRLGE). The best performance (ACC = 0.77; AUC = 0.83) considering the early-MLO view was reached with a NNET trained with LOOCV and balanced data (with ADASYN function) and a subset of ten robust features (MEAN, MAD, RANGE, IQR, VARIANCE, CORRELATION, RLV, COARSNESS, BUSYNESS, and STRENGTH). The best performance (ACC = 0.73; AUC = 0.82) considering the late-MLO view was reached with a NNET trained with LOOCV and balanced data (with ADASYN function) and a subset of eleven robust features (MODE, MEDIAN, RANGE, RLN, LRLGE, RLV, LZLGE, GLV_GLSZM, ZSV, COARSNESS, and BUSYNESS). Multivariate analyses using pattern recognition approaches, considering 144 textural features extracted from all three mammographic projections (CC, early MLO, and late MLO), optimized by adaptive synthetic sampling and feature selection operations obtained the best results (ACC = 0.87; AUC = 0.90) and showed the best performance in the discrimination of benign and malignant lesions.","",""
12,"Andrea Pazienza, G. Mallardi, Corrado Fasciano, Felice Vitulano","Artificial Intelligence on Edge Computing: a Healthcare Scenario in Ambient Assisted Living",2019,"","","","",129,"2022-07-13 09:21:26","","","","",,,,,12,4.00,3,4,3,"The aging population brings many challenges surrounding the quality of life for older people and their carers, as well as impacts on the healthcare market. Several initiatives all over the world have focused on the problem of helping the aging population with Artificial Intelligence (AI) technology, aiming at promoting a healthier society, which constitutes a main social and economic challenge. In this paper, we focus on an Ambient Assisted Living scenario in which a Smart Home Environment is carried out to assist elders at home, performing trustworthy automated complex decisions by means of IoT sensors, smart healthcare devices, and edge nodes. The core idea is to exploit the proximity between computing and information-generation sources. Taking automated complex decisions with the help AI-based techniques directly on the Edge enables a faster, more private, and context-aware Edge Computing empowering, called Edge Intelligence.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",130,"2022-07-13 09:21:26","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",131,"2022-07-13 09:21:26","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",132,"2022-07-13 09:21:26","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
8,"Hiroshi Kuwajima, F. Ishikawa","Adapting SQuaRE for Quality Assessment of Artificial Intelligence Systems",2019,"","","","",133,"2022-07-13 09:21:26","","10.1109/ISSREW.2019.00035","","",,,,,8,2.67,4,2,3,"More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional software systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and Ethics guidelines for trustworthy AI from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",134,"2022-07-13 09:21:26","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",135,"2022-07-13 09:21:26","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",136,"2022-07-13 09:21:26","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",137,"2022-07-13 09:21:26","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
9,"Anurag Malik, Anil Kumar, Priyan Rai, Alban Kuriqi","Prediction of Multi-Scalar Standardized Precipitation Index by Using Artificial Intelligence and Regression Models",2021,"","","","",138,"2022-07-13 09:21:26","","10.3390/CLI9020028","","",,,,,9,9.00,2,4,1,"Accurate monitoring and forecasting of drought are crucial. They play a vital role in the optimal functioning of irrigation systems, risk management, drought readiness, and alleviation. In this work, Artificial Intelligence (AI) models, comprising Multi-layer Perceptron Neural Network (MLPNN) and Co-Active Neuro-Fuzzy Inference System (CANFIS), and regression, model including Multiple Linear Regression (MLR), were investigated for multi-scalar Standardized Precipitation Index (SPI) prediction in the Garhwal region of Uttarakhand State, India. The SPI was computed on six different scales, i.e., 1-, 3-, 6-, 9-, 12-, and 24-month, by deploying monthly rainfall information of available years. The significant lags as inputs for the MLPNN, CANFIS, and MLR models were obtained by utilizing Partial Autocorrelation Function (PACF) with a significant level equal to 5% for SPI-1, SPI-3, SPI-6, SPI-9, SPI-12, and SPI-24. The predicted multi-scalar SPI values utilizing the MLPNN, CANFIS, and MLR models were compared with calculated SPI of multi-time scales through different performance evaluation indicators and visual interpretation. The appraisals of results indicated that CANFIS performance was more reliable for drought prediction at Dehradun (3-, 6-, 9-, and 12-month scales), Chamoli and Tehri Garhwal (1-, 3-, 6-, 9-, and 12-month scales), Haridwar and Pauri Garhwal (1-, 3-, 6-, and 9-month scales), Rudraprayag (1-, 3-, and 6-month scales), and Uttarkashi (3-month scale) stations. The MLPNN model was best at Dehradun (1- and 24- month scales), Tehri Garhwal and Chamoli (24-month scale), Haridwar (12- and 24-month scales), Pauri Garhwal (12-month scale), Rudraprayag (9-, 12-, and 24-month), and Uttarkashi (1- and 6-month scales) stations, while the MLR model was found to be optimal at Pauri Garhwal (24-month scale) and Uttarkashi (9-, 12-, and 24-month scales) stations. Furthermore, the modeling approach can foster a straightforward and trustworthy expert intelligent mechanism for projecting multi-scalar SPI and decision making for remedial arrangements to tackle meteorological drought at the stations under study.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",139,"2022-07-13 09:21:26","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",140,"2022-07-13 09:21:26","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",141,"2022-07-13 09:21:26","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",142,"2022-07-13 09:21:26","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",143,"2022-07-13 09:21:26","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
7,"F. Arama, Slimane Laribi, T. Ghaitaoui","A Control Method using Artificial Intelligence in Wind Energy Conversion System",2019,"","","","",144,"2022-07-13 09:21:26","","10.46657/ajresd.2019.1.1.6","","",,,,,7,2.33,2,3,3,"This work presents a field-oriented control (FOC) of active and reactive power applied on Doubly Fed Induction Machine (DFIM) integrated in wind energy conversion system (WECS). The main objective of this work is to compare the performances of energy produced by the use of two types of controllers ( PI regulator and the neural network regulator (NN)) in order to control the wind power conversion system to compare their precision & robustness against the wind fluctuation and the impact on the quality of produced energy. A field oriented control of DEFIG stator is also presented to control the active and reactive power. To show the efficiency of the performances and the robustness of the two control methods those were analyzed and compared by simulation using Matlab/Simulink software. The results described the favoured method.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",145,"2022-07-13 09:21:26","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",146,"2022-07-13 09:21:26","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",147,"2022-07-13 09:21:26","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",148,"2022-07-13 09:21:26","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",149,"2022-07-13 09:21:26","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",150,"2022-07-13 09:21:26","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",151,"2022-07-13 09:21:26","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",152,"2022-07-13 09:21:26","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
3,"Laura J. Freeman, Abdul Rahman, Feras A. Batarseh","Enabling Artificial Intelligence Adoption through Assurance",2021,"","","","",153,"2022-07-13 09:21:26","","10.3390/socsci10090322","","",,,,,3,3.00,1,3,1,"The wide scale adoption of Artificial Intelligence (AI) will require that AI engineers and developers can provide assurances to the user base that an algorithm will perform as intended and without failure. Assurance is the safety valve for reliable, dependable, explainable, and fair intelligent systems. AI assurance provides the necessary tools to enable AI adoption into applications, software, hardware, and complex systems. AI assurance involves quantifying capabilities and associating risks across deployments including: data quality to include inherent biases, algorithm performance, statistical errors, and algorithm trustworthiness and security. Data, algorithmic, and context/domain-specific factors may change over time and impact the ability of AI systems in delivering accurate outcomes. In this paper, we discuss the importance and different angles of AI assurance, and present a general framework that addresses its challenges.","",""
3,"Amy Papadopoulos, J. Salinas, Cindy Crump","Computational modeling approaches to characterize risk and achieve safe, effective, and trusted designs in the development of artificial intelligence and autonomous closed-loop medical systems",2021,"","","","",154,"2022-07-13 09:21:26","","10.1117/12.2586101","","",,,,,3,3.00,1,3,1,"While software using artificial intelligence and machine learning (AI/ML) is pervasive in many areas of society today, the use of these technologies to diagnose and treat medical conditions is limited due to a number of challenges associated with the trustworthiness of the results. This may include the inability to fully explain how an algorithm works inherent to the black-box nature of the system. Additionally, AI/ML may create a potential for bias and artifacts that cannot be validated due to the same limitations. In a medical application, the lack of transparency in how the system operates may lead to a loss of trust by users. Bayesian approaches that use computational modeling to quantify the level of uncertainty in a given result may provide a path towards improved confidence and use. In this paper, evidence from studies in a range of medical applications is presented and discussed, showing how Bayesian approaches can help to foster trust. A retrospective study using a publicly available dataset explored the feasibility of creating predictive models for early intervention in a Type 1 diabetes population. Creating the perfect model was not the goal of the exercise, rather the study aimed to demonstrate how Bayesian methods could be used to identify areas of uncertainty during model development. Feature selection was based on analytical assessment of various patterns found in the data. Models were trained, validated, and tested, generating uncertainty estimates. A two-feature Gaussian Naïve Bayes (GNB) model, using the previous five minutes and ten minutes of blood glucose values, showed similar results for predictive accuracy as a threefeature model that included average change over the preceding 30 minutes. The two-feature model was selected because it allowed for a more easily understood visualization of uncertainty. The 2-feature GNB achieved an AUC = .94. The model showed good sensitivity for exceeding the < 180 mg/dl limit, obtaining threshold prediction = 89.8% and normal range prediction = 90.8%. The sensitivity was lower for the < 70 mg/dl limit, attaining a sensitivity = 77.5%. Posterior probabilities showed differing levels of uncertainty in the prediction of high and low out-of-range conditions. The model demonstrated the feasibility of providing robust parameter estimates. Bayesian machine learning approaches to model uncertainty may improve the transparency, explainability, and applicability of AI/ML in medical treatment, realizing the promise to improve patient safety and outcomes.","",""
3,"I. Godinho, Cláudio R. Flores, Nuno Castro Marques","CONSULTATION ON THE WHITE PAPER ON ARTIFICIAL INTELLIGENCE - A EUROPEAN APPROACH",2021,"","","","",155,"2022-07-13 09:21:26","","10.46294/ULPLR-RDULP.V14I1.7475","","",,,,,3,3.00,1,3,1,"SUMMARY     From 19 February to 14 June 2020, the European Commission held a Public Consultation on several policy and regulatory proposals that are currently being considered in the area of Artificial Intelligence (AI).  This consultation was centered on two main documents presented by the Commission: the White Paper on Artificial Intelligence[1] and the “Report on the safety and liability implications of Artificial Intelligence, the Internet of Things and robotics”[2].  The consultation also included an online survey[3], where the central themes of those two documents were covered in a summarized way.  In November 2020, the results of the consultation were presented, as well as the texts accepted for publication[4].  In order to participate in this pre-legislative process, a working group was created within the Faculty of Law and Political Science of the Lusófona University of Porto, which presented a contribution that was accepted and published by the European Commission[5].  The White Paper is centred in one powerful objective which is “to enable a trustworthy and secure development of AI in Europe, in full respect of the values and rights of EU citizens”, and for that presents two central ideas considered essential to attain it that are to create an ecosystem of excellence along the entire value chain and an ecosystem of trust that ensure compliance with EU rules, including rules protecting fundamental rights and consumers’ rights.   The text that follows is divided in two main parts: Part I is focused on presenting an overview on the three main topics pointed out at the consultation: Excellence, Trust and Liability; Part II corresponds to text of the contribution submitted in the Public Consultation held by the European Commission.     Keywords: Artificial Intelligence; Liability; Cybercrime; Ethics; Competition","",""
3,"M. Padmaja, S. Shitharth, K. Prasuna, Abhay Chaturvedi, P. Kshirsagar, A. Vani","Grow of Artificial Intelligence to Challenge Security in IoT Application",2021,"","","","",156,"2022-07-13 09:21:26","","10.1007/s11277-021-08725-4","","",,,,,3,3.00,1,6,1,"","",""
3,"Jessica Van Brummelen, Viktoriya Tabunshchyk, Tommy Heng","“Alexa, Can I Program You?”: Student Perceptions of Conversational Artificial Intelligence Before and After Programming Alexa",2021,"","","","",157,"2022-07-13 09:21:26","","10.1145/3459990.3460730","","",,,,,3,3.00,1,3,1,"Growing up in an artificial intelligence-filled world, with Siri and Amazon Alexa often within arm’s—or speech’s—reach, could have significant impact on children. Conversational agents could influence how students anthropomorphize computer systems or develop a theory of mind. Previous research has explored how conversational agents are used and perceived by children within and outside of learning contexts. This study investigates how middle and high school students’ perceptions of Alexa change through programming their own conversational agents in week-long AI education workshops. Specifically, we investigate the workshops’ influence on student perceptions of Alexa’s intelligence, friendliness, aliveness, safeness, trustworthiness, human-likeness, and feelings of closeness. We found that students felt Alexa was more intelligent and felt closer to Alexa after the workshops. We also found strong correlations between students’ perceptions of Alexa’s friendliness and trustworthiness, and safeness and trustworthiness. We recommend designers carefully consider personification, transparency, playfulness and utility when designing conversational agents for learning contexts.","",""
2,"Xiang Bai, Hanchen Wang, Liya Ma, Yongchao Xu, Jiefeng Gan, Ziwei Fan, Fan Yang, Ke Ma, Jiehua Yang, S. Bai, Chang Shu, X. Zou, Renhao Huang, Changzheng Zhang, Xiaowu Liu, Dandan Tu, Chuou Xu, Wenqing Zhang, X. Wang, Anguo Chen, Yu Zeng, Dehua Yang, Ming-Wei Wang, N. Holalkere, N. Halin, I. Kamel, Jia Wu, Xue-Hua Peng, Xiang Wang, Jianbo Shao, P. Mongkolwat, Jianjun Zhang, Weiyang Liu, Michael Roberts, Z. Teng, L. Beer, Lorena E. Sanchez, E. Sala, D. Rubin, Adrian Weller, Joan Lasenby, Chuangsheng Zheng, Jianming Wang, Zhen Li, C. Schonlieb, Tian Xia","Advancing COVID-19 Diagnosis with Privacy-Preserving Collaboration in Artificial Intelligence",2021,"","","","",158,"2022-07-13 09:21:26","","10.1038/s42256-021-00421-z","","",,,,,2,2.00,0,46,1,"","",""
2,"D. Cyman, E. Gromova, E. Juchnevicius","Regulation of Artificial Intelligence in BRICS and the European Union",2021,"","","","",159,"2022-07-13 09:21:26","","10.21684/2412-2343-2021-8-1-86-115","","",,,,,2,2.00,1,3,1,"Global digitization and the emergence of Artificial Intelligence-based technologies pose challenges for all countries. The BRICS and European Union countries are no exception. BRICS as well as the European Union seek to strengthen their positions as leading actors on the world stage. At the present time, an essential means of doing so is for BRICS and the EU to implement smart policy and create suitable conditions for the development of digital technologies, including AI. For this reason, one of the most important tasks for BRICS and the EU is to develop an adequate approach to the regulation of AI-based technologies. This research paper is an analysis of the current approaches to the regulation of AI at the BRICS group level, in each of the BRICS countries, and in the European Union. The analysis is based on the application of comparative and formal juridical analysis of the legislation of the selected countries on AI and other digital technologies. The results of the analysis lead the authors to conclude that it is necessary to design ageneral approach to the regulation of these technologies for the BRICS countries similar to the approach chosen in the EU (the trustworthy approach) and to upgrade this legislation to achieve positive effects from digital transformation. The authors offer several suggestions for optimization of the provisions of the legislation, including designing a model legal act in the sphere of AI.","",""
2,"M. Kabir, Khondokar Fida Hasan, M Zahid Hasan, Keyvan Ansari","Explainable Artificial Intelligence for Smart City Application: A Secure and Trusted Platform",2021,"","","","",160,"2022-07-13 09:21:26","","","","",,,,,2,2.00,1,4,1,"Artificial Intelligence (AI) is one of the disruptive technologies that is shaping the future. It has growing applications for data-driven decisions in major smart city solutions, including transportation, education, healthcare, public governance, and power systems. At the same time, it is gaining popularity in protecting critical cyber infrastructure from cyber threats, attacks, damages, or unauthorized access. However, one of the significant issues of those traditional AI technologies (e.g., deep learning) is that the rapid progress in complexity and sophistication propelled and turned out to be uninterpretable black boxes. On many occasions, it is very challenging to understand the decision and bias to control and trust systems’ unexpected or seemingly unpredictable outputs. It is acknowledged that the loss of control over interpretability of decision-making becomes a critical issue for many data-driven automated applications. But how may it affect the system’s security and trustworthiness? This chapter conducts a comprehensive study of machine learning applications in cybersecurity to indicate the need for explainability to address this question. While doing that, this chapter first discusses the black-box problems of AI technologies for Cybersecurity applications in smart city-based solutions. Later, considering the new technological paradigm, Explainable Artificial Intelligence (XAI), this chapter discusses the transition from black-box to white-box. This chapter also discusses the transition requirements concerning the interpretability, transparency, understandability, and Explainability of AI-based technologies in applying different autonomous systems in smart cities. Finally, it has presented some commercial XAI platforms that offer explainability over traditional AI technologies before presenting future challenges and opportunities.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",161,"2022-07-13 09:21:26","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",162,"2022-07-13 09:21:26","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",163,"2022-07-13 09:21:26","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",164,"2022-07-13 09:21:26","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"Nigamanth Sridhar, Li Yang, J. Joshi, Victor P. Piotrowski","Cybersecurity Education in the Age of Artificial Intelligence",2021,"","","","",165,"2022-07-13 09:21:26","","10.1145/3408877.3439525","","",,,,,0,0.00,0,4,1,"The 2019 Federal Cybersecurity Research and Development Strategic Plan highlighted the mutual needs and benefits of artificial intelligence (AI) and cybersecurity. AI techniques are expected to enhance cybersecurity by assisting human system managers with automated monitoring, analysis, and responses to cybersecurity attacks. Conversely, it is essential to guard AI technologies from unintended uses and hostile exploitation by leveraging cybersecurity practices. Research results at the intersection of AI and cybersecurity can help us to be better equipped with tools and techniques to tackle the growing cybersecurity challenges, while also presenting an opportunity to devise fundamentally new ways to motivate and educate students about cybersecurity in the age of AI. Likewise, a June 2019 technical workshop on 'Artificial Intelligence and Cybersecurity: Opportunities and Challenges' noted how the interplay between AI, machine learning, and cybersecurity will continue to introduce new opportunities and challenges in the security of AI as well as AI for cybersecurity. Basic research at the intersection of AI, cybersecurity, and education has the potential to expand existing AI opportunities and resources in cybersecurity education and workforce development. Education efforts are needed to foster workforce knowledge and skills about applying AI expertise to cybersecurity as well as building robust and trustworthy AI. This BOF session will bring together researchers who are interested in these collaborative explorations.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",166,"2022-07-13 09:21:26","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",167,"2022-07-13 09:21:26","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",168,"2022-07-13 09:21:26","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",169,"2022-07-13 09:21:26","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",170,"2022-07-13 09:21:26","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",171,"2022-07-13 09:21:26","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",172,"2022-07-13 09:21:26","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",173,"2022-07-13 09:21:26","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
45,"H. Abbass","Social Integration of Artificial Intelligence: Functions, Automation Allocation Logic and Human-Autonomy Trust",2019,"","","","",174,"2022-07-13 09:21:26","","10.1007/s12559-018-9619-0","","",,,,,45,15.00,45,1,3,"","",""
52,"B. Shneiderman","Human-Centered Artificial Intelligence: Three Fresh Ideas",2020,"","","","",175,"2022-07-13 09:21:26","","10.17705/1thci.00131","","",,,,,52,26.00,52,1,2,"Human-Centered AI (HCAI) is a promising direction for designing AI systems that support human self-efficacy, promote creativity, clarify responsibility, and facilitate social participation. These human aspirations also encourage consideration of privacy, security, environmental protection, social justice, and human rights. This commentary reverses the current emphasis on algorithms and AI methods, by putting humans at the center of systems design thinking, in effect, a second Copernican Revolution. It offers three ideas: (1) a two-dimensional HCAI framework, which shows how it is possible to have both high levels of human control AND high levels of automation, (2) a shift from emulating humans to empowering people with a plea to shift language, imagery, and metaphors away from portrayals of intelligent autonomous teammates towards descriptions of powerful tool-like appliances and tele-operated devices, and (3) a three-level governance structure that describes how software engineering teams can develop more reliable systems, how managers can emphasize a safety culture across an organization, and how industry-wide certification can promote trustworthy HCAI systems. These ideas will be challenged by some, refined by others, extended to accommodate new technologies, and validated with quantitative and qualitative research. They offer a reframe -a chance to restart design discussions for products and services -which could bring greater benefits to individuals, families, communities, businesses, and society.","",""
6,"O. Marques, F. Kitamura","Trustworthiness of Artificial Intelligence Models in Radiology and the Role of Explainability.",2021,"","","","",176,"2022-07-13 09:21:26","","10.1016/j.jacr.2021.02.008","","",,,,,6,6.00,3,2,1,"","",""
21,"D. Mollura, M. Culp, E. Pollack, Gillian Battino, J. Scheel, Victoria L. Mango, A. Elahi, A. Schweitzer, F. Dako","Artificial Intelligence in Low- and Middle-Income Countries: Innovating Global Health Radiology.",2020,"","","","",177,"2022-07-13 09:21:26","","10.1148/radiol.2020201434","","",,,,,21,10.50,2,9,2,"Scarce or absent radiology resources impede adoption of artificial intelligence (AI) for medical imaging by resource-poor health institutions. They face limitations in local equipment, personnel expertise, infrastructure, data-rights frameworks, and public policies. The trustworthiness of AI for medical decision making in global health and low-resource settings is hampered by insufficient data diversity, nontransparent AI algorithms, and resource-poor health institutions' limited participation in AI production and validation. RAD-AID's three-pronged integrated strategy for AI adoption in resource-poor health institutions is presented, which includes clinical radiology education, infrastructure implementation, and phased AI introduction. This strategy derives from RAD-AID's more-than-a-decade experience as a nonprofit organization developing radiology in resource-poor health institutions, both in the United States and in low- and middle-income countries. The three components synergistically provide the foundation to address health care disparities. Local radiology personnel expertise is augmented through comprehensive education. Software, hardware, and radiologic and networking infrastructure enables radiology workflows incorporating AI. These educational and infrastructure developments occur while RAD-AID delivers phased introduction, testing, and scaling of AI via global health collaborations.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",178,"2022-07-13 09:21:26","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",179,"2022-07-13 09:21:26","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",180,"2022-07-13 09:21:26","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",181,"2022-07-13 09:21:26","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",182,"2022-07-13 09:21:26","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",183,"2022-07-13 09:21:26","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
23,"V. Mishra","Artificial Intelligence: The Beginning of a New Era in Pharmacy Profession",2018,"","","","",184,"2022-07-13 09:21:26","","10.22377/AJP.V12I02.2317","","",,,,,23,5.75,23,1,4,"Artificial intelligence (AI) is a branch of computer science that deals with the problem-solving by the aid of symbolic programming. It has greatly evolved into a science of problem-solving with huge applications in business, health care, and engineering. One of the pivotal applications of AI is the development of the expert system. With the advent of big data and AI, robots are now becoming more trustworthy for doctors, and a large number of institutions are now employing robots along with human supervision to carry out activities that were previously done by humans. The major advantage of AI is that it reduces the time that is needed for drug development and, in turn, it reduces the costs that are associated with drug development, enhances the returns on investment and may even cause a decrease in cost for the end user. A large number of researches are being carried out to improve the current available AI technology to make the pharmacy profession more efficient. The present article briefly describes the importance of AI in the process of drug development and then looks at the various AI tools that are available at the disposal of a modern-day pharmacist to aid in a more efficient functioning.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",185,"2022-07-13 09:21:26","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",186,"2022-07-13 09:21:26","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",187,"2022-07-13 09:21:26","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
14,"M. Yazdani-Asrami, Mehran Taghipour-Gorjikolaie, Wenjuan Song, Min Zhang, W. Yuan","Prediction of Nonsinusoidal AC Loss of Superconducting Tapes Using Artificial Intelligence-Based Models",2020,"","","","",188,"2022-07-13 09:21:26","","10.1109/ACCESS.2020.3037685","","",,,,,14,7.00,3,5,2,"Current is no longer sinusoidal in modern electric networks because of widespread use of power electronic-based equipments and nonlinear loads. Usually AC loss is calculated for pure sinusoidal current, while it is no longer accurate when current is nonsinusoidal. On the other hand, efficiency of cooling system in large scale power devices is dependent on accurate estimation and prediction of the heat load caused by AC loss in design stage. Therefore, estimation of nonsinusoidal AC loss of high temperature superconducting (HTS) material would be of great interest for designers of large-scale superconducting devices. In this paper, at first nonsinusoidal AC loss of a typical HTS tape was calculated under distorted currents using H-formulation finite element method. Then, a range of artificial intelligence (AI) models were implemented to predict AC loss of a typical HTS tape. In order to find the best and more adaptive AI model for nonsinusoidal AC loss prediction, different regression models are evaluated using Support Vector Machine regression model, Generalized Linear regression model, Decision Tree regression model, Feed Forward Neural Network based model, Adaptive Neuro Fuzzy Inference System based model, and Radial Basis Function Neural Network (RBFNN) based model. In order to evaluate robustness of developed models cross-validation technique is implemented on experimental data. To compare the performance of different AI models, four prediction measures were used: Theil’s U coefficients (U_Accuracy and U_Quality), Root Mean Square Error (RMSE) and Regression value (R-value). Obtained results show that best performance belongs to RBFNN based model and then ANFIS based model. U coefficients and RMSE values are obtained less than 0.005 and R-Value is become close to one by using RBFNN based model for testing data, which indicates high accuracy prediction performance.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",189,"2022-07-13 09:21:26","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
14,"E. Kotter, E. Ranschaert","Challenges and solutions for introducing artificial intelligence (AI) in daily clinical workflow",2020,"","","","",190,"2022-07-13 09:21:26","","10.1007/s00330-020-07148-2","","",,,,,14,7.00,7,2,2,"","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",191,"2022-07-13 09:21:26","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",192,"2022-07-13 09:21:26","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
12,"M. Pedersen, K. Verspoor, M. Jenkinson, M. Law, D. Abbott, G. Jackson","Artificial intelligence for clinical decision support in neurology",2020,"","","","",193,"2022-07-13 09:21:26","","10.1093/braincomms/fcaa096","","",,,,,12,6.00,2,6,2,"Abstract Artificial intelligence is one of the most exciting methodological shifts in our era. It holds the potential to transform healthcare as we know it, to a system where humans and machines work together to provide better treatment for our patients. It is now clear that cutting edge artificial intelligence models in conjunction with high-quality clinical data will lead to improved prognostic and diagnostic models in neurological disease, facilitating expert-level clinical decision tools across healthcare settings. Despite the clinical promise of artificial intelligence, machine and deep-learning algorithms are not a one-size-fits-all solution for all types of clinical data and questions. In this article, we provide an overview of the core concepts of artificial intelligence, particularly contemporary deep-learning methods, to give clinician and neuroscience researchers an appreciation of how artificial intelligence can be harnessed to support clinical decisions. We clarify and emphasize the data quality and the human expertise needed to build robust clinical artificial intelligence models in neurology. As artificial intelligence is a rapidly evolving field, we take the opportunity to iterate important ethical principles to guide the field of medicine is it moves into an artificial intelligence enhanced future.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",194,"2022-07-13 09:21:26","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",195,"2022-07-13 09:21:26","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",196,"2022-07-13 09:21:26","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",197,"2022-07-13 09:21:26","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
11,"S. Goto, K. Mahara, L. Beussink-Nelson, H. Ikura, Y. Katsumata, J. Endo, H. Gaggin, S. J. Shah, Y. Itabashi, C. Macrae, R. Deo","Artificial Intelligence-Enabled, Fully Automated Detection of Cardiac Amyloidosis Using Electrocardiograms and Echocardiograms.",2020,"","","","",198,"2022-07-13 09:21:26","","10.1101/2020.07.02.20141028","","",,,,,11,5.50,1,11,2,"Although individually uncommon, rare diseases collectively affect over 350 million patients worldwide and are increasingly the target of therapeutic development efforts. Unfortunately, the pursuit and use of such therapies have been hindered by a common challenge: patients with specific rare diseases are difficult to identify, especially if the conditions resemble more prevalent disorders. Cardiac amyloidosis is one such rare disease, which is characterized by deposition of misfolded proteins within the heart muscle resulting in heart failure and death. In recent years, specific therapies have emerged for cardiac amyloidosis and several more are under investigation, but because cardiac amyloidosis is mistaken for common forms of heart failure, it is typically diagnosed late in its course. As a possible solution, artificial intelligence methods could enable automated detection of rare diseases, but model performance must address low disease prevalence. Here we present an automated multi-modality pipeline for cardiac amyloidosis detection using two neural-network models; one using electrocardiograms (ECG) and the second using echocardiographic videos as input. These models were trained and validated on 3 and 5 academic medical centers (AMC), respectively, in the United States and Japan. Both models had excellent accuracy for detecting cardiac amyloidosis with C-statistics of 0.85-0.92 and 0.91-1.00 for the ECG and echocardiography models, respectively, with the latter outperforming expert diagnosis. Simulating deployment on 13,906 and 7775 patients with ECG-echocardiography paired data for AMC2 and AMC3 indicated a positive predictive value (PPV) for the ECG model of 4% and 3% at 61% and 54% recall, respectively. Pre-screening with ECG enhanced the echocardiography model performance from PPV 23% and 20% to PPV 58% and 53% at 64% recall, respectively for AMC2 and AMC3. In conclusion, we have developed a robust pipeline to augment detection of cardiac amyloidosis, which should serve as a generalizable strategy for other rare and intermediate frequency cardiac diseases with established or emerging therapies.","",""
9,"R. Haneef, M. Delnord, M. Vernay, E. Bauchet, R. Gaidelytė, H. Van Oyen, Z. Or, B. Pérez-Gómez, L. Palmieri, P. Achterberg, M. Tijhuis, M. Zaletel, S. Mathis-Edenhofer, O. Májek, H. Haaheim, H. Tolonen, A. Gallay","Innovative use of data sources: a cross-sectional study of data linkage and artificial intelligence practices across European countries",2020,"","","","",199,"2022-07-13 09:21:26","","10.1186/s13690-020-00436-9","","",,,,,9,4.50,1,17,2,"","",""
9,"K. Goodman, Diana Zandi, A. Reis, E. Vayena","Balancing risks and benefits of artificial intelligence in the health sector",2020,"","","","",200,"2022-07-13 09:21:26","","10.2471/blt.20.253823","","",,,,,9,4.50,2,4,2,"230 During the last decade, enhanced computing power and the availability of large amounts of data have prompted the practical use of artificial intelligence in health care. Health and medical journals now commonly include reports on machine learning and big data, and descriptions of the risks posed by, and the governance required to manage, this technology. Machine learning algorithms are used to make diagnoses, identify treatments and analyse public health threats, and these systems can learn and improve continuously in response to new data. The tension between risks and concerns on one hand versus potential and opportunity on the other has shaped this issue of the Bulletin of the World Health Organization on the new ethical challenges of artificial intelligence in public health. Data-driven discovery and analysis in health care can increase knowledge and efficiency as well as challenge social values related to privacy, data control and the monetization of personal information. In India, for example, the adoption of a system for assigning all citizens a unique identification number, linking it to individual health records and several health-related schemes, raises ethical, legal and social issues, and the need for an appropriate ethical framework and data governance.1 These issues might be particularly challenging in lowand middle-income countries. Trust is perhaps the overarching theme of the contributions to this issue, and it is indeed one of the central values in digital health. One article explores opportunities for a human-centric ethical and regulatory environment to support the evolution of trust-based artificial intelligence with special regard to health insurance.2 Likewise, trust plays a role along with empathy and compassion in the humane side of care, the importance of which must be preserved in exploring the kind of health care society ought to promote.3 Similarly, European Union guidance might be too context-specific and as such leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally.4 In the context of population health research, researchers propose a post-research review model for ethics governance of research using artificial intelligence.5 For mobile health research in behavioural science, machine learning tools pose novel challenges for transparency, privacy, consent and the management of adverse events, all of which point to the need for consensusbased guidelines.6 As use of artificial intelligence systems expands, accountability for harm to patients and responsibility for their safety entail the need for human control and understanding of these systems.7 Other safeguards will require deliberate investments in data quality, access to care and processes to minimize bias, all in the service of trustworthiness.8 Success in integrating artificial intelligence into everyday patient care, as for instance in the United Kingdom of Great Britain and Northern Ireland’s National Health Service, is dependent on transparency, accountability and trust.9 In addition to trust, the values of fairness, justice and equity are seen as posing challenges even if other ethical duties are met. If artificial intelligence systems can explicitly improve equity, it is also a requirement that they do not worsen inequity.10 Thus, the case of neglected tropical diseases in low-resource settings illustrates opportunities for improved public health, as well as new challenges.11 Globally, the potential to help address some shortages and unmet needs in public health and care services might be realized by artificial intelligence-controlled conversational agents or chatbots that give health advice. However, realizing this potential will require the collaborative establishment of best practices and international ethics guidelines for technologies that replace humans.12 The field of bioethics emerged and grew in response to the development of new technologies and, sometimes, related wrongdoing. Ensuring adequate education, governance and ongoing ethical scrutiny will be essential if we are to realize the benefits and minimize the risks of this new technology. Questions of artificial intelligence accountability, equity and inclusiveness remain. The field is quickly evolving, and more artificial intelligence-based applications and services are becoming available in high-income countries. Identifying better tools for benefit-sharing and, simultaneously, evidence-based safeguards and criteria for appropriate uses and users to benefit everyone, including those in middleand lowincome countries, is essential. The World Health Organization (WHO) has made a commitment to addressing ethics, governance and regulation of artificial intelligence for health. In late 2019, WHO established an expert group to help develop a global framework for ethics and governance in artificial intelligence. The goal of this initiative is to ensure that these technologies are aligned with the overarching aims of promoting fair and equitable global health, meeting human rights standards and supporting Member States’ commitments to achieve universal health coverage. ■ Balancing risks and benefits of artificial intelligence in the health sector Kenneth Goodman, Diana Zandi, Andreas Reis & Effy Vayena","",""
