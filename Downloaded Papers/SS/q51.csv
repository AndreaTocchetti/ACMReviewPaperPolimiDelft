Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
4,"Ninghao Liu, Mengnan Du, Xia Hu","Adversarial Machine Learning: An Interpretation Perspective",2020,"","","","",1,"2022-07-13 09:25:44","","","","",,,,,4,2.00,1,3,2,"Recent years have witnessed the significant advances of machine learning in a wide spectrum of applications. However, machine learning models, especially deep neural networks, have been recently found to be vulnerable to carefully-crafted input called adversarial samples. The difference between normal and adversarial samples is almost imperceptible to human. Many work have been proposed to study adversarial attack and defense in different scenarios. An intriguing and crucial aspect among those work is to understand the essential cause of model vulnerability, which requires in-depth exploration of another concept in machine learning models, i.e., interpretability. Interpretable machine learning tries to extract human-understandable terms for the working mechanism of models, which also receives a lot of attention from both academia and industry. Recently, an increasing number of work start to incorporate interpretation into the exploration of adversarial robustness. Furthermore, we observe that many previous work of adversarial attacking, although did not mention it explicitly, can be regarded as natural extension of interpretation. In this paper, we review recent work on adversarial attack and defense, particularly, from the perspective of machine learning interpretation. We categorize interpretation into two types, according to whether it focuses on raw features or model components. For each type of interpretation, we elaborate on how it could be used in attacks, or defense against adversaries. After that, we briefly illustrate other possible correlations between the two domains. Finally, we discuss the challenges and future directions along tackling adversary issues with interpretation.","",""
13,"Xinlei Mi, Baiming Zou, F. Zou, J. Hu","Permutation-based identification of important biomarkers for complex diseases via machine learning models",2021,"","","","",2,"2022-07-13 09:25:44","","10.1038/s41467-021-22756-2","","",,,,,13,13.00,3,4,1,"","",""
0,"Jianbo Chen","Towards Interpretability and Robustness of Machine Learning Models",2019,"","","","",3,"2022-07-13 09:25:44","","","","",,,,,0,0.00,0,1,3,"Author(s): Chen, Jianbo | Advisor(s): Jordan, Michael I; Wainwright, Martin J | Abstract: Modern machine learning models can be difficult to probe and understand after they have been trained. This is a major problem for the field, with consequences for trustworthiness, diagnostics, debugging, robustness, and a range of other engineering and human interaction issues surrounding the deployment of a model. Another problem of modern machine learning models is their vulnerability to small adversarial perturbations to the input, which incurs a security risk when they are applied to critical areas.In this thesis, we develop systematic and efficient tools for interpreting machine learning models and evaluating their adversarial robustness. Part I focuses on model interpretation. We derive an efficient feature scoring method by exploiting the graph structure in data. We also develop a learning-based method under an information-based framework. As an attempt to leverage prior knowledge about what constitutes a satisfying interpretation in a given domain, we propose a systematic approach to exploiting syntactic constituency structure by leveraging a parse tree for interpretation of models in the setting of linguistic data. Part II focuses on the evaluation of adversarial robustness. We first propose a probabilistic framework for generating adversarial examples on discrete data, and develop two algorithms to implement it. We also introduce a novel attack method in the setting where the attacker has access to model decisions alone. We investigate the robustness of various machine learning models and existing defense mechanisms under the proposed attack method. In Part III, we build a connection between the two fields by developing a method for detecting adversarial examples via tools in model interpretation.","",""
3,"Linhai Ma, Liang Liang","Enhance CNN Robustness Against Noises for Classification of 12-Lead ECG with Variable Length",2020,"","","","",4,"2022-07-13 09:25:44","","10.1109/ICMLA51294.2020.00137","","",,,,,3,1.50,2,2,2,"Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor the condition of the cardiovascular system. Deep neural networks (DNNs), have been developed in many research labs for automatic interpretation of ECG signals to identify potential abnormalities in patient hearts. Studies have shown that given a sufficiently large amount of data, the classification accuracy of DNNs could reach human-expert cardiologist level. However, despite of the excellent performance in classification accuracy, it has been shown that DNNs are highly vulnerable to adversarial noises which are subtle changes in input of a DNN and lead to a wrong class-label prediction with a high confidence. Thus, it is challenging and essential to improve robustness of DNNs against adversarial noises for ECG signal classification -a life-critical application. In this work, we designed a CNN for classification of 12-lead ECG signals with variable length, and we applied three defense methods to improve robustness of this CNN for this classification task. The ECG data in this study is very challenging because the sample size is limited, and the length of each ECG recording varies in a large range. The evaluation results show that our customized CNN reached satisfying F1 score and average accuracy, comparable to the top-6 entries in the CPSC2018 ECG classification challenge, and the defense methods enhanced robustness of our CNN against adversarial noises and white noises, with a minimal reduction in accuracy on clean data.","",""
3,"Hengtong Zhang, Jing Gao, Lu Su","Data Poisoning Attacks Against Outcome Interpretations of Predictive Models",2021,"","","","",5,"2022-07-13 09:25:44","","10.1145/3447548.3467405","","",,,,,3,3.00,1,3,1,"The past decades have witnessed significant progress towards improving the accuracy of predictions powered by complex machine learning models. Despite much success, the lack of model interpretability prevents the usage of these techniques in life-critical systems such as medical diagnosis and self-driving systems. Recently, the interpretability issue has received much attention, and one critical task is to explain why a predictive model makes a specific decision. We refer to this task as outcome interpretation. Many outcome interpretation methods have been developed to produce human-understandable interpretations by utilizing intermediate results of the machine learning models, such as gradients and model parameters. Although the effectiveness of outcome interpretation approaches has been shown in a benign environment, their robustness against data poisoning attacks (i.e., attacks at the training phase) has not been studied. As the first work towards this direction, we aim to answer an important question: Can training-phase adversarial samples manipulate the outcome interpretation of target samples? To answer this question, we propose a data poisoning attack framework named IMF (Interpretation Manipulation Framework), which can manipulate the interpretations of target samples produced by representative outcome interpretation methods. Extensive evaluations verify the effectiveness and efficiency of the proposed attack strategies on two real-world datasets.","",""
0,"Mutao Huang, Jinmeng Wang, Xiaojuan Li","Land Use Change Moritoring in Nature Reserves Base on GF-1/GF-2",2021,"","","","",6,"2022-07-13 09:25:44","","10.1109/ICPECA51329.2021.9362542","","",,,,,0,0.00,0,3,1,"Relying on the remote sensing image of GF-1,GF-2, DEM datas, GIS datas and other datas resources of nature reserve, this paper develops a dynamic monitoring system for nature reserves of B/S version, based on Web RS, Web GIS, machine learning, statistical analysis and big datas technology organically integrated. After a series of preprocessing and interpretation of multi-temporal remote sensing image datas of nature reserve, the system can show changes of land use, vegetation cover and human activity monitoring elements in nature reserve. It is concluded that the accuracy, reliability and robustness of remote sensing image classification are improved by making full use of different disciplines theories and technologies, so that the land classification information of nature reserves can be identified and extracted more quickly and accurately, which can be used for land use planning, land use structure adjustment and government decision-making of nature reserves, and provides a forward method for effectively solving the main scientific problems and key technical problems of land use management in nature reserves under changing environment.","",""
1,"Samir Rachid Zaim, C. Kenost, J. Berghout, Wesley Chiu, Liam Wilson, H. Zhang, Y. Lussier","binomialRF: interpretable combinatoric efficiency of random forests to identify biomarker interactions",2020,"","","","",7,"2022-07-13 09:25:44","","10.1186/s12859-020-03718-9","","",,,,,1,0.50,0,7,2,"","",""
0,"Xinlei Mi, Baiming Zou, F. Zou, J. Hu","Permutation-based Identification of Important Biomarkers for Complex Diseases via Black-box Models",2020,"","","","",8,"2022-07-13 09:25:44","","10.1101/2020.04.27.064170","","",,,,,0,0.00,0,4,2,"Study of human disease remains challenging due to convoluted disease etiologies and complex molecular mechanisms at genetic, genomic, and proteomic levels. Many machine learning-based methods, including deep learning and random forest, have been developed and widely used to alleviate some analytic challenges in complex human disease studies. While enjoying the modeling flexibility and robustness, these model frameworks suffer from non-transparency and difficulty in interpreting the role of each individual feature due to their intrinsic black-box natures. However, identifying important biomarkers associated with complex human diseases is a critical pursuit towards assisting researchers to establish novel hypotheses regarding prevention, diagnosis and treatment of complex human diseases. Herein, we propose a Permutation-based Feature Importance Test (PermFIT) for estimating and testing the feature importance, and for assisting interpretation of individual feature in various black-box frameworks, including deep neural networks, random forests, and support vector machines. PermFIT (available at https://github.com/SkadiEye/deepTL) is implemented in a computationally efficient manner, without model refitting for each permuted data. We conduct extensive numerical studies under various scenarios, and show that PermFIT not only yields valid statistical inference, but also helps to improve the prediction accuracy of black-box models with top selected features. With the application to the Cancer Genome Atlas (TCGA) kidney tumor data and the HITChip atlas BMI data, PermFIT clearly demonstrates its practical usage in identifying important biomarkers and boosting performance of black-box predictive models.","",""
2,"Samir Rachid Zaim, C. Kenost, J. Berghout, Wesley Chiu, Liam Wilson, H. Zhang, Y. Lussier","binomialRF: interpretable combinatoric efficiency of random forests to identify biomarker interactions",2019,"","","","",9,"2022-07-13 09:25:44","","10.1186/s12859-020-03718-9","","",,,,,2,0.67,0,7,3,"","",""
15,"C. Goldman, M. Allen, S. Zilberstein","Decentralized language learning through acting",2004,"","","","",10,"2022-07-13 09:25:44","","10.1109/AAMAS.2004.99","","",,,,,15,0.83,5,3,18,"This paper presents an algorithm for learning the meaning of messages communicated between agents that interact while acting optimally towards a cooperative goal. Our reinforcement-learning method is based on Bayesian filtering and has been adapted for a decentralized control process. Empirical results shed light on the complexity of the learning problem, and on factors affecting the speed of convergence. Designing intelligent agents able to adapt their mutual interpretation of messages exchanged, in order to improve overall task-oriented performance, introduces an essential cognitive capability that can upgrade the current state of the art in multi-agent and human-machine systems to the next level. Learning to communicate while acting will add to the robustness and flexibility of these systems and hence to a more efficient and productive performance.","",""
179,"S. Michie, James Thomas, M. Johnston, Pol Mac Aonghusa, J. Shawe-Taylor, M. Kelly, L. Deleris, Ailbhe N. Finnerty, M. Marques, E. Norris, A. O'Mara-Eves, R. West","The Human Behaviour-Change Project: harnessing the power of artificial intelligence and machine learning for evidence synthesis and interpretation",2017,"","","","",11,"2022-07-13 09:25:44","","10.1186/s13012-017-0641-5","","",,,,,179,35.80,18,12,5,"","",""
15,"Vivek Kumar, D. Recupero, Daniele Riboni, Rim Helaoui","Ensembling Classical Machine Learning and Deep Learning Approaches for Morbidity Identification From Clinical Notes",2021,"","","","",12,"2022-07-13 09:25:44","","10.1109/ACCESS.2020.3043221","","",,,,,15,15.00,4,4,1,"The past decade has seen an explosion of the amount of digital information generated within the healthcare domain. Digital data exist in the form of images, video, speech, transcripts, electronic health records, clinical records, and free-text. Analysis and interpretation of healthcare data is a daunting task, and it demands a great deal of time, resources, and human effort. In this paper, we focus on the problem of co-morbidity recognition from patient’s clinical records. To this aim, we employ both classical machine learning and deep learning approaches. We use word embeddings and bag-of-words representations, coupled with feature selection techniques. The goal of our work is to develop a classification system to identify whether a certain health condition occurs for a patient by studying his/her past clinical records. In more detail, we have used pre-trained word2vec, domain-trained, GloVe, fastText, and universal sentence encoder embeddings to tackle the classification of sixteen morbidity conditions within clinical records. We have compared the outcomes of classical machine learning and deep learning approaches with the employed feature representation methods and feature selection methods. We present a comprehensive discussion of the performances and behaviour of the employed classical machine learning and deep learning approaches. Finally, we have also used ensemble learning techniques over a large number of combinations of classifiers to improve the single model performance. For our experiments, we used the n2c2 natural language processing research dataset, released by Harvard Medical School. The dataset is in the form of clinical notes that contain patient discharge summaries. Given the unbalancedness of the data and their small size, the experimental results indicate the advantage of the ensemble learning technique with respect to single classifier models. In particular, the ensemble learning technique has slightly improved the performances of single classification models but has greatly reduced the variance of predictions stabilizing the accuracies (i.e., the lower standard deviation in comparison with single classifiers). In real-life scenarios, our work can be employed to identify with high accuracy morbidity conditions of patients by feeding our tool with their current clinical notes. Moreover, other domains where classification is a common problem might benefit from our approach as well.","",""
24,"V. Croce, G. Caroti, L. D. Luca, K. Jacquot, A. Piemonte, P. Véron","From the Semantic Point Cloud to Heritage-Building Information Modeling: A Semiautomatic Approach Exploiting Machine Learning",2021,"","","","",13,"2022-07-13 09:25:44","","10.3390/rs13030461","","",,,,,24,24.00,4,6,1,"This work presents a semi-automatic approach to the 3D reconstruction of HeritageBuilding Information Models from point clouds based on machine learning techniques. The use of digital information systems leveraging on three-dimensional (3D) representations in architectural heritage documentation and analysis is ever increasing. For the creation of such repositories, realitybased surveying techniques, such as photogrammetry and laser scanning, allow the fast collection of reliable digital replicas of the study objects in the form of point clouds. Besides, their output is raw and unstructured, and the transition to intelligible and semantic 3D representations is still a scarcely automated and time-consuming process requiring considerable human intervention. More refined methods for 3D data interpretation of heritage point clouds are therefore sought after. In tackling these issues, the proposed approach relies on (i) the application of machine learning techniques to semantically label 3D heritage data by identification of relevant geometric, radiometric and intensity features, and (ii) the use of the annotated data to streamline the construction of Heritage-Building Information Modeling (H-BIM) systems, where purely geometric information derived from surveying is associated with semantic descriptors on heritage documentation and management. The “GrandDucal Cloister” dataset, related to the emblematic case study of the Pisa Charterhouse, is discussed.","",""
13,"Tharindu Kaluarachchi, Andrew Reis, Suranga Nanayakkara","A Review of Recent Deep Learning Approaches in Human-Centered Machine Learning",2021,"","","","",14,"2022-07-13 09:25:44","","10.3390/s21072514","","",,,,,13,13.00,4,3,1,"After Deep Learning (DL) regained popularity recently, the Artificial Intelligence (AI) or Machine Learning (ML) field is undergoing rapid growth concerning research and real-world application development. Deep Learning has generated complexities in algorithms, and researchers and users have raised concerns regarding the usability and adoptability of Deep Learning systems. These concerns, coupled with the increasing human-AI interactions, have created the emerging field that is Human-Centered Machine Learning (HCML). We present this review paper as an overview and analysis of existing work in HCML related to DL. Firstly, we collaborated with field domain experts to develop a working definition for HCML. Secondly, through a systematic literature review, we analyze and classify 162 publications that fall within HCML. Our classification is based on aspects including contribution type, application area, and focused human categories. Finally, we analyze the topology of the HCML landscape by identifying research gaps, highlighting conflicting interpretations, addressing current challenges, and presenting future HCML research opportunities.","",""
27,"Dezhen Xiong, Daohui Zhang, Xingang Zhao, Yiwen Zhao","Deep Learning for EMG-based Human-Machine Interaction: A Review",2021,"","","","",15,"2022-07-13 09:25:44","","10.1109/JAS.2021.1003865","","",,,,,27,27.00,7,4,1,"Electromyography (EMG) has already been broadly used in human-machine interaction (HMI) applications. Determining how to decode the information inside EMG signals robustly and accurately is a key problem for which we urgently need a solution. Recently, many EMG pattern recognition tasks have been addressed using deep learning methods. In this paper, we analyze recent papers and present a literature review describing the role that deep learning plays in EMG-based HMI. An overview of typical network structures and processing schemes will be provided. Recent progress in typical tasks such as movement classification, joint angle prediction, and force/torque estimation will be introduced. New issues, including multimodal sensing, inter-subject/inter-session, and robustness toward disturbances will be discussed. We attempt to provide a comprehensive analysis of current research by discussing the advantages, challenges, and opportunities brought by deep learning. We hope that deep learning can aid in eliminating factors that hinder the development of EMG-based HMI systems. Furthermore, possible future directions will be presented to pave the way for future research.","",""
16,"Md. Mokhlesur Rahman, K. Paul, Md. Amjad Hossain, G. Ali, Md. Shahinoor Rahman, J. Thill","Machine Learning on the COVID-19 Pandemic, Human Mobility and Air Quality: A Review",2021,"","","","",16,"2022-07-13 09:25:44","","10.1109/ACCESS.2021.3079121","","",,,,,16,16.00,3,6,1,"The ongoing COVID-19 global pandemic is touching every facet of human lives (e.g., public health, education, economy, transportation, and the environment). This novel pandemic and non-pharmaceutical interventions of lockdown and confinement implemented citywide, regionally or nationally are affecting virus transmission, people’s travel patterns, and air quality. Many studies have been conducted to predict the diffusion of the COVID-19 disease, assess the impacts of the pandemic on human mobility and on air quality, and assess the impacts of lockdown measures on viral spread with a range of Machine Learning (ML) techniques. This literature review aims to analyze the results from past research to understand the interactions among the COVID-19 pandemic, lockdown measures, human mobility, and air quality. The critical review of prior studies indicates that urban form, people’s socioeconomic and physical conditions, social cohesion, and social distancing measures significantly affect human mobility and COVID-19 viral transmission. During the COVID-19 pandemic, many people are inclined to use private transportation for necessary travel to mitigate coronavirus-related health problems. This review study also noticed that COVID-19 related lockdown measures significantly improve air quality by reducing the concentration of air pollutants, which in turn improves the COVID-19 situation by reducing respiratory-related sickness and deaths. It is argued that ML is a powerful, effective, and robust analytic paradigm to handle complex and wicked problems such as a global pandemic. This study also explores the spatio-temporal aspects of lockdown and confinement measures on coronavirus diffusion, human mobility, and air quality. Additionally, we discuss policy implications, which will be helpful for policy makers to take prompt actions to moderate the severity of the pandemic and improve urban environments by adopting data-driven analytic methods.","",""
3,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantitative comparison of Drosophila behavior annotations by human observers and a machine learning algorithm",2020,"","","","",17,"2022-07-13 09:25:44","","10.1101/2020.06.16.153130","","",,,,,3,1.50,1,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications. Significance Statement Accurate quantification of animal behaviors is fundamental to neuroscience. Here, we quantitatively assess how human choices influence the performance of automated classifiers trained by a machine-learning algorithm. We found that human decisions about the computational tracking method, the training images, and the images used for performance evaluation impact both the classifier outputs and how human observers interpret the results. These factors are sometimes overlooked but are critical, especially because animal behavior is itself inherently variable. Automated quantification of animal behavior is becoming increasingly prevalent: our results provide a model for bridging the gap between traditional human annotations and computer-based annotations. Systematic assessment of human choices is important for developing behavior classifiers that perform robustly in a variety of experimental conditions.","",""
2,"Xubo Leng, Margot Wohl, Kenichi Ishii, Pavan Nayak, Kenta Asahina","Quantifying influence of human choice on the automated detection of Drosophila behavior by a supervised machine learning algorithm",2020,"","","","",18,"2022-07-13 09:25:44","","10.1371/journal.pone.0241696","","",,,,,2,1.00,0,5,2,"Automated quantification of behavior is increasingly prevalent in neuroscience research. Human judgments can influence machine-learning-based behavior classification at multiple steps in the process, for both supervised and unsupervised approaches. Such steps include the design of the algorithm for machine learning, the methods used for animal tracking, the choice of training images, and the benchmarking of classification outcomes. However, how these design choices contribute to the interpretation of automated behavioral classifications has not been extensively characterized. Here, we quantify the effects of experimenter choices on the outputs of automated classifiers of Drosophila social behaviors. Drosophila behaviors contain a considerable degree of variability, which was reflected in the confidence levels associated with both human and computer classifications. We found that a diversity of sex combinations and tracking features was important for robust performance of the automated classifiers. In particular, features concerning the relative position of flies contained useful information for training a machine-learning algorithm. These observations shed light on the importance of human influence on tracking algorithms, the selection of training images, and the quality of annotated sample images used to benchmark the performance of a classifier (the ‘ground truth’). Evaluation of these factors is necessary for researchers to accurately interpret behavioral data quantified by a machine-learning algorithm and to further improve automated classifications.","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",19,"2022-07-13 09:25:44","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
13,"M. Grassia, M. Domenico, G. Mangioni","Machine learning dismantling and early-warning signals of disintegration in complex systems",2021,"","","","",20,"2022-07-13 09:25:44","","10.1038/s41467-021-25485-8","","",,,,,13,13.00,4,3,1,"","",""
13,"Nareen O. M. Salim, A. Abdulazeez","Human Diseases Detection Based On Machine Learning Algorithms: A Review",2021,"","","","",21,"2022-07-13 09:25:44","","10.5281/ZENODO.4467510","","",,,,,13,13.00,7,2,1,"One of the most significant subjects of society is human healthcare. It is looking for the best one and robust disease diagnosis to get the care they need as soon as possible. Other fields, such as statistics and computer science, are needed for the health aspect of searching since this recognition is often complicated. The task of following new approaches is challenging these disciplines, moving beyond the conventional ones. The actual number of new techniques makes it possible to provide a broad overview that avoids particular aspects. To this end, we suggest a systematic analysis of human diseases related to machine learning. This research concentrates on existing techniques related to machine learning growth applied to the diagnosis of human illnesses in the medical field to discover exciting trends, make unimportant predictions, and help decision-making. This paper analyzes unique machine learning algorithms used for healthcare applications to create adequate decision support. This paper intends to reduce the research gap in creating a realistic decision support system for medical applications.","",""
48,"Clemens Stachl, F. Pargent, S. Hilbert, Gabriella M. Harari, Ramona Schoedel, Sumer S. Vaid, S. Gosling, M. Bühner","Personality Research and Assessment in the Era of Machine Learning",2019,"","","","",22,"2022-07-13 09:25:44","","10.1002/per.2257","","",,,,,48,16.00,6,8,3,"The increasing availability of high–dimensional, fine–grained data about human behaviour, gathered from mobile sensing studies and in the form of digital footprints, is poised to drastically alter the way personality psychologists perform research and undertake personality assessment. These new kinds and quantities of data raise important questions about how to analyse the data and interpret the results appropriately. Machine learning models are well suited to these kinds of data, allowing researchers to model highly complex relationships and to evaluate the generalizability and robustness of their results using resampling methods. The correct usage of machine learning models requires specialized methodological training that considers issues specific to this type of modelling. Here, we first provide a brief overview of past studies using machine learning in personality psychology. Second, we illustrate the main challenges that researchers face when building, interpreting, and validating machine learning models. Third, we discuss the evaluation of personality scales, derived using machine learning methods. Fourth, we highlight some key issues that arise from the use of latent variables in the modelling process. We conclude with an outlook on the future role of machine learning models in personality research and assessment.","",""
9,"J. Harrison, J. Gilbertson, M. Hanna, N. Olson, J. Seheult, James M. Sorace, M. Stram","Introduction to Artificial Intelligence and Machine Learning for Pathology.",2021,"","","","",23,"2022-07-13 09:25:44","","10.5858/arpa.2020-0541-CP","","",,,,,9,9.00,1,7,1,"CONTEXT.— Recent developments in machine learning have stimulated intense interest in software that may augment or replace human experts. Machine learning may impact pathology practice by offering new capabilities in analysis, interpretation, and outcomes prediction using images and other data. The principles of operation and management of machine learning systems are unfamiliar to pathologists, who anticipate a need for additional education to be effective as expert users and managers of the new tools.   OBJECTIVE.— To provide a background on machine learning for practicing pathologists, including an overview of algorithms, model development, and performance evaluation; to examine the current status of machine learning in pathology and consider possible roles and requirements for pathologists in local deployment and management of machine learning systems; and to highlight existing challenges and gaps in deployment methodology and regulation.   DATA SOURCES.— Sources include the biomedical and engineering literature, white papers from professional organizations, government reports, electronic resources, and authors' experience in machine learning. References were chosen when possible for accessibility to practicing pathologists without specialized training in mathematics, statistics, or software development.   CONCLUSIONS.— Machine learning offers an array of techniques that in recent published results show substantial promise. Data suggest that human experts working with machine learning tools outperform humans or machines separately, but the optimal form for this combination in pathology has not been established. Significant questions related to the generalizability of machine learning systems, local site verification, and performance monitoring remain to be resolved before a consensus on best practices and a regulatory environment can be established.","",""
9,"Kamalaker Dadi, G. Varoquaux, J. Houenou, D. Bzdok, B. Thirion, D. Engemann","Population modeling with machine learning can enhance measures of mental health",2021,"","","","",24,"2022-07-13 09:25:44","","10.1101/2020.08.25.266536","","",,,,,9,9.00,2,6,1,"Background Biological aging is revealed by physical measures, e.g., DNA probes or brain scans. Instead, individual differences in mental function are explained by psychological constructs, e.g., intelligence or neuroticism. These constructs are typically assessed by tailored neuropsychological tests that build on expert judgement and require careful interpretation. Could machine learning on large samples from the general population be used to build proxy measures of these constructs that do not require human intervention? Results Here, we built proxy measures by applying machine learning on multimodal MR images and rich sociodemographic information from the largest biomedical cohort to date: the UK Biobank. Objective model comparisons revealed that all proxies captured the target constructs and were as useful, and sometimes more useful than the original measures for characterizing real-world health behavior (sleep, exercise, tobacco, alcohol consumption). We observed this complementarity of proxy measures and original measures when modeling from brain signals or sociodemographic data, capturing multiple health-related constructs. Conclusions Population modeling with machine learning can derive measures of mental health from brain signals and questionnaire data, which may complement or even substitute for psychometric assessments in clinical populations. Key Points We applied machine learning on more than 10.000 individuals from the general population to define empirical approximations of health-related psychological measures that do not require human judgment. We found that machine-learning enriched the given psychological measures via approximation from brain and sociodemographic data: Resulting proxy measures related as well or better to real-world health behavior than the original measures. Model comparisons showed that sociodemographic information contributed most to characterizing psychological traits beyond aging.","",""
161,"A. Bhagoji, Daniel Cullina, Chawin Sitawarin, Prateek Mittal","Enhancing robustness of machine learning systems via data transformations",2017,"","","","",25,"2022-07-13 09:25:44","","10.1109/CISS.2018.8362326","","",,,,,161,32.20,40,4,5,"We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification.","",""
39,"Yiyue Luo, Yunzhu Li, Pratyusha Sharma, Wan Shou, Kui Wu, Michael Foshey, Beichen Li, Tomás Palacios, A. Torralba, W. Matusik","Learning human–environment interactions using conformal tactile textiles",2021,"","","","",26,"2022-07-13 09:25:44","","10.1038/S41928-021-00558-0","","",,,,,39,39.00,4,10,1,"","",""
9,"T. Botari, Rafael Izbicki, A. Carvalho","Local Interpretation Methods to Machine Learning Using the Domain of the Feature Space",2019,"","","","",27,"2022-07-13 09:25:44","","10.1007/978-3-030-43823-4_21","","",,,,,9,3.00,3,3,3,"","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",28,"2022-07-13 09:25:44","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
87,"Kate Crawford, T. Paglen","Excavating AI: the politics of images in machine learning training sets",2021,"","","","",29,"2022-07-13 09:25:44","","10.1007/S00146-021-01162-8","","",,,,,87,87.00,44,2,1,"","",""
3,"H. Castañé, G. Baiges-Gaya, A. Hernández-Aguilera, E. Rodríguez-Tomàs, S. Fernández-Arroyo, P. Herrero, A. Delpino-Rius, N. Canela, J. Menéndez, J. Camps, J. Joven","Coupling Machine Learning and Lipidomics as a Tool to Investigate Metabolic Dysfunction-Associated Fatty Liver Disease. A General Overview",2021,"","","","",30,"2022-07-13 09:25:44","","10.3390/biom11030473","","",,,,,3,3.00,0,11,1,"Hepatic biopsy is the gold standard for staging nonalcoholic fatty liver disease (NAFLD). Unfortunately, accessing the liver is invasive, requires a multidisciplinary team and is too expensive to be conducted on large segments of the population. NAFLD starts quietly and can progress until liver damage is irreversible. Given this complex situation, the search for noninvasive alternatives is clinically important. A hallmark of NAFLD progression is the dysregulation in lipid metabolism. In this context, recent advances in the area of machine learning have increased the interest in evaluating whether multi-omics data analysis performed on peripheral blood can enhance human interpretation. In the present review, we show how the use of machine learning can identify sets of lipids as predictive biomarkers of NAFLD progression. This approach could potentially help clinicians to improve the diagnosis accuracy and predict the future risk of the disease. While NAFLD has no effective treatment yet, the key to slowing the progression of the disease may lie in predictive robust biomarkers. Hence, to detect this disease as soon as possible, the use of computational science can help us to make a more accurate and reliable diagnosis. We aimed to provide a general overview for all readers interested in implementing these methods.","",""
4,"S. Nomm, Alejandro Guerra-Manzanares, Hayretdin Bahsi","Towards the Integration of a Post-Hoc Interpretation Step into the Machine Learning Workflow for IoT Botnet Detection",2019,"","","","",31,"2022-07-13 09:25:44","","10.1109/ICMLA.2019.00193","","",,,,,4,1.33,1,3,3,"The analysis of the interplay between the feature selection and the post-hoc local interpretation steps in a machine learning workflow followed for IoT botnet detection constitutes the research scope of the present paper. While the application of machine learning-based techniques has become a trend in cyber security, the main focus has been almost on detection accuracy. However, providing the relevant explanation for a detection decision is a vital requirement in a tiered incident handling processes of the contemporary security operations centers. Moreover, the design of intrusion detection systems in IoT networks has to take the limitations of the computational resources into consideration. Therefore, resource limitations in addition to human element of incident handling necessitate considering feature selection and interpretability at the same time in machine learning workflows. In this paper, first, we analyzed the selection of features and its implication on the data accuracy. Second, we investigated the impact of feature selection on the explanations generated at the post-hoc interpretation phase. We utilized a filter method, Fisher's Score and Local Interpretable Model-Agnostic Explanation (LIME) at feature selection and post-hoc interpretation phases, respectively. To evaluate the quality of explanations, we proposed a metric that reflects the need of the security analysts. It is demonstrated that the application of both steps for the particular case of IoT botnet detection may result in highly accurate and interpretable learning models induced by fewer features. Our metric enables us to evaluate the detection accuracy and interpretability in an integrated way.","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",32,"2022-07-13 09:25:44","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
24,"Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Tizian Thieringer, M. Bethge, F. Wichmann, Wieland Brendel","Partial success in closing the gap between human and machine vision",2021,"","","","",33,"2022-07-13 09:25:44","","","","",,,,,24,24.00,3,7,1,"A few years ago, the first CNN surpassed human performance on ImageNet. However, it soon became clear that machines lack robustness on more challenging test cases, a major obstacle towards deploying machines “in the wild” and towards obtaining better computational models of human visual perception. Here we ask: Are we making progress in closing the gap between human and machine vision? To answer this question, we tested human observers on a broad range of out-ofdistribution (OOD) datasets, recording 85,120 psychophysical trials across 90 participants. We then investigated a range of promising machine learning developments that crucially deviate from standard supervised CNNs along three axes: objective function (self-supervised, adversarially trained, CLIP language-image training), architecture (e.g. vision transformers), and dataset size (ranging from 1M to 1B). Our findings are threefold. (1.) The longstanding distortion robustness gap between humans and CNNs is closing, with the best models now exceeding human feedforward performance on most of the investigated OOD datasets. (2.) There is still a substantial image-level consistency gap, meaning that humans make different errors than models. In contrast, most models systematically agree in their categorisation errors, even substantially different ones like contrastive self-supervised vs. standard supervised models. (3.) In many cases, human-to-model consistency improves when training dataset size is increased by one to three orders of magnitude. Our results give reason for cautious optimism: While there is still much room for improvement, the behavioural difference between human and machine vision is narrowing. In order to measure future progress, 17 OOD datasets with image-level human behavioural data and evaluation code are provided as a toolbox and benchmark at https://github.com/bethgelab/model-vs-human/.","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",34,"2022-07-13 09:25:44","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
1,"J. Ani, Mirajul Islam, Nushrat Jahan Ria, Sharmin Akter, Abu Kaisar Mohammad Masum","Estimating Gender Based On Bengali Conventional Full Name With Various Machine Learning Techniques",2021,"","","","",35,"2022-07-13 09:25:44","","10.1109/ICCCNT51525.2021.9579927","","",,,,,1,1.00,0,5,1,"For finding patterns in data, machine learning models are being trained. Gender relations psychology looks for social norms like inter dimensionality, beliefs, social experience and self-perception, and self-respect. Training on gender based text NLP models unknowingly become acquainted with unusual patterns. In this paper, we represent gender recognition by using Bengali conventional full names. We present a review and interpretation of gender classification based on individual names in this correspondence. These days, NLP has demonstrated excellent execution in identifying human gender. In the field of knowledge, gender classification is a demonstrative binary classification phenomenon. We've used a total of seven algorithms in this research. We were added to the dataset with details regarding which features are currently used for prediction along with that it determines how these features are affected by data preprocessing model initialization and architecture selection. Our research compares those classifiers, examines the impact of pretraining moreover, assesses the robustness of the alignment preprocessing through the confusion matrix.. The proposed Neural Network outperforms most approaches and is much more reliable than other models. This model has the best weighted precision of all the models, with such a 73.04 % accuracy score.","",""
1,"Riqiang Gao, Mirza S. Khan, Yucheng Tang, Kaiwen Xu, S. Deppen, Yuankai Huo, K. Sandler, P. Massion, B. Landman","Technical Report: Quality Assessment Tool for Machine Learning with Clinical CT",2021,"","","","",36,"2022-07-13 09:25:44","","","","",,,,,1,1.00,0,9,1,"Image Quality Assessment (IQA) is important for scientific inquiry, especially in medical imaging and machine learning. Potential data quality issues can be exacerbated when human-based workflows use limited views of the data that may obscure digital artifacts. In practice, multiple factors such as network issues, accelerated acquisitions, motion artifacts, and imaging protocol design can impede the interpretation of image collections. The medical image processing community has developed a wide variety of tools for the inspection and validation of imaging data. Yet, IQA of computed tomography (CT) remains an under-recognized challenge, and no user-friendly tool is commonly available to address these potential issues. Here, we create and illustrate a pipeline specifically designed to identify and resolve issues encountered with large-scale data mining of clinically acquired CT data. Using the widely studied National Lung Screening Trial (NLST), we have identified approximately 4% of image volumes with quality concerns out of 17,392 scans. To assess robustness, we applied the proposed pipeline to our internal datasets where we find our tool is generalizable to clinically acquired medical images. In conclusion, the tool has been useful and time-saving for research study of clinical data, and the code and tutorials are publicly available at https://github.com/MASILab/QA_tool.","",""
0,"Ahmed Reda Ali, M. Jaya, E. A. Jones","Machine Learning Strategies for Accurate Log Prediction in Reservoir Characterization: Self-Calibrating Versus Domain-Knowledge",2021,"","","","",37,"2022-07-13 09:25:44","","10.2118/205602-ms","","",,,,,0,0.00,0,3,1,"  Petrophysical evaluation is a crucial task for reservoir characterization but it is often complicated, time-consuming and associated with uncertainties. Moreover, this job is subjective and ambiguous depending on the petrophysicist's experience. Utilizing the flourishing Artificial Intelligence (AI)/Machine Learning (ML) is a way to build an automating process with minimal human intervention, improving consistency and efficiency of well log prediction and interpretation. Nowadays, the argument is whether AI-ML should base on a statistically self-calibrating or knowledge-based prediction framework! In this study, we develop a petrophysically knowledge-based AI-ML workflow that upscale sparsely-sampled core porosity and permeability into continuous curves along the entire well interval.  AI-ML focuses on making predictions from analyzing data by learning and identifying patterns. The accuracy of the self-calibrating statistical models is heavily dependent on the volume of training data. The proposed AI-ML workflow uses raw well logs (gamma-ray, neutron and density) to predict porosity and permeability over the well interval using sparsely core data. The challenge in building the AI-ML model is the number of data points used for training showed an imbalance in the relative sampling of plugs, i.e. the number of core data (used as target variable) is less than 10%. Ensemble learning and stacking ML approaches are used to obtain maximum predictive performance of self-calibrating learning strategy.  Alternatively, a new petrophysical workflow is established to debrief the domain experience in the feature selection that is used as an important weight in the regression problem. This helps ML model to learn more accurately by discovering hidden relationships between independent and target variables. This workflow is the inference engine of the AI-ML model to extract relevant domain-knowledge within the system that leads to more accurate predictions.  The proposed knowledge-driven ML strategy achieved a prediction accuracy of R2 score = 87% (Correlation Coefficient (CC) of 96%). This is a significant improvement by R2 = 57% (CC = 62%) compared to the best performing self-calibrating ML models. The predicted properties are upscaled automatically to predict uncored intervals, improving data coverage and property population in reservoir models leading to the improvement of the model robustness. The high prediction accuracy demonstrates the potential of knowledge-driven AI-ML strategy in predicting rock properties under data sparsity and limitations and saving significant cost and time.  This paper describes an AI-ML workflow that predicts high-resolution continuous porosity and permeability logs from imbalanced and sparse core plug data. The method successfully incorporates new type petrophysical facies weight as a feature augmentation engine for ML domain-knowledge framework. The workflow consisted of petrophysical treatment of raw data includes log quality control, preconditioning, processing, features augmentation and labelling, followed by feature selection to impersonate domain experience.","",""
5,"S. Satapathy, D. Loganathan","A Study of Human Sleep Stage Classification Based on Dual Channels of EEG Signal Using Machine Learning Techniques",2021,"","","","",38,"2022-07-13 09:25:44","","10.1007/s42979-021-00528-5","","",,,,,5,5.00,3,2,1,"","",""
21,"Shantani Kannan, K. Subbaram, Sheeza Ali, H. Kannan","The Role of Artificial Intelligence and Machine Learning Techniques: Race for COVID-19 Vaccine",2020,"","","","",39,"2022-07-13 09:25:44","","10.5812/archcid.103232","","",,,,,21,10.50,5,4,2,"Context: In the healthcare system, Artificial Intelligence (AI) is emerging as a productive tool. There are instances where AI has done marvels in the diagnosis of various health conditions and the interpretation of complex medical disorders. Although AI is far from human intelligence, it can be used as an effective tool to study the SARS-CoV-2 and its capabilities, virulence, and genome. The progress of the pandemic can be tracked, and the patients can be monitored, thereby speeding up the research for the treatment of COVID-19. In this review article, we highlighted the importance of AI and Machine learning (ML) techniques that can speed up the path to the discovery of a possible cure for COVID-19. We also deal with the interactions between viromics and AI, which can hopefully find a solution to this pandemic. Evidence Acquisition: A review of different articles was conducted using the following databases: MEDLINE/PubMed, SCOPUS, Web of Science, ScienceDirect, and Google Scholar for recent studies regarding the use of AI, seeking the spread of different infectious diseases using relevant MeSH subheadings. Results: After a thorough screening of different articles, 30 articles were considered, and key information was obtained from them. Finally, the scope was broadened to obtain more information. Our findings indicated that AI/ML is a promising approach to drug development. Conclusions: The field of AI has enormous potential to predict the changes that may take place in the environment. If this technology is applied to situations of a pandemic such as COVID-19, breakthroughs could potentially pave the way for new vaccines and antiviral drugs.","",""
0,"S. Chujfi, C. Meinel","Machine Learning and Human Cognition Combined to Enhance Knowledge Discovery Fidelity",2019,"","","","",40,"2022-07-13 09:25:44","","10.1109/CogMI48466.2019.00010","","",,,,,0,0.00,0,2,3,"The objective of this work is knowledge discovery in large-scale audio files by performing a Cognitive Analysis – CA –, where the knowledge is extracted from transcribed customer service conversations taking into consideration individual cognitive styles to mimic the human cognitive process and maximize the correct meaning interpretation information in a given context. We make the following three contributions: (i) integrate a Cyber Cognitive Identity model – CCI – that states the cognitive profile an individual has for interacting in cyberspace, which yields superior fidelity to identify the meaning of spoken sentences following Sternberg's Thinking Style Inventory (TSI). In particular it guides an analysis grounded in peers' cognitive styles to index words by dimension; (ii) a novel method that extends the Latent Dirichlet Allocation (LDA) approach to a multidimensional partially supervised machine learning model with the help of the psychological activation theory Adaptive Control of Thought – ACT; (iii) an improvement of the Exploratory Data Analysis – EDA–suggested by De Mast and Trip, envisioned as an extended approach to obtain high-fidelity data where topics of a three-dimensional corpus are clustered according to cognitive categorizations. Using speech-to-text software, we transcribed and evaluated 27 500 calls from 206 German-speaking teleworkers combining these three complementary methods and achieved significant fidelity to generate a hypothesis based on individuals' cognitive affinities.","",""
18,"S. Moazemi, Z. Khurshid, A. Erle, S. Lütje, M. Essler, T. Schultz, R. Bundschuh","Machine Learning Facilitates Hotspot Classification in PSMA-PET/CT with Nuclear Medicine Specialist Accuracy",2020,"","","","",41,"2022-07-13 09:25:44","","10.3390/diagnostics10090622","","",,,,,18,9.00,3,7,2,"Gallium-68 prostate-specific membrane antigen positron emission tomography (68Ga-PSMA-PET) is a highly sensitive method to detect prostate cancer (PC) metastases. Visual discrimination between malignant and physiologic/unspecific tracer accumulation by a nuclear medicine (NM) specialist is essential for image interpretation. In the future, automated machine learning (ML)-based tools will assist physicians in image analysis. The aim of this work was to develop a tool for analysis of 68Ga-PSMA-PET images and to compare its efficacy to that of human readers. Five different ML methods were compared and tested on multiple positron emission tomography/computed tomography (PET/CT) data-sets. Forty textural features extracted from both PET- and low-dose CT data were analyzed. In total, 2419 hotspots from 72 patients were included. Comparing results from human readers to those of ML-based analyses, up to 98% area under the curve (AUC), 94% sensitivity (SE), and 89% specificity (SP) were achieved. Interestingly, textural features assessed in native low-dose CT increased the accuracy significantly. Thus, ML based on 68Ga-PSMA-PET/CT radiomics features can classify hotspots with high precision, comparable to that of experienced NM physicians. Additionally, the superiority of multimodal ML-based analysis considering all PET and low-dose CT features was shown. Morphological features seemed to be of special additional importance even though they were extracted from native low-dose CTs.","",""
12,"J. Vizcarra, M. Gearing, Michael J. Keiser, J. Glass, B. Dugger, D. Gutman","Validation of machine learning models to detect amyloid pathologies across institutions",2020,"","","","",42,"2022-07-13 09:25:44","","10.1186/s40478-020-00927-4","","",,,,,12,6.00,2,6,2,"","",""
20,"Taylor Faucett, J. Thaler, D. Whiteson","Mapping machine-learned physics into a human-readable space",2020,"","","","",43,"2022-07-13 09:25:44","","10.1103/PHYSREVD.103.036020","","",,,,,20,10.00,7,3,2,"We present a technique for translating a black-box machine-learned classifier operating on a high-dimensional input space into a small set of human-interpretable observables that can be combined to make the same classification decisions. We iteratively select these observables from a large space of high-level discriminants by finding those with the highest decision similarity relative to the black box, quantified via a metric we introduce that evaluates the relative ordering of pairs of inputs. Successive iterations focus only on the subset of input pairs that are misordered by the current set of observables. This method enables simplification of the machine-learning strategy, interpretation of the results in terms of well-understood physical concepts, validation of the physical model, and the potential for new insights into the nature of the problem itself. As a demonstration, we apply our approach to the benchmark task of jet classification in collider physics, where a convolutional neural network acting on calorimeter jet images outperforms a set of six well-known jet substructure observables. Our method maps the convolutional neural network into a set of observables called energy flow polynomials, and it closes the performance gap by identifying a class of observables with an interesting physical interpretation that has been previously overlooked in the jet substructure literature.","",""
19,"Nuria Caballé-Cervigón, J. Castillo-Sequera, J. Gómez-Pulido, J. Gómez-Pulido, M. Polo-Luque","Machine Learning Applied to Diagnosis of Human Diseases: A Systematic Review",2020,"","","","",44,"2022-07-13 09:25:44","","10.3390/app10155135","","",,,,,19,9.50,4,5,2,"Human healthcare is one of the most important topics for society. It tries to find the correct effective and robust disease detection as soon as possible to patients receipt the appropriate cares. Because this detection is often a difficult task, it becomes necessary medicine field searches support from other fields such as statistics and computer science. These disciplines are facing the challenge of exploring new techniques, going beyond the traditional ones. The large number of techniques that are emerging makes it necessary to provide a comprehensive overview that avoids very particular aspects. To this end, we propose a systematic review dealing with the Machine Learning applied to the diagnosis of human diseases. This review focuses on modern techniques related to the development of Machine Learning applied to diagnosis of human diseases in the medical field, in order to discover interesting patterns, making non-trivial predictions and useful in decision-making. In this way, this work can help researchers to discover and, if necessary, determine the applicability of the machine learning techniques in their particular specialties. We provide some examples of the algorithms used in medicine, analysing some trends that are focused on the goal searched, the algorithm used, and the area of applications. We detail the advantages and disadvantages of each technique to help choose the most appropriate in each real-life situation, as several authors have reported. The authors searched Scopus, Journal Citation Reports (JCR), Google Scholar, and MedLine databases from the last decades (from 1980s approximately) up to the present, with English language restrictions, for studies according to the objectives mentioned above. Based on a protocol for data extraction defined and evaluated by all authors using PRISMA methodology, 141 papers were included in this advanced review.","",""
13,"Alexander M Zolotarev, B. Hansen, Ekaterina A. Ivanova, Katelynn M. Helfrich, Ning Li, P. Janssen, P. Mohler, N. Mokadam, B. Whitson, M. Fedorov, J. Hummel, D. Dylov, V. Fedorov","Optical Mapping-Validated Machine Learning Improves Atrial Fibrillation Driver Detection by Multi-Electrode Mapping",2020,"","","","",45,"2022-07-13 09:25:44","","10.1161/CIRCEP.119.008249","","",,,,,13,6.50,1,13,2,"Supplemental Digital Content is available in the text. Background: Atrial fibrillation (AF) can be maintained by localized intramural reentrant drivers. However, AF driver detection by clinical surface-only multielectrode mapping (MEM) has relied on subjective interpretation of activation maps. We hypothesized that application of machine learning to electrogram frequency spectra may accurately automate driver detection by MEM and add some objectivity to the interpretation of MEM findings. Methods: Temporally and spatially stable single AF drivers were mapped simultaneously in explanted human atria (n=11) by subsurface near-infrared optical mapping (NIOM; 0.3 mm2 resolution) and 64-electrode MEM (higher density or lower density with 3 and 9 mm2 resolution, respectively). Unipolar MEM and NIOM recordings were processed by Fourier transform analysis into 28 407 total Fourier spectra. Thirty-five features for machine learning were extracted from each Fourier spectrum. Results: Targeted driver ablation and NIOM activation maps efficiently defined the center and periphery of AF driver preferential tracks and provided validated annotations for driver versus nondriver electrodes in MEM arrays. Compared with analysis of single electrogram frequency features, averaging the features from each of the 8 neighboring electrodes, significantly improved classification of AF driver electrograms. The classification metrics increased when less strict annotation, including driver periphery electrodes, were added to driver center annotation. Notably, f1-score for the binary classification of higher-density catheter data set was significantly higher than that of lower-density catheter (0.81±0.02 versus 0.66±0.04, P<0.05). The trained algorithm correctly highlighted 86% of driver regions with higher density but only 80% with lower-density MEM arrays (81% for lower-density+higher-density arrays together). Conclusions: The machine learning model pretrained on Fourier spectrum features allows efficient classification of electrograms recordings as AF driver or nondriver compared with the NIOM gold-standard. Future application of NIOM-validated machine learning approach may improve the accuracy of AF driver detection for targeted ablation treatment in patients.","",""
12,"Boris Kovalerchuk, M. Ahmad, Ankur Teredesai Department of Computer Science, Central Washington University, U. C. O. Science, Systems, University of Washington Tacoma, Usa Kensci Inc., Usa","Survey of explainable machine learning with visual and granular methods beyond quasi-explanations",2020,"","","","",46,"2022-07-13 09:25:44","","10.1007/978-3-030-64949-4_8","","",,,,,12,6.00,1,9,2,"","",""
36,"Rachelly Normand, Wenfei Du, Mayan Briller, R. Gaujoux, E. Starosvetsky, Amit Ziv-Kenet, Gali Shalev-Malul, R. Tibshirani, S. Shen-Orr","Found In Translation: a machine learning model for mouse-to-human inference",2018,"","","","",47,"2022-07-13 09:25:44","","10.1038/s41592-018-0214-9","","",,,,,36,9.00,4,9,4,"","",""
19,"J. Mallick, S. AlQadhi, Swapan Talukdar, Majed Alsubih, Mohd. Ahmed, R. A. Khan, N. Kahla, Saud M. Abutayeh","Risk Assessment of Resources Exposed to Rainfall Induced Landslide with the Development of GIS and RS Based Ensemble Metaheuristic Machine Learning Algorithms",2021,"","","","",48,"2022-07-13 09:25:44","","10.3390/SU13020457","","",,,,,19,19.00,2,8,1,"Disastrous natural hazards, such as landslides, floods, and forest fires cause a serious threat to natural resources, assets and human lives. Consequently, landslide risk assessment has become requisite for managing the resources in future. This study was designed to develop four ensemble metaheuristic machine learning algorithms, such as grey wolf optimized based artificial neural network (GW-ANN), grey wolf optimized based random forest (GW-RF), particle swarm optimization optimized based ANN (PSO-ANN), and PSO optimized based RF for modeling rainfall-induced landslide susceptibility (LS) in Aqabat Al-Sulbat, Asir region, Saudi Arabia, which observes landslide frequently. To obtain very high precision and robust prediction from machine learning algorithms, the grey wolf and PSO optimization algorithms were integrated to develop new ensemble machine learning techniques. Subsequently, LS maps produced by training dataset were validated using the receiver operating characteristics (ROC) curve based on the testing dataset. Based on the area under curve (AUC) value of ROC curve, the best method for LS modeling was selected. We developed ROC curve-based sensitivity analysis to investigate the influence of the parameters for LS modeling. The Gumble extreme value distribution was employed to estimate the rainfall at 2, 5, 10, 20, 50, and 100 year return periods. Then, the landslide hazard maps were prepared at different return periods by integrating the best LS model and estimated rainfall at different return periods. The theory of danger pixels was employed to prepare a final risk assessment of the resources, which have been exposed to the landslide. The results showed that 27–42 and 6–15 km2 were predicted as the very high and high LS zones using four ensemble metaheuristic machine learning algorithms. Based on the area under curve (AUC) of ROC, GR-ANN (AUC-0.905) appeared as the best model for LS modeling. The areas under high and very high landslide hazard were gradually increased over the progression of time (26 km2 at the 2 year return period and 40 km2 at the 100 year return period for the high landslide hazard zone, and 6 km2 at the 2 year return period and 20 km2 at the 100 year return period for the very high landslide hazard zone). Similarly, the areas of danger pixel also increased gradually from the 2 to 100 year return periods (37 km2 to 62 km2). Various natural resources, such as scrubland, built up, and sparse vegetation, were identified under risk zone due to landslide hazards. In addition, these resources would be exposed extensively to landslides over the advancement of return periods. Therefore, the outcome of the present study will help planners and scientists to propose high precision management plans for protecting natural resources, which have been exposed to landslides.","",""
10,"Alan Le Goallec, B. Tierney, Jacob M. Luber, Evan M. Cofer, A. Kostic, C. Patel","A systematic machine learning and data type comparison yields metagenomic predictors of infant age, sex, breastfeeding, antibiotic usage, country of origin, and delivery type",2020,"","","","",49,"2022-07-13 09:25:44","","10.1371/journal.pcbi.1007895","","",,,,,10,5.00,2,6,2,"The microbiome is a new frontier for building predictors of human phenotypes. However, machine learning in the microbiome is fraught with issues of reproducibility, driven in large part by the wide range of analytic models and metagenomic data types available. We aimed to build robust metagenomic predictors of host phenotype by comparing prediction performances and biological interpretation across 8 machine learning methods and 4 different types of metagenomic data. Using 1,570 samples from 300 infants, we fit 7,865 models for 6 host phenotypes. We demonstrate the dependence of accuracy on algorithm choice and feature definition in microbiome data and propose a framework for building microbiome-derived indicators of host phenotype. We additionally identify biological features predictive of age, sex, breastfeeding status, historical antibiotic usage, country of origin, and delivery type. Our complete results can be viewed at http://apps.chiragjpgroup.org/ubiome_predictions/.","",""
10,"T. Mizoguchi, S. Kiyohara","Machine learning approaches for ELNES/XANES.",2020,"","","","",50,"2022-07-13 09:25:44","","10.1093/jmicro/dfz109","","",,,,,10,5.00,5,2,2,"Materials characterization is indispensable for materials development. In particular, spectroscopy provides atomic configuration, chemical bonding and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material. Despite its importance, the interpretation of spectra using human-driven methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the rapid increase in experimental spectral data. To overcome the limitations of such methods, we develop new data-driven approaches based on machine learning. Specifically, we use hierarchical clustering, a decision tree and a feedforward neural network to investigate the electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as local measurement of material functions.","",""
10,"Krupal P. Jethava, Jonathan A Fine, Yingqi Chen, Ahad Hossain, G. Chopra","Accelerated Reactivity Mechanism and Interpretable Machine Learning Model of N-Sulfonylimines toward Fast Multicomponent Reactions.",2020,"","","","",51,"2022-07-13 09:25:44","","10.26434/chemrxiv.12116163.v1","","",,,,,10,5.00,2,5,2,"We introduce chemical reactivity flowcharts to help chemists interpret reaction outcomes using statistically robust machine learning models trained on a small number of reactions. We developed fast N-sulfonylimine multicomponent reactions for understanding reactivity and to generate training data. Accelerated reactivity mechanisms were investigated using density functional theory. Intuitive chemical features learned by the model accurately predicted heterogeneous reactivity of N-sulfonylimine with different carboxylic acids. Validation of the predictions shows that reaction outcome interpretation is useful for human chemists.","",""
17,"Xuesi Ma, Baohang Xi, Yi Zhang, Lijuan Zhu, Xin Sui, Geng Tian, Jialiang Yang","A Machine Learning-based Diagnosis of Thyroid Cancer Using Thyroid Nodules Ultrasound Images",2020,"","","","",52,"2022-07-13 09:25:44","","10.2174/1574893614666191017091959","","",,,,,17,8.50,2,7,2,"  Ultrasound test is one of the routine tests for the diagnosis of thyroid cancer. The diagnosis accuracy depends largely on the correct interpretation of ultrasound images of thyroid nodules. However, human eye-based image recognition is usually subjective and sometimes error-prone especially for less experienced doctors, which presents a need for computeraided diagnostic systems.    To our best knowledge, there is no well-maintained ultrasound image database for the Chinese population. In addition, though there are several computational methods for image-based thyroid cancer detection, a comparison among them is missing. Finally, the effects of features like the choice of distance measures have not been assessed. The study aims to give the improvement of these limitations and proposes a highly accurate image-based thyroid cancer diagnosis system, which can better assist doctors in the diagnosis of thyroid cancer.    We first establish a novel thyroid nodule ultrasound image database consisting of 508 images collected from the Third Hospital of Hebei Medical University in China. The clinical information for the patients is also collected from the hospital, where 415 patients are diagnosed to be benign and 93 are malignant by doctors following a standard diagnosis procedure. We develop and apply five machine learning methods to the dataset including deep neural network, support vector machine, the center clustering method, k-nearest neighbor, and logistic regression.    Experimental results show that deep neural network outperforms other diagnosis methods with an average cross-validation accuracy of 0.87 in 10 runs. Meanwhile, we also explore the performance of four image distance measures including the Euclidean distance, the Manhattan distance, the Chebyshev distance, and the Minkowski distance, among which the Chebyshev distance is the best. The resource can be directly used to aid doctors in thyroid cancer diagnosis and treatment.    The paper establishes a novel thyroid nodule ultrasound image database and develops a high accurate image-based thyroid cancer diagnosis system which can better assist doctors in the diagnosis of thyroid cancer. ","",""
506,"W. James Murdoch, Chandan Singh, Karl Kumbier, R. Abbasi-Asl, Bin Yu","Definitions, methods, and applications in interpretable machine learning",2019,"","","","",53,"2022-07-13 09:25:44","","10.1073/pnas.1900654116","","",,,,,506,168.67,101,5,3,"Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.","",""
24,"Bethany Signal, B. Gloss, M. Dinger, T. Mercer","Machine learning annotation of human branchpoints",2018,"","","","",54,"2022-07-13 09:25:44","","10.1093/bioinformatics/btx688","","",,,,,24,6.00,6,4,4,"Motivation: The branchpoint element is required for the first lariat‐forming reaction in splicing. However current catalogues of human branchpoints remain incomplete due to the difficulty in experimentally identifying these splicing elements. To address this limitation, we have developed a machine‐learning algorithm—branchpointer—to identify branchpoint elements solely from gene annotations and genomic sequence. Results: Using branchpointer, we annotate branchpoint elements in 85% of human gene introns with sensitivity (61.8%) and specificity (97.8%). In addition to annotation, branchpointer can evaluate the impact of SNPs on branchpoint architecture to inform functional interpretation of genetic variants. Branchpointer identifies all published deleterious branchpoint mutations annotated in clinical variant databases, and finds thousands of additional clinical and common genetic variants with similar predicted effects. This genome‐wide annotation of branchpoints provides a reference for the genetic analysis of splicing, and the interpretation of noncoding variation. Availability and implementation: Branchpointer is written and implemented in the statistical programming language R and is freely available under a BSD license as a package through Bioconductor. Contact: b.signal@garvan.org.au or t.mercer@garvan.org Supplementary information: Supplementary data are available at Bioinformatics online.","",""
0,"Jia Qi Lim, N. Alias, F. Johar","Supervised Classification of Normal and Tumorous Brain MR Images Using Machine Learning Schemes",2020,"","","","",55,"2022-07-13 09:25:44","","10.20944/preprints202007.0688.v1","","",,,,,0,0.00,0,3,2,"Manual interpretation of these huge amounts of image volumes are susceptible to inter-reader variability and human error. Thus, accurate automated CAD scheme is highly desirable in clinical pathological diagnosis. In this research, plethora of machine learning paradigms (e.g. feature extraction, dimensionality reduction and supervised classification methods) were explored, evaluated, compared and analyzed to identify the optimal pathway for brain MR images (normal vs neoplastic) binary classification task. External validation dataset was used to test the generalizability of the optimal predictive models implemented. Relevant and informative features were selected to construct cross-validated decision tree and eventually simple rule set was built based on the decision tree. The experimental results show that almost all pattern recognition paradigms achieve high accuracy with careful selection of number of attributes. LDA+ELM with 55 features are the optimal pipelines which achieve perfect classification when training and test data are of same source; and achieving (accuracy=97.5%, AUC=0.989, sensitivity=95% and specificity=100%) under balanced test dataset; (accuracy=99.5%, AUC=0.988, sensitivity=95% and specificity=100%). Cross-validated decision tree model also shows comparable performance: accuracy=98.8%, AUC=99.1%, sensitivity=99.6% and specificity=98.2%. Three highly relevant and robust attributes are visualized and selected for construction of decision tree models and finally a rule sets are read directly off the decision tree. This rule sets can potentially serve as fast and accurate classification algorithm.","",""
0,"T. Mizoguchi, S. Kiyohara","Chapter 17. Machine Learning for Core-loss Spectrum",2020,"","","","",56,"2022-07-13 09:25:44","","10.1039/9781839160233-00424","","",,,,,0,0.00,0,2,2,"Characterization is indispensable for developing functional materials and molecules. In particular, spectroscopy provides atomic configuration, chemical bonding, and vibrational information, which are crucial for understanding the mechanism underlying the functions of a material and molecule. Despite its importance, the interpretation of spectra using “human-driven” methods, such as manual comparison of experimental spectra with reference/simulated spectra, is becoming difficult owing to the increase in experimental data. To overcome the limitations of “human-driven” methods, new data-driven approaches based on machine learning were developed. In this chapter, we review our machine learning method for spectral analysis. Hierarchical clustering, a decision tree, and a feedforward neural network were combined to investigate the core loss spectroscopy, namely electron energy loss near edge structures (ELNES) spectrum, which is identical to the X-ray absorption near edge structure (XANES) spectrum. Hierarchical clustering and the decision tree are used to interpret and predict ELNES/XANES, while the feedforward neural network is used to obtain hidden information about the material structure and properties from the spectra. Further, we construct a prediction model that is robust against noise by data augmentation. Finally, we apply our method to noisy spectra and predict six properties accurately. In summary, the proposed approaches can pave the way for fast and accurate spectrum interpretation/prediction as well as the local measurement of material functions.","",""
0,"David A. Hindin","Artificial Intelligence and Machine Learning: Implications for Surgery",2020,"","","","",57,"2022-07-13 09:25:44","","10.1007/978-3-030-49100-0_23","","",,,,,0,0.00,0,1,2,"","",""
0,"Adhideb Ghosh, A. Navarini","Biological function polarity prediction of missense variants using machine learning",2020,"","","","",58,"2022-07-13 09:25:44","","10.1101/2020.04.03.023440","","",,,,,0,0.00,0,2,2,"Functional interpretation is crucial when facing on average 20,000 missense variants per human exome, as the great majority are not associated with any underlying disease. In silico bioinformatics tools can predict the deleteriousness of variants or assess their functional impact by assigning scores, but they cannot predict whether the variant in question results in gain or loss of function at the protein level. Here, we show that machine learning can effectively predict this biological function polarity of missense variants. The new method adapts weighted gradient boosting machine approach on a set of damaging variants (1,288 loss of function and 218 gain of function variants) as annotated by the tools SIFT, PolyPhen2 and CADD. Area under the ROC curve of 0.85 illustrates high discriminative power of the classifier. Predictive performance of the classifier remains consistent against an independent set of damaging variants as highlighted by the area under the ROC curve of 0.83. This new approach may help to guide biological experiments on the clinical relevance of damaging genetic variants. Author summary Missense variant occurs when a single genetic alteration in DNA takes place and as a result a new amino acid is translated into the protein. This amino acid change can inactivate the existing protein function causing loss-of-function or produce a new function causing gain-of-function. Therefore, it is very important to interpret these functional consequences of missense variants as they often turn out to be disease causing. Each individual’s genome sequence has thousands of missense variants, out of which very few are actually associated with any underlying disease. Various computational tools have been developed to predict whether missense variants are damaging or not, but none of them can actually predict whether the damaging missense variants cause gain-of-function or loss-of-function. We have developed a new ensemble classifier to predict this biological function polarity at the protein level. The classifier combines the prediction scores of three existing bioinformatics tools and applies machine learning to make effective predictions. We have validated our classifier against an independent data set to show its high predictive power and robustness. The predictions made by our machine learning tool can be used as indicators of biological function polarity, but with further evidence on pathogenicity.","",""
4,"Barry McDermott, A. Elahi, A. Santorelli, M. O’halloran, J. Avery, E. Porter","Multi-frequency symmetry difference electrical impedance tomography with machine learning for human stroke diagnosis.",2020,"","","","",59,"2022-07-13 09:25:44","","10.1088/1361-6579/ab9e54","","",,,,,4,2.00,1,6,2,"OBJECTIVE Multi-Frequency Symmetry Difference Electrical Impedance Tomography (MFSD-EIT) can robustly detect and identify unilateral perturbations in symmetric scenes. Here, an investigation is performed to assess if the algorithm can be successfully applied to identify the aetiology of stroke with the aid of machine learning.   METHODS Anatomically realistic four-layer Finite Element Method models of the head based on stroke patient images are developed and used to generate EIT data over a 5 Hz - 100 Hz frequency range with and without bleed and clot lesions present. Reconstruction generates conductivity maps of each head at each frequency. Application of a quantitative metric assessing changes in symmetry across the sagittal plane of the reconstructed image and over the frequency range allows lesion detection and identification. The algorithm is applied to both simulated and human (n=34 subjects) data. A classification algorithm is applied to the metric value in order to differentiate between normal, haemorrhage and clot values.   RESULTS An average accuracy of 85% is achieved when MFSD-EIT with Support Vector Machines (SVM) classification is used to identify and differentiate bleed from clot in human data, with 77% accuracy when differentiating normal from stroke in human data.   CONCLUSION Applying a classification algorithm to metrics derived from MFSD-EIT images is a novel and promising technique for detection and identification of perturbations in static scenes.   SIGNIFICANCE The MFSD-EIT algorithm used with machine learning gives promising results of lesion detection and identification in challenging conditions like stroke. The results imply feasible translation to human patients.","",""
18,"M. A. Khan, Seifedine Kadry, P. Parwekar, Robertas Damaševičius, A. Mehmood, J. Khan, S. R. Naqvi","Human gait analysis for osteoarthritis prediction: a framework of deep learning and kernel extreme learning machine",2021,"","","","",60,"2022-07-13 09:25:44","","10.1007/S40747-020-00244-2","","",,,,,18,18.00,3,7,1,"","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",61,"2022-07-13 09:25:44","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
117,"Xiao Chen, Chaoran Li, Derui Wang, S. Wen, Jun Zhang, S. Nepal, Yang Xiang, K. Ren","Android HIV: A Study of Repackaging Malware for Evading Machine-Learning Detection",2018,"","","","",62,"2022-07-13 09:25:44","","10.1109/TIFS.2019.2932228","","",,,,,117,29.25,15,8,4,"Machine learning-based solutions have been successfully employed for the automatic detection of malware on Android. However, machine learning models lack robustness to adversarial examples, which are crafted by adding carefully chosen perturbations to the normal inputs. So far, the adversarial examples can only deceive detectors that rely on syntactic features (e.g., requested permissions, API calls, etc.), and the perturbations can only be implemented by simply modifying application’s manifest. While recent Android malware detectors rely more on semantic features from Dalvik bytecode rather than manifest, existing attacking/defending methods are no longer effective. In this paper, we introduce a new attacking method that generates adversarial examples of Android malware and evades being detected by the current models. To this end, we propose a method of applying optimal perturbations onto Android APK that can successfully deceive the machine learning detectors. We develop an automated tool to generate the adversarial examples without human intervention. In contrast to existing works, the adversarial examples crafted by our method can also deceive recent machine learning-based detectors that rely on semantic features such as control-flow-graph. The perturbations can also be implemented directly onto APK’s Dalvik bytecode rather than Android manifest to evade from recent detectors. We demonstrate our attack on two state-of-the-art Android malware detection schemes, MaMaDroid and Drebin. Our results show that the malware detection rates decreased from 96% to 0% in MaMaDroid, and from 97% to 0% in Drebin, with just a small number of codes to be inserted into the APK.","",""
22,"J. Phillip, Kyu-Sang Han, Wei-Chiang Chen, D. Wirtz, Pei-Hsun Wu","A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei.",2021,"","","","",63,"2022-07-13 09:25:44","","10.1038/s41596-020-00432-x","","",,,,,22,22.00,4,5,1,"","",""
312,"Jonas Rauber, Wieland Brendel, M. Bethge","Foolbox: A Python toolbox to benchmark the robustness of machine learning models",2017,"","","","",64,"2022-07-13 09:25:44","","","","",,,,,312,62.40,104,3,5,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox. The most up-to-date documentation can be found at http://foolbox.readthedocs.io. In 2013, Szegedy et al. demonstrated that minimal perturbations, often almost imperceptible to humans, can have devastating effects on machine predictions. These so-called adversarial perturbations thus demonstrate a striking difference between human and machine perception. As a result, adversarial perturbations have been subject to many Equal contribution Centre for Integrative Neuroscience, University of Tübingen, Germany Bernstein Center for Computational Neuroscience, Tübingen, Germany International Max Planck Research School for Intelligent Systems, Tübingen, Germany Max Planck Institute for Biological Cybernetics, Tübingen, Germany Institute for Theoretical Physics, University of Tübingen, Germany. Correspondence to: Jonas Rauber <jonas.rauber@bethgelab.org>. Reliable Machine Learning in the Wild Workshop, 34 th International Conference on Machine Learning, Sydney, Australia, 2017. studies concerning the generation of such perturbations and strategies to protect machine learning models such as deep neural networks against them. A practical definition of the robustness R of a model, first used by Szegedy et al. (2013), is the average size of the minimum adversarial perturbation ρ(x) across many samples x, R = 〈ρ(x)〉 x where (1) ρ(x) = min δ d(x,x+ δ) s.t. x+ δ is adversarial (2) and d(·) is some distance measure. Unfortunately, finding the global minimum adversarial perturbation is close to impossible in any practical setting, and we thus employ heuristic attacks to find a suitable approximation. Such heuristics, however, can fail, in which case we could easily be mislead to believe that a model is robust (Brendel & Bethge, 2017). Our best strategy is thus to employ as many attacks as possible, and to use the minimal perturbation found across all attacks as an approximation to the true global minimum. At the moment, however, such a strategy is severely obstructed by two problems: first, the code for most known attack methods is either not available at all, or only available for one particular deep learning framework. Second, implementations of the same attack often differ in many details and are thus not directly comparable. Foolbox improves upon the existing Python package cleverhans by Papernot et al. (2016b) in three important aspects: 1. It interfaces with most popular machine learning frameworks such as PyTorch, Keras, TensorFlow, Theano, Lasagne and MXNet and provides a straight forward way to add support for other frameworks, 2. it provides reference implementations for more than 15 adversarial attacks with a simple and consistent API, and 3. it supports many different criteria for adversarial examples, including custom ones. This technical report is structured as follows: In section 1 we provide an overview over Foolbox and demonstrate Foolbox: A Python toolbox to benchmark the robustness of machine learning models how to benchmark a model and report the result. In section 2 we describe the adversarial attack methods that are implemented in Foolbox and explain the internal hyperparameter tuning.","",""
5,"Haohan Wang, Zeyi Huang, Hanlin Zhang, Eric P. Xing","Toward Learning Human-aligned Cross-domain Robust Models by Countering Misaligned Features",2021,"","","","",65,"2022-07-13 09:25:44","","","","",,,,,5,5.00,1,4,1,"Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective as-suming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available here.","",""
45,"R. Roelofs, Vaishaal Shankar, B. Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, Ludwig Schmidt","A Meta-Analysis of Overfitting in Machine Learning",2019,"","","","",66,"2022-07-13 09:25:44","","","","",,,,,45,15.00,6,7,3,"We conduct the first large meta-analysis of overfitting due to test set reuse in the machine learning community. Our analysis is based on over one hundred machine learning competitions hosted on the Kaggle platform over the course of several years. In each competition, numerous practitioners repeatedly evaluated their progress against a holdout set that forms the basis of a public ranking available throughout the competition. Performance on a separate test set used only once determined the final ranking. By systematically comparing the public ranking with the final ranking, we assess how much participants adapted to the holdout set over the course of a competition. Our study shows, somewhat surprisingly, little evidence of substantial overfitting. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.","",""
30,"D. Yang, Liling Zhu, Yalong Liu, Danhong Wu, B. Ran","A Novel Car-Following Control Model Combining Machine Learning and Kinematics Models for Automated Vehicles",2019,"","","","",67,"2022-07-13 09:25:44","","10.1109/TITS.2018.2854827","","",,,,,30,10.00,6,5,3,"The machine learning-based car-following models are widely adopted to control the longitudinal movements of automated vehicles, such as Google Car and Apple Car, by mimicking the human drivers’ car-following maneuver. However, like human drivers, the models easily produce unsafe maneuvers for automated vehicles and has low robustness, especially in uncommon situations. To improve the machine learning-based car-following models, this paper proposes to combine the machine learning models with the kinematics-based car-following models that can overcome the shortcomings of machine learning models, using an optimal combination prediction method, which is called the combination car-following model in the paper. The selected kinematics-based car-following model is the Gipps model that has an intrinsic crash-avoidance mechanism, and the used machine learning-based models are the Back-Propagation Neural Networks (BPNN) model and Random Forest (RF) model, producing the two CCF models, the Gipps-RF model and Gipps-BPNN model. The real vehicle trajectory data sets are applied to calibrate and validate the proposed models, and simulations are conducted to evaluate the model performances. The results display that the proposed CCF models can enhance safety level and robustness of the car-following control of automated vehicles. Both the two CCF models have better performance than the BPNN and RF car-following models in reducing congestion, stabilizing traffic, and avoiding crashes, especially the Gipps-BPNN model.","",""
46,"M. Umehara, H. Stein, D. Guevarra, P. F. Newhouse, D. Boyd, J. Gregoire","Analyzing machine learning models to accelerate generation of fundamental materials insights",2019,"","","","",68,"2022-07-13 09:25:44","","10.1038/s41524-019-0172-5","","",,,,,46,15.33,8,6,3,"","",""
62,"Shi Feng, Jordan L. Boyd-Graber","What can AI do for me?: evaluating machine learning interpretations in cooperative play",2018,"","","","",69,"2022-07-13 09:25:44","","10.1145/3301275.3302265","","",,,,,62,15.50,31,2,4,"Machine learning is an important tool for decision making, but its ethical and responsible application requires rigorous vetting of its interpretability and utility: an understudied problem, particularly for natural language processing models. We propose an evaluation of interpretation on a real task with real human users, where the effectiveness of interpretation is measured by how much it improves human performance. We design a grounded, realistic human-computer cooperative setting using a question answering task, Quizbowl. We recruit both trivia experts and novices to play this game with computer as their teammate, who communicates its prediction via three different interpretations. We also provide design guidance for natural language processing human-in-the-loop settings.","",""
19,"C. Cai, M. Linnenluecke, M. Marrone, Abhay K. Singh","Machine Learning and Expert Judgement: Analyzing Emerging Topics in Accounting and Finance Research in the Asia–Pacific",2019,"","","","",70,"2022-07-13 09:25:44","","10.1111/abac.12179","","",,,,,19,6.33,5,4,3,"In this paper, we focus on the question to what extent machine learning (ML) tools can be used to support systematic literature reviews. We apply a ML approach for topic detection to analyze emerging topics in the literature—our context is accounting and finance research in the Asia–Pacific region. To evaluate the robustness of the approach, we compare findings from the automated ML approach with the results from a manual analysis of the literature. The automated approach uses a keyword algorithm detection mechanism whereby the manual analysis uses common techniques for qualitative data analysis, that is, triangulation between researchers (expert judgement). From our paper, we conclude that both methods have strengths and weaknesses. The automated analysis works well for large corpora of text and provides a very standardized and non‐biased way of analyzing the literature. However, the human researcher is potentially better equipped to evaluate current issues and future trends in the literature. Overall, the best results might be achieved when a variety of tools are used together. [ABSTRACT FROM AUTHOR]","",""
29,"Muhammet Fatih Aslan, Akif Durdu, K. Sabanci","Human action recognition with bag of visual words using different machine learning methods and hyperparameter optimization",2019,"","","","",71,"2022-07-13 09:25:44","","10.1007/s00521-019-04365-9","","",,,,,29,9.67,10,3,3,"","",""
24,"V. M","Melanoma Skin Cancer Detection using Image Processing and Machine Learning",2019,"","","","",72,"2022-07-13 09:25:44","","10.31142/IJTSRD23936","","",,,,,24,8.00,24,1,3,"Copyright © 2019 by author(s) and International Journal of Trend in Scientific Research and Development Journal. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0) (http://creativecommons.org/licenses/ by/4.0) ABSTRACT Dermatological Diseases are one of the biggest medical issues in 21st century due to its highly complex and expensive diagnosis with difficulties and subjectivity of human interpretation. In cases of fatal diseases like Melanoma diagnosis in early stages play a vital role in determining the probability of getting cured. We believe that the application of automated methods will help in early diagnosis especially with the set of images with variety of diagnosis. Hence, in this article we present a completely automated system of dermatological disease recognition through lesion images, a machine intervention in contrast to conventional medical personnel-based detection. Our model is designed into three phases compromising of data collection and augmentation, designing model and finally prediction. We have used multiple AI algorithms like Convolutional Neural Network and Support Vector Machine and amalgamated it with image processing tools to form a better structure, leading to higher accuracy of 85%.","",""
23,"Martin G. Seneviratne, N. Shah, Larry Chu","Bridging the implementation gap of machine learning in healthcare",2019,"","","","",73,"2022-07-13 09:25:44","","10.1136/bmjinnov-2019-000359","","",,,,,23,7.67,8,3,3,"Applications of machine learning on clinical data are now attaining levels of performance that match or exceed human clinicians.1–3 Fields involving image interpretation—radiology, pathology and dermatology—have led the charge due to the power of convolutional neural networks, the existence of standard data formats and large data repositories. We have also seen powerful diagnostic and predictive algorithms built using a range of other data, including electronic health records (EHR), -omics, monitoring signals, insurance claims and patient-generated data.4 The looming extinction of doctors has captured the public imagination, with editorials such as ‘The AI Doctor Will See You Now’.5 The prevailing view among experts is more balanced: that doctors who use artificial intelligence (AI) will replace those who do not.6  Amid such inflated expectations, the elephant in the room is the implementation gap of machine learning in healthcare.7 8 Very few of these algorithms ever make it to the bedside; and even the most technology-literate academic medical centres are not routinely using AI in clinical workflows. A recent systematic review of deep learning applications using EHR data highlighted the need to focus on the last mile of implementation: ‘for direct clinical impact, deployment and automation of deep learning models must be considered’.9 The typical life-cycle of an algorithm remains: train on historical data, publish a good receiver-operator curve and then collect dust in the ‘model graveyard’.  This begs the question: if model performance is so …","",""
13,"Nicholas Carlini, Ú. Erlingsson, Nicolas Papernot","Distribution Density, Tails, and Outliers in Machine Learning: Metrics and Applications",2019,"","","","",74,"2022-07-13 09:25:44","","","","",,,,,13,4.33,4,3,3,"We develop techniques to quantify the degree to which a given (training or testing) example is an outlier in the underlying distribution. We evaluate five methods to score examples in a dataset by how well-represented the examples are, for different plausible definitions of ""well-represented"", and apply these to four common datasets: MNIST, Fashion-MNIST, CIFAR-10, and ImageNet. Despite being independent approaches, we find all five are highly correlated, suggesting that the notion of being well-represented can be quantified. Among other uses, we find these methods can be combined to identify (a) prototypical examples (that match human expectations); (b) memorized training examples; and, (c) uncommon submodes of the dataset. Further, we show how we can utilize our metrics to determine an improved ordering for curriculum learning, and impact adversarial robustness. We release all metric values on training and test sets we studied.","",""
9,"Shanwen Sun, Benzhi Dong, Q. Zou","Revisiting genome-wide association studies from statistical modelling to machine learning",2020,"","","","",75,"2022-07-13 09:25:44","","10.1093/bib/bbaa263","","",,,,,9,4.50,3,3,2,"Over the last decade, genome-wide association studies (GWAS) have discovered thousands of genetic variants underlying complex human diseases and agriculturally important traits. These findings have been utilized to dissect the biological basis of diseases, to develop new drugs, to advance precision medicine and to boost breeding. However, the potential of GWAS is still underexploited due to methodological limitations. Many challenges have emerged, including detecting epistasis and single-nucleotide polymorphisms (SNPs) with small effects and distinguishing causal variants from other SNPs associated through linkage disequilibrium. These issues have motivated advancements in GWAS analyses in two contrasting cultures-statistical modelling and machine learning. In this review, we systematically present the basic concepts and the benefits and limitations in both methods. We further discuss recent efforts to mitigate their weaknesses. Additionally, we summarize the state-of-the-art tools for detecting the missed signals, ultrarare mutations and gene-gene interactions and for prioritizing SNPs. Our work can offer both theoretical and practical guidelines for performing GWAS analyses and for developing further new robust methods to fully exploit the potential of GWAS.","",""
17,"Luke E K Achenie, A. Scarpa, R. Factor, Tao Wang, D. Robins, D. S. McCrickard","A Machine Learning Strategy for Autism Screening in Toddlers.",2019,"","","","",76,"2022-07-13 09:25:44","","10.1097/DBP.0000000000000668","","",,,,,17,5.67,3,6,3,"OBJECTIVE Autism spectrum disorder (ASD) screening can improve prognosis via early diagnosis and intervention, but lack of time and training can deter pediatric screening. The Modified Checklist for Autism in Toddlers, Revised (M-CHAT-R) is a widely used screener but requires follow-up questions and error-prone human scoring and interpretation. We consider an automated machine learning (ML) method for overcoming barriers to ASD screening, specifically using the feedforward neural network (fNN).   METHODS The fNN technique was applied using archival M-CHAT-R data of 14,995 toddlers (age 16-30 months, 46.51% male). The 20 M-CHAT-R items were inputs, and ASD diagnosis after follow-up and diagnostic evaluation (i.e., ASD or not ASD) was the output. The sample was divided into subgroups by race (i.e., white and black), sex (i.e., boys and girls), and maternal education (i.e., below and above 15 years of education completed) to examine subgroup differences. Each subgroup was evaluated for best-performing fNN models.   RESULTS For the total sample, best results yielded 99.72% correct classification using 18 items. Best results yielded 99.92% correct classification using 14 items for white toddlers and 99.79% correct classification using 18 items for black toddlers. In boys, best results yielded 99.64% correct classification using 18 items, whereas best results yielded 99.95% correct classification using 18 items in girls. For the case when maternal education is 15 years or less (i.e., associate degree and below), best results were 99.75% correct classification when using 16 items. Results were essentially the same when maternal education was 16 years or more (i.e., above associate degree); that is, 99.70% correct classification was obtained using 16 items.   CONCLUSION The ML method was comparable to the M-CHAT-R with follow-up items in accuracy of ASD diagnosis while using fewer items. Therefore, ML may be a beneficial tool in implementing automatic, efficient scoring that negates the need for labor-intensive follow-up and circumvents human error, providing an advantage over previous screening methods.","",""
74,"Monika A. Myszczynska, P. Ojamies, Alix M. B. Lacoste, Daniel Neil, Amir Saffari, R. Mead, G. Hautbergue, J. Holbrook, L. Ferraiuolo","Applications of machine learning to diagnosis and treatment of neurodegenerative diseases",2020,"","","","",77,"2022-07-13 09:25:44","","10.1038/s41582-020-0377-8","","",,,,,74,37.00,8,9,2,"","",""
75,"M. Prosperi, Yi Guo, M. Sperrin, J. Koopman, Jae Min, Xing He, S. Rich, Mo Wang, I. Buchan, J. Bian","Causal inference and counterfactual prediction in machine learning for actionable healthcare",2020,"","","","",78,"2022-07-13 09:25:44","","10.1038/s42256-020-0197-y","","",,,,,75,37.50,8,10,2,"","",""
5,"J. Dukart, S. Weis, S. Genon, S. Eickhoff","Towards increasing the clinical applicability of machine learning biomarkers in psychiatry.",2021,"","","","",79,"2022-07-13 09:25:44","","10.1038/s41562-021-01085-w","","",,,,,5,5.00,1,4,1,"","",""
36,"Dingding Wang, Jiaqing Mo, Gang Zhou, Liang Xu, Yajun Liu","An efficient mixture of deep and machine learning models for COVID-19 diagnosis in chest X-ray images",2020,"","","","",80,"2022-07-13 09:25:44","","10.1371/journal.pone.0242535","","",,,,,36,18.00,7,5,2,"A newly emerged coronavirus (COVID-19) seriously threatens human life and health worldwide. In coping and fighting against COVID-19, the most critical step is to effectively screen and diagnose infected patients. Among them, chest X-ray imaging technology is a valuable imaging diagnosis method. The use of computer-aided diagnosis to screen X-ray images of COVID-19 cases can provide experts with auxiliary diagnosis suggestions, which can reduce the burden of experts to a certain extent. In this study, we first used conventional transfer learning methods, using five pre-trained deep learning models, which the Xception model showed a relatively ideal effect, and the diagnostic accuracy reached 96.75%. In order to further improve the diagnostic accuracy, we propose an efficient diagnostic method that uses a combination of deep features and machine learning classification. It implements an end-to-end diagnostic model. The proposed method was tested on two datasets and performed exceptionally well on both of them. We first evaluated the model on 1102 chest X-ray images. The experimental results show that the diagnostic accuracy of Xception + SVM is as high as 99.33%. Compared with the baseline Xception model, the diagnostic accuracy is improved by 2.58%. The sensitivity, specificity and AUC of this model reached 99.27%, 99.38% and 99.32%, respectively. To further illustrate the robustness of our method, we also tested our proposed model on another dataset. Finally also achieved good results. Compared with related research, our proposed method has higher classification accuracy and efficient diagnostic performance. Overall, the proposed method substantially advances the current radiology based methodology, it can be very helpful tool for clinical practitioners and radiologists to aid them in diagnosis and follow-up of COVID-19 cases.","",""
0,"Andreea Chiorean, K. Farncombe, Sean Delong, Veronica Andric, S. Ansar, Clarissa Chan, Kaitlin A. Clark, Arpad M. Danos, Yizhuo Gao, R. Giles, A. Goldenberg, P. Jani, Kilannin Krysiak, Lynzey Kujan, Samantha Macpherson, E. Maher, L. McCoy, Yasser Salama, Jason Saliba, Lana M. Sheta, M. Griffith, O. Griffith, L. Erdman, A. Ramani, Raymond H. Kim","Large scale genotype- and phenotype-driven machine learning in Von Hippel-Lindau disease.",2022,"","","","",81,"2022-07-13 09:25:44","","10.1002/humu.24392","","",,,,,0,0.00,0,25,1,"Von Hippel-Lindau (VHL) disease is a hereditary cancer syndrome where individuals are predisposed to tumor development in the brain, adrenal gland, kidney and other organs. It is caused by pathogenic variants in the VHL tumor suppressor gene. Standardized disease information has been difficult to collect due to the rarity and diversity of VHL patients. Over 4100 unique articles published until October 2019 were screened for germline genotype-phenotype data. Patient data was translated into standardized descriptions using Human Genome Variation Society (HGVS) gene variant nomenclature and Human Phenotype Ontology (HPO) terms and has been manually curated into an open-access knowledgebase called Clinical Interpretation of Variants in Cancer (CIViC). In total, 634 unique VHL variants, 2882 patients and 1991 families from 427 papers were captured. We identified relationship trends between phenotype and genotype data using classic statistical methods and spectral clustering unsupervised learning. Our analyses reveal earlier onset of pheochromocytoma/paraganglioma and retinal angiomas, phenotype co-occurrences and genotype-phenotype correlations including hot-spots. It confirms existing VHL associations and can be used to identify new patterns and associations in VHL disease. Our database serves as an aggregate knowledge translation tool to facilitate sharing information about the pathogenicity of VHL variants. This article is protected by copyright. All rights reserved.","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",82,"2022-07-13 09:25:44","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
8,"Jo-Hsuan Wu, T. Y. A. Liu, W. Hsu, J. Ho, Chien-Chang Lee","Performance and Limitation of Machine Learning Algorithms for Diabetic Retinopathy Screening: Meta-analysis",2021,"","","","",83,"2022-07-13 09:25:44","","10.2196/23863","","",,,,,8,8.00,2,5,1,"Background Diabetic retinopathy (DR), whose standard diagnosis is performed by human experts, has high prevalence and requires a more efficient screening method. Although machine learning (ML)–based automated DR diagnosis has gained attention due to recent approval of IDx-DR, performance of this tool has not been examined systematically, and the best ML technique for use in a real-world setting has not been discussed. Objective The aim of this study was to systematically examine the overall diagnostic accuracy of ML in diagnosing DR of different categories based on color fundus photographs and to determine the state-of-the-art ML approach. Methods Published studies in PubMed and EMBASE were searched from inception to June 2020. Studies were screened for relevant outcomes, publication types, and data sufficiency, and a total of 60 out of 2128 (2.82%) studies were retrieved after study selection. Extraction of data was performed by 2 authors according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses), and the quality assessment was performed according to the Quality Assessment of Diagnostic Accuracy Studies 2 (QUADAS-2). Meta-analysis of diagnostic accuracy was pooled using a bivariate random effects model. The main outcomes included diagnostic accuracy, sensitivity, and specificity of ML in diagnosing DR based on color fundus photographs, as well as the performances of different major types of ML algorithms. Results The primary meta-analysis included 60 color fundus photograph studies (445,175 interpretations). Overall, ML demonstrated high accuracy in diagnosing DR of various categories, with a pooled area under the receiver operating characteristic (AUROC) ranging from 0.97 (95% CI 0.96-0.99) to 0.99 (95% CI 0.98-1.00). The performance of ML in detecting more-than-mild DR was robust (sensitivity 0.95; AUROC 0.97), and by subgroup analyses, we observed that robust performance of ML was not limited to benchmark data sets (sensitivity 0.92; AUROC 0.96) but could be generalized to images collected in clinical practice (sensitivity 0.97; AUROC 0.97). Neural network was the most widely used method, and the subgroup analysis revealed a pooled AUROC of 0.98 (95% CI 0.96-0.99) for studies that used neural networks to diagnose more-than-mild DR. Conclusions This meta-analysis demonstrated high diagnostic accuracy of ML algorithms in detecting DR on color fundus photographs, suggesting that state-of-the-art, ML-based DR screening algorithms are likely ready for clinical applications. However, a significant portion of the earlier published studies had methodology flaws, such as the lack of external validation and presence of spectrum bias. The results of these studies should be interpreted with caution.","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",84,"2022-07-13 09:25:44","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
6,"P. Washington, O. Mutlu, É. Leblanc, A. Kline, C. Hou, B. Chrisman, N. Stockham, K. Paskov, C. Voss, N. Haber, D. Wall","Using Crowdsourcing to Train Facial Emotion Machine Learning Models with Ambiguous Labels",2021,"","","","",85,"2022-07-13 09:25:44","","","","",,,,,6,6.00,1,11,1,"Current emotion detection classifiers predict discrete emotions. However, literature in psychology has documented that compound and ambiguous facial expressions are often evoked by humans. As a stride towards development of machine learning models that more accurately reflect compound and ambiguous emotions, we replace traditional one-hot encoded label representations with a crowd's distribution of labels. We center our study on the Child Affective Facial Expression (CAFE) dataset, a gold standard dataset of pediatric facial expressions which includes 100 human labels per image. We first acquire crowdsourced labels for 207 emotions from CAFE and demonstrate that the consensus labels from the crowd tend to match the consensus from the original CAFE raters, validating the utility of crowdsourcing. We then train two versions of a ResNet-152 classifier on CAFE images with two types of labels (1) traditional one-hot encoding and (2) vector labels representing the crowd distribution of responses. We compare the resulting output distributions of the two classifiers. While the traditional F1-score for the one-hot encoding classifier is much higher (94.33% vs. 78.68%), the output probability vector of the crowd-trained classifier much more closely resembles the distribution of human labels (t=3.2827, p=0.0014). For many applications of affective computing, reporting an emotion probability distribution that more closely resembles human interpretation can be more important than traditional machine learning metrics. This work is a first step for engineers of interactive systems to account for machine learning cases with ambiguous classes and we hope it will generate a discussion about machine learning with ambiguous labels and leveraging crowdsourcing as a potential solution.","",""
1,"Owain Evans, W. Saunders, Andreas Stuhlmüller","Machine Learning Projects for Iterated Distillation and Amplification",2019,"","","","",86,"2022-07-13 09:25:44","","","","",,,,,1,0.33,0,3,3,"Iterated Distillation and Amplification (IDA) is a framework for training ML models. IDA is related to existing frameworks like imitation learning and reinforcement learning, but it aims to solve tasks for which humans cannot construct a suitable reward function or solve directly. This document reviews IDA and proposes three projects that explore aspects of IDA. Project 1 applies IDA to problems in highschool mathematics and investigates whether learning to decompose problems can improve performance over supervised learning. Project 2 applies IDA to neural program interpretation, where neural nets are trained on the internal behavior (execution traces) of traditional computer programs. Project 3 investigates whether adaptive computation time (varying compute at inference time as a function of the input) can improve the robustness and efficiency of IDA. Our goal in outlining these projects is to generate discussion and encourage research on IDA. We are not (as of June 2019) working on these projects, but we are interested in collaboration.","",""
5,"Xueqin Pang, C. Forrest, Félice Lê-Scherban, A. Masino","Understanding Early Childhood Obesity via Interpretation of Machine Learning Model Predictions",2019,"","","","",87,"2022-07-13 09:25:44","","10.1109/ICMLA.2019.00235","","",,,,,5,1.67,1,4,3,"Obesity, as an independent risk factor for increased morbidity and mortality throughout the lifecycle, is a major health issue in the United States. Pediatric obesity is a strong risk factor for adult obesity, as it tends to be stable and tracks into adulthood. Therefore, prevention of childhood obesity is urgently required for reduction in obesity prevalence and obesity related comorbidities. In this paper, the general pediatric obesity development pattern and the onset time period of early childhood obesity was identified via analysis of approximately 11 million pediatric clinical encounters of 860,510 unique individuals. XGBoost model was developed to predict at age 2 years if individuals would develop obesity in early childhood. The model is generalized to both males and females, and achieved an AUC of 81% (± 0.1%). Obesity associated risk factors were further analyzed via interpretation of the XGBoost model predictions. Besides known predictive factors such as weight, height, race, and ethnicity, new factors such as body temperature and respiratory rate were also identified. As body temperature and respiratory rate are related to human metabolism, novel physiologic mechanisms that cause these associations might be discovered in future research. We decomposed model recall to different age ranges when obesity incidence occurred. The model recall for individuals with obesity incidence between 24–36 months was 97.63%, while recall for obesity incidence between 72–84 months was 48.96%, suggesting obesity is less predictable further in the future. Since obesity is largely affected by evolving factors such as life style, diet, and living environment, it is possible that obesity prevention may be achieved via changes in adjustable factors.","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",88,"2022-07-13 09:25:44","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
0,"P. O. Fernandes, J. Martins, E. D. de Melo, R. B. de Oliveira, T. Kronenberger, V. Maltarollo","Quantitative structure-activity relationship and machine learning studies of 2-thiazolylhydrazone derivatives with anti-Cryptococcus neoformans activity.",2021,"","","","",89,"2022-07-13 09:25:44","","10.1080/07391102.2021.1935321","","",,,,,0,0.00,0,6,1,"Cryptococcus neoformans is a fungus responsible for infections in humans with a significant number of cases in immunosuppressed patients, mainly in underdeveloped countries. In this context, the thiazolylhydrazones are a promising class of compounds with activity against C. neoformans. The understanding of the structure-activity relationship of these derivatives could lead to the design of robust compounds that could be promising drug candidates for fungal infections. Specifically, modern techniques such as 4D-QSAR and machine learning methods were employed in this work to generate two QSAR models (one 2D and one 4D) with high predictive power (r2 for the test set equals to 0.934 and 0.831, respectively), and one random forest classification model was reported with Matthews correlation coefficient equals to 1 and 0.62 for internal and external validations, respectively. The physicochemical interpretation of selected models, indicated the importance of aliphatic substituents at the hydrazone moiety to antifungal activity, corroborating experimental data.Communicated by Ramaswamy H. Sarma.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",90,"2022-07-13 09:25:44","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",91,"2022-07-13 09:25:44","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
9,"Robert G. de Luna, E. Dadios, A. Bandala, R. R. Vicerra","Size Classification of Tomato Fruit Using Thresholding, Machine Learning, and Deep Learning Techniques",2019,"","","","",92,"2022-07-13 09:25:44","","10.17503/agrivita.v41i3.2435","","",,,,,9,3.00,2,4,3,"The size of tomato fruits is closely related to the market segment and price. Manual sorting in tomato is very dependent on human interpretation and thus, very prone to error.  The study presents thresholding, machine learning, and deep learning techniques in classifying the tomato as small, medium, and large based from a single tomato fruit image implemented using Open CV libraries and Python programming. Tomato images with different sizes are gathered where features like area, perimeter, and enclosed circle radius are extracted. The experiment shows that using thresholding, a classification accuracy of 85.83%, 65.83%, and 80% was achieved for area, perimeter, and enclosed circle radius, respectively. For machine learning, the training accuracy rates were recorded as 94.00%-95.00% for SVM, 97.50-92.50% for KNN and 90.33-92.50% for ANN. Comparison of models revealed that SVM is the most model without over fitting. The deep learning approach, regardless of the algorithm, produced low performances with 82.31%-78.21%-55.97% training-validation-testing accuracy for VGG16, 48.17%-41.44%-37.64% for InceptionV3, and 56.05%-44.96%-22.78% for ResNet50 models. Comparative analysis showed that machine learning technique bested the performance of the thresholding and deep learning techniques in classifying the tomato fruit size in terms of accuracy performance.","",""
27,"E. Mekov, M. Miravitlles, R. Petkov","Artificial intelligence and machine learning in respiratory medicine",2020,"","","","",93,"2022-07-13 09:25:44","","10.1080/17476348.2020.1743181","","",,,,,27,13.50,9,3,2,"ABSTRACT Introduction The application of artificial intelligence (AI) and machine learning (ML) in medicine and in particular in respiratory medicine is an increasingly relevant topic. Areas covered We aimed to identify and describe the studies published on the use of AI and ML in the field of respiratory diseases. The string ‘(((pulmonary) OR respiratory)) AND ((artificial intelligence) OR machine learning)’ was used in PubMed as a search strategy. The majority of studies identified corresponded to the area of chronic obstructive pulmonary disease (COPD), in particular to COPD and chest computed tomography scans, interpretation of pulmonary function tests, exacerbations and treatment. Another field of interest is the application of AI and ML to the diagnosis of interstitial lung disease, and a few other studies were identified on the fields of mechanical ventilation, interpretation of images on chest X-ray and diagnosis of bronchial asthma. Expert opinion ML may help to make clinical decisions but will not replace the physician completely. Human errors in medicine are associated with large financial losses, and many of them could be prevented with the help of AI and ML. AI is particularly useful in the absence of conclusive evidence of decision-making.","",""
51,"Zhen Wang, H. Di, M. Shafiq, Yazeed Alaudah, G. AlRegib","Successful leveraging of image processing and machine learning in seismic structural interpretation: A review",2018,"","","","",94,"2022-07-13 09:25:44","","10.1190/TLE37060451.1","","",,,,,51,12.75,10,5,4,"As a process that identifies geologic structures of interest such as faults, salt domes, or elements of petroleum systems in general, seismic structural interpretation depends heavily on the domain knowledge and experience of interpreters as well as visual cues of geologic structures, such as texture and geometry. With the dramatic increase in size of seismic data acquired for hydrocarbon exploration, structural interpretation has become more time consuming and labor intensive. By treating seismic data as images rather than signal traces, researchers have been able to utilize advanced image-processing and machine-learning techniques to assist interpretation directly. In this paper, we mainly focus on the interpretation of two important geologic structures, faults and salt domes, and summarize interpretation workflows based on typical or advanced image-processing and machine-learning algorithms. In recent years, increasing computational power and the massive amount of available data have led to the rise of deep learning. Deep-learning models that simulate the human brain's biological neural networks can achieve state-of-the-art accuracy and even exceed human-level performance on numerous applications. The convolutional neural network — a form of deep-learning model that is effective in analyzing visual imagery — has been applied in fault and salt dome interpretation. At the end of this review, we provide insight and discussion on the future of structural interpretation.","",""
29,"Md. Khayrul Bashar, Ishio Chiaki, Hiroaki Yoshida","Human identification from brain EEG signals using advanced machine learning method EEG-based biometrics",2016,"","","","",95,"2022-07-13 09:25:44","","10.1109/IECBES.2016.7843496","","",,,,,29,4.83,10,3,6,"EEG-based human recognition is increasingly becoming a popular modality for biometric authentication. Two important features of EEG signals are liveliness and the robustness against falsification. However, a comprehensive study on human authentication using EEG signal is still remains. On the other hand, low-cost wireless EEG recording devices are now growing in the market places. Although these devices have the potential to many applications, researches have yet to be done to find the feasibility of these devices. In this study, we propose a method for human identification using EEG signals obtained from such low-cost devices. EEG signal is first preprocessed to remove noise and artifacts using Bandpass FIR filter. These signals are then divided into disjoint segments. Three feature extraction methods, namely multiscale shape description (MSD), multiscale wavelet packet statistics (WPS) and multiscale wavelet packet energy statistics (WPES) are then applied. These features are finally used to train a supervised error-correcting output code multiclass model (ECOC) using support vector machine (SVM) classifier, which ultimately can recognize humans from test EEG signals. A preliminary experiment with 9 EEG records from 9 subjects shows the true positive rate of 94.44% of the proposed method.","",""
9,"Manuel B. Garcia, Shaneth C. Ambat, Rossana Adao","Tomayto, Tomahto: A Machine Learning Approach for Tomato Ripening Stage Identification Using Pixel-Based Color Image Classification",2019,"","","","",96,"2022-07-13 09:25:44","","10.1109/HNICEM48295.2019.9072892","","",,,,,9,3.00,3,3,3,"The main enterprise of the Philippine agriculture sector is crop cultivation where tomato is deliberated as one of the major crops in the country. With the abundance on tomato production, ripeness classification becomes fairly laborious and challenging, not to mention the subjective visual interpretation of human graders grounded from practical experience that is easily influenced by the environment and prone to error. Thus, this study proposes an automatic tomato ripeness identification using Support Vector Machine (SVM) classifier and CIELab color space via a machine learning approach. Dataset used for modeling and validation experiment in a 5-fold cross-validation strategy was composed of 900 images assembled from a farm and various image search engines. Divided into six classes that represent tomato ripening stages, experimental results showed that the proposed method was successful with 83.39% accuracy in ripeness classification detection. With this machine learning approach and combination of image processing techniques, the agriculture industry could benefit by automating the ripeness estimation which then could save tomatoes from damage.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",97,"2022-07-13 09:25:44","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",98,"2022-07-13 09:25:44","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",99,"2022-07-13 09:25:44","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
0,"G. Truda","Quantified Sleep: Machine learning techniques for observational n-of-1 studies",2021,"","","","",100,"2022-07-13 09:25:44","","","","",,,,,0,0.00,0,1,1,"This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features. The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. “Markov unfolding” is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal β-parameters, and using the SHAP framework, which can explain any “black box” model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.","",""
33,"A. Samarakoon, K. Barros, Y. Li, M. Eisenbach, Qiang Zhang, F. Ye, V. Sharma, Z. Dun, Haidong Zhou, S. A. Grigera, C. Batista, D. Tennant","Machine-learning-assisted insight into spin ice Dy2Ti2O7",2019,"","","","",101,"2022-07-13 09:25:44","","10.1038/s41467-020-14660-y","","",,,,,33,11.00,3,12,3,"","",""
26,"W. Gou, Chu-wen Ling, Yan He, Zengliang Jiang, Yuanqing Fu, Fengzhe Xu, Z. Miao, Ting-yu Sun, Jie-sheng Lin, Hui-lian Zhu, Hongwei Zhou, Yu-ming Chen, Ju-Sheng Zheng","Interpretable Machine Learning Framework Reveals Robust Gut Microbiome Features Associated With Type 2 Diabetes",2020,"","","","",102,"2022-07-13 09:25:44","","10.2337/dc20-1536","","",,,,,26,13.00,3,13,2,"OBJECTIVE To identify the core gut microbial features associated with type 2 diabetes risk and potential demographic, adiposity, and dietary factors associated with these features. RESEARCH DESIGN AND METHODS We used an interpretable machine learning framework to identify the type 2 diabetes–related gut microbiome features in the cross-sectional analyses of three Chinese cohorts: one discovery cohort (n = 1,832, 270 cases of type 2 diabetes) and two validation cohorts (cohort 1: n = 203, 48 cases; cohort 2: n = 7,009, 608 cases). We constructed a microbiome risk score (MRS) with the identified features. We examined the prospective association of the MRS with glucose increment in 249 participants without type 2 diabetes and assessed the correlation between the MRS and host blood metabolites (n = 1,016). We transferred human fecal samples with different MRS levels to germ-free mice to confirm the MRS–type 2 diabetes relationship. We then examined the prospective association of demographic, adiposity, and dietary factors with the MRS (n = 1,832). RESULTS The MRS (including 14 microbial features) consistently associated with type 2 diabetes, with risk ratio for per 1-unit change in MRS 1.28 (95% CI 1.23–1.33), 1.23 (1.13–1.34), and 1.12 (1.06–1.18) across three cohorts. The MRS was positively associated with future glucose increment (P < 0.05) and was correlated with a variety of gut microbiota–derived blood metabolites. Animal study further confirmed the MRS–type 2 diabetes relationship. Body fat distribution was found to be a key factor modulating the gut microbiome–type 2 diabetes relationship. CONCLUSIONS Our results reveal a core set of gut microbiome features associated with type 2 diabetes risk and future glucose increment.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",103,"2022-07-13 09:25:44","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
20,"Georgios Rizos, Björn Schuller","Average Jane, Where Art Thou? – Recent Avenues in Efficient Machine Learning Under Subjectivity Uncertainty",2020,"","","","",104,"2022-07-13 09:25:44","","10.1007/978-3-030-50146-4_4","","",,,,,20,10.00,10,2,2,"","",""
2,"E. Lughofer","Model Explanation and Interpretation Concepts for Stimulating Advanced Human-Machine Interaction with ""Expert-in-the-Loop""",2018,"","","","",105,"2022-07-13 09:25:44","","10.1007/978-3-319-90403-0_10","","",,,,,2,0.50,2,1,4,"","",""
19,"Johannes Burdack, Fabian Horst, Sven Giesselbach, Ibrahim Hassan, Sabrina Daffner, W. Schöllhorn","Systematic Comparison of the Influence of Different Data Preprocessing Methods on the Performance of Gait Classifications Using Machine Learning",2019,"","","","",106,"2022-07-13 09:25:44","","10.3389/fbioe.2020.00260","","",,,,,19,6.33,3,6,3,"Human movements are characterized by highly non-linear and multi-dimensional interactions within the motor system. Therefore, the future of human movement analysis requires procedures that enhance the classification of movement patterns into relevant groups and support practitioners in their decisions. In this regard, the use of data-driven techniques seems to be particularly suitable to generate classification models. Recently, an increasing emphasis on machine-learning applications has led to a significant contribution, e.g., in increasing the classification performance. In order to ensure the generalizability of the machine-learning models, different data preprocessing steps are usually carried out to process the measured raw data before the classifications. In the past, various methods have been used for each of these preprocessing steps. However, there are hardly any standard procedures or rather systematic comparisons of these different methods and their impact on the classification performance. Therefore, the aim of this analysis is to compare different combinations of commonly applied data preprocessing steps and test their effects on the classification performance of gait patterns. A publicly available dataset on intra-individual changes of gait patterns was used for this analysis. Forty-two healthy participants performed 6 sessions of 15 gait trials for 1 day. For each trial, two force plates recorded the three-dimensional ground reaction forces (GRFs). The data was preprocessed with the following steps: GRF filtering, time derivative, time normalization, data reduction, weight normalization and data scaling. Subsequently, combinations of all methods from each preprocessing step were analyzed by comparing their prediction performance in a six-session classification using Support Vector Machines, Random Forest Classifiers, Multi-Layer Perceptrons, and Convolutional Neural Networks. The results indicate that filtering GRF data and a supervised data reduction (e.g., using Principal Components Analysis) lead to increased prediction performance of the machine-learning classifiers. Interestingly, the weight normalization and the number of data points (above a certain minimum) in the time normalization does not have a substantial effect. In conclusion, the present results provide first domain-specific recommendations for commonly applied data preprocessing methods and might help to build more comparable and more robust classification models based on machine learning that are suitable for a practical application.","",""
19,"P. Mathur, S. Srivastava, Xiaowei Xu, J. Mehta","Artificial Intelligence, Machine Learning, and Cardiovascular Disease",2020,"","","","",107,"2022-07-13 09:25:44","","10.1177/1179546820927404","","",,,,,19,9.50,5,4,2,"Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.","",""
49,"Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, A. Madry","Learning Perceptually-Aligned Representations via Adversarial Robustness",2019,"","","","",108,"2022-07-13 09:25:44","","","","",,,,,49,16.33,8,6,3,"Many applications of machine learning require models that are “human-aligned,” i.e., that make decisions based on human-meaningful information about the input. We identify the pervasive brittleness of deep networks’ learned representations as a fundamental barrier to attaining this goal. We then re-cast robust optimization as a tool for enforcing human priors on the features learned by deep neural networks. The resulting robust feature representations turn out to be significantly more aligned with human perception. We leverage these representations to perform input interpolation, feature manipulation, and sensitivity mapping, without any post-processing or human intervention after model training.1","",""
14,"Megha Srivastava, Besmira Nushi, Ece Kamar, S. Shah, E. Horvitz","An Empirical Analysis of Backward Compatibility in Machine Learning Systems",2020,"","","","",109,"2022-07-13 09:25:44","","10.1145/3394486.3403379","","",,,,,14,7.00,3,5,2,"In many applications of machine learning (ML), updates are performed with the goal of enhancing model performance. However, current practices for updating models rely solely on isolated, aggregate performance analyses, overlooking important dependencies, expectations, and needs in real-world deployments. We consider how updates, intended to improve ML models, can introduce new errors that can significantly affect downstream systems and users. For example, updates in models used in cloud-based classification services, such as image recognition, can cause unexpected erroneous behavior in systems that make calls to the services. Prior work has shown the importance of ""backward compatibility"" for maintaining human trust. We study challenges with backward compatibility across different ML architectures and datasets, focusing on common settings including data shifts with structured noise and ML employed in inferential pipelines. Our results show that (i) compatibility issues arise even without data shift due to optimization stochasticity, (ii) training on large-scale noisy datasets often results in significant decreases in backward compatibility even when model accuracy increases, and (iii) distributions of incompatible points align with noise bias, motivating the need for compatibility aware de-noising and robustness methods.","",""
43,"A. Abrol, Z. Fu, Mustafa S. Salman, Rogers F. Silva, Y. Du, S. Plis, V. Calhoun","Deep learning encodes robust discriminative neuroimaging representations to outperform standard machine learning",2021,"","","","",110,"2022-07-13 09:25:44","","10.1038/s41467-020-20655-6","","",,,,,43,43.00,6,7,1,"","",""
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",111,"2022-07-13 09:25:44","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
7,"Jarrett Blair, M. D. Weiser, M. Kaspari, Matthew Miller, C. Siler, K. Marshall","Robust and simplified machine learning identification of pitfall trap‐collected ground beetles at the continental scale",2020,"","","","",112,"2022-07-13 09:25:44","","10.1002/ece3.6905","","",,,,,7,3.50,1,6,2,"Abstract Insect populations are changing rapidly, and monitoring these changes is essential for understanding the causes and consequences of such shifts. However, large‐scale insect identification projects are time‐consuming and expensive when done solely by human identifiers. Machine learning offers a possible solution to help collect insect data quickly and efficiently. Here, we outline a methodology for training classification models to identify pitfall trap‐collected insects from image data and then apply the method to identify ground beetles (Carabidae). All beetles were collected by the National Ecological Observatory Network (NEON), a continental scale ecological monitoring project with sites across the United States. We describe the procedures for image collection, image data extraction, data preparation, and model training, and compare the performance of five machine learning algorithms and two classification methods (hierarchical vs. single‐level) identifying ground beetles from the species to subfamily level. All models were trained using pre‐extracted feature vectors, not raw image data. Our methodology allows for data to be extracted from multiple individuals within the same image thus enhancing time efficiency, utilizes relatively simple models that allow for direct assessment of model performance, and can be performed on relatively small datasets. The best performing algorithm, linear discriminant analysis (LDA), reached an accuracy of 84.6% at the species level when naively identifying species, which was further increased to >95% when classifications were limited by known local species pools. Model performance was negatively correlated with taxonomic specificity, with the LDA model reaching an accuracy of ~99% at the subfamily level. When classifying carabid species not included in the training dataset at higher taxonomic levels species, the models performed significantly better than if classifications were made randomly. We also observed greater performance when classifications were made using the hierarchical classification method compared to the single‐level classification method at higher taxonomic levels. The general methodology outlined here serves as a proof‐of‐concept for classifying pitfall trap‐collected organisms using machine learning algorithms, and the image data extraction methodology may be used for nonmachine learning uses. We propose that integration of machine learning in large‐scale identification pipelines will increase efficiency and lead to a greater flow of insect macroecological data, with the potential to be expanded for use with other noninsect taxa.","",""
2,"A. Smart, Larry James, B. Hutchinson, Simone Wu, Shannon Vallor","Why Reliabilism Is not Enough: Epistemic and Moral Justification in Machine Learning",2020,"","","","",113,"2022-07-13 09:25:44","","10.1145/3375627.3375866","","",,,,,2,1.00,0,5,2,"In this paper we argue that standard calls for explainability that focus on the epistemic inscrutability of black-box machine learning models may be misplaced. If we presume, for the sake of this paper, that machine learning can be a source of knowledge, then it makes sense to wonder what kind of \em justification it involves. How do we rationalize on the one hand the seeming justificatory black box with the observed wide adoption of machine learning? We argue that, in general, people implicitly adoptreliabilism regarding machine learning. Reliabilism is an epistemological theory of epistemic justification according to which a belief is warranted if it has been produced by a reliable process or method \citegoldman2012reliabilism. We argue that, in cases where model deployments require \em moral justification, reliabilism is not sufficient, and instead justifying deployment requires establishing robust human processes as a moral ""wrapper'' around machine outputs. We then suggest that, in certain high-stakes domains with moral consequences, reliabilism does not provide another kind of necessary justification---moral justification. Finally, we offer cautions relevant to the (implicit or explicit) adoption of the reliabilist interpretation of machine learning.","",""
2,"Md Nafis Ul Alam, U. F. Chowdhury","Short k-mer abundance profiles yield robust machine learning features and accurate classifiers for RNA viruses",2020,"","","","",114,"2022-07-13 09:25:44","","10.1371/journal.pone.0239381","","",,,,,2,1.00,1,2,2,"High throughout sequencing technologies have greatly enabled the study of genomics, transcriptomics and metagenomics. Automated annotation and classification of the vast amounts of generated sequence data has become paramount for facilitating biological sciences. Genomes of viruses can be radically different from all life, both in terms of molecular structure and primary sequence. Alignment-based and profile-based searches are commonly employed for characterization of assembled viral contigs from high-throughput sequencing data. Recent attempts have highlighted the use of machine learning models for the task but these models rely entirely on DNA genomes and owing to the intrinsic genomic complexity of viruses, RNA viruses have gone completely overlooked. Here, we present a novel short k-mer based sequence scoring method that generates robust sequence information for training machine learning classifiers. We trained 18 classifiers for the task of distinguishing viral RNA from human transcripts. We challenged our models with very stringent testing protocols across different species and evaluated performance against BLASTn, BLASTx and HMMER3 searches. For clean sequence data retrieved from curated databases, our models display near perfect accuracy, outperforming all similar attempts previously reported. On de-novo assemblies of raw RNA-Seq data from cells subjected to Ebola virus, the area under the ROC curve varied from 0.6 to 0.86 depending on the software used for assembly. Our classifier was able to properly classify the majority of the false hits generated by BLAST and HMMER3 searches on the same data. The outstanding performance metrics of our model lays the groundwork for robust machine learning methods for the automated annotation of sequence data. Author Summary In this age of high-throughput sequencing, proper classification of copious amounts of sequence data remains to be a daunting challenge. Presently, sequence alignment methods are immediately assigned to the task. Owing to the selection forces of nature, there is considerable homology even between the sequences of different species which draws ambiguity to the results of alignment-based searches. Machine Learning methods are becoming more reliable for characterizing sequence data, but virus genomes are more variable than all forms of life and viruses with RNA-based genomes have gone overlooked in previous machine learning attempts. We designed a novel short k-mer based scoring criteria whereby a large number of highly robust numerical feature sets can be derived from sequence data. These features were able to accurately distinguish virus RNA from human transcripts with performance scores better than all previous reports. Our models were able to generalize well to distant species of viruses and mouse transcripts. The model correctly classifies the majority of false hits generated by current standard alignment tools. These findings strongly imply that this k-mer score based computational pipeline forges a highly informative, rich set of numerical machine learning features and similar pipelines can greatly advance the field of computational biology.","",""
5,"Been Kim","An Introduction on Interpretable Machine Learning",2020,"","","","",115,"2022-07-13 09:25:44","","10.35940/ijitee.g1023.0597s20","","",,,,,5,2.50,5,1,2,"As Artificial Intelligence penetrates all aspects of human life, more and more questions about ethical practices and fair uses arise, which has motivated the research community to look inside and develop methods to interpret these Artificial Intelligence/Machine Learning models. This concept of interpretability can not only help with the ethical questions but also can provide various insights into the working of these machine learning models, which will become crucial in trust-building and understanding how a model makes decisions. Furthermore, in many machine learning applications, the feature of interpretability is the primary value that they offer. However, in practice, many developers select models based on the accuracy score and disregarding the level of interpretability of that model, which can be chaotic as predictions by many high accuracy models are not easily explainable. In this paper, we introduce the concept of Machine Learning Model Interpretability, Interpretable Machine learning, and the methods used for interpretation and explanations.","",""
29,"Kanchan Dabre, S. Dholay","Machine learning model for sign language interpretation using webcam images",2014,"","","","",116,"2022-07-13 09:25:44","","10.1109/CSCITA.2014.6839279","","",,,,,29,3.63,15,2,8,"Human beings interact with each other either using a natural language channel such as words, writing, or by body language (gestures) e.g. hand gestures, head gestures, facial expression, lip motion and so on. As understanding natural language is important, understanding sign language is also very important. The sign language is the basic communication method within hearing disable people. People with hearing disabilities face problems in communicating with other hearing people without a translator. For this reason, the implementation of a system that recognize the sign language would have a significant benefit impact on deaf people social live. In this paper, we have proposed a marker-free, visual Indian Sign Language recognition system using image processing, computer vision and neural network methodologies, to identify the characteristics of the hand in images taken from a video trough web camera. This approach will convert video of daily frequently used full sentences gesture into a text and then convert it into audio. Identification of hand shape from continuous frames will be done by using series of image processing operations. Interpretation of signs and corresponding meaning will be identified by using Haar Cascade Classifier. Finally displayed text will be converted into speech using speech synthesizer.","",""
48,"Shuting Han, Ekaterina H. Taralova, C. Dupre, R. Yuste","Comprehensive machine learning analysis of Hydra behavior reveals a stable basal behavioral repertoire",2018,"","","","",117,"2022-07-13 09:25:44","","10.7554/eLife.32605","","",,,,,48,12.00,12,4,4,"Animal behavior has been studied for centuries, but few efficient methods are available to automatically identify and classify it. Quantitative behavioral studies have been hindered by the subjective and imprecise nature of human observation, and the slow speed of annotating behavioral data. Here, we developed an automatic behavior analysis pipeline for the cnidarian Hydra vulgaris using machine learning. We imaged freely behaving Hydra, extracted motion and shape features from the videos, and constructed a dictionary of visual features to classify pre-defined behaviors. We also identified unannotated behaviors with unsupervised methods. Using this analysis pipeline, we quantified 6 basic behaviors and found surprisingly similar behavior statistics across animals within the same species, regardless of experimental conditions. Our analysis indicates that the fundamental behavioral repertoire of Hydra is stable. This robustness could reflect a homeostatic neural control of ""housekeeping"" behaviors which could have been already present in the earliest nervous systems.","",""
297,"Andrius Vabalas, E. Gowen, E. Poliakoff, A. Casson","Machine learning algorithm validation with a limited sample size",2019,"","","","",118,"2022-07-13 09:25:44","","10.1371/journal.pone.0224365","","",,,,,297,99.00,74,4,3,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.","",""
1,"Jo-Hsuan Wu, T. Liu, W. Hsu, J. Ho, Chien-Chang Lee","Performance and limitation of machine learning algorithms for diabetic retinopathy screening: A meta-analysis (Preprint)",2020,"","","","",119,"2022-07-13 09:25:44","","10.2196/preprints.23863","","",,,,,1,0.50,0,5,2,"  BACKGROUND  Standardly diagnosed by human experts, the high prevalence of diabetic retinopathy (DR) warrants a more efficient screening method. Although machine learning (ML)-based automated DR diagnosis has gained attention due to recent approval of IDx-DR, performance of this tool has not be examined systematically, and the best ML technique for utilization in real-world setting has not been discussed.       OBJECTIVE  To examine systematically the overall diagnostic accuracy of ML in diagnosing DR of different categories based on color fundus photographs and to determine the state-of-the-art ML approach.      METHODS  Published studies in PubMed and EMBASE were searched from inception to June, 2020. Studies were screened for relevant outcomes, publication types, and data sufficiency, and a total of 60 (2.8%) out of 2128 studies were retrieved after study selection. Extraction of data was performed by 2 authors according to PRISMA, and the quality assessment was performed according to QUADUS-2. Meta-analysis of diagnostic accuracy was pooled using a bivariate random-effects model. The main outcomes included diagnostic accuracy, sensitivity, and specificity of ML in diagnosing DR based on color fundus photographs, as well as the performances of different major types of ML algorithms.      RESULTS  The primary meta-analysis included 60 color fundus photograph studies (445,175 interpretations). Overall, ML demonstrated high accuracy in diagnosing DR of various categories, with a pooled AUROC from 0.97 (95% CI: 0.96, 0.99) to 0.99 (95%CI: 0.98, 1.00). The performance of ML in detecting more-than-mild DR (mtmDR) was robust (Sen: 0.95, AUROC: 0.97), and by subgroup analyses, we observed that robust performance of ML was not limited to benchmark datasets (Sen: 0.92; AUROC: 0.96) but could be generalized to images collected in clinical practice (Sen: 0.97; AUROC: 097). Neural network was the most widely utilized method, and the subgroup analysis revealed a pooled AUROC of 0.98 (95% CI: 0.96, 0.99) for studies that utilized neural networks to diagnose mtmDR.      CONCLUSIONS  This meta-analysis demonstrated high diagnostic accuracy of ML algorithms in detecting diabetic retinopathy on color fundus photographs, suggesting that state-of-the-art, ML-based DR screening algorithms are likely ready for clinical applications. However, a significant portion of the earlier published studies had methodology flaws, such as the lack of external validation and presence of spectrum bias. The results of these studies should be interpreted with caution.      CLINICALTRIAL   ","",""
0,"K. Kelly","Man and the machine rise to the spike‐wave. Commentary on “An automated, machine learning‐based detection algorithm for spike‐wave discharges (SWDs) in a mouse model of absence epilepsy.”",2020,"","","","",120,"2022-07-13 09:25:44","","10.1002/epi4.12428","","",,,,,0,0.00,0,1,2,"Anyone who has spent a considerable amount of time in visual analysis and manual scoring of EEG events of either human or animal long-term EEG recordings fully understands that the process is not entirely a labor of love. Manual review of large volumes of EEG data, whether for detection of ictal discharges, epileptiform activity, or abnormal slowing, is notoriously time-consuming, fatigue-inducing, and frequently inexact. Numerous analytical software programs have been developed over the last several decades to aid visual review of continuous EEG recordings and have contributed significantly to the precision and accuracy of event detection. However, event detection by even the best algorithms remains an imperfect science. The ongoing need to build better analytical “mousetraps” for EEG event capture continues to be a daunting challenge for epileptologists, computer scientists, and basic researchers. Such a challenge was embraced wholeheartedly by Pfammatter and colleagues.1 They built an automated, machine learning-based detection algorithm for spike-wave discharges (SWDs) in the γ2R43Q mouse model, a GABAA receptor knock-in mutation that generates ~6 Hz SWDs (absence epilepsy) in the animal. As many are aware, SWDs in rodent models of acquired epilepsy continue to be an active topic of discussion and interpretation.2 The fundamental uncertainty of this ongoing issue is what is or is not an actual SWD associated with “absence” discharges. The authors of this study recognized the critical importance of rigor in defining SWDs in their model and the associated need to develop robust, automated methods for their detection. They contended that the true definition of SWDs should arise from comparison of rigorously definable events, such as a set of predictor variables, with other known EEG features, such as the sleep-wake cycle, or treatments that alter SWDs, for example, ethosuximide. Their deliberative efforts resulted in a highly integrated system of confidence-based scoring of events along a continuum, in addition to a binary classification (SWD/non-SWD), that reflected physiologically relevant EEG features of normal behavioral states and matched scoring characteristics of human reviewers. Their efforts began with two of the authors manually scoring 24-hour unannotated EEG records outside of the EEG training sets for the presence of SWDs—4 from γ2R43Q mice (RQ) and 1 without the mutation but with the same genetic background (RR)—in order to facilitate the development and performance validation of a 2-stage algorithm. For Stage 1, they constructed a support vector machine (SVM)based algorithm, a learning tool used to analyze data and separate groups of events for classification purposes, after being trained with a set of prescribed labels. Importantly, as the authors describe, the boundaries of the classification space are defined by events assigned as support vectors; the location of each event relative to the nearest support vectors can be used for its classification, and the distance from each event to its nearest support vector can be used as a proxy for confidence in its assigned classification. The algorithm first identified 2500 putative SWDs based on frequencyand","",""
16,"Mitchell J. Feldmann, M. Hardigan, R. Famula, Cindy M. López, A. Tabb, Glenn S. Cole, S. Knapp","Multi-dimensional machine learning approaches for fruit shape phenotyping in strawberry",2020,"","","","",121,"2022-07-13 09:25:44","","10.1093/gigascience/giaa030","","",,,,,16,8.00,2,7,2,"Abstract Background Shape is a critical element of the visual appeal of strawberry fruit and is influenced by both genetic and non-genetic determinants. Current fruit phenotyping approaches for external characteristics in strawberry often rely on the human eye to make categorical assessments. However, fruit shape is an inherently multi-dimensional, continuously variable trait and not adequately described by a single categorical or quantitative feature. Morphometric approaches enable the study of complex, multi-dimensional forms but are often abstract and difficult to interpret. In this study, we developed a mathematical approach for transforming fruit shape classifications from digital images onto an ordinal scale called the Principal Progression of k Clusters (PPKC). We use these human-recognizable shape categories to select quantitative features extracted from multiple morphometric analyses that are best fit for genetic dissection and analysis. Results We transformed images of strawberry fruit into human-recognizable categories using unsupervised machine learning, discovered 4 principal shape categories, and inferred progression using PPKC. We extracted 68 quantitative features from digital images of strawberries using a suite of morphometric analyses and multivariate statistical approaches. These analyses defined informative feature sets that effectively captured quantitative differences between shape classes. Classification accuracy ranged from 68% to 99% for the newly created phenotypic variables for describing a shape. Conclusions Our results demonstrated that strawberry fruit shapes could be robustly quantified, accurately classified, and empirically ordered using image analyses, machine learning, and PPKC. We generated a dictionary of quantitative traits for studying and predicting shape classes and identifying genetic factors underlying phenotypic variability for fruit shape in strawberry. The methods and approaches that we applied in strawberry should apply to other fruits, vegetables, and specialty crops.","",""
42,"T. Luechtefeld, C. Rowlands, T. Hartung","Big-data and machine learning to revamp computational toxicology and its use in risk assessment.",2018,"","","","",122,"2022-07-13 09:25:44","","10.1039/c8tx00051d","","",,,,,42,10.50,14,3,4,"The creation of large toxicological databases and advances in machine-learning techniques have empowered computational approaches in toxicology. Work with these large databases based on regulatory data has allowed reproducibility assessment of animal models, which highlight weaknesses in traditional in vivo methods. This should lower the bars for the introduction of new approaches and represents a benchmark that is achievable for any alternative method validated against these methods. Quantitative Structure Activity Relationships (QSAR) models for skin sensitization, eye irritation, and other human health hazards based on these big databases, however, also have made apparent some of the challenges facing computational modeling, including validation challenges, model interpretation issues, and model selection issues. A first implementation of machine learning-based predictions termed REACHacross achieved unprecedented sensitivities of >80% with specificities >70% in predicting the six most common acute and topical hazards covering about two thirds of the chemical universe. While this is awaiting formal validation, it demonstrates the new quality introduced by big data and modern data-mining technologies. The rapid increase in the diversity and number of computational models, as well as the data they are based on, create challenges and opportunities for the use of computational methods.","",""
40,"Yue Zhao, M. K. Hryniewicki, Francesca Cheng, Boyang Fu, Xiaoyu Zhu","Employee Turnover Prediction with Machine Learning: A Reliable Approach",2018,"","","","",123,"2022-07-13 09:25:44","","10.1007/978-3-030-01057-7_56","","",,,,,40,10.00,8,5,4,"","",""
36,"M. Domínguez‐Rodrigo, E. Baquedano","Distinguishing butchery cut marks from crocodile bite marks through machine learning methods",2018,"","","","",124,"2022-07-13 09:25:44","","10.1038/s41598-018-24071-1","","",,,,,36,9.00,18,2,4,"","",""
24,"P. Poudel, A. Illanes, Debdoot Sheet, M. Friebe","Evaluation of Commonly Used Algorithms for Thyroid Ultrasound Images Segmentation and Improvement Using Machine Learning Approaches",2018,"","","","",125,"2022-07-13 09:25:44","","10.1155/2018/8087624","","",,,,,24,6.00,6,4,4,"The thyroid is one of the largest endocrine glands in the human body, which is involved in several body mechanisms like controlling protein synthesis and the body's sensitivity to other hormones and use of energy sources. Hence, it is of prime importance to track the shape and size of thyroid over time in order to evaluate its state. Thyroid segmentation and volume computation are important tools that can be used for thyroid state tracking assessment. Most of the proposed approaches are not automatic and require long time to correctly segment the thyroid. In this work, we compare three different nonautomatic segmentation algorithms (i.e., active contours without edges, graph cut, and pixel-based classifier) in freehand three-dimensional ultrasound imaging in terms of accuracy, robustness, ease of use, level of human interaction required, and computation time. We figured out that these methods lack automation and machine intelligence and are not highly accurate. Hence, we implemented two machine learning approaches (i.e., random forest and convolutional neural network) to improve the accuracy of segmentation as well as provide automation. This comparative study intends to discuss and analyse the advantages and disadvantages of different algorithms. In the last step, the volume of the thyroid is computed using the segmentation results, and the performance analysis of all the algorithms is carried out by comparing the segmentation results with the ground truth.","",""
83,"D. Wilkins, Andrea Grisafi, Yang Yang, K. Lao, Robert A. DiStasio, M. Ceriotti","Accurate molecular polarizabilities with coupled cluster theory and machine learning",2018,"","","","",126,"2022-07-13 09:25:44","","10.1073/pnas.1816132116","","",,,,,83,20.75,14,6,4,"Significance The dipole polarizability of molecules and materials is central to several physical phenomena, modeling techniques, and the interpretation of many experiments. Its accurate evaluation from first principles requires quantum chemistry methods that are often too demanding for routine use. The highly accurate calculations reported herein provide a much-needed benchmark of the accuracy of hybrid density functional theory (DFT) as well as training data for a machine-learning model that can predict the polarizability tensor with an error that is about 50% smaller than DFT. This framework provides an accurate, inexpensive, and transferable strategy for estimating the polarizabilities of molecules containing dozens of atoms, and therefore removes a considerable obstacle to accurate and reliable atomistic-based modeling of matter. The molecular dipole polarizability describes the tendency of a molecule to change its dipole moment in response to an applied electric field. This quantity governs key intra- and intermolecular interactions, such as induction and dispersion; plays a vital role in determining the spectroscopic signatures of molecules; and is an essential ingredient in polarizable force fields. Compared with other ground-state properties, an accurate prediction of the molecular polarizability is considerably more difficult, as this response quantity is quite sensitive to the underlying electronic structure description. In this work, we present highly accurate quantum mechanical calculations of the static dipole polarizability tensors of 7,211 small organic molecules computed using linear response coupled cluster singles and doubles theory (LR-CCSD). Using a symmetry-adapted machine-learning approach, we demonstrate that it is possible to predict the LR-CCSD molecular polarizabilities of these small molecules with an error that is an order of magnitude smaller than that of hybrid density functional theory (DFT) at a negligible computational cost. The resultant model is robust and transferable, yielding molecular polarizabilities for a diverse set of 52 larger molecules (including challenging conjugated systems, carbohydrates, small drugs, amino acids, nucleobases, and hydrocarbon isomers) at an accuracy that exceeds that of hybrid DFT. The atom-centered decomposition implicit in our machine-learning approach offers some insight into the shortcomings of DFT in the prediction of this fundamental quantity of interest.","",""
7,"May Me Me Hlaing, Nang Saing Moon Kham","Defining News Authenticity on Social Media Using Machine Learning Approach",2020,"","","","",127,"2022-07-13 09:25:44","","10.1109/ICCA49400.2020.9022837","","",,,,,7,3.50,4,2,2,"Social network and online news media are becoming popular in today’s era. Due to low cost, easy access and rapid diffusion, social media platform becomes a source to distribute false information. Fake news propagation on social media can cause serious negative effects on human society especially in politic, reputation and finance. So, automatic fake news detection plays a vital role to robust news media platform on social network. Defining news authenticity is insufficient based on news content only. It also needs to analyze social features of news. In this paper, we propose an approach to detect fake news on social media that covers both news content and social context. We use synonym-based feature extraction method and three different classifiers based on multidimensional dataset. Experimental result shows the effective as an accuracy way to define news authenticity on online news media.","",""
39,"C. Rosé, Elizabeth A. McLaughlin, Ran Liu, K. Koedinger","Explanatory learner models: Why machine learning (alone) is not the answer",2019,"","","","",128,"2022-07-13 09:25:44","","10.1111/BJET.12858","","",,,,,39,13.00,10,4,3,"Using data to understand learning and improve education has great promise. However, the promise will not be achieved simply by AI and Machine Learning researchers developing innovative models that more accurately predict labeled data. As AI advances, modeling techniques and the models they produce are getting increasingly complex, often involving tens of thousands of parameters or more. Though strides towards interpretation of complex models are being made in core machine learning communities, it remains true in these cases of ""black box"" modeling that research teams may have little possibility to peer inside to try understand how, why, or even whether such models will work when applied beyond the data on which they were built. Rather than relying on AI expertise alone, we suggest that learning engineering teams bring interdisciplinary expertise to bear to develop explanatory learner models that provide interpretable and actionable insights in addition to accurate prediction. We describe examples that illustrate use of different kinds of data (eg, click stream and discourse data) in different course content (eg, math and writing) and toward different goals (eg, improving student models and generating actionable feedback). We recommend learning engineering teams, shared infrastructure and funder incentives toward better explanatory learner model development that advances learning science, produces better pedagogical practices and demonstrably improves student learning. Practitioner NotesWhat is already known about this topic Researchers in learning analytics and educational data mining have been successful in creating innovative models of data that optimize prediction.Some of these models produce scientific or practical insights and fewer have been put into use and demonstrated to enhance student learning.What this paper adds We provide examples of development of explanatory models of learners that not only accurately predict data but also provide scientific insights and yield practical outcomes.In particular, researchers with expertise in cognitive science and math education content use AI‐based data analytics to discover previously unrecognized barriers to geometry student learning. They use model‐derived insights to redesign an online tutoring system and ""close‐the‐loop"" by experimentally demonstrating that the new system produces better student learning than the original.Implications for practice and/or policy We define explanatory learning models and provide an articulation of a process for generating them that involves interdisciplinary teams employing human–computer interaction and learning engineering methods.Based on our experiences, we recommend learning engineering teams, shared infrastructure and funder incentives toward better explanatory learner model development that advances learning science, produces better pedagogical practices and demonstrably improves student learning. [ABSTRACT FROM AUTHOR]","",""
166,"M. Alber, A. Buganza Tepole, W. R. Cannon, S. De, S. Dura-Bernal, K. Garikipati, G. Karniadakis, W. Lytton, P. Perdikaris, L. Petzold, E. Kuhl","Integrating machine learning and multiscale modeling—perspectives, challenges, and opportunities in the biological, biomedical, and behavioral sciences",2019,"","","","",129,"2022-07-13 09:25:44","","10.1038/s41746-019-0193-y","","",,,,,166,55.33,17,11,3,"","",""
57,"A. Chelli, M. Pätzold","A Machine Learning Approach for Fall Detection and Daily Living Activity Recognition",2019,"","","","",130,"2022-07-13 09:25:44","","10.1109/ACCESS.2019.2906693","","",,,,,57,19.00,29,2,3,"The number of older people in western countries is constantly increasing. Most of them prefer to live independently and are susceptible to fall incidents. Falls often lead to serious or even fatal injuries which are the leading cause of death for elderlies. To address this problem, it is essential to develop robust fall detection systems. In this context, we develop a machine learning framework for fall detection and daily living activity recognition. We use acceleration and angular velocity data from two public databases to recognize seven different activities, including falls and activities of daily living. From the acceleration and angular velocity data, we extract time- and frequency-domain features and provide them to a classification algorithm. In this paper, we test the performance of four algorithms for classifying human activities. These algorithms are the artificial neural network (ANN),  $K$ -nearest neighbors (KNN), quadratic support vector machine (QSVM), and ensemble bagged tree (EBT). New features that improve the performance of the classifier are extracted from the power spectral density of the acceleration. In the first step, only the acceleration data are used for activity recognition. Our results reveal that the KNN, ANN, QSVM, and EBT algorithms could achieve overall accuracy of 81.2%, 87.8%, 93.2%, and 94.1%, respectively. The accuracy of fall detection reaches 97.2% and 99.1% without any false alarms for the QSVM and EBT algorithms, respectively. In a second step, we extract features from the autocorrelation function and the power spectral density of both the acceleration and the angular velocity data, which improves the classification accuracy. By using the proposed features, we could achieve overall accuracy of 85.8%, 91.8%, 96.1%, and 97.7% for the KNN, ANN, QSVM, and EBT algorithms, respectively. The accuracy of fall detection reaches 100% for both the QSVM and EBT algorithms without any false alarm, which is the best achievable performance.","",""
56,"M. Krishnan","Against Interpretability: a Critical Examination of the Interpretability Problem in Machine Learning",2019,"","","","",131,"2022-07-13 09:25:44","","10.1007/S13347-019-00372-9","","",,,,,56,18.67,56,1,3,"","",""
63,"Yanju Zhang, Ruopeng Xie, Jiawei Wang, A. Leier, T. Marquez-Lago, T. Akutsu, Geoffrey I. Webb, K. Chou, Jiangning Song","Computational analysis and prediction of lysine malonylation sites by exploiting informative features in an integrative machine-learning framework",2018,"","","","",132,"2022-07-13 09:25:44","","10.1093/bib/bby079","","",,,,,63,15.75,7,9,4,"As a newly discovered post-translational modification (PTM), lysine malonylation (Kmal) regulates a myriad of cellular processes from prokaryotes to eukaryotes and has important implications in human diseases. Despite its functional significance, computational methods to accurately identify malonylation sites are still lacking and urgently needed. In particular, there is currently no comprehensive analysis and assessment of different features and machine learning (ML) methods that are required for constructing the necessary prediction models. Here, we review, analyze and compare 11 different feature encoding methods, with the goal of extracting key patterns and characteristics from residue sequences of Kmal sites. We identify optimized feature sets, with which four commonly used ML methods (random forest, support vector machines, K-nearest neighbor and logistic regression) and one recently proposed [Light Gradient Boosting Machine (LightGBM)] are trained on data from three species, namely, Escherichia coli, Mus musculus and Homo sapiens, and compared using randomized 10-fold cross-validation tests. We show that integration of the single method-based models through ensemble learning further improves the prediction performance and model robustness on the independent test. When compared to the existing state-of-the-art predictor, MaloPred, the optimal ensemble models were more accurate for all three species (AUC: 0.930, 0.923 and 0.944 for E. coli, M. musculus and H. sapiens, respectively). Using the ensemble models, we developed an accessible online predictor, kmal-sp, available at http://kmalsp.erc.monash.edu/. We hope that this comprehensive survey and the proposed strategy for building more accurate models can serve as a useful guide for inspiring future developments of computational methods for PTM site prediction, expedite the discovery of new malonylation and other PTM types and facilitate hypothesis-driven experimental validation of novel malonylated substrates and malonylation sites.","",""
66,"R. Cuocolo, Maria Brunella Cipullo, A. Stanzione, L. Ugga, V. Romeo, L. Radice, A. Brunetti, M. Imbriaco","Machine learning applications in prostate cancer magnetic resonance imaging",2019,"","","","",133,"2022-07-13 09:25:44","","10.1186/s41747-019-0109-2","","",,,,,66,22.00,8,8,3,"","",""
62,"Philipp Schmidt, F. Biessmann","Quantifying Interpretability and Trust in Machine Learning Systems",2019,"","","","",134,"2022-07-13 09:25:44","","","","",,,,,62,20.67,31,2,3,"Decisions by Machine Learning (ML) models have become ubiquitous. Trusting these decisions requires understanding how algorithms take them. Hence interpretability methods for ML are an active focus of research. A central problem in this context is that both the quality of interpretability methods as well as trust in ML predictions are difficult to measure. Yet evaluations, comparisons and improvements of trust and interpretability require quantifiable measures. Here we propose a quantitative measure for the quality of interpretability methods. Based on that we derive a quantitative measure of trust in ML decisions. Building on previous work we propose to measure intuitive understanding of algorithmic decisions using the information transfer rate at which humans replicate ML model predictions. We provide empirical evidence from crowdsourcing experiments that the proposed metric robustly differentiates interpretability methods. The proposed metric also demonstrates the value of interpretability for ML assisted human decision making: in our experiments providing explanations more than doubled productivity in annotation tasks. However unbiased human judgement is critical for doctors, judges, policy makers and others. Here we derive a trust metric that identifies when human decisions are overly biased towards ML predictions. Our results complement existing qualitative work on trust and interpretability by quantifiable measures that can serve as objectives for further improving methods in this field of research.","",""
41,"Zijian Zhang, Jaspreet Singh, U. Gadiraju, Avishek Anand","Dissonance Between Human and Machine Understanding",2019,"","","","",135,"2022-07-13 09:25:44","","10.1145/3359158","","",,,,,41,13.67,10,4,3,"Complex machine learning models are deployed in several critical domains including healthcare and autonomous vehicles nowadays, albeit as functional blackboxes. Consequently, there has been a recent surge in interpreting decisions of such complex models in order to explain their actions to humans. Models which correspond to human interpretation of a task are more desirable in certain contexts and can help attribute liability, build trust, expose biases and in turn build better models. It is therefore crucial to understand how and which models conform to human understanding of tasks. In this paper we present a large-scale crowdsourcing study that reveals and quantifies the dissonance between human and machine understanding, through the lens of an image classification task. In particular, we seek to answer the following questions: Which (well performing) complex ML models are closer to humans in their use of features to make accurate predictions? How does task difficulty affect the feature selection capability of machines in comparison to humans? Are humans consistently better at selecting features that make image recognition more accurate? Our findings have important implications on human-machine collaboration, considering that a long term goal in the field of artificial intelligence is to make machines capable of learning and reasoning like humans.","",""
27,"Johannes H. Uhl, S. Leyk, Yao-Yi Chiang, Weiwei Duan, Craig A. Knoblock","Extracting Human Settlement Footprint from Historical Topographic Map Series Using Context-Based Machine Learning",2017,"","","","",136,"2022-07-13 09:25:44","","10.1049/CP.2017.0144","","",,,,,27,5.40,5,5,5,"Information extraction from historical maps represents a persistent challenge due to inferior graphical quality and large data volume in digital map archives, which can hold thousands of digitized map sheets. In this paper, we describe an approach to extract human settlement symbols in United States Geological Survey (USGS) historical topographic maps using contemporary building data as the contextual spatial layer. The presence of a building in the contemporary layer indicates a high probability that the same building can be found at that location on the historical map. We describe the design of an automatic sampling approach using these contemporary data to collect thousands of graphical examples for the symbol of interest. These graphical examples are then used for robust learning to then carry out feature extraction in the entire map. We employ a Convolutional Neural Network (LeNet) for the recognition task. Results are promising and will guide the next steps in this research to provide an unsupervised approach to extracting features from historical maps.","",""
37,"M. Abdar, V. N. Wijayaningrum, Sadiq Hussain, R. Alizadehsani, Pawel Plawiak, U. Acharya, V. Makarenkov","IAPSO-AIRS: A novel improved machine learning-based system for wart disease treatment",2019,"","","","",137,"2022-07-13 09:25:44","","10.1007/s10916-019-1343-0","","",,,,,37,12.33,5,7,3,"","",""
37,"Alex Bratt, Jiwon Kim, Meridith P. Pollie, Ashley N Beecy, Nathan H. Tehrani, N. Codella, R. Perez-Johnston, M. Palumbo, Javid Alakbarli, Wayne Colizza, Ian R. Drexler, C. Azevedo, R. Kim, R. Devereux, J. Weinsaft","Machine learning derived segmentation of phase velocity encoded cardiovascular magnetic resonance for fully automated aortic flow quantification",2019,"","","","",138,"2022-07-13 09:25:44","","10.1186/s12968-018-0509-0","","",,,,,37,12.33,4,15,3,"","",""
127,"Sohrab Saeb, L. Lonini, A. Jayaraman, D. Mohr, Konrad Paul Kording","The need to approximate the use-case in clinical machine learning",2017,"","","","",139,"2022-07-13 09:25:44","","10.1093/gigascience/gix019","","",,,,,127,25.40,25,5,5,"Abstract The availability of smartphone and wearable sensor technology is leading to a rapid accumulation of human subject data, and machine learning is emerging as a technique to map those data into clinical predictions. As machine learning algorithms are increasingly used to support clinical decision making, it is vital to reliably quantify their prediction accuracy. Cross-validation (CV) is the standard approach where the accuracy of such algorithms is evaluated on part of the data the algorithm has not seen during training. However, for this procedure to be meaningful, the relationship between the training and the validation set should mimic the relationship between the training set and the dataset expected for the clinical use. Here we compared two popular CV methods: record-wise and subject-wise. While the subject-wise method mirrors the clinically relevant use-case scenario of diagnosis in newly recruited subjects, the record-wise strategy has no such interpretation. Using both a publicly available dataset and a simulation, we found that record-wise CV often massively overestimates the prediction accuracy of the algorithms. We also conducted a systematic review of the relevant literature, and found that this overly optimistic method was used by almost half of the retrieved studies that used accelerometers, wearable sensors, or smartphones to predict clinical outcomes. As we move towards an era of machine learning-based diagnosis and treatment, using proper methods to evaluate their accuracy is crucial, as inaccurate results can mislead both clinicians and data scientists.","",""
31,"Matthew R. Carbone, Shinjae Yoo, M. Topsakal, D. Lu","Classification of local chemical environments from x-ray absorption spectra using supervised machine learning",2019,"","","","",140,"2022-07-13 09:25:44","","10.1103/PhysRevMaterials.3.033604","","",,,,,31,10.33,8,4,3,"X-ray absorption spectroscopy is a premier element-specific technique for materials characterization. Specifically, the x-ray absorption near-edge structure (XANES) encodes important information about the local chemical environment of an absorbing atom, including coordination number, symmetry, and oxidation state. Interpreting XANES spectra is a key step towards understanding the structural and electronic properties of materials, and as such, extracting structural and electronic descriptors from XANES spectra is akin to solving a challenging inverse problem. Existing methods rely on empirical fingerprints, which are often qualitative or semiquantitative and not transferable. In this paper, we present a machine learning-based approach, which is capable of classifying the local coordination environments of the absorbing atom from simulated K-edge XANES spectra. The machine learning classifiers can learn important spectral features in a broad energy range without human bias and once trained, can make predictions on the fly. The robustness and fidelity of the machine learning method are demonstrated by an average 86% accuracy across the wide chemical space of oxides in eight 3d transition-metal families. We found that spectral features beyond the preedge region play an important role in the local structure classification problem especially for the late 3d transition-metal elements.","",""
0,"J. O’Donovan, Ken Kahn, M. MacRae, A. S. Namanda, Rebecca Hamala, Kenneth Kabali, Anne Geniets, A. Lakati, Simon M. Mbae, N. Winters","Analysing 3429 digital supervisory interactions between Community Health Workers in Uganda and Kenya: the development, testing and validation of an open access predictive machine learning web app",2022,"","","","",141,"2022-07-13 09:25:44","","10.1186/s12960-021-00699-5","","",,,,,0,0.00,0,10,1,"","",""
17,"Fanyi Xiao, L. Pei, Lei Chu, Danping Zou, Wenxian Yu, Yifan Zhu, Tao Li","A Deep Learning Method for Complex Human Activity Recognition Using Virtual Wearable Sensors",2020,"","","","",142,"2022-07-13 09:25:44","","10.1007/978-3-030-69873-7_19","","",,,,,17,8.50,2,7,2,"","",""
20,"Pouria Asadi, M. Gindy, Marco A. Alvarez","A Machine Learning Based Approach for Automatic Rebar Detection and Quantification of Deterioration in Concrete Bridge Deck Ground Penetrating Radar B-scan Images",2019,"","","","",143,"2022-07-13 09:25:44","","10.1007/S12205-019-2012-Z","","",,,,,20,6.67,7,3,3,"","",""
103,"F. Granata, S. Papirio, G. Esposito, R. Gargano, G. D. Marinis","Machine Learning Algorithms for the Forecasting of Wastewater Quality Indicators",2017,"","","","",144,"2022-07-13 09:25:44","","10.3390/W9020105","","",,,,,103,20.60,21,5,5,"Stormwater runoff is often contaminated by human activities. Stormwater discharge into water bodies significantly contributes to environmental pollution. The choice of suitable treatment technologies is dependent on the pollutant concentrations. Wastewater quality indicators such as biochemical oxygen demand (BOD5), chemical oxygen demand (COD), total suspended solids (TSS), and total dissolved solids (TDS) give a measure of the main pollutants. The aim of this study is to provide an indirect methodology for the estimation of the main wastewater quality indicators, based on some characteristics of the drainage basin. The catchment is seen as a black box: the physical processes of accumulation, washing, and transport of pollutants are not mathematically described. Two models deriving from studies on artificial intelligence have been used in this research: Support Vector Regression (SVR) and Regression Trees (RT). Both the models showed robustness, reliability, and high generalization capability. However, with reference to coefficient of determination R2 and root‐mean square error, Support Vector Regression showed a better performance than Regression Tree in predicting TSS, TDS, and COD. As regards BOD5, the two models showed a comparable performance. Therefore, the considered machine learning algorithms may be useful for providing an estimation of the values to be considered for the sizing of the treatment units in absence of direct measures.","",""
15,"G. E. Jergensen, A. McGovern, Ryan Lagerquist, Travis M. Smith","Classifying Convective Storms Using Machine Learning",2019,"","","","",145,"2022-07-13 09:25:44","","10.1175/waf-d-19-0170.1","","",,,,,15,5.00,4,4,3,"  We demonstrate that machine learning (ML) can skillfully classify thunderstorms into three categories: supercell, part of a quasi-linear convective system, or disorganized. These classifications are based on radar data and environmental information obtained through a proximity sounding. We compare the performance of five ML algorithms: logistic regression with the elastic-net penalty, random forests, gradient-boosted forests, and support-vector machines with both a linear and nonlinear kernel. The gradient-boosted forest performs best, with an accuracy of 0.77 ± 0.02 and a Peirce score of 0.58 ± 0.04. The linear support-vector machine performs second best, with values of 0.70 ± 0.02 and 0.55 ± 0.05, respectively. We use two interpretation methods, permutation importance and sequential forward selection, to determine the most important predictors for the ML models. We also use partial-dependence plots to determine how these predictors influence the outcome. A main conclusion is that shape predictors, based on the outline of the storm, appear to be highly important across ML models. The training data, a storm-centered radar scan and modeled proximity sounding, are similar to real-time data. Thus, the models could be used operationally to aid human decision-making by reducing the cognitive load involved in manual storm-mode identification. Also, they could be run on historical data to perform climatological analyses, which could be valuable to both the research and operational communities.","",""
103,"Baibhab Chatterjee, D. Das, Shovan Maity, Shreyas Sen","RF-PUF: Enhancing IoT Security Through Authentication of Wireless Nodes Using In-Situ Machine Learning",2018,"","","","",146,"2022-07-13 09:25:44","","10.1109/JIOT.2018.2849324","","",,,,,103,25.75,26,4,4,"Traditional authentication in radio-frequency (RF) systems enable secure data communication within a network through techniques such as digital signatures and hash-based message authentication codes (HMAC), which suffer from key-recovery attacks. State-of-the-art Internet of Things networks such as Nest also use open authentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery forgery (CSRF), which shows that these techniques may not prevent an adversary from copying or modeling the secret IDs or encryption keys using invasive, side channel, learning or software attacks. Physical unclonable functions (PUFs), on the other hand, can exploit manufacturing process variations to uniquely identify silicon chips which makes a PUF-based system extremely robust and secure at low cost, as it is practically impossible to replicate the same silicon characteristics across dies. Taking inspiration from human communication, which utilizes inherent variations in the voice signatures to identify a certain speaker, we present RF-PUF: a deep neural network-based framework that allows real-time authentication of wireless nodes, using the effects of inherent process variation on RF properties of the wireless transmitters (Tx), detected through in-situ machine learning at the receiver (Rx) end. The proposed method utilizes the already-existing asymmetric RF communication framework and does not require any additional circuitry for PUF generation or feature extraction. The burden of device identification is completely shifted to the gateway Rx, similar to the operation of a human listener’s brain. Simulation results involving the process variations in a standard 65-nm technology node, and features such as local oscillator offset and  ${I}$ – ${Q}$  imbalance detected with a neural network having 50 neurons in the hidden layer indicate that the framework can distinguish up to 4800 Tx(s) with an accuracy of 99.9% [≈99% for 10000 Tx(s)] under varying channel conditions, and without the need for traditional preambles. The proposed scheme can be used as a stand-alone security feature, or as a part of traditional multifactor authentication.","",""
23,"J. Zhang, Kang Liu, Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, T. Theocharides, Alessandro Artussi, M. Shafique, S. Garg","Building Robust Machine Learning Systems: Current Progress, Research Challenges, and Opportunities",2019,"","","","",147,"2022-07-13 09:25:44","","10.1145/3316781.3323472","","",,,,,23,7.67,3,9,3,"Machine learning, in particular deep learning, is being used in almost all the aspects of life to facilitate humans, specifically in mobile and Internet of Things (IoT)-based applications. Due to its state-of-the-art performance, deep learning is also being employed in safety-critical applications, for instance, autonomous vehicles. Reliability and security are two of the key required characteristics for these applications because of the impact they can have on human's life. Towards this, in this paper, we highlight the current progress, challenges and research opportunities in the domain of robust systems for machine learning-based applications.","",""
12,"Kristoffer Hougaard Madsen, L. Krohne, Xin-Lu Cai, Yi Wang, R. Chan","Perspectives on Machine Learning for Classification of Schizotypy Using fMRI Data.",2018,"","","","",148,"2022-07-13 09:25:44","","10.1093/schbul/sby026","","",,,,,12,3.00,2,5,4,"Functional magnetic resonance imaging is capable of estimating functional activation and connectivity in the human brain, and lately there has been increased interest in the use of these functional modalities combined with machine learning for identification of psychiatric traits. While these methods bear great potential for early diagnosis and better understanding of disease processes, there are wide ranges of processing choices and pitfalls that may severely hamper interpretation and generalization performance unless carefully considered. In this perspective article, we aim to motivate the use of machine learning schizotypy research. To this end, we describe common data processing steps while commenting on best practices and procedures. First, we introduce the important role of schizotypy to motivate the importance of reliable classification, and summarize existing machine learning literature on schizotypy. Then, we describe procedures for extraction of features based on fMRI data, including statistical parametric mapping, parcellation, complex network analysis, and decomposition methods, as well as classification with a special focus on support vector classification and deep learning. We provide more detailed descriptions and software as supplementary material. Finally, we present current challenges in machine learning for classification of schizotypy and comment on future trends and perspectives.","",""
45,"Geir Thore Berge, Ole-Christoffer Granmo, T. Tveit, Morten Goodwin, Lei Jiao, B. Matheussen","Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization With Medical Applications",2018,"","","","",149,"2022-07-13 09:25:44","","10.1109/ACCESS.2019.2935416","","",,,,,45,11.25,8,6,4,"Medical applications challenge today’s text categorization techniques by demanding both high accuracy and ease-of-interpretation. Although deep learning has provided a leap forward in regard to accuracy, this leap comes at the sacrifice of interpretability. In this paper, we introduce a text categorization approach that leverages the recently introduced Tsetlin Machine to address this accuracy-interpretability challenge. Briefly, we represent the terms of a text as propositional variables. From these variables, we capture categories using simple propositional formulae, such as: IF “rash” AND “reaction” AND “penicillin” THEN Allergy. The Tsetlin Machine learns these formulae from labeled text, utilizing conjunctive clauses to represent the particular facets of each category. Therefore, also the absence of terms (negated features) can be used for categorization purposes. Our empirical comparisons with Naïve Bayes classifiers, decision trees, linear support vector machines (SVMs), random forest, long short-term memory (LSTM) neural networks, and other techniques, are quite conclusive. Using relatively simple propositional formulae, the accuracy of the Tsetlin Machine either outperforms or performs approximately on par with the best evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a clinical dataset containing authentic electronic health records (EHRs). On average, the Tsetlin Machine delivers the best recall and precision scores across the datasets. The main merit of the proposed approach is thus its capacity for producing human-interpretable rules, while at the same time achieving acceptable accuracy. We believe that our novel approach can have a significant impact on a wide range of text analysis applications, providing a promising starting point for deeper natural language understanding with the Tsetlin Machine.","",""
6,"Tanya Tiwari, Tanuj Tiwari, Sanjay Tiwari","How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?",2018,"","","","",150,"2022-07-13 09:25:44","","10.23956/IJARCSSE.V8I2.569","","",,,,,6,1.50,2,3,4,"There is a lot of confusion these days about Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL). A computer system able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. Artificial Intelligence has made it possible. Deep learning is a subset of machine learning, and machine learning is a subset of AI, which is an umbrella term for any computer program that does something smart. In other words, all machine learning is AI, but not all AI is machine learning, and so forth. Machine Learning represents a key evolution in the fields of computer science, data analysis, software engineering, and artificial intelligence. Machine learning (ML)is a vibrant field of research, with a range of exciting areas for further development across different methods and applications. These areas include algorithmic interpretability, robustness, privacy, fairness, inference of causality, human-machine interaction, and security. The goal of ML is never to make “perfect” guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful. Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones. This paper gives an overview of artificial intelligence, machine learning & deep learning techniques and compare these techniques.","",""
16,"Phil Legg, Jim E. Smith, A. Downing","Visual analytics for collaborative human-machine confidence in human-centric active learning tasks",2019,"","","","",151,"2022-07-13 09:25:44","","10.1186/s13673-019-0167-8","","",,,,,16,5.33,5,3,3,"","",""
8,"Ruichuan Zhang, N. El-Gohary","A Machine Learning Approach for Compliance Checking-Specific Semantic Role Labeling of Building Code Sentences",2018,"","","","",152,"2022-07-13 09:25:44","","10.1007/978-3-030-00220-6_67","","",,,,,8,2.00,4,2,4,"","",""
31,"Amirata Ghorbani, David Ouyang, Abubakar Abid, B. He, Jonathan H. Chen, R. Harrington, D. Liang, E. Ashley, James Y. Zou","Deep learning interpretation of echocardiograms",2020,"","","","",153,"2022-07-13 09:25:44","","10.1038/s41746-019-0216-8","","",,,,,31,15.50,3,9,2,"","",""
7,"M. Asiedu, Anish K. Simhal, Christopher T Lam, Jenna L. Mueller, Usamah N. Chaudhary, J. W. Schmitt, G. Sapiro, N. Ramanujam","Image processing and machine learning techniques to automate diagnosis of Lugol's iodine cervigrams for a low-cost point-of-care digital colposcope",2018,"","","","",154,"2022-07-13 09:25:44","","10.1117/12.2282792","","",,,,,7,1.75,1,8,4,"The world health organization recommends visual inspection with acetic acid (VIA) and/or Lugol’s Iodine (VILI) for cervical cancer screening in low-resource settings. Human interpretation of diagnostic indicators for visual inspection is qualitative, subjective, and has high inter-observer discordance, which could lead both to adverse outcomes for the patient and unnecessary follow-ups. In this work, we a simple method for automatic feature extraction and classification for Lugol’s Iodine cervigrams acquired with a low-cost, miniature, digital colposcope. Algorithms to preprocess expert physician-labelled cervigrams and to extract simple but powerful color-based features are introduced. The features are used to train a support vector machine model to classify cervigrams based on expert physician labels. The selected framework achieved a sensitivity, specificity, and accuracy of 89.2%, 66.7% and 80.6% with majority diagnosis of the expert physicians in discriminating cervical intraepithelial neoplasia (CIN +) relative to normal tissues. The proposed classifier also achieved an area under the curve of 84 when trained with majority diagnosis of the expert physicians. The results suggest that utilizing simple color-based features may enable unbiased automation of VILI cervigrams, opening the door to a full system of low-cost data acquisition complemented with automatic interpretation.","",""
11,"J. Halotel, V. Demyanov, A. Gardiner","Value of Geologically Derived Features in Machine Learning Facies Classification",2019,"","","","",155,"2022-07-13 09:25:44","","10.1007/s11004-019-09838-0","","",,,,,11,3.67,4,3,3,"","",""
78,"Peter Buhlmann","Invariance, Causality and Robustness",2018,"","","","",156,"2022-07-13 09:25:44","","10.1214/19-sts721","","",,,,,78,19.50,78,1,4,"We discuss recent work for causal inference and predictive robustness in a unifying way. The key idea relies on a notion of probabilistic invariance or stability: it opens up new insights for formulating causality as a certain risk minimization problem with a corresponding notion of robustness. The invariance itself can be estimated from general heterogeneous or perturbation data which frequently occur with nowadays data collection. The novel methodology is potentially useful in many applications, offering more robustness and better “causal-oriented” interpretation than machine learning or estimation in standard regression or classification frameworks.","",""
12,"Atik Mahabub","A robust voting approach for diabetes prediction using traditional machine learning techniques",2019,"","","","",157,"2022-07-13 09:25:44","","10.1007/s42452-019-1759-7","","",,,,,12,4.00,12,1,3,"","",""
12,"Andrew Pilny, Kelly G. McAninch, A. Slone, Kelsey P. Moore","Using Supervised Machine Learning in Automated Content Analysis: An Example Using Relational Uncertainty",2019,"","","","",158,"2022-07-13 09:25:44","","10.1080/19312458.2019.1650166","","",,,,,12,4.00,3,4,3,"ABSTRACT The goal of this research is to make progress towards using supervised machine learning for automated content analysis dealing with complex interpretations of text. For Step 1, two humans coded a sub-sample of online forum posts for relational uncertainty. For Step 2, we evaluated reliability, in which we trained three different classifiers to learn from those subjective human interpretations. Reliability was established when two different metrics of inter-coder reliability could not distinguish whether a human or a machine coded the text on a separate hold-out set. Finally, in Step 3 we assessed validity. To accomplish this, we administered a survey in which participants described their own relational uncertainty/certainty via text and completed a questionnaire. After classifying the text, the machine’s classifications of the participants’ text positively correlated with the subjects’ own self-reported relational uncertainty and relational satisfaction. We discuss our results in line with areas of computational communication science, content analysis, and interpersonal communication.","",""
21,"M. Yazdani, Bryn C. Taylor, Justine W. Debelius, Weizhong Li, R. Knight, L. Smarr","Using machine learning to identify major shifts in human gut microbiome protein family abundance in disease",2016,"","","","",159,"2022-07-13 09:25:44","","10.1109/BIGDATA.2016.7840731","","",,,,,21,3.50,4,6,6,"Inflammatory Bowel Disease (IBD) is an autoimmune condition that is observed to be associated with major alterations in the gut microbiome taxonomic composition. Here we classify major changes in microbiome protein family abundances between healthy subjects and IBD patients. We use machine learning to analyze results obtained previously from computing relative abundance of ∼10,000 KEGG orthologous protein families in the gut microbiome of a set of healthy individuals and IBD patients. We develop a machine learning pipeline, involving the Kolomogorv-Smirnov test, to identify the 100 most statistically significant entries in the KEGG database. Then we use these 100 as a training set for a Random Forest classifier to determine ∼5% the KEGGs which are best at separating disease and healthy states. Lastly, we developed a Natural Language Processing classifier of the KEGG description files to predict KEGG relative over-or under-abundance. As we expand our analysis from 10,000 KEGG protein families to one million proteins identified in the gut microbiome, scalable methods for quickly identifying such anomalies between health and disease states will be increasingly valuable for biological interpretation of sequence data.","",""
11,"P. Poudel, A. Illanes, E. Ataide, N. Esmaeili, Sathish Balakrishnan, M. Friebe","Thyroid Ultrasound Texture Classification Using Autoregressive Features in Conjunction With Machine Learning Approaches",2019,"","","","",160,"2022-07-13 09:25:44","","10.1109/ACCESS.2019.2923547","","",,,,,11,3.67,2,6,3,"The thyroid is one of the largest endocrine glands in the human body, which is involved in several body mechanisms like controlling protein synthesis, use of energy sources, and controlling the body’s sensitivity to other hormones. Thyroid segmentation and volume reconstruction are hence essential to diagnose thyroid related diseases as most of these diseases involve a change in the shape and size of the thyroid over time. Classification of thyroid texture is the first step toward the segmentation of the thyroid. The classification of texture in thyroid Ultrasound (US) images is not an easy task as it suffers from low image contrast, presence of speckle noise, and non-homogeneous texture distribution inside the thyroid region. Hence, a robust algorithmic approach is required to accurately classify thyroid texture. In this paper, we propose three machine learning based approaches: Support Vector Machine; Artificial Neural Network; and Random Forest Classifier to classify thyroid texture. The computation of features for training these classifiers is based on a novel approach recently proposed by our team, where autoregressive modeling was applied on a signal version of the 2D thyroid US images to compute 30 spectral energy-based features for classifying the thyroid and non-thyroid textures. Our approach differs from the methods proposed in the literature as they use image-based features to characterize thyroid tissues. We obtained an accuracy of around 90% with all the three methods.","",""
38,"G. Caravagna, Timon Heide, Marc J. Williams, L. Zapata, D. Nichol, K. Chkhaidze, W. Cross, G. Cresswell, B. Werner, A. Acar, L. Chesler, C. Barnes, G. Sanguinetti, T. Graham, A. Sottoriva","Subclonal reconstruction of tumors using machine learning and population genetics",2020,"","","","",161,"2022-07-13 09:25:44","","10.1038/s41588-020-0675-5","","",,,,,38,19.00,4,15,2,"","",""
9,"S. Aich, Sabyasachi Chakraborty, J. Sim, Dong-Jin Jang, Hee-Cheol Kim","The Design of an Automated System for the Analysis of the Activity and Emotional Patterns of Dogs with Wearable Sensors Using Machine Learning",2019,"","","","",162,"2022-07-13 09:25:44","","10.3390/app9224938","","",,,,,9,3.00,2,5,3,"The safety and welfare of companion animals such as dogs has become a large challenge in the last few years. To assess the well-being of a dog, it is very important for human beings to understand the activity pattern of the dog, and its emotional behavior. A wearable, sensor-based system is suitable for such ends, as it will be able to monitor the dogs in real-time. However, the question remains unanswered as to what kind of data should be used to detect the activity patterns and emotional patterns, as does another: what should be the location of the sensors for the collection of data and how should we automate the system? Yet these questions remain unanswered, because to date, there is no such system that can address the above-mentioned concerns. The main purpose of this study was (1) to develop a system that can detect the activities and emotions based on the accelerometer and gyroscope signals and (2) to automate the system with robust machine learning techniques for implementing it for real-time situations. Therefore, we propose a system which is based on the data collected from 10 dogs, including nine breeds of various sizes and ages, and both genders. We used machine learning classification techniques for automating the detection and evaluation process. The ground truth fetched for the evaluation process was carried out by taking video recording data in frame per second and the wearable sensors data were collected in parallel with the video recordings. Evaluation of the system was performed using an ANN (artificial neural network), random forest, SVM (support vector machine), KNN (k nearest neighbors), and a naïve Bayes classifier. The robustness of our system was evaluated by taking independent training and validation sets. We achieved an accuracy of 96.58% while detecting the activity and 92.87% while detecting emotional behavior, respectively. This system will help the owners of dogs to track their behavior and emotions in real-life situations for various breeds in different scenarios.","",""
9,"R. Roelofs","Measuring Generalization and Overfitting in Machine Learning",2019,"","","","",163,"2022-07-13 09:25:44","","","","",,,,,9,3.00,9,1,3,"Author(s): Roelofs, Rebecca | Advisor(s): Recht, Benjamin; Demmel, James | Abstract: Due to the prevalence of machine learning algorithms and the potential for their decisions to profoundly impact billions of human lives, it is crucial that they are robust, reliable, and understandable. This thesis examines key theoretical pillars of machine learning surrounding generalization and overfitting, and tests the extent to which empirical behavior matches existing theory. We develop novel methods for measuring overfitting and generalization, and we characterize how reproducible observed behavior is across differences in optimization algorithm, dataset, task, evaluation metric, and domain.First, we examine how optimization algorithms bias machine learning models towards solutions with varying generalization properties. We show that adaptive gradient methods empirically find solutions with inferior generalization behavior compared to those found by stochastic gradient descent. We then construct an example using a simple overparameterized model that corroborates the algorithms’ empirical behavior on neural networks. Next, we study the extent to which machine learning models have overfit to commonly reused datasets in both academic benchmarks and machine learning competitions. We build new test sets for the CIFAR-10 and ImageNet datasets and evaluate a broad range of classification models on the new datasets. All models experience a drop in accuracy, which indicates that current accuracy numbers are susceptible to even minute natural variations in the data distribution. Surprisingly, despite several years of adaptively selecting the models to perform well on these competitive benchmarks, we find no evidence of overfitting. We then analyze data from the machine learning platform Kaggle and find little evidence of substantial overfitting in ML competitions. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.Overall, our work suggests that the true concern for robust machine learning is distribution shift rather than overfitting, and designing models that still work reliably in dynamic environments is a challenging but necessary undertaking.","",""
37,"B. Pham, A. Jaafari, Mohammadtaghi Avand, N. Al‐Ansari, Tran Dinh Du, H. Yen, T. Phong, D. H. Nguyen, H. V. Le, D. Gholami, Indra Prakash, Hoang Thi Thuy, T. T. Tuyen","Performance Evaluation of Machine Learning Methods for Forest Fire Modeling and Prediction",2020,"","","","",164,"2022-07-13 09:25:44","","10.3390/sym12061022","","",,,,,37,18.50,4,13,2,"Predicting and mapping fire susceptibility is a top research priority in fire-prone forests worldwide. This study evaluates the abilities of the Bayes Network (BN), Naive Bayes (NB), Decision Tree (DT), and Multivariate Logistic Regression (MLP) machine learning methods for the prediction and mapping fire susceptibility across the Pu Mat National Park, Nghe An Province, Vietnam. The modeling methodology was formulated based on processing the information from the 57 historical fires and a set of nine spatially explicit explanatory variables, namely elevation, slope degree, aspect, average annual temperate, drought index, river density, land cover, and distance from roads and residential areas. Using the area under the receiver operating characteristic curve (AUC) and seven other performance metrics, the models were validated in terms of their abilities to elucidate the general fire behaviors in the Pu Mat National Park and to predict future fires. Despite a few differences between the AUC values, the BN model with an AUC value of 0.96 was dominant over the other models in predicting future fires. The second best was the DT model (AUC = 0.94), followed by the NB (AUC = 0.939), and MLR (AUC = 0.937) models. Our robust analysis demonstrated that these models are sufficiently robust in response to the training and validation datasets change. Further, the results revealed that moderate to high levels of fire susceptibilities are associated with ~19% of the Pu Mat National Park where human activities are numerous. This study and the resultant susceptibility maps provide a basis for developing more efficient fire-fighting strategies and reorganizing policies in favor of sustainable management of forest resources.","",""
148,"Ken Kubota, Jason A. Chen, M. Little","Machine learning for large‐scale wearable sensor data in Parkinson's disease: Concepts, promises, pitfalls, and futures",2016,"","","","",165,"2022-07-13 09:25:44","","10.1002/mds.26693","","",,,,,148,24.67,49,3,6,"For the treatment and monitoring of Parkinson's disease (PD) to be scientific, a key requirement is that measurement of disease stages and severity is quantitative, reliable, and repeatable. The last 50 years in PD research have been dominated by qualitative, subjective ratings obtained by human interpretation of the presentation of disease signs and symptoms at clinical visits. More recently, “wearable,” sensor‐based, quantitative, objective, and easy‐to‐use systems for quantifying PD signs for large numbers of participants over extended durations have been developed. This technology has the potential to significantly improve both clinical diagnosis and management in PD and the conduct of clinical studies. However, the large‐scale, high‐dimensional character of the data captured by these wearable sensors requires sophisticated signal processing and machine‐learning algorithms to transform it into scientifically and clinically meaningful information. Such algorithms that “learn” from data have shown remarkable success in making accurate predictions for complex problems in which human skill has been required to date, but they are challenging to evaluate and apply without a basic understanding of the underlying logic on which they are based. This article contains a nontechnical tutorial review of relevant machine‐learning algorithms, also describing their limitations and how these can be overcome. It discusses implications of this technology and a practical road map for realizing the full potential of this technology in PD research and practice. © 2016 International Parkinson and Movement Disorder Society","",""
14,"B. Ansell, B. Pope, P. Georgeson, Samantha J. Emery-Corbin, A. Jex","Annotation of the Giardia proteome through structure-based homology and machine learning",2018,"","","","",166,"2022-07-13 09:25:44","","10.1093/gigascience/giy150","","",,,,,14,3.50,3,5,4,"Abstract Background Large-scale computational prediction of protein structures represents a cost-effective alternative to empirical structure determination with particular promise for non-model organisms and neglected pathogens. Conventional sequence-based tools are insufficient to annotate the genomes of such divergent biological systems. Conversely, protein structure tolerates substantial variation in primary amino acid sequence and is thus a robust indicator of biochemical function. Structural proteomics is poised to become a standard part of pathogen genomics research; however, informatic methods are now required to assign confidence in large volumes of predicted structures. Aims Our aim was to predict the proteome of a neglected human pathogen, Giardia duodenalis, and stratify predicted structures into high- and lower-confidence categories using a variety of metrics in isolation and combination. Methods We used the I-TASSER suite to predict structural models for ∼5,000 proteins encoded in G. duodenalis and identify their closest empirically-determined structural homologues in the Protein Data Bank. Models were assigned to high- or lower-confidence categories depending on the presence of matching protein family (Pfam) domains in query and reference peptides. Metrics output from the suite and derived metrics were assessed for their ability to predict the high-confidence category individually, and in combination through development of a random forest classifier. Results We identified 1,095 high-confidence models including 212 hypothetical proteins. Amino acid identity between query and reference peptides was the greatest individual predictor of high-confidence status; however, the random forest classifier outperformed any metric in isolation (area under the receiver operating characteristic curve = 0.976) and identified a subset of 305 high-confidence-like models, corresponding to false-positive predictions. High-confidence models exhibited greater transcriptional abundance, and the classifier generalized across species, indicating the broad utility of this approach for automatically stratifying predicted structures. Additional structure-based clustering was used to cross-check confidence predictions in an expanded family of Nek kinases. Several high-confidence-like proteins yielded substantial new insight into mechanisms of redox balance in G. duodenalis—a system central to the efficacy of limited anti-giardial drugs. Conclusion Structural proteomics combined with machine learning can aid genome annotation for genetically divergent organisms, including human pathogens, and stratify predicted structures to promote efficient allocation of limited resources for experimental investigation.","",""
7,"S. Vigneshwari, B. Bharathi, T. Sasikala, S. Mukkamala","A Study on the Application of Machine Learning Algorithms Using R",2019,"","","","",167,"2022-07-13 09:25:44","","10.1166/jctn.2019.8309","","",,,,,7,2.33,2,4,3,"Machine learning is preferred to human interpretations during the analysis of vast scientific datasets, since the data processing time is reduced with and increased accuracy of results. Gene classification is very important in scientific analysis of bio assay datasets especially for  effective disease identification and drug discovery. The important task in gene classification process is the construction of decision tree. Real time datasets are used for this analysis and the results are in terms of 35 known siRNA gene expression factors of 64752 substances. Three types  of machine learning algorithms are used for analyzing the bio assay dataset which are CTree algorithm, Rpart algorithm and K-Means clustering algorithm. The performance analysis shows better accuracy, precision and F-measure rates of Rpart algorithm. From the result analysis, it is  inferred that the performance tree based decision making algorithms like Rpart and CTree is far better than K-Means clustering algorithm in the diagnosis of biological activities in the protein coded genes. It is also proved that the tree based algorithms are less sensitive and less specific  which leads to a development of high impact decision trees even for complex datasets like AID_651811. The analysis is done in R programming tool and the mutation factors are predicted and classified.","",""
5,"Xiaohua Li, Yu Chen, K. Zeng","Integration of machine learning and human learning for training optimization in robust linear regression",2016,"","","","",168,"2022-07-13 09:25:44","","10.1109/ICASSP.2016.7472150","","",,,,,5,0.83,2,3,6,"In this paper machine learning and human learning are applied jointly to optimize the training of linear regression. Human learning is exploited to label extra training data so as to resolve problems such as insufficient training and over-fitting. Considering the inevitable human errors in labeling, two machine learning algorithms are developed which optimize the selection of the extra training data and detect human errors during linear regression. The first algorithm assumes sparse human errors and implements a sparse optimization within a sequential active learning procedure. The second algorithm deals with non-sparse human errors. By exploiting the IRT (item response theory) to model the distribution of human errors, it reconstructs the training data set so that the human labeling errors become sparse. Simulations are conducted to show that the two algorithms are effective in resolving the insufficient training and human labeling error problems.","",""
4,"Oliver Fleetwood, M. Kasimova, Annie M. Westerlund, L. Delemotte","Molecular insights from conformational ensembles using Machine Learning",2019,"","","","",169,"2022-07-13 09:25:44","","10.1101/695254","","",,,,,4,1.33,1,4,3,"Biomolecular simulations are intrinsically high dimensional and generate noisy datasets of ever increasing size. Extracting important features in the data is crucial for understanding the biophysical properties of molecular processes, but remains a big challenge. Machine learning (ML) provides powerful dimensionality reduction tools. However, such methods are often criticized to resemble black boxes with limited human-interpretable insight. We use methods from supervised and unsupervised ML to efficiently create interpretable maps of important features from molecular simulations. We benchmark the performance of several methods including neural networks, random forests and principal component analysis, using a toy model with properties reminiscent of macromolecular behavior. We then analyze three diverse biological processes: conformational changes within the soluble protein calmodulin, ligand binding to a G protein-coupled receptor and activation of an ion channel voltage-sensor domain, unravelling features critical for signal transduction, ligand binding and voltage sensing. This work demonstrates the usefulness of ML in understanding biomolecular states and demystifying complex simulations. STATEMENT OF SIGNIFICANCE Understanding how biomolecules function requires resolving the ensemble of structures they visit. Molecular dynamics simulations compute these ensembles and generate large amounts of data that can be noisy and need to be condensed for human interpretation. Machine learning methods are designed to process large amounts of data, but are often criticized for their black-box nature and have historically been modestly used in the analysis of biomolecular systems. We demonstrate how machine learning tools can provide an interpretable overview of important features in a simulation dataset. We develop a protocol to quickly perform data-driven analysis of molecular simulations. This protocol is applied to identify the molecular basis of ligand binding to a receptor and of voltage sensitivity of an ion channel.","",""
3,"Finn Kuusisto, V. S. Costa, Zhonggang Hou, James A. Thomson, David Page, R. Stewart","Machine Learning to Predict Developmental Neurotoxicity with High-Throughput Data from 2D Bio-Engineered Tissues",2019,"","","","",170,"2022-07-13 09:25:44","","10.1109/ICMLA.2019.00055","","",,,,,3,1.00,1,6,3,"There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.","",""
4,"M. Tong","Using Machine Learning to Predict Core Sizes of High-Efficiency Turbofan Engines",2019,"","","","",171,"2022-07-13 09:25:44","","10.1115/1.4044770","","",,,,,4,1.33,4,1,3,"  With the rise in big data and analytics, machine learning is transforming many industries. It is being increasingly employed to solve a wide range of complex problems, producing autonomous systems that support human decision-making. For the aircraft engine industry, machine learning of historical and existing engine data could provide insights that help drive for better engine design. This work explored the application of machine learning to engine preliminary design. Engine core-size prediction was chosen for the first study because of its relative simplicity in terms of number of input variables required (only three). Specifically, machine-learning predictive tools were developed for turbofan engine core-size prediction, using publicly available data of two hundred manufactured engines and engines that were studied previously in NASA aeronautics projects. The prediction results of these models show that, by bringing together big data, robust machine-learning algorithms and data science, a machine learning-based predictive model can be an effective tool for turbofan engine core-size prediction. The promising results of this first study paves the way for further exploration of the use of machine learning for aircraft engine preliminary design.","",""
0,"Kamlesh Ramcharitar, A. Ramdhanie","Using Machine Learning Methods to Identify Reservoir Compartmentalization in Mature Oilfields from Legacy Production Data",2021,"","","","",172,"2022-07-13 09:25:44","","10.2118/200979-ms","","",,,,,0,0.00,0,2,1,"  Despite long production histories, operators of mature oilfields sometimes struggle to account for reservoir compartmentalization. Geological-led workflows do not adequately honor legacy production data since inherent bias is introduced into the process of allocating production by interpreted flow units. This paper details the application of machine learning methods to identify possible reservoir compartments based on legacy production data recorded from individual well completions. We propose an experimental data-driven workflow to rapidly generate multiple scenarios of connected volumes in the subsurface. The workflow is premised upon the logic that well completions draining the same connected reservoir space can exhibit similar production characteristics (rate declines, GOR trends and pressures). We show how the specific challenges of digitized legacy data are solved using outlier detection for error checking and Kalman smoothing imputation for missing data in the structural time series model. Finally, we compare the subsurface grouping of completions obtained by applying unsupervised pattern recognition with Hierarchal clustering. Application of this workflow results in multiple possible scenarios for defining reservoir compartments based on production data trends only. The method is powerful in that, it provides interpretations that are independent of subsurface scenarios generated by more traditional workflows. We demonstrate the potential to integrate interpretations generated from more conventional workflows to increase the robustness of the overall subsurface model. We have leveraged the power of machine learning methods to classify more than forty (40) well completions into discrete reservoir compartments using production characteristics only. This effort would be extremely difficult, or otherwise unreliable given the inherent limitations of human spatial, temporal, and cognitive abilities.","",""
6,"Francesco Riccio, R. Capobianco, D. Nardi","Learning human-robot handovers through π-STAM: Policy improvement with spatio-temporal affordance maps",2016,"","","","",173,"2022-07-13 09:25:44","","10.1109/HUMANOIDS.2016.7803373","","",,,,,6,1.00,2,3,6,"Human-robot handovers are characterized by high uncertainty and poor structure of the problem that make them difficult tasks. While machine learning methods have shown promising results, their application to problems with large state dimensionality, such as in the case of humanoid robots, is still limited. Additionally, by using these methods and during the interaction with the human operator, no guarantees can be obtained on the correct interpretation of spatial constraints (e.g., from social rules). In this paper, we present Policy Improvement with Spatio-Temporal Affordance Maps - π-STAM, a novel iterative algorithm to learn spatial affordances and generate robot behaviors. Our goal consists in generating a policy that adapts to the unknown action semantics by using affordances. In this way, while learning to perform a human-robot handover task, we can (1) efficiently generate good policies with few training episodes, and (2) easily encode action semantics and, if available, enforce prior knowledge in it. We experimentally validate our approach both in simulation and on a real NAO robot whose task consists in taking an object from the hands of a human. The obtained results show that our algorithm obtains a good policy while reducing the computational load and time duration of the learning process.","",""
456,"Amir Mosavi, Pınar Öztürk, K. Chau","Flood Prediction Using Machine Learning Models: Literature Review",2018,"","","","",174,"2022-07-13 09:25:44","","10.3390/w10111536","","",,,,,456,114.00,152,3,4,"Floods are among the most destructive natural disasters, which are highly complex to model. The research on the advancement of flood prediction models contributed to risk reduction, policy suggestion, minimization of the loss of human life, and reduction of the property damage associated with floods. To mimic the complex mathematical expressions of physical processes of floods, during the past two decades, machine learning (ML) methods contributed highly in the advancement of prediction systems providing better performance and cost-effective solutions. Due to the vast benefits and potential of ML, its popularity dramatically increased among hydrologists. Researchers through introducing novel ML methods and hybridizing of the existing ones aim at discovering more accurate and efficient prediction models. The main contribution of this paper is to demonstrate the state of the art of ML models in flood prediction and to give insight into the most suitable models. In this paper, the literature where ML models were benchmarked through a qualitative analysis of robustness, accuracy, effectiveness, and speed are particularly investigated to provide an extensive overview on the various ML algorithms used in the field. The performance comparison of ML models presents an in-depth understanding of the different techniques within the framework of a comprehensive evaluation and discussion. As a result, this paper introduces the most promising prediction methods for both long-term and short-term floods. Furthermore, the major trends in improving the quality of the flood prediction models are investigated. Among them, hybridization, data decomposition, algorithm ensemble, and model optimization are reported as the most effective strategies for the improvement of ML methods. This survey can be used as a guideline for hydrologists as well as climate scientists in choosing the proper ML method according to the prediction task.","",""
1,"C. He, M. Mahfouf, Luis A. Torres-Salomao","An Adaptive General Type-2 Fuzzy Logic Approach for Psychophysiological State Modeling in Real-Time Human–Machine Interfaces",2021,"","","","",175,"2022-07-13 09:25:44","","10.1109/THMS.2020.3027531","","",,,,,1,1.00,0,3,1,"In this article, a new type-2 fuzzy-based modeling approach is proposed to assess human operators’ psychophysiological states for both safety and reliability of human–machine interface systems. Such a new modeling technique combines type-2 fuzzy sets with state tracking to update the rule base through a Bayesian process. These new configurations successfully lead to an adaptive, robust, and transparent computational framework that can be utilized to identify dynamic (i.e., real time) features without prior training. The proposed framework is validated on mental arithmetic cognitive real-time experiments with ten participants. It is found that the proposed framework outperforms other paradigms (i.e., an adaptive neuro-fuzzy inference system and an adaptive general type-2 fuzzy c-means modeling approach) in terms of disturbance rejection and learning capabilities. The proposed framework achieved the best performance compared to other models that have been presented in the related literature. Therefore, the new framework can be a promising development in human–machine interface systems. It can be further utilized to develop advanced control mechanisms, investigate the origins of human compromised task performance, and identify and remedy psychophysiological breakdown in the early stages.","",""
28,"Samuel J. Webb, T. Hanser, B. Howlin, P. Krause, J. Vessey","Feature combination networks for the interpretation of statistical machine learning models: application to Ames mutagenicity",2014,"","","","",176,"2022-07-13 09:25:44","","10.1186/1758-2946-6-8","","",,,,,28,3.50,6,5,8,"","",""
40,"Fadi Al Machot, Ali Elmachot, Mouhannad Ali, Elyan Al Machot, K. Kyamakya","A Deep-Learning Model for Subject-Independent Human Emotion Recognition Using Electrodermal Activity Sensors",2019,"","","","",177,"2022-07-13 09:25:44","","10.3390/s19071659","","",,,,,40,13.33,8,5,3,"One of the main objectives of Active and Assisted Living (AAL) environments is to ensure that elderly and/or disabled people perform/live well in their immediate environments; this can be monitored by among others the recognition of emotions based on non-highly intrusive sensors such as Electrodermal Activity (EDA) sensors. However, designing a learning system or building a machine-learning model to recognize human emotions while training the system on a specific group of persons and testing the system on a totally a new group of persons is still a serious challenge in the field, as it is possible that the second testing group of persons may have different emotion patterns. Accordingly, the purpose of this paper is to contribute to the field of human emotion recognition by proposing a Convolutional Neural Network (CNN) architecture which ensures promising robustness-related results for both subject-dependent and subject-independent human emotion recognition. The CNN model has been trained using a grid search technique which is a model hyperparameter optimization technique to fine-tune the parameters of the proposed CNN architecture. The overall concept’s performance is validated and stress-tested by using MAHNOB and DEAP datasets. The results demonstrate a promising robustness improvement regarding various evaluation metrics. We could increase the accuracy for subject-independent classification to 78% and 82% for MAHNOB and DEAP respectively and to 81% and 85% subject-dependent classification for MAHNOB and DEAP respectively (4 classes/labels). The work shows clearly that while using solely the non-intrusive EDA sensors a robust classification of human emotion is possible even without involving additional/other physiological signals.","",""
13,"Y. Singh","Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance",2017,"","","","",178,"2022-07-13 09:25:44","","10.4258/hir.2017.23.4.271","","",,,,,13,2.60,13,1,5,"Objectives Human immunodeficiency virus infection and acquired immune deficiency syndrome (HIV/AIDS) is one of the major burdens of disease in developing countries, and the standard-of-care treatment includes prescribing antiretroviral drugs. However, antiretroviral drug resistance is inevitable due to selective pressure associated with the high mutation rate of HIV. Determining antiretroviral resistance can be done by phenotypic laboratory tests or by computer-based interpretation algorithms. Computer-based algorithms have been shown to have many advantages over laboratory tests. The ANRS (Agence Nationale de Recherches sur le SIDA) is regarded as a gold standard in interpreting HIV drug resistance using mutations in genomes. The aim of this study was to improve the prediction of the ANRS gold standard in predicting HIV drug resistance. Methods A genome sequence and HIV drug resistance measures were obtained from the Stanford HIV database (http://hivdb.stanford.edu/). Feature selection was used to determine the most important mutations associated with resistance prediction. These mutations were added to the ANRS rules, and the difference in the prediction ability was measured. Results This study uncovered important mutations that were not associated with the original ANRS rules. On average, the ANRS algorithm was improved by 79% ± 6.6%. The positive predictive value improved by 28%, and the negative predicative value improved by 10%. Conclusions The study shows that there is a significant improvement in the prediction ability of ANRS gold standard.","",""
40,"E. Kuminski, Joe George, J. Wallin, L. Shamir","Combining human and machine learning for morphological analysis of galaxy images",2014,"","","","",179,"2022-07-13 09:25:44","","10.1086/678977","","",,,,,40,5.00,10,4,8,"The increasing importance of digital sky surveys collecting many millions of galaxy images has reinforced the need for robust methods that can perform morphological analysis of large galaxy image databases. Citizen science initiatives such as Galaxy Zoo showed that large datasets of galaxy images can be analyzed effectively by non-scientist volunteers, but since databases generated by robotic telescopes grow much faster than the processing power of any group of citizen scientists, it is clear that computer analysis is required. Here we propose to use citizen science data for training machine learning systems, and show experimental results demonstrating that machine learning systems can be trained with citizen science data. Our findings show that the performance of machine learning depends on the quality of the data, which can be improved by using samples that have a high degree of agreement between the citizen scientists. The source code of the method is publicly available.","",""
7,"Efrat Muller, Yadid M. Algavi, E. Borenstein","A meta-analysis study of the robustness and universality of gut microbiome-metabolome associations",2021,"","","","",180,"2022-07-13 09:25:44","","10.1186/s40168-021-01149-z","","",,,,,7,7.00,2,3,1,"","",""
16,"Hyunki Lee, S. Madar, Santusht Sairam, Tejas G. Puranik, A. Payan, Michelle Kirby, Olivia J. Pinon, D. Mavris","Critical Parameter Identification for Safety Events in Commercial Aviation Using Machine Learning",2020,"","","","",181,"2022-07-13 09:25:44","","10.3390/aerospace7060073","","",,,,,16,8.00,2,8,2,"In recent years, there has been a rapid growth in the application of data science techniques that leverage aviation data collected from commercial airline operations to improve safety. This paper presents the application of machine learning to improve the understanding of risk factors during flight and their causal chains. With increasing complexity and volume of operations, rapid accumulation and analysis of this safety-related data has the potential to maintain and even lower the low global accident rates in aviation. This paper presents the development of an analytical methodology called Safety Analysis of Flight Events (SAFE) that synthesizes data cleaning, correlation analysis, classification-based supervised learning, and data visualization schema to streamline the isolation of critical parameters and the elimination of tangential factors for safety events in aviation. The SAFE methodology outlines a robust and repeatable framework that is applicable across heterogeneous data sets containing multiple aircraft, airport of operations, and phases of flight. It is demonstrated on Flight Operations Quality Assurance (FOQA) data from a commercial airline through use cases related to three safety events, namely Tire Speed Event, Roll Event, and Landing Distance Event. The application of the SAFE methodology yields a ranked list of critical parameters in line with subject-matter expert conceptions of these events for all three use cases. The work concludes by raising important issues about the compatibility levels of machine learning and human conceptualization of incidents and their precursors, and provides initial guidance for their reconciliation.","",""
5,"Y. Hasija, N. Garg, Soumya Sourav","Automated detection of dermatological disorders through image-processing and machine learning",2017,"","","","",182,"2022-07-13 09:25:44","","10.1109/ISS1.2017.8389340","","",,,,,5,1.00,2,3,5,"Dermatological Diseases are one of the biggest medical issues in 21st century due to it's highly complex and expensive diagnosis with difficulties and subjectivity of human interpretation. In cases of fatal diseases like Melanoma diagnosis in early stages play a vital role in determining the probability of getting cured. We believe that the application of automated methods will help in early diagnosis especially with the set of images with variety of diagnosis. Hence, in this article we present a completely automated system of dermatological disease recognition through lesion images, a machine intervention in contrast to conventional medical personnel based detection. Our model is designed into three phases compromising of data collection and augmentation, designing model and finally prediction. We have used multiple AI algorithms like Convolutional Neural Network and Support Vector Machine and amalgamated it with image processing tools to form a better structure, leading to higher accuracy of 95.3%.","",""
15,"O. Pianykh, Steven Guitron, Darren Parke, Chengzhao Zhang, P. Pandharipande, J. Brink, D. Rosenthal","Improving healthcare operations management with machine learning",2020,"","","","",183,"2022-07-13 09:25:44","","10.1038/s42256-020-0176-3","","",,,,,15,7.50,2,7,2,"","",""
494,"Robert Geirhos, J. Jacobsen, Claudio Michaelis, R. Zemel, Wieland Brendel, M. Bethge, Felix Wichmann","Shortcut Learning in Deep Neural Networks",2020,"","","","",184,"2022-07-13 09:25:44","","10.1038/s42256-020-00257-z","","",,,,,494,247.00,71,7,2,"","",""
430,"Amirata Ghorbani, Abubakar Abid, James Y. Zou","Interpretation of Neural Networks is Fragile",2017,"","","","",185,"2022-07-13 09:25:44","","10.1609/aaai.v33i01.33013681","","",,,,,430,86.00,143,3,5,"In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.","",""
11,"A. Abrol, Z. Fu, Mustafa S. Salman, Rogers F. Silva, Y. Du, S. Plis, V. Calhoun","Hype versus hope: Deep learning encodes more predictive and robust brain imaging representations than standard machine learning",2020,"","","","",186,"2022-07-13 09:25:44","","10.1101/2020.04.14.041582","","",,,,,11,5.50,2,7,2,"Previous successes of deep learning (DL) approaches on several complex tasks have hugely inflated expectations of their power to learn subtle properties of complex brain imaging data, and scale to large datasets. Perhaps as a reaction to this inflation, recent critical commentaries unfavorably compare DL with standard machine learning (SML) approaches for the analysis of brain imaging data. Yet, their conclusions are based on pre-engineered features which deprives DL of its main advantage: representation learning. Here we evaluate this and show the importance of representation learning for DL performance on brain imaging data. We report our findings from a large-scale systematic comparison of SML approaches versus DL profiled in a ten-way age and gender-based classification task on 12,314 structural MRI images. Results show that DL methods, if implemented and trained following the prevalent DL practices, have the potential to substantially improve compared to SML approaches. We also show that DL approaches scale particularly well presenting a lower asymptotic complexity in relative computational time, despite being more complex. Our analysis reveals that the performance improvement saturates as the training sample size grows, but shows significantly higher performance throughout. We also show evidence that the superior performance of DL is primarily due to the excellent representation learning capabilities and that SML methods can perform equally well when operating on representations produced by the trained DL models. Finally, we demonstrate that DL embeddings span a comprehensible projection spectrum and that DL consistently localizes discriminative brain biomarkers, providing an example of the robustness of prediction relevance estimates. Our findings highlight the presence of non-linearities in brain imaging data that DL frameworks can exploit to generate superior predictive representations for characterizing the human brain, even with currently available data sizes.","",""
11,"Q. Bai, Shaobo Li, Jing Yang, Qi Song, Zhiang Li, Xingxing Zhang","Object Detection Recognition and Robot Grasping Based on Machine Learning: A Survey",2020,"","","","",187,"2022-07-13 09:25:44","","10.1109/ACCESS.2020.3028740","","",,,,,11,5.50,2,6,2,"With the rapid development of machine learning, its powerful function in the machine vision field is increasingly reflected. The combination of machine vision and robotics to achieve the same precise and fast grasping as that of humans requires high-precision target detection and recognition, location and reasonable grasp strategy generation, which is the ultimate goal of global researchers and one of the prerequisites for the large-scale application of robots. Traditional machine learning has a long history and good achievements in the field of image processing and robot control. The CNN (convolutional neural network) algorithm realizes training of large-scale image datasets, solves the disadvantages of traditional machine learning in large datasets, and greatly improves accuracy, thereby positioning CNNs as a global research hotspot. However, the increasing difficulty of labeled data acquisition limits their development. Therefore, unsupervised learning, self-supervised learning and reinforcement learning, which are less dependent on labeled data, have also undergone rapid development and achieved good performance in the fields of image processing and robot capture. According to the inherent defects of vision, this paper summarizes the research achievements of tactile feedback in the fields of target recognition and robot grasping and finds that the combination of vision and tactile feedback can improve the success rate and robustness of robot grasping. This paper provides a systematic summary and analysis of the research status of machine vision and tactile feedback in the field of robot grasping and establishes a reasonable reference for future research.","",""
10,"M. Vishwanath, Salar Jafarlou, Ikhwan Shin, M. Lim, N. Dutt, A. Rahmani, H. Cao","Investigation of Machine Learning Approaches for Traumatic Brain Injury Classification via EEG Assessment in Mice",2020,"","","","",188,"2022-07-13 09:25:44","","10.3390/s20072027","","",,,,,10,5.00,1,7,2,"Due to the difficulties and complications in the quantitative assessment of traumatic brain injury (TBI) and its increasing relevance in today’s world, robust detection of TBI has become more significant than ever. In this work, we investigate several machine learning approaches to assess their performance in classifying electroencephalogram (EEG) data of TBI in a mouse model. Algorithms such as decision trees (DT), random forest (RF), neural network (NN), support vector machine (SVM), K-nearest neighbors (KNN) and convolutional neural network (CNN) were analyzed based on their performance to classify mild TBI (mTBI) data from those of the control group in wake stages for different epoch lengths. Average power in different frequency sub-bands and alpha:theta power ratio in EEG were used as input features for machine learning approaches. Results in this mouse model were promising, suggesting similar approaches may be applicable to detect TBI in humans in practical scenarios.","",""
11,"I. Hofer, Michael Burns, S. Kendale, J. Wanderer","Realistically Integrating Machine Learning Into Clinical Practice: A Road Map of Opportunities, Challenges, and a Potential Future.",2020,"","","","",189,"2022-07-13 09:25:44","","10.1213/ANE.0000000000004575","","",,,,,11,5.50,3,4,2,"Recently, interest in machine learning has rapidly grown within the health care community. This popularity has been due in part to the advances in perception tasks such as speech processing and image analysis, which has led to the successful implementation of machine learning across a variety of industries: from the ancient game of Go to Netflix movie suggestions.1 The abundance of electronic health record data coupled with the low costs of computation power and data storage makes machine learning and medicine well matched. Although health care has been traditionally slow to adopt new technologies, the time is approaching when machine learning delivers on promises to improve the current and future practice of perioperative medicine. Deployment and operationalization of a machinelearning model require synthesizing knowledge in data processing and model development with a knowledge of medicine and clinical workflows. In this article, we hope to elucidate what machine learning is and why it will transform clinical care, discuss what it takes to implement machine learning in clinical care, address current limitations and drawbacks, and ultimately examine what the future of machine learning in health care may hold. A PRIMER ON MACHINE LEARNING Machine learning is a subset of artificial intelligence in which a computer iteratively learns from data without explicit rule-based programming. Machine-learning models find patterns within data and apply these patterns to new data to make predictions. Because of the computer’s ability to rapidly process large amounts of electronic data, these models are advantageous when using large datasets. Where humans can become overwhelmed with increasingly large and complex data inputs, machine-learning models often thrive. The recent rapid explosion in computational processing power and increasing availability of large data enable capabilities beyond traditional rule-based modeling, including improved analytical capacities and accessibility to unique, potentially hidden insights. As these methods become more widely adopted in the medical community, all parties will benefit. Improvements include increased care efficiency and more accurate hospital reimbursements and increase care quality, such as improved disease classification, predicting complications, and ultimately better outcomes, Machine-learning models have been created to predict an increasing number of clinical outcomes, such as diagnoses and mortality, with applications including C. difficile infection in the inpatient hospital setting,2 identifying molecular markers for cancer treatments,3 and postoperative surgical outcomes.4 Examples of machine learning include a cardiologist using an automated interpretation of an ECG and a radiologist using an automated detection of a lung nodule in a chest x-ray. In both of these examples, a machine-learning model approximates a trained physician’s diagnosis with high accuracy. To date, models are successfully constructed to answer a single clinical question by using appropriately labeled representative data. The tools to develop these models (using languages such as R and Python) are largely free of charge and openly Realistically Integrating Machine Learning Into Clinical Practice: A Road Map of Opportunities, Challenges, and a Potential Future","",""
75,"J. Ko, S. Baldassano, Po-Ling Loh, Konrad Paul Kording, B. Litt, D. Issadore","Machine learning to detect signatures of disease in liquid biopsies - a user's guide.",2018,"","","","",190,"2022-07-13 09:25:44","","10.1039/c7lc00955k","","",,,,,75,18.75,13,6,4,"New technologies that measure sparse molecular biomarkers from easily accessible bodily fluids (e.g. blood, urine, and saliva) are revolutionizing disease diagnostics and precision medicine. Microchip devices can measure more disease biomarkers with better sensitivity and specificity each year, but clinical interpretation of these biomarkers remains a challenge. Single biomarkers in 'liquid biopsy' often cannot accurately predict the state of a disease due to heterogeneity in phenotype and disease expression across individuals. To address this challenge, investigators are combining multiplexed measurements of different biomarkers that together define robust signatures for specific disease states. Machine learning is a useful tool to automatically discover and detect these signatures, especially as new technologies output increasing quantities of molecular data. In this paper, we review the state of the field of machine learning applied to molecular diagnostics and provide practical guidance to use this tool effectively and to avoid common pitfalls.","",""
72,"Khanh Nguyen, Hal Daumé, Jordan L. Boyd-Graber","Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback",2017,"","","","",191,"2022-07-13 09:25:44","","10.18653/v1/D17-1153","","",,,,,72,14.40,24,3,5,"Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.","",""
18,"Kimiaki Shirahama, M. Grzegorzek","Towards large-scale multimedia retrieval enriched by knowledge about human interpretation",2014,"","","","",192,"2022-07-13 09:25:44","","10.1007/s11042-014-2292-8","","",,,,,18,2.25,9,2,8,"","",""
0,"Ying Hou, Mei-Ling Bao, Chen-Jiang Wu, Jing Zhang, Yu-Dong Zhang, Hai-bin Shi","A Radiomics Machine Learning Based Redefining Score Robustly Identifies Clinically Significant Prostate Cancer in Equivocal PI-RADS Score 3 Lesions",2020,"","","","",193,"2022-07-13 09:25:44","","10.2139/ssrn.3576778","","",,,,,0,0.00,0,6,2,"Background: PI-RADS score 3 lesions are recognized as equivocal likelihood of clinically significant prostate cancer (csPCa) occurrence, the optimal management of which remains controversial.    Methods: We developed a radiomics machine learning (RML) based redefining score to screen out csPCa in equivocal PI-RADS score 3 category in 263 patients with the dominant index lesion scored PI-RADS 3 who underwent biopsy and/or follow-up. One-step RML ( RML-i ) model integrated radiomic features of T2WI, DWI and ADC images all together, and two-step RML (RML-ii) model integrated the three independent radiomic signatures from T2WI images(T2WIRS), DWI images(DWIRS) and ADC images(ADCRS) separately into a regression model. The two RML models, as well as T2WIRS, DWIRS and ADCRS, were compared using the receiver operating characteristic-derived area under the curve (AUC), calibration plot and decision-curve analysis (DCA). Two radiologists were asked to give a subjective binary assessment, Cohen’s kappa statistics were calculated.    Findings: A total of 59/263 (22.4%) csPCa were identified. Inter-reader agreement was moderate (Kappa =0.435). The AUC of RML-i (0.89; 95% CI: 0.88-0.90) is significantly (p = 0.003) higher than that of RML-ii (0.87; 95% CI: 0.86-0.88). The DCA demonstrated that the RML-i and RML-ii significantly improved risk prediction at threshold probabilities of csPCa at 20% to 80% compared with doing-none or doing-all by PI-RADS score 3 or stratifying by separated DWI RS , ADC RS or T2WI RS .    Interpretation: Our RML models have the potential to predict csPCa in PI-RADS 3 lesions, thus informing the decision making process of biopsy.    Funding: None.    Declaration of Interests: The author declares no conflict of interest.    Ethics Approval Statement: This study was approved by the Independent Research Ethics Boards of the First Affiliated Hospital of Nanjing Medical University (protocol 2016-SRFA-093) on Dec 2016, before data analysis was conducted. Informed consent was waived and all procedures performed in studies involving human participants were in accordance with the 1964 Helsinki declaration and its later amendments.","",""
63,"Xin Huang, C. Xie, X. Fang, Liang-pei Zhang","Combining Pixel- and Object-Based Machine Learning for Identification of Water-Body Types From Urban High-Resolution Remote-Sensing Imagery",2015,"","","","",194,"2022-07-13 09:25:44","","10.1109/JSTARS.2015.2420713","","",,,,,63,9.00,16,4,7,"Water is one of the vital components for the ecological environment, which plays an important role in human survival and socioeconomic development. Water resources in urban areas are gradually decreasing due to the rapid urbanization, especially in developing countries. Therefore, the precise extraction and automatic identification of water bodies are of great significance and urgently required for urban planning. It should be noted that although some studies have been reported regarding the water-area extraction, to our knowledge, few papers concern the identification of urban water types (e.g, rivers, lakes, canals, and ponds). In this paper, a novel two-level machine-learning framework is proposed for identifying the water types from urban high-resolution remote-sensing images. The framework consists of two interpretation levels: 1) water bodies are extracted at the pixel level, where the water/shadow/vegetation indexes are considered and 2) water types are further identified at the object level, where a set of geometrical and textural features are used. Both levels employ machine learning for the image interpretation. The proposed framework is validated using the GeoEye-1 and WorldView-2 images, over two mega cities in China, i.e, Wuhan and Shenzhen, respectively. The experimental results show that the proposed method achieved satisfactory accuracies for both water extraction [95.4% (Shenzhen), 96.2% (Wuhan)], and water type classification [94.1% (Shenzhen), 95.9% (Wuhan)] in complex urban areas.","",""
2,"Zhiyang Wang, Y. Ou","On stability for learning human control strategy by demonstrations using SVM",2019,"","","","",195,"2022-07-13 09:25:44","","10.1108/aa-11-2018-0236","","",,,,,2,0.67,1,2,3,"This paper aims to deal with the trade-off of the stability and the accuracy in learning human control strategy from demonstrations. With the stability conditions and the estimated stability region, this paper aims to conveniently get rid of the unstable controller or controller with relatively small stability region. With this evaluation, the learning human strategy controller becomes much more robust to perturbations.,In this paper, the criterion to verify the stability and a method to estimate the domain of attraction are provided for the learning controllers trained with support vector machines (SVMs). Conditions are formulated based on the discrete-time system Lyapunov theory to ensure that a closed-form of the learning control system is strongly stable under perturbations (SSUP). Then a Chebychev point based approach is proposed to estimate its domain of attraction.,Some of such learning controllers have been implemented in the vertical balance control of a dynamically stable, statically unstable wheel mobile robot.","",""
28,"Nilay Tufek, M. Yalcin, M. Altintas, F. Kalaoglu, Yi Li, S. K. Bahadir","Human Action Recognition Using Deep Learning Methods on Limited Sensory Data",2020,"","","","",196,"2022-07-13 09:25:44","","10.1109/JSEN.2019.2956901","","",,,,,28,14.00,5,6,2,"In recent years, due to the widespread usage of various sensors action recognition is becoming more popular in many fields such as person surveillance, human-robot interaction etc. In this study, we aimed to develop an action recognition system by using only limited accelerometer and gyroscope data. Several deep learning methods like Convolutional Neural Network(CNN), Long-Short Term Memory (LSTM) with classical machine learning algorithms and their combinations were implemented and a performance analysis was carried out. Data balancing and data augmentation methods were applied and accuracy rates were increased noticeably. We achieved new state-of-the-art result on the UCI HAR dataset by 97.4% accuracy rate with using 3 layer LSTM model. Also, we implemented same model on collected dataset (ETEXWELD) and 99.0% accuracy rate was obtained which means a solid contribution. Moreover, the performance analysis is not only based on accuracy results, but also includes precision, recall and f1-score metrics. Additionally, a real-time application was developed by using 3 layer LSTM network for evaluating how the best model classifies activities robustly.","",""
60,"Keze Wang, Xiaopeng Yan, Dongyu Zhang, Lei Zhang, Liang Lin","Towards Human-Machine Cooperation: Self-Supervised Sample Mining for Object Detection",2018,"","","","",197,"2022-07-13 09:25:44","","10.1109/CVPR.2018.00173","","",,,,,60,15.00,12,5,4,"Though quite challenging, leveraging large-scale unlabeled or partially labeled images in a cost-effective way has increasingly attracted interests for its great importance to computer vision. To tackle this problem, many Active Learning (AL) methods have been developed. However, these methods mainly define their sample selection criteria within a single image context, leading to the suboptimal robustness and impractical solution for large-scale object detection. In this paper, aiming to remedy the drawbacks of existing AL methods, we present a principled Self-supervised Sample Mining (SSM) process accounting for the real challenges in object detection. Specifically, our SSM process concentrates on automatically discovering and pseudo-labeling reliable region proposals for enhancing the object detector via the introduced cross image validation, i.e., pasting these proposals into different labeled images to comprehensively measure their values under different image contexts. By resorting to the SSM process, we propose a new AL framework for gradually incorporating unlabeled or partially labeled data into the model learning while minimizing the annotating effort of users. Extensive experiments on two public benchmarks clearly demonstrate our proposed framework can achieve the comparable performance to the state-of-the-art methods with significantly fewer annotations.","",""
51,"Amirata Ghorbani, David Ouyang, Abubakar Abid, B. He, Jonathan H. Chen, R. Harrington, D. Liang, E. Ashley, James Y. Zou","Deep Learning Interpretation of Echocardiograms",2019,"","","","",198,"2022-07-13 09:25:44","","10.1101/681676","","",,,,,51,17.00,6,9,3,"Echocardiography uses ultrasound technology to capture high temporal and spatial resolution images of the heart and surrounding structures and is the most common imaging modality in cardiovascular medicine. Using convolutional neural networks on a large new dataset, we show that deep learning applied to echocardiography can identify local cardiac structures, estimate cardiac function, and predict systemic phenotypes that modify cardiovascular risk but not readily identifiable to human interpretation. Our deep learning model, EchoNet, accurately identified the presence of pacemaker leads (AUC = 0.89), enlarged left atrium (AUC = 0.85), normal left ventricular wall thickness (AUC = 0.75), left ventricular end systolic and diastolic volumes(R2 = 0.73 and R2 = 0.68), and ejection fraction (R2 = 0.48) as well as predicted systemic phenotypes of age (R2 = 0.46), sex (AUC = 0.88), weight (R2 = 0.56), and height (R2 = 0.33). Interpretation analysis validates that EchoNet shows appropriate attention to key cardiac structures when performing human-explainable tasks and highlight hypothesis-generating regions of interest when predicting systemic phenotypes difficult for human interpretation. Machine learning on echocardiography images can streamline repetitive tasks in the clinical workflow, standardize interpretation in areas with insufficient qualified cardiologists, and more consistently produce echocardiographic measurements.","",""
13,"Nastacia L. Goodwin, S. Nilsson, S. Golden","Rage Against the Machine: Advancing the study of aggression ethology via machine learning.",2020,"","","","",199,"2022-07-13 09:25:44","","10.1007/s00213-020-05577-x","","",,,,,13,6.50,4,3,2,"","",""
3,"Kimiaki Shirahama, M. Grzegorzek","Towards Large-Scale Multimedia Retrieval Enriched by Knowledge about Human Interpretation Retrospective Survey",2014,"","","","",200,"2022-07-13 09:25:44","","","","",,,,,3,0.38,2,2,8,"Recent Large-Scale Multimedia Retrieval (LSMR) methods seem to heavily rely on analysing a large amount of data using high-performance machines. This paper aims to warn this research trend. We advocate that the above methods are useful only for recognising certain primitive meanings, knowledge about human interpretation is necessary to derive high-level meanings from primitive ones. We emphasise this by conducting a retrospective survey on machine-based methods which build classifiers based on features, and human-based methods which exploit user annotation and interaction. Our survey reveals that due to prioritising the generality and scalability for large-scale data, knowledge about human interpretation is left out by recent methods, while it was fully used in classical methods. Thus, we defend the importance of human-machine cooperation which incorporates the above knowledge into LSMR. In particular, we define its three future directions (cognition-based, ontology-based and adaptive learning) depending on types of knowledge, and suggest to explore each direction by considering its relation to the others.","",""
