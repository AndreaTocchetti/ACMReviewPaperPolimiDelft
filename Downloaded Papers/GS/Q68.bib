@article{pop00001,
	author = {B Zhang and Z Dong and J Zhang and H Lin},
	title = {Functional Network: A Novel Framework for Interpretability of Deep Neural Networks},
	journal = {arXiv preprint arXiv:2205.11702},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2205.11702},
	fulltext = {https://arxiv.org/pdf/2205.11702},
	related = {https://scholar.google.com/scholar?q=related:EIUKhHuxG1cJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… robustness by lowering the fault tolerance. (2) Dropout improves generalization and robustness of … Given a deep neural network and a dataset, we record the output values of neurons …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00002,
	author = {M Yang and J Wu and X Niu},
	title = {Camera module Lens blemish detection based on neural network interpretability},
	journal = {Multimedia Tools and Applications},
	publisher = {Springer},
	doi = {10.1007/s11042-021-11716-z},
	url = {https://link.springer.com/article/10.1007/s11042-021-11716-z},
	related = {https://scholar.google.com/scholar?q=related:YoHyugwSDaUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… model has strong robustness and generalization ability for the detection of blemish. … it is also the basis of the interpretability of neural network. The activation layer can suppress useless …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00003,
	author = {E Galinkin},
	title = {Robustness and Usefulness in AI Explanation Methods},
	journal = {arXiv preprint arXiv:2203.03729},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2203.03729},
	fulltext = {https://arxiv.org/pdf/2203.03729},
	related = {https://scholar.google.com/scholar?q=related:gWISQ8QKRPwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… We evaluate these methods with respect to: robustness, in the sense of sample complexity … popular explanation methods applied to trained models rather than inherent interpretability. …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00004,
	author = {L Kong and D Chen and R Cheng},
	title = {WRNFS: Width Residual Neuro Fuzzy System, a Fast-Learning Algorithm with High Interpretability},
	journal = {Applied Sciences},
	publisher = {mdpi.com},
	url = {https://www.mdpi.com/2076-3417/12/12/5810},
	fulltext = {https://www.mdpi.com/2076-3417/12/12/5810/htm},
	related = {https://scholar.google.com/scholar?q=related:bM_edRbH-IEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… neural network has a strong fitting ability, it is difficult to be applied to safety-critical fields because of its poor interpretability. … interpretability, complexity, time efficiency, and robustness of …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00005,
	author = {J Xing and T Nagata and X Zou and E Neftci and ...},
	title = {Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2205.08685},
	fulltext = {https://arxiv.org/pdf/2205.08685},
	related = {https://scholar.google.com/scholar?q=related:g5QoKfzkYJ4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… interpretability while maintaining good task performance. Selective input gradient regularization also improves the robustness … the efficient interpretability and robustness to attacks of RL …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00006,
	author = {F Bonassi and M Farina and J Xie and R Scattolini},
	type = {HTML},
	title = {On Recurrent Neural Networks for learning-based control: recent results and ideas for future developments},
	journal = {Journal of Process Control},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0959152422000610?casa_token=0qbufK236kQAAAAA:mHkODWkWIP0B1bOpwYrXUjoYeZU2TpJeMoRnl_UqJLexX3rXoNZ-01aJ3Xj2VgGejuo3iJiYWOs},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0959152422000610?casa_token=0qbufK236kQAAAAA:mHkODWkWIP0B1bOpwYrXUjoYeZU2TpJeMoRnl_UqJLexX3rXoNZ-01aJ3Xj2VgGejuo3iJiYWOs},
	related = {https://scholar.google.com/scholar?q=related:z_VzcBAlkCgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… for control, namely their robustness, verifiability, and interpretability. The former properties … the robustness and verifiability of the RNN models, while the requirement of interpretability …},
	note = {2 cites: https://scholar.google.com/scholar?cites=2922876910699804111\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00007,
	author = {Z Salahuddin and HC Woodruff and A Chatterjee and ...},
	type = {HTML},
	title = {Transparency of deep neural networks for medical image analysis: A review of interpretability methods},
	journal = {Computers in biology and …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482521009057},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0010482521009057},
	related = {https://scholar.google.com/scholar?q=related:TNjlKexkJy8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… We can incorporate interpretability during the design process of the deep neural network. … The evaluation of explanations is important to ensure the robustness of the interpretability …},
	note = {11 cites: https://scholar.google.com/scholar?cites=3397795409352317004\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00008,
	author = {S Yu and M Wang and S Pang and L Song and S Qiao},
	type = {HTML},
	title = {Intelligent fault diagnosis and visual interpretability of rotating machinery based on residual neural network},
	journal = {Measurement},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224122004778?casa_token=oqCTdWhQTbIAAAAA:2XmZNry6byZZzJAZu0ECu01tYoz7fRrttFhyUmO4zGc58pXAkU8cf9o8dYWjZWIYxQHb2oq11A0},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0263224122004778?casa_token=oqCTdWhQTbIAAAAA:2XmZNry6byZZzJAZu0ECu01tYoz7fRrttFhyUmO4zGc58pXAkU8cf9o8dYWjZWIYxQHb2oq11A0},
	related = {https://scholar.google.com/scholar?q=related:vsarYwgTm6EJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… neural network interpretability to avoid the impact of forecast errors. There is less research on the interpretability … layer is adopted to improve the robustness of the model and the softmax …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00009,
	author = {X Wang and C Li and C Yi and X Xu and J Wang and Y Zhang},
	type = {HTML},
	title = {EcoForecast: An interpretable data-driven approach for short-term macroeconomic forecasting using N-BEATS neural network},
	journal = {Engineering Applications of …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197622002299?casa_token=epxFuezLTv0AAAAA:sci2s5qB9FSOlb-C5bVkvAenOlZGt5Q75CDtjCwBsrFoPDAiDmeRYEU6rtcoKF_VuHEJNVbLwG4},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0952197622002299?casa_token=epxFuezLTv0AAAAA:sci2s5qB9FSOlb-C5bVkvAenOlZGt5Q75CDtjCwBsrFoPDAiDmeRYEU6rtcoKF_VuHEJNVbLwG4},
	year = {2022},
	abstract = {… the model, structural optimization, robustness to transition forecast frequencies and forecast indicators, and interpretability tests. In Section 5, conclusions and future work are described. …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00010,
	author = {L Wu and P Cui and J Pei and L Zhao and L Song},
	title = {Graph neural networks},
	journal = {Graph Neural Networks: Foundations …},
	publisher = {Springer},
	doi = {10.1007/978-981-16-6054-2_3},
	url = {https://link.springer.com/chapter/10.1007/978-981-16-6054-2_3},
	related = {https://scholar.google.com/scholar?q=related:de3ltSVPnakJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… We will introduce the fundamental aspects of GNNs ranging from the popular models and their expressive powers, to the scalability, interpretability and robustness of GNNs. Then, we …},
	note = {16 cites: https://scholar.google.com/scholar?cites=12222011987137523061\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00011,
	author = {M Huai and J Liu and C Miao and L Yao and A Zhang},
	type = {PDF},
	title = {Towards Automating Model Explanations with Certified Robustness Guarantees},
	publisher = {aaai.org},
	url = {https://www.aaai.org/AAAI22Papers/AAAI-3836.HuaiM.pdf},
	fulltext = {https://www.aaai.org/AAAI22Papers/AAAI-3836.HuaiM.pdf},
	related = {https://scholar.google.com/scholar?q=related:d8IgZZgJVpgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… In addition, we can also follow the above proposed robust interpretability regularizer to provide certified robustness guarantees for the generated similarity results (ie, c(x)=[c1, ··· ,cM ]T ). …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00012,
	author = {NCL Kong and E Margalit and JL Gardner and ...},
	type = {HTML},
	title = {Increasing neural network robustness improves match to macaque V1 eigenspectrum, spatial frequency preference and predictivity},
	journal = {PLoS Computational …},
	publisher = {journals.plos.org},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009739},
	fulltext = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009739},
	related = {https://scholar.google.com/scholar?q=related:FwLJPdkvuagJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… Theory suggests that the robustness of a system to these perturbations could be related to … during task-optimization in order to improve robustness and V1 neural response predictivity. …},
	note = {3 cites: https://scholar.google.com/scholar?cites=12157801279154356759\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00013,
	author = {V Szolnoky and V Andersson and B Kulcsar and ...},
	title = {On the Interpretability of Regularisation for Neural Networks Through Model Gradient Similarity},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2205.12642},
	fulltext = {https://arxiv.org/pdf/2205.12642},
	related = {https://scholar.google.com/scholar?q=related:otjGhhRK39gJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… We show that MGS can be used to analyse neural network training, monitoring how model … 6.3 Training parameter robustness Finally, we test the robustness of each regularisation …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00014,
	author = {S Wäldchen and K Sharma and M Zimmer and ...},
	title = {Merlin-Arthur Classifiers: Formal Interpretability with Interactive Black Boxes},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2206.00759},
	fulltext = {https://arxiv.org/pdf/2206.00759},
	related = {https://scholar.google.com/scholar?q=related:Sz2qFuDCXz4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… We thus connect notions of robustness to interpretability, a game theoretic equilibrium to … using a Neural Network. Specifically, we consider a convolutional neural network with a ReLU …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00015,
	author = {B Liu and C Malon and L Xue and E Kruus},
	type = {HTML},
	title = {Improving neural network robustness through neighborhood preserving layers},
	journal = {Image and Vision Computing},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0262885622000981?casa_token=JFhoFgolVIQAAAAA:iTwhgqOG0e6FwJcKX1u5ME4hdGK1OIV8xjDv5rvtWNtUbbYYzVoOrFfb0LkOa-T1y3KuOiUF2Vk},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0262885622000981?casa_token=JFhoFgolVIQAAAAA:iTwhgqOG0e6FwJcKX1u5ME4hdGK1OIV8xjDv5rvtWNtUbbYYzVoOrFfb0LkOa-T1y3KuOiUF2Vk},
	related = {https://scholar.google.com/scholar?q=related:3ohLDiqXnUgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… Next, we introduce the concept of robustness against adversarial attack, and discuss why our proposed layer can improve network robustness in high level. Many theoretical and …},
	note = {1 cites: https://scholar.google.com/scholar?cites=5232504548958636254\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00016,
	author = {H Yin and V Kekatos and M Jin},
	title = {Learning Neural Networks under Input-Output Specifications},
	journal = {arXiv preprint arXiv:2202.11246},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2202.11246},
	fulltext = {https://arxiv.org/pdf/2202.11246},
	related = {https://scholar.google.com/scholar?q=related:nPGoiY721L0J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2022},
	abstract = {… scheme of the original neural network based on loop transformation, which leads … interpretability [11]. Up till now, verification of NN has been primarily focused on adversarial …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00017,
	author = {A Noack and I Ahern and D Dou and B Li},
	title = {An empirical study on the relation between network interpretability and adversarial robustness},
	journal = {SN Computer Science},
	publisher = {Springer},
	doi = {10.1007/s42979-020-00390-x},
	url = {https://link.springer.com/article/10.1007/s42979-020-00390-x},
	fulltext = {https://arxiv.org/pdf/1912.03430},
	related = {https://scholar.google.com/scholar?q=related:UXYxuQe2-8MJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… These findings naturally lead one to wonder if the converse is true; if we force a neural network to have interpretable gradients, will it then become robust? We devise a technique called …},
	note = {8 cites: https://scholar.google.com/scholar?cites=14122081200838374993\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00018,
	author = {RP Ramos and P Pereira and H Moniz and JP Carvalho and B Martins},
	type = {CITATION},
	title = {Retrieval Augmentation to Improve Robustness and Interpretability of Deep Neural Networks},
	journal = {arXiv preprint arXiv …},
	year = {2021},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00019,
	author = {W Wu},
	title = {On the Robustness and Interpretability of Deep Learning Models},
	publisher = {search.proquest.com},
	url = {https://search.proquest.com/openview/c84e605a373c3a7285b7f602911dce22/1?pq-origsite=gscholar\&cbl=2026366\&diss=y},
	related = {https://scholar.google.com/scholar?q=related:702EqrV0nlwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… neural network model as a function F(x;θ) = y, which accepts an input image x ∈ Rn and outputs a vector y ∈ Rm. For convenience, we denote the corresponding deep neural network …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00020,
	author = {Y Zhang and P Tiňo and A Leonardis and ...},
	title = {A survey on neural network interpretability},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9521221/?casa_token=aSAS_lw4f8AAAAAA:m_pMR2N3r20Q0r7OuzjjEHiTFFhiIjj3H8a_4fXqJvQpjOoasKPtthbomGuPISsVfkowJblVJA},
	fulltext = {https://ieeexplore.ieee.org/iel7/7433297/9544073/09521221.pdf?casa_token=P1lOl9cMbwgAAAAA:Q1ARi724qjLaQgxqUWGmyilAGR1ADBpI2g--jbJstxbHka0M_BDMbWL1CLg7x9x6jivauVNF0Q},
	related = {https://scholar.google.com/scholar?q=related:G3ZQq8P7XusJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… the neural network interpretability research. We first clarify the definition of interpretability as … Then we elaborate on the importance of interpretability and propose a novel taxonomy orga…},
	note = {98 cites: https://scholar.google.com/scholar?cites=16960270064535238171\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00021,
	author = {MB Zafar and M Donini and D Slack and C Archambeau and ...},
	title = {On the lack of robust interpretability of neural text classifiers},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2106.04631},
	fulltext = {https://arxiv.org/pdf/2106.04631},
	related = {https://scholar.google.com/scholar?q=related:-zohYftQjmkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… adopted approaches for model interpretability is feature-based interpretability, ie, ranking … In this work, we assess the robustness of interpretations of neural text classifiers, specifically…},
	note = {6 cites: https://scholar.google.com/scholar?cites=7606105861271927547\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00022,
	author = {F Arthur Oliveira Santos and C Zanchettin and ...},
	title = {On the Impact of Interpretability Methods in Active Image Augmentation Method},
	journal = {Logic Journal of the …},
	publisher = {academic.oup.com},
	doi = {10.1093/jigpal/jzab006/6123345},
	url = {https://academic.oup.com/jigpal/advance-article-abstract/doi/10.1093/jigpal/jzab006/6123345},
	fulltext = {https://academic.oup.com/jigpal/advance-article/doi/10.1093/jigpal/jzab006/6123345?casa_token=7cKdbuZPYaoAAAAA:eyoF9ZyLwAv8sLHuhmlCMKklfB-rH7fVHQKTonwMN2U4NReTuJzqbewdsx34qZfvUSfX6E5dPStCRqA},
	related = {https://scholar.google.com/scholar?q=related:CP0NADTYgwQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… five different interpretability methods to evaluate its impact on model robustness. The … Given a ground truth (GT) mask and the mask obtained by neural network model output (MO…},
	note = {1 cites: https://scholar.google.com/scholar?cites=325341315951623432\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00023,
	author = {F Santos and C Zanchettin and L Matos and P Novais},
	title = {On the Impact of Interpretability Methods in Active Image Augmentation Method},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2102.12354},
	fulltext = {https://arxiv.org/pdf/2102.12354},
	related = {https://scholar.google.com/scholar?q=related:5Pn1Me-_ed8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… five different interpretability methods to evaluate its impact on model robustness. The … Given a ground truth (GT) mask and the mask obtained by neural network model output (MO…},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00024,
	author = {K Du and S Chang and H Wen and H Zhang},
	title = {Fighting Adversarial Images With Interpretable Gradients},
	journal = {ACM Turing Award Celebration …},
	publisher = {dl.acm.org},
	doi = {10.1145/3472634.3472644},
	url = {https://dl.acm.org/doi/abs/10.1145/3472634.3472644?casa_token=cKNB0D3G8uoAAAAA:OEtoazLD-VFppW2tRdO4F02Y0cg807sbm3Fsf-3LHBvMZg9cyQnpLi01qfqc7CWtap-FVa-IDKCmmA},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3472634.3472644?casa_token=vbN5gQm4L40AAAAA:xAuTS11jSFXxcienv0H3FaKI9Ykb6cfN1RpH3jnYsl3bJdPrLuyCeRgpcL9R8McC1Q07BpW8nkK4IA},
	related = {https://scholar.google.com/scholar?q=related:5cPmLg-9BLQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… interpretability of the gradients of a neural network model can help boosting adversarial robustness of the neural network … ial robustness of a neural network and the interpretability of the …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00025,
	author = {AM Hanif and S Beqiri and PA Keane and ...},
	type = {HTML},
	title = {Applications of interpretability in deep learning models for ophthalmology},
	journal = {Current opinion in …},
	publisher = {journals.lww.com},
	url = {https://journals.lww.com/co-ophthalmology/Fulltext/2021/09000/Applications_of_interpretability_in_deep_learning.10.aspx?casa_token=ZTofyitXjPYAAAAA:p4PkCJe401-5sCL_ohyu8WWi5W_uYdbW1aCZeyro7LCXVyofyvS4EcbW8yBNx-xX-_-SqmVoF7NfAkGJpvMS6cptzno},
	fulltext = {https://journals.lww.com/co-ophthalmology/Fulltext/2021/09000/Applications_of_interpretability_in_deep_learning.10.aspx?casa_token=ZTofyitXjPYAAAAA:p4PkCJe401-5sCL_ohyu8WWi5W_uYdbW1aCZeyro7LCXVyofyvS4EcbW8yBNx-xX-_-SqmVoF7NfAkGJpvMS6cptzno},
	related = {https://scholar.google.com/scholar?q=related:0pJzYB3ac3IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Structured representation of the varied categories of interpretability methods discussed in this article… We might instead strive for model reliability by establishing standards for robustness, …},
	note = {3 cites: https://scholar.google.com/scholar?cites=8247175162352603858\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00026,
	author = {W Pan and C Zhang},
	title = {The Definitions of Interpretability and Learning of Interpretable Models},
	journal = {arXiv preprint arXiv:2105.14171},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2105.14171},
	fulltext = {https://arxiv.org/pdf/2105.14171},
	related = {https://scholar.google.com/scholar?q=related:DiA0TVByMkYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… For the sake of simplicity, we use a multi-layer neural network as an … Suppose f is a neural network with L layers. For a sample x, xi is … 2) We examine the robustness of models with two …},
	note = {3 cites: https://scholar.google.com/scholar?cites=5058231020708700174\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00027,
	author = {U Ozbulak and B Vandersmissen and A Jalalvand and ...},
	type = {HTML},
	title = {Investigating the significance of adversarial attacks and their relation to interpretability for radar-based human activity recognition systems},
	journal = {Computer Vision and …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S1077314220301338},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S1077314220301338},
	related = {https://scholar.google.com/scholar?q=related:6n-gy4Bz4LwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… neural network interpretability method, hereby showing the connection between adversarial perturbation and prediction interpretability… In this section, we analyze the robustness of radar-…},
	note = {5 cites: https://scholar.google.com/scholar?cites=13610005070922940394\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00028,
	author = {S Huang and X Wang and D Tao},
	title = {Stochastic partial swap: Enhanced model generalization and interpretability for fine-grained recognition},
	journal = {Proceedings of the IEEE/CVF …},
	publisher = {openaccess.thecvf.com},
	url = {http://openaccess.thecvf.com/content/ICCV2021/html/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.html},
	fulltext = {https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:fRIZinT3VjYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… , degrading its robustness and generalization capability. To … material recognition while improving model interpretability. … this strategy effectively promotes the neural network to rely on …},
	note = {6 cites: https://scholar.google.com/scholar?cites=3915589005950390909\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00029,
	author = {A Hoffmann and C Fanconi and R Rade and J Kohler},
	title = {This looks like that... does it? Shortcomings of latent space prototype interpretability in deep networks},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2105.02968},
	fulltext = {https://arxiv.org/pdf/2105.02968},
	related = {https://scholar.google.com/scholar?q=related:oFvllCo2Ht0J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… , where any flaw in interpretability is easily detected, we consider this lack of robustness to be much … Benchmarking neural network robustness to common corruptions and perturbations. …},
	note = {10 cites: https://scholar.google.com/scholar?cites=15933232088197979040\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00030,
	author = {IE Nielsen and D Dera and G Rasool and N Bouaynaya and ...},
	title = {Robust explainability: A tutorial on gradient-based attribution methods for deep neural networks},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2107.11400},
	fulltext = {https://arxiv.org/pdf/2107.11400},
	related = {https://scholar.google.com/scholar?q=related:LvcBydkrYhAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… of the saliency maps of a robustified neural network was not a side-effect of adversarial … We consider that the robustness of interpretability methods is tightly coupled with the robustness …},
	note = {4 cites: https://scholar.google.com/scholar?cites=1180554266704738094\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00031,
	author = {T Han and WW Tu and YF Li},
	title = {Explanation consistency training: Facilitating consistency-based semi-supervised learning with interpretability},
	journal = {Proceedings of the AAAI conference on artificial …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16934},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/download/16934/16741},
	related = {https://scholar.google.com/scholar?q=related:M5x49GYXMdgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Then we compare the visual effect and measure the robustness of explanations. Finally, we … We build a convolutional neural network using BatchNorm and ReLu functions, followed by …},
	note = {4 cites: https://scholar.google.com/scholar?cites=15578258317006904371\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00032,
	author = {JL Amey and J Keeley and T Choudhury and ...},
	title = {Neural network interpretation using descrambler groups},
	journal = {Proceedings of the …},
	publisher = {National Acad Sciences},
	doi = {10.1073/pnas.2016917118},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2016917118},
	fulltext = {https://www.pnas.org/doi/full/10.1073/pnas.2016917118},
	related = {https://scholar.google.com/scholar?q=related:OCZnTK4jrZQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… interpretability and trust, for which, at the moment, not even the definitions are settled. We can approximately define interpretability … (8), transferability (9), and robustness (10)—may be …},
	note = {12 cites: https://scholar.google.com/scholar?cites=10713258320097388088\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00033,
	author = {K Wang and F Li and CM Chen and MM Hassan and ...},
	title = {Interpreting adversarial examples and robustness for deep learning-based auto-driving systems},
	journal = {IEEE Transactions …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9539019/?casa_token=J2TeGFH72loAAAAA:QCxpkp5dQ5HtRRiQqPZf0apIhJDT93VN3PNEzzEhLMXN3Q4ByvzEnL4ZDBjsSqjGHYUz8gZwpQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/6979/4358928/09539019.pdf?casa_token=Xp1GBbqyrj8AAAAA:AsStEublso6DgkE8Npzc9uzMnUGYuYFWiP_-bKQ89KTW-BZ22P5B4b_lPLO_oML2-1WlzBDwug},
	related = {https://scholar.google.com/scholar?q=related:SLCsCPy6KdMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… on deep neural network show a … interpretability for adversarial examples problems is of great significance and belongs to the difficult problem in the field of deep learning interpretability. …},
	note = {2 cites: https://scholar.google.com/scholar?cites=15215898407687991368\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00034,
	author = {FL Fan and J Xiong and M Li and G Wang},
	title = {On interpretability of artificial neural networks: A survey},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9380482/?casa_token=oKXCfwskv30AAAAA:5_gdjDQli12-hhJ-1yeDgQRlWIHUYcavI4vt6KeJHFsZAXMefIrRogTn5OFU7H6EC4aa6LcpMw},
	fulltext = {https://ieeexplore.ieee.org/iel7/7433213/7870700/09380482.pdf?casa_token=TDC6BTXWyVUAAAAA:8WxKLNuKyhsx-5BBJt9IGZ7_fuk5Vt0R2rpIJPrTaU8nMd-d8qlCpuMJLGWsUdAWQPuQVbyLXQ},
	related = {https://scholar.google.com/scholar?q=related:ByxgFsB69JIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… interpretability and robustness are closely connected [131]. On the one hand, the improvements in model robustness prompt model interpretability. … of a neural network, and explanation …},
	note = {82 cites: https://scholar.google.com/scholar?cites=10589223589282589703\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00035,
	author = {K Yao and F Cao and Y Leung and J Liang},
	type = {HTML},
	title = {Deep neural network compression through interpretability-based filter pruning},
	journal = {Pattern Recognition},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321002430?casa_token=QS19wZcFzmgAAAAA:ZAYEWM2VhngaDvDCBQ22gpOAKBCHoryjpwYDWHGh1DtlfmlYVe7oyiHwfEgJN1p-svgN7imYPFQ},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0031320321002430?casa_token=QS19wZcFzmgAAAAA:ZAYEWM2VhngaDvDCBQ22gpOAKBCHoryjpwYDWHGh1DtlfmlYVe7oyiHwfEgJN1p-svgN7imYPFQ},
	related = {https://scholar.google.com/scholar?q=related:TQoOMVNt7WoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… from concepts of neural network interpretability (LRP). As … terms of both performance and robustness (smaller is better). … in terms of both performance and robustness. As shown in Fig. 6, …},
	note = {2 cites: https://scholar.google.com/scholar?cites=7704934741573503565\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00036,
	author = {Y FUKUHARA and T ITAZURI and H KATAOKA and ...},
	type = {CITATION},
	title = {Property Analysis of Adversarially Robust Representation},
	journal = {精密工学会誌 …},
	publisher = {jglobal.jst.go.jp},
	url = {https://jglobal.jst.go.jp/en/detail?JGLOBAL_ID=202102253457387539},
	year = {2021},
	abstract = {… deep neural network About deep neural network … About adversarial robustness …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00037,
	author = {S Hao and R Wang and Y Wang and Y Li},
	title = {A spatial attention based convolutional neural network for gesture recognition with HD-sEMG signals},
	journal = {2020 IEEE International …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9399004/},
	related = {https://scholar.google.com/scholar?q=related:i8XD6vpCVXsJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… of neural network. In this way, we can re-weight the input channel to get a better accuracy, robustness and interpretability. By utilizing the Group Convolution Neural Network (CNN), the …},
	note = {2 cites: https://scholar.google.com/scholar?cites=8887083085133497739\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00038,
	author = {X Li and H Xiong and X Li and X Wu and X Zhang and J Liu and J Bian and ...},
	title = {Interpretable deep learning: Interpretation, interpretability, trustworthiness, and beyond},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2103.10689},
	fulltext = {https://arxiv.org/pdf/2103.10689},
	related = {https://scholar.google.com/scholar?q=related:uXtZuJcTi8sJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Let F be a neural network, x be the input and x be the baseline input, which can be a black … On the connection between adversarial robustness and saliency map interpretability. arXiv …},
	note = {26 cites: https://scholar.google.com/scholar?cites=14666838153816013753\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00039,
	author = {J Ren and D Zhang and Y Wang and L Chen and ...},
	title = {Towards a Unified Game-Theoretic View of Adversarial Perturbations and Robustness},
	journal = {Advances in …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2021/hash/1f4fe6a4411edc2ff625888b4093e917-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2021/file/1f4fe6a4411edc2ff625888b4093e917-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:xn0_s0yjZpAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Furthermore, we find that the robustness of adversarially … unify adversarial perturbations and robustness, which can explain … between network interpretability and adversarial robustness. …},
	note = {1 cites: https://scholar.google.com/scholar?cites=10405183538906234310\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00040,
	author = {H Sun and Y Xu and G Kuang and J Chen},
	title = {Adversarial robustness evaluation of deep convolutional neural network based SAR ATR algorithm},
	journal = {2021 IEEE International …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9554783/?casa_token=IlW4hq1reCQAAAAA:f_oUtF_xa5oNBuYnzRrgSGyoplZBvUB9hU4uymhFxu-i3TnqmZz2FM5jN8J_nPFs-392m3awpA},
	fulltext = {https://ieeexplore.ieee.org/iel7/9553015/9553016/09554783.pdf?casa_token=YUnSvX7vX5gAAAAA:SdOd-llydHFl_9XIjVnh7-EglIs0ZJEPgoUKUDddmHcbZ0FoZrxN9Kr0UXxCTfg2TQq8whwa0A},
	related = {https://scholar.google.com/scholar?q=related:ytbtiGTpVBcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Attacks have been carried on nine commonly used deep convolutional neural network … an analysis of feature activation in multiple layers from the perspective of interpretability. …},
	note = {3 cites: https://scholar.google.com/scholar?cites=1681225178919327434\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00041,
	author = {GD Portwood and BT Nadiga and JA Saenz and ...},
	title = {Interpreting neural network models of residual scalar flux},
	journal = {Journal of Fluid …},
	publisher = {cambridge.org},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/interpreting-neural-network-models-of-residual-scalar-flux/C33E8094A6612DDC33F64F6030A9642F},
	fulltext = {https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C33E8094A6612DDC33F64F6030A9642F/S0022112020008617a_hi.pdf/interpreting-neural-network-models-of-residual-scalar-flux.pdf?casa_token=uPVbX0hRZjMAAAAA:uMzM0lNJPrMJDeliGvwgDALAQtJi6YCnnRaj5BjUVSgSmflvPAypE9LMm6N7d91xtKOPFETkyQ},
	related = {https://scholar.google.com/scholar?q=related:DotOJMHzp4EJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Besides enabling enhanced-accuracy LES of passive scalars henceforth, we anticipate this work to contribute to utilising neural network models as a tool in interpretability, robustness …},
	note = {20 cites: https://scholar.google.com/scholar?cites=9342703962866748174\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00042,
	author = {M Heggen},
	title = {An investigation of different interpretability methods used to evaluate a prediction from a CNN model},
	publisher = {duo.uio.no},
	url = {https://www.duo.uio.no/handle/10852/87832},
	fulltext = {https://www.duo.uio.no/bitstream/handle/10852/87832/1/MasterThesis04.pdf},
	related = {https://scholar.google.com/scholar?q=related:bAWmYAGkN1EJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… some of the robustness analysis of the existing interpretability … Therefore it is very important to know how the neural network … This is referred to as a self-explaining neural network (SENN)…},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00043,
	author = {M Casadio and ML Daggitt and E Komendantskaya and W Kokke and ...},
	title = {Network robustness as a mathematical property: training, evaluation and attack},
	publisher = {openreview.net},
	url = {https://openreview.net/forum?id=VAmkgdMztWs},
	fulltext = {https://openreview.net/pdf?id=VAmkgdMztWs},
	related = {https://scholar.google.com/scholar?q=related:W2R-569uNuoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… by analysing their relationships, assumptions, interpretability and verifiability. By viewing … the exact definition of robustness that we optimise for when we train our neural network f : Rn → …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00044,
	author = {S Xu and J Vaughan and J Chen and A Zhang and ...},
	title = {Traversing the local polytopes of relu neural networks: A unified approach for network verification},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2111.08922},
	fulltext = {https://arxiv.org/pdf/2111.08922},
	related = {https://scholar.google.com/scholar?q=related:2GJ1cV1WKkEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… on robustness and interpretability. Previous works to examine robustness and to improve interpretability … Firstly, a neural network may run into extrapolation issues for points outside the …},
	note = {1 cites: https://scholar.google.com/scholar?cites=4695660520822629080\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00045,
	author = {PY Lagrave and M Riou},
	type = {PDF},
	title = {Toward Geometrical Robustness with Hybrid Deep Learning and Differential Invariants Theory.},
	journal = {AAAI Spring Symposium: MLPS},
	publisher = {ceur-ws.org},
	url = {http://ceur-ws.org/Vol-2964/article_71.pdf},
	fulltext = {http://ceur-ws.org/Vol-2964/article_71.pdf},
	related = {https://scholar.google.com/scholar?q=related:XtjVGZfmPywJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… robustness to perturbations and low memory usage. The use of differential equation formulation to embed desired properties into the neural network … on the interpretability feature of our …},
	note = {1 cites: https://scholar.google.com/scholar?cites=3188520597849495646\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00046,
	author = {X Li and Y Zhou and N Dvornek and M Zhang and S Gao and ...},
	type = {HTML},
	title = {Braingnn: Interpretable brain graph neural network for fmri analysis},
	journal = {Medical Image …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841521002784?casa_token=IjA26pKtS8oAAAAA:ILwMdcpLKhRmbmjyxBdf-u7e54fAr37AnrDSaEPh2PGZPYtGpRlDcvtSHqp1T750TjCLWk2hPF8},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S1361841521002784?casa_token=IjA26pKtS8oAAAAA:ILwMdcpLKhRmbmjyxBdf-u7e54fAr37AnrDSaEPh2PGZPYtGpRlDcvtSHqp1T750TjCLWk2hPF8},
	related = {https://scholar.google.com/scholar?q=related:PaRSs39qzz8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… In this work, we propose a graph neural network-based framework for mapping regional … Also, our GNN design facilitates model interpretability by regulating intermediate outputs with a …},
	note = {70 cites: https://scholar.google.com/scholar?cites=4598010841270494269\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00047,
	author = {M Villegas and A Gonzalez-Agirre and A Gutiérrez-Fandiño and ...},
	title = {Predicting the evolution of COVID-19 mortality risk: A recurrent neural network approach},
	journal = {MedRxiv},
	publisher = {medrxiv.org},
	doi = {10.1101/2020.12.22.20244061.abstract},
	url = {https://www.medrxiv.org/content/10.1101/2020.12.22.20244061.abstract},
	fulltext = {https://www.medrxiv.org/content/medrxiv/early/2020/12/23/2020.12.22.20244061.full.pdf},
	related = {https://scholar.google.com/scholar?q=related:Wls8lJR7NHkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… healthcare systems and aims at interpretability. The system is … This not only validates the robustness of the proposal but … is the effort devoted to the interpretability of the model, which is …},
	note = {7 cites: https://scholar.google.com/scholar?cites=8733741455450594138\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00048,
	author = {S Jha and B Jalaian and A Roy and G Verma},
	title = {Trinity: Trust, Resilience and Interpretability of Machine Learning Models},
	journal = {Game Theory and Machine …},
	publisher = {Wiley Online Library},
	doi = {10.1002/9781119723950.ch16},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119723950.ch16},
	related = {https://scholar.google.com/scholar?q=related:dZbKyAtHhHkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… we have proved that the neural network is robust to bounded … inputs are provided by a neural network controller’s feedback, … While improving the accuracy and robustness of DNNs has …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00049,
	author = {Y Sun and X Hu and X Xu and J Li},
	title = {Lightweight Smog Detection Model for Unmanned Ground Vehicle Based on Interpretability of Neural Networks},
	journal = {International Conference on Autonomous …},
	publisher = {Springer},
	doi = {10.1007/978-981-16-9492-9_9},
	url = {https://link.springer.com/chapter/10.1007/978-981-16-9492-9_9},
	related = {https://scholar.google.com/scholar?q=related:hrE64yILCSoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… such as fire disasters seriously degrade the robustness of LIDAR-based algorithms. Therefore… Combining Gaussian mixture model and HSV model with deep convolution neural network …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00050,
	author = {SK Yeom and P Seegerer and S Lapuschkin and A Binder and ...},
	type = {HTML},
	title = {Pruning by explaining: A novel criterion for deep neural network pruning},
	journal = {Pattern Recognition},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321000868},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0031320321000868},
	related = {https://scholar.google.com/scholar?q=related:izIOMMLkccoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… pruning inspired by neural network interpretability: The most … By exploring this idea, we connect the lines of interpretability … We thus gain robustness against the model’s (in)confidence …},
	note = {59 cites: https://scholar.google.com/scholar?cites=14587692190710772363\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00051,
	author = {AF Sequeira and T Gonçalves and W Silva and JR Pinto and ...},
	title = {An exploratory study of interpretability for face presentation attack detection},
	journal = {IET …},
	publisher = {Wiley Online Library},
	doi = {10.1049/bme2.12045},
	url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/bme2.12045},
	fulltext = {https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/bme2.12045},
	related = {https://scholar.google.com/scholar?q=related:-rWtkrYt-OAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… This deep convolutional neural network was trained using a … interpretability, that the presence of more attacks during training has a positive effect on the generalisation and robustness …},
	note = {3 cites: https://scholar.google.com/scholar?cites=16210757120888255994\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00052,
	author = {AA Ismail and H Corrada Bravo and ...},
	title = {Improving deep learning interpretability by saliency guided training},
	journal = {Advances in Neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2021/hash/e0cd3f16f9e883ca91c2a4c24f47b3d9-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2021/file/e0cd3f16f9e883ca91c2a4c24f47b3d9-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:TVbc13tGKPQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… the robustness and overall performance of convolutional neural networks. Our work focuses on a different task which is increasing model interpretability … Let fθ denote a neural network …},
	note = {5 cites: https://scholar.google.com/scholar?cites=17593389442039305805\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00053,
	author = {G Ioannou and T Papagiannis and T Tagaris and ...},
	title = {Visual interpretability analysis of Deep CNNs using an Adaptive Threshold method on Diabetic Retinopathy images},
	journal = {Proceedings of the …},
	publisher = {openaccess.thecvf.com},
	url = {https://openaccess.thecvf.com/content/ICCV2021W/MIA-COV19D/html/Ioannou_Visual_Interpretability_Analysis_of_Deep_CNNs_Using_an_Adaptive_Threshold_ICCVW_2021_paper.html},
	fulltext = {https://openaccess.thecvf.com/content/ICCV2021W/MIA-COV19D/papers/Ioannou_Visual_Interpretability_Analysis_of_Deep_CNNs_Using_an_Adaptive_Threshold_ICCVW_2021_paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:rljuTPC8bjMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… were conducted to ensure the robustness of the results. … A wide variety of deep neural network architectures have been … state-of-the-art interpretability methods to focus on the parts that …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00054,
	author = {J Springer and M Mitchell and ...},
	title = {A little robustness goes a long way: Leveraging robust features for targeted transfer attacks},
	journal = {Advances in Neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2021/hash/50f3f8c42b998a48057e9d33f4144b8b-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2021/file/50f3f8c42b998a48057e9d33f4144b8b-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:yLWg0eLE1V4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… attacks are especially important for understanding neural-network classifiers, as they provide a … In our work, we show that each individual slightly-robust neural network transfers features …},
	note = {3 cites: https://scholar.google.com/scholar?cites=6833584488063219144\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00055,
	author = {L El Ghaoui and F Gu and B Travacca and A Askari and A Tsai},
	title = {Implicit deep learning},
	journal = {SIAM Journal on …},
	publisher = {SIAM},
	doi = {10.1137/20M1358517},
	url = {https://epubs.siam.org/doi/abs/10.1137/20M1358517},
	fulltext = {https://epubs.siam.org/doi/pdf/10.1137/20M1358517},
	related = {https://scholar.google.com/scholar?q=related:tSDe-Hob7PMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… architectures and algorithms, robustness analysis and design, interpretability, sparsity, and … For comparison purposes, we also train a neural network with three hidden layers of width n/…},
	note = {56 cites: https://scholar.google.com/scholar?cites=17576453660695470261\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00056,
	author = {S Wang and Y Yin and D Wang and Y Wang and ...},
	title = {Interpretability-based multimodal convolutional neural networks for skin lesion diagnosis},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9543523/?casa_token=D-R601OBepAAAAAA:FMHmfKHinHxGFWWRzxwVfwQI37cXRnbnbvk83w1IzW6wjkt2rEau-jXLLwd6pCbZx_TPYc4zmw},
	fulltext = {https://ieeexplore.ieee.org/iel7/6221036/6352949/09543523.pdf?casa_token=Ls5b-vriOlcAAAAA:4fnGRd47gO-uLvGi-x-m5QkFduIRCZHv2lyi9VPfxiMGh5rivXxq_FxyoDdrSyO5loySLwP7Ow},
	related = {https://scholar.google.com/scholar?q=related:KxRn9NHBFAYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… issue, we propose an interpretability-based multimodal convolutional neural network (IM-CNN… They used various methods to improve its accuracy and robustness. Kassani and Kassani […},
	note = {6 cites: https://scholar.google.com/scholar?cites=438188171254502443\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00057,
	author = {T McGrath and A Kapishnikov and N Tomašev and ...},
	title = {Acquisition of chess knowledge in alphazero},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2111.09259},
	fulltext = {https://arxiv.org/pdf/2111.09259},
	related = {https://scholar.google.com/scholar?q=related:nN4eovP58D8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… neural network interpretability. In this work we provide evidence that human knowledge is acquired by the AlphaZero neural network … work on neural network interpretability (Section 2.1) …},
	note = {8 cites: https://scholar.google.com/scholar?cites=4607457243592318620\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00058,
	author = {J Cheng and M Gao and J Liu and H Yue and H Kuang and ...},
	title = {Multimodal disentangled variational autoencoder with game theoretic interpretability for glioma grading},
	journal = {IEEE Journal of …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9478224/?casa_token=O_C5yNiE5qgAAAAA:dS9cH9PyC7T2AG-qTOdLDZGQthj5GbMB1TdWQdOK6puGEiTuNlGDNf3P1MkK2YuuaKCEEmOclQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/6221020/6363502/09478224.pdf?casa_token=6gOE69GdqYMAAAAA:ywgE56QWfSk5WIDknpOtwkzZFzHdLA0pPIkiLvdEPCvu1C9-b6q43TSw8wmMKpxE-hwQTo_LnQ},
	related = {https://scholar.google.com/scholar?q=related:9uWPAJckATEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… In this study, we propose a deep neural network model termed as multimodal disentangled … method has good robustness to tiny changes in ROI when these features are discarded. …},
	note = {8 cites: https://scholar.google.com/scholar?cites=3531143813803271670\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00059,
	author = {V Srinivasan and N Strodthoff and J Ma and A Binder and ...},
	title = {On the robustness of pretraining and self-supervision for a deep learning-based analysis of diabetic retinopathy},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2106.13497},
	fulltext = {https://arxiv.org/pdf/2106.13497},
	related = {https://scholar.google.com/scholar?q=related:e5FwfXzVSS4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… We also show improvements in robustness to distortions for selfsupervised learning in comparison to purely supervised training. Finally, we use interpretability methods to gain …},
	note = {2 cites: https://scholar.google.com/scholar?cites=3335431729701753211\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00060,
	author = {J Pfau and AT Young and J Wei and ML Wei and MJ Keiser},
	title = {Robust semantic interpretability: Revisiting concept activation vectors},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2104.02768},
	fulltext = {https://arxiv.org/pdf/2104.02768},
	related = {https://scholar.google.com/scholar?q=related:RO35LxVHf1oJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… , a semantic interpretability method must work with existing convolutional neural network (CNN) … To this end, we use ImageNet to quantify the robustness of semantic interpretability …},
	note = {5 cites: https://scholar.google.com/scholar?cites=6521008941780561220\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00061,
	author = {J Gu},
	title = {Interpretable graph capsule networks for object recognition},
	journal = {Proceedings of the AAAI Conference on Artificial …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/16237},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/view/16237/16044},
	related = {https://scholar.google.com/scholar?q=related:tHmJZMyezIgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… To overcome the lack of interpretability, we can either propose … representations and affine transformation robustness. … in terms of the adversarial robustness. In this experiment, we use …},
	note = {10 cites: https://scholar.google.com/scholar?cites=9857428285104421300\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00062,
	author = {M Casadio and M Daggitt and E Komendantskaya and ...},
	title = {Property-driven training: All you (n) ever wanted to know about},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2104.01396},
	fulltext = {https://arxiv.org/pdf/2104.01396},
	related = {https://scholar.google.com/scholar?q=related:LNIWvY5nMn4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… known as explainability and interpretability: we usually deploy … that we optimise for when we train our neural network f : Rn … robustness and approximate classification robustness. As …},
	note = {1 cites: https://scholar.google.com/scholar?cites=9093444460369859116\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00063,
	author = {Z Yang and A Zhang and A Sudjianto},
	type = {HTML},
	title = {GAMI-Net: An explainable neural network based on generalized additive models with structured interactions},
	journal = {Pattern Recognition},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321003484?casa_token=QAWVltszUvoAAAAA:EJx3CvlyemMwVO66C13nN8HknhhIzmiXBQAAUb1wlXSiXei9DzMtiwje8DrSDihDmuufuynoi4E},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0031320321003484?casa_token=QAWVltszUvoAAAAA:EJx3CvlyemMwVO66C13nN8HknhhIzmiXBQAAUb1wlXSiXei9DzMtiwje8DrSDihDmuufuynoi4E},
	related = {https://scholar.google.com/scholar?q=related:x8Pt6JFtvnkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… The lack of interpretability is an inevitable problem when using neural network models in real applications. In this … In this paper, we limit our focus to the second type of interpretability. …},
	note = {20 cites: https://scholar.google.com/scholar?cites=8772569597609886663\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00064,
	author = {Y Zhang and Z Zhao and G Chen and F Song and T Chen},
	type = {HTML},
	title = {BDD4BNN: A BDD-Based Quantitative Analysis Framework for Binarized Neural Networks},
	journal = {International Conference on …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-81685-8_8},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-81685-8_8},
	fulltext = {https://link.springer.com/chapter/10.1007/978-3-030-81685-8_8},
	related = {https://scholar.google.com/scholar?q=related:IY42pKIos6wJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… In this paper, we study verification and interpretability … providing quantitative robustness analysis and interpretability for … for a neural network such that a property (eg, local robustness) is …},
	note = {6 cites: https://scholar.google.com/scholar?cites=12444334874359664161\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00065,
	author = {D Ye and C Chen and C Liu and H Wang and ...},
	title = {Detection defense against adversarial attacks with saliency map},
	journal = {International Journal of …},
	publisher = {Wiley Online Library},
	doi = {10.1002/int.22458},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22458?casa_token=pkOKWhEC-JAAAAAA:khDaEiBNvmW6GLzgcrs3BK1oO1meZ5x8kaIvpooJROvurbKgekLTk3HDFDRz4GgiYXOdn5ISBPe73pw},
	fulltext = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.22458?casa_token=aSObsoz1bnMAAAAA:TbXgAWCGMWvDzL7eVaZFubqte1V9-Djk7Da33aGU_uxwcnDRpjPYMe6-1V5qMfrTYdlGNH-ex58K4-o},
	related = {https://scholar.google.com/scholar?q=related:ednzLEMkHesJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… Existing defenses are trend to harden the robustness of models … from the view of enhancing model interpretability, it is similar to … We analyze the interpretability of model based on deep …},
	note = {8 cites: https://scholar.google.com/scholar?cites=16941737244173261177\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00066,
	author = {H Baniecki and W Kretowicz and P Biecek},
	title = {Fooling Partial Dependence via Data Poisoning},
	journal = {arXiv preprint arXiv:2105.12837},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2105.12837},
	fulltext = {https://arxiv.org/pdf/2105.12837},
	related = {https://scholar.google.com/scholar?q=related:A4t9QAka304J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… At their core, they provide various algorithms for fooling neural network interpretability and … In the robustness check we aim to maximize the distance between the result of model …},
	note = {4 cites: https://scholar.google.com/scholar?cites=5683289881803852547\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00067,
	author = {L Glass and W Hilali and O Nelles},
	title = {Compressing Interpretable Representations of Piecewise Linear Neural Networks using Neuro-Fuzzy Models},
	journal = {2021 IEEE Symposium Series on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9659976/},
	related = {https://scholar.google.com/scholar?q=related:uZojHm3UwNAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… INTRODUCTION Neural networks’ lack of interpretability is a … the field of adversarial example robustness to regression. This … of adversarial robustness in neural network classification [26]…},
	note = {1 cites: https://scholar.google.com/scholar?cites=15042256320539630265\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00068,
	author = {H Liz and M Sánchez-Montañés and A Tagarro and ...},
	type = {HTML},
	title = {Ensembles of Convolutional Neural Network models for pediatric pneumonia diagnosis},
	journal = {Future Generation …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X2100128X?casa_token=1gMPj-QYAX0AAAAA:BqztvBdQYAyrmfC1li9f2Qgjcr0xEugYQJiBJ7rJhMq28prfJOOWjKQN8yg44FntJyPKdr4tDxw},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0167739X2100128X?casa_token=1gMPj-QYAX0AAAAA:BqztvBdQYAyrmfC1li9f2Qgjcr0xEugYQJiBJ7rJhMq28prfJOOWjKQN8yg44FntJyPKdr4tDxw},
	related = {https://scholar.google.com/scholar?q=related:muBNImFGK8YJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… due to the lack of interpretability, because of these models … This allows to overcome the explainability and interpretability … In order to increase the performance and robustness of our …},
	note = {15 cites: https://scholar.google.com/scholar?cites=14279584426509590682\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00069,
	author = {R Yao and C Huang and Z Hu and K Pei},
	title = {Adaptive Retraining for Neural Network Robustness in Classification},
	journal = {2021 International Joint …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9534294/?casa_token=sBlzqq7kVQIAAAAA:OZz_CnO2bDjmhIJSZqk42mgmbgVVHDwXQpAuGjWzcaFHpGCvZsJJdnK5BqYXo9Ri8M81FlSdaQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/9533266/9533267/09534294.pdf?casa_token=77rf6W_vir0AAAAA:5TPWgLkdufUEql6TxexjDRDTyOrPm0O_gwdVIY8EuZrufZc0mTse5fXS5kdMaq-PmIGdGow6xQ},
	related = {https://scholar.google.com/scholar?q=related:O4UnA2d0saQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… methods for neural network robustness optimization primarily … Consequently, we propose a neural network retraining … method succeeds in improving the robustness of pre-trained neural …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00070,
	author = {P Lu and Y Gao and H Xi and Y Zhang and C Gao and B Zhou and ...},
	type = {HTML},
	title = {KecNet: a light neural network for arrhythmia classification based on knowledge reinforcement},
	journal = {Journal of Healthcare …},
	publisher = {hindawi.com},
	url = {https://www.hindawi.com/journals/jhe/2021/6684954/},
	fulltext = {https://www.hindawi.com/journals/jhe/2021/6684954/},
	related = {https://scholar.google.com/scholar?q=related:-anOdAzFzoMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2021},
	abstract = {… high robustness to noisy environments, low memory usage, and physical interpretability … We discuss the robustness of KecNet in various environments by adding white noise to the …},
	note = {1 cites: https://scholar.google.com/scholar?cites=9497745321460935161\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00071,
	author = {A Boopathy and S Liu and G Zhang and C Liu and ...},
	title = {Proper network interpretability helps adversarial robustness in classification},
	journal = {International …},
	publisher = {proceedings.mlr.press},
	url = {https://proceedings.mlr.press/v119/boopathy20a},
	fulltext = {http://proceedings.mlr.press/v119/boopathy20a/boopathy20a.pdf},
	related = {https://scholar.google.com/scholar?q=related:fDIsBYkIY30J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… neural network interpretability (namely, making network interpretation maps visually similar), or interpretability is … Spurred by that, we develop an interpretability-aware defensive scheme …},
	note = {22 cites: https://scholar.google.com/scholar?cites=9035074662025671292\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00072,
	author = {T Tsiligkaridis and J Roberts},
	title = {Second order optimization for adversarial robustness and interpretability},
	journal = {arXiv preprint arXiv:2009.04923},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2009.04923},
	fulltext = {https://arxiv.org/pdf/2009.04923},
	related = {https://scholar.google.com/scholar?q=related:3jsA6rprR2kJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… and retain a high level of robustness against various types of strong attacks. Furthermore, we show how these networks improve interpretability and can be used to explain DNN …},
	note = {2 cites: https://scholar.google.com/scholar?cites=7586150547862862814\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00073,
	author = {A Gu and TW Weng and PY Chen and S Liu and ...},
	type = {PDF},
	title = {Certified Interpretability Robustness for Class Activation Mapping},
	journal = {Annual Conference on …},
	publisher = {ml4ad.github.io},
	url = {https://ml4ad.github.io/files/papers2020/Certified%20Interpretability%20Robustness%20for%20Class%20Activation%20Mapping.pdf},
	fulltext = {https://ml4ad.github.io/files/papers2020/Certified%20Interpretability%20Robustness%20for%20Class%20Activation%20Mapping.pdf},
	related = {https://scholar.google.com/scholar?q=related:k-kkYrzIQPQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… A class activation map (CAM) is a 2-dimensional heatmap that explains a neural network’s … CAM only provides an interpretability map for convolutional neural network architectures …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00074,
	author = {Y Shi and Y Han and Q Zhang and X Kuang},
	type = {HTML},
	title = {Adaptive iterative attack towards explainable adversarial robustness},
	journal = {Pattern Recognition},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320320301138?casa_token=E4eLe9niVhQAAAAA:K5813_tfD8omkr2BZRbXTWwYodwSL5iXLrrhEl0tLRspYapJ6EvE2re7uSfuZd3Nc__xPEMtQbs},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0031320320301138?casa_token=E4eLe9niVhQAAAAA:K5813_tfD8omkr2BZRbXTWwYodwSL5iXLrrhEl0tLRspYapJ6EvE2re7uSfuZd3Nc__xPEMtQbs},
	related = {https://scholar.google.com/scholar?q=related:h1x_II6mvaAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… robustness of DNNs, we illustrate the invariant step size setting could be a crucial deficiency. Different from the gradient-based interpretability … changed from neural network parameters …},
	note = {23 cites: https://scholar.google.com/scholar?cites=11582596946027568263\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00075,
	author = {P McClure and D Moraczewski and KC Lam and A Thomas and ...},
	title = {Improving the Interpretability of fMRI Decoding using Deep Neural Networks and Adversarial Robustness},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2004.11114},
	fulltext = {https://arxiv.org/pdf/2004.11114},
	related = {https://scholar.google.com/scholar?q=related:_MJinMZ1AqAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… with the goal of improving interpretability. We introduce two quantitative … different methods vary widely in interpretability, in both in … maps score higher on interpretability than linear model …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00076,
	author = {M Amirian and L Tuggener and R Chavarriaga and ...},
	title = {Two to trust: Automl for safe modelling and interpretable deep learning for robustness},
	journal = {… Workshop on the …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-73959-1_23},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-73959-1_23},
	fulltext = {https://digitalcollection.zhaw.ch/bitstream/11475/22061/2/2021_Amirian_etal_AutoML-for-safe-modelling_TAILOR_ECAI.pdf},
	related = {https://scholar.google.com/scholar?q=related:lYsEXPAIqHoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… ; (b) Interpretability of neural network outputs, which … the interpretability of a model’s decision and show how they allow detection of adversarial attacks, improving the model’s robustness …},
	note = {2 cites: https://scholar.google.com/scholar?cites=8838324097143573397\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00077,
	author = {J Wang and Y Wu and M Li and X Lin and J Wu and C Li},
	title = {Interpretability is a kind of safety: An interpreter-based ensemble for adversary defense},
	journal = {Proceedings of the 26th ACM …},
	publisher = {dl.acm.org},
	doi = {10.1145/3394486.3403044},
	url = {https://dl.acm.org/doi/abs/10.1145/3394486.3403044?casa_token=tj7IojWnyOgAAAAA:i0xb2xoeNM_bd7Z8nGqG1ogkY-0kz0U8rCgyW7jeF0GehSWBEq9M3kNbJTrSQeZJP0iThUhkXu2gCQ},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3394486.3403044?casa_token=l1a0YFsrJxsAAAAA:IMoaPO9bVKlNlVc81zW7annfUB5wlIJxbYXJ3PMcj51OqLYZPU2w0Qwplv9snYGjuZ33j_622rD2OQ},
	related = {https://scholar.google.com/scholar?q=related:wRLgiyH3N9sJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… On one hand, an ensemble can improve the robustness of sub-… , our model all shows superior accuracy and robustness. … For a neural network classifier 𝐹, we denote 𝑓𝑚 as the output …},
	note = {8 cites: https://scholar.google.com/scholar?cites=15796365941478003393\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00078,
	author = {X Huang and D Kroening and W Ruan and J Sharp and Y Sun and ...},
	type = {HTML},
	title = {A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability},
	journal = {Computer Science …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S1574013719302527?casa_token=lpcQkPTrfRoAAAAA:ezkLTygj8rgSDoY4tkmYDhfY2Hw1otJr2tWR9ZyjtO1Y_VpDhT4US1sfFAiPwkXReqs19hSvkrY},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S1574013719302527?casa_token=lpcQkPTrfRoAAAAA:ezkLTygj8rgSDoY4tkmYDhfY2Hw1otJr2tWR9ZyjtO1Y_VpDhT4US1sfFAiPwkXReqs19hSvkrY},
	related = {https://scholar.google.com/scholar?q=related:qKikn0KOa-cJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… by a human and by a neural network, and does not necessarily involve an adversary. … robustness property. Note that, all existing testing approaches surveyed relate to local robustness, …},
	note = {150 cites: https://scholar.google.com/scholar?cites=16675578462066747560\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00079,
	author = {C Zhang and A Liu and X Liu and Y Xu and H Yu and ...},
	title = {Interpreting and improving adversarial robustness of deep neural networks with neuron sensitivity},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9286885/?casa_token=4eafdCDSkSEAAAAA:R-QyZqrg5rt_pJB4GJY0O7xvpbrlraNEiGS9iZos7HI7lNxoXOcuGiZFFRuP6hgTdYRx0aZZTw},
	fulltext = {https://ieeexplore.ieee.org/iel7/83/4358840/09286885.pdf?casa_token=7sEFMEMD8skAAAAA:lFVnDQ0-cKbFRTCn4g_CAS5ESaIKKY27f9M28L6SmPNDFKEVrMgtRtn3GBWG7dxozwHRnUjQRQ},
	related = {https://scholar.google.com/scholar?q=related:sr3Fw63jhaUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Thus, the interpretability of a DNN in the adversarial setting … we try to explain adversarial robustness for deep models from … local scope of explanation of the neural network. In contrast to […},
	note = {36 cites: https://scholar.google.com/scholar?cites=11927189523613990322\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00080,
	author = {P McClure and D Moraczewski and KC Lam and A Thomas and ...},
	type = {CITATION},
	title = {Evaluating adversarial robustness for deep neural network interpretability using fmri decoding},
	journal = {arXiv preprint arXiv …},
	related = {https://scholar.google.com/scholar?q=related:Y1oWG1orn6UJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	note = {1 cites: https://scholar.google.com/scholar?cites=11934305203556604515\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00081,
	author = {S Amini and S Ghaemmaghami},
	title = {Towards improving robustness of deep neural networks to adversarial perturbations},
	journal = {IEEE Transactions on Multimedia},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8970483/?casa_token=PGJOBAHcILMAAAAA:RGcgnDfXyNLdbmsKDoWnMY50PRsWw5ewmtks9_71YCnhNP_tpyNYU0ediu4BTYVj8n-Gr83OGA},
	fulltext = {https://ieeexplore.ieee.org/iel7/6046/4456689/08970483.pdf?casa_token=5W7q3zpU7-oAAAAA:4-mtEbxcOZTFCAwQAvvrLzS2kPQDeRqeRqeOiLzzyTKhHMbmsxzJt4qcjjociutLuIgCgh-4rw},
	related = {https://scholar.google.com/scholar?q=related:pitdiJ4T1BIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… , we show how a deep convolutional neural network (CNN), … enhanced generalization and robustness to adversarial … ] to simultaneously improve robustness and interpretability of …},
	note = {7 cites: https://scholar.google.com/scholar?cites=1356730959358929830\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00082,
	author = {P Le and W Zuidema},
	title = {DoLFIn: Distributions over Latent Features for Interpretability},
	journal = {arXiv preprint arXiv:2011.05295},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2011.05295},
	fulltext = {https://arxiv.org/pdf/2011.05295},
	related = {https://scholar.google.com/scholar?q=related:vB9QXUOsLDQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… the robustness and trustworthiness of the models, but work on neural network interpretability … We propose a novel strategy for achieving interpretability that – in our experiments – avoids …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00083,
	author = {S Srinivas and F Fleuret},
	title = {Rethinking the role of gradient-based attribution methods for model interpretability},
	journal = {arXiv preprint arXiv:2006.09128},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2006.09128},
	fulltext = {https://arxiv.org/pdf/2006.09128},
	related = {https://scholar.google.com/scholar?q=related:reTs4QYwHPEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… algorithms used for neural network visualizations are remarkably … Improving the adversarial robustness and interpretability of … Evaluating the visualization of what a deep neural network …},
	note = {13 cites: https://scholar.google.com/scholar?cites=17373814268606866605\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00084,
	author = {Z Liao and H Pan and X Fan and Y Zhang and ...},
	title = {Multiple wavelet convolutional neural network for short-term load forecasting},
	journal = {IEEE Internet of Things …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9205877/?casa_token=hRcXoUln55kAAAAA:KPDQK1pkWV-ubG8TLI3aNNW3hLrvCZxoIpOu1LYEAtn6y-L52ouNY-U8gnxGFCqRntnOpio5uQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/6488907/9447294/09205877.pdf?casa_token=3qEj4wBQB4kAAAAA:R1k6XldLU8E3C0gh2jRTqI13bb_q1mrpbQRHdq62-Cz6CfLc6ZDdsBEuHFwrDSoMGBYQvFqaqA},
	related = {https://scholar.google.com/scholar?q=related:xeBO836OOogJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… On two public data sets, we verified the performance and robustness of the … robustness of the model by perturbing the input to varying degrees. Finally, we present the interpretability …},
	note = {5 cites: https://scholar.google.com/scholar?cites=9816315013706473669\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00085,
	author = {Y Wang and H Su and B Zhang and X Hu},
	title = {Interpret neural networks by extracting critical subnetworks},
	journal = {IEEE Transactions on Image …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9093114/?casa_token=PolA3s5YV-IAAAAA:frjiU81mn-en4BfJ4ryhAmfaa27FbMyY-Fp9GbdXmAJt5luBtqUuXU0LNHoZuTHE9LyjyGJRGA},
	fulltext = {https://ieeexplore.ieee.org/iel7/83/4358840/09093114.pdf?casa_token=nP9G09hPeEUAAAAA:jtUdbrSWvM6mOi1veoQIc8L5IFUhQAND114H98njEqhr3RDfm2oR06fmzMvL94hejPyUrAH1KQ},
	related = {https://scholar.google.com/scholar?q=related:y7Fpu_xlPMEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… In this paper, we investigate the topic of neural network interpretability from a new perspective … To improve the robustness of the neural network against adversarial attacks, we propose …},
	note = {2 cites: https://scholar.google.com/scholar?cites=13924116284073161163\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00086,
	author = {H Lee and H Bae and S Yoon},
	title = {Gradient masking of label smoothing in adversarial robustness},
	journal = {IEEE Access},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9311250/},
	fulltext = {https://ieeexplore.ieee.org/iel7/6287639/9312710/09311250.pdf},
	related = {https://scholar.google.com/scholar?q=related:eIc5rxApe2YJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… of adversarial accuracy in terms of interpretability aspects. • We … ROBUSTNESS Adversarial perturbations are small perturbations that change the predicted class of a neural network. …},
	note = {2 cites: https://scholar.google.com/scholar?cites=7384541165640058744\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00087,
	author = {J Sun and F Darbehani and M Zaidi and B Wang},
	title = {Saunet: Shape attentive u-net for interpretable medical image segmentation},
	journal = {International Conference on …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-59719-1_77},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-59719-1_77},
	fulltext = {https://arxiv.org/pdf/2001.07645},
	related = {https://scholar.google.com/scholar?q=related:WK8vl7KUN2gJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… interpretability. Thus, we present a new architecture called Shape Attentive U-Net (SAUNet) which focuses on model interpretability and robustness. … -level interpretability and mitigates …},
	note = {54 cites: https://scholar.google.com/scholar?cites=7509634398425165656\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00088,
	author = {E La Malfa and M Wu and L Laurenti and B Wang and ...},
	title = {Assessing robustness of text classification through maximal safe radius computation},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2010.02004},
	fulltext = {https://arxiv.org/pdf/2010.02004},
	related = {https://scholar.google.com/scholar?q=related:qdBEnhLUR1IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… an analysis of robustness trends. We also apply our framework to interpretability analysis and … For each combination of a neural network and embedding, we quantify the MSR against …},
	note = {8 cites: https://scholar.google.com/scholar?cites=5928940610886357161\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00089,
	author = {J Zhang and J Li},
	type = {HTML},
	title = {Testing and verification of neural-network-based safety-critical control software: A systematic literature review},
	journal = {Information and Software Technology},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584920300471},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0950584920300471},
	related = {https://scholar.google.com/scholar?q=related:uIMg7KO6w94J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… high-order themes, namely, assuring robustness of NNs, improving the failure resilience of … the interpretability of NNs. From the industry perspective, improving the interpretability of NNs …},
	note = {18 cites: https://scholar.google.com/scholar?cites=16051878710082569144\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00090,
	author = {A Venzke and S Chatzivasileiadis},
	title = {Verification of neural network behaviour: Formal guarantees for power system applications},
	journal = {IEEE Transactions on Smart …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9141308/?casa_token=HHCt3SsOw1cAAAAA:dC7O8sTkig12lyvbKQILqC7xgPuKVQrIHKgknte_ELNKXYms-bRLHEnt_lvQ7lVW9AF7SqgzMg},
	fulltext = {https://ieeexplore.ieee.org/iel7/5165411/5446437/09141308.pdf?casa_token=Kx_5njB5wW8AAAAA:H4XEqaJEzvxCMhel2HMA6TV5j4n5ia_0e4SLls_T1mulwSpyP5hEj6WxWy-OWqaziB5k6G3gmw},
	related = {https://scholar.google.com/scholar?q=related:Vspyi0J8X2IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… , methods to assess and improve neural network robustness in power systems, and … for a continuous range of neural network inputs. Second, we improve the interpretability of neural …},
	note = {37 cites: https://scholar.google.com/scholar?cites=7088520963753691734\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00091,
	author = {H Sun and L Liang and C Wang and Y Wu and F Yang and M Rong},
	title = {Prediction of the Electrical Strength and Boiling Temperature of the Substitutes for Greenhouse Gas SF₆ Using Neural Network and Random Forest},
	journal = {IEEE Access},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9123755/},
	fulltext = {https://ieeexplore.ieee.org/iel7/6287639/8948470/09123755.pdf},
	related = {https://scholar.google.com/scholar?q=related:wRekLX9EcfEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… , artificial neural network and random forest … interpretability of predictors. Considering the available data are limited, random forest shows superior performance with higher robustness …},
	note = {8 cites: https://scholar.google.com/scholar?cites=17397762148526200769\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00092,
	author = {A Neacsu and JC Pesquet and ...},
	title = {Accuracy-robustness trade-off for positively weighted neural networks},
	journal = {ICASSP 2020-2020 IEEE …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9053803/?casa_token=zaYyKuMbvNYAAAAA:v8r8mV7Aks_4mi3MqO8tdat6nlRMNU-Y10MAnwZ-ZM9kBokM2E--fAd6slLVriprQT6-KXQppg},
	fulltext = {https://ieeexplore.ieee.org/iel7/9040208/9052899/09053803.pdf?casa_token=fWRtN2R4EoUAAAAA:yCN-yWPe09Zq7Yhb94U5-MFANPpvylJ72plKJ_2V8RBCt0jXltGm3WnTXIAO8urTtgCBHT864w},
	related = {https://scholar.google.com/scholar?q=related:seJnDXTBS_IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… for training a feedforward neural network subject to spectral … to improve the network operation interpretability [10], but on … To assess and control the robustness of the neural network, …},
	note = {4 cites: https://scholar.google.com/scholar?cites=17459261084617138865\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00093,
	author = {W Shi and A Shih and A Darwiche and A Choi},
	title = {On tractable representations of binary neural networks},
	journal = {arXiv preprint arXiv:2004.02082},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2004.02082},
	fulltext = {https://arxiv.org/pdf/2004.02082},
	related = {https://scholar.google.com/scholar?q=related:b8IepxOLAq8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… of a neural network’s behavior. First, we consider the task of verifying the robustness of a neural network, and show how we can compute the expected robustness of a neural network, …},
	note = {27 cites: https://scholar.google.com/scholar?cites=12610794823115260527\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00094,
	author = {N Das and H Park and ZJ Wang and F Hohman and ...},
	title = {Bluff: Interactively deciphering adversarial attacks on deep neural networks},
	journal = {2020 IEEE …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9331279/},
	fulltext = {https://arxiv.org/pdf/2009.02608.pdf%5D},
	related = {https://scholar.google.com/scholar?q=related:02eSNlg0KEQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Neural Network Interpretability. Deep neural networks have … [12] propose to quantify interpretability by measuring alignment … Improving the adversarial robustness and interpretability …},
	note = {10 cites: https://scholar.google.com/scholar?cites=4911232947124856787\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00095,
	author = {T Yang and RE Gregg and S Babaeizadeh},
	title = {Detection of strict left bundle branch block by neural network and a method to test detection consistency},
	journal = {Physiological Measurement},
	publisher = {iopscience.iop.org},
	doi = {10.1088/1361-6579/ab6e55},
	url = {https://iopscience.iop.org/article/10.1088/1361-6579/ab6e55/meta?casa_token=-4fDZRFci64AAAAA:J30vRlWTKjvEyaRffVVf5AbxKCrvhoChMew-H4UbWVD_hOVNZAo2hl6B5XosXICY_ajuLl9o77o},
	fulltext = {https://iopscience.iop.org/article/10.1088/1361-6579/ab6e55/pdf?casa_token=x7szA5O3akMAAAAA:0layMnQY7I2VuJsF8wAETUOtuzEABWw6jr_OQvQbUjvF-h1WQavNzG1F_yelDaT0cKXo3wCHCu8},
	related = {https://scholar.google.com/scholar?q=related:NjdC5K9YYvMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… the neural network increased the accuracy by more than 10%. Using the feature set selected by random forest increased the interpretability … the robustness of neural network in detecting …},
	note = {6 cites: https://scholar.google.com/scholar?cites=17537677411406198582\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00096,
	author = {P Bhardwaj},
	title = {Towards adversarially robust knowledge graph embeddings},
	journal = {Proceedings of the AAAI Conference on Artificial …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/7128},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/view/7128/6982},
	related = {https://scholar.google.com/scholar?q=related:zuumsgyedugJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… robustness and evaluating the effect of proposed improvement on their interpretability. … They differ from each other in their neural network architectures and underlying theoretical …},
	note = {3 cites: https://scholar.google.com/scholar?cites=16750749641425218510\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00097,
	author = {H Chen and Y Ji},
	title = {Learning variational word masks to improve the interpretability of neural text classifiers},
	journal = {arXiv preprint arXiv:2010.00667},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2010.00667},
	fulltext = {https://arxiv.org/pdf/2010.00667},
	related = {https://scholar.google.com/scholar?q=related:Is75KD_U99AJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… interpretability as an intrinsic property of neural network models. Furthermore, we hypothesize that neural network mod… Improving the adversarial robustness and interpretability of deep …},
	note = {26 cites: https://scholar.google.com/scholar?cites=15057737246872030754\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00098,
	author = {F Marchetti and E Minisci},
	title = {A hybrid neural network-genetic programming intelligent control approach},
	journal = {… Conference on Bioinspired Methods and Their …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-63710-1_19},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-63710-1_19},
	fulltext = {https://strathprints.strath.ac.uk/74956/1/Marchetti_Minisci_BIOMA2020_A_hybrid_Neural_Network_Genetic_Programming.pdf},
	related = {https://scholar.google.com/scholar?q=related:iPQacWBDKmIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… black box model, GP allows for a greater interpretability of the created model, which is a key … of a NN with the interpretability of GP. Moreover, to improve the robustness of the GP control …},
	note = {3 cites: https://scholar.google.com/scholar?cites=7073540246232298632\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00099,
	author = {D Sharma and A Durand and MA Legault and ...},
	title = {Deep interpretability for GWAS},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2007.01516},
	fulltext = {https://arxiv.org/pdf/2007.01516},
	related = {https://scholar.google.com/scholar?q=related:BaPWrDBc4uUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… In order to test the scalability and robustness of our approach on real data, we perform experiments on genetic data obtained from the UK Biobank (Sec. 3.2). We train several two-layer (…},
	note = {5 cites: https://scholar.google.com/scholar?cites=16564903743550038789\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00100,
	author = {NIH Kuo and M Harandi and N Fourrier and ...},
	title = {An Input Residual Connection for Simplifying Gated Recurrent Neural Networks},
	journal = {… Joint Conference on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9207238/?casa_token=Sbkly-GA938AAAAA:uwFygYiQaelROKIS7ZOy6T89yJW9uR80WFw7wOTPp5784vHt6Pefk37fHdbFoVW0ApTjrUhcPw},
	fulltext = {https://ieeexplore.ieee.org/iel7/9200848/9206590/09207238.pdf?casa_token=LA8Bj7W4D2gAAAAA:SZrr8bOjju02kmE4WnPGxl9cXblvXFa2lL7QK8_qt57_3Pgmsp84dL4ElMevjL9khAh4TFYvRA},
	related = {https://scholar.google.com/scholar?q=related:2pSMwcR4F94J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… In this paper, we increase interpretability by returning to first … provide the GRU memory with robustness and plasticity. … simplest form, updates a neural network with parameters θt via …},
	note = {2 cites: https://scholar.google.com/scholar?cites=16003392587340485850\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00101,
	author = {P Mangla and V Singh and VN Balasubramanian},
	title = {On saliency maps and adversarial robustness},
	journal = {joint European conference on …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-67661-2_17},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-67661-2_17},
	fulltext = {https://arxiv.org/pdf/2006.07828},
	related = {https://scholar.google.com/scholar?q=related:vtvMaVDWAIAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… of interpretability and adversarial robustness, unlike earlier efforts that focus solely on good interpretations or robustness … map to improve robustness while training a neural network. Our …},
	note = {6 cites: https://scholar.google.com/scholar?cites=9223607677715536830\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00102,
	author = {M Singh and N Kumari and P Mangla and A Sinha and ...},
	title = {Attributional robustness training using input-gradient spatial alignment},
	journal = {… on Computer Vision},
	publisher = {Springer},
	doi = {10.1007/978-3-030-58583-9_31},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-58583-9_31},
	fulltext = {https://arxiv.org/pdf/1911.13073},
	related = {https://scholar.google.com/scholar?q=related:oUUvyuvCzVEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Interpretability is an emerging area of research in trustworthy machine learning. Safe … to input, drastically change the neural network’s prediction. While adversarial robustness has been …},
	note = {5 cites: https://scholar.google.com/scholar?cites=5894581805263046049\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00103,
	author = {P Linardatos and V Papastefanopoulos and S Kotsiantis},
	title = {Explainable ai: A review of machine learning interpretability methods},
	journal = {Entropy},
	publisher = {mdpi.com},
	url = {https://www.mdpi.com/936718},
	fulltext = {https://www.mdpi.com/1099-4300/23/1/18/pdf},
	related = {https://scholar.google.com/scholar?q=related:Jbl3MkpMWo4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… to explain predictions that are made by deep neural network by attributing them to the network’s … boundaries in an effort to enhance robustness of decision making systems against such …},
	note = {361 cites: https://scholar.google.com/scholar?cites=10257594982847723813\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00104,
	author = {X Liu and X Han and N Zhang and Q Liu},
	title = {Certified monotonic neural networks},
	journal = {Advances in Neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2020/hash/b139aeda1c2914e3b579aafd3ceeb1bd-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2020/file/b139aeda1c2914e3b579aafd3ceeb1bd-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:3Zr-jKpPe5QJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… To enforce interpretability, we add monotonic constraints … believe higher interpretability indicates higher robustness. … Figure 5: (a) We train a neural network on MNIST with the constraint …},
	note = {25 cites: https://scholar.google.com/scholar?cites=10699232933677275869\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00105,
	author = {G Dao and M Lee},
	title = {Demystifying deep neural networks through interpretation: A survey},
	journal = {arXiv preprint arXiv:2012.07119},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2012.07119},
	fulltext = {https://arxiv.org/pdf/2012.07119},
	related = {https://scholar.google.com/scholar?q=related:AWjVEtFu434J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Differently to the other neural network interpretability methods, adversarial examples focus … interpreting neural network exists between the accuracy and robustness of a neural network …},
	note = {3 cites: https://scholar.google.com/scholar?cites=9143273512735434753\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00106,
	author = {Y Shi and A Deng and M Deng and J Zhu and Y Liu and Q Cheng},
	title = {Enhanced lightweight multiscale convolutional neural network for rolling bearing fault diagnosis},
	journal = {IEEE Access},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9274434/},
	fulltext = {https://ieeexplore.ieee.org/iel7/6287639/8948470/09274434.pdf},
	related = {https://scholar.google.com/scholar?q=related:8mf8Hs9n-pcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… lightweight multiscale convolutional neural network (CNN) for … Secondly, the interpretability of the multiscale learning … feature extraction ability and robustness than single scale CNN, …},
	note = {9 cites: https://scholar.google.com/scholar?cites=10951179583180531698\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00107,
	author = {PK Koo and M Ploenzke},
	type = {HTML},
	title = {Deep learning for inferring transcription factor binding sites},
	journal = {Current opinion in systems biology},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S2452310020300032},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S2452310020300032},
	related = {https://scholar.google.com/scholar?q=related:_PKl_SuDIyEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… , that is, deep, neural network, composed of layers that enable … and advances in model interpretability and then conclude … robustness properties but also improved interpretability [51,63]. …},
	note = {29 cites: https://scholar.google.com/scholar?cites=2387896452398838524\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00108,
	author = {YH Wang and ZN Li and JW Xu and P Yu and T Chen and ...},
	title = {Predicted robustness as qos for deep neural network models},
	journal = {Journal of Computer …},
	publisher = {Springer},
	doi = {10.1007/s11390-020-0482-6},
	url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s11390-020-0482-6\&casa_token=Aq3XYR1WS1sAAAAA:1shOzKCMn9AXBYK0SJGFOX3dXAqwUBO2aQCcI9b14fiV8Lbe3jDxMkCyGoVQEpUKDchGNB-0bBsiwQr3Gw},
	fulltext = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s11390-020-0482-6.pdf\&casa_token=CpXIpmvWdr8AAAAA:PdbiWlXBlXZQmovpDPVf7zLkAcfxhMwPorYuoyztti52zQKNw-ly_ew2oZ-avpmNLdOv_ktgM7a_Rn1k5Q},
	related = {https://scholar.google.com/scholar?q=related:hiQJGIvGHvkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… of interpretability for … robustness predictor for each trained DNN model offline. At runtime, for each input fed to the model, one may use the robustness predictor to predict how robustness …},
	note = {3 cites: https://scholar.google.com/scholar?cites=17951003465451381894\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00109,
	author = {D Anand and NC Kurian and S Dhage and N Kumar and ...},
	type = {HTML},
	title = {Deep learning to estimate human epidermal growth factor receptor 2 status from hematoxylin and eosin-stained breast tissue images},
	journal = {Journal of pathology …},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S2153353922002486},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S2153353922002486},
	related = {https://scholar.google.com/scholar?q=related:NL2gh2xZcd4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… and three deep neural network modules in tandem for robustness and interpretability. Statistical … of multi-stage machine learning pipelines for added robustness and interpretability. …},
	note = {13 cites: https://scholar.google.com/scholar?cites=16028690871455104308\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00110,
	author = {E Wong and T Schneider and J Schmitt and ...},
	title = {Neural network virtual sensors for fuel injection quantities with provable performance specifications},
	journal = {2020 IEEE Intelligent …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9304765/?casa_token=qG-vCWLUeFAAAAAA:67d6UK4kc7D0mVZBCQYqXTxf7GsRTY--qI6EJSaVodxbfqSeAuuqk3VmT2wfXAmLofNLIlGVbQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/9304518/9304528/09304765.pdf?casa_token=eZzJRnD6-xQAAAAA:SIkvTsvdEA3rhqz8jJUjkTiFSorOKunIEpqwC8MNmXwgnEa0zwvf2N9EoaAayLLFK95N8b3HtA},
	related = {https://scholar.google.com/scholar?q=related:SXUgXH3tJysJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… within a limited output range instead, rather than having overall robustness across the entire output range. We show how the robustness of the virtual sensor can be tuned to target a …},
	note = {6 cites: https://scholar.google.com/scholar?cites=3109715190394942793\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00111,
	author = {K Maeda and K Horii and T Ogawa and ...},
	title = {Multi-Task Convolutional Neural Network Leading to High Performance and Interpretability via Attribute Estimation},
	journal = {IEICE Transactions on …},
	publisher = {jstage.jst.go.jp},
	url = {https://www.jstage.jst.go.jp/article/transfun/E103.A/12/E103.A_2020SML0006/_article/-char/ja/},
	fulltext = {https://eprints.lib.hokudai.ac.jp/dspace/bitstream/2115/80378/1/2020-12-01_Multi-ta.pdf},
	related = {https://scholar.google.com/scholar?q=related:RwE_jwS7OJIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… leading to high performance and interpretability via attribute estimation is … interpretability and classification performance is realized. key words: multi-task convolutional neural network, …},
	note = {1 cites: https://scholar.google.com/scholar?cites=10536376956490809671\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00112,
	author = {J Rauber and R Zimmermann and M Bethge and ...},
	type = {PDF},
	title = {Foolbox native: Fast adversarial attacks to benchmark the robustness of machine learning models in pytorch, tensorflow, and jax},
	journal = {Journal of Open Source …},
	publisher = {joss.theoj.org},
	doi = {10.21105/joss.02607},
	url = {https://joss.theoj.org/papers/10.21105/joss.02607.pdf},
	fulltext = {https://joss.theoj.org/papers/10.21105/joss.02607.pdf},
	related = {https://scholar.google.com/scholar?q=related:sTJ7is239DwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Evaluating the adversarial robustness of machine learning models is crucial to … safety, security, and interpretability. Foolbox Native is the first adversarial robustness toolbox that is both …},
	note = {82 cites: https://scholar.google.com/scholar?cites=4392337630012584625\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00113,
	author = {D Bau and JY Zhu and H Strobelt and ...},
	title = {Understanding the role of individual units in a deep neural network},
	journal = {Proceedings of the …},
	publisher = {National Acad Sciences},
	doi = {10.1073/pnas.1907375117},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1907375117},
	fulltext = {https://www.pnas.org/doi/full/10.1073/pnas.1907375117},
	related = {https://scholar.google.com/scholar?q=related:slURF8jFfKYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… First, we analyze a convolutional neural network (CNN) trained on scene classification and discover units that match a diverse set of object concepts. We find evidence that the network …},
	note = {161 cites: https://scholar.google.com/scholar?cites=11996680970579301810\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00114,
	author = {L Yu and XS Gao},
	title = {Improve the Robustness and Accuracy of Deep Neural Network with Normalization},
	journal = {arXiv preprint arXiv:2010.04912},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2010.04912},
	fulltext = {https://arxiv.org/pdf/2010.04912},
	related = {https://scholar.google.com/scholar?q=related:whZF9ZNCpTkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Despite of its huge success, the DNN still has spaces for significant improvements in terms of interpretability, robustness, over-fitting, and existence of adversary samples. …},
	note = {3 cites: https://scholar.google.com/scholar?cites=4153799434561722050\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00115,
	author = {P Esser and R Rombach and B Ommer},
	title = {A disentangling invertible interpretation network for explaining latent representations},
	journal = {Proceedings of the IEEE …},
	publisher = {openaccess.thecvf.com},
	url = {http://openaccess.thecvf.com/content_CVPR_2020/html/Esser_A_Disentangling_Invertible_Interpretation_Network_for_Explaining_Latent_Representations_CVPR_2020_paper.html},
	fulltext = {http://openaccess.thecvf.com/content_CVPR_2020/papers/Esser_A_Disentangling_Invertible_Interpretation_Network_for_Explaining_Latent_Representations_CVPR_2020_paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:bZfg88-FEe0J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… and robustness. To summarize, (i) we present a new approach to the interpretability of neural … Here, we are interested in interpretations of internal representations of a neural network in …},
	note = {36 cites: https://scholar.google.com/scholar?cites=17082581989789308781\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00116,
	author = {Y Sheu},
	type = {HTML},
	title = {Illuminating the black box: interpreting deep neural network models for psychiatric research},
	journal = {Frontiers in Psychiatry},
	publisher = {frontiersin.org},
	doi = {10.3389/fpsyt.2020.551299},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyt.2020.551299/full},
	fulltext = {https://www.frontiersin.org/articles/10.3389/fpsyt.2020.551299/full},
	related = {https://scholar.google.com/scholar?q=related:6suYGu0A-T8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… interpretability for DNNs focus on theoretical and/or engineering perspectives. This article reviews approaches to DNN interpretability … indeed should improve robustness. Nevertheless, …},
	note = {14 cites: https://scholar.google.com/scholar?cites=4609716711943883754\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00117,
	author = {M Reyes and R Meier and S Pereira and CA Silva and ...},
	type = {HTML},
	title = {On the interpretability of artificial intelligence in radiology: challenges and opportunities},
	journal = {Radiology: artificial …},
	publisher = {ncbi.nlm.nih.gov},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7259808/},
	fulltext = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7259808/},
	related = {https://scholar.google.com/scholar?q=related:RibvWUuLboMJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… to comprehend every computation performed in a deep neural network. … interpretability approaches can be used to enhance trust by creating evidence that demonstrates the robustness …},
	note = {129 cites: https://scholar.google.com/scholar?cites=9470660222154384966\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00118,
	author = {B Malolan and A Parekh and F Kazi},
	title = {Explainable deep-fake detection using visual interpretability methods},
	journal = {2020 3rd International …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9092227/?casa_token=XRK0Z5NBOlcAAAAA:IZ4YFwYFrK0gDldZzLXf6HZxjlHbZLHCuQD3Tfdeu3ZHjKd2ZCV1ajn34CXdcFHw786KF8mzRw},
	fulltext = {https://ieeexplore.ieee.org/iel7/9086668/9091976/09092227.pdf?casa_token=4GQJI--1cikAAAAA:63UDbenmPoniXjHb-Sd3GDnqcsNbS_ph_ixFuMQ1i6aD4YoDSpovGf1QLmtjwv_2TqdGK4iUWg},
	related = {https://scholar.google.com/scholar?q=related:DtOYWJimrU4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… doing a backward pass in the deep neural network, thus elucidating why a specific decision … Also, we will test the robustness of our model to Gaussian blur noise and affine transforms. …},
	note = {13 cites: https://scholar.google.com/scholar?cites=5669370679180972814\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00119,
	author = {A Kori and P Natekar and G Krishnamurthi and ...},
	title = {Abstracting deep neural networks into concept graphs for concept level interpretability},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/2008.06457},
	fulltext = {https://arxiv.org/pdf/2008.06457},
	related = {https://scholar.google.com/scholar?q=related:4ggEg7IRWjoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Robustness: Here, we try to evaluate the robustness of the formed clusters. Weights belonging to a specific layer in a neural network can be considered as iid (Giryes, Sapiro, and …},
	note = {4 cites: https://scholar.google.com/scholar?cites=4204692660503709922\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00120,
	author = {E Chou and F Tramer and G Pellegrino},
	title = {Sentinet: Detecting localized universal attacks against deep learning systems},
	journal = {2020 IEEE Security and …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9283822/?casa_token=k264By32AdUAAAAA:ZMYUMyU-Qbd2a-v5ZWyFlW7ONc4DsSRnRPo4EaK9z_mMWzOs4GpDdyAwS0gi7AySTl7PQT4xaw},
	fulltext = {https://ieeexplore.ieee.org/iel7/9283745/9283819/09283822.pdf?casa_token=i3hEyT1Ve-kAAAAA:LHg-IZ0lY4_BepJvttTGVTQf6ATiVG7H4UT9-CSoS2p73WIhPVD6E4DhQgusx8QXlKXr_B6E1w},
	related = {https://scholar.google.com/scholar?q=related:YU2Mfy9Q944J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… the neural network’s susceptibility to attacks and by using techniques from model interpretability and … In a second step, we exploit the strong robustness and generalization properties of …},
	note = {48 cites: https://scholar.google.com/scholar?cites=10301790837566885217\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00121,
	author = {H Liang and Z Ouyang and Y Zeng and H Su and Z He and ST Xia and ...},
	title = {Training interpretable convolutional neural networks by differentiating class-specific filters},
	journal = {… on Computer Vision},
	publisher = {Springer},
	doi = {10.1007/978-3-030-58536-5_37},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-58536-5_37},
	fulltext = {https://arxiv.org/pdf/2007.08194},
	related = {https://scholar.google.com/scholar?q=related:2hQUtl0nyDcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… In contrast, this paper focuses on the interpretability of class-specific filters, and we propose … , which endows model with better interpretability and robustness. We believe CSG is a …},
	note = {11 cites: https://scholar.google.com/scholar?cites=4019505950868378842\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00122,
	author = {Z Wang and Y Su and S Jin and W Shen and J Ren and X Zhang and ...},
	type = {HTML},
	title = {A novel unambiguous strategy of molecular feature extraction in machine learning assisted predictive models for environmental properties},
	journal = {Green …},
	publisher = {pubs.rsc.org},
	url = {https://pubs.rsc.org/en/content/articlehtml/2020/gc/d0gc01122c?casa_token=GIlxW4qAbaoAAAAA:H0L-AgjRWf4nmSgjddFWU6CcoyvthJyMetIf0WjbQahTK0ev8sQSGEluRwkED6QeiOw7tV1TA8On3LY},
	fulltext = {https://pubs.rsc.org/en/content/articlehtml/2020/gc/d0gc01122c?casa_token=GIlxW4qAbaoAAAAA:H0L-AgjRWf4nmSgjddFWU6CcoyvthJyMetIf0WjbQahTK0ev8sQSGEluRwkED6QeiOw7tV1TA8On3LY},
	related = {https://scholar.google.com/scholar?q=related:rG0dO8XpJKgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… is characterized by interpretability and discriminating power … in conjunction with a neural network framework. The structure … In order to improve the robustness of the neural network, the …},
	note = {22 cites: https://scholar.google.com/scholar?cites=12116065930843090348\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00123,
	author = {Y Cao and Z Zhou and C Hu and W He and ...},
	title = {On the interpretability of belief rule-based expert systems},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/9199531/?casa_token=4ioIA5or_a4AAAAA:PDDDYQbueQCBKpzMYh5nlSY4_oHkDBWx8GmMGFdpQjJO0h2OlcvoT8g69-CANKj5YJpdQSlbhw},
	fulltext = {https://ieeexplore.ieee.org/iel7/91/4358784/09199531.pdf?casa_token=H1Q0zODZuukAAAAA:-GKJZSz6ntctiExOhibp6bTGuMsYdbV3l1ypr3dMtBVOVcAx3vq3svTJh_QIwJpGnC4mcgSKwQ},
	related = {https://scholar.google.com/scholar?q=related:UF9jDWuReTkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2020},
	abstract = {… Part II is the comparison of BRB2, BP neural network, and … The robustness analysis result is presented in Table XIV. It can … BRB1, which means that the robustness of the modified P-CMA…},
	note = {11 cites: https://scholar.google.com/scholar?cites=4141501221316026192\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00124,
	author = {C Etmann and S Lunz and P Maass and CB Schönlieb},
	title = {On the connection between adversarial robustness and saliency map interpretability},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1905.04172},
	fulltext = {https://arxiv.org/pdf/1905.04172},
	related = {https://scholar.google.com/scholar?q=related:iodvglxM_HwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… between a neural network’s robustness to adversarial attacks and the interpretability of the … We hypothesized that the perceived increase in interpretability is due to a higher alignment …},
	note = {93 cites: https://scholar.google.com/scholar?cites=9006157315043198858\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00125,
	author = {B Kim and J Seo and T Jeon},
	title = {Bridging adversarial robustness and gradient interpretability},
	journal = {arXiv preprint arXiv:1903.11626},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1903.11626},
	fulltext = {https://arxiv.org/pdf/1903.11626},
	related = {https://scholar.google.com/scholar?q=related:vwVaN0k5I94J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… on quantifying the interpretability of loss gradients. However, quantitative interpretability of logit … Analyzing the effect of norm used to constrain the adversary on the neural network’s …},
	note = {29 cites: https://scholar.google.com/scholar?cites=16006700487228917183\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00126,
	author = {S Sharma and J Henderson and J Ghosh},
	title = {Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models},
	journal = {arXiv preprint arXiv:1905.07857},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1905.07857},
	fulltext = {https://arxiv.org/pdf/1905.07857},
	related = {https://scholar.google.com/scholar?q=related:UBAd0SV2rlgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… We train a 4 layer neural network with an input layer, 2 hidden layers of 20 neurons each, … We train a 6 layer neural network with an input layer, 4 hidden layers of 80 neurons each, and …},
	note = {63 cites: https://scholar.google.com/scholar?cites=6390174826079522896\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00127,
	author = {H Zheng and E Fernandes and A Prakash},
	title = {Analyzing the interpretability robustness of self-explaining models},
	journal = {arXiv preprint arXiv:1905.12429},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1905.12429},
	fulltext = {https://arxiv.org/pdf/1905.12429},
	related = {https://scholar.google.com/scholar?q=related:wEhRyerpHtwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… goal of providing interpretability robustness. We evaluate the interpretability robustness of SEMs … to output labels, they do not consider the robustness of the first stage of the model that …},
	note = {8 cites: https://scholar.google.com/scholar?cites=15861372132254632128\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00128,
	author = {P Pezeshkpour and Y Tian and S Singh},
	title = {Investigating robustness and interpretability of link prediction via adversarial modifications},
	journal = {arXiv preprint arXiv:1905.00563},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1905.00563},
	fulltext = {https://arxiv.org/pdf/1905.00563},
	related = {https://scholar.google.com/scholar?q=related:3NyOHQvxZn4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… and overlook other aspects such as robustness and interpretability. In this paper, … robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability …},
	note = {35 cites: https://scholar.google.com/scholar?cites=9108232326446243036\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00129,
	author = {C Etmann},
	type = {PDF},
	title = {Double Backpropagation with Applications to Robustness and Saliency Map Interpretability},
	publisher = {core.ac.uk},
	url = {https://core.ac.uk/download/pdf/322818060.pdf},
	fulltext = {https://core.ac.uk/download/pdf/322818060.pdf},
	related = {https://scholar.google.com/scholar?q=related:Jin6JpkPWIIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… a neural network’s vulnerability to adversarial attacks. Such an increase in adversarial robustness … to this problem, in this thesis a neural network approach is presented, for which a task-…},
	note = {3 cites: https://scholar.google.com/scholar?cites=9392274173339511078\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00130,
	author = {V Couteaux and O Nempont and G Pizaine and I Bloch},
	title = {Towards interpretability of segmentation networks by analyzing deepdreams},
	journal = {Interpretability of machine …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-33850-3_7},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-33850-3_7},
	fulltext = {https://perso.telecom-paristech.fr/bloch/papers/proceedings/MICCAI-iMIMIC2019-Vincent.pdf},
	related = {https://scholar.google.com/scholar?q=related:fwKUnARSEfIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… Interpretability of a neural network can be expressed as the … how it enables to assess the robustness to a given feature, or … the method correctly assesses the robustness of a network to a …},
	note = {20 cites: https://scholar.google.com/scholar?cites=17442813011542934143\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00131,
	author = {F Wu and T Michel and A Briot},
	title = {Leveraging Model Interpretability and Stability to increase Model Robustness},
	journal = {arXiv preprint arXiv:1910.00387},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1910.00387},
	fulltext = {https://arxiv.org/pdf/1910.00387},
	related = {https://scholar.google.com/scholar?q=related:uT6Cseflwt4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… We present a method to increase the robustness of a Deep Neural Network (DNN) by discriminating its wrong and correct predictions. However there already exist methods in the …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00132,
	author = {A Noack and I Ahern and D Dou and B Li},
	type = {PDF},
	title = {Training Deep Neural Networks for Interpretability and Adversarial Robustness},
	journal = {arXiv preprint arXiv:1912.03430},
	publisher = {researchgate.net},
	url = {https://www.researchgate.net/profile/Adam-Noack/publication/337855671_Training_Deep_Neural_Networks_for_Interpretability_and_Adversarial_Robustness/links/5f3c46c3299bf13404cecf45/Training-Deep-Neural-Networks-for-Interpretability-and-Adversarial-Robustness.pdf},
	fulltext = {https://www.researchgate.net/profile/Adam-Noack/publication/337855671_Training_Deep_Neural_Networks_for_Interpretability_and_Adversarial_Robustness/links/5f3c46c3299bf13404cecf45/Training-Deep-Neural-Networks-for-Interpretability-and-Adversarial-Robustness.pdf},
	related = {https://scholar.google.com/scholar?q=related:sGwUilx_ZG0J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… of which improve adversarial robustness, lead to qualitatively … for robustness could result in some degree of interpretability. … y0 ∈ RK, we adopt a neural network f(·) with ReLU activation…},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00133,
	author = {S Lakshmanan},
	title = {Investigating Interpretability and Robustness of Machine Learning Algorithms},
	publisher = {monami.hs-mittweida.de},
	url = {https://monami.hs-mittweida.de/frontdoor/index/index/docId/11913},
	year = {2019},
	abstract = {… output of such networks, the lack of interpretability makes them black boxes. On the other … the neural network architecture. This prototype layer will train alongside the neural network and …},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00134,
	author = {A Boopathy and S Liu and G Zhang and PY Chen and S Chang and ...},
	title = {Visual Interpretability Alone Helps Adversarial Robustness},
	publisher = {openreview.net},
	url = {https://openreview.net/forum?id=Hyes70EYDB},
	fulltext = {https://openreview.net/pdf?id=Hyes70EYDB},
	related = {https://scholar.google.com/scholar?q=related:XJOVEL0Fp2AJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… from neural network interpretability (namely, making network interpretation maps visually similar), and interpretability … We show that our defense achieves high classification robustness, …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00135,
	author = {F Eitel and K Ritter and ...},
	title = {Testing the robustness of attribution methods for convolutional neural networks in MRI-based Alzheimer's disease classification},
	journal = {Interpretability of …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-33850-3_1},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-33850-3_1},
	fulltext = {https://arxiv.org/pdf/1909.08856},
	related = {https://scholar.google.com/scholar?q=related:v4gguud6UXwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… In this study, we tested the robustness of four attribution methods, namely gradient * input, … We have repeatedly trained a convolutional neural network (CNN) with identical training …},
	note = {45 cites: https://scholar.google.com/scholar?cites=8958076269495355583\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00136,
	author = {J Chen},
	type = {BOOK},
	title = {Towards Interpretability and Robustness of Machine Learning Models},
	publisher = {search.proquest.com},
	url = {https://search.proquest.com/openview/b3152e2d82185a8648394fddcee9f783/1?pq-origsite=gscholar\&cbl=18750\&diss=y},
	fulltext = {https://escholarship.org/content/qt2bj9c0br/qt2bj9c0br.pdf},
	related = {https://scholar.google.com/scholar?q=related:epT3GdqRuCwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… See Figure 1.1 for an illustration of accessible components of the target neural network … The majority of work assumes the target model is a neural network with continuous inputs. …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00137,
	author = {S Lu and Q Li and L Bai and R Wang},
	type = {HTML},
	title = {Performance predictions of ground source heat pump system based on random forest and back propagation neural network models},
	journal = {Energy Conversion and Management},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0196890419308465?casa_token=GBFcR5qXIWUAAAAA:ugEpbN_68I0a7NdGQOrs3Neodmtfv_YL2sJa5gDDcVnZqa3MwRzZWrzPKQ-f6dCD5LWEhFOXFgE},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0196890419308465?casa_token=GBFcR5qXIWUAAAAA:ugEpbN_68I0a7NdGQOrs3Neodmtfv_YL2sJa5gDDcVnZqa3MwRzZWrzPKQ-f6dCD5LWEhFOXFgE},
	related = {https://scholar.google.com/scholar?q=related:edTfM5VdvBkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… neural network (BPNN) from robustness, interpretability, and efficiency. First, since GSHP system involving multiple indicators, the robustness, … According to CV-RMSE, robustness of RF …},
	note = {30 cites: https://scholar.google.com/scholar?cites=1854460041971618937\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00138,
	author = {N Carlini},
	type = {PDF},
	title = {Is ami (attacks meet interpretability) robust to adversarial examples?},
	journal = {arXiv preprint arXiv:1902.02322},
	publisher = {arxiv.org},
	url = {https://arxiv.org/pdf/1902.02322},
	fulltext = {https://arxiv.org/pdf/1902.02322},
	related = {https://scholar.google.com/scholar?q=related:faXrHzMxg4IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… interpretability techniques to a pre-trained neural network, AmI identifies “important” neurons. It then creates a second augmented neural network … claims about robustness, making it …},
	note = {29 cites: https://scholar.google.com/scholar?cites=9404414542528357757\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00139,
	author = {ZT Fernando and J Singh and A Anand},
	title = {A study on the Interpretability of Neural Retrieval Models using DeepSHAP},
	journal = {… of the 42nd International ACM SIGIR …},
	publisher = {dl.acm.org},
	doi = {10.1145/3331184.3331312},
	url = {https://dl.acm.org/doi/abs/10.1145/3331184.3331312?casa_token=fK8otXiRaEcAAAAA:MTj0R8sqKdoOXPOBy8JhwNy0vp-TcpU7ZAzezupRflr_nXwCU4uhn-LvXeuo7zIzrfYSHW2bzo5alw},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3331184.3331312?casa_token=p7MDx2axpMQAAAAA:63o80j95sM-EJFLlZa7T5NmkzpvIoJ5fXEWx-CfvXsm5Khnod6tr7oZlbS300dOS-I7GoPXqXcashA},
	related = {https://scholar.google.com/scholar?q=related:Dbq5mfyJiwQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… attributions by inspecting the neural network architectures. Interpretability in ranking models … with recent works on the lack of robustness in interpretability approaches. We also tried to …},
	note = {33 cites: https://scholar.google.com/scholar?cites=327507115918342669\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00140,
	author = {A Ghorbani and A Abid and J Zou},
	title = {Interpretation of neural networks is fragile},
	journal = {Proceedings of the AAAI conference on …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4252},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/view/4252/4130},
	related = {https://scholar.google.com/scholar?q=related:M_8W3bXus3sJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… We systematically characterize the robustness of interpreta… More precisely, we define the interpretation of neural network to be … To attack interpretability in such networks, we replace the …},
	note = {458 cites: https://scholar.google.com/scholar?cites=8913730552362106675\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00141,
	author = {SA Siddiqui and D Mercier and M Munir and A Dengel and ...},
	title = {Tsviz: Demystification of deep learning models for time-series analysis},
	journal = {IEEE …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8695734/},
	fulltext = {https://ieeexplore.ieee.org/iel7/6287639/6514899/08695734.pdf},
	related = {https://scholar.google.com/scholar?q=related:-u5Dfvh6NuUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… the interpretability of image-centric deep neural network … We assess the proposed framework for interpretability with a … ferent questions: (a) Robustness of the network against adversarial …},
	note = {46 cites: https://scholar.google.com/scholar?cites=16516523891116732154\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00142,
	author = {W Woods and J Chen and C Teuscher},
	type = {HTML},
	title = {Adversarial explanations for understanding image classification decisions and improved neural network robustness},
	journal = {Nature Machine Intelligence},
	publisher = {nature.com},
	url = {https://idp.nature.com/authorize/casa?redirect_uri=https://www.nature.com/articles/s42256-019-0104-6\&casa_token=l-ZwJJMliXUAAAAA:VmwM5VhDz6f8QBNvmOjpBUSE0BXeBFFU7nJqOEJfqqrUyp4MSqipXzBLp418SIer8oxWpLX_W_hMRorOPg},
	fulltext = {https://idp.nature.com/authorize/casa?redirect_uri=https://www.nature.com/articles/s42256-019-0104-6\&casa_token=l-ZwJJMliXUAAAAA:VmwM5VhDz6f8QBNvmOjpBUSE0BXeBFFU7nJqOEJfqqrUyp4MSqipXzBLp418SIer8oxWpLX_W_hMRorOPg},
	related = {https://scholar.google.com/scholar?q=related:RTPLVf0sjRcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… For sensitive problems, such as medical imaging or fraud detection, neural network (NN) … On the ImageNet classification task, we demonstrate a network with an accuracy-robustness …},
	note = {28 cites: https://scholar.google.com/scholar?cites=1697062101166273349\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00143,
	author = {A Khakzar and S Albarqouni and N Navab},
	title = {Learning interpretable features via adversarially robust optimization},
	journal = {International Conference on Medical …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-32226-7_88},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-32226-7_88},
	fulltext = {https://arxiv.org/pdf/1905.03767},
	related = {https://scholar.google.com/scholar?q=related:norhs3J9VDQJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… for robustness against adversarial examples in [2, 6]. In this work, we improve the interpretability of the state of the art neural network … Initially, we propose a baseline neural network …},
	note = {9 cites: https://scholar.google.com/scholar?cites=3770776719613594270\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00144,
	author = {F Hohman and H Park and C Robinson and ...},
	title = {Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations},
	journal = {IEEE transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8807294/?casa_token=8QBVJndvP90AAAAA:Ygj1nMs1QmsCuD43yCf90n2Sy0F3Sw8pp3_Vk2WfuMD-6n4vFgob89QNv2v4CUDlkM2Pn9p4rw},
	fulltext = {https://ieeexplore.ieee.org/iel7/2945/4359476/08807294.pdf?casa_token=1z2swg67LNcAAAAA:WCb4mpMXoCB5oxHQf3Nne5N2CIV8K--k4d2bAQxOoyJushP20lPM_BwTVbg8_p_F8spbzdL-eA},
	related = {https://scholar.google.com/scholar?q=related:9vqeB3eRyl4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… neural network models into compact, interactive visualizations. We present neural network … ’s learned representations and informs future neural network architecture design. The …},
	note = {134 cites: https://scholar.google.com/scholar?cites=6830431725275773686\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00145,
	author = {송기범},
	title = {A Study on Effective Machine Learning Approaches Using Interpretability},
	publisher = {repository.hanyang.ac.kr},
	url = {https://repository.hanyang.ac.kr/handle/20.500.11754/99309},
	year = {2019},
	abstract = {… Neural network-based algorithms popularly used are known for … Two hot keywords, interpretability and explainability, are … , we proposed algorithm to validate robustness of the viii …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00146,
	author = {S Hooker and D Erhan and ...},
	title = {A benchmark for interpretability methods in deep neural networks},
	journal = {Advances in neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2019/hash/fe4b8556000d0f0cae99daa5c5c5a410-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2019/file/fe4b8556000d0f0cae99daa5c5c5a410-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:EN8t9aUbnhkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… Interpretability research is diverse, and many different approaches are used to gain intuition about the function implemented by a neural network. … whether interpretability methods are …},
	note = {310 cites: https://scholar.google.com/scholar?cites=1845943296865459984\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00147,
	author = {F Yu and Z Qin and C Liu and L Zhao and Y Wang and X Chen},
	title = {Interpreting and evaluating neural network robustness},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1905.04270},
	fulltext = {https://arxiv.org/pdf/1905.04270},
	related = {https://scholar.google.com/scholar?q=related:_DFMq0v88wYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… a robustness evaluation metric. Combined with a new normalization method, the metric can invariantly reflect a neural network’s intrinsic robustness … robustness and interpretability of …},
	note = {32 cites: https://scholar.google.com/scholar?cites=501021385494901244\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00148,
	author = {C Liu and R Tomioka and V Cevher},
	title = {On certifying non-uniform bounds against adversarial attacks},
	journal = {International Conference on …},
	publisher = {proceedings.mlr.press},
	url = {http://proceedings.mlr.press/v97/liu19h.html},
	fulltext = {http://proceedings.mlr.press/v97/liu19h/liu19h.pdf},
	related = {https://scholar.google.com/scholar?q=related:6ZBtSS52aYAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… robustness certification problem of neural network … robustness. Further, compared with normal models, the robust models have even larger non-uniform bounds and better interpretability…},
	note = {17 cites: https://scholar.google.com/scholar?cites=9253056850581885161\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00149,
	author = {R Pan},
	title = {Static deep neural network analysis for robustness},
	journal = {Proceedings of the 2019 27th ACM Joint meeting on …},
	publisher = {dl.acm.org},
	doi = {10.1145/3338906.3342502},
	url = {https://dl.acm.org/doi/abs/10.1145/3338906.3342502?casa_token=KkUlALeXRUUAAAAA:02gEcy97gU1P0fAKoSOhNdkM-X_T98c6DCr_SkGDs8kkEEdlGBxupnmxtheY2GXNMUQoqbjqLQej7A},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3338906.3342502?casa_token=0AAkPkXrTLcAAAAA:boF1XMKNWs5mPNKiOfLe_6o6K0t5DSHICiSG1AAEq3J7Rks0aZG6lP8RJ4fN8pk5qioNO1CuaK6FTA},
	related = {https://scholar.google.com/scholar?q=related:Yts1JgY_a1gJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… We observe the improvement of robustness in comparison to … based approach to increase the robustness of DNN based models… our work to retrain the model to increase the robustness. …},
	note = {4 cites: https://scholar.google.com/scholar?cites=6371255393489116002\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00150,
	author = {PK Koo and S Qian and G Kaplun and V Volf and D Kalimeris},
	title = {Robust neural networks are more interpretable for genomics},
	journal = {bioRxiv},
	publisher = {biorxiv.org},
	doi = {10.1101/657437.abstract},
	url = {https://www.biorxiv.org/content/10.1101/657437.abstract},
	fulltext = {https://www.biorxiv.org/content/10.1101/657437.full.pdf},
	related = {https://scholar.google.com/scholar?q=related:6gZe9FKYm0MJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… improves using methods aimed to promote robustness, including … robustness have a small impact on classification performance, but can significantly improve the interpretability …},
	note = {10 cites: https://scholar.google.com/scholar?cites=4871654903985866474\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00151,
	author = {NC Dvornek and X Li and J Zhuang and JS Duncan},
	title = {Jointly discriminative and generative recurrent neural networks for learning from fMRI},
	journal = {International Workshop on …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-32692-0_44},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-32692-0_44},
	fulltext = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7143657/},
	related = {https://scholar.google.com/scholar?q=related:01qZclX9EgIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… Furthermore, network interpretability is unclear. To address these … results by analyzing the robustness of the extracted … Since the number of subjects per site is small for neural network …},
	note = {20 cites: https://scholar.google.com/scholar?cites=149460281093348051\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00152,
	author = {L Szymanski and B McCane and C Atkinson},
	title = {Switched linear projections and inactive state sensitivity for deep neural network interpretability},
	publisher = {openreview.net},
	url = {https://openreview.net/forum?id=SyxjVRVKDB},
	fulltext = {https://openreview.net/pdf?id=SyxjVRVKDB},
	related = {https://scholar.google.com/scholar?q=related:GGc0S4OK-TkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… in a ReLU-based deep neural network in terms of a single … We also propose that for interpretability it is instructive and … very effective interpretability method for deep neural networks. …},
	note = {2 cites: https://scholar.google.com/scholar?cites=4177522425869920024\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00153,
	author = {L Szymanski and B McCane and C Atkinson},
	title = {Switched linear projections for neural network interpretability},
	journal = {arXiv preprint arXiv:1909.11275},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1909.11275},
	fulltext = {https://arxiv.org/pdf/1909.11275},
	related = {https://scholar.google.com/scholar?q=related:oniTvsHU90sJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… els to approximate what a neural network does, or to trace … We also introduce a new approach to interpretability analysis that … further into active and inactive parts of the neural network. …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00154,
	author = {D Rueckert and JA Schnabel},
	title = {Model-based and data-driven strategies in medical image computing},
	journal = {Proceedings of the IEEE},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8867900/?casa_token=NbQhVIRw1hsAAAAA:bc8KO3ffO-k32gRBPKiPR-TaKfrjMWJQPRWBwGM4J4OU1bY2M3F-tIrkSkf7dKDg6Dtmt2wPjQ},
	fulltext = {https://ieeexplore.ieee.org/iel7/5/8944310/08867900.pdf?casa_token=RbgJZ6UK190AAAAA:IdkELyKVAc8RC02_Ixd_VjrayTrzVDfYcEsVrabR5RIeT268E41qpajXZskKjmhvC42ezcQupA},
	related = {https://scholar.google.com/scholar?q=related:Q8BuuT5FUxUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… mance (robustness, accuracy, and speed) as well as in terms of clinical utility (interpretability and … [100] or reconstructing images from features learned by the deep neural network [78]. …},
	note = {34 cites: https://scholar.google.com/scholar?cites=1536648033564803139\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00155,
	author = {M Singh and N Kumari and P Mangla and A Sinha and ...},
	type = {PDF},
	title = {On the benefits of attributional robustness},
	journal = {arXiv preprint arXiv …},
	publisher = {researchgate.net},
	url = {https://www.researchgate.net/profile/Mayank-Singh-30/publication/337671257_On_the_Benefits_of_Attributional_Robustness/links/5e4e2fa3299bf1cdb938dc71/On-the-Benefits-of-Attributional-Robustness.pdf},
	fulltext = {https://www.researchgate.net/profile/Mayank-Singh-30/publication/337671257_On_the_Benefits_of_Attributional_Robustness/links/5e4e2fa3299bf1cdb938dc71/On-the-Benefits-of-Attributional-Robustness.pdf},
	related = {https://scholar.google.com/scholar?q=related:rsL2AHrbAjUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… results in attributional robustness of neural network and helps in … • We introduce the concept of attributional robustness and … adversarial robustness and saliency map interpretability. …},
	note = {6 cites: https://scholar.google.com/scholar?cites=3819856751012266670\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00156,
	author = {M Sotoudeh and AV Thakur},
	title = {Computing linear restrictions of neural networks},
	journal = {Advances in Neural Information …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/9562-computing-linear-restrictions-of-neural-networks},
	fulltext = {https://proceedings.neurips.cc/paper/2019/file/908075ea2c025c335f4865f7db427062-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:mtSLIacTgjEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… of understanding the decision boundaries of a neural network over some infinite set of inputs. … In the process, using EXACTLINE, we discover a strong association between robustness …},
	note = {18 cites: https://scholar.google.com/scholar?cites=3567435463374132378\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00157,
	author = {R Wang and S Lu and Q Li},
	type = {HTML},
	title = {Multi-criteria comprehensive study on predictive algorithm of hourly heating energy consumption for residential buildings},
	journal = {Sustainable Cities and Society},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S2210670719309527?casa_token=z7LTK0pleB8AAAAA:N1_QkWrM2V4OIpcRk6HJkD4WwBQIDVCxQanhevYq3tcs9dvD-d9n5AIGZV1mX_SWKmdVgQfitGI},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S2210670719309527?casa_token=z7LTK0pleB8AAAAA:N1_QkWrM2V4OIpcRk6HJkD4WwBQIDVCxQanhevYq3tcs9dvD-d9n5AIGZV1mX_SWKmdVgQfitGI},
	related = {https://scholar.google.com/scholar?q=related:NE3awtqh3vEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… neural network is presently the most widely used and the most common type of neural network… with respect to accuracy, efficiency, robustness, and interpretability. A residential district in …},
	note = {52 cites: https://scholar.google.com/scholar?cites=17428545568914427188\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00158,
	author = {K Suzuki and M Reyes and T Syeda-Mahmood and E Konukoglu and ...},
	type = {BOOK},
	title = {Interpretability of Machine Intelligence in Medical Image Computing and Multimodal Learning for Clinical Decision Support: Second International Workshop …},
	publisher = {books.google.com},
	url = {https://books.google.com/books?hl=en\&lr=\&id=Vvm4DwAAQBAJ\&oi=fnd\&pg=PR5\&dq=%22robustness%22+%22neural+network%22+%22interpretability%22\&ots=Z9KqpPcRBF\&sig=UYagxInlPdW_IJr_JTCQdj9JmTA},
	related = {https://scholar.google.com/scholar?q=related:XFDZCCNXfWYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… and opportunities of interpretability of machine … , interpretability is closely related with AI safety in healthcare. Besides increasing trust and acceptance by physicians, interpretability of …},
	note = {2 cites: https://scholar.google.com/scholar?cites=7385154771941412956\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00159,
	author = {A Laugros and A Caplier and M Ospici},
	title = {Are adversarial robustness and common perturbation robustness independant attributes?},
	journal = {Proceedings of the IEEE …},
	publisher = {openaccess.thecvf.com},
	url = {http://openaccess.thecvf.com/content_ICCVW_2019/html/RLQ/Laugros_Are_Adversarial_Robustness_and_Common_Perturbation_Robustness_Independant_Attributes__ICCVW_2019_paper.html},
	fulltext = {http://openaccess.thecvf.com/content_ICCVW_2019/papers/RLQ/Laugros_Are_Adversarial_Robustness_and_Common_Perturbation_Robustness_Independant_Attributes__ICCVW_2019_paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:mW1EbYEJ7CsJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… robustness and robustness to common perturbations are independent. Our results make us believe that neural network robustness … the adversarial robustness and interpretability of …},
	note = {20 cites: https://scholar.google.com/scholar?cites=3164915089623248281\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00160,
	author = {F Croce and M Andriushchenko and ...},
	title = {Provable robustness of relu networks via maximization of linear regions},
	journal = {the 22nd International …},
	publisher = {proceedings.mlr.press},
	url = {http://proceedings.mlr.press/v89/croce19a.html},
	fulltext = {http://proceedings.mlr.press/v89/croce19a/croce19a.pdf},
	related = {https://scholar.google.com/scholar?q=related:kENhKaimLnkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… It has been shown that neural network classifiers are not robust. This raises concerns about … , this non-robustness has also implications on follow-up processes like interpretability. How …},
	note = {124 cites: https://scholar.google.com/scholar?cites=8732099968696927120\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00161,
	author = {C Sitawarin and D Wagner},
	title = {On the robustness of deep k-nearest neighbors},
	journal = {2019 IEEE Security and Privacy …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8844626/?casa_token=yC9yM7sUxSkAAAAA:8bjhUA5nNZKpSk6vfu8TdNecE8kx4OcnXFTQg-vLo5As3k0pK9iRRnKxkFzps97p8Bp47wbDDg},
	fulltext = {https://ieeexplore.ieee.org/iel7/8834415/8844588/08844626.pdf?casa_token=EGfPvjBJVg0AAAAA:f39tduWIhp7qWINRbNFwPcj9UGEXsc4-zsdn77SBiwOBelg9JFB0Oj4AzDq17XzcFLomeGJTFg},
	related = {https://scholar.google.com/scholar?q=related:hJlgQ0pupCEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… suggests it offers robustness against adversarial examples, interpretability, and other … produced by the neural network. In this paper, we examine the robustness of DkNN against …},
	note = {35 cites: https://scholar.google.com/scholar?cites=2424183764669208964\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00162,
	author = {H Wang and T Xu and Q Liu and D Lian and E Chen and D Du and ...},
	title = {MCNE: an end-to-end framework for learning multiple conditional network representations of social network},
	journal = {Proceedings of the 25th …},
	publisher = {dl.acm.org},
	doi = {10.1145/3292500.3330931},
	url = {https://dl.acm.org/doi/abs/10.1145/3292500.3330931?casa_token=T2leGKsRTtsAAAAA:wFkYPOjy_StWjbfRFnfh3UWg3YmohHYLWDbr2IVEOWMTrOPl2Ds_p_el4hb99RfJwjgt84c360O4sQ},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3292500.3330931?casa_token=jigi0w0ybLcAAAAA:VANCCM5YedM-Rdot1Bf5v5x87fTB3Cp9tB5NayFMPiBJA5VTI1UJbZdlwadYER5Nn5F9Iq7SYnbWlg},
	related = {https://scholar.google.com/scholar?q=related:0QWeVGVeQyIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… learning tasks with excellent interpretability and robustness. … Specifically, we adopt the framework of Graph Neural Network (GNN… For each layer of graph neural network, we first utilize a …},
	note = {60 cites: https://scholar.google.com/scholar?cites=2468920810033513937\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00163,
	author = {T Cheng},
	title = {Interpretability Study on Deep Learning for Jet Physics at the Large Hadron Collider},
	journal = {arXiv preprint arXiv:1911.01872},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1911.01872},
	fulltext = {https://arxiv.org/pdf/1911.01872},
	related = {https://scholar.google.com/scholar?q=related:NsbzufKogqUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2019},
	abstract = {… aspects such as uncertainties and robustness, would be worth further exploring. … neural network setup. In order to explore the jet splitting mechanisms and corresponding neural network …},
	note = {3 cites: https://scholar.google.com/scholar?cites=11926280523685807670\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00164,
	author = {D Alvarez-Melis and TS Jaakkola},
	title = {On the robustness of interpretability methods},
	journal = {arXiv preprint arXiv:1806.08049},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1806.08049},
	fulltext = {https://arxiv.org/pdf/1806.08049},
	related = {https://scholar.google.com/scholar?q=related:fBBvw8dr2qUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… that robustness can be enforced on existing interpretability approaches. … of robustness that we seek in the next section. Then, in Section 3, we show how various popular interpretability …},
	note = {290 cites: https://scholar.google.com/scholar?cites=11950983066902532220\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00165,
	author = {A Ross and F Doshi-Velez},
	title = {Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
	journal = {Proceedings of the AAAI Conference on …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11504},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/download/11504/11363},
	related = {https://scholar.google.com/scholar?q=related:J6yCNcySaJIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… Datasets and Models We evaluated the robustness of distillation, adversarial training, and … On all datasets, we test a simple convolutional neural network with 5x5x32 and 5x5x64 …},
	note = {442 cites: https://scholar.google.com/scholar?cites=10549843532884126759\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00166,
	author = {D Alvarez Melis and T Jaakkola},
	title = {Towards robust interpretability with self-explaining neural networks},
	journal = {Advances in neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:R6C_9iQ3ha8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… When θ(·) is realized with a neural network, we refer to f as a self-explaining neural network (… , where we observe that the lack of robustness of methods that rely on raw inputs is …},
	note = {489 cites: https://scholar.google.com/scholar?cites=12647575760438009927\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00167,
	author = {G Tao and S Ma and Y Liu and X Zhang},
	title = {Attacks meet interpretability: Attribute-steered detection of adversarial samples},
	journal = {Advances in Neural …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2018/hash/b994697479c5716eda77e8e9713e5f0f-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2018/file/b994697479c5716eda77e8e9713e5f0f-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:fJo4eh34bSkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… We further investigate the robustness of AmI employing different sets of witnesses by excluding those of some attribute during adversary detection. Specifically, we evaluate on four …},
	note = {127 cites: https://scholar.google.com/scholar?cites=2985314933504776828\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00168,
	author = {X Peng and IW Tsang and JT Zhou and H Zhu},
	title = {k-meansnet: When k-means meets differentiable programming},
	journal = {arXiv preprint arXiv:1808.07292},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1808.07292},
	fulltext = {https://arxiv.org/pdf/1808.07292},
	related = {https://scholar.google.com/scholar?q=related:Ks9Vv7v_I5MJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… neural network. From the view of k-means, three highly desired properties are achieved, ie robustness … , and interpretability in neural network which are briefly introduced in this section. …},
	note = {22 cites: https://scholar.google.com/scholar?cites=10602599129594318634\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00169,
	author = {M Graziani and V Andrearczyk and H Müller},
	title = {Regression concept vectors for bidirectional explanations in histopathology},
	journal = {Understanding and Interpreting …},
	publisher = {Springer},
	doi = {10.1007/978-3-030-02628-8_14},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-02628-8_14},
	fulltext = {https://arxiv.org/pdf/1904.04520},
	related = {https://scholar.google.com/scholar?q=related:zH7dXTQ9bGYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… Explanations for deep neural network predictions in terms of domain… We evaluate score robustness and consistency by statistical … Intense research on network interpretability defined the …},
	note = {54 cites: https://scholar.google.com/scholar?cites=7380341184475791052\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00170,
	author = {N Narodytska and S Kasiviswanathan and L Ryzhyk and ...},
	title = {Verifying properties of binarized deep neural networks},
	journal = {Proceedings of the …},
	publisher = {ojs.aaai.org},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/12206},
	fulltext = {https://ojs.aaai.org/index.php/AAAI/article/view/12206/12065},
	related = {https://scholar.google.com/scholar?q=related:OP2fNwVg26sJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… robustness and equivalence. … neural network, not just robustness. (Cheng, Nührenberg, and Ruess 2017a) propose using a MIP solver to verify resilience properties of a neural network. …},
	note = {156 cites: https://scholar.google.com/scholar?cites=12383597175909645624\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00171,
	author = {Z Qin and F Yu and C Liu and X Chen},
	title = {How convolutional neural network see the world-A survey of convolutional neural network visualization methods},
	journal = {arXiv preprint arXiv:1804.11191},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1804.11191},
	fulltext = {https://arxiv.org/pdf/1804.11191},
	related = {https://scholar.google.com/scholar?q=related:X68kSEOXx0AJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… is the lack of network interpretability, especially the limited … network interpretability significantly hinders the robustness … A qualitative way to improve the network interpretability is the …},
	note = {157 cites: https://scholar.google.com/scholar?cites=4667865854021775199\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00172,
	author = {K Xu and S Liu and P Zhao and PY Chen and H Zhang and Q Fan and ...},
	title = {Structured adversarial attack: Towards general implementation and better interpretability},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1808.01664},
	fulltext = {https://arxiv.org/pdf/1808.01664},
	related = {https://scholar.google.com/scholar?q=related:7EOipt7BiiEJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… We also show that StrAttack provides better interpretability (ie, better correspondence with discriminative image regions) through adversarial saliency map (Papernot et al., 2016b) and …},
	note = {125 cites: https://scholar.google.com/scholar?cites=2416957312060244972\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00173,
	author = {N Papernot and P McDaniel},
	title = {Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning},
	journal = {arXiv preprint arXiv:1803.04765},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1803.04765},
	fulltext = {https://arxiv.org/pdf/1803.04765.pdf?fbclid=IwAR2D5gqQf9SL0xRWBctEVrUCL9uUiIf9lZrpPN83YZYbiCGdLAlMlhhaVns},
	related = {https://scholar.google.com/scholar?q=related:WJ_IVrmpMVkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… on interpretability and robustness in (deep) machine learning. … deep neural network (DNN) that underlies it allows the DkNN algorithm to strengthen the interpretability and robustness of …},
	note = {368 cites: https://scholar.google.com/scholar?cites=6427104756724440920\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00174,
	author = {Y Wang and H Su and B Zhang and X Hu},
	title = {Interpret neural networks by identifying critical data routing paths},
	journal = {proceedings of the IEEE …},
	publisher = {openaccess.thecvf.com},
	url = {http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html},
	fulltext = {https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Interpret_Neural_Networks_CVPR_2018_paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:W0fwBc2esZsJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… In this paper, we investigate the topic of neural network interpretability from a new perspective … To improve the robustness of neural network against adversarial attacking, we propose a …},
	note = {55 cites: https://scholar.google.com/scholar?cites=11218922750161733467\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00175,
	author = {F Yu and Z Xu and Y Wang and C Liu and X Chen},
	title = {Towards robust training of neural networks by regularizing adversarial gradients},
	journal = {arXiv preprint arXiv:1805.09370},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1805.09370},
	fulltext = {https://arxiv.org/pdf/1805.09370},
	related = {https://scholar.google.com/scholar?q=related:5G0nWYmFAVcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… To address this problem and improve the robustness of … emerged based on network interpretability, such as transferable … a five-layer neural network with three convolutional layers …},
	note = {13 cites: https://scholar.google.com/scholar?cites=6269438981229211108\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00176,
	author = {K Shi and Y Qiao and W Zhao and Q Wang and M Liu and Z Lu},
	title = {An improved random forest model of short‐term wind‐power forecasting to enhance accuracy, efficiency, and robustness},
	journal = {Wind energy},
	publisher = {Wiley Online Library},
	doi = {10.1002/we.2261},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/we.2261?casa_token=JjW0UscCFLgAAAAA:xi4MyhZI7WUTzmChR-L-hQeLbmIm5HwNxCUsHpRF5bJm0zC3z0UAESIB8deElOzjEY-q05vtfp6RvJJx},
	fulltext = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/we.2261?casa_token=ipYG6CipTlMAAAAA:9-5Mhb5rsy-0bZduzWTEGnoOeaqmRCPs5XBp8Qdgr5mMLs_mXVruNcJ7pbIejfFD7hWBQIxeoHZ1-Vpd},
	related = {https://scholar.google.com/scholar?q=related:9gTtFuRb_sIJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… is difficult to control, resulting in poor interpretability.24 Its credibility needs to be … neural network model increases rapidly, and the numerical stability is not good enough. The robustness …},
	note = {22 cites: https://scholar.google.com/scholar?cites=14050768922637829366\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00177,
	author = {ZC Lipton},
	type = {PDF},
	title = {The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
	journal = {Queue},
	publisher = {dl.acm.org},
	doi = {10.1145/3236386.3241340},
	url = {https://dl.acm.org/doi/pdf/10.1145/3236386.3241340},
	fulltext = {https://dl.acm.org/doi/pdf/10.1145/3236386.3241340},
	related = {https://scholar.google.com/scholar?q=related:aMNh86C6mdYJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… The problem can also arise when you desire robustness to changes in the dynamics … by a neural network, some of the literature focuses instead on explaining what a neural network …},
	note = {3120 cites: https://scholar.google.com/scholar?cites=15463595995994112872\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00178,
	author = {M Ferro and B Fernandes and ...},
	title = {Non-negative Structured Pyramidal Neural Network for Pattern Recognition},
	journal = {2018 International Joint …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8489216/?casa_token=OaZOznpg49AAAAAA:mTuj3728Go9SWkU5h29OlwXCYCiBwZcwKF-lvoBZMQQ00kV8zrJnZqsR5snGA4tG9E4qpVzhoA},
	fulltext = {https://ieeexplore.ieee.org/iel7/8465565/8488986/08489216.pdf?casa_token=qhvcgvkQAEcAAAAA:UVQPbZ4m3rjDUwL09UoN6jMHDGeELb5po7vAnBff4snq8A9EEUjhPRbz5C6pAeIGXQS79LbG0w},
	related = {https://scholar.google.com/scholar?q=related:MuOhq8XvMDkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… impacts on the performance and interpretability of the network. … aiming to obtain better interpretability of the SPNN learning … stability and robustness, while improves the interpretability of …},
	note = {2 cites: https://scholar.google.com/scholar?cites=4121057291311113010\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00179,
	author = {S Saralajew and L Holdijk and M Rees and T Villmann},
	title = {Prototype-based neural network layers: incorporating vector quantization},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1812.01214},
	fulltext = {https://arxiv.org/pdf/1812.01214},
	related = {https://scholar.google.com/scholar?q=related:Mr0_Cy2PU0kJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… Nevertheless, neural networks are lacking robustness and interpretability. Prototype-based vector quantization methods on the other hand are known for being robust and interpretable. …},
	note = {16 cites: https://scholar.google.com/scholar?cites=5283724211460750642\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00180,
	author = {F Yu and C Liu and Y Wang and L Zhao and X Chen},
	title = {Interpreting adversarial robustness: A view from decision surface in input space},
	journal = {arXiv preprint arXiv:1810.00144},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1810.00144},
	fulltext = {https://arxiv.org/pdf/1810.00144},
	related = {https://scholar.google.com/scholar?q=related:c3KTgcq95mUJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… We then propose an adversarial robustness indicator, which can evaluate a neural network’… Improving the adversarial robustness and interpretability of deep neural networks by …},
	note = {18 cites: https://scholar.google.com/scholar?cites=7342764919929139827\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00181,
	author = {A Matyasko and LP Chau},
	title = {Improved network robustness with adversary critic},
	journal = {Advances in Neural Information …},
	publisher = {proceedings.neurips.cc},
	url = {https://proceedings.neurips.cc/paper/2018/hash/f77ecc17109b1b806350eb7e7bbfd861-Abstract.html},
	fulltext = {https://proceedings.neurips.cc/paper/2018/file/f77ecc17109b1b806350eb7e7bbfd861-Paper.pdf},
	related = {https://scholar.google.com/scholar?q=related:62ZjnySvMToJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… ability of deep neural networks, reduces model interpretability, and limits applications of deep … the robustness of two networks with rectified activation: 1) a fully-connected neural network …},
	note = {11 cites: https://scholar.google.com/scholar?cites=4193325299886417643\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00182,
	author = {N Narodytska},
	type = {PDF},
	title = {Formal Analysis of Deep Binarized Neural Networks.},
	journal = {IJCAI},
	publisher = {merascu.github.io},
	url = {https://merascu.github.io/links/Resources/ReadingGroup/Formal%20Analysis%20of%20Deep%20Binarized%20Neural%20Networks.pdf},
	fulltext = {https://merascu.github.io/links/Resources/ReadingGroup/Formal%20Analysis%20of%20Deep%20Binarized%20Neural%20Networks.pdf},
	related = {https://scholar.google.com/scholar?q=related:XcEGQA1SwmsJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… from robustness to properties related to network structure. We consider a general feedforward neural network … First, we look at the robustness property in the context of the classification …},
	note = {21 cites: https://scholar.google.com/scholar?cites=7764858924402393437\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@book{pop00183,
	author = {T Jaakkola and D Alvarez Melis},
	title = {Towards robust interpretability with self-explaining neural networks},
	publisher = {dspace.mit.edu},
	url = {https://dspace.mit.edu/handle/1721.1/137669},
	fulltext = {https://dspace.mit.edu/bitstream/handle/1721.1/137669/8003-towards-robust-interpretability-with-self-explaining-neural-networks.pdf?sequence=2\&isAllowed=y},
	related = {https://scholar.google.com/scholar?q=related:BBjVSeYGTBoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… When θ(·) is realized with a neural network, we refer to f as a self-explaining neural network (… , where we observe that the lack of robustness of methods that rely on raw inputs is …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00184,
	author = {DA Hudson and CD Manning},
	title = {Compositional attention networks for machine reasoning},
	journal = {arXiv preprint arXiv:1803.03067},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1803.03067},
	fulltext = {https://arxiv.org/pdf/1803.03067},
	related = {https://scholar.google.com/scholar?q=related:AXNrIIon61YJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2018},
	abstract = {… We demonstrate the model’s strength, robustness and in… how best to design a neural network to perform the structured … often limits their interpretability and hinders their capacity …},
	note = {418 cites: https://scholar.google.com/scholar?cites=6263143180991689473\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00185,
	author = {A Dhurandhar and V Iyengar and R Luss and ...},
	title = {Tip: Typifying the interpretability of procedures},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1706.02952},
	fulltext = {https://arxiv.org/pdf/1706.02952},
	related = {https://scholar.google.com/scholar?q=related:HCDxmSYtpoAJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… of δinterpretability to account for robustness besides just … as robustness in this case, can be added to better capture … eye, and try to check the robustness of any neural network. The δ is …},
	note = {34 cites: https://scholar.google.com/scholar?cites=9270146526803468316\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00186,
	author = {A Dhurandhar and V Iyengar and R Luss and ...},
	title = {A formal framework to characterize interpretability of procedures},
	journal = {arXiv preprint arXiv …},
	publisher = {arxiv.org},
	url = {https://arxiv.org/abs/1707.03886},
	fulltext = {https://arxiv.org/pdf/1707.03886},
	related = {https://scholar.google.com/scholar?q=related:-RI7vNYlTiwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… The neural network had excellent performance, presumably due to the deep architecture … for δinterpretability that accounts for key concepts such as performance and robustness and …},
	note = {27 cites: https://scholar.google.com/scholar?cites=3192530790063477497\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00187,
	author = {C Olah and A Mordvintsev and L Schubert},
	type = {HTML},
	title = {Feature visualization},
	journal = {Distill},
	publisher = {distill.pub},
	url = {https://distill.pub/2017/feature-visualization/?ref=hackernoon.com},
	fulltext = {https://distill.pub/2017/feature-visualization/?ref=hackernoon.com},
	related = {https://scholar.google.com/scholar?q=related:4607IvvPm34J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… The field of neural network interpretability has formed in response to these concerns. As it … space and a suite of transformation robustness techniques. Images were optimized for 2560 …},
	note = {719 cites: https://scholar.google.com/scholar?cites=9123114147687149027\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00188,
	author = {X Zhang and X Pan and S Wang},
	title = {Fuzzy DBN with rule-based knowledge representation and high interpretability},
	journal = {2017 12th International conference …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/8258762/},
	related = {https://scholar.google.com/scholar?q=related:slLji3kXfEkJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… neural network, the learned features do not change with the changing factors, and have stronger robustness to … it relies on its own unique interpretability, strong learning ability and good …},
	note = {16 cites: https://scholar.google.com/scholar?cites=5295133072686273202\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00189,
	author = {T Kang and W Ding and L Zhang and D Ziemek and K Zarringhalam},
	type = {HTML},
	title = {A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data},
	journal = {BMC bioinformatics},
	publisher = {Springer},
	doi = {10.1186/s12859-017-1984-2;},
	url = {https://link.springer.com/article/10.1186/s12859-017-1984-2;},
	fulltext = {https://link.springer.com/article/10.1186/s12859-017-1984-2;},
	related = {https://scholar.google.com/scholar?q=related:CWrncPov69EJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… in order to increase robustness and reproducibility of omic-scale markers. The integrated group-wise regularization methods increases the interpretability of biological signatures and …},
	note = {29 cites: https://scholar.google.com/scholar?cites=15126236526136486409\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00190,
	author = {X Li and Y Rao and H Xie and RYK Lau and J Yin and ...},
	title = {Bootstrapping social emotion classification with semantically rich hybrid neural networks},
	journal = {IEEE Transactions on …},
	publisher = {ieeexplore.ieee.org},
	url = {https://ieeexplore.ieee.org/abstract/document/7953530/?casa_token=UUmT1s42YYwAAAAA:zywUuMQznV9eGhbV6jfkwti5rmSGyuMJq3k-Ed8o8TvIVyvs6wR-A_p-2Z-L8lqc8IOcumsMGw},
	fulltext = {https://ieeexplore.ieee.org/iel7/5165369/5520654/07953530.pdf?casa_token=dyJ8RcCXSZkAAAAA:jMrTaO_mDM4HwbBXfFTqGSAQ8ILs-qxOsCHlP682X1145FuGdcDmVy6dHdKZp23DtQ_xY22Zrw},
	related = {https://scholar.google.com/scholar?q=related:6cITb6owP1IJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2017},
	abstract = {… knowledge into the neural network to bootstrap its inference power and interpretability. To … Goodfellow, “Improving the robustness of deep neural networks via stability training,” in Proc…},
	note = {50 cites: https://scholar.google.com/scholar?cites=5926509143209001705\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00191,
	author = {S Kundu and KC Sim and MJF Gales},
	title = {Incorporating a Generative Front-End Layer to Deep Neural Network for Noise Robust Automatic Speech Recognition.},
	journal = {INTERSPEECH},
	publisher = {asa.isca-speech.org},
	url = {https://asa.isca-speech.org/archive_v0/Interspeech_2016/pdfs/0760.PDF},
	fulltext = {https://scholar.archive.org/work/dhott4b6svafrfqq6iv35qqyne/access/wayback/http://pdfs.semanticscholar.org/38da/6ace562b700779c3c1109f6bd599323ae603.pdf},
	related = {https://scholar.google.com/scholar?q=related:ibU9mH8OmRsJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2016},
	abstract = {… to Deep Neural Network (DNN) due to the lack of interpretability of … Another direction for noise robustness in DNN-based … adaptation approach for noise robustness by incorporating a …},
	note = {7 cites: https://scholar.google.com/scholar?cites=1988636651638601097\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00192,
	author = {E Lughofer},
	title = {Evolving fuzzy systems—fundamentals, reliability, interpretability, useability, applications},
	journal = {Handbook on Computational Intelligence: Volume 1 …},
	publisher = {World Scientific},
	doi = {10.1142/9789814675017_0003},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789814675017_0003},
	fulltext = {https://www.flll.jku.at/sites/default/files/u6/b2017-v1-ch03_FINAL_PROOFS.pdf},
	related = {https://scholar.google.com/scholar?q=related:s-Zxys15KG8J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2016},
	abstract = {… to guarantee robustness and user-friendliness) as well as an educated interpretability (usually a … Typically, the fuzzy model is transformed into a neural network structure (by introducing …},
	note = {59 cites: https://scholar.google.com/scholar?cites=8009785862050145971\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00193,
	author = {SH Hsu and W Chen and M Hsieh},
	title = {Robustness testing of PLS, LISREL, EQS and ANN-based SEM for measuring customer satisfaction},
	journal = {Total Quality Management \& Business …},
	publisher = {Taylor \& Francis},
	doi = {10.1080/14783360500451465},
	url = {https://www.tandfonline.com/doi/abs/10.1080/14783360500451465},
	fulltext = {https://www.tandfonline.com/doi/pdf/10.1080/14783360500451465},
	related = {https://scholar.google.com/scholar?q=related:OaBQBcJyrkwJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2006},
	abstract = {… First, we conduct the robustness testing of both covariance-… Although previous research conducted the robustness testing … a classic feed-forward neural network trained with the back-…},
	note = {288 cites: https://scholar.google.com/scholar?cites=5525479970468569145\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00194,
	author = {R Guglielmann and L Ironi},
	title = {Generating fuzzy models from deep knowledge: robustness and interpretability issues},
	journal = {… on Symbolic and Quantitative Approaches to …},
	publisher = {Springer},
	doi = {10.1007/11518655_51},
	url = {https://link.springer.com/chapter/10.1007/11518655_51},
	fulltext = {https://www.researchgate.net/profile/Liliana-Ironi/publication/220907592_Generating_Fuzzy_Models_from_Deep_Knowledge_Robustness_and_Interpretability_Issues/links/0c96052fa2e54840d0000000/Generating-Fuzzy-Models-from-Deep-Knowledge-Robustness-and-Interpretability-Issues.pdf},
	related = {https://scholar.google.com/scholar?q=related:dgoiw0n7AZoJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2005},
	abstract = {… Herein, we discuss a revised version of FS-QM that aims to cope with robustness and interpretability problems. To this end, we report results obtained by the application of FS-QM to …},
	note = {6 cites: https://scholar.google.com/scholar?cites=11097427251042585206\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00195,
	author = {R Guglielmann and L Ironi},
	type = {PDF},
	title = {The need for qualitative reasoning in fuzzy modeling: robustness and interpretability issues},
	journal = {Proceedings of the International …},
	publisher = {researchgate.net},
	url = {https://www.researchgate.net/profile/Raffaella-Guglielmann/publication/252691753_The_need_for_qualitative_reasoning_in_fuzzy_modeling_robustness_and_interpretability_issues/links/545ced430cf295b5615e62b1/The-need-for-qualitative-reasoning-in-fuzzy-modeling-robustness-and-interpretability-issues},
	fulltext = {https://www.researchgate.net/profile/Raffaella-Guglielmann/publication/252691753_The_need_for_qualitative_reasoning_in_fuzzy_modeling_robustness_and_interpretability_issues/links/545ced430cf295b5615e62b1/The-need-for-qualitative-reasoning-in-fuzzy-modeling-robustness-and-interpretability-issues},
	related = {https://scholar.google.com/scholar?q=related:6yMkfccqzu4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2004},
	abstract = {… dynamics deal with robustness and interpretability. As for … to significantly improve both robustness and interpretability. The … of the model generalization and interpretability properties is …},
	note = {5 cites: https://scholar.google.com/scholar?cites=17207738262515622891\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00196,
	author = {O Intrator and N Intrator},
	type = {HTML},
	title = {Interpreting neural-network results: a simulation study},
	journal = {Computational statistics \& data analysis},
	publisher = {Elsevier},
	url = {https://www.sciencedirect.com/science/article/pii/S0167947301000160?casa_token=n8Z7zXH7IqoAAAAA:uEsoKLtgsALaH5FA8KYklzU6xA2Y2g2at5aGvZO5JWG5zEWlJYLx8VMEBef1tEW4mdv41qWAYyM},
	fulltext = {https://www.sciencedirect.com/science/article/pii/S0167947301000160?casa_token=n8Z7zXH7IqoAAAAA:uEsoKLtgsALaH5FA8KYklzU6xA2Y2g2at5aGvZO5JWG5zEWlJYLx8VMEBef1tEW4mdv41qWAYyM},
	related = {https://scholar.google.com/scholar?q=related:ptTVcMFCvFcJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	year = {2001},
	abstract = {… The effects of different regularization methods on the robustness of the interpretation are … the interpretation of the neural network model. Using the interpretability methods developed in …},
	note = {115 cites: https://scholar.google.com/scholar?cites=6322001375510516902\&as_sdt=2005\&sciodt=2007\&hl=en},
	note = {Query date: 2022-07-13 14:28:45},
}
@misc{pop00197,
	author = {S ROBUSTNESS},
	type = {CITATION},
	title = {VISUAL INTERPRETABILITY ALONE HELPS ADVER},
	related = {https://scholar.google.com/scholar?q=related:iA-z_sUQUDgJ:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00198,
	author = {H ZHANG},
	type = {PDF},
	title = {A quick tour: Neural Network Interpretability},
	journal = {talep.lis-lab.fr},
	url = {https://talep.lis-lab.fr/seminars/2022-05-09-zhang-SEMINAIRE-POLE-SD.pdf},
	fulltext = {https://talep.lis-lab.fr/seminars/2022-05-09-zhang-SEMINAIRE-POLE-SD.pdf},
	related = {https://scholar.google.com/scholar?q=related:-us-8t8KBb4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	abstract = {… Robustness and improvements … Dimensions of interpretability methods … Dimensions of interpretability methods …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00199,
	author = {YY Yang},
	type = {PDF},
	title = {Adversarial Robustness},
	journal = {yyyang.me},
	url = {http://yyyang.me/docs/research_statement.pdf},
	fulltext = {http://yyyang.me/docs/research_statement.pdf},
	related = {https://scholar.google.com/scholar?q=related:ga_bLs6iHs4J:scholar.google.com/\&scioq=%22robustness%22+%22neural+network%22+%22interpretability%22\&hl=en\&as_sdt=2007},
	abstract = {… possible to further achieve interpretability on top of robustness and accuracy. … a neural network, we expect it to perform similarly to the training examples. However, how a neural network …},
	note = {Query date: 2022-07-13 14:28:45},
}
@article{pop00200,
	author = {MI Idrissi and N Bousquet and F Gamboa and B Iooss and JM Loubes},
	type = {PDF},
	title = {Robustness assessment of black-box models},
	journal = {mascotnum2022.sciencesconf.org},
	url = {https://mascotnum2022.sciencesconf.org/data/pages/poster_Il_Idrissi.pdf},
	fulltext = {https://mascotnum2022.sciencesconf.org/data/pages/poster_Il_Idrissi.pdf},
	abstract = {… About the CIFRE PhD (EDF R\&D and IMT) Development of interpretability methods for machine learning models applied to critical systems, at the crossroads between sensitivity …},
	note = {Query date: 2022-07-13 14:28:45},
}
