Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
16,"Xuanqing Liu, Tesi Xiao, Uc Davis, Qin Cao","How Does Noise Help Robustness? Explanation and Exploration under the Neural SDE Framework",2020,"","","","",1,"2022-07-13 09:26:09","","10.1109/cvpr42600.2020.00036","","",,,,,16,8.00,4,4,2,"Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g., dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE), which naturally incorporates various commonly used regularization mechanisms based on random noise injection. For regularization purposes, our framework includes multiple types of noise patterns, such as dropout, additive, and multiplicative noise, which are common in plain neural networks. We provide some theoretical analyses explaining the improved robustness of our models against input perturbations. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.","",""
8,"Simón C. Smith, S. Ramamoorthy","Counterfactual Explanation and Causal Inference In Service of Robustness in Robot Control",2020,"","","","",2,"2022-07-13 09:26:09","","10.1109/ICDL-EpiRob48136.2020.9278061","","",,,,,8,4.00,4,2,2,"We propose an architecture for training generative models of counterfactual conditionals of the form, ‘can we modify event A to cause B instead of C?’, motivated by applications in robot control. Using an ‘adversarial training’ paradigm, an image-based deep neural network model is trained to produce small and realistic modifications to an original image in order to cause user-defined effects. These modifications can be used in the design process of image-based robust control - to determine the ability of the controller to return to a working regime by modifications in the input space, rather than by adaptation. In contrast to conventional control design approaches, where robustness is quantified in terms of the ability to reject noise, we explore the space of counterfactuals that might cause a certain requirement to be violated, thus proposing an alternative model that might be more expressive in certain robotics applications. So, we propose the generation of counterfactuals as an approach to explanation of black-box models and the envisioning of potential movement paths in autonomous robotic control. Firstly, we demonstrate this approach in a set of classification tasks, using the well known MNIST and CelebFaces Attributes datasets. Then, addressing multi-dimensional regression, we demonstrate our approach in a reaching task with a physical robot, and in a navigation task with a robot in a digital twin simulation.","",""
0,"Simón C. Smith, S. Ramamoorthy","Counterfactual Explanation and Causal in Service of Robustness in Robot Control",2020,"","","","",3,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,2,2,"We propose an architecture for training generative models of counterfactual conditionals of the form, ‘can we modify event A to cause B instead of C?’, motivated by applications in robot control. Using an ‘adversarial training’ paradigm, an image-based deep neural network model is trained to produce small and realistic modifications to an original image in order to cause user-defined effects. These modifications can be used in the design process of image-based robust control to determine the ability of the controller to return to a working regime by modifications in the input space, rather than by adaptation. In contrast to conventional control design approaches, where robustness is quantified in terms of the ability to reject noise, we explore the space of counterfactuals that might cause a certain requirement to be violated, thus proposing an alternative model that might be more expressive in certain robotics applications. So, we propose the generation of counterfactuals as an approach to explanation of black-box models and the envisioning of potential movement paths in autonomous robotic control. Firstly, we demonstrate this approach in a set of classification tasks, using the well known MNIST and CelebFaces Attributes datasets. Then, addressing multi-dimensional regression, we demonstrate our approach in a reaching task with a physical robot, and in a navigation task with a robot in a digital twin simulation.","",""
0,"Pau","Neural network signal understanding for instrumentation",2019,"","","","",4,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,3,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Nuno Calaim, F. Dehmelt, P. J. Gonçalves, Christian K. Machens","The geometry of robustness in spiking neural networks.",2022,"","","","",5,"2022-07-13 09:26:09","","10.7554/eLife.73276","","",,,,,0,0.00,0,4,1,"Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate howneural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons; subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a 'bounding box'. Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synapticweights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we showthat functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks-low-dimensional representations, heterogeneity of tuning, and precise negative feedback-may be key to understanding the robustness of neural systems at the circuit level.","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",6,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",7,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Pau","Neural network signal understanding for instrumentation",2018,"","","","",8,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,4,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Fei Wang","The Evaluation of Public Opinion in the Internet Using Optimized Neural Network and Genetic Algorithm",2016,"","","","",9,"2022-07-13 09:26:09","","10.14257/ASTL.2016.121.11","","",,,,,0,0.00,0,1,6,"Over the past era of time, with the bursting interaction and propagation of the Internet information, collecting emerging plenty of internet information and fining out the hot topic of network public opinion becomes a hotspot research branch. In the paper, we propose a novel model and prototype aiming at evaluating internet public opinions based on neural network (NN). Firstly, a novel evaluation indicator system is proposed and designed based on the characteristics analysis of internet public opinions. Later, we propose a novel evaluation model for the public opinion analysis, the detailed steps are discussed. Finally, we conduct experiment to test the robustness and effectiveness of our proposed methodology with detailed explanation.","",""
4,"Adam Ivankay, Ivan Girardi, Chiara Marchiori, P. Frossard","FAR: A General Framework for Attributional Robustness",2020,"","","","",10,"2022-07-13 09:26:09","","","","",,,,,4,2.00,1,4,2,"Attribution maps have gained popularity as tools for explaining neural networks predictions. By assigning an importance value to each input dimension that represents their influence towards the outcome, they give an intuitive explanation of the decision process. However, recent work has discovered vulnerability of these maps to imperceptible, carefully crafted changes in the input that lead to significantly different attributions, rendering them meaningless. By borrowing notions of traditional adversarial training - a method to achieve robust predictions - we propose a novel framework for attributional robustness (FAR) to mitigate this vulnerability. Central assumption is that similar inputs should yield similar attribution maps, while keeping the prediction of the network constant. Specifically, we define a new generic regularization term and training objective that minimizes the maximal dissimilarity of attribution maps in a local neighbourhood of the input. We then show how current state-of-the-art methods can be recovered through principled instantiations of these objectives. Moreover, we propose two new training methods, AAT and AdvAAT, derived from the framework, that directly optimize for robust attributions and predictions. We showcase the effectivity of our training methods by comparing them to current state-of-the-art attributional robustness approaches on widely used vision datasets. Experiments show that they perform better or comparably to current methods in terms of attributional robustness, while being applicable to any attribution method and input data domain. We finally show that our methods mitigate undesired dependencies of attributional robustness and some training and estimation parameters, which seem to critically affect other methods.","",""
1,"David Morales, Estefanía Talavera, Beatriz Remeseiro","Playing to distraction: towards a robust training of CNN classifiers through visual explanation techniques",2020,"","","","",11,"2022-07-13 09:26:09","","10.1007/s00521-021-06282-2","","",,,,,1,0.50,0,3,2,"","",""
9,"Xupeng Miao, Nezihe Merve Gürel, Wentao Zhang, Zhichao Han, Bo Li, Wei Min, Susie Xi Rao, Hansheng Ren, Yinan Shan, Yingxia Shao, Yujie Wang, Fan Wu, H. Xue, Yaming Yang, Zitao Zhang, Yang Zhao, Shuai Zhang, Yujing Wang, B. Cui, Ce Zhang","DeGNN: Improving Graph Neural Networks with Graph Decomposition",2021,"","","","",12,"2022-07-13 09:26:09","","10.1145/3447548.3467312","","",,,,,9,9.00,1,20,1,"Mining from graph-structured data is an integral component of graph data management. A recent trending technique, graph convolutional network (GCN), has gained momentum in the graph mining field, and plays an essential part in numerous graph-related tasks. Although the emerging GCN optimization techniques bring improvements to specific scenarios, they perform diversely in different applications and introduce many trial-and-error costs for practitioners. Moreover, existing GCN models often suffer from oversmoothing problem. Besides, the entanglement of various graph patterns could lead to non-robustness and harm the final performance of GCNs. In this work, we propose a simple yet efficient graph decomposition approach to improve the performance of general graph neural networks. We first empirically study existing graph decomposition methods and propose an automatic connectivity-ware graph decomposition algorithm, DeGNN. To provide a theoretical explanation, we then characterize GCN from the information-theoretic perspective and show that under certain conditions, the mutual information between the output after l layers and the input of GCN converges to 0 exponentially with respect to l. On the other hand, we show that graph decomposition can potentially weaken the condition of such convergence rate, alleviating the information loss when GCN becomes deeper. Extensive experiments on various academic benchmarks and real-world production datasets demonstrate that graph decomposition generally boosts the performance of GNN models. Moreover, our proposed solution DeGNN achieves state-of-the-art performances on almost all these tasks.","",""
32,"Weijia Shi, Andy Shih, Adnan Darwiche, Arthur Choi","On Tractable Representations of Binary Neural Networks",2020,"","","","",13,"2022-07-13 09:26:09","","10.24963/kr.2020/91","","",,,,,32,16.00,8,4,2,"We consider the compilation of a binary neural network's decision function into tractable representations such as Ordered Binary Decision Diagrams (OBDDs) and Sentential Decision Diagrams (SDDs). Obtaining this function as an OBDD/SDD facilitates the explanation and formal verification of a neural network's behavior. First, we consider the task of verifying the robustness of a neural network, and show how we can compute the expected robustness of a neural network, given an OBDD/SDD representation of it. Next, we consider a more efficient approach for compiling neural networks, based on a pseudo-polynomial time algorithm for compiling a neuron. We then provide a case study in a handwritten digits dataset, highlighting how two neural networks trained from the same dataset can have very high accuracies, yet have very different levels of robustness. Finally, in experiments, we show that it is feasible to obtain compact representations of neural networks as SDDs.","",""
5,"Nuno Calaim, F. Dehmelt, P. J. Gonçalves, Christian K. Machens","Robustness in spiking networks: a geometric perspective",2020,"","","","",14,"2022-07-13 09:26:09","","10.1101/2020.06.15.148338","","",,,,,5,2.50,1,4,2,"Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate how neural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons’ subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a ‘bounding box.’ Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synaptic weights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we show that functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks—low-dimensional representations, heterogeneity of tuning, and precise negative feedback—may be key to understanding the robustness of neural systems at the circuit level.","",""
1,"Deep Patel, P. Sastry","Memorization in Deep Neural Networks: Does the Loss Function Matter?",2021,"","","","",15,"2022-07-13 09:26:09","","10.1007/978-3-030-75765-6_11","","",,,,,1,1.00,1,2,1,"","",""
0,"Junho Kim, Seong-Tae Kim, Seong Tae Kim, Y. Ro","Robust Perturbation for Visual Explanation: Cross-Checking Mask Optimization to Avoid Class Distortion",2021,"","","","",16,"2022-07-13 09:26:09","","10.1109/TIP.2021.3130526","","",,,,,0,0.00,0,4,1,"Along with the outstanding performance of the deep neural networks (DNNs), considerable research efforts have been devoted to finding ways to understand the decision of DNNs structures. In the computer vision domain, visualizing the attribution map is one of the most intuitive and understandable ways to achieve human-level interpretation. Among them, perturbation-based visualization can explain the “black box” property of the given network by optimizing perturbation masks that alter the network prediction of the target class the most. However, existing perturbation methods could make unexpected changes to network predictions after applying a perturbation mask to the input image, resulting in a loss of robustness and fidelity of the perturbation mechanisms. In this paper, we define class distortion as the unexpected changes of the network prediction during the perturbation process. To handle that, we propose a novel visual interpretation framework, Robust Perturbation, which shows robustness against the unexpected class distortion during the mask optimization. With a new cross-checking mask optimization strategy, our proposed framework perturbs the target prediction of the network while upholding the non-target predictions, providing more reliable and accurate visual explanations. We evaluate our framework on three different public datasets through extensive experiments. Furthermore, we propose a new metric for class distortion evaluation. In both quantitative and qualitative experiments, tackling the class distortion problem turns out to enhance the quality and fidelity of the visual explanation in comparison with the existing perturbation-based methods.","",""
57,"Jonathan Peck, J. Roels, B. Goossens, Y. Saeys","Lower bounds on the robustness to adversarial perturbations",2017,"","","","",17,"2022-07-13 09:26:09","","","","",,,,,57,11.40,14,4,5,"The input-output mappings learned by state-of-the-art neural networks are significantly discontinuous. It is possible to cause a neural network used for image recognition to misclassify its input by applying very specific, hardly perceptible perturbations to the input, called adversarial perturbations. Many hypotheses have been proposed to explain the existence of these peculiar samples as well as several methods to mitigate them. A proven explanation remains elusive, however. In this work, we take steps towards a formal characterization of adversarial perturbations by deriving lower bounds on the magnitudes of perturbations necessary to change the classification of neural networks. The bounds are experimentally verified on the MNIST and CIFAR-10 data sets.","",""
0,"","May 07, 2020 Neural network signal",,"","","","",18,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,0,,"-This paper reports on the use of neural signal interpre- tation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, di- agnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data.","",""
0,"Yuanyuan Liu, Zhongkui Sun, Xiaoli Yang, Wei Xu","Rhythmicity and firing modes in modular neuronal network under electromagnetic field",2021,"","","","",19,"2022-07-13 09:26:09","","10.1007/S11071-021-06470-8","","",,,,,0,0.00,0,4,1,"","",""
5,"Hui Liu, Wei Kong, Tianshuang Qiu, Guo-Li Li","A Neural Network Based on Rough Set (RSNN) for Prediction of Solitary Pulmonary Nodules",2009,"","","","",20,"2022-07-13 09:26:09","","10.1109/IJCBS.2009.105","","",,,,,5,0.38,1,4,13,"Although algorithms based on rough set (RS) theory can extract useful decision rules with the effectiveness in dealing with inexact, uncertain or vague information, the deterministic mechanism for the description of error is very simple and the rules generated by RS are often unstable and have low classification accuracy. Neural networks (NN) are considered the most powerful classifier for their low classification error rates and robustness to noise. But NN usually require long time to train the huge amount of data of large databases and lack explanation facilities for their knowledge. Therefore, we combine RS and NN for autonomous decision-making, with high accuracy, robustness to noise, efficiency, and good understandability. First, generate the decision rules based on RS, then construct the NN with the hidden layer representing decision rules, and learn the arguments of the NN with BP algorithm. With the direction of RS, NN needn’t long time for training, and the knowledge buried in their structures and weights can be well explained by decision rule on RS. The proposed algorithm has been tested on a medical data set for patients with solitary pulmonary nodules (SPN).","",""
52,"A. Rivkind, O. Barak","Local Dynamics in Trained Recurrent Neural Networks.",2015,"","","","",21,"2022-07-13 09:26:09","","10.1103/PhysRevLett.118.258101","","",,,,,52,7.43,26,2,7,"Learning a task induces connectivity changes in neural circuits, thereby changing their dynamics. To elucidate task-related neural dynamics, we study trained recurrent neural networks. We develop a mean field theory for reservoir computing networks trained to have multiple fixed point attractors. Our main result is that the dynamics of the network's output in the vicinity of attractors is governed by a low-order linear ordinary differential equation. The stability of the resulting equation can be assessed, predicting training success or failure. As a consequence, networks of rectified linear units and of sigmoidal nonlinearities are shown to have diametrically different properties when it comes to learning attractors. Furthermore, a characteristic time constant, which remains finite at the edge of chaos, offers an explanation of the network's output robustness in the presence of variability of the internal neural dynamics. Finally, the proposed theory predicts state-dependent frequency selectivity in the network response.","",""
0,"Pau","Neural network signal understanding for instrumentation-Instrumentation and Measurement, IEEE Transactions on",2009,"","","","",22,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,13,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
0,"Du Guo-cheng","GSH Fermentation Process Modeling Based on CCTSK Fuzzy Neural Network",2008,"","","","",23,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,1,14,"The prediction accuracy of GSH fermentation process modeling is often deteriorated by noise existing in the corresponding experimental data.In order to circumvent this problem,the CCTSK fuzzy neural network was employed.The results demonstrated that the proposed method has better explanation and robustness,compared with the BP neural network based method.","",""
5,"Cao Jun-xing","RESERVOIR PARAMETER PREDICTION OF NEURAL NETWORK BASED ON PARTICLE SWARM OPTIMIZATION",2007,"","","","",24,"2022-07-13 09:26:09","","","","",,,,,5,0.33,5,1,15,"A Predictive reservoir model with the self-adoption and complicated nonlinear property is set up. Because Multi-layer Feed Forward Neural Networks BP Algorithm exists weakness of getting bogged down in the local optima, stronger robustness and global convergence of PSO Algorithm, this research makes use of the particle swarm optimization (PSO) to improve the neural network, then, on the basis of the Luodai gas field in Sichuan Province, by the computation methods of PSO of the neural network, the reservoir characters(such as porosity, permeability) is forecasted, also the precision is tested and is compared with traditional computation methods of BP and LMBP, by which a obvious geography efficiency superior to traditional explanation methods is obtained, the shortcoming base from BP and LMBP algorithm are effectively overcome.","",""
0,"Yu-hong Xiong, Zhi-yu Wen, Ming-yan Wang, S. Xu, Wei-li Wang, Jian Xiao","[Design and analysis of spectral recognition system based on neural network].",2007,"","","","",25,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,6,15,"The technology of spectral recognition is the foundation of qualitative analysis by spectrum. With the technology of pattern recognition developed, the technology of spectral recognition has been a important tool for quick detection in medicine, environment and petrochemical industry etc. Artificial neural network has many good qualities, such as nonlinear mapping, self-adaptive learning, robustness and fault tolerant ability. It is widely applied in signal procesing, knowledge engineering and pattern recognition etc. The present paper takes spectral signal according with Lambert-Beer' law as object, introduces basic pattern recognition theory of artificial neural network in brief, puts forward spectral recognition method based on multiple features and neural network according to spectral recognition need, makes system design and the basic frame of model, and gives an example for explanation.","",""
25,"L. Pau, F. Johansen","Neural network signal understanding for instrumentation",1990,"","","","",26,"2022-07-13 09:26:09","","10.1109/19.57233","","",,,,,25,0.78,13,2,32,"A report is presented on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation and its performance in terms of correct classification rates and robustness to noise are described. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control using functional link nets is given, and an explanation facility designed to help neural signal understanding is described. The results are compared to those obtained with a knowledge-based signal interpretation system using the same instrument and data. >","",""
0,"Cristea Alexandra, Cristea P, Okamoto T","Revue Roumaine Des Sciencetechnique, Série Électrotechnique Et Énergétique Neural Network Knowledge Extraction",1997,"","","","",27,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,3,25,"The usage of ANNs in ""safety-critical"" domains, which include the economic and financial applications, is hindered by their "" black box ""-type approach, which makes it difficult to verify and debug software that includes ANN components. Significant advantages can be gained by combining the symbolic knowledge of a domain theory (DT), with the empirical sub-symbolic knowledge stored in an ANN trained on examples. Rule extraction adds the needed explanation/comprehension component to the much prized ability of ANN to generalise over a learned set of examples. Compiling rules into the an ANN provides better initial conditions for training the network and can significantly improve the speed of learning. The mixed approach allows building hybrid systems that cooperatively combine ANN and AI techniques, increasing both robustness and flexibility. The paper gives an overview of the bases of ANN knowledge extraction under the form of logical functions. ANN design relations are established.","",""
174,"S. Sreenivasan, I. Fiete","Grid cells generate an analog error-correcting code for singularly precise neural computation",2011,"","","","",28,"2022-07-13 09:26:09","","10.1038/nn.2901","","",,,,,174,15.82,87,2,11,"","",""
0,"M. P. Thompson, C. Kambhampati","Increasing innate robustness in artificial neural networks using redundancy",1995,"","","","",29,"2022-07-13 09:26:09","","10.1049/EL:19951338","","",,,,,0,0.00,0,2,27,"A theoretical explanation of robustness and its relationship with redunduncy is proposed and used to derive a novel and powerful technique which allows the innate robustness of most types of artificial neural network (ANN) to be enhanced to a user-defined degree.","",""
235,"Stanislav Fort, Huiyi Hu, Balaji Lakshminarayanan","Deep Ensembles: A Loss Landscape Perspective",2019,"","","","",30,"2022-07-13 09:26:09","","","","",,,,,235,78.33,78,3,3,"Deep ensembles have been empirically shown to be a promising approach for improving accuracy, uncertainty and out-of-distribution robustness of deep learning models. While deep ensembles were theoretically motivated by the bootstrap, non-bootstrap ensembles trained with just random initialization also perform well in practice, which suggests that there could be other explanations for why deep ensembles work well. Bayesian neural networks, which learn distributions over the parameters of the network, are theoretically well-motivated by Bayesian principles, but do not perform as well as deep ensembles in practice, particularly under dataset shift. One possible explanation for this gap between theory and practice is that popular scalable variational Bayesian methods tend to focus on a single mode, whereas deep ensembles tend to explore diverse modes in function space. We investigate this hypothesis by building on recent work on understanding the loss landscape of neural networks and adding our own exploration to measure the similarity of functions in the space of predictions. Our results show that random initializations explore entirely different modes, while functions along an optimization trajectory or sampled from the subspace thereof cluster within a single mode predictions-wise, while often deviating significantly in the weight space. Developing the concept of the diversity--accuracy plane, we show that the decorrelation power of random initializations is unmatched by popular subspace sampling methods. Finally, we evaluate the relative effects of ensembling, subspace based methods and ensembles of subspace based methods, and the experimental results validate our hypothesis.","",""
153,"Ann-Kathrin Dombrowski, M. Alber, Christopher J. Anders, M. Ackermann, K. Müller, P. Kessel","Explanations can be manipulated and geometry is to blame",2019,"","","","",31,"2022-07-13 09:26:09","","","","",,,,,153,51.00,26,6,3,"Explanation methods aim to make neural networks more trustworthy and interpretable. In this paper, we demonstrate a property of explanation methods which is disconcerting for both of these purposes. Namely, we show that explanations can be manipulated arbitrarily by applying visually hardly perceptible perturbations to the input that keep the network's output approximately constant. We establish theoretically that this phenomenon can be related to certain geometrical properties of neural networks. This allows us to derive an upper bound on the susceptibility of explanations to manipulations. Based on this result, we propose effective mechanisms to enhance the robustness of explanations.","",""
7,"Emanuele La Malfa, A. Zbrzezny, Rhiannon Michelmore, Nicola Paoletti, M. Kwiatkowska","On Guaranteed Optimal Robust Explanations for NLP Models",2021,"","","","",32,"2022-07-13 09:26:09","","10.24963/366","","",,,,,7,7.00,1,5,1,"We build on abduction-based explanations for machine learning and develop a method for computing local explanations for neural network models in natural language processing (NLP). Our explanations comprise a subset of the words of the input text that satisfies two key features: optimality w.r.t. a user-defined cost function, such as the length of explanation, and robustness, in that they ensure prediction invariance for any bounded perturbation in the embedding space of the left-out words. We present two solution algorithms, respectively based on implicit hitting sets and maximum universal subsets, introducing a number of algorithmic improvements to speed up convergence of hard instances. We show how our method can be configured with different perturbation sets in the embedded space and used to detect bias in predictions by enforcing include/exclude constraints on biased terms, as well as to enhance existing heuristic-based NLP explanation frameworks such as Anchors. We evaluate our framework on three widely used sentiment analysis tasks and texts of up to 100 words from SST, Twitter and IMDB datasets, demonstrating the effectiveness of the derived explanations.","",""
1,"Zifan Wang, Matt Fredrikson, Anupam Datta","Boundary Attributions Provide Normal (Vector) Explanations",2021,"","","","",33,"2022-07-13 09:26:09","","","","",,,,,1,1.00,0,3,1,"Recent work on explaining Deep Neural Networks (DNNs) focuses on attributing the model’s output scores to input features. However, when it comes to classification problems, a more fundamental question is how much does each feature contribute to the model’s decision to classify an input instance into a specific class? Our first contribution is Boundary Attribution (BA), a new explanation method to address this question. BA leverages an understanding of the geometry of activation regions. Specifically, they involve computing (and aggregating) normal vectors of the local decision boundaries for the target input. Our second contribution is a set of analytical results connecting adversarial robustness of the network and the quality of gradient-based explanations. Specifically, we prove two theorems for ReLU networks: BA of randomized smoothed networks or robustly trained networks is much closer to non-boundary attribution methods than that in standard networks. These analytics encourage users to improve model robustness for highquality explanations. Finally, we evaluate the proposed methods on ImageNet and show BAs produce more concentrated and sharper visualizations compared with nonboundary ones. We further demonstrate that our method also helps to reduce the sensitivity of attributions to the baseline input if one is required. An example of the implementation is available on Github 1","",""
31,"Haofan Wang, Mengnan Du, Fan Yang, Zijian Zhang","Score-CAM: Improved Visual Explanations Via Score-Weighted Class Activation Mapping",2019,"","","","",34,"2022-07-13 09:26:09","","","","",,,,,31,10.33,8,4,3,"Recently, more and more attention has been drawn into the internal mechanism of the convolutional neural network and on what basis does the network make a specific decision. In this paper, we develop a novel post-hoc visual explanation method called Score-CAM based on class activation mapping. Unlike previous class activation mapping based approaches, Score-CAM gets rid of the dependence on gradient by obtaining the weight of each activation map through its forward passing score on target class, the final result is obtained by a linear combination of weights and activation maps. We demonstrate that Score-CAM achieves better visual performance with less noise and has better stability than Grad-CAM and Grad-CAM++. In the experiment, we rethink issues of previous evaluation metrics and propose a representative evaluation approach Energy- Based Pointing Game to measure the quality of the generated saliency maps. Our approach outperforms previous methods on energy-based pointing game and recognition and shows more robustness under adversarial attack.","",""
1,"Emil Wärnberg","Implementation and Robustness of Hopfield Networks with Spiking Neurons",2014,"","","","",35,"2022-07-13 09:26:09","","","","",,,,,1,0.13,1,1,8,"Computational models of neural activity and neural networks have been an active area of research as long as there have been computers, and have led several important discoveries in the eld of machine learning. One kind of articial network proposed by John J. Hopeld in 1982 has been among the more successful ones, and is still in active use today. It has been suggested that in addition to its merits in machine learning, it could also serve as a foundation of the explanation of human ability of recollection and association. However, Hopeld's original design used a very simplied model of neurons. By using so called integrate-and-remodels, higher realism can be achieved.This report begins with a discussion of mechanistic and quantitative description of neurons, in particular the induction of action potentials, and furthermore why an integrate-and-re model is a reasonable choice for a model of intermediate complexity. By explicitly describing individual spikes, a fundamental but often neglected characteristic of communication between neurons is captured. Integrate-and-re models are included in the Neural Simulation Tool (NEST), and in this report such a neural model is applied to Hopeld networks. Both spike-rate coding and temporal coding are studied, as well as a simple model of synaptic Spike-Timing DependentPlasticity (STDP) for online learning. The networks' robustness is evaluated with respect to changes in (a) global scaling of the synaptic weights, (b) delays in the synaptic connections, (c) level of noise and (d) strength of input stimuli. They are found to be somewhat sensitive, with (a) giving the most denite results, suggesting that the used description of Hopfield networks might not be an immediately plausible biological model. In particular, networks using temporal coding are found to be especially difficult to calibrate. This could reveal a potential weakness in relatively recent and apparently successful models.","",""
23,"Benyou Wang, Qiuchi Li, M. Melucci, D. Song","Semantic Hilbert Space for Text Representation Learning",2019,"","","","",36,"2022-07-13 09:26:09","","10.1145/3308558.3313516","","",,,,,23,7.67,6,4,3,"Capturing the meaning of sentences has long been a challenging task. Current models tend to apply linear combinations of word features to conduct semantic composition for bigger-granularity units e.g. phrases, sentences, and documents. However, the semantic linearity does not always hold in human language. For instance, the meaning of the phrase “ivory tower” cannot be deduced by linearly combining the meanings of “ivory” and “tower”. To address this issue, we propose a new framework that models different levels of semantic units (e.g. sememe, word, sentence, and semantic abstraction) on a single Semantic Hilbert Space, which naturally admits a non-linear semantic composition by means of a complex-valued vector word representation. An end-to-end neural network 1 is proposed to implement the framework in the text classification task, and evaluation results on six benchmarking text classification datasets demonstrate the effectiveness, robustness and self-explanation power of the proposed model. Furthermore, intuitive case studies are conducted to help end users to understand how the framework works.","",""
46,"Y. Gal, Zoubin Ghahramani","Dropout as a Bayesian Approximation: Appendix",2015,"","","","",37,"2022-07-13 09:26:09","","","","",,,,,46,6.57,23,2,7,"We show that a neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to a well known Bayesian model. This interpretation might offer an explanation to some of dropout's key properties, such as its robustness to overfitting. Our interpretation allows us to reason about uncertainty in deep learning, and allows the introduction of the Bayesian machinery into existing deep learning frameworks in a principled way. This document is an appendix for the main paper ""Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"" by Gal and Ghahramani, 2015.","",""
9,"Leilani H. Gilpin, J. Macbeth, Evelyn Florentine","Monitoring Scene Understanders with Conceptual Primitive Decomposition and Commonsense Knowledge",2018,"","","","",38,"2022-07-13 09:26:09","","","","",,,,,9,2.25,3,3,4,"Although there have been many key advancements in connecting text and perception, computergenerated image captions still lack common sense. As a first step towards constraining these perception mechanisms to commonsense judgment, we have developed reasonableness monitors: a wrapper interface that can explain if the descriptive output of an opaque deep neural network is plausible. These monitor a standalone system that uses careful dependency tracking, commonsense knowledge, and conceptual primitives to explain a perceived scene description to be reasonable or not. If such an explanation cannot be made, it is evidence that something unreasonable has been perceived. The development of reasonableness monitors is work towards generalizing that vision, with the intention of developing a system-construction methodology that enhances robustness at run time by dynamic checking and explaining of the behaviors of scene understanders for reasonableness in context.","",""
14,"Tsutomu Hoshino, Daisuke Mitsumoto, Tohru Nagano","Fractal Fitness Landscape and Loss of Robustness in Evolutionary Robot Navigation",1998,"","","","",39,"2022-07-13 09:26:09","","10.1023/A:1008874222544","","",,,,,14,0.58,5,3,24,"","",""
20,"Anthony R. Ward, Gabriela Alarcón, J. Nigg, E. Musser","Variation in Parasympathetic Dysregulation Moderates Short-term Memory Problems in Childhood Attention-Deficit/Hyperactivity Disorder",2015,"","","","",40,"2022-07-13 09:26:09","","10.1007/s10802-015-0054-3","","",,,,,20,2.86,5,4,7,"","",""
6,"R. Masuoka","Noise robustness of EBNN learning",1993,"","","","",41,"2022-07-13 09:26:09","","10.1109/IJCNN.1993.716972","","",,,,,6,0.21,6,1,29,"A variety of methods have recently been proposed for constraining neural networks to fit various constraints while being trained. One such approach is to constrain the function approximated by the network to fit desired slopes, or derivatives. Such slopes may be provided by the designer, as in Simard's character recognizer network which was constrained so that the slope of the output with respect to translations, rotations, etc. of the input should be zero. Alternatively, target slopes may be generated automatically by program as in explanation based neural network (EBNN) learning. While slope information is known to improve generalization, sometimes slope information as well as value information is corrupted by noise. This paper explores the effects of noise in value and slope information on EBNN learning, compared with standard backpropagation. Experimental results show several characteristics of noise robustness of EBNN learning.","",""
91,"J. Shawe-Taylor, N. Cristianini","On the generalization of soft margin algorithms",2002,"","","","",42,"2022-07-13 09:26:09","","10.1109/TIT.2002.802647","","",,,,,91,4.55,46,2,20,"Generalization bounds depending on the margin of a classifier are a relatively new development. They provide an explanation of the performance of state-of-the-art learning systems such as support vector machines (SVMs) and Adaboost. The difficulty with these bounds has been either their lack of robustness or their looseness. The question of whether the generalization of a classifier can be more tightly bounded in terms of a robust measure of the distribution of margin values has remained open for some time. The paper answers this open question in the affirmative and, furthermore, the analysis leads to bounds that motivate the previously heuristic soft margin SVM algorithms as well as justifying the use of the quadratic loss in neural network training algorithms. The results are extended to give bounds for the probability of failing to achieve a target accuracy in regression prediction, with a statistical analysis of ridge regression and Gaussian processes as a special case. The analysis presented in the paper has also lead to new boosting algorithms described elsewhere.","",""
4,"M. Su, Hsiao-Te Chang","Extracting Rules from Composite Neural Networks for Medical Diagnostic Problems",1998,"","","","",43,"2022-07-13 09:26:09","","10.1023/A:1009681803460","","",,,,,4,0.17,2,2,24,"","",""
0,"L. Shtram, S. Policker, A. Geva","The effect of the temperature parameter on convergence in the Boltzmann machines",1996,"","","","",44,"2022-07-13 09:26:09","","10.1109/EEIS.1996.566929","","",,,,,0,0.00,0,3,26,"Boltzmann machines show attractive features in traditional neural network tasks. We tested the robustness of the Boltzmann machine in a non-linear mapping task. The system's errors were classified into several categories and the distribution of errors between the categories was studied. Using simulations, it is demonstrated that limitation of the temperature parameter causes the distribution of the network's errors to be unique and different from its usual error distribution. The phenomenon receives a mathematical explanation rooted in the statistical mechanics basics of the Boltzmann machine. This has applications in designing and evaluating mapping tasks for the Boltzmann machines and can help speed up system convergence, which is known to be a major deficit of the Boltzmann machine.","",""
63,"Nina Pörner, Hinrich Schütze, Benjamin Roth","Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement",2018,"","","","",45,"2022-07-13 09:26:09","","10.18653/v1/P18-1032","","",,,,,63,15.75,21,3,4,"The behavior of deep neural networks (DNNs) is hard to understand. This makes it necessary to explore post hoc explanation methods. We conduct the first comprehensive evaluation of explanation methods for NLP. To this end, we design two novel evaluation paradigms that cover two important classes of NLP problems: small context and large context problems. Both paradigms require no manual annotation and are therefore broadly applicable. We also introduce LIMSSE, an explanation method inspired by LIME that is designed for NLP. We show empirically that LIMSSE, LRP and DeepLIFT are the most effective explanation methods and recommend them for explaining DNNs in NLP.","",""
84,"E. Saad, D. Wunsch","Neural network explanation using inversion",2007,"","","","",46,"2022-07-13 09:26:09","","10.1016/j.neunet.2006.07.005","","",,,,,84,5.60,42,2,15,"","",""
18,"R. Eberhart, R. W. Dobbins","Designing neural network explanation facilities using genetic algorithms",1991,"","","","",47,"2022-07-13 09:26:09","","10.1109/IJCNN.1991.170682","","",,,,,18,0.58,9,2,31,"The authors describe the use of genetic algorithms to provide components of explanation facilities for neural network applications. The genetic algorithm implementation, Genesis, uses a trained backpropagation neural network weight matrix as the genetic algorithm fitness function. Using different combinations of Genesis' run-time options, codebook vectors and decision surfaces are defined for the trained neural network. These vectors and surfaces can then be used as components of a facility that explains how the network is trained, and how it differentiates between classes. Two examples of this methodology are presented and briefly discussed. The first is a network trained to solve the XOR problem. The second is a network trained to diagnose appendicitis.<<ETX>>","",""
22,"Walt Woods, Jack H Chen, C. Teuscher","Adversarial explanations for understanding image classification decisions and improved neural network robustness",2019,"","","","",48,"2022-07-13 09:26:09","","10.1038/s42256-019-0104-6","","",,,,,22,7.33,7,3,3,"","",""
0,"Zhimin Li, Shusen Liu, Xin Yu, K. Bhavya, Jie Cao, Diffenderfer James Daniel, P. Bremer, Valerio Pascucci","""Understanding Robustness Lottery"": A Comparative Visual Analysis of Neural Network Pruning Approaches",2022,"","","","",49,"2022-07-13 09:26:09","","10.48550/arXiv.2206.07918","","",,,,,0,0.00,0,8,1,"Deep learning approaches have provided state-of-the-art performance in many applications by relying on extremely large and heavily overparameterized neural networks. However, such networks have been shown to be very brittle, not generalize well to new uses cases, and are often difficult if not impossible to deploy on resources limited platforms. Model pruning, i.e., reducing the size of the network, is a widely adopted strategy that can lead to more robust and generalizable network – usually orders of magnitude smaller with the same or even improved performance. While there exist many heuristics for model pruning, our understanding of the pruning process remains limited. Empirical studies show that some heuristics improve performance while others can make models more brittle or have other side effects. This work aims to shed light on how different pruning methods alter the network’s internal feature representation, and the corresponding impact on model performance. To provide a meaningful comparison and characterization of model feature space, we use three geometric metrics that are decomposed from the common adopted classification loss. With these metrics, we design a visualization system to highlight the impact of pruning on model prediction as well as the latent feature embedding. The proposed tool provides an environment for exploring and studying differences among pruning methods and between pruned and original model. By leveraging our visualization, the ML researchers can not only identify samples that are fragile to model pruning and data corruption but also obtain insights and explanations on how some pruned models achieve superior robustness performance.","",""
7,"Guangyao Chen, Peixi Peng, Li Ma, Jia Li, Lin Du, Yonghong Tian","Amplitude-Phase Recombination: Rethinking Robustness of Convolutional Neural Networks in Frequency Domain",2021,"","","","",50,"2022-07-13 09:26:09","","10.1109/iccv48922.2021.00051","","",,,,,7,7.00,1,6,1,"Recently, the generalization behavior of Convolutional Neural Networks (CNN) is gradually transparent through explanation techniques with the frequency components decomposition. However, the importance of the phase spectrum of the image for a robust vision system is still ignored. In this paper, we notice that the CNN tends to converge at the local optimum which is closely related to the high-frequency components of the training images, while the amplitude spectrum is easily disturbed such as noises or common corruptions. In contrast, more empirical studies found that humans rely on more phase components to achieve robust recognition. This observation leads to more explanations of the CNN’s generalization behaviors in both robustness to common perturbations and out-of-distribution detection, and motivates a new perspective on data augmentation designed by re-combing the phase spectrum of the current image and the amplitude spectrum of the distracter image. That is, the generated samples force the CNN to pay more attention to the structured information from phase components and keep robust to the variation of the amplitude. Experiments on several image datasets indicate that the proposed method achieves state-of-the-art performances on multiple generalizations and calibration tasks, including adaptability for common corruptions and surface variations, out-of-distribution detection, and adversarial attack. The code is released on github/iCGY96/APR.","",""
36,"Wei He, Yongkun Sun, Zichen Yan, Chenguang Yang, Zhijun Li, O. Kaynak","Disturbance Observer-Based Neural Network Control of Cooperative Multiple Manipulators With Input Saturation",2020,"","","","",51,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2923241","","",,,,,36,18.00,6,6,2,"In this paper, the complex problems of internal forces and position control are studied simultaneously and a disturbance observer-based radial basis function neural network (RBFNN) control scheme is proposed to: 1) estimate the unknown parameters accurately; 2) approximate the disturbance experienced by the system due to input saturation; and 3) simultaneously improve the robustness of the system. More specifically, the proposed scheme utilizes disturbance observers, neural network (NN) collaborative control with an adaptive law, and full state feedback. Utilizing Lyapunov stability principles, it is shown that semiglobally uniformly bounded stability is guaranteed for all controlled signals of the closed-loop system. The effectiveness of the proposed controller as predicted by the theoretical analysis is verified by comparative experimental studies.","",""
0,"Hongwei Zhang, Can Wang, Yuanqing Xia, Tijin Yan","Information Fusion of Topological Structure and Node Features in Graph Neural Network",2021,"","","","",52,"2022-07-13 09:26:09","","10.23919/CCC52363.2021.9550081","","",,,,,0,0.00,0,4,1,"Graph neural networks(GNNs) have shown great popularity and achieved promising performance on various graph-based tasks in the past years. However, there is little work that explores the information fusion mechanism, which plays an import role in GNNs. Besides, datasets in the real world often have noises, which make the information fusion difficult. In this paper, we give an information-theoretic explanation. Specifically, we focus on how the information from topological structures and node features fuses and how different information contributes to the downstream task. Furthermore, we propose a general framework named M-GCN to express the fusion process in GNNs. Graph embeddings and feature graph are introduced to extract the information from topological structure and node features separately in M-GCN. Extensive experiments are conducted on several benchmark datasets and experimental results show that our proposed models are more robust and outperform state-of-the-art methods.","",""
0,"Wanli Liu, Chen Li, Hongzan Sun, Weiming Hu, Hao Chen, Changhao Sun, M. Grzegorzek","Is Image Size Important? A Robustness Comparison of Deep Learning Methods for Multi-scale Cell Image Classification Tasks: from Convolutional Neural Networks to Visual Transformers",2021,"","","","",53,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,7,1,"Cervical cancer is a very common and fatal cancer in women, but it can be prevented through early examination and treatment. Cytopathology images are often used to screen for cancer. Then, because of the possibility of artificial errors due to the large number of this method, the computer-aided diagnosis system based on deep learning is developed. The image input required by the deep learning method is usually consistent, but the size of the clinical medical image is inconsistent. The internal information is lost after resizing the image directly, so it is unreasonable. A lot of research is to directly resize the image, and the results are still robust. In order to find a reasonable explanation, 22 deep learning models are used to process images of different scales, and experiments are conducted on the SIPaKMeD dataset. The conclusion is that the deep learning method is very robust to the size changes of images. This conclusion is also validated on the Herlev dataset.","",""
16,"Ce Zhang, Young-Keun Kim, A. Eskandarian","EEG-inception: an accurate and robust end-to-end neural network for EEG-based motor imagery classification",2021,"","","","",54,"2022-07-13 09:26:09","","10.1088/1741-2552/abed81","","",,,,,16,16.00,5,3,1,"Objective. Classification of electroencephalography (EEG)-based motor imagery (MI) is a crucial non-invasive application in brain–computer interface (BCI) research. This paper proposes a novel convolutional neural network (CNN) architecture for accurate and robust EEG-based MI classification that outperforms the state-of-the-art methods. Approach. The proposed CNN model, namely EEG-inception, is built on the backbone of the inception-time network, which has showed to be highly efficient and accurate for time-series classification. Also, the proposed network is an end-to-end classification, as it takes the raw EEG signals as the input and does not require complex EEG signal-preprocessing. Furthermore, this paper proposes a novel data augmentation method for EEG signals to enhance the accuracy, at least by 3%, and reduce overfitting with limited BCI datasets. Main results. The proposed model outperforms all state-of-the-art methods by achieving the average accuracy of 88.4% and 88.6% on the 2008 BCI Competition IV 2a (four-classes) and 2b datasets (binary-classes), respectively. Furthermore, it takes less than 0.025 s to test a sample suitable for real-time processing. Moreover, the classification standard deviation for nine different subjects achieves the lowest value of 5.5 for the 2b dataset and 7.1 for the 2a dataset, which validates that the proposed method is highly robust. Significance. From the experiment results, it can be inferred that the EEG-inception network exhibits a strong potential as a subject-independent classifier for EEG-based MI tasks.","",""
2,"Lei Gu, R. Wu","Robust Cortical Criticality and Diverse Neural Network Dynamics Resulting from Functional Specification",2020,"","","","",55,"2022-07-13 09:26:09","","10.1101/2020.10.23.352849","","",,,,,2,1.00,1,2,2,"Despite recognized layered structure and increasing evidence for criticality in the cortex, how the specification of input, output and computational layers affects the self-organized criticality has been surprisingly neglected. By constructing heterogeneous structures with a well-accepted model of leaky neurons, we found that the specification can lead to robust criticality almost insensitive to the strength of external stimuli. This naturally unifies the adaptation to strong inputs without extra synaptic plasticity mechanisms. Presence of output neurons constitutes an alternative explanation to subcriticality other than the high frequency inputs. Degree of recurrence is proposed as a network metric to account for the signal termination due to output neurons. Unlike fully recurrent networks where external stimuli always render subcriticality, the dynamics of networks with sufficient feed-forward connections can be driven to criticality and supercriticality. These findings indicate that functional and structural specification and their interplay with external stimuli are of crucial importance for the network dynamics. The robust criticality puts forward networks of the leaky neurons as a promising platform for realizing artificial neural networks that work in the vicinity of critical points.","",""
38,"C. Bechlioulis, G. Rovithakis","A Priori Guaranteed Evolution Within the Neural Network Approximation Set and Robustness Expansion via Prescribed Performance Control",2012,"","","","",56,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2186152","","",,,,,38,3.80,19,2,10,"A neuroadaptive control scheme for strict feedback systems is designed, which is capable of achieving prescribed performance guarantees for the output error while keeping all closed-loop signals bounded, despite the presence of unknown system nonlinearities and external disturbances. The aforementioned properties are induced without resorting to a special initialization procedure or a tricky control gains selection, but addressing through a constructive methodology the longstanding problem in neural network control of a priori guaranteeing that the system states evolve strictly within the compact region in which the approximation capabilities of neural networks hold. Moreover, it is proven that robustness against external disturbances is significantly expanded, with the only practical constraint being the magnitude of the required control effort. A comparative simulation study clarifies and verifies the approach.","",""
56,"Xinqiao Zhao, Hongmiao Zhang, Guilin Zhu, Fengxiang You, S. Kuang, Lining Sun","A Multi-Branch 3D Convolutional Neural Network for EEG-Based Motor Imagery Classification",2019,"","","","",57,"2022-07-13 09:26:09","","10.1109/TNSRE.2019.2938295","","",,,,,56,18.67,9,6,3,"One of the challenges in motor imagery (MI) classification tasks is finding an easy-handled electroencephalogram (EEG) representation method which can preserve not only temporal features but also spatial ones. To fully utilize the features on various dimensions of EEG, a novel MI classification framework is first introduced in this paper, including a new 3D representation of EEG, a multi-branch 3D convolutional neural network (3D CNN) and the corresponding classification strategy. The 3D representation is generated by transforming EEG signals into a sequence of 2D array which preserves spatial distribution of sampling electrodes. The multi-branch 3D CNN and classification strategy are designed accordingly for the 3D representation. Experimental evaluation reveals that the proposed framework reaches state-of-the-art classification kappa value level and significantly outperforms other algorithms by 50% decrease in standard deviation of different subjects, which shows good performance and excellent robustness on different subjects. The framework also shows great performance with only nine sampling electrodes, which can significantly enhance its practicality. Moreover, the multi-branch structure exhibits its low latency and a strong ability in mitigating overfitting issues which often occur in MI classification because of the small training dataset.","",""
0,"Shriya Atmakuri, Tejas Chheda, Dinesh Kandula, Nishant Yadav, Taesung Lee, Hessel Tuinhof","Robustness of Explanation Methods for NLP Models",2022,"","","","",58,"2022-07-13 09:26:09","","10.48550/arXiv.2206.12284","","",,,,,0,0.00,0,6,1,". Explanation methods have emerged as an important tool to highlight the features responsible for the predictions of neural networks. There is mounting evidence that many explanation methods are rather unreliable and susceptible to malicious manipulations. In this paper, we particularly aim to understand the robustness of explanation methods in the context of text modality. We provide initial insights and results towards devising a successful adversarial attack against text explanations. To our knowledge, this is the ﬁrst attempt to evaluate the adversarial robustness of an explanation method. Our experiments show the explanation method can be largely disturbed for up to 86% of the tested samples with small changes in the input sentence and its semantics.","",""
17,"Saima Sharmin, P. Panda, Syed Shakib Sarwar, Chankyu Lee, Wachirawit Ponghiran, K. Roy","A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks",2019,"","","","",59,"2022-07-13 09:26:09","","10.1109/IJCNN.2019.8851732","","",,,,,17,5.67,3,6,3,"In this era of machine learning models, their functionality is being threatened by adversarial attacks. In the face of this struggle for making artificial neural networks robust, finding a model, resilient to these attacks, is very important. In this work, we present, for the first time, a comprehensive analysis of the behavior of more bio-plausible networks, namely Spiking Neural Network (SNN) under state-of-the-art adversarial tests. We perform a comparative study of the accuracy degradation between conventional VGG-9 Artificial Neural Network (ANN) and equivalent spiking network with CIFAR-10 dataset in both whitebox and blackbox setting for different types of single-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We demonstrate that SNNs tend to show more resiliency compared to ANN under blackbox attack scenario. Additionally, we find that SNN robustness is largely dependent on the corresponding training mechanism. We observe that SNNs trained by spike-based backpropagation are more adversarially robust than the ones obtained by ANN-to-SNN conversion rules in several whitebox and blackbox scenarios. Finally, we also propose a simple, yet, effective framework for crafting adversarial attacks from SNNs. Our results suggest that attacks crafted from SNNs following our proposed method are much stronger than those crafted from ANNs.","",""
49,"Peng Wu, Jing Liu, Fang Shen","A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes",2020,"","","","",60,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2933554","","",,,,,49,24.50,16,3,2,"How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations’ diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.","",""
144,"Tong Yang, Ning Sun, He Chen, Yongchun Fang","Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones",2020,"","","","",61,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2910580","","",,,,,144,72.00,36,4,2,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.","",""
24,"S. Tortora, S. Ghidoni, C. Chisari, S. Micera, F. Artoni","Deep learning-based BCI for gait decoding from EEG with LSTM recurrent neural network.",2020,"","","","",62,"2022-07-13 09:26:09","","10.1088/1741-2552/ab9842","","",,,,,24,12.00,5,5,2,"OBJECTIVE Mobile Brain/Body Imaging (MoBI) frameworks allowed the research community to find evidence of cortical involvement at walking initiation and during locomotion. However, the decoding of gait patterns from brain signals remains an open challenge. The aim of this work is to propose and validate a deep learning model to decode gait phases from Electroenchephalography (EEG).   APPROACH A Long-Short Term Memory (LSTM) deep neural network has been trained to deal with time-dependent information within brain signals during locomotion. The EEG signals have been preprocessed by means of Artifacts Subspace Reconstruction (ASR) and Reliable Independent Component Analysis (RELICA) to ensure that classification performance was not affected by movement-related artifacts.   MAIN RESULT The network was evaluated on the dataset of 11 healthy subjects walking on a treadmill. The proposed decoding approach shows a robust reconstruction (AUC>90%) of gait patterns (i.e., swing and stance states) of both legs together, or of each leg independently.   SIGNIFICANCE Our results support for the first time the use of a memory-based deep learning classifier to decode walking activity from non-invasive brain recordings. We suggest that this classifier, exploited in real time, can be a more effective input for devices restoring locomotion in impaired people.","",""
36,"T. Roshni, M. Jha, J. Drisya","Neural network modeling for groundwater-level forecasting in coastal aquifers",2020,"","","","",63,"2022-07-13 09:26:09","","10.1007/s00521-020-04722-z","","",,,,,36,18.00,12,3,2,"","",""
0,"","AGGREGATING EXPLANATION METHODS FOR NEURAL NETWORKS STABILIZES EXPLANATIONS",2019,"","","","",64,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,0,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. The aggregation is more robust and aligns better with the neural network than any single explanation method.. Second, we propose a new approach to evaluating explanation methods that circumvents the need for manual evaluation and is not reliant on the alignment of neural networks and humans decision processes.","",""
40,"Ding Wang, Derong Liu, C. Mu, Yun Zhang","Neural Network Learning and Robust Stabilization of Nonlinear Systems With Dynamic Uncertainties",2018,"","","","",65,"2022-07-13 09:26:09","","10.1109/TNNLS.2017.2749641","","",,,,,40,10.00,10,4,4,"Due to the existence of dynamical uncertainties, it is important to pay attention to the robustness of nonlinear control systems, especially when designing adaptive critic control strategies. In this paper, based on the neural network learning component, the robust stabilization scheme of nonlinear systems with general uncertainties is developed. Through system transformation and employing adaptive critic technique, the approximate optimal controller of the nominal plant can be applied to accomplish robust stabilization for the original uncertain dynamics. The neural network weight vector is very convenient to initialize by virtue of the improved critic learning formulation. Under the action of the approximate optimal control law, the stability issues for the closed-loop form of nominal and uncertain plants are analyzed, respectively. Simulation illustrations via a typical nonlinear system and a practical power system are included to verify the control performance.","",""
25,"Guoyang Liu, Weidong Zhou, Minxing Geng","Automatic Seizure Detection Based on S-Transform and Deep Convolutional Neural Network",2020,"","","","",66,"2022-07-13 09:26:09","","10.1142/S0129065719500242","","",,,,,25,12.50,8,3,2,"Automatic seizure detection is significant for the diagnosis of epilepsy and reducing the massive workload of reviewing continuous EEGs. In this work, a novel approach, combining Stockwell transform (S-transform) with deep Convolutional Neural Networks (CNN), is proposed to detect seizure onsets in long-term intracranial EEG recordings. Primarily, raw EEG data is filtered with wavelet decomposition. Then, S-transform is used to obtain a proper time-frequency representation of each EEG segment. After that, a 15-layer deep CNN using dropout and batch normalization serves as a robust feature extractor and classifier. Finally, smoothing and collar technique are applied to the outputs of CNN to improve the detection accuracy and reduce the false detection rate (FDR). The segment-based and event-based evaluation assessments and receiver operating characteristic (ROC) curves are employed for the performance evaluation on a public EEG database containing 21 patients. A segment-based sensitivity of 97.01% and a specificity of 98.12% are yielded. For the event-based assessment, this method achieves a sensitivity of 95.45% with an FDR of 0.36/h.","",""
27,"Sheng Zhang, W. Zheng","Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment",2018,"","","","",67,"2022-07-13 09:26:09","","10.1109/TNNLS.2017.2761259","","",,,,,27,6.75,14,2,4,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.","",""
33,"Sébastien Bubeck, Mark Sellke","A Universal Law of Robustness via Isoperimetry",2021,"","","","",68,"2022-07-13 09:26:09","","","","",,,,,33,33.00,17,2,1,"Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is necessary if one wants to interpolate the data smoothly. Namely we show that smooth interpolation requires d times more parameters than mere interpolation, where d is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layer neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj.","",""
3,"Yiya Hao, Abdullah Küçük, Anshuman Ganguly, I. Panahi","Spectral Flux-Based Convolutional Neural Network Architecture for Speech Source Localization and Its Real-Time Implementation",2020,"","","","",69,"2022-07-13 09:26:09","","10.1109/ACCESS.2020.3033533","","",,,,,3,1.50,1,4,2,"In this article, we present a real-time convolutional neural network (CNN)-based Speech source localization (SSL) algorithm that is robust to realistic background acoustic conditions (noise and reverberation). We have implemented and tested the proposed method on a prototype (Raspberry Pi) for real-time operation. We have used the combination of the imaginary-real coefficients of the short-time Fourier transform (STFT) and Spectral Flux (SF) with delay-and-sum (DAS) beamforming as the input feature. We have trained the CNN model using noisy speech recordings collected from different rooms and inference on an unseen room. We provide quantitative comparison with five other previously published SSL algorithms under several realistic noisy conditions, and show significant improvements by incorporating the Spectral Flux (SF) with beamforming as an additional feature to learn temporal variation in speech spectra. We perform real-time inferencing of our CNN model on the prototyped platform with low latency (21 milliseconds (ms) per frame with a frame length of 30 ms) and high accuracy (i.e. 89.68% under Babble noise condition at 5dB SNR). Lastly, we provide a detailed explanation of real-time implementation and on-device performance (including peak power consumption metrics) that sets this work apart from previously published works. This work has several notable implications for improving the audio-processing algorithms for portable battery-operated Smart loudspeakers and hearing improvement (HI) devices.","",""
2,"Chirag Agarwal, Bo Dong, D. Schonfeld, A. Hoogs","An Explainable Adversarial Robustness Metric for Deep Learning Neural Networks",2018,"","","","",70,"2022-07-13 09:26:09","","","","",,,,,2,0.50,1,4,4,"Deep Neural Networks(DNN) have excessively advanced the field of computer vision by achieving state of the art performance in various vision tasks. These results are not limited to the field of vision but can also be seen in speech recognition and machine translation tasks. Recently, DNNs are found to poorly fail when tested with samples that are crafted by making imperceptible changes to the original input images. This causes a gap between the validation and adversarial performance of a DNN. An effective and generalizable robustness metric for evaluating the performance of DNN on these adversarial inputs is still missing from the literature. In this paper, we propose Noise Sensitivity Score (NSS), a metric that quantifies the performance of a DNN on a specific input under different forms of fix-directional attacks. An insightful mathematical explanation is provided for deeply understanding the proposed metric. By leveraging the NSS, we also proposed a skewness based dataset robustness metric for evaluating a DNN's adversarial performance on a given dataset. Extensive experiments using widely used state of the art architectures along with popular classification datasets, such as MNIST, CIFAR-10, CIFAR-100, and ImageNet, are used to validate the effectiveness and generalization of our proposed metrics. Instead of simply measuring a DNN's adversarial robustness in the input domain, as previous works, the proposed NSS is built on top of insightful mathematical understanding of the adversarial attack and gives a more explicit explanation of the robustness.","",""
54,"M. Pezeshki, Sekouba Kaba, Y. Bengio, Aaron C. Courville, Doina Precup, Guillaume Lajoie","Gradient Starvation: A Learning Proclivity in Neural Networks",2020,"","","","",71,"2022-07-13 09:26:09","","","","",,,,,54,27.00,9,6,2,"We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments.","",""
83,"Juyeon Heo, Sunghwan Joo, Taesup Moon","Fooling Neural Network Interpretations via Adversarial Model Manipulation",2019,"","","","",72,"2022-07-13 09:26:09","","","","",,,,,83,27.67,28,3,3,"We ask whether the neural network interpretation methods can be fooled via adversarial model manipulation, which is defined as a model fine-tuning step that aims to radically alter the explanations without hurting the accuracy of the original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating the interpretation results directly in the penalty term of the objective function for fine-tuning, we show that the state-of-the-art saliency map based interpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with our model manipulation. We propose two types of fooling, Passive and Active, and demonstrate such foolings generalize well to the entire validation set as well as transfer to other interpretation methods. Our results are validated by both visually showing the fooled explanations and reporting quantitative metrics that measure the deviations from the original explanations. We claim that the stability of neural network interpretation method with respect to our adversarial model manipulation is an important criterion to check for developing robust and reliable neural network interpretation method.","",""
31,"Y. Nakamura, O. Hasegawa","Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data",2017,"","","","",73,"2022-07-13 09:26:09","","10.1109/TNNLS.2015.2489225","","",,,,,31,6.20,16,2,5,"With the ongoing development and expansion of communication networks and sensors, massive amounts of data are continuously generated in real time from real environments. Beforehand, prediction of a distribution underlying such data is difficult; furthermore, the data include substantial amounts of noise. These factors make it difficult to estimate probability densities. To handle these issues and massive amounts of data, we propose a nonparametric density estimator that rapidly learns data online and has high robustness. Our approach is an extension of both kernel density estimation (KDE) and a self-organizing incremental neural network (SOINN); therefore, we call our approach KDESOINN. An SOINN provides a clustering method that learns about the given data as networks of prototype of data; more specifically, an SOINN can learn the distribution underlying the given data. Using this information, KDESOINN estimates the probability density function. The results of our experiments show that KDESOINN outperforms or achieves performance comparable to the current state-of-the-art approaches in terms of robustness, learning time, and accuracy.","",""
52,"L. Arras, Ahmed Osman, K. Müller, W. Samek","Evaluating Recurrent Neural Network Explanations",2019,"","","","",74,"2022-07-13 09:26:09","","10.18653/v1/W19-4813","","",,,,,52,17.33,13,4,3,"Recently, several methods have been proposed to explain the predictions of recurrent neural networks (RNNs), in particular of LSTMs. The goal of these methods is to understand the network’s decisions by assigning to each input variable, e.g., a word, a relevance indicating to which extent it contributed to a particular prediction. In previous works, some of these methods were not yet compared to one another, or were evaluated only qualitatively. We close this gap by systematically and quantitatively comparing these methods in different settings, namely (1) a toy arithmetic task which we use as a sanity check, (2) a five-class sentiment prediction of movie reviews, and besides (3) we explore the usefulness of word relevances to build sentence-level representations. Lastly, using the method that performed best in our experiments, we show how specific linguistic phenomena such as the negation in sentiment analysis reflect in terms of relevance patterns, and how the relevance visualization can help to understand the misclassification of individual samples.","",""
23,"Hao Li, S. Misra, Jiabo He","Neural network modeling of in situ fluid-filled pore size distributions in subsurface shale reservoirs under data constraints",2019,"","","","",75,"2022-07-13 09:26:09","","10.1007/s00521-019-04124-w","","",,,,,23,7.67,8,3,3,"","",""
17,"A. A. Khater, Ahmad M. El-Nagar, M. El-Bardini, N. El-Rabaie","Online learning based on adaptive learning rate for a class of recurrent fuzzy neural network",2019,"","","","",76,"2022-07-13 09:26:09","","10.1007/s00521-019-04372-w","","",,,,,17,5.67,4,4,3,"","",""
22,"Arpan Jain, Apoorva Mishra, A. Shukla, R. Tiwari","A Novel Genetically Optimized Convolutional Neural Network for Traffic Sign Recognition: A New Benchmark on Belgium and Chinese Traffic Sign Datasets",2019,"","","","",77,"2022-07-13 09:26:09","","10.1007/s11063-019-09991-x","","",,,,,22,7.33,6,4,3,"","",""
37,"C. Pham, Yaonan Wang","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",78,"2022-07-13 09:26:09","","10.1007/s00521-015-1873-4","","",,,,,37,6.17,19,2,6,"","",""
14,"M. Serrurier, F. Mamalet, Alberto Gonz'alez-Sanz, Thibaut Boissin, Jean-Michel Loubes, E. Barrio","Achieving robustness in classification using optimal transport with hinge regularization",2020,"","","","",79,"2022-07-13 09:26:09","","10.1109/CVPR46437.2021.00057","","",,,,,14,7.00,2,6,2,"Adversarial examples have pointed out Deep Neural Network’s vulnerability to small local noise. It has been shown that constraining their Lipschitz constant should enhance robustness, but make them harder to learn with classical loss functions. We propose a new framework for binary classification, based on optimal transport, which integrates this Lipschitz constraint as a theoretical requirement. We propose to learn 1-Lipschitz networks using a new loss that is an hinge regularized version of the Kantorovich-Rubinstein dual formulation for the Wasserstein distance estimation. This loss function has a direct interpretation in terms of adversarial robustness together with certifiable robustness bound. We also prove that this hinge regularized version is still the dual formulation of an optimal transportation problem, and has a solution. We also establish several geometrical properties of this optimal solution, and extend the approach to multi-class problems. Experiments show that the proposed approach provides the expected guarantees in terms of robustness without any significant accuracy drop. The adversarial examples, on the proposed models, visibly and meaningfully change the input providing an explanation for the classification.","",""
25,"Michael Green, U. Ekelund, L. Edenbrandt, J. Björk, J. Forberg, M. Ohlsson","Exploring new possibilities for case-based explanation of artificial neural network ensembles",2009,"","","","",80,"2022-07-13 09:26:09","","10.1016/j.neunet.2008.09.014","","",,,,,25,1.92,4,6,13,"","",""
88,"Zhuanzhe Zhao, Qingsong Xu, M. Jia","Improved shuffled frog leaping algorithm-based BP neural network and its application in bearing early fault diagnosis",2016,"","","","",81,"2022-07-13 09:26:09","","10.1007/s00521-015-1850-y","","",,,,,88,14.67,29,3,6,"","",""
23,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","A comparative study of HTM and other neural network models for online sequence learning with streaming data",2016,"","","","",82,"2022-07-13 09:26:09","","10.1109/IJCNN.2016.7727380","","",,,,,23,3.83,6,4,6,"Online sequence learning from streaming data is one of the most challenging topics in machine learning. Neural network models represent promising candidates for sequence learning due to their ability to learn and recognize complex temporal patterns. In this paper, we present a comparative study of Hierarchical Temporal Memory (HTM), a neurally-inspired model, and other feedforward and recurrent artificial neural network models on both artificial and real-world sequence prediction algorithms. HTM and long-short term memory (LSTM) give the best prediction accuracy. HTM additionally demonstrates many other features that are desirable for real-world sequence learning, such as fast adaptation to changes in the data stream, robustness to sensor noise and fault tolerance. These features make HTM an ideal candidate for online sequence learning problems.","",""
48,"P. D. Cuong, W. Nan","Adaptive trajectory tracking neural network control with robust compensator for robot manipulators",2016,"","","","",83,"2022-07-13 09:26:09","","10.1007/s00521-015-1873-4","","",,,,,48,8.00,24,2,6,"","",""
145,"Haohan Wang, Xindi Wu, Pengcheng Yin, E. Xing","High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks",2019,"","","","",84,"2022-07-13 09:26:09","","10.1109/cvpr42600.2020.00871","","",,,,,145,48.33,36,4,3,"We investigate the relationship between the frequency spectrum of image data and the generalization behavior of convolutional neural networks (CNN). We first notice CNN's ability in capturing the high-frequency components of images. These high-frequency components are almost imperceptible to a human. Thus the observation leads to multiple hypotheses that are related to the generalization behaviors of CNN, including a potential explanation for adversarial examples, a discussion of CNN's trade-off between robustness and accuracy, and some evidence in understanding training heuristics.","",""
92,"Xiaojian Li, Guanghong Yang","Neural-Network-Based Adaptive Decentralized Fault-Tolerant Control for a Class of Interconnected Nonlinear Systems",2018,"","","","",85,"2022-07-13 09:26:09","","10.1109/TNNLS.2016.2616906","","",,,,,92,23.00,46,2,4,"This paper is concerned with the adaptive decentralized fault-tolerant tracking control problem for a class of uncertain interconnected nonlinear systems with unknown strong interconnections. An algebraic graph theory result is introduced to address the considered interconnections. In addition, to achieve the desirable tracking performance, a neural-network-based robust adaptive decentralized fault-tolerant control (FTC) scheme is given to compensate the actuator faults and system uncertainties. Furthermore, via the Lyapunov analysis method, it is proven that all the signals of the resulting closed-loop system are semiglobally bounded, and the tracking errors of each subsystem exponentially converge to a compact set, whose radius is adjustable by choosing different controller design parameters. Finally, the effectiveness and advantages of the proposed FTC approach are illustrated with two simulated examples.","",""
104,"Liu Yang, Hanxin Chen","Fault diagnosis of gearbox based on RBF-PF and particle swarm optimization wavelet neural network",2019,"","","","",86,"2022-07-13 09:26:09","","10.1007/s00521-018-3525-y","","",,,,,104,34.67,52,2,3,"","",""
5,"Hongjun Wang, Guangrun Wang, Guanbin Li, Liang Lin","CamDrop: A New Explanation of Dropout and A Guided Regularization Method for Deep Neural Networks",2019,"","","","",87,"2022-07-13 09:26:09","","10.1145/3357384.3357999","","",,,,,5,1.67,1,4,3,"To force convolutional networks to explore more discriminative evidence throughout spatial regions, this paper presents a novel CamDrop to improve the conventional dropout in two aspects. First, by considering the intensity of class activation mapping (CAM) all around, CamDrop selectively abandons some specific spatial regions in predominating visual patterns at each iteration. In many classification tasks, CamDrop demonstrates its effectiveness and achieves considerable improvements on robust predictions for adversarial examples. Second, although dropout is a widely adopted technique that has been applied to regularize large models, the improvement in performance always attributes to better preventing DNN from overfitting. Here we give a new explanation of dropout from the perspective of optimization that it makes the upper bound of the magnitude of gradients much tighter, which leads to a more stable behavior of the gradients and effectively avoids neurons falling into the saturation region of the nonlinear activation, even when using high learning rates. Extensive experiments have been performed to prove the above two strengths of CamDrop.","",""
40,"Lei Liu, Zhanshan Wang, Huaguang Zhang","Neural-Network-Based Robust Optimal Tracking Control for MIMO Discrete-Time Systems With Unknown Uncertainty Using Adaptive Critic Design",2018,"","","","",88,"2022-07-13 09:26:09","","10.1109/TNNLS.2017.2660070","","",,,,,40,10.00,13,3,4,"This paper is concerned with the robust optimal tracking control strategy for a class of nonlinear multi-input multi-output discrete-time systems with unknown uncertainty via adaptive critic design (ACD) scheme. The main purpose is to establish an adaptive actor-critic control method, so that the cost function in the procedure of dealing with uncertainty is minimum and the closed-loop system is stable. Based on the neural network approximator, an action network is applied to generate the optimal control signal and a critic network is used to approximate the cost function, respectively. In contrast to the previous methods, the main features of this paper are: 1) the ACD scheme is integrated into the controllers to cope with the uncertainty and 2) a novel cost function, which is not in quadric form, is proposed so that the total cost in the design procedure is reduced. It is proved that the optimal control signals and the tracking errors are uniformly ultimately bounded even when the uncertainty exists. Finally, a numerical simulation is developed to show the effectiveness of the present approach.","",""
692,"W. Samek, Alexander Binder, G. Montavon, S. Lapuschkin, K. Müller","Evaluating the Visualization of What a Deep Neural Network Has Learned",2015,"","","","",89,"2022-07-13 09:26:09","","10.1109/TNNLS.2016.2599820","","",,,,,692,98.86,138,5,7,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.","",""
55,"Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, Cho-Jui Hsieh","On the Adversarial Robustness of Vision Transformers",2021,"","","","",90,"2022-07-13 09:26:09","","","","",,,,,55,55.00,11,5,1,"Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides the first and comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various white-box and transfer attack settings, we find that ViTs possess better adversarial robustness when compared with convolutional neural networks (CNNs). We summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less low-level information and are more generalizable, which contributes to superior robustness against adversarial perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning low-level features in ViTs can improve classification accuracy but at the cost of adversarial robustness. 3) Increasing the proportion of transformers in the model structure (when the model consists of both transformer and CNN blocks) leads to better robustness. But for a pure transformer model, simply increasing the size or adding layers cannot guarantee a similar effect. 4) Pre-training on larger datasets does not significantly improve adversarial robustness though it is critical for training ViTs. 5) Adversarial training is also applicable to ViT for training robust models. Furthermore, feature visualization and frequency analysis are conducted for explanation. The results show that ViTs are less sensitive to high-frequency perturbations than CNNs and there is a high correlation between how well the model learns lowlevel features and its robustness against different frequencybased perturbations.","",""
42,"G. Basalyga, E. Salinas","When Response Variability Increases Neural Network Robustness to Synaptic Noise",2005,"","","","",91,"2022-07-13 09:26:09","","10.1162/neco.2006.18.6.1349","","",,,,,42,2.47,21,2,17,"Cortical sensory neurons are known to be highly variable, in the sense that responses evoked by identical stimuli often change dramatically from trial to trial. The origin of this variability is uncertain, but it is usually interpreted as detrimental noise that reduces the computational accuracy of neural circuits. Here we investigate the possibility that such response variability might in fact be beneficial, because it may partially compensate for a decrease in accuracy due to stochastic changes in the synaptic strengths of a network. We study the interplay between two kinds of noise, response (or neuronal) noise and synaptic noise, by analyzing their joint influence on the accuracy of neural networks trained to perform various tasks. We find an interesting, generic interaction: when fluctuations in the synaptic connections are proportional to their strengths (multiplicative noise), a certain amount of response noise in the input neurons can significantly improve network performance, compared to the same network without response noise. Performance is enhanced because response noise and multiplicative synaptic noise are in some ways equivalent. So if the algorithm used to find the optimal synaptic weights can take into account the variability of the model neurons, it can also take into account the variability of the synapses. Thus, the connection patterns generated with response noise are typically more resistant to synaptic degradation than those obtained without response noise. As a consequence of this interplay, if multiplicative synaptic noise is present, it is better to have response noise in the network than not to have it. These results are demonstrated analytically for the most basic network consisting of two input neurons and one output neuron performing a simple classification task, but computer simulations show that the phenomenon persists in a wide range of architectures, including recurrent (attractor) networks and sensorimotor networks that perform coordinate transformations. The results suggest that response variability could play an important dynamic role in networks that continuously learn.","",""
27,"Alexander Warnecke, Dan Arp, Christian Wressnegger, K. Rieck","Evaluating Explanation Methods for Deep Learning in Security",2019,"","","","",92,"2022-07-13 09:26:09","","10.1109/EuroSP48549.2020.00018","","",,,,,27,9.00,7,4,3,"Deep learning is increasingly used as a building block of security systems. Unfortunately, neural networks are hard to interpret and typically opaque to the practitioner. The machine learning community has started to address this problem by developing methods for explaining the predictions of neural networks. While several of these approaches have been successfully applied in the area of computer vision, their application in security has received little attention so far. It is an open question which explanation methods are appropriate for computer security and what requirements they need to satisfy. In this paper, we introduce criteria for comparing and evaluating explanation methods in the context of computer security. These cover general properties, such as the accuracy of explanations, as well as security-focused aspects, such as the completeness, efficiency, and robustness. Based on our criteria, we investigate six popular explanation methods and assess their utility in security systems for malware detection and vulnerability discovery. We observe significant differences between the methods and build on these to derive general recommendations for selecting and applying explanation methods in computer security.","",""
140,"R. Wai, Rajkumar Muthusamy","Fuzzy-Neural-Network Inherited Sliding-Mode Control for Robot Manipulator Including Actuator Dynamics",2013,"","","","",93,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2228230","","",,,,,140,15.56,70,2,9,"This paper presents the design and analysis of an intelligent control system that inherits the robust properties of sliding-mode control (SMC) for an n-link robot manipulator, including actuator dynamics in order to achieve a high-precision position tracking with a firm robustness. First, the coupled higher order dynamic model of an n-link robot manipulator is briefy introduced. Then, a conventional SMC scheme is developed for the joint position tracking of robot manipulators. Moreover, a fuzzy-neural-network inherited SMC (FNNISMC) scheme is proposed to relax the requirement of detailed system information and deal with chattering control efforts in the SMC system. In the FNNISMC strategy, the FNN framework is designed to mimic the SMC law, and adaptive tuning algorithms for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. Numerical simulations and experimental results of a two-link robot manipulator actuated by DC servo motors are provided to justify the claims of the proposed FNNISMC system, and the superiority of the proposed FNNISMC scheme is also evaluated by quantitative comparison with previous intelligent control schemes.","",""
40,"Hongwei Zhang, Xiong Xiao, O. Hasegawa","A Load-Balancing Self-Organizing Incremental Neural Network",2014,"","","","",94,"2022-07-13 09:26:09","","10.1109/TNNLS.2013.2287884","","",,,,,40,5.00,13,3,8,"Clustering is widely used in machine learning, feature extraction, pattern recognition, image analysis, information retrieval, and bioinformatics. Online unsupervised incremental learning is an important branch of data clustering. However, accurately separating high-density overlapped areas in a network has a direct impact on the performance of the clustering algorithm. In this paper, we propose a load-balancing self-organizing incremental neural network (LB-SOINN) to achieve good clustering results and demonstrate that it is more stable than an enhanced SOINN (E-SOINN). LB-SOINN has all the advantages of E-SOINN, such as robustness to noise and online unsupervised incremental learning. It overcomes the shortcomings of the topology structure generated by E-SOINN, such as dependence on the sequence of the input data, and avoids the turbulence that occurs when separating a composite class into subclasses. Furthermore, we also introduce a distance combination framework to obtain good performance for high-dimensional space-clustering tasks. Experiments involving both artificial and real world data sets indicate that LB-SOINN has superior performance in comparison with E-SOINN and other methods.","",""
32,"R. Eberhart","The role of genetic algorithms in neural network query-based learning and explanation facilities",1992,"","","","",95,"2022-07-13 09:26:09","","10.1109/COGANN.1992.273940","","",,,,,32,1.07,32,1,30,"Genetic algorithms are used as a means of achieving neural network inversion. Neural network inversion allows a user to find one or more neural network input patterns which yield a specific output. The input patterns obtained from the genetic algorithm can use in training partially-trained networks, as well as in the building of neural network system explanation facilities.<<ETX>>","",""
65,"S. Thrun, Tom Michael Mitchell","Integrating Inductive Neural Network Learning and Explanation-Based Learning",1993,"","","","",96,"2022-07-13 09:26:09","","","","",,,,,65,2.24,33,2,29,"Many researchers have noted the importance of combining inductive and analytical learning, yet we still lack combined learning methods that are effective in practice. We present here a learning method that combines explanation-based learning from a previously learned approximate domain theory, together with inductive learning from observations. This method, called explanation-based neural network learning (EBNN), is based on a neural network representation of domain knowledge. Explanations are constructed by chaining together inferences from multiple neural networks. In contrast with symbolic approaches to explanation-based learning which extract weakest preconditions from the explanation, EBNN extracts the derivatives of the target concept with respect to the training example features. These derivatives summarize the dependencies within the explanation, and are used to bias the inductive learning of the target concept. Experimental results on a simulated robot control task show that EBNN requires significantly fewer training examples than standard inductive learning. Furthermore, the method is shown to be robust to errors in the domain theory, operating effectively over a broad spectrum from very strong to very weak domain theories.","",""
1,"Burooj Ghani, S. Hallerberg","A Randomized Bag-of-Birds Approach to Study Robustness of Automated Audio Based Bird Species Classification",2021,"","","","",97,"2022-07-13 09:26:09","","10.20944/preprints202108.0277.v1","","",,,,,1,1.00,1,2,1,"The automatic classification of bird sounds is an ongoing research topic and several results have been reported for the classification of selected bird species. In this contribution we use an artificial neural network fed with pre-computed sound features to study the robustness of bird sound classification. We investigate in detail if and how classification results are dependent on the number of species and the selection of species in the subsets presented to the classifier. In more detail, a bag-of-birds approach is employed to randomly create balanced subsets of sounds from different species for repeated classification runs. The number of species present in each subset is varied between 10 and 300, randomly drawing sounds of species from a dataset of 659 bird species taken from Xeno-Canto database. We observe that the shallow artificial neural network trained on pre-computed sound features is able to classify the bird sounds relatively well. The classification performance is evaluated using several common measures such as precision, recall, accuracy, mean average precision and area under the receiver operator characteristics curve. All of these measures indicate a decrease in classification success as the number of species present in the subsets is increased. We analyze this dependence in detail and compare the computed results to an analytic explanation assuming dependencies for an idealized perfect classifier. Moreover, we observe that the classification performance depends on the individual composition of the subset and varies across 20 randomly drawn subsets.","",""
0,"D. Bzdok, J. Ioannidis","Deep ] neural networks are elaborate regression methods aimed solely at prediction , not estimation or explanation",2019,"","","","",98,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,2,3,"The last decades saw dramatic progress in brain research. These advances were often buttressed by probing single variables to make circumscribed discoveries, typically through null hypothesis significance testing. New ways for generating massive data fueled tension between the traditional methodology, used to infer statistically relevant effects in carefully-chosen variables, and pattern-learning algorithms, used to identify predictive signatures by searching through abundant information. In this article, we detail the antagonistic philosophies behind two quantitative approaches: certifying robust effects in understandable variables, and evaluating how accurately a built model can forecast future outcomes. We discourage choosing analysis tools via categories like ‘statistics’ or ‘machine learning’. Rather, to establish reproducible knowledge about the brain, we advocate prioritizing tools in view of the core motivation of each quantitative analysis: aiming towards mechanistic insight, or optimizing predictive accuracy.","",""
6,"Yifei Huang, Yaodong Yu, Hongyang R. Zhang, Yi Ma, Yuan Yao","Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients",2020,"","","","",99,"2022-07-13 09:26:09","","","","",,,,,6,3.00,1,5,2,"In this paper we introduce a provably stable architecture for Neural Ordinary Differential Equations (ODEs) which achieves non-trivial adversarial robustness under white-box adversarial attacks even when the network is trained naturally. For most existing defense methods withstanding strong white-box attacks, to improve robustness of neural networks, they need to be trained adversarially, hence have to strike a trade-off between natural accuracy and adversarial robustness. Inspired by dynamical system theory, we design a stabilized neural ODE network named SONet whose ODE blocks are skew-symmetric and proved to be input-output stable. With natural training, SONet can achieve comparable robustness with the state-of-the-art adversarial defense methods, without sacrificing natural accuracy. Even replacing only the first layer of a ResNet by such a ODE block can exhibit further improvement in robustness, e.g., under PGD-20 ($\ell_\infty=0.031$) attack on CIFAR-10 dataset, it achieves 91.57\% and natural accuracy and 62.35\% robust accuracy, while a counterpart architecture of ResNet trained with TRADES achieves natural and robust accuracy 76.29\% and 45.24\%, respectively. To understand possible reasons behind this surprisingly good result, we further explore the possible mechanism underlying such an adversarial robustness. We show that the adaptive stepsize numerical ODE solver, DOPRI5, has a gradient masking effect that fails the PGD attacks which are sensitive to gradient information of training loss; on the other hand, it cannot fool the CW attack of robust gradients and the SPSA attack that is gradient-free. This provides a new explanation that the adversarial robustness of ODE-based networks mainly comes from the obfuscated gradients in numerical ODE solvers.","",""
0,"Namuk Park, Songkuk Kim","Blurs Make Results Clearer: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness",2021,"","","","",100,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,2,1,"Bayesian neural networks (BNNs) have shown success in the areas of uncertainty estimation and robustness. However, a crucial challenge prohibits their use in practice: Bayesian NNs require a large number of predictions to produce reliable results, leading to a significant increase in computational cost. To alleviate this issue, we propose spatial smoothing, a method that ensembles neighboring feature map points of CNNs. By simply adding a few blur layers to the models, we empirically show that the spatial smoothing improves accuracy, uncertainty estimation, and robustness of BNNs across a whole range of ensemble sizes. In particular, BNNs incorporating the spatial smoothing achieve high predictive performance merely with a handful of ensembles. Moreover, this method also can be applied to canonical deterministic neural networks to improve the performances. A number of evidences suggest that the improvements can be attributed to the smoothing and flattening of the loss landscape. In addition, we provide a fundamental explanation for prior works—namely, global average pooling, pre-activation, and ReLU6—by addressing to them as special cases of the spatial smoothing. These not only enhance accuracy, but also improve uncertainty estimation and robustness by making the loss landscape smoother in the same manner as the spatial smoothing. The code is available at https://github.com/xxxnell/spatial-smoothing.","",""
76,"Yong Xu, Qiuqiang Kong, Qiang Huang, Wenwu Wang, Mark D. Plumbley","Convolutional gated recurrent neural network incorporating spatial features for audio tagging",2017,"","","","",101,"2022-07-13 09:26:09","","10.1109/IJCNN.2017.7966291","","",,,,,76,15.20,15,5,5,"Environmental audio tagging is a newly proposed task to predict the presence or absence of a specific audio event in a chunk. Deep neural network (DNN) based methods have been successfully adopted for predicting the audio tags in the domestic audio scene. In this paper, we propose to use a convolutional neural network (CNN) to extract robust features from mel-filter banks (MFBs), spectrograms or even raw waveforms for audio tagging. Gated recurrent unit (GRU) based recurrent neural networks (RNNs) are then cascaded to model the long-term temporal structure of the audio signal. To complement the input information, an auxiliary CNN is designed to learn on the spatial features of stereo recordings. We evaluate our proposed methods on Task 4 (audio tagging) of the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE 2016) challenge. Compared with our recent DNN-based method, the proposed structure can reduce the equal error rate (EER) from 0.13 to 0.11 on the development set. The spatial features can further reduce the EER to 0.10. The performance of the end-to-end learning on raw waveforms is also comparable. Finally, on the evaluation set, we get the state-of-the-art performance with 0.12 EER while the performance of the best existing system is 0.15 EER.","",""
1,"Yuchai Wan, Zhongshu Zheng, Ran Liu, Zheng Zhu, Hongen Zhou, Xun Zhang, Said Boumaraf","A Multi-Scale and Multi-Level Fusion Approach for Deep Learning-Based Liver Lesion Diagnosis in Magnetic Resonance Images with Visual Explanation",2021,"","","","",102,"2022-07-13 09:26:09","","10.3390/life11060582","","",,,,,1,1.00,0,7,1,"Many computer-aided diagnosis methods, especially ones with deep learning strategies, of liver cancers based on medical images have been proposed. However, most of such methods analyze the images under only one scale, and the deep learning models are always unexplainable. In this paper, we propose a deep learning-based multi-scale and multi-level fusing approach of CNNs for liver lesion diagnosis on magnetic resonance images, termed as MMF-CNN. We introduce a multi-scale representation strategy to encode both the local and semi-local complementary information of the images. To take advantage of the complementary information of multi-scale representations, we propose a multi-level fusion method to combine the information of both the feature level and the decision level hierarchically and generate a robust diagnostic classifier based on deep learning. We further explore the explanation of the diagnosis decision of the deep neural network through visualizing the areas of interest of the network. A new scoring method is designed to evaluate whether the attention maps can highlight the relevant radiological features. The explanation and visualization make the decision-making process of the deep neural network transparent for the clinicians. We apply our proposed approach to various state-of-the-art deep learning architectures. The experimental results demonstrate the effectiveness of our approach.","",""
22,"Zifan Wang, Yilin Yang, Ankit Shrivastava, Varun Rawal, Zihao Ding","Towards Frequency-Based Explanation for Robust CNN",2020,"","","","",103,"2022-07-13 09:26:09","","","","",,,,,22,11.00,4,5,2,"Current explanation techniques towards a transparent Convolutional Neural Network (CNN) mainly focuses on building connections between the human-understandable input features with models' prediction, overlooking an alternative representation of the input, the frequency components decomposition. In this work, we present an analysis of the connection between the distribution of frequency components in the input dataset and the reasoning process the model learns from the data. We further provide quantification analysis about the contribution of different frequency components toward the model's prediction. We show that the vulnerability of the model against tiny distortions is a result of the model is relying on the high-frequency features, the target features of the adversarial (black and white-box) attackers, to make the prediction. We further show that if the model develops stronger association between the low-frequency component with true labels, the model is more robust, which is the explanation of why adversarially trained models are more robust against tiny distortions.","",""
11,"J. Fei, Dan Wu","Adaptive control of MEMS gyroscope using fully tuned RBF neural network",2017,"","","","",104,"2022-07-13 09:26:09","","10.1007/s00521-015-2098-2","","",,,,,11,2.20,6,2,5,"","",""
29,"S. A. Taqvi, L. Tufa, H. Zabiri, A. Maulud, F. Uddin","Fault detection in distillation column using NARX neural network",2018,"","","","",105,"2022-07-13 09:26:09","","10.1007/s00521-018-3658-z","","",,,,,29,7.25,6,5,4,"","",""
30,"Ding Wang, Derong Liu, Yun Zhang, Hongyi Li","Neural network robust tracking control with adaptive critic framework for uncertain nonlinear systems",2018,"","","","",106,"2022-07-13 09:26:09","","10.1016/j.neunet.2017.09.005","","",,,,,30,7.50,8,4,4,"","",""
47,"A. Tavanaei, A. Maida","Multi-layer unsupervised learning in a spiking convolutional neural network",2017,"","","","",107,"2022-07-13 09:26:09","","10.1109/IJCNN.2017.7966099","","",,,,,47,9.40,24,2,5,"Spiking neural networks (SNNs) have advantages over traditional, non-spiking networks with respect to biorealism, potential for low-power hardware implementations, and theoretical computing power. However, in practice, spiking networks with multi-layer learning have proven difficult to train. This paper explores a novel, bio-inspired spiking convolutional neural network (CNN) that is trained in a greedy, layer-wise fashion. The spiking CNN consists of a convolutional/pooling layer followed by a feature discovery layer, both of which undergo bio-inspired learning. Kernels for the convolutional layer are trained using a sparse, spiking auto-encoder representing primary visual features. The feature discovery layer uses a probabilistic spike-timing-dependent plasticity (STDP) learning rule. This layer represents complex visual features using WTA-thresholded, leaky, integrate-and-fire (LIF) neurons. The new model is evaluated on the MNIST digit dataset using clean and noisy images. Intermediate results show that the convolutional layer is stack-admissible, enabling it to support a multi-layer learning architecture. The recognition performance for clean images is above 98%. This performance is accounted for by the independent and informative visual features extracted in a hierarchy of convolutional and feature discovery layers. The performance loss for recognizing the noisy images is in the range 0.1% to 8.5%. This level of performance loss indicates that the network is robust to additive noise.","",""
40,"J. Dethier, P. Nuyujukian, S. Ryu, K. Shenoy, K. Boahen","Design and validation of a real-time spiking-neural-network decoder for brain-machine interfaces.",2013,"","","","",108,"2022-07-13 09:26:09","","10.1088/1741-2560/10/3/036008","","",,,,,40,4.44,8,5,9,"OBJECTIVE Cortically-controlled motor prostheses aim to restore functions lost to neurological disease and injury. Several proof of concept demonstrations have shown encouraging results, but barriers to clinical translation still remain. In particular, intracortical prostheses must satisfy stringent power dissipation constraints so as not to damage cortex.   APPROACH One possible solution is to use ultra-low power neuromorphic chips to decode neural signals for these intracortical implants. The first step is to explore in simulation the feasibility of translating decoding algorithms for brain-machine interface (BMI) applications into spiking neural networks (SNNs).   MAIN RESULTS Here we demonstrate the validity of the approach by implementing an existing Kalman-filter-based decoder in a simulated SNN using the Neural Engineering Framework (NEF), a general method for mapping control algorithms onto SNNs. To measure this system's robustness and generalization, we tested it online in closed-loop BMI experiments with two rhesus monkeys. Across both monkeys, a Kalman filter implemented using a 2000-neuron SNN has comparable performance to that of a Kalman filter implemented using standard floating point techniques.   SIGNIFICANCE These results demonstrate the tractability of SNN implementations of statistical signal processing algorithms on different monkeys and for several tasks, suggesting that a SNN decoder, implemented on a neuromorphic chip, may be a feasible computational platform for low-power fully-implanted prostheses. The validation of this closed-loop decoder system and the demonstration of its robustness and generalization hold promise for SNN implementations on an ultra-low power neuromorphic chip using the NEF.","",""
86,"Zitong Yang, Yaodong Yu, Chong You, J. Steinhardt, Yi Ma","Rethinking Bias-Variance Trade-off for Generalization of Neural Networks",2020,"","","","",109,"2022-07-13 09:26:09","","","","",,,,,86,43.00,17,5,2,"The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation for this by measuring the bias and variance of neural networks: while the bias is monotonically decreasing as in the classical theory, the variance is unimodal or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent curve observed in recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.","",""
7,"Thorben Funke, Megha Khosla, Avishek Anand","Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks",2021,"","","","",110,"2022-07-13 09:26:09","","","","",,,,,7,7.00,2,3,1,"With the ever-increasing popularity and applications of graph neural networks, several proposals have been made to explain and understand the decisions of a graph neural network. Explanations for graph neural networks differ in principle from other input settings. It is important to attribute the decision to input features and other related instances connected by the graph structure. We find that the previous explanation generation approaches that maximize the mutual information between the label distribution produced by the model and the explanation to be restrictive. Specifically, existing approaches do not enforce explanations to be valid, sparse, or robust to input perturbations. In this paper, we lay down some of the fundamental principles that an explanation method for graph neural networks should follow and introduce a metric RDT-Fidelity as a measure of the explanation’s effectiveness. We propose a novel approach Zorro based on the principles from rate-distortion theory that uses a simple combinatorial procedure to optimize for RDT-Fidelity. Extensive experiments on real and synthetic datasets reveal that Zorro produces sparser, stable, and more faithful explanations than existing graph neural network explanation approaches.","",""
1,"R. Vardhan, Ninghao Liu, Phakpoom Chinprutthiwong, Weijie Fu, Zhen Hu, Xia Hu, G. Gu","ExAD: An Ensemble Approach for Explanation-based Adversarial Detection",2021,"","","","",111,"2022-07-13 09:26:09","","","","",,,,,1,1.00,0,7,1,"Recent research has shown Deep Neural Networks (DNNs) to be vulnerable to adversarial examples that induce desired misclassifications in the models. Such risks impede the application of machine learning in security-sensitive domains. Several defense methods have been proposed against adversarial attacks to detect adversarial examples at test time or to make machine learning models more robust. However, while existing methods are quite effective under blackbox threat model, where the attacker is not aware of the defense, they are relatively ineffective under whitebox threat model, where the attacker has full knowledge of the defense. In this paper, we propose ExAD, a framework to detect adversarial examples using an ensemble of explanation techniques. Each explanation technique in ExAD produces an explanation map identifying the relevance of input variables for the model’s classification. For every class in a dataset, the system includes a detector network, corresponding to each explanation technique, which is trained to distinguish between normal and abnormal explanation maps. At test time, if the explanation map of an input is detected as abnormal by any detector model of the classified class, then we consider the input to be an adversarial example. We evaluate our approach using six state-of-the-art adversarial attacks on three image datasets. Our extensive evaluation shows that our mechanism can effectively detect these attacks under blackbox threat model with limited false-positives. Furthermore, we find that our approach achieves promising results in limiting the success rate of whitebox attacks.","",""
14,"Jin Wang, C. Lim, D. Creighton, A. Khosravi, S. Nahavandi, J. Ugon, P. Vamplew, A. Stranieri, Laura Martin, Anton Freischmidt","Patient admission prediction using a pruned fuzzy min–max neural network with rule extraction",2015,"","","","",112,"2022-07-13 09:26:09","","10.1007/s00521-014-1631-z","","",,,,,14,2.00,1,10,7,"","",""
181,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","Continuous Online Sequence Learning with an Unsupervised Neural Network Model",2015,"","","","",113,"2022-07-13 09:26:09","","10.1162/NECO_a_00893","","",,,,,181,25.86,45,4,7,"Abstract The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.","",""
47,"K. Shojaei","Three-dimensional neural network tracking control of a moving target by underactuated autonomous underwater vehicles",2019,"","","","",114,"2022-07-13 09:26:09","","10.1007/s00521-017-3085-6","","",,,,,47,15.67,47,1,3,"","",""
90,"Jen-Tzung Chien, Y. Ku","Bayesian Recurrent Neural Network for Language Modeling",2016,"","","","",115,"2022-07-13 09:26:09","","10.1109/TNNLS.2015.2499302","","",,,,,90,15.00,45,2,6,"A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.","",""
3,"Stefani Karp, Ezra Winston, Yuanzhi Li, Aarti Singh","Local Signal Adaptivity: Provable Feature Learning in Neural Networks Beyond Kernels",2021,"","","","",116,"2022-07-13 09:26:09","","","","",,,,,3,3.00,1,4,1,"Neural networks have been shown to outperform kernel methods in practice (including neural tangent kernels). Most theoretical explanations of this performance gap focus on learning a complex hypothesis class; in some cases, it is unclear whether this hypothesis class captures realistic data. In this work, we propose a related, but alternative, explanation for this performance gap in the image classification setting, based on finding a sparse signal in the presence of noise. Specifically, we prove that, for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent simultaneously learns to threshold out the noise and find the signal. On the other hand, the corresponding neural tangent kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. We supplement our theoretical results by demonstrating this phenomenon empirically: in CIFAR-10 and MNIST images with various backgrounds, as the background noise increases in intensity, a CNN’s performance stays relatively robust, whereas its corresponding neural tangent kernel sees a notable drop in performance. We therefore propose the local signal adaptivity (LSA) phenomenon as one explanation for the superiority of neural networks over kernel methods.","",""
17,"Bin Hu, Shigang Yue, Zhuhong Zhang","A Rotational Motion Perception Neural Network Based on Asymmetric Spatiotemporal Visual Information Processing",2017,"","","","",117,"2022-07-13 09:26:09","","10.1109/TNNLS.2016.2592969","","",,,,,17,3.40,6,3,5,"All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts—presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.","",""
18,"E. Egrioglu, U. Yolcu, E. Bas, Ali Z. Dalar","Median-Pi artificial neural network for forecasting",2019,"","","","",118,"2022-07-13 09:26:09","","10.1007/s00521-017-3002-z","","",,,,,18,6.00,5,4,3,"","",""
58,"Youshen Xia, Changyin Sun, W. Zheng","Discrete-Time Neural Network for Fast Solving Large Linear $L_{1}$ Estimation Problems and its Application to Image Restoration",2012,"","","","",119,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2184800","","",,,,,58,5.80,19,3,10,"There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","",""
14,"Hui Zhao, Lixiang Li, Haipeng Peng, J. Kurths, Jinghua Xiao, Yixian Yang","Finite-Time Robust Synchronization of Memrisive Neural Network with Perturbation",2017,"","","","",120,"2022-07-13 09:26:09","","10.1007/s11063-017-9664-9","","",,,,,14,2.80,2,6,5,"","",""
13,"Guillermo Ortiz-Jiménez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, P. Frossard","Optimism in the Face of Adversity: Understanding and Improving Deep Learning Through Adversarial Robustness",2020,"","","","",121,"2022-07-13 09:26:09","","10.1109/JPROC.2021.3050042","","",,,,,13,6.50,3,4,2,"Driven by massive amounts of data and important advances in computational resources, new deep learning systems have achieved outstanding results in a large spectrum of applications. Nevertheless, our current theoretical understanding of the mathematical foundations of deep learning lags far behind its empirical success. However, the field of adversarial robustness has recently become one of the main sources of explanations of our deep models. In this article, we provide an in-depth review of the field and give a self-contained introduction to its main notions. However, in contrast to the mainstream pessimistic perspective of adversarial robustness, we focus on the main positive aspects that it entails. We highlight the intuitive connection between adversarial examples and the geometry of deep neural networks and, eventually, explore how the geometric study of adversarial examples can serve as a powerful tool to understand deep learning. Furthermore, we demonstrate the broad applicability of adversarial robustness, providing an overview of the main emerging applications of adversarial robustness beyond security. The goal of this article is to provide readers with a set of new perspectives to understand deep learning and supply them with intuitive tools and insights on how to use adversarial robustness to improve it.","",""
55,"Chih-Min Lin, A. Ting, Chun-Fei Hsu, Chao-Ming Chung","Adaptive Control for MIMO uncertain nonlinear Systems Using Recurrent Wavelet Neural Network",2012,"","","","",122,"2022-07-13 09:26:09","","10.1142/S0129065712002992","","",,,,,55,5.50,14,4,10,"Recurrent wavelet neural network (RWNN) has the advantages such as fast learning property, good generalization capability and information storing ability. With these advantages, this paper proposes an RWNN-based adaptive control (RBAC) system for multi-input multi-output (MIMO) uncertain nonlinear systems. The RBAC system is composed of a neural controller and a bounding compensator. The neural controller uses an RWNN to online mimic an ideal controller, and the bounding compensator can provide smooth and chattering-free stability compensation. From the Lyapunov stability analysis, it is shown that all signals in the closed-loop RBAC system are uniformly ultimately bounded. Finally, the proposed RBAC system is applied to the MIMO uncertain nonlinear systems such as a mass-spring-damper mechanical system and a two-link robotic manipulator system. Simulation results verify that the proposed RBAC system can achieve favorable tracking performance with desired robustness without any chattering phenomenon in the control effort.","",""
60,"Qingshan Liu, Jun Wang","$L_{1}$ -Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network",2016,"","","","",123,"2022-07-13 09:26:09","","10.1109/TNNLS.2015.2481006","","",,,,,60,10.00,30,2,6,"This paper presents several L1 -minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1 -minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1 -minimization algorithms.","",""
36,"E. Magosso, Cristiano Cuppini, M. Ursino","A Neural Network Model of Ventriloquism Effect and Aftereffect",2012,"","","","",124,"2022-07-13 09:26:09","","10.1371/journal.pone.0042503","","",,,,,36,3.60,12,3,10,"Presenting simultaneous but spatially discrepant visual and auditory stimuli induces a perceptual translocation of the sound towards the visual input, the ventriloquism effect. General explanation is that vision tends to dominate over audition because of its higher spatial reliability. The underlying neural mechanisms remain unclear. We address this question via a biologically inspired neural network. The model contains two layers of unimodal visual and auditory neurons, with visual neurons having higher spatial resolution than auditory ones. Neurons within each layer communicate via lateral intra-layer synapses; neurons across layers are connected via inter-layer connections. The network accounts for the ventriloquism effect, ascribing it to a positive feedback between the visual and auditory neurons, triggered by residual auditory activity at the position of the visual stimulus. Main results are: i) the less localized stimulus is strongly biased toward the most localized stimulus and not vice versa; ii) amount of the ventriloquism effect changes with visual-auditory spatial disparity; iii) ventriloquism is a robust behavior of the network with respect to parameter value changes. Moreover, the model implements Hebbian rules for potentiation and depression of lateral synapses, to explain ventriloquism aftereffect (that is, the enduring sound shift after exposure to spatially disparate audio-visual stimuli). By adaptively changing the weights of lateral synapses during cross-modal stimulation, the model produces post-adaptive shifts of auditory localization that agree with in-vivo observations. The model demonstrates that two unimodal layers reciprocally interconnected may explain ventriloquism effect and aftereffect, even without the presence of any convergent multimodal area. The proposed study may provide advancement in understanding neural architecture and mechanisms at the basis of visual-auditory integration in the spatial realm.","",""
2,"Vedant Nanda, Till Speicher, John P. Dickerson, K. Gummadi, M. B. Zafar","Unifying Model Explainability and Robustness via Machine-Checkable Concepts",2020,"","","","",125,"2022-07-13 09:26:09","","","","",,,,,2,1.00,0,5,2,"As deep neural networks (DNNs) get adopted in an ever-increasing number of applications, explainability has emerged as a crucial desideratum for these models. In many real-world tasks, one of the principal reasons for requiring explainability is to in turn assess prediction robustness, where predictions (i.e., class labels) that do not conform to their respective explanations (e.g., presence or absence of a concept in the input) are deemed to be unreliable. However, most, if not all, prior methods for checking explanation-conformity (e.g., LIME, TCAV, saliency maps) require significant manual intervention, which hinders their large-scale deployability. In this paper, we propose a robustness-assessment framework, at the core of which is the idea of using machine-checkable concepts. Our framework defines a large number of concepts that the DNN explanations could be based on and performs the explanation-conformity check at test time to assess prediction robustness. Both steps are executed in an automated manner without requiring any human intervention and are easily scaled to datasets with a very large number of classes. Experiments on real-world datasets and human surveys show that our framework is able to enhance prediction robustness significantly: the predictions marked to be robust by our framework have significantly higher accuracy and are more robust to adversarial perturbations.","",""
2,"Namuk Park, S. Kim","Blurs Behave Like Ensembles: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness",2021,"","","","",126,"2022-07-13 09:26:09","","","","",,,,,2,2.00,1,2,1,"Neural network ensembles, such as Bayesian neural networks (BNNs), have shown success in the areas of uncertainty estimation and robustness. However, a crucial challenge prohibits their use in practice. BNNs require a large number of predictions to produce reliable results, leading to a significant increase in computational cost. To alleviate this issue, we propose spatial smoothing, a method that spatially ensembles neighboring feature map points of convolutional neural networks. By simply adding a few blur layers to the models, we empirically show that spatial smoothing improves accuracy, uncertainty estimation, and robustness of BNNs across a whole range of ensemble sizes. In particular, BNNs incorporating spatial smoothing achieve high predictive performance merely with a handful of ensembles. Moreover, this method also can be applied to canonical deterministic neural networks to improve the performances. A number of evidences suggest that the improvements can be attributed to the stabilized feature maps and the smoothing of the loss landscape. In addition, we provide a fundamental explanation for prior works—namely, global average pooling, pre-activation, and ReLU6—by addressing them as special cases of spatial smoothing. These not only enhance accuracy, but also improve uncertainty estimation and robustness by making the loss landscape smoother in the same manner as spatial smoothing.","",""
119,"Yi Shen, Jun Wang","Robustness Analysis of Global Exponential Stability of Recurrent Neural Networks in the Presence of Time Delays and Random Disturbances",2012,"","","","",127,"2022-07-13 09:26:09","","10.1109/TNNLS.2011.2178326","","",,,,,119,11.90,60,2,10,"In recent years, the global stability of recurrent neural networks (RNNs) has been investigated extensively. It is well known that time delays and external disturbances can derail the stability of RNNs. In this paper, we analyze the robustness of global stability of RNNs subject to time delays and random disturbances. Given a globally exponentially stable neural network, the problem to be addressed here is how much time delay and noise the RNN can withstand to be globally exponentially stable in the presence of delay and noise. The upper bounds of the time delay and noise intensity are characterized by using transcendental equations for the RNNs to sustain global exponential stability. Moreover, we prove theoretically that, for any globally exponentially stable RNNs, if additive noises and time delays are smaller than the derived lower bounds arrived at here, then the perturbed RNNs are guaranteed to also be globally exponentially stable. Three numerical examples are provided to substantiate the theoretical results.","",""
3,"Alexander Warnecke, Dan Arp, Christian Wressnegger, K. Rieck","Evaluating Explanation Methods for Deep Learning in Computer Security",2020,"","","","",128,"2022-07-13 09:26:09","","","","",,,,,3,1.50,1,4,2,"Deep learning is increasingly used as a building block of security systems. Unfortunately, neural networks are hard to interpret and typically opaque to the practitioner. The machine learning community has started to address this problem by developing methods for explaining the predictions of neural networks. While several of these approaches have been successfully applied in the area of computer vision, their application in security has received little attention so far. It is an open question which explanation methods are appropriate for computer security and what requirements they need to satisfy.  In this paper, we introduce criteria for comparing and evaluating explanation methods in the context of computer security. These cover general properties, such as the accuracy of explanations, as well as security-focused aspects, such as the completeness, efficiency, and robustness. Based on our criteria, we investigate six popular explanation methods and assess their utility in security systems for malware detection and vulnerability discovery. We observe significant differences between the methods and build on these to derive general recommendations for selecting and applying explanation methods in computer security.","",""
9,"Federico Baldassarre, Kevin Smith, J. Sullivan, Hossein Azizpour","Explanation-based Weakly-supervised Learning of Visual Relations with Graph Networks",2020,"","","","",129,"2022-07-13 09:26:09","","10.1007/978-3-030-58604-1_37","","",,,,,9,4.50,2,4,2,"","",""
28,"U. Oparaji, R. Sheu, M. Bankhead, J. Austin, E. Patelli","Robust artificial neural network for reliability and sensitivity analyses of complex non-linear systems",2017,"","","","",130,"2022-07-13 09:26:09","","10.1016/j.neunet.2017.09.003","","",,,,,28,5.60,6,5,5,"","",""
68,"Qiang Yu, Rui Yan, Huajin Tang, K. Tan, Haizhou Li","A Spiking Neural Network System for Robust Sequence Recognition",2016,"","","","",131,"2022-07-13 09:26:09","","10.1109/TNNLS.2015.2416771","","",,,,,68,11.33,14,5,6,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.","",""
33,"J. Wall, L. McDaid, L. Maguire, T. Mcginnity","Spiking Neural Network Model of Sound Localization Using the Interaural Intensity Difference",2012,"","","","",132,"2022-07-13 09:26:09","","10.1109/TNNLS.2011.2178317","","",,,,,33,3.30,8,4,10,"In this paper, a spiking neural network (SNN) architecture to simulate the sound localization ability of the mammalian auditory pathways using the interaural intensity difference cue is presented. The lateral superior olive was the inspiration for the architecture, which required the integration of an auditory periphery (cochlea) model and a model of the medial nucleus of the trapezoid body. The SNN uses leaky integrate-and-fire excitatory and inhibitory spiking neurons, facilitating synapses and receptive fields. Experimentally derived head-related transfer function (HRTF) acoustical data from adult domestic cats were employed to train and validate the localization ability of the architecture, training used the supervised learning algorithm called the remote supervision method to determine the azimuthal angles. The experimental results demonstrate that the architecture performs best when it is localizing high-frequency sound data in agreement with the biology, and also shows a high degree of robustness when the HRTF acoustical data is corrupted by noise.","",""
36,"Lin Sun, Jiucheng Xu, Shangwang Liu, Shiguang Zhang, Yuan Li, Chang'an Shen","A robust image watermarking scheme using Arnold transform and BP neural network",2018,"","","","",133,"2022-07-13 09:26:09","","10.1007/s00521-016-2788-4","","",,,,,36,9.00,6,6,4,"","",""
83,"Hao Quan, D. Srinivasan, A. Khosravi","Incorporating Wind Power Forecast Uncertainties Into Stochastic Unit Commitment Using Neural Network-Based Prediction Intervals",2015,"","","","",134,"2022-07-13 09:26:09","","10.1109/TNNLS.2014.2376696","","",,,,,83,11.86,28,3,7,"Penetration of renewable energy resources, such as wind and solar power, into power systems significantly increases the uncertainties on system operation, stability, and reliability in smart grids. In this paper, the nonparametric neural network-based prediction intervals (PIs) are implemented for forecast uncertainty quantification. Instead of a single level PI, wind power forecast uncertainties are represented in a list of PIs. These PIs are then decomposed into quantiles of wind power. A new scenario generation method is proposed to handle wind power forecast uncertainties. For each hour, an empirical cumulative distribution function (ECDF) is fitted to these quantile points. The Monte Carlo simulation method is used to generate scenarios from the ECDF. Then the wind power scenarios are incorporated into a stochastic security-constrained unit commitment (SCUC) model. The heuristic genetic algorithm is utilized to solve the stochastic SCUC problem. Five deterministic and four stochastic case studies incorporated with interval forecasts of wind power are implemented. The results of these cases are presented and discussed together. Generation costs, and the scheduled and real-time economic dispatch reserves of different unit commitment strategies are compared. The experimental results show that the stochastic model is more robust than deterministic ones and, thus, decreases the risk in system operations of smart grids.","",""
58,"S. Naz, A. I. Umar, Riaz Ahmad, S. Ahmed, S. H. Shirazi, M. I. Razzak","Urdu Nasta’liq text recognition system based on multi-dimensional recurrent neural network and statistical features",2017,"","","","",135,"2022-07-13 09:26:09","","10.1007/s00521-015-2051-4","","",,,,,58,11.60,10,6,5,"","",""
75,"Qinmin Yang, S. Jagannathan, Youxian Sun","Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems",2015,"","","","",136,"2022-07-13 09:26:09","","10.1109/TNNLS.2015.2470175","","",,,,,75,10.71,25,3,7,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.","",""
0,"Qinghua Zheng, Jihong Wang, Minnan Luo, Yaoliang Yu, Jundong Li, L. Yao, Xiao Chang","Towards Explanation for Unsupervised Graph-Level Representation Learning",2022,"","","","",137,"2022-07-13 09:26:09","","10.48550/arXiv.2205.09934","","",,,,,0,0.00,0,7,1,"Due to the superior performance of Graph Neural Networks (GNNs) in various domains, there is an increasing interest in the GNN explanation problem "" which fraction of the input graph is the most crucial to decide the model’s decision? "" Existing explanation methods focus on the supervised settings, e.g. , node classiﬁcation and graph classiﬁcation, while the explanation for unsupervised graph-level representation learning is still unexplored. The opaqueness of the graph representations may lead to unexpected risks when deployed for high-stake decision-making scenarios. In this paper, we advance the Information Bottleneck principle (IB) to tackle the proposed explanation problem for unsupervised graph representations, which leads to a novel principle, Unsupervised Subgraph Information Bottleneck (USIB). We also theoretically analyze the connection between graph representations and explanatory subgraphs on the label space, which reveals that the expressiveness and robustness of representations beneﬁt the ﬁdelity of explanatory subgraphs. Experimental results on both synthetic and real-world datasets demonstrate the superiority of our developed explainer and the validity of our theoretical analysis. ABSTRACT Data artifacts incentivize machine learning models to learn non-transferable generalizations by taking advantage of shortcuts in the data, and there is growing evidence that data artifacts play a role for the strong results that deep learning models achieve in recent natural language processing benchmarks. In this paper, we focus on task-oriented dialogue and investigate whether popular datasets such as MultiWOZ contain such data artifacts. We found that by only keeping frequent phrases in the training examples, state-of-the-art models perform similarly compared to the variant trained with full data, suggesting they exploit these spurious correlations to solve the task. Motivated by this, we propose a contrastive learning based framework to encourage the model to ignore these cues and focus on learning generalisable patterns. We also experiment with adversarial filtering to remove “easy” training instances so that the model would focus on learning from the “harder” instances. We conduct a number of generalization experiments — e.g., cross-domain/dataset and adversarial tests — to assess the robustness of our approach and found that it works exceptionally well.","",""
1,"Guozhang Chen, Franz Scherr, W. Maass","Analysis of visual processing capabilities and neural coding strategies of a detailed model for laminar cortical microcircuits in mouse V1",2021,"","","","",138,"2022-07-13 09:26:09","","10.1101/2021.12.07.471653","","",,,,,1,1.00,0,3,1,"Neural networks of the brain that process visual information have structural properties that differ significantly from those of neural networks which are commonly used for visual processing in AI, such as Convolutional Neural Networks (CNNs). But it has remained unknown how these structural differences are related to network function. We analyze visual processing capabilities of a large-scale model for area V1 that arguably provides the most comprehensive accumulation of anatomical and neurophysiological data that is currently available. Its network structure turns out to induce a number of characteristic visual processing capabilities of the brain, in particular the capability to multiplex different visual processing tasks, also on temporally dispersed visual information, with remarkable robustness to noise. This V1 model also exhibits a number of characteristic neural coding properties of the brain, which provide explanations for its superior noise robustness. Since visual processing in the brain is substantially more energy-efficient than implementations of CNNs in common computer hardware, such brain-like neural network models are likely to have also an impact on technology: As blueprints for visual processing in more energy-efficient neuromorphic hardware.","",""
2,"Tom Grimes, E. Church, W. Pitts, Lynn Wood","Explanation of Unintended Radiated Emission Classification via LIME",2020,"","","","",139,"2022-07-13 09:26:09","","","","",,,,,2,1.00,1,4,2,"Unintended radiated emissions arise during the use of electronic devices. Identifying and mitigating the effects of these emissions is a key element of modern power engineering and associated control systems. Signal processing of the electrical system can identify the sources of these emissions. A dataset known as Flaming Moes includes captured unintended radiated emissions from consumer electronics. This dataset was analyzed to construct next-generation methods for device identification. To this end, a neural network based on applying the ResNet-18 image classification architecture to the short time Fourier transforms of short segments of voltage signatures was constructed. Using this classifier, the 18 device classes and background class were identified with close to 100 percent accuracy. By applying LIME to this classifier and aggregating the results over many classifications for the same device, it was possible to determine the frequency bands used by the classifier to make decisions. Using ensembles of classifiers trained on very similar datasets from the same parent data distribution, it was possible to recover robust sets of features of device output useful for identification. The additional understanding provided by the application of LIME enhances the trainability, trustability, and transferability of URE analysis networks.","",""
24,"G. Rajchakit, R. Sriraman","Robust Passivity and Stability Analysis of Uncertain Complex-Valued Impulsive Neural Networks with Time-Varying Delays",2021,"","","","",140,"2022-07-13 09:26:09","","10.1007/s11063-020-10401-w","","",,,,,24,24.00,12,2,1,"","",""
61,"Zhijun Li, Yuanqing Xia, C. Su, Jun Deng, Jun Fu, W. He","Missile Guidance Law Based on Robust Model Predictive Control Using Neural-Network Optimization",2015,"","","","",141,"2022-07-13 09:26:09","","10.1109/TNNLS.2014.2345734","","",,,,,61,8.71,10,6,7,"In this brief, the utilization of robust model-based predictive control is investigated for the problem of missile interception. Treating the target acceleration as a bounded disturbance, novel guidance law using model predictive control is developed by incorporating missile inside constraints. The combined model predictive approach could be transformed as a constrained quadratic programming (QP) problem, which may be solved using a linear variational inequality-based primal-dual neural network over a finite receding horizon. Online solutions to multiple parametric QP problems are used so that constrained optimal control decisions can be made in real time. Simulation studies are conducted to illustrate the effectiveness and performance of the proposed guidance control law for missile interception.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",142,"2022-07-13 09:26:09","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
19,"Xuhong Wang, Baihong Jin, Ying Du, Ping Cui, Yupu Yang","One-class graph neural networks for anomaly detection in attributed networks",2020,"","","","",143,"2022-07-13 09:26:09","","10.1007/S00521-021-05924-9","","",,,,,19,9.50,4,5,2,"","",""
8,"Feng Jiang, Hua Yang, Yi Shen","On the robustness of global exponential stability for hybrid neural networks with noise and delay perturbations",2014,"","","","",144,"2022-07-13 09:26:09","","10.1007/s00521-013-1374-2","","",,,,,8,1.00,3,3,8,"","",""
4,"Theodoros Tsiligkaridis, Jay Roberts","Second Order Optimization for Adversarial Robustness and Interpretability",2020,"","","","",145,"2022-07-13 09:26:09","","","","",,,,,4,2.00,2,2,2,"Deep neural networks are easily fooled by small perturbations known as adversarial attacks. Adversarial Training (AT) is a technique aimed at learning features robust to such attacks and is widely regarded as a very effective defense. However, the computational cost of such training can be prohibitive as the network size and input dimensions grow. Inspired by the relationship between robustness and curvature, we propose a novel regularizer which incorporates first and second order information via a quadratic approximation to the adversarial loss. The worst case quadratic loss is approximated via an iterative scheme. It is shown that using only a single iteration in our regularizer achieves stronger robustness than prior gradient and curvature regularization schemes, avoids gradient obfuscation, and, with additional iterations, achieves strong robustness with significantly lower training time than AT. Further, it retains the interesting facet of AT that networks learn features which are well-aligned with human perception. We demonstrate experimentally that our method produces higher quality human-interpretable features than other geometric regularization techniques. These robust features are then used to provide human-friendly explanations to model predictions.","",""
22,"Ikbal Eski, Ş. Yıldırım","Neural network-based fuzzy inference system for speed control of heavy duty vehicles with electronic throttle control system",2017,"","","","",146,"2022-07-13 09:26:09","","10.1007/s00521-016-2362-0","","",,,,,22,4.40,11,2,5,"","",""
22,"Foued Saâdaoui","A seasonal feedforward neural network to forecast electricity prices",2017,"","","","",147,"2022-07-13 09:26:09","","10.1007/s00521-016-2356-y","","",,,,,22,4.40,22,1,5,"","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",148,"2022-07-13 09:26:09","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
96,"Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John C. Duchi, Percy Liang","Understanding and Mitigating the Tradeoff Between Robustness and Accuracy",2020,"","","","",149,"2022-07-13 09:26:09","","","","",,,,,96,48.00,19,5,2,"Adversarial training augments the training set with perturbations to improve the robust error (over worst-case perturbations), but it often leads to an increase in the standard error (on unperturbed test inputs). Previous explanations for this tradeoff rely on the assumption that no predictor in the hypothesis class has low standard and robust error. In this work, we precisely characterize the effect of augmentation on the standard error in linear regression when the optimal linear predictor has zero standard and robust error. In particular, we show that the standard error could increase even when the augmented perturbations have noiseless observations from the optimal linear predictor. We then prove that the recently proposed robust self-training (RST) estimator improves robust error without sacrificing standard error for noiseless linear regression. Empirically, for neural networks, we find that RST with different adversarial training methods improves both standard and robust error for random and adversarial rotations and adversarial $\ell_\infty$ perturbations in CIFAR-10.","",""
75,"Vaibhav Gandhi, G. Prasad, D. Coyle, L. Behera, T. McGinnity","Quantum Neural Network-Based EEG Filtering for a Brain–Computer Interface",2014,"","","","",150,"2022-07-13 09:26:09","","10.1109/TNNLS.2013.2274436","","",,,,,75,9.38,15,5,8,"A novel neural information processing architecture inspired by quantum mechanics and incorporating the well-known Schrodinger wave equation is proposed in this paper. The proposed architecture referred to as recurrent quantum neural network (RQNN) can characterize a nonstationary stochastic signal as time-varying wave packets. A robust unsupervised learning algorithm enables the RQNN to effectively capture the statistical behavior of the input signal and facilitates the estimation of signal embedded in noise with unknown characteristics. The results from a number of benchmark tests show that simple signals such as dc, staircase dc, and sinusoidal signals embedded within high noise can be accurately filtered and particle swarm optimization can be employed to select model parameters. The RQNN filtering procedure is applied in a two-class motor imagery-based brain-computer interface where the objective was to filter electroencephalogram (EEG) signals before feature extraction and classification to increase signal separability. A two-step inner-outer fivefold cross-validation approach is utilized to select the algorithm parameters subject-specifically for nine subjects. It is shown that the subject-specific RQNN EEG filtering significantly improves brain-computer interface performance compared to using only the raw EEG or Savitzky-Golay filtered EEG across multiple sessions.","",""
18,"Claudio Ciancio, G. Ambrogio, F. Gagliardi, R. Musmanno","Heuristic techniques to optimize neural network architecture in manufacturing applications",2016,"","","","",151,"2022-07-13 09:26:09","","10.1007/s00521-015-1994-9","","",,,,,18,3.00,5,4,6,"","",""
18,"Francesco Donnarumma, R. Prevete, F. Chersi, G. Pezzulo","A Programmer-Interpreter Neural Network Architecture for Prefrontal Cognitive Control",2015,"","","","",152,"2022-07-13 09:26:09","","10.1142/S0129065715500173","","",,,,,18,2.57,5,4,7,"There is wide consensus that the prefrontal cortex (PFC) is able to exert cognitive control on behavior by biasing processing toward task-relevant information and by modulating response selection. This idea is typically framed in terms of top-down influences within a cortical control hierarchy, where prefrontal-basal ganglia loops gate multiple input-output channels, which in turn can activate or sequence motor primitives expressed in (pre-)motor cortices. Here we advance a new hypothesis, based on the notion of programmability and an interpreter-programmer computational scheme, on how the PFC can flexibly bias the selection of sensorimotor patterns depending on internal goal and task contexts. In this approach, multiple elementary behaviors representing motor primitives are expressed by a single multi-purpose neural network, which is seen as a reusable area of ""recycled"" neurons (interpreter). The PFC thus acts as a ""programmer"" that, without modifying the network connectivity, feeds the interpreter networks with specific input parameters encoding the programs (corresponding to network structures) to be interpreted by the (pre-)motor areas. Our architecture is validated in a standard test for executive function: the 1-2-AX task. Our results show that this computational framework provides a robust, scalable and flexible scheme that can be iterated at different hierarchical layers, supporting the realization of multiple goals. We discuss the plausibility of the ""programmer-interpreter"" scheme to explain the functioning of prefrontal-(pre)motor cortical hierarchies.","",""
0,"Junhee Lee, Hyeonseong Cho, Yun Jang Pyun, Suk‐Ju Kang, H. Nam","Heatmap Assisted Accuracy Score Evaluation Method for Machine-Centric Explainable Deep Neural Networks",2022,"","","","",153,"2022-07-13 09:26:09","","10.1109/access.2022.3184453","","",,,,,0,0.00,0,5,1,"There have existed many studies about the explainable artificial intelligence (XAI) that explains the logic behind the complex deep neural network called a black box. At the same time, researchers have tried to evaluate the explainability performance of various XAIs. However, most previous evaluation methods are human-centric, that is, subjective, where they rely on how much the results of explanation are similar to what people’s decision is based on rather than what features actually affect the decision in the model. Their XAI selections are also dependent of datasets. Furthermore, they are focusing only on the output variation of a target class. On the other hand, this paper proposes a robust heatmap assisted accuracy score (HAAS) scheme over datasets that helps selecting machine-centric explanation algorithms to show what actually leads to the decision of a given classification network. The proposed method modifies the input image with the heatmap scores obtained by a given explanation algorithm and then puts the resultant heatmap assisted (HA) images into the network to estimate the accuracy change. The resultant metric (<inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula>) is computed as a ratio of accuracies of the given network over HA and original images. The proposed evaluation scheme is verified in the image classification models of LeNet-5 for MNIST and VGG-16 for CIFAR-10, STL-10, and ILSVRC2012 over totally 11 XAI algorithms of saliency map, deconvolution, and 9 layer-wise relevance propagation (LRP) configurations. Consequently, for LRP1 and LRP3, MINST showed largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> values of 1.0088 and 1.0079, CIFAR-10 achieved 1.1160 and 1.1254, STL-10 had 1.0906 and 1.0918, and ILSVRC2012 got 1.3207 and 1.3469. While LRP1 consists of <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for input, convolutional, and fully-connected layers, LRP3 adopts a bounded-rule for an input layer and the same <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for other layers as LRP1. The consistency of evaluation results of HAAS and AOPC has been compared by means of Kullback-Leibler divergence, ensuring that HAAS is the more robust evaluation method than AOPC independently of datasets since HAAS has much lower average divergence of 0.0251 than AOPC of 0.3048. In addition, the validity of the proposed HAAS scheme is further investigated through the inverted HA test that employs inverted HA images made up with inverted heatmap scores and estimates the accuracy degradation caused by applying them to the network. The XAI algorithms with largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> results experience biggest accuracy degradation in the inverted HA test.","",""
93,"W. Yeh","New Parameter-Free Simplified Swarm Optimization for Artificial Neural Network Training and its Application in the Prediction of Time Series",2013,"","","","",154,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2232678","","",,,,,93,10.33,93,1,9,"A new soft computing method called the parameter-free simplified swarm optimization (SSO)-based artificial neural network (ANN), or improved SSO for short, is proposed to adjust the weights in ANNs. The method is a modification of the SSO, and seeks to overcome some of the drawbacks of SSO. In the experiments, the iSSO is compared with five other famous soft computing methods, including the backpropagation algorithm, the genetic algorithm, the particle swarm optimization (PSO) algorithm, cooperative random learning PSO, and the SSO, and its performance is tested on five famous time-series benchmark data to adjust the weights of two ANN models (multilayer perceptron and single multiplicative neuron model). The experimental results demonstrate that iSSO is robust and more efficient than the other five algorithms.","",""
15,"J. Hopfield","Understanding Emergent Dynamics: Using a Collective Activity Coordinate of a Neural Network to Recognize Time-Varying Patterns",2015,"","","","",155,"2022-07-13 09:26:09","","10.1162/NECO_a_00768","","",,,,,15,2.14,15,1,7,"Abstract In higher animals, complex and robust behaviors are produced by the microscopic details of large structured ensembles of neurons. I describe how the emergent computational dynamics of a biologically based neural network generates a robust natural solution to the problem of categorizing time-varying stimulus patterns such as spoken words or animal stereotypical behaviors. The recognition of these patterns is made difficult by their substantial variation in cadence and duration. The neural circuit behaviors used are similar to those associated with brain neural integrators. In the larger context described here, this kind of circuit becomes a building block of an entirely different computational algorithm for solving complex problems. While the network behavior is simulated in detail, a collective view is essential to understanding the results. A closed equation of motion for the collective variable describes an algorithm that quantitatively accounts for many aspects of the emergent network computation. The feedback connections and ongoing activity in the network shape the collective dynamics onto a reduced dimensionality manifold of activity space, which defines the algorithm and computation actually performed. The external inputs are weak and are not the dominant drivers of network activity.","",""
0,"K.T.Yasas Mahima, Mohamed Ayoob, Guhanathan Poravi","An Assessment of Robustness for Adversarial Attacks and Physical Distortions on Image Classification using Explainable AI",2021,"","","","",156,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,3,1,"Introducing defence mechanisms to overcome the vulnerability of adversarial attacks is a highly focused research area. However recent research highlights that introducing defence approaches for man-made adversarial attacks is not sufficient, because the deep learning models are vulnerable to the perturbations outside the scope of the training set and the physical world itself acts as an adversarial sample generator. Given this caveat, there is a necessity to introduce general defence approaches for both man-made and physical world adversarial samples. Prior to that, a brief explanation of how the model’s decision-making process happens in the inference phase under the various adversarial perturbations is required. However, the deep learning models act as black boxes in the inference phase where the decision-making is not interpretable. As a result, research on model interpretability and explainability has been carried out in the domain which is collectively known as Explainable AI. Using a set of Explainable AI techniques, this study is investigating the deep learning networks’ robustness; i.e., the decision-making process in neural networks and important pixel attributes for the predictions that are captured when the deep learning model inference gets adversarial inputs. These adversarial inputs are perturbed by adversarial attacks or the physical world adversaries using the deep learning network trained on the CIFAR10 dataset. The study reveals, that when the inference gets adversarial samples, the necessary pixel attributes for the prediction captured by the network vary everywhere in the image. However, when the network is re-trained using adversarial training or data transformation-based augmentation, it will be able to capture pixel attributes within the particular object or reduce the capture of negative pixel attributes. Based on the deductions gained from the findings, this paper states some potential research approaches to introduce a general adversarial defence method.","",""
11,"H. Suleman, A. Maulud, Z. Man","Reconciliation of outliers in CO2-alkanolamine-H2O datasets by robust neural network winsorization",2017,"","","","",157,"2022-07-13 09:26:09","","10.1007/s00521-016-2213-z","","",,,,,11,2.20,4,3,5,"","",""
0,"D. Elton","Common Pitfalls When Explaining AI and Why Mechanistic Explanation Is a Hard Problem",2021,"","","","",158,"2022-07-13 09:26:09","","10.1007/978-981-16-2377-6_38","","",,,,,0,0.00,0,1,1,"","",""
8,"F. List, N. Rodd, G. Lewis","Dim but not entirely dark: Extracting the Galactic Center Excess' source-count distribution with neural nets",2021,"","","","",159,"2022-07-13 09:26:09","","10.1103/PhysRevD.104.123022","","",,,,,8,8.00,3,3,1,"The two leading hypotheses for the Galactic Center Excess (GCE) in the Fermi data are an unresolved population of faint millisecond pulsars (MSPs) and dark-matter (DM) annihilation. The dichotomy between these explanations is typically reflected by modeling them as two separate emission components. However, point-sources (PSs) such as MSPs become statistically degenerate with smooth Poisson emission in the ultra-faint limit (formally where each source is expected to contribute much less than one photon on average), leading to an ambiguity that can render questions such as whether the emission is PS-like or Poissonian in nature ill-defined. We present a conceptually new approach that describes the PS and Poisson emission in a unified manner and only afterwards derives constraints on the Poissonian component from the so obtained results. For the implementation of this approach, we leverage deep learning techniques, centered around a neural network-based method for histogram regression that expresses uncertainties in terms of quantiles. We demonstrate that our method is robust against a number of systematics that have plagued previous approaches, in particular DM / PS misattribution. In the Fermi data, we find a faint GCE described by a median source-count distribution (SCD) peaked at a flux of ∼ 4 × 10−11 counts cm−2 s−1 (corresponding to ∼ 3− 4 expected counts per PS), which would require N ∼ O(10) sources to explain the entire excess (median value N = 29,300 across the sky). Although faint, this SCD allows us to derive the constraint ηP ≤ 66% for the Poissonian fraction of the GCE flux ηP at 95% confidence, suggesting that a substantial amount of the GCE flux is due to PSs.","",""
184,"D. Querlioz, O. Bichler, C. Gamrat","Simulation of a memristor-based spiking neural network immune to device variations",2011,"","","","",160,"2022-07-13 09:26:09","","10.1109/IJCNN.2011.6033439","","",,,,,184,16.73,61,3,11,"We propose a design methodology to exploit adaptive nanodevices (memristors), virtually immune to their variability. Memristors are used as synapses in a spiking neural network performing unsupervised learning. The memristors learn through an adaptation of spike timing dependent plasticity. Neurons' threshold is adjusted following a homeostasis-type rule. System level simulations on a textbook case show that performance can compare with traditional supervised networks of similar complexity. They also show the system can retain functionality with extreme variations of various memristors' parameters, thanks to the robustness of the scheme, its unsupervised nature, and the power of homeostasis. Additionally the network can adjust to stimuli presented with different coding schemes.","",""
47,"Qing Guo, Yi Zhang, B. Celler, S. Su","Neural Adaptive Backstepping Control of a Robotic Manipulator With Prescribed Performance Constraint",2019,"","","","",161,"2022-07-13 09:26:09","","10.1109/TNNLS.2018.2854699","","",,,,,47,15.67,12,4,3,"This paper presents an adaptive neural network (NN) control of a two-degree-of-freedom manipulator driven by an electrohydraulic actuator. To restrict the system output in a prescribed performance constraint, a weighted performance function is designed to guarantee the dynamic and steady tracking errors of joint angle in a required accuracy. Then, a radial-basis-function NN is constructed to train the unknown model dynamics of a manipulator by traditional backstepping control (TBC) and obtain the preliminary estimated model, which can replace the preknown dynamics in the backstepping iteration. Furthermore, an adaptive estimation law is adopted to self-tune every trained-node weight, and the estimated model is online optimized to enhance the robustness of the NN controller. The effectiveness of the proposed control is verified by comparative simulation and experimental results with Proportional–integral-derivative and TBC methods.","",""
25,"Hai Wang, Zhengming Xu, Do Manh Tuan, Jinchuan Zheng, Z. Cao, Linsen Xie","Neural-network-based robust control for steer-by-wire systems with uncertain dynamics",2015,"","","","",162,"2022-07-13 09:26:09","","10.1007/s00521-014-1819-2","","",,,,,25,3.57,4,6,7,"","",""
122,"Huaguang Zhang, Jinhai Liu, Dazhong Ma, Zhanshan Wang","Data-Core-Based Fuzzy Min–Max Neural Network for Pattern Classification",2011,"","","","",163,"2022-07-13 09:26:09","","10.1109/TNN.2011.2175748","","",,,,,122,11.09,31,4,11,"A fuzzy min-max neural network based on data core (DCFMN) is proposed for pattern classification. A new membership function for classifying the neuron of DCFMN is defined in which the noise, the geometric center of the hyperbox, and the data core are considered. Instead of using the contraction process of the FMNN described by Simpson, a kind of overlapped neuron with new membership function based on the data core is proposed and added to neural network to represent the overlapping area of hyperboxes belonging to different classes. Furthermore, some algorithms of online learning and classification are presented according to the structure of DCFMN. DCFMN has strong robustness and high accuracy in classification taking onto account the effect of data core and noise. The performance of DCFMN is checked by some benchmark datasets and compared with some traditional fuzzy neural networks, such as the fuzzy min-max neural network (FMNN), the general FMNN, and the FMNN with compensatory neuron. Finally the pattern classification of a pipeline is evaluated using DCFMN and other classifiers. All the results indicate that the performance of DCFMN is excellent.","",""
33,"J. A. Villacorta-Atienza, V. A. Makarov","Neural Network Architecture for Cognitive Navigation in Dynamic Environments",2013,"","","","",164,"2022-07-13 09:26:09","","10.1109/TNNLS.2013.2271645","","",,,,,33,3.67,17,2,9,"Navigation in time-evolving environments with moving targets and obstacles requires cognitive abilities widely demonstrated by even simplest animals. However, it is a long-standing challenging problem for artificial agents. Cognitive autonomous robots coping with this problem must solve two essential tasks: 1) understand the environment in terms of what may happen and how I can deal with this and 2) learn successful experiences for their further use in an automatic subconscious way. The recently introduced concept of compact internal representation (CIR) provides the ground for both the tasks. CIR is a specific cognitive map that compacts time-evolving situations into static structures containing information necessary for navigation. It belongs to the class of global approaches, i.e., it finds trajectories to a target when they exist but also detects situations when no solution can be found. Here we extend the concept of situations with mobile targets. Then using CIR as a core, we propose a closed-loop neural network architecture consisting of conscious and subconscious pathways for efficient decision-making. The conscious pathway provides solutions to novel situations if the default subconscious pathway fails to guide the agent to a target. Employing experiments with roving robots and numerical simulations, we show that the proposed architecture provides the robot with cognitive abilities and enables reliable and flexible navigation in realistic time-evolving environments. We prove that the subconscious pathway is robust against uncertainty in the sensory information. Thus if a novel situation is similar but not identical to the previous experience (because of, e.g., noisy perception) then the subconscious pathway is able to provide an effective solution.","",""
52,"Mathias Lechner, Ramin M. Hasani, Alexander Amini, T. Henzinger, D. Rus, R. Grosu","Neural circuit policies enabling auditable autonomy",2020,"","","","",165,"2022-07-13 09:26:09","","10.1038/s42256-020-00237-3","","",,,,,52,26.00,9,6,2,"","",""
14,"N. Strisciuglio, Manuel López-Antequera, N. Petkov","Enhanced robustness of convolutional networks with a push–pull inhibition layer",2020,"","","","",166,"2022-07-13 09:26:09","","10.1007/s00521-020-04751-8","","",,,,,14,7.00,5,3,2,"","",""
45,"Yimeng Qi, Long Jin, Yaonan Wang, Lin Xiao, Jiliang Zhang","Complex-Valued Discrete-Time Neural Dynamics for Perturbed Time-Dependent Complex Quadratic Programming With Applications",2019,"","","","",167,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2944992","","",,,,,45,15.00,9,5,3,"It has been reported that some specially designed recurrent neural networks and their related neural dynamics are efficient for solving quadratic programming (QP) problems in the real domain. A complex-valued QP problem is generated if its variable vector is composed of the magnitude and phase information, which is often depicted in a time-dependent form. Given the important role that complex-valued problems play in cybernetics and engineering, computational models with high accuracy and strong robustness are urgently needed, especially for time-dependent problems. However, the research on the online solution of time-dependent complex-valued problems has been much less investigated compared to time-dependent real-valued problems. In this article, to solve the online time-dependent complex-valued QP problems subject to linear constraints, two new discrete-time neural dynamics models, which can achieve global convergence performance in the presence of perturbations with the provided theoretical analyses, are proposed and investigated. In addition, the second proposed model is developed to eliminate the operation of explicit matrix inversion by introducing the quasi-Newton Broyden–Fletcher–Goldfarb–Shanno (BFGS) method. Moreover, computer simulation results and applications in robotics and filters are provided to illustrate the feasibility and superiority of the proposed models in comparison with the existing solutions.","",""
5,"Mohammed Bany Muhammad, M. Yeasin","Eigen-CAM: Visual Explanations for Deep Convolutional Neural Networks",2021,"","","","",168,"2022-07-13 09:26:09","","10.1007/s42979-021-00449-3","","",,,,,5,5.00,3,2,1,"","",""
130,"David Sussillo, P. Nuyujukian, Joline M. Fan, J. Kao, S. Stavisky, S. Ryu, K. Shenoy","A recurrent neural network for closed-loop intracortical brain-machine interface decoders.",2012,"","","","",169,"2022-07-13 09:26:09","","10.1088/1741-2560/9/2/026027","","",,,,,130,13.00,19,7,10,"Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships in time series data with complex temporal dependences. In this paper, we explore the ability of a simplified type of RNN, one with limited modifications to the internal weights called an echostate network (ESN), to effectively and continuously decode monkey reaches during a standard center-out reach task using a cortical brain-machine interface (BMI) in a closed loop. We demonstrate that the RNN, an ESN implementation termed a FORCE decoder (from first order reduced and controlled error learning), learns the task quickly and significantly outperforms the current state-of-the-art method, the velocity Kalman filter (VKF), using the measure of target acquire time. We also demonstrate that the FORCE decoder generalizes to a more difficult task by successfully operating the BMI in a randomized point-to-point task. The FORCE decoder is also robust as measured by the success rate over extended sessions. Finally, we show that decoded cursor dynamics are more like naturalistic hand movements than those of the VKF. Taken together, these results suggest that RNNs in general, and the FORCE decoder in particular, are powerful tools for BMI decoder applications.","",""
74,"A. Azar","Fast neural network learning algorithms for medical applications",2013,"","","","",170,"2022-07-13 09:26:09","","10.1007/s00521-012-1026-y","","",,,,,74,8.22,74,1,9,"","",""
34,"H. Dinh, R. Kamalapurkar, S. Bhasin, W. Dixon","Dynamic neural network-based robust observers for uncertain nonlinear systems",2014,"","","","",171,"2022-07-13 09:26:09","","10.1016/j.neunet.2014.07.009","","",,,,,34,4.25,9,4,8,"","",""
11,"Philipp Benz, Chaoning Zhang, Adil Karjauv, I. Kweon","Robustness May Be at Odds with Fairness: An Empirical Study on Class-wise Accuracy",2020,"","","","",172,"2022-07-13 09:26:09","","","","",,,,,11,5.50,3,4,2,"Recently, convolutional neural networks (CNNs) have made significant advancement, however, they are widely known to be vulnerable to adversarial attacks. Adversarial training is the most widely used technique for improving adversarial robustness to strong white-box attacks. Prior works have been evaluating and improving the model average robustness without per-class evaluation. The average evaluation alone might provide a false sense of robustness. For example, the attacker can focus on attacking the vulnerable class, which can be dangerous, especially, when the vulnerable class is a critical one, such as ""human"" in autonomous driving. In this preregistration submission, we propose an empirical study on the class-wise accuracy and robustness of adversarially trained models. Given that the CIFAR10 training dataset has an equal number of samples for each class, interestingly, preliminary results on it with Resnet18 show that there exists inter-class discrepancy for accuracy and robustness on standard models, for instance, ""cat"" is more vulnerable than other classes. Moreover, adversarial training increases inter-class discrepancy. Our work aims to investigate the following questions: (a) is the phenomenon of inter-class discrepancy universal for other classification benchmark datasets on other seminal model architectures with various optimization hyper-parameters? (b) If so, what can be possible explanations for the inter-class discrepancy? (c) Can the techniques proposed in the long tail classification be readily extended to adversarial training for addressing the inter-class discrepancy?","",""
7,"Laura Rieger, L. K. Hansen","Aggregating explanation methods for stable and robust explainability.",2019,"","","","",173,"2022-07-13 09:26:09","","","","",,,,,7,2.33,4,2,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. We provide evidence that the aggregation is better at identifying important features, than on individual methods. Adversarial attacks on explanations is a recent active research topic. As our second contribution, we present evidence that aggregate explanations are much more robust to attacks than individual explanation methods.","",""
18,"M. Witczak, M. Mrugalski, J. Korbicz","Towards Robust Neural-Network-Based Sensor and Actuator Fault Diagnosis: Application to a Tunnel Furnace",2015,"","","","",174,"2022-07-13 09:26:09","","10.1007/s11063-014-9387-0","","",,,,,18,2.57,6,3,7,"","",""
2,"Jian-Fang Zhou, Wu-Jie Yuan, Zhao Zhou, Changsong Zhou","Model predictions of features in microsaccade-related neural responses in a feedforward network with short-term synaptic depression",2016,"","","","",175,"2022-07-13 09:26:09","","10.1038/srep20888","","",,,,,2,0.33,1,4,6,"","",""
12,"Laura Rieger, L. K. Hansen","IROF: a low resource evaluation metric for explanation methods",2020,"","","","",176,"2022-07-13 09:26:09","","","","",,,,,12,6.00,6,2,2,"The adoption of machine learning in health care hinges on the transparency of the used algorithms, necessitating the need for explanation methods. However, despite a growing literature on explaining neural networks, no consensus has been reached on how to evaluate those explanation methods. We propose IROF, a new approach to evaluating explanation methods that circumvents the need for manual evaluation. Compared to other recent work, our approach requires several orders of magnitude less computational resources and no human input, making it accessible to lower resource groups and robust to human bias.","",""
39,"Jacob R. Kauffmann, Malte Esders, G. Montavon, W. Samek, K. Müller","From Clustering to Cluster Explanations via Neural Networks",2019,"","","","",177,"2022-07-13 09:26:09","","10.1109/TNNLS.2022.3185901","","",,,,,39,13.00,8,5,3,"A recent trend in machine learning has been to enrich learned models with the ability to explain their own predictions. The emerging field of explainable AI (XAI) has so far mainly focused on supervised learning, in particular, deep neural network classifiers. In many practical problems, however, the label information is not given and the goal is instead to discover the underlying structure of the data, for example, its clusters. While powerful methods exist for extracting the cluster structure in data, they typically do not answer the question why a certain data point has been assigned to a given cluster. We propose a new framework that can, for the first time, explain cluster assignments in terms of input features in an efficient and reliable manner. It is based on the novel insight that clustering models can be rewritten as neural networks-or ""neuralized."" Cluster predictions of the obtained networks can then be quickly and accurately attributed to the input features. Several showcases demonstrate the ability of our method to assess the quality of learned clusters and to extract novel insights from the analyzed data and representations.","",""
39,"H. Singh, N. Sukavanam","Stability analysis of robust adaptive hybrid position/force controller for robot manipulators using neural network with uncertainties",2013,"","","","",178,"2022-07-13 09:26:09","","10.1007/s00521-012-0966-6","","",,,,,39,4.33,20,2,9,"","",""
4,"Theodoros Tsiligkaridis, Jay Roberts","On Frank-Wolfe Optimization for Adversarial Robustness and Interpretability",2020,"","","","",179,"2022-07-13 09:26:09","","","","",,,,,4,2.00,2,2,2,"Deep neural networks are easily fooled by small perturbations known as adversarial attacks. Adversarial Training (AT) is a technique that approximately solves a robust optimization problem to minimize the worst-case loss and is widely regarded as the most effective defense against such attacks. While projected gradient descent (PGD) has received most attention for approximately solving the inner maximization of AT, Frank-Wolfe (FW) optimization is projection-free and can be adapted to any L norm. A Frank-Wolfe adversarial training approach is presented and is shown to provide as competitive level of robustness as PGD-AT without much tuning for a variety of architectures. We empirically show that robustness is strongly connected to the L magnitude of the adversarial perturbation and that more locally linear loss landscapes tend to have larger L distortions despite having the same L∞ distortion. We provide theoretical guarantees on the magnitude of the distortion for FW that depend on local geometry which FW-AT exploits. It is empirically shown that FW-AT achieves strong robustness to white-box attacks and black-box attacks and offers improved resistance to gradient masking. Further, FW-AT allows networks to learn highquality human-interpretable features which are then used to generate counterfactual explanations to model predictions by using dense and sparse adversarial perturbations.","",""
20,"Bernhard A. Kaplan, A. Lansner","A spiking neural network model of self-organized pattern recognition in the early mammalian olfactory system",2014,"","","","",180,"2022-07-13 09:26:09","","10.3389/fncir.2014.00005","","",,,,,20,2.50,10,2,8,"Olfactory sensory information passes through several processing stages before an odor percept emerges. The question how the olfactory system learns to create odor representations linking those different levels and how it learns to connect and discriminate between them is largely unresolved. We present a large-scale network model with single and multi-compartmental Hodgkin–Huxley type model neurons representing olfactory receptor neurons (ORNs) in the epithelium, periglomerular cells, mitral/tufted cells and granule cells in the olfactory bulb (OB), and three types of cortical cells in the piriform cortex (PC). Odor patterns are calculated based on affinities between ORNs and odor stimuli derived from physico-chemical descriptors of behaviorally relevant real-world odorants. The properties of ORNs were tuned to show saturated response curves with increasing concentration as seen in experiments. On the level of the OB we explored the possibility of using a fuzzy concentration interval code, which was implemented through dendro-dendritic inhibition leading to winner-take-all like dynamics between mitral/tufted cells belonging to the same glomerulus. The connectivity from mitral/tufted cells to PC neurons was self-organized from a mutual information measure and by using a competitive Hebbian–Bayesian learning algorithm based on the response patterns of mitral/tufted cells to different odors yielding a distributed feed-forward projection to the PC. The PC was implemented as a modular attractor network with a recurrent connectivity that was likewise organized through Hebbian–Bayesian learning. We demonstrate the functionality of the model in a one-sniff-learning and recognition task on a set of 50 odorants. Furthermore, we study its robustness against noise on the receptor level and its ability to perform concentration invariant odor recognition. Moreover, we investigate the pattern completion capabilities of the system and rivalry dynamics for odor mixtures.","",""
96,"An‐Min Zou, K. Kumar","Neural Network-Based Distributed Attitude Coordination Control for Spacecraft Formation Flying With Input Saturation",2012,"","","","",181,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2196710","","",,,,,96,9.60,48,2,10,"This brief considers the attitude coordination control problem for spacecraft formation flying when only a subset of the group members has access to the common reference attitude. A quaternion-based distributed attitude coordination control scheme is proposed with consideration of the input saturation and with the aid of the sliding-mode observer, separation principle theorem, Chebyshev neural networks, smooth projection algorithm, and robust control technique. Using graph theory and a Lyapunov-based approach, it is shown that the distributed controller can guarantee the attitude of all spacecraft to converge to a common time-varying reference attitude when the reference attitude is available only to a portion of the group of spacecraft. Numerical simulations are presented to demonstrate the performance of the proposed distributed controller.","",""
0,"Sara Fridovich-Keil, Brian Bartoldson, James Diffenderfer, B. Kailkhura, P. Bremer","Models Out of Line: A Fourier Lens on Distribution Shift Robustness",2022,"","","","",182,"2022-07-13 09:26:09","","","","",,,,,0,0.00,0,5,1,"Improving the accuracy of deep neural networks (DNNs) on out-of-distribution (OOD) data is critical to an acceptance of deep learning (DL) in real world applications. It has been observed that accuracies on in-distribution (ID) versus OOD data follow a linear trend and models that outperform this baseline are exceptionally rare (and referred to as “effectively robust”). Recently, some promising approaches have been developed to improve OOD robustness: model pruning, data augmentation, and ensembling or zero-shot evaluating large pretrained models. However, there still is no clear understanding of the conditions on OOD data and model properties that are required to observe effective robustness. We approach this issue by conducting a comprehensive empirical study of diverse approaches that are known to impact OOD robustness on a broad range of natural and synthetic distribution shifts of CIFAR-10 and ImageNet. In particular, we view the “effective robustness puzzle"" through a Fourier lens and ask how spectral properties of both models and OOD data inﬂuence the corresponding effective robustness. We ﬁnd this Fourier lens offers some insight into why certain robust models, particularly those from the CLIP family, achieve OOD robustness. However, our analysis also makes clear that no known metric is consistently the best explanation (or even a strong explanation) of OOD robustness. Thus, to aid future research into the OOD puzzle, we address the gap in publicly-available models with effective robustness by introducing a set of pretrained models— RobustNets —with varying levels of OOD robustness.","",""
0,"Abderrahmen Amich, Birhanu Eshete","EG-Booster: Explanation-Guided Booster of ML Evasion Attacks",2021,"","","","",183,"2022-07-13 09:26:09","","10.1145/3508398.3511510","","",,,,,0,0.00,0,2,1,"The widespread usage of machine learning (ML) in a myriad of domains has raised questions about its trustworthiness in high-stakes environments. Part of the quest for trustworthy ML is assessing robustness to test-time adversarial examples. Inline with the trustworthy ML goal, a useful input to potentially aid robustness evaluation is feature-based explanations of model predictions. In this paper, we present a novel approach, called EG-Booster, that leverages techniques from explainable ML to guide adversarial example crafting for improved robustness evaluation of ML models. The key insight in EG-Booster is the use of feature-based explanations of model predictions to guide adversarial example crafting by adding consequential perturbations (likely to result in model evasion) and avoiding non-consequential perturbations (unlikely to contribute to evasion). EG-Booster is agnostic to model architecture, threat model, and supports diverse distance metrics used in the literature. We evaluate EG-Booster using image classification benchmark datasets: MNIST and CIFAR10. Our findings suggest that EG-Booster significantly improves the evasion rate of state-of-the-art attacks while performing a smaller number of perturbations. Through extensive experiments that cover four white-box and three black-box attacks, we demonstrate the effectiveness of EG-Booster against two undefended neural networks trained on MNIST and CIFAR10, and an adversarially-trained ResNet model trained on CIFAR10. Furthermore, we introduce a stability assessment metric and evaluate the reliability of our explanation-based attack boosting approach by tracking the similarity between the model's predictions across multiple runs of EG-Booster. Our results over 10 separate runs suggest that EG-Booster's output is stable across distinct runs. Combined with state-of-the-art attacks, we hope EG-Booster will be used towards improved robustness assessment of ML models against evasion attacks.","",""
1,"Yuyang Gao, Tong Sun, Guang-ying Bai, Siyi Gu, S. Hong, Liang Zhao","RES: A Robust Framework for Guiding Visual Explanation",2022,"","","","",184,"2022-07-13 09:26:09","","10.1145/3534678.3539419","","",,,,,1,1.00,0,6,1,"Despite the fast progress of explanation techniques in modern Deep Neural Networks (DNNs) where the main focus is handling “how to generate the explanations”, advanced research questions that exam-ine the quality of the explanation itself (e.g., “whether the explanations are accurate”) and improve the explanation quality (e.g., “how to adjust the model to generate more accurate explanations when explanations are inaccurate”) are still relatively under-explored. To guide the model toward better explanations, techniques in explanation supervision—which add supervision signals on the model explanation—have started to show promising effects on improving both the generalizability as and intrinsic interpretability of Deep Neural Networks. However, the research on supervising explanations, especially in vision-based applications represented through saliency maps, is in its early stage due to several inherent challenges: 1) inaccuracy of the human explanation annotation boundary, 2) incompleteness of the human explanation annotation region, and 3) inconsistency of the data distribution between human annotation and model explanation maps. To address the challenges, we propose a generic RES 1 framework for guiding visual explanation by developing a novel objective that handles inaccurate boundary, incomplete region, and inconsistent distribution of human annotations, with a theoretical justification on model generalizability. Extensive experiments on two real-world image datasets demonstrate the effectiveness of the proposed framework on enhancing","",""
22,"Masaki Kobayashi","Noise Robust Projection Rule for Hyperbolic Hopfield Neural Networks",2020,"","","","",185,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2899914","","",,,,,22,11.00,22,1,2,"A complex-valued Hopfield neural network (CHNN) is a multistate Hopfield model. Low noise tolerance is the main disadvantage of CHNNs. The hyperbolic Hopfield neural network (HHNN) is a noise robust multistate Hopfield model. In HHNNs employing the projection rule, noise tolerance rapidly worsened as the number of training patterns increased. This result was caused by the self-loops. The projection rule for CHNNs improves noise tolerance by removing the self-loops, however, that for HHNNs cannot remove them. In this brief, we extended the stability condition for the self-loops of HHNNs and modified the projection rule. Thus, the HHNNs had improved noise tolerance.","",""
33,"V. Nguyen, J. Starzyk, Wooi-Boon Goh, Daniel Jachyra","Neural Network Structure for Spatio-Temporal Long-Term Memory",2012,"","","","",186,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2191419","","",,,,,33,3.30,8,4,10,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","",""
31,"M. Senapati, P. Dash","Local linear wavelet neural network based breast tumor classification using firefly algorithm",2013,"","","","",187,"2022-07-13 09:26:09","","10.1007/s00521-012-0927-0","","",,,,,31,3.44,16,2,9,"","",""
47,"W. Yao, Xiaoqian Chen, Yong Zhao, M. V. Tooren","Concurrent Subspace Width Optimization Method for RBF Neural Network Modeling",2012,"","","","",188,"2022-07-13 09:26:09","","10.1109/TNNLS.2011.2178560","","",,,,,47,4.70,12,4,10,"Radial basis function neural networks (RBFNNs) are widely used in nonlinear function approximation. One of the challenges in RBFNN modeling is determining how to effectively optimize width parameters to improve approximation accuracy. To solve this problem, a width optimization method, concurrent subspace width optimization (CSWO), is proposed based on a decomposition and coordination strategy. This method decomposes the large-scale width optimization problem into several subspace optimization (SSO) problems, each of which has a single optimization variable and smaller training and validation data sets so as to greatly simplify optimization complexity. These SSOs can be solved concurrently, thus computational time can be effectively reduced. With top-level system coordination, the optimization of SSOs can converge to a consistent optimum, which is equivalent to the optimum of the original width optimization problem. The proposed method is tested with four mathematical examples and one practical engineering approximation problem. The results demonstrate the efficiency and robustness of CSWO in optimizing width parameters over the traditional width optimization methods.","",""
28,"Qinmin Yang, Zaiyue Yang, Youxian Sun","Universal Neural Network Control of MIMO Uncertain Nonlinear Systems",2012,"","","","",189,"2022-07-13 09:26:09","","10.1109/TNNLS.2012.2197219","","",,,,,28,2.80,9,3,10,"In this brief, a continuous tracking control law is proposed for a class of high-order multi-input-multi-output uncertain nonlinear dynamic systems with external disturbance and unknown varying control direction matrix. The proposed controller consists of high-gain feedback, Nussbaum gain matrix selector, online approximator (OLA) model and a robust term. The OLA model is represented by a two-layer neural network. The continuousness of the control signal is guaranteed to relax the requirement for the actuator bandwidth and avoid the incurred chattering effect. Asymptotic tracking performance is achieved theoretically by standard Lyapunov analysis. The control feasibility is also verified in simulation environment.","",""
24,"Ç. Aladag, E. Egrioglu, U. Yolcu","Robust multilayer neural network based on median neuron model",2014,"","","","",190,"2022-07-13 09:26:09","","10.1007/s00521-012-1315-5","","",,,,,24,3.00,8,3,8,"","",""
19,"J. Townsend, Thomas Chaton, J. Monteiro","Extracting Relational Explanations From Deep Neural Networks: A Survey From a Neural-Symbolic Perspective",2020,"","","","",191,"2022-07-13 09:26:09","","10.1109/TNNLS.2019.2944672","","",,,,,19,9.50,6,3,2,"The term “explainable AI” refers to the goal of producing artificially intelligent agents that are capable of providing explanations for their decisions. Some models (e.g., rule-based systems) are designed to be explainable, while others are less explicit “black boxes” for which their reasoning remains a mystery. One example of the latter is the neural network, and over the past few decades, researchers in the field of neural-symbolic integration (NSI) have sought to extract relational knowledge from such networks. Extraction from deep neural networks, however, has remained a challenge until recent years in which many methods of extracting distinct, salient features from input or hidden feature spaces of deep neural networks have been proposed. Furthermore, methods of identifying relationships between these features have also emerged. This article presents examples of old and new developments in extracting relational explanations in order to argue that the latter have analogies in the former and, as such, can be described in terms of long-established taxonomies and frameworks presented in early neural-symbolic literature. We also outline potential future research directions that come to light from this refreshed perspective.","",""
22,"Tong Wang, S. Tong, Yong-ming Li","Adaptive neural network output feedback control of stochastic nonlinear systems with dynamical uncertainties",2013,"","","","",192,"2022-07-13 09:26:09","","10.1007/s00521-012-1099-7","","",,,,,22,2.44,7,3,9,"","",""
28,"Song Zhu, Yi Shen","Robustness analysis for connection weight matrices of global exponential stability of stochastic recurrent neural networks",2013,"","","","",193,"2022-07-13 09:26:09","","10.1016/j.neunet.2012.10.004","","",,,,,28,3.11,14,2,9,"","",""
1,"S. Matveev, I. Oseledets, E. Ponomarev, A. Chertkov","Overview of Visualization Methods for Artificial Neural Networks",2021,"","","","",194,"2022-07-13 09:26:09","","10.1134/S0965542521050134","","",,,,,1,1.00,0,4,1,"","",""
59,"Yu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, W. Hsu, Cho-Jui Hsieh","On the Robustness of Self-Attentive Models",2019,"","","","",195,"2022-07-13 09:26:09","","10.18653/v1/P19-1147","","",,,,,59,19.67,10,6,3,"This work examines the robustness of self-attentive neural networks against adversarial input perturbations. Specifically, we investigate the attention and feature extraction mechanisms of state-of-the-art recurrent neural networks and self-attentive architectures for sentiment analysis, entailment and machine translation under adversarial attacks. We also propose a novel attack algorithm for generating more natural adversarial examples that could mislead neural models but not humans. Experimental results show that, compared to recurrent neural models, self-attentive models are more robust against adversarial perturbation. In addition, we provide theoretical explanations for their superior robustness to support our claims.","",""
8,"Seyed Iman Mirzadeh, Arslan Chaudhry, Huiyi Hu, Razvan Pascanu, Dilan Gorur, Mehrdad Farajtabar","Wide Neural Networks Forget Less Catastrophically",2021,"","","","",196,"2022-07-13 09:26:09","","","","",,,,,8,8.00,1,6,1,"A growing body of research in continual learning is devoted to overcoming the “Catastrophic Forgetting” of neural networks by designing new algorithms that are more robust to the distribution shifts. While the recent progress in continual learning literature is encouraging, our understanding of what properties of neural networks contribute to catastrophic forgetting is still limited. To address this, instead of focusing on continual learning algorithms, in this work, we focus on the model itself and study the impact of “width” of the neural network architecture on catastrophic forgetting, and show that width has a surprisingly significant effect on forgetting. To explain this effect, we study the learning dynamics of the network from various perspectives such as gradient norm and sparsity, orthogonalization, and lazy training regime. We provide potential explanations that are consistent with the empirical results across different architectures and continual learning benchmarks.","",""
92,"N. Punn, Sonali Agarwal","Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray images using fine-tuned deep neural networks",2020,"","","","",197,"2022-07-13 09:26:09","","10.1007/s10489-020-01900-3","","",,,,,92,46.00,46,2,2,"","",""
14,"Weiwei Luo, Kai Zhong, Song Zhu, Yi Shen","Further results on robustness analysis of global exponential stability of recurrent neural networks with time delays and random disturbances",2014,"","","","",198,"2022-07-13 09:26:09","","10.1016/j.neunet.2014.02.007","","",,,,,14,1.75,4,4,8,"","",""
37,"Devon K. Barrow, S. Crone, N. Kourentzes","An evaluation of neural network ensembles and model selection for time series prediction",2010,"","","","",199,"2022-07-13 09:26:09","","10.1109/IJCNN.2010.5596686","","",,,,,37,3.08,12,3,12,"Ensemble methods represent an approach to combine a set of models, each capable of solving a given task, but which together produce a composite global model whose accuracy and robustness exceeds that of the individual models. Ensembles of neural networks have traditionally been applied to machine learning and pattern recognition but more recently have been applied to forecasting of time series data. Several methods have been developed to produce neural network ensembles ranging from taking a simple average of individual model outputs to more complex methods such as bagging and boosting. Which ensemble method is best; what factors affect ensemble performance, under what data conditions are ensembles most useful and when is it beneficial to use ensembles over model selection are a few questions which remain unanswered. In this paper we present some initial findings using neural network ensembles based on the mean and median applied to forecast synthetic time series data. We vary factors such as the number of models included in the ensemble and how the models are selected, whether randomly or based on performance. We compare the performance of different ensembles to model selection and present the results.","",""
21,"Yiwen Yang, Yunong Zhang","Superior robustness of power-sum activation functions in Zhang neural networks for time-varying quadratic programs perturbed with large implementation errors",2011,"","","","",200,"2022-07-13 09:26:09","","10.1007/s00521-011-0692-5","","",,,,,21,1.91,11,2,11,"","",""
