Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
9,"Nathalie A. Smuha, Emma Ahmed-Rengers, Adam Harkens, Wenlong Li, J. Maclaren, Riccardo Piselli, K. Yeung","How the EU Can Achieve Legally Trustworthy AI: A Response to the European Commission’s Proposal for an Artificial Intelligence Act",2021,"","","","",1,"2022-07-13 09:36:00","","10.2139/ssrn.3899991","","",,,,,9,9.00,1,7,1,"This document contains the response to the European Commission’s Proposal for an Artificial Intelligence Act from members of the Legal, Ethical & Accountable Digital Society (LEADS) Lab at the University of Birmingham. The Proposal seeks to give expression to the concept of ‘Lawful AI.’ This concept was mentioned, but not developed in the Commission’s High-Level Expert Group on AI’s Ethics Guidelines for Trustworthy AI (2019), which instead confined its discussion to the concepts of ‘Ethical’ and ‘Robust’ AI. After a brief introduction (Chapter 1), we set out the many aspects of the Proposal which we welcome, and stress our wholehearted support for its aim to protect fundamental rights (Chapter 2). Subsequently, we develop the concept of ‘Legally Trustworthy AI,’ arguing that it should be grounded in respect for three pillars on which contemporary liberal democratic societies are founded, namely: fundamental rights, the rule of law, and democracy (Chapter 3). Drawing on this conceptual framework, we first argue that the Proposal fails to reflect fundamental rights as claims with enhanced moral and legal status, which subjects any rights interventions to a demanding regime of scrutiny and must satisfy tests of necessity and proportionality. Moreover, the Proposal does not always accurately recognise the wrongs and harms associated with different kinds of AI systems and appropriately allocates responsibility for them. Second, the Proposal does not provide an effective framework for the enforcement of legal rights and duties, and does not ensure legal certainty and consistency, which are essential for the rule of law. Third, the Proposal neglects to ensure meaningful transparency, accountability, and rights of public participation, thereby failing to reflect adequate protection for democracy (Chapter 4). Based on these shortcomings in respecting and promoting the three pillars of Legally Trustworthy AI, we provide detailed recommendations for the Proposal’s revision (Chapter 5).","",""
7,"Vinicius M. Alves, S. Auerbach, N. Kleinstreuer, J. Rooney, E. Muratov, I. Rusyn, A. Tropsha, Charles Schmitt","Curated Data In — Trustworthy In Silico Models Out: The Impact of Data Quality on the Reliability of Artificial Intelligence Models as Alternatives to Animal Testing",2021,"","","","",2,"2022-07-13 09:36:00","","10.1177/02611929211029635","","",,,,,7,7.00,1,8,1,"New Approach Methodologies (NAMs) that employ artificial intelligence (AI) for predicting adverse effects of chemicals have generated optimistic expectations as alternatives to animal testing. However, the major underappreciated challenge in developing robust and predictive AI models is the impact of the quality of the input data on the model accuracy. Indeed, poor data reproducibility and quality have been frequently cited as factors contributing to the crisis in biomedical research, as well as similar shortcomings in the fields of toxicology and chemistry. In this article, we review the most recent efforts to improve confidence in the robustness of toxicological data and investigate the impact that data curation has on the confidence in model predictions. We also present two case studies demonstrating the effect of data curation on the performance of AI models for predicting skin sensitisation and skin irritation. We show that, whereas models generated with uncurated data had a 7–24% higher correct classification rate (CCR), the perceived performance was, in fact, inflated owing to the high number of duplicates in the training set. We assert that data curation is a critical step in building computational models, to help ensure that reliable predictions of chemical toxicity are achieved through use of the models.","",""
2,"D. Rawat","Secure and trustworthy machine learning/artificial intelligence for multi-domain operations",2021,"","","","",3,"2022-07-13 09:36:00","","10.1117/12.2592860","","",,,,,2,2.00,2,1,1,"Machine Learning (ML) algorithms and Artificial Intelligence (AI) are now regarded as very useful for data-driven applications including resilient multi-domain operations. However, ML algorithms and AI systems can be controlled, dodged, biased, and misled through flawed learning models and input data, they need robust security features and trust. Furthermore, ML algorithms and AI systems add challenges when we have (unlabeled/labeled) sparse/small data or big data for training and evaluation. It is very important to design, evaluate and test ML algorithms and AI systems that produce reliable, robust, trustworthy, explainable, and fair/unbiased outcomes to make them acceptable and reliable in mission critical multi-domain operations. ML algorithms rely on data and work on the principle of ``Garbage In, Garbage Out,"" which means that if the input data to learning model is corrupted or compromised, the outcomes of the ML/AI would not be optimal, reliable and trustworthy.","",""
0,"Bern Beckert","The European way of doing Artificial Intelligence: The state of play implementing Trustworthy AI",2021,"","","","",4,"2022-07-13 09:36:00","","10.1109/fitce53297.2021.9588560","","",,,,,0,0.00,0,1,1,"“Trustworthy AI” is the concept of the European Commission to facilitate acceptance and diffusion of Artificial Intelligence in Europe. The concept claims that European AI applications shall be lawful, ethical and robust, both from a technical and societal perspective. The contribution asks for the state of play of implementing the concept of Trustworthy AI. More concretely, it sets out to identify concrete cases of implementing Trustworthy AI in order to analyse approaches and experiences. However, it turns out that such projects currently only exist in a research context and at neither large companies nor start-ups or medium-sized companies provide suitable examples, with only a few exceptions. This gives rise to the question, why companies today ignore or even avoid the carefully worked out guidelines to implement Trustworthy AI. Three answers are given which refer to time-to-market considerations, different mindsets of software engineers and social scientists, and the fact that implementing Trustworthy AI requires of firms to go the extra mile with additional expertise and governance structures. Following this, two possibilities are presented to increase in the number of companies actually picking up on the guidelines and concretely implementing Trustworthy AI. These possibilities are firstly to break down existing implementation guidelines to the requirements of software engineers, computer scientists and managers, and secondly to embed social scientists and stakeholders in the implementation process.","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",5,"2022-07-13 09:36:00","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
3,"Hongmei He, J. Gray, A. Cangelosi, Q. Meng, T. McGinnity, J. Mehnen","The challenges and opportunities of artificial intelligence in implementing trustworthy robotics and autonomous systems",2020,"","","","",6,"2022-07-13 09:36:00","","","","",,,,,3,1.50,1,6,2,"Effective Robots and Autonomous Systems (RAS) must be trustworthy. Trust is essential in designing autonomous and semi-autonomous technologies, because “No trust, no use”. RAS should provide high quality of services, with the four key properties that make it trust, i.e. they must be (i) robust for any health issues, (ii) safe for any matters in their surrounding environments, (iii) secure for any threats from cyber spaces, and (iv) trusted for human-machine interaction. We have thoroughly analysed the challenges in implementing the trustworthy RAS in respects of the four properties, and addressed the power of AI in improving the trustworthiness of RAS. While we put our eyes on the beneﬁts that AI brings to human, we should realise the potential risks that could be caused by AI. The new concept of human-centred AI will be the core in implementing the trustworthy RAS. This review could provide a brief reference for the research on AI for trustworthy RAS.","",""
3,"Hongmei He, J. Gray, A. Cangelosi, Q. Meng, T. McGinnity, J. Mehnen","The Challenges and Opportunities of Artificial Intelligence for Trustworthy Robots and Autonomous Systems",2020,"","","","",7,"2022-07-13 09:36:00","","10.1109/IRCE50905.2020.9199244","","",,,,,3,1.50,1,6,2,"Trust is essential in designing autonomous and semiautonomous Robots and Autonomous Systems (RAS), because of the “No trust, no use” concept. RAS should provide high quality services, with four key properties that make them trustworthy: they must be (i) robust with regards to any system health related issues, (ii) safe for any matters in their surrounding environments, (iii) secure against any threats from cyber spaces, and (iv) trusted for human-machine interaction. This article thoroughly analyses the challenges in implementing the trustworthy RAS in respects of the four properties, and addresses the power of AI in improving the trustworthiness of RAS. While we focus on the benefits that AI brings to human, we should realize the potential risks that could be caused by AI. This article introduces for the first time the set of key aspects of human-centered AI for RAS, which can serve as a cornerstone for implementing trustworthy RAS by design in the future.","",""
0,"Migle Laukyte","TRUSTWORTHY ARTIFICIAL INTELLIGENCE AND HUMAN RIGHTS",2020,"","","","",8,"2022-07-13 09:36:00","","10.2307/j.ctv102bm6p.8","","",,,,,0,0.00,0,1,2,"In April 2019, High-Level Expert Group on Artificial Intelligence, set up by the European Commission, has published its Ethics Guidelines for Trustworthy Artificial Intelligence (AI), which addresses the future of AI development in Europe. In particular, these Guidelines work out a vision of AI that Europe should foster and indicates the features that any AI-based system should have: the framework is composed of three parts, namely, lawful, ethical and robust AI. The Guidelines do not deal with the first of these parts—lawful AI—where, among other things, authors include the necessity that AI would respect fundamental human rights: this is the so called “fundamental-rights based approach” which is the approach that EU promotes with respect to AI.  As the Expert Group prefers to focus on ethics and robustness of AI, this paper will focus on lawfulness of AI. In particular, I will focus on the impact that AI could have on human rights, established in the Charter of the Fundamental Rights of the European Union (EU), other relevant international treaties, and specific regulations such as General Data Protection Regulation. The Guidelines list some of the human rights that should be the foundational stones for any AI within the EU, namely, protection of human dignity and human freedoms in the broad sense of the term, respect for democracy, justice and the rule of law, equality and non discrimination and citizenship-related rights, such as the right to vote. These rights also reverberate in the discussion on ethical AI, where specific ethical principles are being discussed.  The aim of this paper is to address the aforementioned human rights and see in what ways AI could have an impact on them: how could AI not only respect (passive stance) but also support and help to bring into being (active stance) some of these rights? In particular I will look at the existing AI applications and discuss whether we are approaching the challenge to make AI work for (and not against) human rights in the right way. Furthermore, the paper will also raise the question whether AI could advance any kind of new human rights that we might consider to be fundamental in the future. For instance, do we have a right to know when we interact with an AI on telecommunication networks and not with a human being? Do we have a right to explicability of algorithms?","",""
11,"A. Holzinger, M. Dehmer, F. Emmert‐Streib, N. Díaz-Rodríguez, R. Cucchiara, Isabelle Augenstein, J. Ser, W. Samek, I. Jurisica","Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence",2021,"","","","",9,"2022-07-13 09:36:00","","10.1016/j.inffus.2021.10.007","","",,,,,11,11.00,1,9,1,"","",""
12,"Nathalie A. Smuha","From a ‘race to AI’ to a ‘race to AI regulation’: regulatory competition for artificial intelligence",2021,"","","","",10,"2022-07-13 09:36:00","","10.1080/17579961.2021.1898300","","",,,,,12,12.00,12,1,1,"ABSTRACT Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is a possibility, a reality and a desirability.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",11,"2022-07-13 09:36:00","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
17,"Nathalie A. Smuha","From a 'Race to AI' to a 'Race to AI Regulation' - Regulatory Competition for Artificial Intelligence",2019,"","","","",12,"2022-07-13 09:36:00","","10.2139/ssrn.3501410","","",,,,,17,5.67,17,1,3,"Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising those risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is (1) a possibility, (2) a reality and (3) a desirability.","",""
0,"L. Martí-Bonmatí, D. Koh, K. Riklund, Maciej Bobowicz, Y. Roussakis, J. Vilanova, J. Fütterer, J. Rimola, Pedro Mallol, Gloria Ribas, A. Miguel, M. Tsiknakis, K. Lekadir, G. Tsakou","Considerations for artificial intelligence clinical impact in oncologic imaging: an AI4HI position paper",2022,"","","","",13,"2022-07-13 09:36:00","","10.1186/s13244-022-01220-9","","",,,,,0,0.00,0,14,1,"","",""
1,"J. Bieger, K. Thórisson","Requirements for General Intelligence : A Case Study in Trustworthy Cumulative Learning for Air Traffic Control",2018,"","","","",14,"2022-07-13 09:36:00","","","","",,,,,1,0.25,1,2,4,"While many evaluation procedures have been proposed in past research for artificial general intelligence (AGI), few take the time to carefully list the (minimum, general) requirements that an AGIaspiring (cognitive) control architecture is intended to eventually meet. Such requirements could guide the design process and help evaluate the potential of an architecture to become generally intelligent— not through measuring the performance of a running AI system, but through a white-box, offline evaluation of what requirements have been met to what degree. Rather than providing our estimate of what features are necessary to achieve AGI, we analyze a concrete task from the air traffic control (ATC) domain to come up with a crisp set of requirements that AGI would need to meet as well. To avoid major disruptions to proven workflows in safety-critical domains, a trustworthy, robust and adaptable AI system must work side-by-side with a human operator and cumulatively learn new tasks that can gradually be introduced into the operator’s complex workflow. Our analysis results in a set of minimal/necessary requirements that can guide the development of AGI-aspiring architectures. We conclude the paper with an evaluation of the degree to which several common AI approaches and architectures meet these requirements.","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",15,"2022-07-13 09:36:00","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
4,"Markus Borg, Joshua Bronson, Linus Christensson, Fredrik Olsson, Olof Lennartsson, Elias Sonnsjö, Hamid Ebabi, Martin Karsberg","Exploring the Assessment List for Trustworthy AI in the Context of Advanced Driver-Assistance Systems",2021,"","","","",16,"2022-07-13 09:36:00","","10.1109/SEthics52569.2021.00009","","",,,,,4,4.00,1,8,1,"Artificial Intelligence (AI) is increasingly used in critical applications. Thus, the need for dependable AI systems is rapidly growing. In 2018, the European Commission appointed experts to a High-Level Expert Group on AI (AI-HLEG). AI- HLEG defined Trustworthy AI as 1) lawful, 2) ethical, and 3) robust and specified seven corresponding key requirements. To help development organizations, AI-HLEG recently published the Assessment List for Trustworthy AI (ALTAI). We present an illustrative case study from applying ALTAI to an ongoing development project of an Advanced Driver-Assistance System (ADAS) that relies on Machine Learning (ML). Our experience shows that ALTAI is largely applicable to ADAS development, but specific parts related to human agency and transparency can be disregarded. Moreover, bigger questions related to societal and environmental impact cannot be tackled by an ADAS supplier in isolation. We present how we plan to develop the ADAS to ensure ALTAI-compliance. Finally, we provide three recommendations for the next revision of ALTAI, i.e., life-cycle variants, domainspecific adaptations, and removed redundancy.","",""
0,"H. Ruess","Systems Challenges for Trustworthy Embodied Systems",2022,"","","","",17,"2022-07-13 09:36:00","","","","",,,,,0,0.00,0,1,1,"A new generation of increasingly autonomous and self-learning systems, which we call embodied systems, is about to emerge. When deploying these systems into our very societal fabric, we face various engineering challenges, as it is crucial to coordinate the behavior of embodied systems in a beneficial manner, ensure their compatibility with our human-centered social values, and design verifiably safe and reliable human–machine interaction. We argue that traditional systems engineering is coming to a climacteric from embedded to embodied systems, and with assuring the trustworthiness of dynamic federations of situationally aware, intent-driven, explorative, ever-evolving, largely unpredictable, and increasingly autonomous embodied systems in uncertain, complex, and unpredictable real-world contexts. With this goal in mind we identify urgent systems engineering challenges for designing embodied systems in which we can put our trust, including robust and human-centered artificial intelligence, cognitive architectures, uncertainty quantification, trustworthy self-integration, and continual analysis and assurance.","",""
0,"N. Leventi, A. Vodenitcharova, K. Popova","Guidelines for Trustworthy AI application in clinical trials",2020,"","","","",18,"2022-07-13 09:36:00","","10.1093/eurpub/ckaa165.806","","",,,,,0,0.00,0,3,2,"      Innovative information technologies (IIT) like artificial intelligence (AI), big data, etc. promise to support individual patient care, and promote public health. Their use raises ethical, social and legal issues. Here we demonstrate how the guidelines for trustworthy AI, can assist to answer those ethical issues in the case of clinical trials (CT).        In 2018 the European Commission established the High-Level Expert Group on Artificial Intelligence (AI HLEG). The group proposed Guidelines to promote Trustworthy AI, with three components, which should be met throughout the system's entire life cycle, as it should be lawful, ethical and robust.  Trustworthiness is a prerequisite for people and societies to develop, and use AI systems. We used a focus group methodology to explore how the guidelines for trustworthy AI can assist to answer the ethical issues that rise by the application of AI in CTs.        The discussion was directed to the seven requirements for trustworthy AI in CTs, by questions like:  Are they relevant in CTs as a whole? Would they be applicable to the use of IIT as AI in CTs? Are you currently applying part, or all, of the proposed list? In the future, would you attach some, or all, of the proposed list? Is the administrative burden of applying the requirements justified by the effect?        It was recommended that:  the guidelines are relevant in the conduct of the CT; planning and implementation of CTs using IIT, should take them into account; ethical aspects and challenges are of the utmost importance; the proposed list is a very comprehensive framework; particular attention should be paid where more vulnerable groups are affected; the administrative burden is acceptable, as the effect exceeds the resources invested.        IIT are becoming increasingly important in medicine, and requirements for trustworthy IIT, and AI are necessary. Appropriate instrument in the case of the CTs are the provided by AI HLEG guidelines. ","",""
0,"Alankrita Aggarwal, D. Chatha","To Design a Mammogram Edge Detection Algorithm Using an Artificial Neural Network (ANN)",2019,"","","","",19,"2022-07-13 09:36:00","","10.4018/ijdai.2019010104","","",,,,,0,0.00,0,2,3,"An artificial neural network (ANN) is used to resolve problems related to complex scenarios and logical thinking. Nowadays, a cause for concern is the mortality rate among women due to cancer. Generally, women to around 45 years old are the most vulnerable to this disease. Early detection is the only hope for the patient to survive, otherwise it may reach an unrecoverable stage. Currently, there are numerous techniques available for the diagnosis of such diseases out of which mammography is the most trustworthy method for detecting early stage cancer. The analysis of these mammogram images is always difficult to analyze due to low contrast and non-uniform background. The mammogram images are scanned, digitized for processing, nut that further reduces the contrast between region of interest (ROI) and the background. Furthermore, presence of noise, glands, and muscles leads to background contrast variations. The boundaries of the suspected tumor area are always fuzzy and improper. The aim of this article is to develop a robust edge detection technique which works optimally on mammogram images to segment a tumor area.","",""
8,"Yonatan Elul, Aviv A. Rosenberg, Assaf Schuster, A. Bronstein, Y. Yaniv","Meeting the unmet needs of clinicians from AI systems showcased for cardiology with deep-learning–based ECG analysis",2021,"","","","",20,"2022-07-13 09:36:00","","10.1073/pnas.2020620118","","",,,,,8,8.00,2,5,1,"Significance The use of artificial intelligence (AI) in medicine, particularly deep learning, has gained considerable attention recently. Although some works boast superior capabilities compared to clinicians, actual deployments of AI systems in the clinic are scarce. We describe four important gaps on the machine-learning side responsible for this discrepancy by first formulating them in a way that is actionable by AI researchers and then systematically addressing these needs. Aiming beyond the search for better model architectures or improved accuracy, we focus directly on the challenges of clinical usefulness as stated by medical professionals in the literature. Our results show that deep-learning systems can be robust, trustworthy, explainable, and transparent while retaining the superior level of performance these algorithms are known for. Despite their great promise, artificial intelligence (AI) systems have yet to become ubiquitous in the daily practice of medicine largely due to several crucial unmet needs of healthcare practitioners. These include lack of explanations in clinically meaningful terms, handling the presence of unknown medical conditions, and transparency regarding the system’s limitations, both in terms of statistical performance as well as recognizing situations for which the system’s predictions are irrelevant. We articulate these unmet clinical needs as machine-learning (ML) problems and systematically address them with cutting-edge ML techniques. We focus on electrocardiogram (ECG) analysis as an example domain in which AI has great potential and tackle two challenging tasks: the detection of a heterogeneous mix of known and unknown arrhythmias from ECG and the identification of underlying cardio-pathology from segments annotated as normal sinus rhythm recorded in patients with an intermittent arrhythmia. We validate our methods by simulating a screening for arrhythmias in a large-scale population while adhering to statistical significance requirements. Specifically, our system 1) visualizes the relative importance of each part of an ECG segment for the final model decision; 2) upholds specified statistical constraints on its out-of-sample performance and provides uncertainty estimation for its predictions; 3) handles inputs containing unknown rhythm types; and 4) handles data from unseen patients while also flagging cases in which the model’s outputs are not usable for a specific patient. This work represents a significant step toward overcoming the limitations currently impeding the integration of AI into clinical practice in cardiology and medicine in general.","",""
6,"S. Pal, S. Mukhopadhyay, N. Suryadevara","Development and Progress in Sensors and Technologies for Human Emotion Recognition",2021,"","","","",21,"2022-07-13 09:36:00","","10.3390/s21165554","","",,,,,6,6.00,2,3,1,"With the advancement of human-computer interaction, robotics, and especially humanoid robots, there is an increasing trend for human-to-human communications over online platforms (e.g., zoom). This has become more significant in recent years due to the Covid-19 pandemic situation. The increased use of online platforms for communication signifies the need to build efficient and more interactive human emotion recognition systems. In a human emotion recognition system, the physiological signals of human beings are collected, analyzed, and processed with the help of dedicated learning techniques and algorithms. With the proliferation of emerging technologies, e.g., the Internet of Things (IoT), future Internet, and artificial intelligence, there is a high demand for building scalable, robust, efficient, and trustworthy human recognition systems. In this paper, we present the development and progress in sensors and technologies to detect human emotions. We review the state-of-the-art sensors used for human emotion recognition and different types of activity monitoring. We present the design challenges and provide practical references of such human emotion recognition systems in the real world. Finally, we discuss the current trends in applications and explore the future research directions to address issues, e.g., scalability, security, trust, privacy, transparency, and decentralization.","",""
2,"Aidan Murphy, Gráinne Murphy, Jorge Amaral, D. M. Dias, Enrique Naredo, C. Ryan","Towards Incorporating Human Knowledge in Fuzzy Pattern Tree Evolution",2021,"","","","",22,"2022-07-13 09:36:00","","10.1007/978-3-030-72812-0_5","","",,,,,2,2.00,0,6,1,"","",""
0,"Kaiyu Yang","1 Machine Learning for Reasoning",2021,"","","","",23,"2022-07-13 09:36:00","","","","",,,,,0,0.00,0,1,1,"Reasoning is a core component of human intelligence that machines still struggle with. I do research in the field of artificial intelligence, with the long-term goal of building machines that reason precisely, systematically, in ways that are interpretable and robust to ambiguity in real-world environments. My research advances towards this goal by attempting to combine the complementary strengths of machine learning and symbolic reasoning. My graduate research has focused on developing machine learning models that represent reasoning via symbolic proofs. They show the promise of new learning paradigms that I envision to be more robust, interpretable, and trustworthy for deployment in real-world high-stake applications. Symbolic reasoning is precise and generalizes systematically to unseen scenarios. But it has been restricted to domains amenable to rigid formalization. In contrast, machine learning has the flexibility to handle noisy and ambiguous domains that are hard to formalize. But predominant machine learning models, such as deep neural networks, are notoriously uninterpretable, data-hungry, and incapable of generalizing outside the training data distribution. Integrating the strengths of both approaches is essential for building flexible reasoning machines with precise and systematic generalization. However, due to the discrete nature of symbolic reasoning, such integration may require a radical departure from the predominant paradigm of gradient-based learning. And my research tries to answer what that alternative form of learning might look like.","",""
0,"Alexander Bastounis, Anders, Christian Hansen, D. Higham, I. Tyukin","Uniform-in-diffusivity Chaotic Mixing and the Batchelor Spectrum",2021,"","","","",24,"2022-07-13 09:36:00","","","","",,,,,0,0.00,0,5,1,"In a field of research where algorithms can misinterpret stop signs as speed limit signs with the addition of minimal graffiti [3], many commentators are wondering whether current artificial intelligence (AI) solutions are sufficiently robust, resilient, and trustworthy. How can the research community quantify and address such issues? Many empirical approaches investigate the generation of adversarial attacks: small, deliberate perturbations to an input that cause dramatic changes in a system’s output. Changes that are essentially imperceptible to the human eye may alter predictions in the field of image classification, which has implications in many high-stakes and safety-critical settings. The rise of algorithms that construct attacks—and heuristic techniques that identify or guard against them—has led to a version of conflict escalation wherein attack and defense strategies become increasingly ingenious [10]. These issues concern the conditioning of the underlying problem and stability of the algorithms in use. Recent research has utilized mathematical tools—notably from numerical analysis, applied probability, and high-dimensional geometry— to shed light on this field. However, many open problems remain.","",""
0,"Chongyi Yuan, Lijie Wen, Xiongliang Yan","Towards the Future: Bring Program Correctness back to the focus",2022,"","","","",25,"2022-07-13 09:36:00","","10.48550/arXiv.2203.15653","","",,,,,0,0.00,0,3,1,"Program correctness used to be the main concern of computer software in the early days when formal semantics was a hot topic. But, the word “correct” was afterwards replaced by reliable, robust and trustworthy etc., a tradeo ﬀ situation then. This is not because correctness is no longer important, but because people found no way to get through in this direction. The tradeo ﬀ has led software engineers to focus on techniques and testing tools. Rapid development of software engineering has now reached a peak and programmers are now working freely without worrying too much about bugs, since bugs are not avoidable anyway. While software engineers are enjoying their work, computer applications are, in the name of artiﬁcial intelligence, big data and cloud computing etc., creating big fortune. Can we always ignore existence of errors like today? Or equally, is it meaningful to talk about program correctness today? Our answer is yes. It is the time to seriously consider correctness again, before it is too late, to prepare for the future. Future generation computer systems should be correct, both syntactically (statically) and semantically (dynamically). The book “OESPA: Semantic Oriented Theory of Programming” (2019) by the ﬁrst author has opened a new direction for semantic study. Theoretically speaking, it is possible now, based on OESPA, to compute program semantics from program text so that program correctness could be proved. But, semantic computations and correctness proving cannot be done by hand when the size of a program is big. Automatic tools are necessary. This paper tries to lay a foundation for developing needed auto tools, so that OESPA is enriched to serve future need. To this end, a new concept named conditional semantic predicate is proposed. Concepts in OESPA, including semantic functions, semantic predicates, semantic formulas and semantic calculus, are re-represented in accordance. Such re-introduction is necessary since the book is the only publication on semantic calculus so far. The new version of semantic calculus illustrates how semantics auto-computation would be carried out. The second and third authors have played an important role in the course of this stage of study.A3-step meta-method called ARM is the tour-guide in writing this paper. As readers may ﬁnd that the ﬁrst step of ARM, i.e. abstraction of physical object (variables here), is the key step for OESPA. ARM aims at constructing formal models whenever a formal model is needed. OE is a formal computation model for programming, SPA provides a formal way in deﬁning program semantics (A), and doing semantics predicate (SP) calculus.","",""
0,"Madeline Kovaleski, Aaron B. Fuller, J. Kerley, Brendan Alvey, Peter Popescu, D. Anderson, A. Buck, J. Keller, Grant Scott, Clare Yang, Ken Yasuda, Hollie Ryan","Explosive hazard pre-screener based on simulated data with perfect annotation and imprecisely labeled real data",2022,"","","","",26,"2022-07-13 09:36:00","","10.1117/12.2618792","","",,,,,0,0.00,0,12,1,"Datasets with accurate ground truth from unmanned aerial vehicles (UAV) are cost and time prohibitive. This is a problem as most modern machine learning (ML) algorithms are based on supervised learning and require large and diverse well-annotated datasets. As a result, new creative ideas are needed to drive innovation in robust and trustworthy artificial intelligence (AI) / ML. Herein, we use the Unreal Engine (UE) to generate simulated visual spectrum imagery for explosive hazard detection (EHD) with corresponding pixel-level labels, UAV metadata, and environment metadata. We also have access to a relatively small set of real world EH data with less precise ground truth – axis aligned bounding box labels – and sparse metadata. In this article, we train a lightweight, real-time, pixel-level EHD pre-screener for a low-altitude UAV. Specifically, we focus on training with respect to different combinations of simulated and real data. Encouraging preliminary results are provided relative to real world EH data. Our findings suggest that while simulated data can be used to augment limited volume and variety real world data, it could perhaps be sufficient by itself to train an EHD pre-screener.","",""
0,"Dongfang Li, Dongfang Li, Baotian Hu, Qingcai Chen, Tujie Xu, Jingcong Tao, Yunan Zhang","Unifying Model Explainability and Robustness for Joint Text Classification and Rationale Extraction",2021,"","","","",27,"2022-07-13 09:36:00","","10.1609/aaai.v36i10.21342","","",,,,,0,0.00,0,7,1,"Recent works have shown explainability and robustness are two crucial ingredients of trustworthy and reliable text classification. However, previous works usually address one of two aspects: i) how to extract accurate rationales for explainability while being beneficial to prediction; ii) how to make the predictive model robust to different types of adversarial attacks. Intuitively, a model that produces helpful explanations should be more robust against adversarial attacks, because we cannot trust the model that outputs explanations but changes its prediction under small perturbations. To this end, we propose a joint classification and rationale extraction model named AT-BMC. It includes two key mechanisms: mixed Adversarial Training (AT) is designed to use various perturbations in discrete and embedding space to improve the model’s robustness, and Boundary Match Constraint (BMC) helps to locate rationales more precisely with the guidance of boundary information. Performances on benchmark datasets demonstrate that the proposed AT-BMC outperforms baselines on both classification and rationale extraction by a large margin. Robustness analysis shows that the proposed AT-BMC decreases the attack success rate effectively by up to 69%. The results indicate that there are connections between robust models and better explanations.","",""
5,"Blake Ruprecht, Wenlong Wu, M. Islam, Derek T. Anderson, James M. Keller, G. Scott, Curt Davis, F. Petry, P. Elmore, Kristen Nock, Elizabeth Gilmour","Possibilistic Clustering Enabled Neuro Fuzzy Logic",2020,"","","","",28,"2022-07-13 09:36:00","","10.1109/FUZZ48607.2020.9177593","","",,,,,5,2.50,1,11,2,"Artificial neural networks are a dominant force in our modern era of data-driven artificial intelligence. The adaptive neuro fuzzy inference system (ANFIS) is a neural network based on fuzzy logic versus a more traditional premise like convolution. Advantages of ANFIS include the ability to encode and potentially understand machine learned neural information in the pursuit of explainable, interpretable, and ultimately trustworthy artificial intelligence. However, real-world data is almost always imperfect, e.g., incomplete or noisy, and ANFIS is not naturally robust. Specifically, ANFIS is susceptible to over inflated uncertainty, poor antecedent (fuzzy set) data alignment, degenerate optimization conditions, and hard to interpret logic, to name a few factors. Herein, we explore the use of possibilistic clustering to identify outliers, specifically typicality degrees, to increase the robustness of ANFIS; or any fuzzy logic neuron/network. Experiments are presented that demonstrate the need and quality of the proposed solutions in the pursuit of robust interpretable machine learned neuro fuzzy logic solutions.","",""
1,"F. Fabiano","Towards a Complete Characterization of Epistemic Reasoning: the Notion of Trust",2020,"","","","",29,"2022-07-13 09:36:00","","","","",,,,,1,0.50,1,1,2,"Designing autonomous agents, that interact with others to perform complex tasks, has always been one of the main objective of the Artificial Intelligence community. For such systems to be employed in complex scenarios, where the information about others is key (e.g., self-driving cars), it is necessary to define robust formalisms that allow each agent to act considering her beliefs on both: i) the state of the world; and ii) the other agents’ perspective of it. The branch of AI that studies such formalisms is known in literature as Multi-Agent Epistemic Planning (MEP). The epistemic action-based language mA, to the best of our knowledge, is the most comprehensive tool to model MEP domains but still lacks concepts that are necessary to reason on real-world scenarios. In this paper we introduce the actions (un)trustworthy announcement and (mis)trustworthy announcement for mA. These actions increase the language’s expressiveness introducing the notion of trust, therefore allowing for a more profound representation of real-world scenarios. In particular, we will provide the characterization, along with some desired properties, of the aforementioned actions’ transition functions. Finally, we will discuss the importance of formalizing the concept of trust in the MEP problem.","",""
0,"C. Sample, S. Loo, M. Bishop","Resilient Data : An Interdisciplinary Approach",2020,"","","","",30,"2022-07-13 09:36:00","","10.1109/RWS50334.2020.9241268","","",,,,,0,0.00,0,3,2,"Cybersecurity continues the migration toward data-informed solutions and the quality of the data is gaining in importance. Data accuracy is foundational to the trustworthiness required of artificial intelligence solutions. Trustworthy data must be accurate, robust, resistant and resilient to unauthorized modifications, going beyond traditional security solutions that perform data integrity checking. Cyber-physical systems present unique challenges with physical outcomes.Cyber-physical systems present unique challenges in achieving trustworthy data. The combination of security data and safety data is unique. Capturing both sets of data and determining the accuracy of that data requires an interdisciplinary approach. This effort describes the merging of information theory and information security constructs along with physical systems data. Knowledge is needed in control systems engineering, cybersecurity and information theory. As training data that informs decisions and feeds artificial intelligence algorithms accuracy and resilience are important.Resilient data is trustworthy data that represents a research challenge offering an opportunity to apply lessons learned from information disorders into the broader cybersecurity environment including the cyber-physical systems that power much of the US critical infrastructure. Creating resilient data, for use as training data requires data be examined in ways that have not historically been a part of traditional cybersecurity analysis. This effort describes a proposed method of contextually evaluating cyber-physical systems security data in order to determine the accuracy of the data and in the event of tampering, reconstitute the data to the last known trustworthy state.","",""
3,"J. Cirera, J. Carino, D. Zurita, J. Ortega","Data Analytics for Performance Evaluation Under Uncertainties Applied to an Industrial Refrigeration Plant",2019,"","","","",31,"2022-07-13 09:36:00","","10.1109/ACCESS.2019.2917079","","",,,,,3,1.00,1,4,3,"Artificial intelligence has bounced into industrial applications contributing several advantages to the field and have led to the possibility to open new ways to solve many actual problems. In this paper, a data-driven performance evaluation methodology is presented and applied to an industrial refrigeration system. The strategy takes advantage of the Multivariate Kernel Density Estimation technique and Self-Organizing Maps to develop a robust method, which is able to determine a near-optimal performance map, taking into account the system uncertainties and the multiple signals involved in the process. A normality model is used to detect and filter non-representative operating samples to subsequently develop a reliable performance map. The performance map allows comparing the plant assessment under the same operating conditions and permits to identify the potential system improvement capabilities. To ensure that the resulting evaluation is trustworthy, a robustness strategy is developed to identify either possible new operation conditions or abnormal situations in order to avoid uncertain assessments. Furthermore, the proposed approach is tested with real industrial plant data to validate the suitability of the method.","",""
1,"Geoffrey Rockwell, Emily Black, Evan Selinger, Antonio Davola, Elana Seide, K. Gulson","From Shortcut to Sleight of Hand: Why the Checklist Approach in the EU Guidelines Does Not Work",2019,"","","","",32,"2022-07-13 09:36:00","","","","",,,,,1,0.33,0,6,3,"Author(s): Rockwell, Geoffrey; Black, Emily; Selinger, Evan; Davola, Antonio; Seide, Elana; Gulson, Kalervo | Abstract: In April 2019, the High-Level Expert Group on Artificial Intelligence (AI) nominated by the EU Commission presented “Ethics Guidelines for Trustworthy Artificial Intelligence,” followed in June 2019 by a second “Policy and investment recommendations” Document.The Guidelines establish three characteristics (lawful, ethical, and robust) and seven key requirements (Human agency and oversight; Technical Robustness and safety; Privacy and data governance; Transparency; Diversity, non-discrimination and fairness; Societal and environmental well-being; and Accountability) that the development of AI should follow.The Guidelines are of utmost significance for the international debate over the regulation of AI. Firstly, they aspire to set a universal standard of care for the development of AI in the future. Secondly, they have been developed within a group of experts nominated by a regulatory body, and therefore will shape the normative approach in the EU regulation of AI and in its interaction with foreign countries. As the GDPR has shown, the effect of this normative activity goes way past the European Union territory.One of the most debated aspects of the Guidelines was the need to find an objective methodology to evaluate conformity with the key requirements. For this purpose, the Expert Group drafted an “assessment checklist” in the last part of the document: the list is supposed to be incorporated into existing practices, as a way for technology developers to consider relevant ethical issues and create more “trustworthy” AI. Our group undertook a critical assessment of the proposed tool from a multidisciplinary perspective, to assess its implications and limitations for global AI development.","",""
2,"Vinit Kumar Gunjan, Amit Kumar, A. A. Rao","Present & Future Paradigms of Cyber Crime & Security Majors - Growth & Rising Trends",2014,"","","","",33,"2022-07-13 09:36:00","","10.1109/ICAIET.2014.24","","",,,,,2,0.25,1,3,8,"Cybercrime is all about the crimes involved with the environment where ever a network is involved and the steps implemented to control or overcome this cyber-security. The work culture of all the sectors are moving towards digitalization and cloud based systems in order to increase the work efficiency with more accuracy, In addition to this a majority of individuals are fond of using social networking sites and email servers in many ways directly or indirectly. Cybercrime is a type of crime where technical expertise is required not only to crack it but in order to make a user secure or to apply any preventive majors. In this paper we have described about the basics of this dreadful crime, recent research & development in the field of cyber security, the types of crimes and a small survey with an IT company. Our aim with this research is to check the awareness level of cybercrime and security majors and to suggest necessary steps which can really be helpful in making the cyber environment secure, robust and trustworthy.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",34,"2022-07-13 09:36:00","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
60,"A. Markus, J. Kors, P. Rijnbeek","The role of explainability in creating trustworthy artificial intelligence for health care: a comprehensive survey of the terminology, design choices, and evaluation strategies",2020,"","","","",35,"2022-07-13 09:36:00","","10.1016/j.jbi.2020.103655","","",,,,,60,30.00,20,3,2,"","",""
36,"Scott Thiebes, S. Lins, A. Sunyaev","Trustworthy artificial intelligence",2020,"","","","",36,"2022-07-13 09:36:00","","10.1007/S12525-020-00441-4","","",,,,,36,18.00,12,3,2,"","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",37,"2022-07-13 09:36:00","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",38,"2022-07-13 09:36:00","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
171,"B. Shneiderman","Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",2020,"","","","",39,"2022-07-13 09:36:00","","10.1080/10447318.2020.1741118","","",,,,,171,85.50,171,1,2,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.","",""
120,"Hoang Nguyen, X. Bui","Predicting Blast-Induced Air Overpressure: A Robust Artificial Intelligence System Based on Artificial Neural Networks and Random Forest",2018,"","","","",40,"2022-07-13 09:36:00","","10.1007/s11053-018-9424-1","","",,,,,120,30.00,60,2,4,"","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",41,"2022-07-13 09:36:00","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
7,"A. Rawal, J. Mccoy, D. Rawat, Brian M. Sadler, R. Amant","Recent Advances in Trustworthy Explainable Artificial Intelligence: Status, Challenges and Perspectives",2021,"","","","",42,"2022-07-13 09:36:00","","10.36227/techrxiv.17054396.v1","","",,,,,7,7.00,1,5,1,"This is a survey paper on Explainable Artificial Intelligence (XAI).","",""
8,"J. Lötsch, D. Kringel, A. Ultsch","Explainable Artificial Intelligence (XAI) in Biomedicine: Making AI Decisions Trustworthy for Physicians and Patients",2021,"","","","",43,"2022-07-13 09:36:00","","10.3390/biomedinformatics2010001","","",,,,,8,8.00,3,3,1,"The use of artificial intelligence (AI) systems in biomedical and clinical settings can disrupt the traditional doctor–patient relationship, which is based on trust and transparency in medical advice and therapeutic decisions. When the diagnosis or selection of a therapy is no longer made solely by the physician, but to a significant extent by a machine using algorithms, decisions become nontransparent. Skill learning is the most common application of machine learning algorithms in clinical decision making. These are a class of very general algorithms (artificial neural networks, classifiers, etc.), which are tuned based on examples to optimize the classification of new, unseen cases. It is pointless to ask for an explanation for a decision. A detailed understanding of the mathematical details of an AI algorithm may be possible for experts in statistics or computer science. However, when it comes to the fate of human beings, this “developer’s explanation” is not sufficient. The concept of explainable AI (XAI) as a solution to this problem is attracting increasing scientific and regulatory interest. This review focuses on the requirement that XAIs must be able to explain in detail the decisions made by the AI to the experts in the field.","",""
42,"M. Nassar, K. Salah, M. H. Rehman, D. Svetinovic","Blockchain for explainable and trustworthy artificial intelligence",2019,"","","","",44,"2022-07-13 09:36:00","","10.1002/widm.1340","","",,,,,42,14.00,11,4,3,"The increasing computational power and proliferation of big data are now empowering Artificial Intelligence (AI) to achieve massive adoption and applicability in many fields. The lack of explanation when it comes to the decisions made by today's AI algorithms is a major drawback in critical decision‐making systems. For example, deep learning does not offer control or reasoning over its internal processes or outputs. More importantly, current black‐box AI implementations are subject to bias and adversarial attacks that may poison the learning or the inference processes. Explainable AI (XAI) is a new trend of AI algorithms that provide explanations of their AI decisions. In this paper, we propose a framework for achieving a more trustworthy and XAI by leveraging features of blockchain, smart contracts, trusted oracles, and decentralized storage. We specify a framework for complex AI systems in which the decision outcomes are reached based on decentralized consensuses of multiple AI and XAI predictors. The paper discusses how our proposed framework can be utilized in key application areas with practical use cases.","",""
5,"Silverio Mart'inez-Fern'andez, X. Franch, Andreas Jedlitschka, Marc Oriol, Adam Trendowicz","Research Directions for Developing and Operating Artificial Intelligence Models in Trustworthy Autonomous Systems",2020,"","","","",45,"2022-07-13 09:36:00","","10.1007/978-3-030-75018-3_14","","",,,,,5,2.50,1,5,2,"","",""
4,"Kristi Joamets, Archil Chochia","Access to Artificial Intelligence for Persons with Disabilities: Legal and Ethical Questions Concerning the Application of Trustworthy AI",2021,"","","","",46,"2022-07-13 09:36:00","","10.11590/ABHPS.2021.1.04","","",,,,,4,4.00,2,2,1,"Digitalisation and emerging technologies affect our lives and are increasingly present in a growing number of fields. Ethical implications of the digitalisation process have therefore long been discussed by the scholars. The rapid development of artificial intelligence (AI) has taken the legal and ethical discussion to another level. There is no doubt that AI can have a positive impact on the society. The focus here, however, is on its more negative impact. This article will specifically consider how the law and ethics in their interaction can be applied in a situation where a disabled person needs some kind of assistive technology to participate in the society as an equal member. This article intends to investigate whether the EU Guidelines for Trustworthy AI, as a milestone of ethics concerning technology, has the power to change the current practice of how social and economic rights are applied. The main focus of the article is the ethical requirements ‘Human agency and oversight’ and, more specifically, fundamental rights.","",""
4,"Karim Lekadira, Richard Osuala, C. Gallin, Noussair Lazrak, Kaisar Kushibar, G. Tsakou, Susanna Auss'o, Leonor Cerd'a Alberich, K. Marias, Manolis Tskinakis, S. Colantonio, Nickolas Papanikolaou, Zohaib Salahuddin, H. Woodruff, P. Lambin, L. Mart'i-Bonmat'i","FUTURE-AI: Guiding Principles and Consensus Recommendations for Trustworthy Artificial Intelligence in Medical Imaging",2021,"","","","",47,"2022-07-13 09:36:00","","","","",,,,,4,4.00,0,16,1,"The recent advancements in artificial intelligence (AI) combined with the extensive amount of data generated by today’s clinical systems, has led to the development of imaging AI solutions across the whole value chain of medical imaging, including image reconstruction, medical image segmentation, image-based diagnosis and treatment planning. Notwithstanding the successes and future potential of AI in medical imaging, many stakeholders are concerned of the potential risks and ethical implications of imaging AI solutions, which are perceived as complex, opaque, and difficult to comprehend, utilise, and trust in critical clinical applications. Despite these concerns and risks, there are currently no concrete guidelines and best practices for guiding future AI developments in medical imaging towards increased trust, safety and adoption. To bridge this gap, this paper introduces a careful selection of guiding principles drawn from the accumulated experiences, consensus, and best practices from five large European projects on AI in Health Imaging. These guiding principles are named FUTURE-AI and its building blocks consist of (i) Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness and (vi) Explainability. In a step-by-step approach, these guidelines are further translated into a framework of concrete recommendations for specifying, developing, evaluating, and deploying technically, clinically and ethically trustworthy AI solutions into clinical practice.","",""
1,"Ke Zhang, Peidong Xu, Tianlu Gao, Jun Zhang","A Trustworthy Framework of Artificial Intelligence for Power Grid Dispatching Systems",2021,"","","","",48,"2022-07-13 09:36:00","","10.1109/DTPI52967.2021.9540198","","",,,,,1,1.00,0,4,1,"With the widespread application of artificial intelligence (AI) technologies in power systems, the properties of lack of reliability and transparency for AI technologies have revealed gradually. Here, how to build a trustworthy-AI framework based on the power system is the focus. Due to the multidimensional and heterogeneous information of power grid data, the heterogeneous graph attention network (HGAT) model of power grid dispatching is established, and the corresponding explainer (HGAT-Explainer) for the model of power equipment faults is proposed to provide more favorable support for the trustworthy-AI systems.","",""
1,"E. Manziuk, O. Barmak, I. Krak, O. Mazurets, T. Skrypnyk","Formal Model of Trustworthy Artificial Intelligence Based on Standardization",2021,"","","","",49,"2022-07-13 09:36:00","","","","",,,,,1,1.00,0,5,1,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",50,"2022-07-13 09:36:00","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
80,"M. Janssen, P. Brous, Elsa Estevez, L. Barbosa, T. Janowski","Data governance: Organizing data for trustworthy Artificial Intelligence",2020,"","","","",51,"2022-07-13 09:36:00","","10.1016/j.giq.2020.101493","","",,,,,80,40.00,16,5,2,"","",""
4,"Eleanore Hickman, M. Petrin","Trustworthy AI and Corporate Governance: The EU’s Ethics Guidelines for Trustworthy Artificial Intelligence from a Company Law Perspective",2021,"","","","",52,"2022-07-13 09:36:00","","10.1007/s40804-021-00224-0","","",,,,,4,4.00,2,2,1,"","",""
19,"Kristine Bærøe, Ainar Miyata-Sturm, Edmund Henden","How to achieve trustworthy artificial intelligence for health",2020,"","","","",53,"2022-07-13 09:36:00","","10.2471/BLT.19.237289","","",,,,,19,9.50,6,3,2,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.","",""
2,"Suleyman Uslu, Davinder Kaur, S. Rivera, A. Durresi, M. Durresi, M. Babbar‐Sebens","Trustworthy Acceptance: A New Metric for Trustworthy Artificial Intelligence Used in Decision Making in Food-Energy-Water Sectors",2021,"","","","",54,"2022-07-13 09:36:00","","10.1007/978-3-030-75100-5_19","","",,,,,2,2.00,0,6,1,"","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",55,"2022-07-13 09:36:00","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
14,"L. Robert, G. Bansal, C. Lütge","ICIS 2019 SIGHCI Workshop Panel Report: Human– Computer Interaction Challenges and Opportunities for Fair, Trustworthy and Ethical Artificial Intelligence",2020,"","","","",56,"2022-07-13 09:36:00","","10.17705/1thci.00130","","",,,,,14,7.00,5,3,2,"Artificial Intelligence (AI) is rapidly changing every aspect of our society—including amplifying our biases. Fairness, trust and ethics are at the core of many of the issues underlying the implications of AI. Despite this, research on AI with relation to fairness, trust and ethics in the information systems (IS) field is still scarce. This panel brought together academia, business and government perspectives to discuss the challenges and identify potential solutions to address such challenges. This panel report presents eight themes based around the discussion of two questions: (1) What are the biggest challenges to designing, implementing and deploying fair, ethical and trustworthy AI?; and (2) What are the biggest challenges to policy and governance for fair, ethical and trustworthy AI? The eight themes are: (1) identifying AI biases; (2) drawing attention to AI biases; (3) addressing AI biases; (4) designing transparent and explainable AI; (5) AI fairness, trust, ethics: old wine in a new bottle?; (6) AI accountability; (7) AI laws, policies, regulations and standards; and (8) frameworks for fair, ethical and trustworthy AI. Based on the results of the panel discussion, we present research questions for each theme to guide future research in the area of human–computer interaction.","",""
14,"Jinchao Feng, J. L. Lansford, M. Katsoulakis, D. Vlachos","Explainable and trustworthy artificial intelligence for correctable modeling in chemical sciences",2020,"","","","",57,"2022-07-13 09:36:00","","10.1126/sciadv.abc3204","","",,,,,14,7.00,4,4,2,"The developed framework apportions model error to inputs, computes predictive guarantees, and enables model correctability. Data science has primarily focused on big data, but for many physics, chemistry, and engineering applications, data are often small, correlated and, thus, low dimensional, and sourced from both computations and experiments with various levels of noise. Typical statistics and machine learning methods do not work for these cases. Expert knowledge is essential, but a systematic framework for incorporating it into physics-based models under uncertainty is lacking. Here, we develop a mathematical and computational framework for probabilistic artificial intelligence (AI)–based predictive modeling combining data, expert knowledge, multiscale models, and information theory through uncertainty quantification and probabilistic graphical models (PGMs). We apply PGMs to chemistry specifically and develop predictive guarantees for PGMs generally. Our proposed framework, combining AI and uncertainty quantification, provides explainable results leading to correctable and, eventually, trustworthy models. The proposed framework is demonstrated on a microkinetic model of the oxygen reduction reaction.","",""
14,"Stéphan Vincent-Lancrin, R. V. D. Vlies","Trustworthy artificial intelligence (AI) in education",2020,"","","","",58,"2022-07-13 09:36:00","","10.1787/a6c90fa9-en","","",,,,,14,7.00,7,2,2,"This paper was written to support the G20 artificial intelligence (AI) dialogue. With the rise of artificial intelligence (AI), education faces two challenges: reaping the benefits of AI to improve education processes, both in the classroom and at the system level; and preparing students for new skillsets for increasingly automated economies and societies. AI applications are often still nascent, but there are many examples of promising uses that foreshadow how AI might transform education. With regard to the classroom, this paper highlights how AI can accelerate personalised learning, the support of students with special needs. At the system level, promising uses include predictive analysis to reduce dropout, and assessing new skillsets. A new demand for complex skills that are less easy to automate (e.g. higher cognitive skills like creativity and critical thinking) is also the consequence of AI and digitalisation. Reaching the full potential of AI requires that stakeholders trust not only the technology, but also its use by humans. This raises new policy challenges around “trustworthy AI”, encompassing the privacy and security of data, but also possible wrongful uses of data leading to biases against individuals or groups.","",""
10,"Davinder Kaur, Suleyman Uslu, A. Durresi","Requirements for Trustworthy Artificial Intelligence - A Review",2020,"","","","",59,"2022-07-13 09:36:00","","10.1007/978-3-030-57811-4_11","","",,,,,10,5.00,3,3,2,"","",""
8,"Banu Buruk, P. Ekmekci, B. Arda","A critical perspective on guidelines for responsible and trustworthy artificial intelligence",2020,"","","","",60,"2022-07-13 09:36:00","","10.1007/s11019-020-09948-1","","",,,,,8,4.00,3,3,2,"","",""
6,"T. M. Harrison, L. F. Luna-Reyes","Cultivating Trustworthy Artificial Intelligence in Digital Government",2020,"","","","",61,"2022-07-13 09:36:00","","10.1177/0894439320980122","","",,,,,6,3.00,3,2,2,"While there is growing consensus that the analytical and cognitive tools of artificial intelligence (AI) have the potential to transform government in positive ways, it is also clear that AI challenges traditional government decision-making processes and threatens the democratic values within which they are framed. These conditions argue for conservative approaches to AI that focus on cultivating and sustaining public trust. We use the extended Brunswik lens model as a framework to illustrate the distinctions between policy analysis and decision making as we have traditionally understood and practiced them and how they are evolving in the current AI context along with the challenges this poses for the use of trustworthy AI. We offer a set of recommendations for practices, processes, and governance structures in government to provide for trust in AI and suggest lines of research that support them.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",62,"2022-07-13 09:36:00","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
8,"Eleanore Hickman, M. Petrin","Trustworthy AI and Corporate Governance – The EU’s Ethics Guidelines For Trustworthy Artificial Intelligence from a Company Law Perspective",2020,"","","","",63,"2022-07-13 09:36:00","","10.2139/ssrn.3607225","","",,,,,8,4.00,4,2,2,"AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even ‘rogue AI’. To address these dangers, the EU published its 'Ethics Guidelines for Trustworthy AI’. The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness and explicability.     If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered but, because the Guidelines only address the former without much reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles, it is clear that the Guidelines' general nature leaves many questions and concerns unanswered.     In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance practices. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.","",""
74,"Nathalie A. Smuha","The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence",2019,"","","","",64,"2022-07-13 09:36:00","","10.9785/cri-2019-200402","","",,,,,74,24.67,74,1,3,"As part of its European strategy for Artificial Intelligence (AI), and as a response to the increasing ethical questions raised by this technology, the European Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG) in June 2018. The group was tasked to draft two deliverables: AI Ethics Guidelines and Policy and Investment Recommendations. Nine months later, its first deliverable was published, putting forward a comprehensive framework to achieve “Trustworthy AI” by offering ethical guidance to AI practitioners. This paper dives into the work carried out by the group, focusing in particular on its AI Ethics Guidelines. First, this paper clarifies the context that led to the creation of the AI HLEG and its mandate (I.). Subsequently, it elaborates on the Guidelines’ aim and purpose (II.), and analyses the Guidelines’ drafting process (III.). Particular focus is given to the questions surrounding the respective role played by ethics and law in the AI governance landscape (IV.), as well as some of the challenges that had to be overcome throughout the process (V.). Finally, this paper places the Guidelines in an international context, and sets out the next steps (VI.) ahead on the journey towards an appropriate governance framework for AI (VII.).","",""
48,"","High-Level Expert Group on Artificial Intelligence – Draft Ethics Guidelines for Trustworthy AI",2019,"","","","",65,"2022-07-13 09:36:00","","","","",,,,,48,16.00,0,0,3,"","",""
4,"N. Gillespie, Caitlin Curtis, Rossana Bianchi, A. Akbari, Rita Fentener van Vlissingen","Achieving Trustworthy AI: A Model for Trustworthy Artificial Intelligence",2020,"","","","",66,"2022-07-13 09:36:00","","10.14264/ca0819d","","",,,,,4,2.00,1,5,2,"","",""
49,"Ninja Marnau","Comments on the “Draft Ethics Guidelines for Trustworthy AI” by the High-LevelExpert Group on Artificial Intelligence.",2019,"","","","",67,"2022-07-13 09:36:00","","","","",,,,,49,16.33,49,1,3,"The European Commission appointed the High-Level Expert Group on Artificial Intelligence (AI HLEG). The AI HLEG has the objective to support the implementation of the European strategy on Artificial Intelligence. This will include the elaboration of recommendations on future-related policy development and on ethical, legal and societal issues related to AI. In January 2019, the Commission asked stakeholders for comments on the AI HLEG’s “Draft Ethics Guidelines for Trustworthy AI”. CISPA submitted the following comments and remarks in the Stakeholders’ Consultation.","",""
1,"O. Jenkins, D. Lopresti, M. Mitchell","Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",2020,"","","","",68,"2022-07-13 09:36:00","","","","",,,,,1,0.50,0,3,2,"The history of AI has included several ""waves"" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called ""expert systems"". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed ""statistical learning algorithms"" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by ""deep learning"" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors.  A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",69,"2022-07-13 09:36:00","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
1,"","RECOMMENDATIONS TO THE EU HIGH LEVEL EXPERT GROUP ON ARTIFICIAL INTELLIGENCE ON ITS DRAFT AI ETHICS GUIDELINES FOR TRUSTWORTHY AI",2019,"","","","",70,"2022-07-13 09:36:00","","","","",,,,,1,0.33,0,0,3,"RECOMMENDATIONS TO THE EU HIGH LEVEL EXPERT GROUP ON ARTIFICIAL INTELLIGENCE ON ITS DRAFT AI ETHICS GUIDELINES FOR TRUSTWORTHY AI The Center for Data Innovation is pleased to submit feedback to the High-Level Expert Group (HLEG) on AI on its draft AI Ethics Guidelines for Trustworthy AI. The Center is a nonprofit research institute focused on the intersection of data, technology, and public policy. With staff in Washington, DC and Brussels, the Center formulates and promotes pragmatic public policies designed to maximize the benefits of data-driven innovation in the public and private sectors. It educates policymakers and the public about the opportunities and challenges associated with data, as well as technology trends such as artificial intelligence, open data, and the Internet of Things. The Center is affiliated with the Information Technology and Innovation Foundation (ITIF), the top-ranked science and technology policy think tank in the world.","",""
25,"K. Varshney","Trustworthy machine learning and artificial intelligence",2019,"","","","",71,"2022-07-13 09:36:00","","10.1145/3313109","","",,,,,25,8.33,25,1,3,"How can we add the most important ingredient to our relationship with machine learning?","",""
44,"A. Goli, H. Zare, R. Tavakkoli-Moghaddam, A. Sadeghieh","Hybrid artificial intelligence and robust optimization for a multi-objective product portfolio problem Case study: The dairy products industry",2019,"","","","",72,"2022-07-13 09:36:00","","10.1016/j.cie.2019.106090","","",,,,,44,14.67,11,4,3,"","",""
6,"Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier, A. Durresi","Trustworthy Artificial Intelligence: A Review",2022,"","","","",73,"2022-07-13 09:36:00","","10.1145/3491209","","",,,,,6,6.00,2,4,1,"Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.","",""
6,"A. McGovern, I. Ebert‐Uphoff, D. Gagne, A. Bostrom","The Need for Ethical, Responsible, and Trustworthy Artificial Intelligence for Environmental Sciences",2021,"","","","",74,"2022-07-13 09:36:00","","10.1017/eds.2022.5","","",,,,,6,6.00,2,4,1,"  Given the growing use of Artificial intelligence (AI) and machine learning (ML) methods across all aspects of environmental sciences, it is imperative that we initiate a discussion about the ethical and responsible use of AI. In fact, much can be learned from other domains where AI was introduced, often with the best of intentions, yet often led to unintended societal consequences, such as hard coding racial bias in the criminal justice system or increasing economic inequality through the financial system. A common misconception is that the environmental sciences are immune to such unintended consequences when AI is being used, as most data come from observations, and AI algorithms are based on mathematical formulas, which are often seen as objective. In this article, we argue the opposite can be the case. Using specific examples, we demonstrate many ways in which the use of AI can introduce similar consequences in the environmental sciences. This article will stimulate discussion and research efforts in this direction. As a community, we should avoid repeating any foreseeable mistakes made in other domains through the introduction of AI. In fact, with proper precautions, AI can be a great tool to help reduce climate and environmental injustice. We primarily focus on weather and climate examples but the conclusions apply broadly across the environmental sciences.","",""
16,"C. Stix","Actionable Principles for Artificial Intelligence Policy: Three Pathways",2021,"","","","",75,"2022-07-13 09:36:00","","10.1007/s11948-020-00277-3","","",,,,,16,16.00,16,1,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",76,"2022-07-13 09:36:00","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
13,"S. Haupt, W. Chapman, Samantha V. Adams, Charlie Kirkwood, J. Hosking, Nial H. Robinson, S. Lerch, A. Subramanian","Towards implementing artificial intelligence post-processing in weather and climate: proposed actions from the Oxford 2019 workshop",2021,"","","","",77,"2022-07-13 09:36:00","","10.1098/rsta.2020.0091","","",,,,,13,13.00,2,8,1,"The most mature aspect of applying artificial intelligence (AI)/machine learning (ML) to problems in the atmospheric sciences is likely post-processing of model output. This article provides some history and current state of the science of post-processing with AI for weather and climate models. Deriving from the discussion at the 2019 Oxford workshop on Machine Learning for Weather and Climate, this paper also presents thoughts on medium-term goals to advance such use of AI, which include assuring that algorithms are trustworthy and interpretable, adherence to FAIR data practices to promote usability, and development of techniques that leverage our physical knowledge of the atmosphere. The coauthors propose several actionable items and have initiated one of those: a repository for datasets from various real weather and climate problems that can be addressed using AI. Five such datasets are presented and permanently archived, together with Jupyter notebooks to process them and assess the results in comparison with a baseline technique. The coauthors invite the readers to test their own algorithms in comparison with the baseline and to archive their results. This article is part of the theme issue ‘Machine learning for weather and climate modelling’.","",""
43,"V. C. Vivoli","Trustworthy Artificial Intelligence",2018,"","","","",78,"2022-07-13 09:36:00","","","","",,,,,43,10.75,43,1,4,"","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",79,"2022-07-13 09:36:00","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
2,"B. Nair, Yakov Diskin, V. Asari","Multi-modal low cost mobile indoor surveillance system on the Robust Artificial Intelligence-based Defense Electro Robot (RAIDER)",2012,"","","","",80,"2022-07-13 09:36:00","","10.1117/12.930353","","",,,,,2,0.20,1,3,10,"We present an autonomous system capable of performing security check routines. The surveillance machine, the Clearpath Husky robotic platform, is equipped with three IP cameras with different orientations for the surveillance tasks of face recognition, human activity recognition, autonomous navigation and 3D reconstruction of its environment. Combining the computer vision algorithms onto a robotic machine has given birth to the Robust Artificial Intelligencebased Defense Electro-Robot (RAIDER). The end purpose of the RAIDER is to conduct a patrolling routine on a single floor of a building several times a day. As the RAIDER travels down the corridors off-line algorithms use two of the RAIDER's side mounted cameras to perform a 3D reconstruction from monocular vision technique that updates a 3D model to the most current state of the indoor environment. Using frames from the front mounted camera, positioned at the human eye level, the system performs face recognition with real time training of unknown subjects. Human activity recognition algorithm will also be implemented in which each detected person is assigned to a set of action classes picked to classify ordinary and harmful student activities in a hallway setting.The system is designed to detect changes and irregularities within an environment as well as familiarize with regular faces and actions to distinguish potentially dangerous behavior. In this paper, we present the various algorithms and their modifications which when implemented on the RAIDER serves the purpose of indoor surveillance.","",""
129,"Arun Das, P. Rad","Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",2020,"","","","",81,"2022-07-13 09:36:00","","","","",,,,,129,64.50,65,2,2,"Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.","",""
133,"K. Yeung","Recommendation of the Council on Artificial Intelligence (OECD)",2020,"","","","",82,"2022-07-13 09:36:00","","10.1017/ilm.2020.5","","",,,,,133,66.50,133,1,2,"On May 22, 2019, the Organisation for Economic Co-operation and Development (OECD) Ministerial Council Meeting adopted the Recommendation on Artificial Intelligence, signed by all 36 OECD member countries and non-member countries Argentina, Brazil, Columbia, Costa Rica, Peru, and Romania. Its aim is to foster innovation and trust in artificial intelligence (AI) by promoting the “responsible stewardship of trustworthy AI.”","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",83,"2022-07-13 09:36:00","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",84,"2022-07-13 09:36:00","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",85,"2022-07-13 09:36:00","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
10,"A. C. Horta, A. Silva, C. Sargo, V. M. Gonçalves, T. C. Zangirolami, Roberto Campos Giordano","Robust artificial intelligence tool for automatic start-up of the supplementary medium feeding in recombinant E. coli cultivations",2011,"","","","",86,"2022-07-13 09:36:00","","10.1007/s00449-011-0540-0","","",,,,,10,0.91,2,6,11,"","",""
50,"M. Ryan","In AI We Trust: Ethics, Artificial Intelligence, and Reliability",2020,"","","","",87,"2022-07-13 09:36:00","","10.1007/s11948-020-00228-y","","",,,,,50,25.00,50,1,2,"","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",88,"2022-07-13 09:36:00","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",89,"2022-07-13 09:36:00","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
74,"E. Neri, F. Coppola, V. Miele, C. Bibbolino, R. Grassi","Artificial intelligence: Who is responsible for the diagnosis?",2020,"","","","",90,"2022-07-13 09:36:00","","10.1007/s11547-020-01135-9","","",,,,,74,37.00,15,5,2,"","",""
5,"R. Medaglia, J. Gil-Garcia, T. Pardo","Artificial Intelligence in Government: Taking Stock and Moving Forward",2021,"","","","",91,"2022-07-13 09:36:00","","10.1177/08944393211034087","","",,,,,5,5.00,2,3,1,"The use of artificial intelligence (AI) applications in government is receiving increasing attention from global research and practice communities. This article, introducing a Special Issue on Artificial Intelligence in Government published in the Social Science Computer Review, presents an overview of some of the main policy initiatives across the world in relation to AI in government and discusses the state of the art of existing research. Based on an analysis of current trends in research and practice, we highlight four areas to be the focus of future research on AI in government: governance of AI, trustworthy AI, impact assessment methodologies, and data governance.","",""
4,"B. Weber-Lewerenz","Corporate digital responsibility (CDR) in construction engineering—ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",2021,"","","","",92,"2022-07-13 09:36:00","","10.1007/s42452-021-04776-1","","",,,,,4,4.00,4,1,1,"","",""
23,"S. Larsson","On the Governance of Artificial Intelligence through Ethics Guidelines",2020,"","","","",93,"2022-07-13 09:36:00","","10.1017/als.2020.19","","",,,,,23,11.50,23,1,2,"Abstract This article uses a socio-legal perspective to analyze the use of ethics guidelines as a governance tool in the development and use of artificial intelligence (AI). This has become a central policy area in several large jurisdictions, including China and Japan, as well as the EU, focused on here. Particular emphasis in this article is placed on the Ethics Guidelines for Trustworthy AI published by the EU Commission’s High-Level Expert Group on Artificial Intelligence in April 2019, as well as the White Paper on AI, published by the EU Commission in February 2020. The guidelines are reflected against partially overlapping and already-existing legislation as well as the ephemeral concept construct surrounding AI as such. The article concludes by pointing to (1) the challenges of a temporal discrepancy between technological and legal change, (2) the need for moving from principle to process in the governance of AI, and (3) the multidisciplinary needs in the study of contemporary applications of data-dependent AI.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",94,"2022-07-13 09:36:00","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
3,"Rüdiger Schmitz, R. Werner, A. Repici, R. Bisschops, A. Meining, Michael Zornow, H. Messmann, C. Hassan, Prateek Sharma, T. Rösch","Artificial intelligence in GI endoscopy: stumbling blocks, gold standards and the role of endoscopy societies",2021,"","","","",95,"2022-07-13 09:36:00","","10.1136/gutjnl-2020-323115","","",,,,,3,3.00,0,10,1,"Artificial intelligence has been portrayed as a silver bullet for a number of challenges encountered in gastrointestinal (GI) endoscopy and beyond. Intense research, commercial and media focus have led to the publication of studies with modest patient numbers and comparatively simple technology. There is no doubt that machine learning (ML) will be a determining medical development for the years to come. However, now that the dust has begun to settle, we are at a critical juncture where the focus is shifting from preclinical work toward the role of ML in clinical practice. Current issues relate to the evaluation and testing of AI and ML systems, especially regarding patient outcomes, and to regulatory issues surrounding implementation. Many of these aspects pertain to one overarching question: how can we ensure that preclinical results translate into trustworthy clinical reality? For the endoscopist, whether as a reader, a reviewer or a potential user of AI, it becomes increasingly important to understand the technical aspects of the systems and their performance measurements in order to realistically assess their practical value. Therefore, with GI endoscopy ML at the jumpoff point from proofofprinciple studies to clinical trials, van der Sommen et al provided us with an accessible guide to understand, assess and critically review the current ML endoscopy literature. Our commentary highlights selected aspects of this review and AI as a whole and elaborates on the role of the GI endoscopy community and how it may both experience and frame the way ahead. In particular, we advocate a close collaboration of technology scientists and clinicians from early development phases onward to allow for the development of welltailored AI algorithms and realistic preclinical testing. More transparency is needed with respect to the training data and the algorithm development process. In addition, in the legislative debates, the endoscopy societies need to play a critical role in defining the research priorities, minimum standards and quality metrics by having a strong voice and presence in this field. Furthermore, we propose the establishment of a ‘rolling gold standard’ to meet requirements for continuous retesting and benchmarking of AI systems.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",96,"2022-07-13 09:36:00","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",97,"2022-07-13 09:36:00","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
0,"F. Filip","AI vs AI (Augmenting [Human] Intellect vs Artificial Intelligence) : Plenary Talk",2021,"","","","",98,"2022-07-13 09:36:00","","10.1109/SACI51354.2021.9465578","","",,,,,0,0.00,0,1,1,"Almost six decades ago, when proposing the scientific programme of Stanford Research Institute (SRI), Engelbart (1962) stated: “…By augmenting human intellect we mean increasing the capability of a man to approach a complex problem situation, to gain comprehension to suit his particular needs, and to derive solutions to problems.” More than twenty-five years, later Engelbart and Lehtman (1988) noticed that “In the optimum design [of a CSCW system], either a tool system or a human system is dependent on the match it must make with the other. The high degree of dependence implies that balanced co-evolution of both is necessary.” This paper aims at presenting how the usage of AI (Artificial Intelligence) has evolved towards a trustworthy discipline and set of tools and facilitated the augmenting the human intellect in order to enable the human to approach and solve complex problems of the day.","",""
0,"Feng Xiaohua, Conrad Marc, E. Elias, Hussein Khalid","Artificial Intelligence and Blockchain for Future Cyber Security Application",2021,"","","","",99,"2022-07-13 09:36:00","","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00133","","",,,,,0,0.00,0,4,1,"AI (Artificial intelligence) application on Big Data had been developed fast. AI cyber security defense for the facing threats were required. Blockchain technology was invented in 2008 with BTC (Bit coin. This technology could be benefited alongside the custom of Blockchain, AI, Big Data and so on. There were a rapid progress in the advancement of Blockchain. This subject had recently become a discussion topic in the ICT (Information and Communications Technology) world. In this paper, AI security is discussed from the initial stage. Suggestion: In this paper, we discussed the impact of AI security from the initial stage and its impact and benefits to IT engineers, ICT students and CS (Computer Sciences) academic researchers, using a case study of medical records with personal recognizable identification privacy information that needs strict access control security. We considered its need for trustworthy cyber security, anti-fake, anti-alteration and transaction accounting transparency reputation to be applied to the NHS (National Health Service). Lastly, the paper provided some necessarily analysis. Blockchain technology had trustworthy cyber security, anti-fake, anti-alteration and transaction accounting transparency reputation to be considered to be applied to NHS (National Health Service). This short paper provided some analysis necessarily.","",""
0,"Victoria Tucci, J. Saary, Thomas E. Doyle","Factors influencing trust in medical artificial intelligence for healthcare professionals: a narrative review",2021,"","","","",100,"2022-07-13 09:36:00","","10.21037/jmai-21-25","","",,,,,0,0.00,0,3,1,"Objective: We performed a comprehensive review of the literature to better understand the trust dynamics between medical artificial intelligence (AI) and healthcare expert end-users. We explored the factors that influence trust in these technologies and how they compare to established concepts of trust in the engineering discipline. By identifying the qualitatively and quantitatively assessed factors that influence trust in medical AI, we gain insight into understanding how autonomous systems can be optimized during the development phase to improve decision-making support and clinician-machine teaming. This facilitates an enhanced understanding of the qualities that healthcare professional users seek in AI to consider it trustworthy. We also highlight key considerations for promoting on-going improvement of trust in autonomous medical systems to support the adoption of medical technologies into practice. Background: decision support systems introduces challenges and barriers to adoption and implementation into clinical practice. Methods: We searched databases including, Ovid MEDLINE, Ovid EMBASE, Clarivate Web of Science, and Google Scholar, as well as gray literature, for publications from 2000 to July 15, 2021, that reported features of AI-based diagnostic and clinical decision support systems that contribute to enhanced end-user trust. Papers discussing implications and applications of medical AI in clinical practice were also recorded. Results were based on the quantity of papers that discussed each trust concept, either quantitatively or qualitatively, using frequency of concept commentary as a proxy for importance of a respective concept. Conclusions: Explainability, transparency, interpretability, usability, and education are among the key identified factors thought to influence a healthcare professionals’ trust in medical AI and enhance clinician-machine teaming in critical decision-making healthcare environments. We also identified the need to better evaluate and incorporate other critical factors to promote trust by consulting medical professionals when developing AI systems for clinical decision-making and diagnostic support.","",""
21,"Ala Ekramifard, H. Amintoosi, Amin Hosseini Seno, A. Dehghantanha, R. Parizi","A Systematic Literature Review of Integration of Blockchain and Artificial Intelligence",2020,"","","","",101,"2022-07-13 09:36:00","","10.1007/978-3-030-38181-3_8","","",,,,,21,10.50,4,5,2,"","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",102,"2022-07-13 09:36:00","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",103,"2022-07-13 09:36:00","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",104,"2022-07-13 09:36:00","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
43,"Stuart J. Russell, Thomas G. Dietterich, Eric Horvitz, B. Selman, F. Rossi, D. Hassabis, S. Legg, Mustafa Suleyman, D. George, D. Phoenix","Letter to the Editor: Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter",2015,"","","","",105,"2022-07-13 09:36:00","","10.1609/aimag.v36i4.2621","","",,,,,43,6.14,4,10,7,"Artificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents — systems that perceive and act in some environment. In this context, ""intelligence"" is related to statistical and economic notions of rationality — colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic and decision-theoretic representations and statistical learning methods has led to a large degree of integration and cross-fertilization among AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition, image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems. As capabilities in these areas and others cross the threshold from laboratory research to economically valuable technologies, a virtuous cycle takes hold whereby even small improvements in performance are worth large sums of money, prompting greater investments in research. There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. The progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008–09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do. The attached research priorities document [see page X] gives many examples of such research directions that can help maximize the societal benefit of AI. This research is by necessity interdisciplinary, because it involves both society and AI. It ranges from economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself. In summary, we believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today.","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",106,"2022-07-13 09:36:00","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",107,"2022-07-13 09:36:00","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
14,"Claudia Gonzalez Viejo, S. Fuentes","Beer Aroma and Quality Traits Assessment Using Artificial Intelligence",2020,"","","","",108,"2022-07-13 09:36:00","","10.3390/fermentation6020056","","",,,,,14,7.00,7,2,2,"Increasing beer quality demands from consumers have put pressure on brewers to target specific steps within the beer-making process to modify beer styles and quality traits. However, this demands more robust methodologies to assess the final aroma profiles and physicochemical characteristics of beers. This research shows the construction of artificial intelligence (AI) models based on aroma profiles, chemometrics, and chemical fingerprinting using near-infrared spectroscopy (NIR) obtained from 20 commercial beers used as targets. Results showed that machine learning models obtained using NIR from beers as inputs were accurate and robust in the prediction of six important aromas for beer (Model 1; R = 0.91; b = 0.87) and chemometrics (Model 2; R = 0.93; b = 0.90). Additionally, two more accurate models were obtained from robotics (RoboBEER) to obtain the same aroma profiles (Model 3; R = 0.99; b = 1.00) and chemometrics (Model 4; R = 0.98; b = 1.00). Low-cost robotics and sensors coupled with computer vision and machine learning modeling could help brewers in the decision-making process to target specific consumer preferences and to secure higher consumer demands.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",109,"2022-07-13 09:36:00","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",110,"2022-07-13 09:36:00","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",111,"2022-07-13 09:36:00","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",112,"2022-07-13 09:36:00","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",113,"2022-07-13 09:36:00","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
7,"Sonal Jain, Manan Luthra, Shagun Sharma, Mehtab Fatima","Trustworthiness of Artificial Intelligence",2020,"","","","",114,"2022-07-13 09:36:00","","10.1109/ICACCS48705.2020.9074237","","",,,,,7,3.50,2,4,2,"This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.","",""
8,"Kehua Guo, Sheng Ren, Md Zakirul Alam Bhuiyan, Ting-Bo Li, Dengchao Liu, Zhonghe Liang, Xiang Chen","MDMaaS: Medical-Assisted Diagnosis Model as a Service With Artificial Intelligence and Trust",2020,"","","","",115,"2022-07-13 09:36:00","","10.1109/TII.2019.2937547","","",,,,,8,4.00,1,7,2,"Artificial intelligence has achieved great success in the field of medical-assisted diagnosis, and a deep learning technology plays a very important role in medical image recognition. However, it usually takes medical institutions extra time, energy, and cost to obtain a credible and efficient deep learning model, which is not conducive to a wide range of applications, including medical image recognition and medical decision making. In this article, we propose a novel medical-assisted diagnosis model as a service (MDMaaS). Medical institutions can obtain and use the medical-assisted diagnosis models from the service providers directly; a model training and a model application in machine learning are assigned to a service provider and a consumer, respectively. We have designed a model acquisition method based on the conventional samples and small samples for MDMaaS providers, and we have also developed a trustworthy model-based recommendation method for MDMaaS consumers, which would help the medical institutions to obtain the reliable medical-assisted diagnosis models quickly and efficiently. Based on the MDMaaS, extensive experiments are performed to verify the effectiveness of the proposed method.","",""
8,"Steven Lockey, N. Gillespie, Caitlin Curtis","Trust in Artificial Intelligence: Australian Insights",2020,"","","","",116,"2022-07-13 09:36:00","","10.14264/b32f129","","",,,,,8,4.00,3,3,2,"Artificial Intelligence (AI) is the cornerstone technology of the Fourth Industrial Revolution and is enabling rapid innovation with many potential benefits for Australian society (e.g. enhanced healthcare diagnostics, transportation optimisation) and business (e.g. enhanced efficiency and competitiveness). The COVID-19 pandemic has accelerated the uptake of advanced technology, and investment in AI continues to grow exponentially.AI also poses considerable risks and challenges to society which raises concerns about whether AI systems are worthy of trust. These concerns have been fuelled by high profile cases of AI use that were biased, discriminatory, manipulative, unlawful, or violated privacy or other human rights. Without public confidence that AI is being developed and used in an ethical and trustworthy manner, it will not be trusted and its full potential will not be realised. To echo the sentiment of Dr Alan Finkel AO, Australia’s Chief Scientist, acceptance of AI rests on “the essential foundation of trust”. Are we capable of extending our trust to AI?This national survey is the first to take a deep dive into answering this question and understanding community trust and expectations in relation to AI. To do this, we surveyed a nationally representative sample of over 2,500 Australian citizens in June to July 2020. Our findings provide important and timely research insights into the public’s trust and attitudes towards AI and lay out a pathway for strengthening trust and acceptance of AI systems.Key findings include:              - Trust is central to the acceptance of AI, and is influenced by four key drivers;              - Australians have low trust in AI systems but generally ‘accept’ or ‘tolerate’ AI;              - Australians expect AI to be regulated and carefully managed;              - Australians expect organisations to uphold the principles of trustworthy AI;              - Australians feel comfortable with some but not all uses of AI at work;              - Australians want to know more about AI but currently have low awareness and understanding of AI and its uses.We draw out the implications of the findings for government, business and NGOs and provide a roadmap to enhancing public trust in AI highlighting three key actions:              - Live up to Australian’s expectations of trustworthy AI              - Strengthen the regulatory framework for governing AI              - Strengthen Australia’s AI literacy","",""
6,"P. Almeida, Carlos Denner dos Santos, Josivânia Silva Farias","Artificial Intelligence Regulation: A Meta-Framework for Formulation and Governance",2020,"","","","",117,"2022-07-13 09:36:00","","10.24251/hicss.2020.647","","",,,,,6,3.00,2,3,2,"This article presents a meta-framework for Artificial Intelligence (AI) regulation that encompasses all stages of international public policy-making, from formulation to sustainable governance. Based on a vast systematic review of the literature on Artificial Intelligence Regulation (AIR) published between 2009 and 2019, a dispersed body of knowledge organized under the label “framework” was identified, containing 15 unique frameworks and several different theories that created a complex scientific scenario for research and practice. Theories and principles as diverse as Agile and Ethics were found. Thus, a structured analytical method was followed to integrate this bulk of knowledge into a cohesive, synthetic, and generic theoretical tool. The resulting “AIR framework” provides a trustworthy lens for societies to think collectively and make informed policy decisions related to what, when, and how the uses and applications of AI should be regulated. Moreover, the novel framework organizes the latest developments in the area in a format that allows future research to be framed in and added to the published literature. The (potential) impacts of AI on society are immense, and therefore the discourses, social negotiations, and applications of this technology should be guided by common grounds in terms of terminology, governance, and social values.","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",118,"2022-07-13 09:36:00","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
2,"Angeliki Kerasidou","Empathy, compassion and trust balancing artificial intelligence in health care",2020,"","","","",119,"2022-07-13 09:36:00","","","","",,,,,2,1.00,2,1,2,"Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the quest for greater efficiency in health care, including economic efficiency, has often resulted in the side-lining of these values, making it difficult for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care. This technology promises greater efficiency and more free time for health-care professionals to focus on the human side of care, including fostering trust relationships and engaging with patients with empathy and compassion. This article considers the vision of efficient, empathetic and trustworthy health care put forward by the proponents of artificial intelligence. The paper suggests that artificial intelligence has the potential to fundamentally alter the way in which empathy, compassion and trust are currently regarded and practised in health care. Moving forward, it is important to re-evaluate whether and how these values could be incorporated and practised within a health-care system where artificial intelligence is increasingly used. Most importantly, there is a need to re-examine what kind of health care society ought to promote is needed. Introduction Empathy, compassion and trust are fundamental values of a patient-centred, relational model of health care. In recent years, the pursuit of greater efficiency in health care, including economic efficiency, has often resulted in these values being side-lined, making it difficult or even impossible for health-care professionals to incorporate them in practice. Artificial intelligence is increasingly being used in health care and promises greater efficiency and effectiveness and a level of personalization not possible before. Artificial intelligence could help improve diagnosis and treatment accuracy, streamline workflow processes and speed up the operation of clinics and hospital departments. The hope is that by improving efficiency, time will be freed for health-care professionals to focus more fully on the human side of care, which involves fostering trust relationships and engaging with patients with empathy and Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 2 of 11 compassion. However, the transformative force of artificial intelligence has the potential to disrupt the relationship between health-care professionals and patients as it is currently understood, and challenge both the role and nature of empathy, compassion and trust in health care. In a time of increasing use of artificial intelligence in health care, it is important to re-evaluate whether and how these values could be incorporated and exercised, but most importantly to re-examine what kind of health care society ought to promote. Empathy, compassion and trust Over the past decades, the rise of patient-centred care has shifted the culture of clinical medicine away from paternalism, in which the therapeutic relationship, the relationship between the health-care professional and the patient, is led by medical expertise, towards a more active engagement of patients in shared medical decision-making. This model of engagement requires the health-care professional to understand the patient’s perspective and guide the patient in making the right decision; a decision which reflects the patient’s needs, desires and ideals, and also promotes health-related values. The central point of the patientcentred model of doctor–patient relationship is that medical competency should not be reduced to technical expertise, but must include relational moral competency, particularly empathy, compassion and trust. Empathy, compassion and trust are broadly recognized as fundamental values of good health-care practice. Empathy allows health-care professionals to understand and share the patient’s feelings and perspective. Compassion is the desire to help that is instigated by the empathetic engagement with the patient. Patients seek out and prefer to engage with health professionals who are competent, but also have the right interpersonal and emotional skills. The belief and confidence in the professional’s competency, understanding and desire to help is what underpins patient trust. Research has demonstrated the benefits of trust and empathetic care, including improved patient satisfaction, increased treatment adherence and improved health outcomes. Despite their importance, empathy and compassion in health care are often side-lined. In recent years, for example, socioeconomic factors, including an ageing population and austerity policies in Europe that followed the 2008 economic collapse, have led to the marginalization of these values. As health-care systems struggle with resourcing, the space for empathy and compassion has shrunk while the need for efficiency has grown. In the United Kingdom of Great Britain and Northern Ireland, high-profile cases and reports, such Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 3 of 11 as the Francis report which followed the Mid Staffordshire scandal, the report by the Health Service Ombudsman entitled Dying without dignity and the Leadership Alliance for the Care of Dying People report, all pointed at lack of empathy as a major problem in clinical care. What these cases also showed was a conflicting relationship between the need for empathy and the pursuit of greater economic efficiency and of meeting operational targets. In 2017, Sir Robert Francis, who chaired the inquiry into the Mid Staffordshire scandal, mentioned in an interview that “at the time at Mid Staffordshire there was huge pressure on organizations to balance their books, to make productivity improvements, and matters of that nature. It all became about figures in the books, rather than outcomes for the patient. And I do believe there’s a danger of that happening again.” Research in 2017 in accident and emergency departments in England on the effect of austerity policies on the everyday experiences of health-care professionals found that the pressure to meet targets negatively affected the doctors’ and nurses’ ability and opportunity to practise empathetic and holistic care, which led to moral distress and burnout among these professionals. Against this backdrop, artificial intelligence has been heralded as a way to save struggling national health-care systems and transform the future of health care by providing greater efficiency, effectiveness and high levels of personalized care. Artificial intelligence in health care Artificial intelligence is broadly defined as “computing technologies that resemble processes associated with human intelligence, such as reasoning, learning and adaptation, sensory understanding, and interaction.” The hope is that these technologies will transform healthcare delivery “from streamlining workflow processes to improving the accuracy of diagnosis and personalizing treatment, as well as helping staff work more efficiently and effectively.” Artificial intelligence could help health-care systems achieve greater efficiency, including economic efficiency, in two ways: (i) by improving time to and accuracy of diagnosis and treatment for patients, and where possible assisting with early prevention; and (ii) by using health-care staff more efficiently. A report published in 2018 in the United Kingdom suggested that the national health system could save up to 10% of its running costs by outsourcing repetitive and administrative tasks to artificial intelligence technologies. The same report also envisaged bedside robots performing social-care tasks such helping patients to eat, wash and dress, thus reducing the workload on care staff by 30%. But it is not only nursing and administrative tasks that Publication: Bulletin of the World Health Organization; Type: Policy & practice Article ID: BLT.19.237198 Page 4 of 11 artificial intelligence can help with. With regard to effectiveness, artificial intelligence systems could be used to deliver better clinical services both by assisting with the diagnosis and management of patients, and by providing the diagnosis and prescribing treatments. Research conducted so far has shown that machines can perform as well as, or even better than, humans in detecting skin cancer, heart arrhythmia and Alzheimer disease. Furthermore, human–machine partnerships can provide far better results than either humans or machines alone. In these examples, the principal benefits of artificial intelligence stem from its ability to improve efficiency and effectiveness by guiding diagnoses, delivering more accurate results and thus eliminating human error. With regard to greater efficiency through prevention, artificial intelligence technologies that track and analyse the movement of individuals could be used to detect people at risk of stroke and eliminate that risk through early intervention. Health care is already using technology to improve its efficiency and effectiveness. From scalpels and syringes to stethoscopes and X-ray machines, the list of technologies used in medicine to facilitate and improve patient care is long. However, artificial intelligence differs from previous medical technological advances. Whereas previous technologies were used to increase the senses and physical capacities of health-care professionals – consider, for example, how the stethoscope enhanced the hearing of doctors and X-rays their vision – the main role of artificial intelligence is to increase their reasoning and decision-making capacities. In this way, artificial intelligence is entering the health-care arena as another morally relevant actor that assists, guides or makes independent decisions regarding the treatment and management of patients. Proponents of artificial intelligence technology in health care maintain that outsourcing tasks and decisions to r","",""
2,"Sylwester Bejger, Stephan Elster","Artificial Intelligence in economic decision making: how to assure a trust?",2020,"","","","",120,"2022-07-13 09:36:00","","10.12775/EIP.2020.028","","",,,,,2,1.00,1,2,2,"Motivation: The decisions made by modern ‘black box’ artificial intelligence models are not understandable and therefore people do not trust them. This limits down the potential power of usage of Artificial Intelligence. Aim: The idea of this text is to show the different initiatives in different countries how AI, especially black box AI, can be made transparent and trustworthy and what kind of regulations will be implemented or discussed to be implemented. We also show up how a commonly used development process within Machine Learning can be enriched to fulfil the requirements e.g. of the Ethics guidelines for trustworthy AI of the High-Level Expert Group of the European Union. We support our discussion with a proposition of empirical tools providing interpretability. Results: The full potential of AI or products using AI can only be raised if the decision of AI models are transparent and trustworthy. Regulations which are followed over the whole life cycle of AI models, algorithms or the products they using these are therefore necessary as well as understandability or explainability of the decisions these models and algorithms made. Initiatives on every level of stakeholders started, e.g. international level on the European Union, country level, USA, China etc. as well on a company level. The post-hoc local interpretability methods could and should be implemented by economic decision makers to provide compliance with the regulations.","",""
2,"M. Maciejewski, Christina E. M. Ratcliff","Artificial Intelligence (AI): new developments and innovations applied to e-commerce",2020,"","","","",121,"2022-07-13 09:36:00","","","","",,,,,2,1.00,1,2,2,"This in-depth analysis discusses the opportunities and challenges brought by the recent and the foreseeable developments of Artificial Intelligence into online platforms and marketplaces. The paper advocates the importance to support trustworthy, explainable AI (in order to fight discrimination and manipulation, and empower citizens), and societal-aware AI (in order to fight polarisation, monopolistic concentration and excessive inequality, and pursue diversity and openness). This document was provided by the Policy Department for Economic, Scientific and Quality of Life Policies at the request of the committee on the Internal Market and Consumer Protection (IMCO). Artificial Intelligence (AI): new developments and innovations applied to e-commerce Challenges to the functioning of the Internal Market This document was requested by the European Parliament's committee on the Internal Market and Consumer Protection. AUTHORS Dino PEDRESCHI, University of Pisa, Italy Ioanna MILIOU, University of Pisa, Italy ADMINISTRATORS RESPONSIBLE Mariusz MACIEJEWSKI Christina RATCLIFF EDITORIAL ASSISTANT Roberto BIANCHINI LINGUISTIC VERSIONS Original: EN ABOUT THE EDITOR Policy departments provide in-house and external expertise to support EP committees and other parliamentary bodies in shaping legislation and exercising democratic scrutiny over EU internal policies. To contact the Policy Department or to subscribe for updates, please write to: Policy Department for Economic, Scientific and Quality of Life Policies European Parliament L-2929 Luxembourg Email: Poldep-Economy-Science@ep.europa.eu Manuscript completed: May 2020 Date of publication: May 2020 © European Union, 2020 This document is available on the internet at: http://www.europarl.europa.eu/supporting-analyses DISCLAIMER AND COPYRIGHT The opinions expressed in this document are the sole responsibility of the authors and do not necessarily represent the official position of the European Parliament. Reproduction and translation for non-commercial purposes are authorised, provided the source is acknowledged and the European Parliament is given prior notice and sent a copy. For citation purposes, the study should be referenced as: Pedreschi, D., Artificial Intelligence (AI): new developments and innovations applied to e-commerce, Study for the committee on the Internal Market and Consumer Protection, Policy Department for Economic, Scientific and Quality of Life Policies, European Parliament, Luxembourg, 2020. © Cover image used under licence from Shutterstock.com Artificial Intelligence (AI): new developments and innovations applied to e-commerce 3 PE 648.791 CONTENTS LIST OF FIGURES 5 EXECUTIVE SUMMARY 6 1. ARTIFICIAL INTELLIGENCE, BIG DATA, MACHINE LEARNING 9 2. AI-RISKS AND CHALLENGES 11","",""
2,"P. Chemouil, P. Hui, W. Kellerer, Noura Limam, R. Stadler, Yonggang Wen","Guest Editorial Special Issue on Advances in Artificial Intelligence and Machine Learning for Networking",2020,"","","","",122,"2022-07-13 09:36:00","","10.1109/JSAC.2020.3003065","","",,,,,2,1.00,0,6,2,"ARTIFICIAL Intelligence (AI) and Machine Learning (ML) approaches have emerged in the networking domain with great expectation. They can be broadly divided into AI/ML techniques for network engineering and management, network designs for AI/ML applications, and system concepts. AI/ML techniques for networking and management improve the way we address networking. They support efficient, rapid, and trustworthy engineering, operations, and management. As such, they meet the current interest in softwarization and network programmability that fuels the need for improved network automation in agile infrastructures, including edge and fog environments. Network design and optimization for AI/ML applications addresses the complementary topic of supporting AI/ML-based systems through novel networking techniques, including new architectures and algorithms. The third topic area is system implementation and open-source software development. This evolution draws particular attention to interdisciplinary approaches. Researchers in communication networks apply ML and AI concepts to optimize and automate network architecture, control, and management. Similarly, AI experts collaborate with networking researchers to optimize network support for architecture and design of data communication and processing for AI purposes. This special issue is a follow-up to the JSAC’s Special Issue on Artificial Intelligence and Machine Learning for Networking and Communications published in June 2019 [1]. It has been organized by the same core team of researchers.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",123,"2022-07-13 09:36:00","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",124,"2022-07-13 09:36:00","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",125,"2022-07-13 09:36:00","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",126,"2022-07-13 09:36:00","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",127,"2022-07-13 09:36:00","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",128,"2022-07-13 09:36:00","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",129,"2022-07-13 09:36:00","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
77,"Alon Jacovi, Ana Marasović, Tim Miller, Yoav Goldberg","Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",2020,"","","","",130,"2022-07-13 09:36:00","","10.1145/3442188.3445923","","",,,,,77,38.50,19,4,2,"Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",131,"2022-07-13 09:36:00","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
0,"K. Panetta","Artificial Intelligence (AI) for Humanity",2020,"","","","",132,"2022-07-13 09:36:00","","10.1109/ccs49175.2020.9231494","","",,,,,0,0.00,0,1,2,"Natural disasters including earthquakes, tsunamis, and anthropogenic disasters, such as wildfires, are dynamic situations requiring constant monitoring as numerous hazards are constantly emerging that hinder humanitarian efforts and create deadly conditions for rescue workers and victims. Now, with humanity facing a pandemic, it becomes even more vital to provide health care workers and first responders with low-cost and robust methods to protect themselves and help stop the spread of a disease that is ravaging our lives and economies. There are high expectations that Artificial Intelligence will be the game changing technology that will make sense of the plethora of disparate sources of data being collected about individuals, communities and the environment and that it will help solve all of these problems. Meanwhile, coupling AI with robotics is anticipated to be the foundation for a future contactless society that will mitigate the spread of diseases and keep us healthier. However, AI is not a box that can magically produce these solutions and building trustworthy AI comes with many challenges. This talk will discuss those challenges and explore some of the pathways forward to best utilize AI and its promise to advance robotics to conquer societal challenges.","",""
10,"N. Rodríguez, G. Pisoni","Accessible Cultural Heritage through Explainable Artificial Intelligence",2020,"","","","",133,"2022-07-13 09:36:00","","10.1145/3386392.3399276","","",,,,,10,5.00,5,2,2,"Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy.","",""
17,"Shengjie Xu, Y. Qian, R. Hu","Data-Driven Edge Intelligence for Robust Network Anomaly Detection",2020,"","","","",134,"2022-07-13 09:36:00","","10.1109/TNSE.2019.2936466","","",,,,,17,8.50,6,3,2,"The advancement of networking platforms for assured online services requires robust and effective network intelligence systems against anomalous events and malicious threats. With the rapid development of modern communication technologies, artificial intelligence, and the revolution of computing devices, cloud computing empowered network intelligence will inevitably become a core platform for various smart applications. While cloud computing provides strong and powerful computation, storage, and networking services to detect and defend cyber threats, edge computing on the other hand will deliver more benefits in specific yet potential critical areas. In this paper, we present a study on the data-driven edge intelligence for robust network anomaly detection. We first highlight the main motivations for edge intelligence, and then propose an intelligence system empowered by edge computing for network anomaly detection. We further propose a scheme on the data-driven robust network anomaly detection. In the proposed scheme, four phases are designed to incorporate with data-driven approaches to train a learning model which is able to detect and identify a network anomaly in a robust way. In the performance evaluations with data experiments, we demonstrate that the proposed scheme achieves the robustness of trained model and the efficiency on the detection of specific anomalies.","",""
0,"","Patients set to benefit from new guidelines on artificial intelligence health solutions",2020,"","","","",135,"2022-07-13 09:36:00","","","","",,,,,0,0.00,0,0,2,"The use of these international guidelines will enable patients, health care professionals and policy-makers to be more confident on whether an AI intervention is safe and effective. This is a key step towards trustworthy AI in health. Development of new reporting guidelines which expand on the current SPIRIT 2013 and CONSORT 2010 reporting frameworks will boost transparency and robustness for clinical trials evaluating AI health solutions.","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",136,"2022-07-13 09:36:00","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
21,"Radhia Garraoui, M. Hamed, L. Sbita","Comparison of MPPT algorithms for DC-DC boost converters based PV systems using robust control technique and artificial intelligence algorithm",2015,"","","","",137,"2022-07-13 09:36:00","","10.1109/SSD.2015.7348163","","",,,,,21,3.00,7,3,7,"This paper proposes two methods of maximum power point tracking algorithm for photovoltaic systems, based on the first hand on fuzzy logic control and on the other hand on the first order sliding mode control. According to the nonlinear characteristic of photovoltaic array, it's necessary to find a solution to track the maximum power of the PV system in order to improve its efficiency. The fuzzy logic controller was presented in many works. It provides fast response and good performance against the climatic and load change and uses directly the DC/DC converter duty cycle as a control parameter. Moreover, the sliding mode control approach is recognized as one of the efficient tools to design robust controllers it has been receiving much more attention within the last two decades and many research are dealing with this type of robust controllers. A detailed comparison between the fuzzy logic and slinging mode controllers was presented in this work. Simulation results show that the proposed algorithms can effectively improve the efficiency of a photovoltaic array output.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",138,"2022-07-13 09:36:00","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",139,"2022-07-13 09:36:00","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
16,"J. Korteling, G. V. D. Boer-Visschedijk, R. Blankendaal, R. Boonekamp, A. Eikelboom","Human- versus Artificial Intelligence",2021,"","","","",140,"2022-07-13 09:36:00","","10.3389/frai.2021.622364","","",,,,,16,16.00,3,5,1,"AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",141,"2022-07-13 09:36:00","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",142,"2022-07-13 09:36:00","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
141,"S. Seshia, Dorsa Sadigh","Toward verified artificial intelligence",2016,"","","","",143,"2022-07-13 09:36:00","","10.1145/3503914","","",,,,,141,23.50,71,2,6,"Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",144,"2022-07-13 09:36:00","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",145,"2022-07-13 09:36:00","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",146,"2022-07-13 09:36:00","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",147,"2022-07-13 09:36:00","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",148,"2022-07-13 09:36:00","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",149,"2022-07-13 09:36:00","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",150,"2022-07-13 09:36:00","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
32,"Y. Gil, B. Selman","A 20-Year Community Roadmap for Artificial Intelligence Research in the US",2019,"","","","",151,"2022-07-13 09:36:00","","","","",,,,,32,10.67,16,2,3,"Decades of research in artificial intelligence (AI) have produced formidable technologies that are providing immense benefit to industry, government, and society. AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars. The deployment of AI systems has not only created a trillion-dollar industry that is projected to quadruple in three years, but has also exposed the need to make AI systems fair, explainable, trustworthy, and secure. Future AI systems will rightfully be expected to reason effectively about the world in which they (and people) operate, handling complex tasks and responsibilities effectively and ethically, engaging in meaningful communication, and improving their awareness through experience.  Achieving the full potential of AI technologies poses research challenges that require a radical transformation of the AI research enterprise, facilitated by significant and sustained investment. These are the major recommendations of a recent community effort coordinated by the Computing Community Consortium and the Association for the Advancement of Artificial Intelligence to formulate a Roadmap for AI research and development over the next two decades.","",""
32,"K. Letaief, Yuanming Shi, Jianmin Lu, Jianhua Lu","Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications",2021,"","","","",152,"2022-07-13 09:36:00","","10.1109/jsac.2021.3126076","","",,,,,32,32.00,8,4,1,"The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from “connected things” to “connected intelligence”. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",153,"2022-07-13 09:36:00","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",154,"2022-07-13 09:36:00","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
28,"Jian Guan","Artificial Intelligence in Healthcare and Medicine: Promises, Ethical Challenges and Governance.",2019,"","","","",155,"2022-07-13 09:36:00","","10.24920/003611","","",,,,,28,9.33,28,1,3,"Artificial intelligence (AI) is rapidly being applied to a wide range of fields, including medicine, and has been considered as an approach that may augment or substitute human professionals in primary healthcare. However, AI also raises several challenges and ethical concerns. In this article, the author investigates and discusses three aspects of AI in medicine and healthcare: the application and promises of AI, special ethical concerns pertaining to AI in some frontier fields, and suggestive ethical governance systems. Despite great potentials of frontier AI research and development in the field of medical care, the ethical challenges induced by its applications has put forward new requirements for governance. To ensure ""trustworthy"" AI applications in healthcare and medicine, the creation of an ethical global governance framework and system as well as special guidelines for frontier AI applications in medicine are suggested. The most important aspects include the roles of governments in ethical auditing and the responsibilities of stakeholders in the ethical governance system.","",""
20,"O. Al-Mushayt","Automating E-Government Services With Artificial Intelligence",2019,"","","","",156,"2022-07-13 09:36:00","","10.1109/ACCESS.2019.2946204","","",,,,,20,6.67,20,1,3,"Artificial Intelligence (AI) has recently advanced the state-of-art results in an ever-growing number of domains. However, it still faces several challenges that hinder its deployment in the e-government applications–both for improving the e-government systems and the e-government-citizens interactions. In this paper, we address the challenges of e-government systems and propose a framework that utilizes AI technologies to automate and facilitate e-government services. Specifically, we first outline a framework for the management of e-government information resources. Second, we develop a set of deep learning models that aim to automate several e-government services. Third, we propose a smart e-government platform architecture that supports the development and implementation of AI applications of e-government. Our overarching goal is to utilize trustworthy AI techniques in advancing the current state of e-government services in order to minimize processing times, reduce costs, and improve citizens’ satisfaction.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",157,"2022-07-13 09:36:00","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
22,"Rushikesh S. Joshi, Alexander F. Haddad, Darryl Lau, C. Ames","Artificial Intelligence for Adult Spinal Deformity",2019,"","","","",158,"2022-07-13 09:36:00","","10.14245/ns.1938414.207","","",,,,,22,7.33,6,4,3,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery.","",""
0,"Renata Guizzardi, Jennifer Horkoff, A. Perini, A. Susi","Preface: 3rd Workshop on Requirements Engineering for Artificial Intelligence (RE4AI)",2022,"","","","",159,"2022-07-13 09:36:00","","","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) is embedded in software systems used in everyday life, such as cars, household appliances, wearable devices, healthcare chatbots, as well as in a variety of software applications that support data-driven decisions, e.g. business intelligence services for insurance companies. For several years, AI researchers have manifested their worries and recommendations for the responsible use of data, employment of discrimination-free algorithms, alignment of AI-based systems and technologies with human values and transparency. Awareness for the need of approaches for “Responsible AI” has rapidly increased and motivated attention by normative and standardisation organisations (e.g. EU Ethics Guidelines for Trustworthy AI1, and the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems2), software technology big players, and diverse research communities, including Software Engineering and Requirements Engineering research communities. The Requirements Engineering for Artificial Intelligence (RE4AI) workshop aims to provide a forum for discussing how Requirements Engineering methods, techniques and tools may be used to support the development of Artificial Intelligence systems that are lawful, ethical and robust. The main goals of the RE4AI workshop are as follows: raising awareness in the RE community about the importance of RE in realizing Trustworthy AI systems; bringing in the same room people from AI and RE industry and academia to discuss pressing issues, such as how RE can contribute to prevent AI systems to fail or to go rogue; setting up the basis for collaboratively producing a report on the challenges, candidate solution paths, and research","",""
21,"D. Ting, M. Ang, J. Mehta, D. Ting","Artificial intelligence-assisted telemedicine platform for cataract screening and management: a potential model of care for global eye health",2019,"","","","",160,"2022-07-13 09:36:00","","10.1136/bjophthalmol-2019-315025","","",,,,,21,7.00,5,4,3,"Artificial intelligence (AI) is the fourth industrial revolution.1 Deep learning is a robust machine learning technique that uses convolutional neural network to perform multilevel data abstraction without the need for manual feature engineering.2 In ophthalmology, many studies showed comparable, if not better, diagnostic performance in using AI to screen, diagnose, predict and monitor various eye conditions on fundus photographs and optical coherence tomography,3 4 including diabetic retinopathy (DR),5 age-related macular degeneration,6 glaucoma,7 retinopathy of prematurity (ROP).8   To date, many countries have reported well-established telemedicine programme to screen for DR and ROP,9–12 but limited for cataracts. Cataract is the leading cause of reversible blindness, affecting approximately 12.6 million (3.4–28.7 million) worldwide.13 14 The prevalence of cataract-related visual impairment also varies between high-income and low-income countries, with the latter having poorer access to tertiary care.13 In this issue, Wu et al 15 reported an AI-integrated telemedicine platform to screen and refer patients with cataract. This article consists of two parts: (1) the first part focusing on the AI system in detection of three tasks (capture mode, cataract diagnosis and referable cataract) and (2) the second part describing how these AI algorithms could be integrated in the telemedicine platform for real-world operational use. In this study, the referable cases were defined as: (1) grade 3 and grade 4 nuclear sclerotic …","",""
16,"K. Denecke, E. Gabarron, R. Grainger, S. Konstantinidis, A. Lau, O. Rivera-Romero, T. Miron-Shatz, M. Merolli","Artificial Intelligence for Participatory Health: Applications, Impact, and Future Implications",2019,"","","","",161,"2022-07-13 09:36:00","","10.1055/s-0039-1677902","","",,,,,16,5.33,2,8,3,"Summary Objective : Artificial intelligence (AI) provides people and professionals working in the field of participatory health informatics an opportunity to derive robust insights from a variety of online sources. The objective of this paper is to identify current state of the art and application areas of AI in the context of participatory health. Methods : A search was conducted across seven databases (PubMed, Embase, CINAHL, PsychInfo, ACM Digital Library, IEEExplore, and SCOPUS), covering articles published since 2013. Additionally, clinical trials involving AI in participatory health contexts registered at clinicaltrials.gov were collected and analyzed. Results : Twenty-two articles and 12 trials were selected for review. The most common application of AI in participatory health was the secondary analysis of social media data: self-reported data including patient experiences with healthcare facilities, reports of adverse drug reactions, safety and efficacy concerns about over-the-counter medications, and other perspectives on medications. Other application areas included determining which online forum threads required moderator assistance, identifying users who were likely to drop out from a forum, extracting terms used in an online forum to learn its vocabulary, highlighting contextual information that is missing from online questions and answers, and paraphrasing technical medical terms for consumers. Conclusions : While AI for supporting participatory health is still in its infancy, there are a number of important research priorities that should be considered for the advancement of the field. Further research evaluating the impact of AI in participatory health informatics on the psychosocial wellbeing of individuals would help in facilitating the wider acceptance of AI into the healthcare ecosystem.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",162,"2022-07-13 09:36:00","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
19,"E. O. Kontis, T. Papadopoulos, M. Syed, E. Guillo‐Sansano, G. Burt, G. Papagiannis","Artificial-Intelligence Method for the Derivation of Generic Aggregated Dynamic Equivalent Models",2019,"","","","",163,"2022-07-13 09:36:00","","10.1109/TPWRS.2019.2894185","","",,,,,19,6.33,3,6,3,"Aggregated equivalent models for the dynamic analysis of active distribution networks (ADNs) can be efficiently developed using dynamic responses recorded through field measurements. However, equivalent model parameters are highly affected from the time-varying composition of power system loads and the stochastic behavior of distributed generators. Thus, equivalent models, developed through in situ measurements, are valid only for the operating conditions from which they have been derived. To overcome this issue, in this paper, a new method is proposed for the derivation of generic aggregated dynamic equivalent models, i.e., for equivalent models that can be used for the dynamic analysis of a wide range of network conditions. The method incorporates clustering and artificial neural network techniques to derive robust sets of parameters for a variable-order dynamic equivalent model. The effectiveness of the proposed method is evaluated using measurements recorded on a laboratory-scale ADN, while its performance is compared with a conventional technique. The corresponding results reveal the applicability of the proposed approach for the analysis and simulation of a wide range of distinct network conditions.","",""
27,"Óscar Álvarez-Machancoses, J. Fernández-Martínez","Using artificial intelligence methods to speed up drug discovery",2019,"","","","",164,"2022-07-13 09:36:00","","10.1080/17460441.2019.1621284","","",,,,,27,9.00,14,2,3,"ABSTRACT Introduction: Drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. Due to the high complexity of genomic data, AI techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. Phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. Phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). This imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. Areas covered: In this paper, the authors present AI methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. Expert opinion: AI is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. The use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","",""
12,"Andrea Pazienza, G. Mallardi, Corrado Fasciano, Felice Vitulano","Artificial Intelligence on Edge Computing: a Healthcare Scenario in Ambient Assisted Living",2019,"","","","",165,"2022-07-13 09:36:00","","","","",,,,,12,4.00,3,4,3,"The aging population brings many challenges surrounding the quality of life for older people and their carers, as well as impacts on the healthcare market. Several initiatives all over the world have focused on the problem of helping the aging population with Artificial Intelligence (AI) technology, aiming at promoting a healthier society, which constitutes a main social and economic challenge. In this paper, we focus on an Ambient Assisted Living scenario in which a Smart Home Environment is carried out to assist elders at home, performing trustworthy automated complex decisions by means of IoT sensors, smart healthcare devices, and edge nodes. The core idea is to exploit the proximity between computing and information-generation sources. Taking automated complex decisions with the help AI-based techniques directly on the Edge enables a faster, more private, and context-aware Edge Computing empowering, called Edge Intelligence.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",166,"2022-07-13 09:36:00","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",167,"2022-07-13 09:36:00","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",168,"2022-07-13 09:36:00","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",169,"2022-07-13 09:36:00","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
9,"Nawaf H. M. M. Shrifan, M. F. Akbar, N. Isa","Prospect of Using Artificial Intelligence for Microwave Nondestructive Testing Technique: A Review",2019,"","","","",170,"2022-07-13 09:36:00","","10.1109/ACCESS.2019.2934143","","",,,,,9,3.00,3,3,3,"The development in materials technology has produced stronger, lighter, stiffer, and more durable electrically insulating composites which are replacing metals in many applications. These composites require alternative inspection techniques because the conventional nondestructive testing (NDT) techniques such as thermography, eddy currents, ultrasonic, X-ray and magnetic particles have limitations of inspecting them. Microwave NDT technique employing open-ended rectangular waveguides (OERW) has emerged as a promising approach to detect the defects in both metal and composite materials. Despite its promising results over conventional NDT techniques, OERW microwave NDT technique has shown numerous limitations in terms of poor spatial resolution due to the stand-off distance variations, inspection area irregularities and quantitative estimation in imaging the size of defects. Microwave NDT employing OERW in conjunction with robust artificial intelligence approaches have tremendous potential and viability for evaluating composite structures for the purpose mentioned here. Artificial intelligence techniques with signal processing techniques are highly possible to enhance the efficiency and resolution of microwave NDT technique because the impact of artificial intelligence approaches is proven in various conventional NDT techniques. This paper provides a comprehensive review of NDT techniques as well as the prospect of using artificial intelligence approaches in microwave NDT technique with regards to other conventional NDT techniques.","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",171,"2022-07-13 09:36:00","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
8,"Hiroshi Kuwajima, F. Ishikawa","Adapting SQuaRE for Quality Assessment of Artificial Intelligence Systems",2019,"","","","",172,"2022-07-13 09:36:00","","10.1109/ISSREW.2019.00035","","",,,,,8,2.67,4,2,3,"More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional software systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and Ethics guidelines for trustworthy AI from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts.","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",173,"2022-07-13 09:36:00","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
8,"S. Kalam, Mohammad Rasheed Khan, Zeeshan Tariq, F. Siddique, A. Abdulraheem, Rizwan Ahmed Khan","A Novel Correlation to Predict Gas Flow Rates Utilizing Artificial Intelligence: An Industrial 4.0 Approach",2019,"","","","",174,"2022-07-13 09:36:00","","10.2118/201170-ms","","",,,,,8,2.67,1,6,3,"  Reservoir and production engineers rely heavily on well production rates to optimize well activities such as ensuring optimum reservoir monitoring. Individual gas well rates are not readily available, rather, they can be estimated thru multi-phase flow meter (MPFM) and well test analysis. These methods are associated with certain limitations such as high cost, high uncertainty, and technically elaborate calculations. Consequently, empirical and numerical calculations are employed with well test data to calculate daily rates. These practices lead to inaccurate gas rate estimations.  A model with an ability to provide accurate estimates of gas rates for a gas reservoir can serve as a handy tool for the subsurface engineers in addressing well and reservoir optimization strategies. This work presents artificial intelligence models to estimate gas rates in a gas field containing ten wells. The aim is to develop a correlation that is simple and easy to incorporate yet providing robust answers on a global scale. Multiple machine learning tools are employed. These include; Artificial Neural Network (ANN), Functional Network (FN), and Adaptive Neuro Fuzzy Inference System (ANFIS).  Production data from a dry gas field X was used for the model development. Data cleaning and data reduction steps were carried out to ensure the input parameters for the proposed model are physically relevant and accurate. Missing these steps would result in the development of an erroneous correlation, i.e., garbage -in garbage-out (GIGO). This led to finalization of certain basic well-head parameters which are available at any typical well and had direct impact on the output production rate. The target parameter for model training is the gas rate. A rigorous comparison between the investigated artificial intelligence models was conducted by calculating average absolute percentage error (AAPE) and coefficient of determination. The comparative analysis shows that the intelligent model is able to predict the gas rate in condensate wells with accuracy in excess of 90%. Examples of such large accuracy has not been reported previously.  ANN performs a step ahead as compared to the various intelligent algorithms used in this study. This paper sheds light on the potential of the Industrial Revolution 4.0 for the Pakistani Oil and Gas Sector. Data-driven artificial intelligent models are capable of validating the well test and multiphase flow meter results. In addition, it can prove to be a vital tool in an engineer's tool-kit to reduce uncertainties in gas rate measurements.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",175,"2022-07-13 09:36:00","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",176,"2022-07-13 09:36:00","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",177,"2022-07-13 09:36:00","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
6,"J. Senthil Kumar, G. Sivasankar, S. Selva Nidhyananthan","An Artificial Intelligence Approach for Enhancing Trust Between Social IoT Devices in a Network",2019,"","","","",178,"2022-07-13 09:36:00","","10.1007/978-3-030-24513-9_11","","",,,,,6,2.00,2,3,3,"","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",179,"2022-07-13 09:36:00","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
6,"Francisco Javier Abarca-Álvarez, F. S. Campos-Sánchez, Fernando Osuna-Pérez","Urban Shape and Built Density Metrics through the Analysis of European Urban Fabrics Using Artificial Intelligence",2019,"","","","",180,"2022-07-13 09:36:00","","10.3390/su11236622","","",,,,,6,2.00,2,3,3,"In recent decades, the concept of urban density has been considered key to the creation of sustainable urban fabrics. However, when it comes to measuring the built density, a difficulty has been observed in defining valid measurement indicators universally. With the intention of identifying the variables that allow the best characterization of the shape of urban fabrics and of obtaining the metrics of their density, a multi-variable analysis methodology from the field of artificial intelligence is proposed. The main objective of this paper was to evaluate the capacity and interest of such a methodology from standard indicators of the built density, measured at various urban scales, (i) to cluster differentiated urban profiles in a robust way by assessing the results statistically, and (ii) to obtain the metrics that characterize them with an identity. As a case study, this methodology was applied to the state of the art European urban fabrics (N = 117) by simultaneously integrating 13 regular parameters to qualify urban shape and density. It was verified that the profiles obtained were more robust than those based on a limited number of indicators, evidencing that the proposed methodology offers operational opportunities in urban management by allowing the comparison of a fabric with the identified profiles.","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",181,"2022-07-13 09:36:00","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
9,"Anurag Malik, Anil Kumar, Priyan Rai, Alban Kuriqi","Prediction of Multi-Scalar Standardized Precipitation Index by Using Artificial Intelligence and Regression Models",2021,"","","","",182,"2022-07-13 09:36:00","","10.3390/CLI9020028","","",,,,,9,9.00,2,4,1,"Accurate monitoring and forecasting of drought are crucial. They play a vital role in the optimal functioning of irrigation systems, risk management, drought readiness, and alleviation. In this work, Artificial Intelligence (AI) models, comprising Multi-layer Perceptron Neural Network (MLPNN) and Co-Active Neuro-Fuzzy Inference System (CANFIS), and regression, model including Multiple Linear Regression (MLR), were investigated for multi-scalar Standardized Precipitation Index (SPI) prediction in the Garhwal region of Uttarakhand State, India. The SPI was computed on six different scales, i.e., 1-, 3-, 6-, 9-, 12-, and 24-month, by deploying monthly rainfall information of available years. The significant lags as inputs for the MLPNN, CANFIS, and MLR models were obtained by utilizing Partial Autocorrelation Function (PACF) with a significant level equal to 5% for SPI-1, SPI-3, SPI-6, SPI-9, SPI-12, and SPI-24. The predicted multi-scalar SPI values utilizing the MLPNN, CANFIS, and MLR models were compared with calculated SPI of multi-time scales through different performance evaluation indicators and visual interpretation. The appraisals of results indicated that CANFIS performance was more reliable for drought prediction at Dehradun (3-, 6-, 9-, and 12-month scales), Chamoli and Tehri Garhwal (1-, 3-, 6-, 9-, and 12-month scales), Haridwar and Pauri Garhwal (1-, 3-, 6-, and 9-month scales), Rudraprayag (1-, 3-, and 6-month scales), and Uttarkashi (3-month scale) stations. The MLPNN model was best at Dehradun (1- and 24- month scales), Tehri Garhwal and Chamoli (24-month scale), Haridwar (12- and 24-month scales), Pauri Garhwal (12-month scale), Rudraprayag (9-, 12-, and 24-month), and Uttarkashi (1- and 6-month scales) stations, while the MLR model was found to be optimal at Pauri Garhwal (24-month scale) and Uttarkashi (9-, 12-, and 24-month scales) stations. Furthermore, the modeling approach can foster a straightforward and trustworthy expert intelligent mechanism for projecting multi-scalar SPI and decision making for remedial arrangements to tackle meteorological drought at the stations under study.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",183,"2022-07-13 09:36:00","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",184,"2022-07-13 09:36:00","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",185,"2022-07-13 09:36:00","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",186,"2022-07-13 09:36:00","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",187,"2022-07-13 09:36:00","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",188,"2022-07-13 09:36:00","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",189,"2022-07-13 09:36:00","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",190,"2022-07-13 09:36:00","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",191,"2022-07-13 09:36:00","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",192,"2022-07-13 09:36:00","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",193,"2022-07-13 09:36:00","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",194,"2022-07-13 09:36:00","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",195,"2022-07-13 09:36:00","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",196,"2022-07-13 09:36:00","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
3,"Amy Papadopoulos, J. Salinas, Cindy Crump","Computational modeling approaches to characterize risk and achieve safe, effective, and trusted designs in the development of artificial intelligence and autonomous closed-loop medical systems",2021,"","","","",197,"2022-07-13 09:36:00","","10.1117/12.2586101","","",,,,,3,3.00,1,3,1,"While software using artificial intelligence and machine learning (AI/ML) is pervasive in many areas of society today, the use of these technologies to diagnose and treat medical conditions is limited due to a number of challenges associated with the trustworthiness of the results. This may include the inability to fully explain how an algorithm works inherent to the black-box nature of the system. Additionally, AI/ML may create a potential for bias and artifacts that cannot be validated due to the same limitations. In a medical application, the lack of transparency in how the system operates may lead to a loss of trust by users. Bayesian approaches that use computational modeling to quantify the level of uncertainty in a given result may provide a path towards improved confidence and use. In this paper, evidence from studies in a range of medical applications is presented and discussed, showing how Bayesian approaches can help to foster trust. A retrospective study using a publicly available dataset explored the feasibility of creating predictive models for early intervention in a Type 1 diabetes population. Creating the perfect model was not the goal of the exercise, rather the study aimed to demonstrate how Bayesian methods could be used to identify areas of uncertainty during model development. Feature selection was based on analytical assessment of various patterns found in the data. Models were trained, validated, and tested, generating uncertainty estimates. A two-feature Gaussian Naïve Bayes (GNB) model, using the previous five minutes and ten minutes of blood glucose values, showed similar results for predictive accuracy as a threefeature model that included average change over the preceding 30 minutes. The two-feature model was selected because it allowed for a more easily understood visualization of uncertainty. The 2-feature GNB achieved an AUC = .94. The model showed good sensitivity for exceeding the < 180 mg/dl limit, obtaining threshold prediction = 89.8% and normal range prediction = 90.8%. The sensitivity was lower for the < 70 mg/dl limit, attaining a sensitivity = 77.5%. Posterior probabilities showed differing levels of uncertainty in the prediction of high and low out-of-range conditions. The model demonstrated the feasibility of providing robust parameter estimates. Bayesian machine learning approaches to model uncertainty may improve the transparency, explainability, and applicability of AI/ML in medical treatment, realizing the promise to improve patient safety and outcomes.","",""
3,"Jessica Van Brummelen, Viktoriya Tabunshchyk, Tommy Heng","“Alexa, Can I Program You?”: Student Perceptions of Conversational Artificial Intelligence Before and After Programming Alexa",2021,"","","","",198,"2022-07-13 09:36:00","","10.1145/3459990.3460730","","",,,,,3,3.00,1,3,1,"Growing up in an artificial intelligence-filled world, with Siri and Amazon Alexa often within arm’s—or speech’s—reach, could have significant impact on children. Conversational agents could influence how students anthropomorphize computer systems or develop a theory of mind. Previous research has explored how conversational agents are used and perceived by children within and outside of learning contexts. This study investigates how middle and high school students’ perceptions of Alexa change through programming their own conversational agents in week-long AI education workshops. Specifically, we investigate the workshops’ influence on student perceptions of Alexa’s intelligence, friendliness, aliveness, safeness, trustworthiness, human-likeness, and feelings of closeness. We found that students felt Alexa was more intelligent and felt closer to Alexa after the workshops. We also found strong correlations between students’ perceptions of Alexa’s friendliness and trustworthiness, and safeness and trustworthiness. We recommend designers carefully consider personification, transparency, playfulness and utility when designing conversational agents for learning contexts.","",""
3,"I. Godinho, Cláudio R. Flores, Nuno Castro Marques","CONSULTATION ON THE WHITE PAPER ON ARTIFICIAL INTELLIGENCE - A EUROPEAN APPROACH",2021,"","","","",199,"2022-07-13 09:36:00","","10.46294/ULPLR-RDULP.V14I1.7475","","",,,,,3,3.00,1,3,1,"SUMMARY     From 19 February to 14 June 2020, the European Commission held a Public Consultation on several policy and regulatory proposals that are currently being considered in the area of Artificial Intelligence (AI).  This consultation was centered on two main documents presented by the Commission: the White Paper on Artificial Intelligence[1] and the “Report on the safety and liability implications of Artificial Intelligence, the Internet of Things and robotics”[2].  The consultation also included an online survey[3], where the central themes of those two documents were covered in a summarized way.  In November 2020, the results of the consultation were presented, as well as the texts accepted for publication[4].  In order to participate in this pre-legislative process, a working group was created within the Faculty of Law and Political Science of the Lusófona University of Porto, which presented a contribution that was accepted and published by the European Commission[5].  The White Paper is centred in one powerful objective which is “to enable a trustworthy and secure development of AI in Europe, in full respect of the values and rights of EU citizens”, and for that presents two central ideas considered essential to attain it that are to create an ecosystem of excellence along the entire value chain and an ecosystem of trust that ensure compliance with EU rules, including rules protecting fundamental rights and consumers’ rights.   The text that follows is divided in two main parts: Part I is focused on presenting an overview on the three main topics pointed out at the consultation: Excellence, Trust and Liability; Part II corresponds to text of the contribution submitted in the Public Consultation held by the European Commission.     Keywords: Artificial Intelligence; Liability; Cybercrime; Ethics; Competition","",""
2,"D. Cyman, E. Gromova, E. Juchnevicius","Regulation of Artificial Intelligence in BRICS and the European Union",2021,"","","","",200,"2022-07-13 09:36:00","","10.21684/2412-2343-2021-8-1-86-115","","",,,,,2,2.00,1,3,1,"Global digitization and the emergence of Artificial Intelligence-based technologies pose challenges for all countries. The BRICS and European Union countries are no exception. BRICS as well as the European Union seek to strengthen their positions as leading actors on the world stage. At the present time, an essential means of doing so is for BRICS and the EU to implement smart policy and create suitable conditions for the development of digital technologies, including AI. For this reason, one of the most important tasks for BRICS and the EU is to develop an adequate approach to the regulation of AI-based technologies. This research paper is an analysis of the current approaches to the regulation of AI at the BRICS group level, in each of the BRICS countries, and in the European Union. The analysis is based on the application of comparative and formal juridical analysis of the legislation of the selected countries on AI and other digital technologies. The results of the analysis lead the authors to conclude that it is necessary to design ageneral approach to the regulation of these technologies for the BRICS countries similar to the approach chosen in the EU (the trustworthy approach) and to upgrade this legislation to achieve positive effects from digital transformation. The authors offer several suggestions for optimization of the provisions of the legislation, including designing a model legal act in the sphere of AI.","",""
