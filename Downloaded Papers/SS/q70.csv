Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
138,"A. S. Rakin, Zhezhi He, Deliang Fan","Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack",2018,"","","","",1,"2022-07-13 09:29:07","","10.1109/CVPR.2019.00068","","",,,,,138,34.50,46,3,4,"Recent developments in the field of Deep Learning have exposed the underlying vulnerability of Deep Neural Network (DNN) against adversarial examples. In image classification, an adversarial example is a carefully modified image that is visually imperceptible to the original image but can cause DNN model to misclassify it. Training the network with Gaussian noise is an effective technique to perform model regularization, thus improving model robustness against input variation. Inspired by this classical method, we explore to utilize the regularization characteristic of noise injection to improve DNN's robustness against adversarial attack. In this work, we propose Parametric-Noise-Injection (PNI) which involves trainable Gaussian noise injection at each layer on either activation or weights through solving the Min-Max optimization problem, embedded with adversarial training. These parameters are trained explicitly to achieve improved robustness. The extensive results show that our proposed PNI technique effectively improves the robustness against a variety of powerful white-box and black-box attacks such as PGD, C&W, FGSM, transferable attack, and ZOO attack. Last but not the least, PNI method improves both clean- and perturbed-data accuracy, in comparison to the state-of-the-art defense methods, which outperforms current unbroken PGD defense by 1.1% and 6.8% on clean- and perturbed- test data respectively, using ResNet-20 architecture.","",""
36,"Shisheng Hu, Yiyang Pei, Paul Pu Liang, Ying-Chang Liang","Deep Neural Network for Robust Modulation Classification Under Uncertain Noise Conditions",2020,"","","","",2,"2022-07-13 09:29:07","","10.1109/TVT.2019.2951594","","",,,,,36,18.00,9,4,2,"Recently, classifying the modulation schemes of signals using deep neural network has received much attention. In this paper, we introduce a general model of deep neural network (DNN)-based modulation classifiers for single-input single-output (SISO) systems. Its feasibility is analyzed using maximum a posteriori probability (MAP) criterion and its robustness to uncertain noise conditions is compared to that of the conventional maximum likelihood (ML)-based classifiers. To reduce the design and training cost of DNN classifiers, a simple but effective pre-processing method is introduced and adopted. Furthermore, featuring multiple recurrent neural network (RNN) layers, the DNN modulation classifier is realized. Simulation results show that the proposed RNN-based classifier is robust to the uncertain noise conditions, and the performance of it approaches to that of the ideal ML classifier with perfect channel and noise information. Moreover, with a much lower complexity, it outperforms the existing ML-based classifiers, specifically, expectation maximization (EM) and expectation conditional maximization (ECM) classifiers which iteratively estimate channel and noise parameters. In addition, the proposed classifier is shown to be invariant to the signal distortion such as frequency offset. Furthermore, the adopted pre-processing method is shown to accelerate the training process of our proposed classifier, thus reducing the training cost. Lastly, the computational complexity of our proposed classifier is analyzed and compared to other traditional ones, which further demonstrates its overall advantage.","",""
16,"Xuanqing Liu, Tesi Xiao, Uc Davis, Qin Cao","How Does Noise Help Robustness? Explanation and Exploration under the Neural SDE Framework",2020,"","","","",3,"2022-07-13 09:29:07","","10.1109/cvpr42600.2020.00036","","",,,,,16,8.00,4,4,2,"Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g., dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE), which naturally incorporates various commonly used regularization mechanisms based on random noise injection. For regularization purposes, our framework includes multiple types of noise patterns, such as dropout, additive, and multiplicative noise, which are common in plain neural networks. We provide some theoretical analyses explaining the improved robustness of our models against input perturbations. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.","",""
21,"Shibo Zhou, Li Xiaohua, Ying Chen, S. T. Chandrasekaran, A. Sanyal","Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance",2019,"","","","",4,"2022-07-13 09:29:07","","","","",,,,,21,7.00,4,5,3,"Spiking neural network (SNN) is interesting both theoretically and practically because of its strong bio-inspiration nature and potentially outstanding energy efficiency. Unfortunately, its development has fallen far behind the conventional deep neural network (DNN), mainly because of difficult training and lack of widely accepted hardware experiment platforms. In this paper, we show that a deep temporal-coded SNN can be trained easily and directly over the benchmark datasets CIFAR10 and ImageNet, with testing accuracy within 1% of the DNN of equivalent size and architecture. Training becomes similar to DNN thanks to the closed-form solution to the spiking waveform dynamics. Considering that SNNs should be implemented in practical neuromorphic hardwares, we train the deep SNN with weights quantized to 8, 4, 2 bits and with weights perturbed by random noise to demonstrate its robustness in practical applications. In addition, we develop a phase-domain signal processing circuit schematic to implement our spiking neuron with 90% gain of energy efficiency over existing work. This paper demonstrates that the temporal-coded deep SNN is feasible for applications with high performance and high energy efficient.","",""
18,"Mitchell Wortsman, Maxwell Horton, Carlos Guestrin, Ali Farhadi, Mohammad Rastegari","Learning Neural Network Subspaces",2021,"","","","",5,"2022-07-13 09:29:07","","","","",,,,,18,18.00,4,5,1,"Recent observations have advanced our understanding of the neural network optimization landscape, revealing the existence of (1) paths of high accuracy containing diverse solutions and (2) wider minima offering improved performance. Previous methods observing diverse paths require multiple training runs. In contrast we aim to leverage both property (1) and (2) with a single method and in a single training run. With a similar computational cost as training one model, we learn lines, curves, and simplexes of high-accuracy neural networks. These neural network subspaces contain diverse solutions that can be ensembled, approaching the ensemble performance of independently trained networks without the training cost. Moreover, using the subspace midpoint boosts accuracy, calibration, and robustness to label noise, outperforming Stochastic Weight Averaging.","",""
19,"Suwon Shon, Tae-Hyun Oh, James R. Glass","Noise-tolerant Audio-visual Online Person Verification Using an Attention-based Neural Network Fusion",2018,"","","","",6,"2022-07-13 09:29:07","","10.1109/ICASSP.2019.8683477","","",,,,,19,4.75,6,3,4,"In this paper, we present a multi-modal online person verification system using both speech and visual signals. Inspired by neuroscientific findings on the association of voice and face, we propose an attention-based end-to-end neural network that learns multi-sensory association for the task of person verification. The attention mechanism in our proposed network learns to conditionally select a salient modality between speech and facial representations that provides a balance between complementary inputs. By virtue of this capability, the network is robust to missing or corrupted data from either modality. In the VoxCeleb2 dataset, we show that our method performs favorably against competing multi-modal methods. Even for extreme cases of large corruption or missing data on either modality, our method demonstrates robustness over other unimodal methods.","",""
7,"Ruibin Feng, C. Leung, J. Sum","Robustness Analysis on Dual Neural Network-based $k$ WTA With Input Noise",2018,"","","","",7,"2022-07-13 09:29:07","","10.1109/TNNLS.2016.2645602","","",,,,,7,1.75,2,3,4,"This paper studies the effects of uniform input noise and Gaussian input noise on the dual neural network-based <inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula>WTA (DNN-<inline-formula> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula>WTA) model. We show that the state of the network (under either uniform input noise or Gaussian input noise) converges to one of the equilibrium points. We then derive a formula to check if the network produce correct outputs or not. Furthermore, for the uniformly distributed inputs, two lower bounds (one for each type of input noise) on the probability that the network produces the correct outputs are presented. Besides, when the minimum separation amongst inputs is given, we derive the condition for the network producing the correct outputs. Finally, experimental results are presented to verify our theoretical results. Since random drift in the comparators can be considered as input noise, our results can be applied to the random drift situation.","",""
24,"Youngchul Kwak, Woo‐Jin Song, Seong-Eun Kim","Speckle-Noise-Invariant Convolutional Neural Network for SAR Target Recognition",2019,"","","","",8,"2022-07-13 09:29:07","","10.1109/LGRS.2018.2877599","","",,,,,24,8.00,8,3,3,"Speckle noise is inherent to synthetic aperture radar (SAR) images and degrades the target recognition performance. Deep learning based on convolutional neural networks (CNNs) has been widely applied for SAR target recognition, but the extracted features are still sensitive to speckle noise. In addition, speckle noise has been seldom considered in such CNN-based approaches. In this letter, we propose a speckle-noise-invariant CNN that employs regularization for minimizing feature variations caused by this noise. Before CNN training, we performed SAR image despeckling using the improved Lee sigma filter for feature extraction. Then, we generated SAR images for CNN training by adding speckle noise to the despeckled images. The proposed regularization improves both the feature robustness to speckle noise and SAR target recognition. Experiments on the moving and stationary target acquisition and recognition database demonstrate that the proposed CNN notably improves the classification accuracy compared with the conventional methods.","",""
27,"Sheng Zhang, W. Zheng","Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment",2018,"","","","",9,"2022-07-13 09:29:07","","10.1109/TNNLS.2017.2761259","","",,,,,27,6.75,14,2,4,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.","",""
69,"Hang Su, Wen Qi, Chenguang Yang, J. Sandoval, G. Ferrigno, E. Momi","Deep Neural Network Approach in Robot Tool Dynamics Identification for Bilateral Teleoperation",2020,"","","","",10,"2022-07-13 09:29:07","","10.1109/LRA.2020.2974445","","",,,,,69,34.50,12,6,2,"For bilateral teleoperation, the haptic feedback demands the availability of accurate force information transmitted from the remote site. Nevertheless, due to the limitation of the size, the force sensor is usually attached outside of the patient's abdominal cavity for the surgical operation. Hence, it measures not only the interaction forces on the surgical tip but also the surgical tool dynamics. In this letter, a model-free based deep convolutional neural network (DCNN) structure is proposed for the tool dynamics identification, which features fast computation and noise robustness. After the tool dynamics identification using DCNN, the calibration is performed, and the bilateral teleoperation is demonstrated to verify the proposed method. The comparison results prove that the proposed DCNN model promises prominent performance than other methods. Low computational time (0.0031 seconds) is ensured by the rectified linear unit (ReLU) function, and the DCNN approach provides superior accuracy for predicting the noised dynamics force and enable its feasibility for bilateral teleoperation.","",""
53,"Xin Liao, Kaide Li, Xinshan Zhu, K. J. R. Liu","Robust Detection of Image Operator Chain With Two-Stream Convolutional Neural Network",2020,"","","","",11,"2022-07-13 09:29:07","","10.1109/JSTSP.2020.3002391","","",,,,,53,26.50,13,4,2,"Many forensic techniques have recently been developed to determine whether an image has undergone a specific manipulation operation. When multiple consecutive operations are applied to images, forensic analysts not only need to identify the existence of each manipulation operation, but also to distinguish the order of the involved operations. However, image operator chain detection is still a challenging problem. In this paper, an order forensics framework for detecting image operator chain based on convolutional neural network (CNN) is presented. Two-stream CNN architecture is designed to capture both tampering artifact evidence and local noise residual evidence. Specifically, the new CNN-based method is proposed for forensically detecting a chain made of two image operators, which could automatically learn manipulation detection features directly from image data. Further, we empirically investigate the robustness of our proposed method in two practical scenarios: forensic investigators have no access to the operating parameters, and manipulations are applied to a JPEG compressed image. Experimental results show that the proposed framework not only obtains significant detection performance but also can distinguish the order in some cases that previous works were unable to identify.","",""
26,"Somshubra Majumdar, Boris Ginsburg","MatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition",2020,"","","","",12,"2022-07-13 09:29:07","","10.21437/Interspeech.2020-1058","","",,,,,26,13.00,13,2,2,"We present an MatchboxNet - an end-to-end neural network for speech command recognition. MatchboxNet is a deep residual network composed from blocks of 1D time-channel separable convolution, batch-normalization, ReLU and dropout layers. MatchboxNet reaches state-of-the-art accuracy on the Google Speech Commands dataset while having significantly fewer parameters than similar models. The small footprint of MatchboxNet makes it an attractive candidate for devices with limited computational resources. The model is highly scalable, so model accuracy can be improved with modest additional memory and compute. Finally, we show how intensive data augmentation using an auxiliary noise dataset improves robustness in the presence of background noise.","",""
27,"Yier Lin, J. Le Kernec, Shufan Yang, F. Fioranelli, O. Romain, Zhiqin Zhao","Human Activity Classification With Radar: Optimization and Noise Robustness With Iterative Convolutional Neural Networks Followed With Random Forests",2018,"","","","",13,"2022-07-13 09:29:07","","10.1109/JSEN.2018.2872849","","",,,,,27,6.75,5,6,4,"The accurate classification of activity patterns based on radar signatures is still an open problem and is a key to detect anomalous behavior for security and health applications. This paper presents a novel iterative convolutional neural network strategy with an autocorrelation pre-processing instead of the traditional micro-Doppler image pre-processing to classify activities or subjects accurately. The proposed strategy uses an iterative deep learning framework for the automatic definition and extraction of features. This is followed by a traditional supervised learning classifier to label different activities. Using three human subjects and their real motion captured data, 12 000 radar signatures were simulated by varying additive white Gaussian noise. In addition, 6720 experimental radar signatures were captured with a frequency-modulated continuous radar at 5.8 GHz with 400 MHz of instantaneous bandwidth from seven activities using one subject and 4800 signatures from five subjects while walking. The simulated and experimental data were both used to validate our proposed method, with signal–noise ratio varying from −20 to 20 dB and with 88.74% average accuracy at −10 dB and 100% peak accuracy at 15 dB. The proposed iterative convolutional neural networks followed with random forests not only outperform the feature-based methods using micro-Doppler images but also outperform the classification methods using other types of supervised classifiers after our proposed iterative convolutional neural network.","",""
67,"A. Narayanan, Deliang Wang","Improving Robustness of Deep Neural Network Acoustic Models via Speech Separation and Joint Adaptive Training",2015,"","","","",14,"2022-07-13 09:29:07","","10.1109/TASLP.2014.2372314","","",,,,,67,9.57,34,2,7,"Although deep neural network (DNN) acoustic models are known to be inherently noise robust, especially with matched training and testing data, the use of speech separation as a frontend and for deriving alternative feature representations has been shown to improve performance in challenging environments. We first present a supervised speech separation system that significantly improves automatic speech recognition (ASR) performance in realistic noise conditions. The system performs separation via ratio time-frequency masking; the ideal ratio mask (IRM) is estimated using DNNs. We then propose a framework that unifies separation and acoustic modeling via joint adaptive training. Since the modules for acoustic modeling and speech separation are implemented using DNNs, unification is done by introducing additional hidden layers with fixed weights and appropriate network architecture. On the CHiME-2 medium-large vocabulary ASR task, and with log mel spectral features as input to the acoustic model, an independently trained ratio masking frontend improves word error rates by 10.9% (relative) compared to the noisy baseline. In comparison, the jointly trained system improves performance by 14.4%. We also experiment with alternative feature representations to augment the standard log mel features, like the noise and speech estimates obtained from the separation module, and the standard feature set used for IRM estimation. Our best system obtains a word error rate of 15.4% (absolute), an improvement of 4.6 percentage points over the next best result on this corpus.","",""
551,"Taku Kudo","Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates",2018,"","","","",15,"2022-07-13 09:29:07","","10.18653/v1/P18-1007","","",,,,,551,137.75,551,1,4,"Subword units are an effective way to alleviate the open vocabulary problems in neural machine translation (NMT). While sentences are usually converted into unique subword sequences, subword segmentation is potentially ambiguous and multiple segmentations are possible even with the same vocabulary. The question addressed in this paper is whether it is possible to harness the segmentation ambiguity as a noise to improve the robustness of NMT. We present a simple regularization method, subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training. In addition, for better subword sampling, we propose a new subword segmentation algorithm based on a unigram language model. We experiment with multiple corpora and report consistent improvements especially on low resource and out-of-domain settings.","",""
20,"Dongsheng Guo, Shuai Li, P. Stanimirović","Analysis and Application of Modified ZNN Design With Robustness Against Harmonic Noise",2020,"","","","",16,"2022-07-13 09:29:07","","10.1109/TII.2019.2944517","","",,,,,20,10.00,7,3,2,"The Zhang neural network (ZNN) has recently realized remarkable success in solving time-varying problems. Harmonic noise widely exists in industrial applications and can severely affect the solution computed by ZNN models. This article attempts to solve the aforementioned limitations by providing the first ZNN design with an inherent capability to prohibit harmonic noise. Moreover, it opens new opportunities to shift the research on ZNNs in ideal situations to that with theoretical consideration on nonideal working environments. We establish a modified ZNN design formula in a noisy environment by incorporating the dynamics of harmonic signals. Theoretical analysis shows the convergence of the proposed ZNN design. An application case study for the new ZNN model verifies its effectiveness for time-varying matrix inversion in the presence of harmonic noise. The simulation further substantiates the effectiveness, superiority, and application prospects of the proposed ZNN design.","",""
11,"Chuteng Zhou, Prad Kadambi, Matthew Mattina, P. Whatmough","Noisy Machines: Understanding Noisy Neural Networks and Enhancing Robustness to Analog Hardware Errors Using Distillation",2020,"","","","",17,"2022-07-13 09:29:07","","","","",,,,,11,5.50,3,4,2,"The success of deep learning has brought forth a wave of interest in computer hardware design to better meet the high demands of neural network inference. In particular, analog computing hardware has been heavily motivated specifically for accelerating neural networks, based on either electronic, optical or photonic devices, which may well achieve lower power consumption than conventional digital electronics. However, these proposed analog accelerators suffer from the intrinsic noise generated by their physical components, which makes it challenging to achieve high accuracy on deep neural networks. Hence, for successful deployment on analog accelerators, it is essential to be able to train deep neural networks to be robust to random continuous noise in the network weights, which is a somewhat new challenge in machine learning. In this paper, we advance the understanding of noisy neural networks. We outline how a noisy neural network has reduced learning capacity as a result of loss of mutual information between its input and output. To combat this, we propose using knowledge distillation combined with noise injection during training to achieve more noise robust networks, which is demonstrated experimentally across different networks and datasets, including ImageNet. Our method achieves models with as much as two times greater noise tolerance compared with the previous best attempts, which is a significant step towards making analog hardware practical for deep learning.","",""
92,"Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh","Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network",2018,"","","","",18,"2022-07-13 09:29:07","","","","",,,,,92,23.00,23,4,4,"We present a new algorithm to train a robust neural network against adversarial attacks. Our algorithm is motivated by the following two ideas. First, although recent work has demonstrated that fusing randomness can improve the robustness of neural networks (Liu 2017), we noticed that adding noise blindly to all the layers is not the optimal way to incorporate randomness. Instead, we model randomness under the framework of Bayesian Neural Network (BNN) to formally learn the posterior distribution of models in a scalable way. Second, we formulate the mini-max problem in BNN to learn the best model distribution under adversarial attacks, leading to an adversarial-trained Bayesian neural net. Experiment results demonstrate that the proposed algorithm achieves state-of-the-art performance under strong attacks. On CIFAR-10 with VGG network, our model leads to 14\% accuracy improvement compared with adversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD attack with $0.035$ distortion, and the gap becomes even larger on a subset of ImageNet.","",""
78,"Shengyuan Li, Xuefeng Zhao","Image-Based Concrete Crack Detection Using Convolutional Neural Network and Exhaustive Search Technique",2019,"","","","",19,"2022-07-13 09:29:07","","10.1155/2019/6520620","","",,,,,78,26.00,39,2,3,"Crack detection is important for the inspection and evaluation during the maintenance of concrete structures. However, conventional image-based methods need extract crack features using complex image preprocessing techniques, so it can lead to challenges when concrete surface contains various types of noise due to extensively varying real-world situations such as thin cracks, rough surface, shadows, etc. To overcome these challenges, this paper proposes an image-based crack detection method using a deep convolutional neural network (CNN). A CNN is designed through modifying AlexNet and then trained and validated using a built database with 60000 images. Through comparing validation accuracy under different base learning rates, 0.01 was chosen as the best base learning rate with the highest validation accuracy of 99.06%, and its training result is used in the following testing process. The robustness and adaptability of the trained CNN are tested on 205 images with 3120 × 4160 pixel resolutions which were not used for training and validation. The trained CNN is integrated into a smartphone application to mobile more public to detect cracks in practice. The results confirm that the proposed method can indeed detect cracks in images from real concrete surfaces.","",""
61,"Ping Ma, Hongli Zhang, Wenhui Fan, Cong Wang, G. Wen, Xining Zhang","A novel bearing fault diagnosis method based on 2D image representation and transfer learning-convolutional neural network",2019,"","","","",20,"2022-07-13 09:29:07","","10.1088/1361-6501/AB0793","","",,,,,61,20.33,10,6,3,"Traditional methods used for intelligent condition monitoring and diagnosis significantly depend on manual feature extraction and selection. To address this issue, a transfer learning-convolutional neural network (TLCNN) based on AlexNet is proposed for bearing fault diagnosis. Firstly, a 2D image representation method converts vibration signals to 2D time-frequency images. Secondly, the proposed TLCNN model extracts the features of the 2D time-frequency images and achieves the classification conditions of the bearing, which is faster to train and more accurate. Thirdly, t-distributed stochastic neighbor embedding (t-SNE) is applied to visualize the feature learning process to demonstrate the feature learning ability of the proposed model. The experimental results verify that the proposed fault diagnosis model has higher accuracy and has much better robustness against noise than other deep learning and traditional methods.","",""
30,"Yangming Li, Shuai Li, B. Hannaford","A Model-Based Recurrent Neural Network With Randomness for Efficient Control With Applications",2019,"","","","",21,"2022-07-13 09:29:07","","10.1109/TII.2018.2869588","","",,,,,30,10.00,10,3,3,"Recently, recurrent neural network (RNN) control schemes for redundant manipulators have been extensively studied. These control schemes demonstrate superior computational efficiency, control precision, and control robustness. However, they lack planning completeness. This paper explains why RNN control schemes suffer from the problem. Based on the analysis, this work presents a new random RNN control scheme, which 1) introduces randomness into RNN to address the planning completeness problem, 2) improves control precision with a new optimization target, and 3) improves planning efficiency through learning from exploration. Theoretical analyses are used to prove the global stability, the planning completeness, and the computational complexity of the proposed method. Software simulation is provided to demonstrate the improved robustness against noise, the planning completeness and the improved planning efficiency of the proposed method over benchmark RNN control schemes. Real-world experiments are presented to demonstrate the application of the proposed method.","",""
26,"Zheng Qiumei, Tan Dan, Wang Fenghua","Improved Convolutional Neural Network Based on Fast Exponentially Linear Unit Activation Function",2019,"","","","",22,"2022-07-13 09:29:07","","10.1109/ACCESS.2019.2948112","","",,,,,26,8.67,9,3,3,"The activation functions play increasingly important roles in deep convolutional neural networks. The traditional activation functions have some problems such as gradient disappearance, neuron death and output offset, and so on. To solve these problems, we propose a new activation function in this paper, Fast Exponentially Linear Unit (FELU), aiming to speed up exponential linear calculations and reduce the time of network running. FELU has the advantages of Rectified Linear Unit (RELU) and Exponential Linear Unit (ELU), leading to have better classification accuracy and faster calculation speed. We test five traditional activation functions such as ReLU, ELU, SLU, MPELU, TReLU, and our new activation function on the cifar10, cifar100 and GTSRB data sets. Experiments show that the proposed activation function FELU not only improves the speed of the exponential calculation, reducing the time of convolutional neural network running, but also effectively enhances the noise robustness of network to improve the accuracy of classification.","",""
17,"Tao Zan, Hui Wang, Min Wang, Zhihao Liu, Xiangsheng Gao","Application of Multi-Dimension Input Convolutional Neural Network in Fault Diagnosis of Rolling Bearings",2019,"","","","",23,"2022-07-13 09:29:07","","10.3390/APP9132690","","",,,,,17,5.67,3,5,3,"Aiming at the problem of poor robustness of the intelligent diagnostic model, a fault diagnosis model of rolling bearing based on a multi-dimension input convolutional neural network (MDI-CNN) is proposed. Compared with the traditional convolution neural network, the proposed model has multiple input layers. Therefore, it can fuse the original signal and processed signal—making full use of advantages of the convolutional neural networks to learn the original signal characteristics automatically, and also improving recognition accuracy and anti-jamming ability. The feasibility and validity of the proposed MDI-CNN are verified, and its advantages are proved by comparison with the other related models. Moreover, the robustness of the model is tested by adding the noise to the test set. Finally, the stability of the model is verified by two experiments. The experimental results show that the proposed model improves the recognition rate, robustness and convergence performance of the traditional convolution model and has good generalization ability.","",""
22,"Ke Chen","Robustness analysis of Wang neural network for online linear equation solving",2012,"","","","",24,"2022-07-13 09:29:07","","10.1049/EL.2012.1940","","",,,,,22,2.20,22,1,10,"The Wang neural network, which could be implemented into circuits, can solve online linear equations effectively and efficiently under the ideal noise-free condition. With the consideration of noises on coefficients and large implementation error, robustness analysis of such a model is presented with the upper boundary of the steady-state solution error also estimated. Illustrative examples demonstrate theoretical results about the robustness properties of the Wang neural network for solving online linear equations.","",""
472,"Yonatan Belinkov, Yonatan Bisk","Synthetic and Natural Noise Both Break Neural Machine Translation",2017,"","","","",25,"2022-07-13 09:29:07","","","","",,,,,472,94.40,236,2,5,"Character-based neural machine translation (NMT) models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems. Unfortunately, they are also very brittle and easily falter when presented with noisy data. In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.","",""
65,"Burkni Palsson, J. Sigurdsson, J. Sveinsson, M. Ulfarsson","Hyperspectral Unmixing Using a Neural Network Autoencoder",2018,"","","","",26,"2022-07-13 09:29:07","","10.1109/ACCESS.2018.2818280","","",,,,,65,16.25,16,4,4,"In this paper, we present a deep learning based method for blind hyperspectral unmixing in the form of a neural network autoencoder. We show that the linear mixture model implicitly puts certain architectural constraints on the network, and it effectively performs blind hyperspectral unmixing. Several different architectural configurations of both shallow and deep encoders are evaluated. Also, deep encoders are tested using different activation functions. Furthermore, we investigate the performance of the method using three different objective functions. The proposed method is compared to other benchmark methods using real data and previously established ground truths of several common data sets. Experiments show that the proposed method compares favorably to other commonly used hyperspectral unmixing methods and exhibits robustness to noise. This is especially true when using spectral angle distance as the network’s objective function. Finally, results indicate that a deeper and a more sophisticated encoder does not necessarily give better results.","",""
66,"Prasun Roy, Subhankar Ghosh, Saumik Bhattacharya, U. Pal","Effects of Degradations on Deep Neural Network Architectures",2018,"","","","",27,"2022-07-13 09:29:07","","","","",,,,,66,16.50,17,4,4,"Recently, image classification methods based on capsules (groups of neurons) and a novel dynamic routing protocol are proposed. The methods show promising performances than the state-of-the-art CNN-based models in some of the existing datasets. However, the behavior of capsule-based models and CNN-based models are largely unknown in presence of noise. So it is important to study the performance of these models under various noises. In this paper, we demonstrate the effect of image degradations on deep neural network architectures for image classification task. We select six widely used CNN architectures to analyse their performances for image classification task on datasets of various distortions. Our work has three main contributions: 1) we observe the effects of degradations on different CNN models; 2) accordingly, we propose a network setup that can enhance the robustness of any CNN architecture for certain degradations, and 3) we propose a new capsule network that achieves high recognition accuracy. To the best of our knowledge, this is the first study on the performance of CapsuleNet (CapsNet) and other state-of-the-art CNN architectures under different types of image degradations. Also, our datasets and source code are available publicly to the researchers.","",""
65,"Yingxiang Sun, Jiajia Chen, C. Yuen, S. Rahardja","Indoor Sound Source Localization With Probabilistic Neural Network",2017,"","","","",28,"2022-07-13 09:29:07","","10.1109/TIE.2017.2786219","","",,,,,65,13.00,16,4,5,"It is known that adverse environments such as high reverberation and low signal-to-noise ratio (SNR) pose a great challenge to indoor sound source localization (SSL). To address this challenge, in this paper, we propose an SSL algorithm based on a probabilistic neural network, namely a generalized cross-correlation classification algorithm (GCA). Experimental results for adverse environments with high reverberation time  $T_{60}$ up to 600 ms and low SNR such as -10 dB show that the average azimuth angle error and elevation angle error by GCA are only 4.6° and 3.1°, respectively. Compared with three recently published algorithms, GCA has increased the success rate on direction of arrival estimation significantly with good robustness to environmental changes. These results show that the proposed GCA can localize accurately and robustly for diverse indoor applications where the site acoustic features can be studied prior to the localization stage.","",""
760,"Giorgio Patrini, A. Rozza, A. Menon, R. Nock, Lizhen Qu","Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach",2016,"","","","",29,"2022-07-13 09:29:07","","10.1109/CVPR.2017.240","","",,,,,760,126.67,152,5,6,"We present a theoretically grounded approach to train deep neural networks, including recurrent networks, subject to class-dependent label noise. We propose two procedures for loss correction that are agnostic to both application domain and network architecture. They simply amount to at most a matrix inversion and multiplication, provided that we know the probability of each class being corrupted into another. We further show how one can estimate these probabilities, adapting a recent technique for noise estimation to the multi-class setting, and thus providing an end-to-end framework. Extensive experiments on MNIST, IMDB, CIFAR-10, CIFAR-100 and a large scale dataset of clothing images employing a diversity of architectures &#x2014; stacking dense, convolutional, pooling, dropout, batch normalization, word embedding, LSTM and residual layers &#x2014; demonstrate the noise robustness of our proposals. Incidentally, we also prove that, when ReLU is the only non-linearity, the loss curvature is immune to class-dependent label noise.","",""
8,"Feng Jiang, Hua Yang, Yi Shen","On the robustness of global exponential stability for hybrid neural networks with noise and delay perturbations",2014,"","","","",30,"2022-07-13 09:29:07","","10.1007/s00521-013-1374-2","","",,,,,8,1.00,3,3,8,"","",""
33,"Ziguang Jia, L. Ren, Hongnan Li, Wei Sun","Pipeline Leak Localization Based on FBG Hoop Strain Sensors Combined with BP Neural Network",2018,"","","","",31,"2022-07-13 09:29:07","","10.3390/APP8020146","","",,,,,33,8.25,8,4,4,"Pipelines function as blood vessels serving to bring life-necessities, so their safe usage is one of the foremost concerns. In our previous work, a fiber Bragg grating (FBG) hoop strain sensor with enhanced sensitivity was developed to measure the pressure drop induced by pipeline leakage. Some hoop strain information during the leakage transient process can be extracted from the amount of FBG hoop strain sensors set along the pipeline. In this paper, an integrated approach of a back-propagation (BP) neural network and hoop strain measurement is first proposed to locate the leak points of the pipeline. Five hoop strain variations are employed as input neurons to achieve pattern recognition so as to predict the leakage point. The RMS error can be as low as 1.01% when choosing appropriate hidden layer neurons. Furthermore, the influence of noise on the network’s performance is investigated through superimposing Gaussian noise with a different level. The results demonstrate the feasibility and robustness of the neural network for pipeline leakage localization.","",""
27,"Khurram Ashfaq Qazi, T. Nawaz, Zahid Mehmood, M. Rashid, H. A. Habib","A hybrid technique for speech segregation and classification using a sophisticated deep neural network",2018,"","","","",32,"2022-07-13 09:29:07","","10.1371/journal.pone.0194151","","",,,,,27,6.75,5,5,4,"Recent research on speech segregation and music fingerprinting has led to improvements in speech segregation and music identification algorithms. Speech and music segregation generally involves the identification of music followed by speech segregation. However, music segregation becomes a challenging task in the presence of noise. This paper proposes a novel method of speech segregation for unlabelled stationary noisy audio signals using the deep belief network (DBN) model. The proposed method successfully segregates a music signal from noisy audio streams. A recurrent neural network (RNN)-based hidden layer segregation model is applied to remove stationary noise. Dictionary-based fisher algorithms are employed for speech classification. The proposed method is tested on three datasets (TIMIT, MIR-1K, and MusicBrainz), and the results indicate the robustness of proposed method for speech segregation. The qualitative and quantitative analysis carried out on three datasets demonstrate the efficiency of the proposed method compared to the state-of-the-art speech segregation and classification-based methods.","",""
65,"Xuanqing Liu, Tesi Xiao, Si Si, Qin Cao, Sanjiv Kumar, Cho-Jui Hsieh","Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise",2019,"","","","",33,"2022-07-13 09:29:07","","","","",,,,,65,21.67,11,6,3,"Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE) network, which naturally incorporates various commonly used regularization mechanisms based on random noise injection. Our framework can model various types of noise injection frequently used in discrete networks for regularization purpose, such as dropout and additive/multiplicative noise in each block. We provide theoretical analysis explaining the improved robustness of Neural SDE models against input perturbations/adversarial attacks. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.","",""
22,"Xu-Chen Yang, M. Yung, Xin Wang","Neural-network-designed pulse sequences for robust control of singlet-Triplet qubits",2017,"","","","",34,"2022-07-13 09:29:07","","10.1103/PhysRevA.97.042324","","",,,,,22,4.40,7,3,5,"Composite pulses are essential for universal manipulation of singlet-triplet spin qubits. In the absence of noise, they are required to perform arbitrary single-qubit operations due to the special control constraint of a singlet-triplet qubits; while in a noisy environment, more complicated sequences have been developed to dynamically correct the error. Tailoring these sequences typically requires numerically solving a set of nonlinear equations. Here we demonstrate that these pulse sequences can be generated by a well-trained, double-layer neural network. For sequences designed for the noise-free case, the trained neural network is capable of producing almost exactly the same pulses known in the literature. For more complicated noise-correcting sequences, the neural network produces pulses with slightly different line-shapes, but the robustness against noises remains comparable. These results indicate that the neural network can be a judicious and powerful alternative to existing techniques, in developing pulse sequences for universal fault-tolerant quantum computation.","",""
631,"S. Gu, Luca Rigazio","Towards Deep Neural Network Architectures Robust to Adversarial Examples",2014,"","","","",35,"2022-07-13 09:29:07","","","","",,,,,631,78.88,316,2,8,"Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. How- ever, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty.","",""
22,"M. Klachko, M. Mahmoodi, D. Strukov","Improving Noise Tolerance of Mixed-Signal Neural Networks",2019,"","","","",36,"2022-07-13 09:29:07","","10.1109/IJCNN.2019.8851966","","",,,,,22,7.33,7,3,3,"Mixed-signal hardware accelerators for deep learning achieve orders of magnitude better power efficiency than their digital counterparts. In the ultra-low power consumption regime, limited signal precision inherent to analog computation becomes a challenge. We perform a case study of a 6-layer convolutional neural network running on a mixed-signal accelerator and evaluate its sensitivity to hardware specific noise. We apply various methods to improve noise robustness of the network and demonstrate an effective way to optimize useful signal ranges through adaptive signal clipping. The resulting model is robust enough to achieve 80.2% classification accuracy on CIFAR-10 dataset with just 1.4 mW power budget, while 6 mW budget allows us to achieve 87.1% accuracy, which is within 1% of the software baseline. For comparison, the unoptimized version of the same model achieves only 67.7% accuracy at 1.4 mW and 78.6% at 6 mW.","",""
15,"C. Dias, L. M. Guerra, J. Ventura, Paulo Aguiar","Memristor-based Willshaw network: Capacity and robustness to noise in the presence of defects",2015,"","","","",37,"2022-07-13 09:29:07","","10.1063/1.4922148","","",,,,,15,2.14,4,4,7,"The recent realization of memristors, nanodevices remarkably similar to biological synapses, opened the possibility to fabricate highly scalable artificial neural networks. While the physical implementation of such networks is still emerging, it is useful to perform simulations to determine the impact of non-ideal devices or device faults in the performance of memory networks. Here, we numerically evaluate a memristor-based Willshaw associative memory network, studying its capacity and robustness to noise as a function of defects probability and device parameter variations. Two types of defective memristors are addressed (stuck-at-0 and stuck-at-1) and Gaussian distributions are imposed to their threshold voltages, ON and OFF resistances. We conclude that the type and number of defects strongly determine how the network should be operated. The reading current threshold also plays a key role in determining the network's capacity and robustness to noise. Furthermore, there is a maximum defect percentage abo...","",""
20,"Egor Lakomkin, M. Zamani, C. Weber, S. Magg, S. Wermter","On the Robustness of Speech Emotion Recognition for Human-Robot Interaction with Deep Neural Networks",2018,"","","","",38,"2022-07-13 09:29:07","","10.1109/IROS.2018.8593571","","",,,,,20,5.00,4,5,4,"Speech emotion recognition (SER) is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.","",""
31,"Y. Nakamura, O. Hasegawa","Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data",2017,"","","","",39,"2022-07-13 09:29:07","","10.1109/TNNLS.2015.2489225","","",,,,,31,6.20,16,2,5,"With the ongoing development and expansion of communication networks and sensors, massive amounts of data are continuously generated in real time from real environments. Beforehand, prediction of a distribution underlying such data is difficult; furthermore, the data include substantial amounts of noise. These factors make it difficult to estimate probability densities. To handle these issues and massive amounts of data, we propose a nonparametric density estimator that rapidly learns data online and has high robustness. Our approach is an extension of both kernel density estimation (KDE) and a self-organizing incremental neural network (SOINN); therefore, we call our approach KDESOINN. An SOINN provides a clustering method that learns about the given data as networks of prototype of data; more specifically, an SOINN can learn the distribution underlying the given data. Using this information, KDESOINN estimates the probability density function. The results of our experiments show that KDESOINN outperforms or achieves performance comparable to the current state-of-the-art approaches in terms of robustness, learning time, and accuracy.","",""
22,"Fei Tao, C. Busso","Bimodal Recurrent Neural Network for Audiovisual Voice Activity Detection",2017,"","","","",40,"2022-07-13 09:29:07","","10.21437/INTERSPEECH.2017-1573","","",,,,,22,4.40,11,2,5,"Voice activity detection (VAD) is an important preprocessing step in speech-based systems, especially for emerging handfree intelligent assistants. Conventional VAD systems relying on audio-only features are normally impaired by noise in the environment. An alternative approach to address this problem is audiovisual VAD (AV-VAD) systems. Modeling timing dependencies between acoustic and visual features is a challenge in AV-VAD. This study proposes a bimodal recurrent neural network (RNN) which combines audiovisual features in a principled, unified framework, capturing the timing dependency within modalities and across modalities. Each modality is modeled with separate bidirectional long short-term memory (BLSTM) networks. The output layers are used as input of another BLSTM network. The experimental evaluation considers a large audiovisual corpus with clean and noisy recordings to assess the robustness of the approach. The proposed approach outperforms audio-only VAD by 7.9% (absolute) under clean/ideal conditions (i.e., high definition (HD) camera, close-talk microphone). The proposed solution outperforms the audio-only VAD system by 18.5% (absolute) when the conditions are more challenging (i.e., camera and microphone from a tablet with noise in the environment). The proposed approach shows the best performance and robustness across a varieties of conditions, demonstrating its potential for real-world applications.","",""
154,"Soumitro Chakrabarty, E. Habets","Broadband doa estimation using convolutional neural networks trained with noise signals",2017,"","","","",41,"2022-07-13 09:29:07","","10.1109/WASPAA.2017.8170010","","",,,,,154,30.80,77,2,5,"A convolution neural network (CNN) based classification method for broadband DOA estimation is proposed, where the phase component of the short-time Fourier transform coefficients of the received microphone signals are directly fed into the CNN and the features required for DOA estimation are learned during training. Since only the phase component of the input is used, the CNN can be trained with synthesized noise signals, thereby making the preparation of the training data set easier compared to using speech signals. Through experimental evaluation, the ability of the proposed noise trained CNN framework to generalize to speech sources is demonstrated. In addition, the robustness of the system to noise, small perturbations in microphone positions, as well as its ability to adapt to different acoustic conditions is investigated using experiments with simulated and real data.","",""
42,"G. Basalyga, E. Salinas","When Response Variability Increases Neural Network Robustness to Synaptic Noise",2005,"","","","",42,"2022-07-13 09:29:07","","10.1162/neco.2006.18.6.1349","","",,,,,42,2.47,21,2,17,"Cortical sensory neurons are known to be highly variable, in the sense that responses evoked by identical stimuli often change dramatically from trial to trial. The origin of this variability is uncertain, but it is usually interpreted as detrimental noise that reduces the computational accuracy of neural circuits. Here we investigate the possibility that such response variability might in fact be beneficial, because it may partially compensate for a decrease in accuracy due to stochastic changes in the synaptic strengths of a network. We study the interplay between two kinds of noise, response (or neuronal) noise and synaptic noise, by analyzing their joint influence on the accuracy of neural networks trained to perform various tasks. We find an interesting, generic interaction: when fluctuations in the synaptic connections are proportional to their strengths (multiplicative noise), a certain amount of response noise in the input neurons can significantly improve network performance, compared to the same network without response noise. Performance is enhanced because response noise and multiplicative synaptic noise are in some ways equivalent. So if the algorithm used to find the optimal synaptic weights can take into account the variability of the model neurons, it can also take into account the variability of the synapses. Thus, the connection patterns generated with response noise are typically more resistant to synaptic degradation than those obtained without response noise. As a consequence of this interplay, if multiplicative synaptic noise is present, it is better to have response noise in the network than not to have it. These results are demonstrated analytically for the most basic network consisting of two input neurons and one output neuron performing a simple classification task, but computer simulations show that the phenomenon persists in a wide range of architectures, including recurrent (attractor) networks and sensorimotor networks that perform coordinate transformations. The results suggest that response variability could play an important dynamic role in networks that continuously learn.","",""
69,"Khan Suhail Ahmad, Anil S. Thosar, J. Nirmal, V. S. Pande","A unique approach in text independent speaker recognition using MFCC feature sets and probabilistic neural network",2015,"","","","",43,"2022-07-13 09:29:07","","10.1109/ICAPR.2015.7050669","","",,,,,69,9.86,17,4,7,"This paper motivates the use of combination of mel frequency cepstral coefficients (MFCC) and its delta derivatives (DMFCC and DDMFCC) calculated using mel spaced Gaussian filter banks for text independent speaker recognition. MFCC modeled on the human auditory system shows robustness against noise and session changes and hence has become synonymous with speaker recognition. Our main aim is to test the accuracy of our proposed feature set for different values of frame overlap and MFCC feature vector sizes to identify the system having highest accuracy. Principal component analysis (PCA) is applied before the training and testing stages for feature dimensionality reduction thereby increasing computing speed and puts low constraint on the memory required for processing. The use of probabilistic neural network (PNN) in the modeling domain provided the advantages of achieving lower operational times during the training stages. The experiments examined the percentage identification accuracy (PIA) of MFCC, combination of MFCC and DMFCC as well as combination of all three feature sets MFCC, DMFCC and DDMFCC. The proposed feature set attains an identification accuracy of 94% for frame overlap of 90% and MFCC feature size of 18 coefficients. It outperforms the identification rates of the other two feature sets. These speaker recognition experiments were tested using the Voxforge database.","",""
19,"Jegor Uglov, L. Jakaite, V. Schetinin, C. Maple","Comparing Robustness of Pairwise and Multiclass Neural-Network Systems for Face Recognition",2007,"","","","",44,"2022-07-13 09:29:07","","10.1155/2008/468693","","",,,,,19,1.27,5,4,15,"Noise, corruptions, and variations in face images can seriously hurt the performance of face-recognition systems. To make these systems robust to noise and corruptions in image data, multiclass neural networks capable of learning from noisy data have been suggested. However on large face datasets such systems cannot provide the robustness at a high level. In this paper, we explore a pairwise neural-network system as an alternative approach to improve the robustness of face recognition. In our experiments, the pairwise recognition system is shown to outperform the multiclass-recognition system in terms of the predictive accuracy on the test face images.","",""
23,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","A comparative study of HTM and other neural network models for online sequence learning with streaming data",2016,"","","","",45,"2022-07-13 09:29:07","","10.1109/IJCNN.2016.7727380","","",,,,,23,3.83,6,4,6,"Online sequence learning from streaming data is one of the most challenging topics in machine learning. Neural network models represent promising candidates for sequence learning due to their ability to learn and recognize complex temporal patterns. In this paper, we present a comparative study of Hierarchical Temporal Memory (HTM), a neurally-inspired model, and other feedforward and recurrent artificial neural network models on both artificial and real-world sequence prediction algorithms. HTM and long-short term memory (LSTM) give the best prediction accuracy. HTM additionally demonstrates many other features that are desirable for real-world sequence learning, such as fast adaptation to changes in the data stream, robustness to sensor noise and fault tolerance. These features make HTM an ideal candidate for online sequence learning problems.","",""
25,"J. P. Dominguez-Morales, A. Jiménez-Fernandez, A. Rios-Navarro, Elena Cerezuela-Escudero, Daniel Gutierrez-Galan, M. Domínguez-Morales, G. Jiménez-Moreno","Multilayer Spiking Neural Network for Audio Samples Classification Using SpiNNaker",2016,"","","","",46,"2022-07-13 09:29:07","","10.1007/978-3-319-44778-0_6","","",,,,,25,4.17,4,7,6,"","",""
37,"Ş. Yıldırım, S. Erkaya, Ikbal Eski, I. Uzmay","Noise and Vibration Analysis of Car Engines using Proposed Neural Network",2009,"","","","",47,"2022-07-13 09:29:07","","10.1177/1077546307087394","","",,,,,37,2.85,9,4,13,"An experimental design method for noise and vibration analysis of two car engines by feedforward and radial basis neural networks is presented. Two types of car engines are experimentally analyzed by using intelligent data acquisition card with software. Measured vibration and noise parameters of two car engines are used as desired values of the neural networks. The effectiveness of using Radial Basis Neural Network (RBNN) with backpropagation algorithm is demonstrated for predicting the vibrations and noises of two car engines. The robustness of the proposed RBNN predictor to parameters of vibration and noise as well measurement disturbances is investigated. The result of experiments and simulation show that the proposed RBNN is able to adapt effectively under disturbances.","",""
51,"D. Bhalke, C. R. Rao, D. Bormane","Automatic musical instrument classification using fractional fourier transform based- MFCC features and counter propagation neural network",2016,"","","","",48,"2022-07-13 09:29:07","","10.1007/s10844-015-0360-9","","",,,,,51,8.50,17,3,6,"","",""
27,"Sri Harish Reddy Mallidi, H. Hermansky","Novel neural network based fusion for multistream ASR",2016,"","","","",49,"2022-07-13 09:29:07","","10.1109/ICASSP.2016.7472765","","",,,,,27,4.50,14,2,6,"Robustness of automatic speech recognition (ASR) to acoustic mismatches can be improved by multistream framework. Frequently used approach to combine decisions from individual streams involve training large number of neural networks, one for each possible stream combination. In this work, we propose to simplify the fusion by replacing the large number of fusion networks with a single fusion network. During training of the proposed fusion network, features from a stream are randomly dropped out. At test time, corrupted streams are identified and dropped out to improve robustness. Using the proposed approach, we were able to achieve significant reduction in number of parameters, while remaining in less than 2.5 % relative degradation of conventional fusion technique. Furthermore, proposed fusion network is also applied in a multistream ASR system to improve noise robustness of Aurora4 speech recognition task. Noticeable improvements were observed over baseline systems (relative improvement of 9.2 % in microphone mismatch and 3.2 % in additive noise conditions).","",""
45,"Razieh Falahian, Maryam Mehdizadeh Dastjerdi, Malihe Molaie, S. Jafari, S. Gharibzadeh","Artificial neural network-based modeling of brain response to flicker light",2015,"","","","",50,"2022-07-13 09:29:07","","10.1007/S11071-015-2118-X","","",,,,,45,6.43,9,5,7,"","",""
83,"Evangelos Stromatias, Daniel Neil, Michael Pfeiffer, F. Galluppi, S. Furber, Shih-Chii Liu","Robustness of spiking Deep Belief Networks to noise and reduced bit precision of neuro-inspired hardware platforms",2015,"","","","",51,"2022-07-13 09:29:07","","10.3389/fnins.2015.00222","","",,,,,83,11.86,14,6,7,"Increasingly large deep learning architectures, such as Deep Belief Networks (DBNs) are the focus of current machine learning research and achieve state-of-the-art results in different domains. However, both training and execution of large-scale Deep Networks require vast computing resources, leading to high power requirements and communication overheads. The on-going work on design and construction of spike-based hardware platforms offers an alternative for running deep neural networks with significantly lower power consumption, but has to overcome hardware limitations in terms of noise and limited weight precision, as well as noise inherent in the sensor signal. This article investigates how such hardware constraints impact the performance of spiking neural network implementations of DBNs. In particular, the influence of limited bit precision during execution and training, and the impact of silicon mismatch in the synaptic weight parameters of custom hybrid VLSI implementations is studied. Furthermore, the network performance of spiking DBNs is characterized with regard to noise in the spiking input signal. Our results demonstrate that spiking DBNs can tolerate very low levels of hardware bit precision down to almost two bits, and show that their performance can be improved by at least 30% through an adapted training mechanism that takes the bit precision of the target platform into account. Spiking DBNs thus present an important use-case for large-scale hybrid analog-digital or digital neuromorphic platforms such as SpiNNaker, which can execute large but precision-constrained deep networks in real time.","",""
198,"Kerstin Beer, Dmytro Bondarenko, Terry Farrelly, T. Osborne, Robert Salzmann, Daniel Scheiermann, Ramona Wolf","Training deep quantum neural networks",2020,"","","","",52,"2022-07-13 09:29:07","","10.1038/s41467-020-14454-2","","",,,,,198,99.00,28,7,2,"","",""
158,"Xu Yan, Chaoda Zheng, Zhuguo Li, Sheng Wang, Shuguang Cui","PointASNL: Robust Point Clouds Processing Using Nonlocal Neural Networks With Adaptive Sampling",2020,"","","","",53,"2022-07-13 09:29:07","","10.1109/cvpr42600.2020.00563","","",,,,,158,79.00,32,5,2,"Raw point clouds data inevitably contains outliers or noise through acquisition from 3D sensors or reconstruction algorithms. In this paper, we present a novel end-to-end network for robust point clouds processing, named PointASNL, which can deal with point clouds with noise effectively. The key component in our approach is the adaptive sampling (AS) module. It first re-weights the neighbors around the initial sampled points from farthest point sampling (FPS), and then adaptively adjusts the sampled points beyond the entire point cloud. Our AS module can not only benefit the feature learning of point clouds, but also ease the biased effect of outliers. To further capture the neighbor and long-range dependencies of the sampled point, we proposed a local-nonlocal (L-NL) module inspired by the nonlocal operation. Such L-NL module enables the learning process insensitive to noise. Extensive experiments verify the robustness and superiority of our approach in point clouds processing tasks regardless of synthesis data, indoor data, and outdoor data with or without noise. Specifically, PointASNL achieves state-of-the-art robust performance for classification and segmentation tasks on all datasets, and significantly outperforms previous methods on real-world outdoor SemanticKITTI dataset with considerate noise.","",""
22,"Matej Ulicny, J. Lundström, S. Byttner","Robustness of Deep Convolutional Neural Networks for Image Recognition",2016,"","","","",54,"2022-07-13 09:29:07","","10.1007/978-3-319-30447-2_2","","",,,,,22,3.67,7,3,6,"","",""
33,"Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, M. Sugiyama","Provably End-to-end Label-Noise Learning without Anchor Points",2021,"","","","",55,"2022-07-13 09:29:07","","","","",,,,,33,33.00,7,5,1,"In label-noise learning, the transition matrix plays a key role in building statistically consistent classifiers. Existing consistent estimators for the transition matrix have been developed by exploiting anchor points. However, the anchorpoint assumption is not always satisfied in real scenarios. In this paper, we propose an end-toend framework for solving label-noise learning without anchor points, in which we simultaneously optimize two objectives: the cross entropy loss between the noisy label and the predicted probability by the neural network, and the volume of the simplex formed by the columns of the transition matrix. Our proposed framework can identify the transition matrix if the clean class-posterior probabilities are sufficiently scattered. This is by far the mildest assumption under which the transition matrix is provably identifiable and the learned classifier is statistically consistent. Experimental results on benchmark datasets demonstrate the effectiveness and robustness of the proposed method.","",""
42,"T. Tan, Y. Qian, Hu Hu, Ying Zhou, W. Ding, Kai Yu","Adaptive Very Deep Convolutional Residual Network for Noise Robust Speech Recognition",2018,"","","","",56,"2022-07-13 09:29:07","","10.1109/TASLP.2018.2825432","","",,,,,42,10.50,7,6,4,"Although great progress has been made in automatic speech recognition, significant performance degradation still exists in noisy environments. Our previous work has demonstrated the superior noise robustness of very deep convolutional neural networks (VDCNN). Based on our work on VDCNNs, this paper proposes a more advanced model referred to as the very deep convolutional residual network (VDCRN). This new model incorporates batch normalization and residual learning, showing more robustness than previous VDCNNs.Then, to alleviate the mismatch between the training and testing conditions, model adaptation and adaptive training are developed and compared for the new VDCRN. This paper focuses on factor aware training (FAT) and cluster adaptive training (CAT). For FAT, a unified framework is explored. For CAT, two schemes are first explored to construct the bases in the canonical model; furthermore, a factorized version of CAT is designed to address multiple nonspeech variabilities in one model. Finally, a complete multipass system is proposed to achieve the best system performance in the noisy scenarios. The proposed new approaches are evaluated on three different tasks: Aurora4 (simulated data with additive noise and channel distortion), CHiME4 (both simulated and real data with additive noise and reverberation), and the AMI meeting transcription task (real data with significant reverberation).The evaluation not only includes different noisy conditions, but also covers both simulated and real noisy data. The experiments show that the new VDCRN is more robust, and the adaptation on this model can further significantly reduce the word error rate (WER). The proposed best architecture obtains consistent and very large improvements on all tasks compared to the baseline VDCNN or long short-term memory. Particularly, on Aurora4 a new milestone 5.67% WER is achieved by only improving acoustic modeling.","",""
40,"Hongwei Zhang, Xiong Xiao, O. Hasegawa","A Load-Balancing Self-Organizing Incremental Neural Network",2014,"","","","",57,"2022-07-13 09:29:07","","10.1109/TNNLS.2013.2287884","","",,,,,40,5.00,13,3,8,"Clustering is widely used in machine learning, feature extraction, pattern recognition, image analysis, information retrieval, and bioinformatics. Online unsupervised incremental learning is an important branch of data clustering. However, accurately separating high-density overlapped areas in a network has a direct impact on the performance of the clustering algorithm. In this paper, we propose a load-balancing self-organizing incremental neural network (LB-SOINN) to achieve good clustering results and demonstrate that it is more stable than an enhanced SOINN (E-SOINN). LB-SOINN has all the advantages of E-SOINN, such as robustness to noise and online unsupervised incremental learning. It overcomes the shortcomings of the topology structure generated by E-SOINN, such as dependence on the sequence of the input data, and avoids the turbulence that occurs when separating a composite class into subclasses. Furthermore, we also introduce a distance combination framework to obtain good performance for high-dimensional space-clustering tasks. Experiments involving both artificial and real world data sets indicate that LB-SOINN has superior performance in comparison with E-SOINN and other methods.","",""
23,"Jürgen T. Geiger, J. Gemmeke, Björn Schuller, G. Rigoll","Investigating NMF speech enhancement for neural network based acoustic models",2014,"","","","",58,"2022-07-13 09:29:07","","","","",,,,,23,2.88,6,4,8,"In the light of the improvements that were made in the last years with neural network-based acoustic models, it is an interesting question whether these models are also suited for noise-robust recognition. This has not yet been fully explored, although first experiments confirm this question. Furthermore, preprocessing techniques that improve the robustness should be re-evaluated with these new models. In this work, we present experimental results to address these questions. Acoustic models based on Gaussian mixture models (GMMs), deep neural networks (DNNs), and long short-term memory (LSTM) recurrent neural networks (which have an improved ability to exploit context) are evaluated for their robustness after clean or multi-condition training. In addition, the influence of non-negative matrix factorization (NMF) for speech enhancement is investigated. Experiments are performed with the Aurora-4 database and the results show that DNNs perform slightly better than LSTMs and, as expected, both beat GMMs. Furthermore, speech enhancement is capable of improving the DNN result.","",""
10,"M. Chow, S. Yee","Robustness test of an incipient fault detector artificial neural network",1991,"","","","",59,"2022-07-13 09:29:07","","10.1109/IJCNN.1991.155152","","",,,,,10,0.32,5,2,31,"Addresses the issue of robustness in artificial neural networks subject to small input perturbations. The robustness in artificial neural networks is studied using the concept of input-output sensitivity analysis applied to an incipient fault detector artificial neural network (IFDANN). The IFDANN was designed to detect winding insulation faults and bearing wear in single-phase squirrel-cage induction motors. Modification of the IFDANN, with the intention of increasing its robustness to input noise during real-time applications, is discussed. Analytical and simulation results are presented to show the significant improvement in robustness of the modified IFDANN for operation with noisy measurements.<<ETX>>","",""
46,"Giorgio Patrini, A. Rozza, A. Menon, R. Nock, Lizhen Qu","Making Neural Networks Robust to Label Noise: a Loss Correction Approach",2016,"","","","",60,"2022-07-13 09:29:07","","","","",,,,,46,7.67,9,5,6,"We present a theoretically grounded approach to train deep neural networks, including recurrent networks, subject to class-dependent label noise. Our method only performs a correction on the loss function, and is agnostic to both the application domain and network architecture. We propose two procedures for loss correction: they simply amount to at most a matrix inversion and multiplication, provided that we know the probability of each class being corrupted into another. We further show how one can estimate these probabilities, adapting a recent technique for noise estimation to the multi-class setting, and thus providing an end-to-end framework. Extensive experiments on MNIST, IMDB, CIFAR-10, CIFAR-100 employing a diversity of architectures — stacking dense, convolutional, pooling, dropout, batch normalization, word embedding, LSTM and residual layers — demonstrate the noise robustness of our proposals. Incidentally, we also prove that, when ReLU is the only non-linearity, the loss curvature is immune to class-dependent label noise.","",""
40,"Bo Li, K. Sim","Improving robustness of deep neural networks via spectral masking for automatic speech recognition",2013,"","","","",61,"2022-07-13 09:29:07","","10.1109/ASRU.2013.6707743","","",,,,,40,4.44,20,2,9,"The performance of human listeners degrades rather slowly compared to machines in noisy environments. This has been attributed to the ability of performing auditory scene analysis which separates the speech prior to recognition. In this work, we investigate two mask estimation approaches, namely the state dependent and the deep neural network (DNN) based estimations, to separate speech from noises for improving DNN acoustic models' noise robustness. The second approach has been experimentally shown to outperform the first one. Due to the stereo data based training and ill-defined masks for speech with channel distortions, both methods do not generalize well to unseen conditions and fail to beat the performance of the multi-style trained baseline system. However, the model trained on masked features demonstrates strong complementariness to the baseline model. The simple average of the two system's posteriors yields word error rates of 4.4% on Aurora2 and 12.3% on Aurora4.","",""
25,"Jongheon Jeong, Jinwoo Shin","Consistency Regularization for Certified Robustness of Smoothed Classifiers",2020,"","","","",62,"2022-07-13 09:29:07","","","","",,,,,25,12.50,13,2,2,"A recent technique of randomized smoothing has shown that the worst-case (adversarial) $\ell_2$-robustness can be transformed into the average-case Gaussian-robustness by ""smoothing"" a classifier, i.e., by considering the averaged prediction over Gaussian noise. In this paradigm, one should rethink the notion of adversarial robustness in terms of generalization ability of a classifier under noisy observations. We found that the trade-off between accuracy and certified robustness of smoothed classifiers can be greatly controlled by simply regularizing the prediction consistency over noise. This relationship allows us to design a robust training objective without approximating a non-existing smoothed classifier, e.g., via soft smoothing. Our experiments under various deep neural network architectures and datasets demonstrate that the ""certified"" $\ell_2$-robustness can be dramatically improved with the proposed regularization, even achieving better or comparable results to the state-of-the-art approaches with significantly less training costs and hyperparameters.","",""
19,"Xinyu Liu, Xiaoguang Di","TanhExp: A Smooth Activation Function with High Convergence Speed for Lightweight Neural Networks",2020,"","","","",63,"2022-07-13 09:29:07","","10.1049/CVI2.12020","","",,,,,19,9.50,10,2,2,"Lightweight or mobile neural networks used for real-time computer vision tasks contain fewer parameters than normal networks, which lead to a constrained performance. In this work, we proposed a novel activation function named Tanh Exponential Activation Function (TanhExp) which can improve the performance for these networks on image classification task significantly. The definition of TanhExp is f(x) = xtanh(e^x). We demonstrate the simplicity, efficiency, and robustness of TanhExp on various datasets and network models and TanhExp outperforms its counterparts in both convergence speed and accuracy. Its behaviour also remains stable even with noise added and dataset altered. We show that without increasing the size of the network, the capacity of lightweight neural networks can be enhanced by TanhExp with only a few training epochs and no extra parameters added.","",""
58,"Youshen Xia, Changyin Sun, W. Zheng","Discrete-Time Neural Network for Fast Solving Large Linear $L_{1}$ Estimation Problems and its Application to Image Restoration",2012,"","","","",64,"2022-07-13 09:29:07","","10.1109/TNNLS.2012.2184800","","",,,,,58,5.80,19,3,10,"There is growing interest in solving linear L1 estimation problems for sparsity of the solution and robustness against non-Gaussian noise. This paper proposes a discrete-time neural network which can calculate large linear L1 estimation problems fast. The proposed neural network has a fixed computational step length and is proved to be globally convergent to an optimal solution. Then, the proposed neural network is efficiently applied to image restoration. Numerical results show that the proposed neural network is not only efficient in solving degenerate problems resulting from the nonunique solutions of the linear L1 estimation problems but also needs much less computational time than the related algorithms in solving both linear L1 estimation and image restoration problems.","",""
11,"M. Trompf","Neural network development for noise reduction in robust speech recognition",1992,"","","","",65,"2022-07-13 09:29:07","","10.1109/IJCNN.1992.227233","","",,,,,11,0.37,11,1,30,"Speech recognition systems with small and medium vocabulary are used as natural human interfaces in a variety of applications. To make such a system more robust, the development of a neural network based noise reduction module is described. Using standard feedforward networks, several topologies have been tested to learn about the properties of neural noise reduction. For the development of a sufficiently robust nonadaptive system, information about the characteristics of the noise and speech components of the input signal including context information was taken into account. The focus is on the stepwise experiment-oriented improvement of a basic linear neural noise reduction network. The isolated word recognition system and the database used for the experiments are described. Results from different noise reduction networks are given. To test their robustness, simulations with varying input signal characteristics were made and are discussed.<<ETX>>","",""
119,"Yi Shen, Jun Wang","Robustness Analysis of Global Exponential Stability of Recurrent Neural Networks in the Presence of Time Delays and Random Disturbances",2012,"","","","",66,"2022-07-13 09:29:07","","10.1109/TNNLS.2011.2178326","","",,,,,119,11.90,60,2,10,"In recent years, the global stability of recurrent neural networks (RNNs) has been investigated extensively. It is well known that time delays and external disturbances can derail the stability of RNNs. In this paper, we analyze the robustness of global stability of RNNs subject to time delays and random disturbances. Given a globally exponentially stable neural network, the problem to be addressed here is how much time delay and noise the RNN can withstand to be globally exponentially stable in the presence of delay and noise. The upper bounds of the time delay and noise intensity are characterized by using transcendental equations for the RNNs to sustain global exponential stability. Moreover, we prove theoretically that, for any globally exponentially stable RNNs, if additive noises and time delays are smaller than the derived lower bounds arrived at here, then the perturbed RNNs are guaranteed to also be globally exponentially stable. Three numerical examples are provided to substantiate the theoretical results.","",""
236,"Eric Arazo Sanchez, Diego Ortego, Paul Albert, N. O'Connor, Kevin McGuinness","Unsupervised label noise modeling and loss correction",2019,"","","","",67,"2022-07-13 09:29:07","","","","",,,,,236,78.67,47,5,3,"Despite being robust to small amounts of label noise, convolutional neural networks trained with stochastic gradient methods have been shown to easily fit random labels. When there are a mixture of correct and mislabelled targets, networks  tend to fit the former before the latter. This suggests using a suitable two-component mixture model as an unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled. Specifically, we propose a beta mixture to estimate this probability and correct the loss by relying on the network prediction (the so-called bootstrapping loss). We further adapt mixup augmentation to drive our approach a step further. Experiments on CIFAR-10/100 and TinyImageNet demonstrate a robustness to label noise that substantially outperforms recent state-of-the-art. Source code is available at https://git.io/fjsvE and Appendix at https://arxiv.org/abs/1904.11238.","",""
27,"Hong Yu, Z. Tan, Zhanyu Ma, Jun Guo","Adversarial Network Bottleneck Features for Noise Robust Speaker Verification",2017,"","","","",68,"2022-07-13 09:29:07","","10.1109/ICNIDC.2018.8525526","","",,,,,27,5.40,7,4,5,"In this paper, we propose a noise robust bottleneck feature representation which is generated by an adversarial network (AN). The AN includes two cascade connected networks, an encoding network (EN) and a discriminative network (DN). Mel-frequency cepstral coefficients (MFCCs) of clean and noisy speech are used as input to the EN and the output of the EN is used as the noise robust feature. The EN and DN are trained in turn, namely, when training the DN, noise types are selected as the training labels and when training the EN, all labels are set as the same, i.e., the clean speech label, which aims to make the AN features invariant to noise and thus achieve noise robustness. We evaluate the performance of the proposed feature on a Gaussian Mixture Model-Universal Background Model based speaker verification system, and make comparison to MFCC features of speech enhanced by short-time spectral amplitude minimum mean square error (STSA-MMSE) and deep neural network-based speech enhancement (DNN-SE) methods. Experimental results on the RSR2015 database show that the proposed AN bottleneck feature (AN-BN) dramatically outperforms the STSA-MMSE and DNN-SE based MFCCs for different noise types and signal-to-noise ratios. Furthermore, the AN-BN feature is able to improve the speaker verification performance under the clean condition.","",""
13,"M. Seera, C. Lim","Transfer learning using the online Fuzzy Min–Max neural network",2014,"","","","",69,"2022-07-13 09:29:07","","10.1007/s00521-013-1517-5","","",,,,,13,1.63,7,2,8,"","",""
98,"Yuzhe Yang, Guo Zhang, D. Katabi, Zhi Xu","ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation",2019,"","","","",70,"2022-07-13 09:29:07","","","","",,,,,98,32.67,25,4,3,"Deep neural networks are vulnerable to adversarial attacks. The literature is rich with algorithms that can easily craft successful adversarial examples. In contrast, the performance of defense techniques still lags behind. This paper proposes ME-Net, a defense method that leverages matrix estimation (ME). In ME-Net, images are preprocessed using two steps: first pixels are randomly dropped from the image; then, the image is reconstructed using ME. We show that this process destroys the adversarial structure of the noise, while re-enforcing the global structure in the original image. Since humans typically rely on such global structures in classifying images, the process makes the network mode compatible with human perception. We conduct comprehensive experiments on prevailing benchmarks such as MNIST, CIFAR-10, SVHN, and Tiny-ImageNet. Comparing ME-Net with state-of-the-art defense mechanisms shows that ME-Net consistently outperforms prior techniques, improving robustness against both black-box and white-box attacks.","",""
42,"Bo Li, K. Sim","A Spectral Masking Approach to Noise-Robust Speech Recognition Using Deep Neural Networks",2014,"","","","",71,"2022-07-13 09:29:07","","10.1109/TASLP.2014.2329237","","",,,,,42,5.25,21,2,8,"Improving the noise robustness of automatic speech recognition systems has been a challenging task for many years. Recently, it was found that Deep Neural Networks (DNNs) yield large performance gains over conventional GMM-HMM systems, when used in both hybrid and tandem systems. However, they are still far from the level of human expectations especially under adverse environments. Motivated by the separation-prior-to-recognition process of the human auditory system, we propose a robust spectral masking system where power spectral domain masks are predicted using a DNN trained on the same filter-bank features used for acoustic modeling. To further improve performance, Linear Input Network (LIN) adaptation is applied to both the mask estimator and the acoustic model DNNs. Since the estimation of LINs for the mask estimator requires stereo data, which is not available during testing, we proposed using the LINs estimated for the acoustic model DNNs to adapt the mask estimators. Furthermore, we used the same set of weights obtained from pre-training for the input layers of both the mask estimator and the acoustic model DNNs to ensure a better consistency for sharing LINs. Experimental results on benchmark Aurora2 and Aurora4 tasks demonstrated the effectiveness of our system, which yielded Word Error Rates (WERs) of 4.6% and 11.8% respectively. Furthermore, the simple averaging of posteriors from systems with and without spectral masking can further reduce the WERs to 4.3% on Aurora2 and 11.4% on Aurora4.","",""
287,"Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel","Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise",2018,"","","","",72,"2022-07-13 09:29:07","","","","",,,,,287,71.75,72,4,4,"The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling for large datasets, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.","",""
114,"J. Schulman, Dandelion Mané","DEFENSIVE QUANTIZATION: WHEN EFFICIENCY MEETS ROBUSTNESS",2018,"","","","",73,"2022-07-13 09:29:07","","","","",,,,,114,28.50,57,2,4,"Neural network quantization is becoming an industry standard to efficiently deploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and FPGAs. However, we observe that the conventional quantization approaches are vulnerable to adversarial attacks. This paper aims to raise people’s awareness about the security of the quantized models, and we designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models. We first conduct an empirical study to show that vanilla quantization suffers more from adversarial attacks. We observe that the inferior robustness comes from the error amplification effect, where the quantization operation further enlarges the distance caused by amplified noise. Then we propose a novel Defensive Quantization (DQ) method by controlling the Lipschitz constant of the network during quantization, such that the magnitude of the adversarial noise remains non-expansive during inference. Extensive experiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization method can defend neural networks against adversarial examples, and even achieves superior robustness than their fullprecision counterparts, while maintaining the same hardware efficiency as vanilla quantization approaches. As a by-product, DQ can also improve the accuracy of quantized models without adversarial attack.","",""
30,"Björn Lütjens, Michael Everett, J. How","Certified Adversarial Robustness for Deep Reinforcement Learning",2019,"","","","",74,"2022-07-13 09:29:07","","","","",,,,,30,10.00,10,3,3,"Deep Neural Network-based systems are now the state-of-the-art in many robotics tasks, but their application in safety-critical domains remains dangerous without formal guarantees on network robustness. Small perturbations to sensor inputs (from noise or adversarial examples) are often enough to change network-based decisions, which was already shown to cause an autonomous vehicle to swerve into oncoming traffic. In light of these dangers, numerous algorithms have been developed as defensive mechanisms from these adversarial inputs, some of which provide formal robustness guarantees or certificates. This work leverages research on certified adversarial robustness to develop an online certified defense for deep reinforcement learning algorithms. The proposed defense computes guaranteed lower bounds on state-action values during execution to identify and choose the optimal action under a worst-case deviation in input space due to possible adversaries or noise. The approach is demonstrated on a Deep Q-Network policy and is shown to increase robustness to noise and adversaries in pedestrian collision avoidance scenarios and a classic control task.","",""
8,"Song Zhu, Yi Shen","Robustness analysis of global exponential stability of neural networks with Markovian switching in the presence of time-varying delays or noises",2013,"","","","",75,"2022-07-13 09:29:07","","10.1007/s00521-012-1105-0","","",,,,,8,0.89,4,2,9,"","",""
682,"Scott E. Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, D. Erhan, Andrew Rabinovich","Training Deep Neural Networks on Noisy Labels with Bootstrapping",2014,"","","","",76,"2022-07-13 09:29:07","","","","",,,,,682,85.25,114,6,8,"Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-the- art results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.","",""
122,"Huaguang Zhang, Jinhai Liu, Dazhong Ma, Zhanshan Wang","Data-Core-Based Fuzzy Min–Max Neural Network for Pattern Classification",2011,"","","","",77,"2022-07-13 09:29:07","","10.1109/TNN.2011.2175748","","",,,,,122,11.09,31,4,11,"A fuzzy min-max neural network based on data core (DCFMN) is proposed for pattern classification. A new membership function for classifying the neuron of DCFMN is defined in which the noise, the geometric center of the hyperbox, and the data core are considered. Instead of using the contraction process of the FMNN described by Simpson, a kind of overlapped neuron with new membership function based on the data core is proposed and added to neural network to represent the overlapping area of hyperboxes belonging to different classes. Furthermore, some algorithms of online learning and classification are presented according to the structure of DCFMN. DCFMN has strong robustness and high accuracy in classification taking onto account the effect of data core and noise. The performance of DCFMN is checked by some benchmark datasets and compared with some traditional fuzzy neural networks, such as the fuzzy min-max neural network (FMNN), the general FMNN, and the FMNN with compensatory neuron. Finally the pattern classification of a pipeline is evaluated using DCFMN and other classifiers. All the results indicate that the performance of DCFMN is excellent.","",""
38,"Rafael Pinot, Laurent Meunier, Alexandre Araujo, H. Kashima, F. Yger, C. Gouy-Pailler, J. Atif","Theoretical evidence for adversarial robustness through randomization",2019,"","","","",78,"2022-07-13 09:29:07","","","","",,,,,38,12.67,5,7,3,"This paper investigates the theory of robustness against adversarial attacks. It focuses on the family of randomization techniques that consist in injecting noise in the network at inference time. These techniques have proven effective in many contexts, but lack theoretical arguments. We close this gap by presenting a theoretical analysis of these approaches, hence explaining why they perform well in practice. More precisely, we make two new contributions. The first one relates the randomization rate to robustness to adversarial attacks. This result applies for the general family of exponential distributions, and thus extends and unifies the previous approaches. The second contribution consists in devising a new upper bound on the adversarial generalization gap of randomized neural networks. We support our theoretical claims with a set of experiments.","",""
85,"Jianchun Li, U. Dackermann, You‐lin Xu, B. Samali","Damage identification in civil engineering structures utilizing PCA‐compressed residual frequency response functions and neural network ensembles",2011,"","","","",79,"2022-07-13 09:29:07","","10.1002/stc.369","","",,,,,85,7.73,21,4,11,"This paper presents a non‐destructive, global, vibration‐based damage identification method that utilizes damage pattern changes in frequency response functions (FRFs) and artificial neural networks (ANNs) to identify defects. To extract damage features and to obtain suitable input parameters for ANNs, principal component analysis (PCA) techniques are applied. Residual FRFs, which are the differences in the FRF data from the intact and the damaged structure, are compressed to a few principal components and fed to ANNs to estimate the locations and severities of structural damage. A hierarchy of neural network ensembles is created to take advantage of individual information from sensor signals. To simulate field‐testing conditions, white Gaussian noise is added to the numerical data and a noise sensitivity study is conducted to investigate the robustness of the developed damage detection technique to noise. Both numerical and experimental results of simply supported steel beam structures have been used to demonstrate effectiveness and reliability of the proposed method. Copyright © 2009 John Wiley & Sons, Ltd.","",""
35,"S. Franciscis, Samuel Johnson, J. J. Torres","Enhancing neural-network performance via assortativity",2010,"","","","",80,"2022-07-13 09:29:07","","10.1103/PhysRevE.83.036114","","",,,,,35,2.92,12,3,12,"The performance of attractor neural networks has been shown to depend crucially on the heterogeneity of the underlying topology. We take this analysis a step further by examining the effect of degree-degree correlations--assortativity--on neural-network behavior. We make use of a method recently put forward for studying correlated networks and dynamics thereon, both analytically and computationally, which is independent of how the topology may have evolved. We show how the robustness to noise is greatly enhanced in assortative (positively correlated) neural networks, especially if it is the hub neurons that store the information.","",""
49,"Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan, Sewoong Oh, P. Viswanath","LEARN Codes: Inventing Low-Latency Codes via Recurrent Neural Networks",2018,"","","","",81,"2022-07-13 09:29:07","","10.1109/ICC.2019.8761286","","",,,,,49,12.25,8,6,4,"Designing channel codes under low latency constraints is one of the most demanding requirements in 5G standards. However, sharp characterizations of the performances of traditional codes are only available in the large block lengths limit. Code designs are guided by those asymptotic analyses and require large block lengths and long latency to achieve the desired error rate. Furthermore, when the codes designed for one channel (e.g. Additive White Gaussian Noise (AWGN) channel) are used for another (e.g. non-AWGN channels), heuristics are necessary to achieve any non trivial performance — thereby severely lacking in robustness as well as adaptivity. Obtained by jointly designing recurrent neural network (RNN) based encoder and decoder, we propose an end-to-end learned neural code which outperforms canonical convolutional code under block settings. With this gained experience of designing a novel neural block code, we propose a new class of codes under low latency constraint — Low-latency Efficient Adaptive Robust Neural (LEARN) codes, which outperform the state-of-the-art low latency codes as well as exhibit robustness and adaptivity properties. LEARN codes show the potential of designing new versatile and universal codes for future communications via tools of modern deep learning coupled with communication engineering insights.","",""
70,"Yixing Huang, Tobias Würfl, K. Breininger, Ling Liu, G. Lauritsch, A. Maier","Some Investigations on Robustness of Deep Learning in Limited Angle Tomography",2018,"","","","",82,"2022-07-13 09:29:07","","10.1007/978-3-030-00928-1_17","","",,,,,70,17.50,12,6,4,"","",""
271,"M. Ahmadlou, H. Adeli","Enhanced probabilistic neural network with local decision circles: A robust classifier",2010,"","","","",83,"2022-07-13 09:29:07","","10.3233/ICA-2010-0345","","",,,,,271,22.58,136,2,12,"In recent years the Probabilistic Neural Network (PPN) has been used in a large number of applications due to its simplicity and efficiency. PNN assigns the test data to the class with maximum likelihood compared with other classes. Likelihood of the test data to each training data is computed in the pattern layer through a kernel density estimation using a simple Bayesian rule. The kernel is usually a standard probability distribution function such as a Gaussian function. A spread parameter is used as a global parameter which determines the width of the kernel. The Bayesian rule in the pattern layer estimates the conditional probability of each class given an input vector without considering any probable local densities or heterogeneity in the training data. In this paper, an enhanced and generalized PNN (EPNN) is presented using local decision circles (LDCs) to overcome the aforementioned shortcoming and improve its robustness to noise in the data. Local decision circles enable EPNN to incorporate local information and non-homogeneity existing in the training population. The circle has a radius which limits the contribution of the local decision. In the conventional PNN the spread parameter can be optimized for maximum classification accuracy. In the proposed EPNN two parameters, the spread parameter and the radius of local decision circles, are optimized to maximize the performance of the model. Accuracy and robustness of EPNN are compared with PNN using three different benchmark classification problems, iris data, diabetic data, and breast cancer data, and five different ratios of training data to testing data: 90:10, 80:20, 70:30, 60:40, and 50:50. EPNN provided the most accurate results consistently for all ratios. Robustness of PNN and EPNN is investigated using different values of signal to noise ratio (SNR). Accuracy of EPNN is consistently higher than accuracy of PNN at different levels of SNR and for all ratios of training data to testing data.","",""
39,"S. Van Der Jeught, J. Dirckx","Deep neural networks for single shot structured light profilometry.",2019,"","","","",84,"2022-07-13 09:29:07","","10.1364/OE.27.017091","","",,,,,39,13.00,20,2,3,"In 3D optical metrology, single-shot structured light profilometry techniques have inherent advantages over their multi-shot counterparts in terms of measurement speed, optical setup simplicity, and robustness to motion artifacts. In this paper, we present a new approach to extract height information from single deformed fringe patterns, based entirely on deep learning. By training a fully convolutional neural network on a large set of simulated height maps with corresponding deformed fringe patterns, we demonstrate the ability of the network to obtain full-field height information from previously unseen fringe patterns with high accuracy. As an added benefit, intermediate data processing steps such as background masking, noise reduction and phase unwrapping that are otherwise required in classic demodulation strategies, can be learned directly by the network as part of its mapping function.","",""
30,"M. Kaselimi, E. Protopapadakis, A. Voulodimos, N. Doulamis, A. Doulamis","Multi-Channel Recurrent Convolutional Neural Networks for Energy Disaggregation",2019,"","","","",85,"2022-07-13 09:29:07","","10.1109/ACCESS.2019.2923742","","",,,,,30,10.00,6,5,3,"Power consumption signals of household appliances are characterized by randomly occurring events (e.g. switch-on events), making timeseries modeling a demanding process. In this paper, we propose a convolutional neural network (CNN)-based architecture with inputs and outputs formed as data sequences taking into consideration an appliance’s previous states for better estimation of its current state. Furthermore, the proposed model endows CNN models with a recurrent property in order to better capture energy signal interdependencies. Using a multi-channel CNN architecture fed with additional variables related to power consumption (current, reactive, and apparent power), additionally to active power, overall performance, robustness to noise and convergence times are improved. The experimental results prove the proposed method’s superiority compared to the current state of the art.","",""
23,"E. Shlizerman, J. Riffell, J. Kutz","Data-driven inference of network connectivity for modeling the dynamics of neural codes in the insect antennal lobe",2014,"","","","",86,"2022-07-13 09:29:07","","10.3389/fncom.2014.00070","","",,,,,23,2.88,8,3,8,"The antennal lobe (AL), olfactory processing center in insects, is able to process stimuli into distinct neural activity patterns, called olfactory neural codes. To model their dynamics we perform multichannel recordings from the projection neurons in the AL driven by different odorants. We then derive a dynamic neuronal network from the electrophysiological data. The network consists of lateral-inhibitory neurons and excitatory neurons (modeled as firing-rate units), and is capable of producing unique olfactory neural codes for the tested odorants. To construct the network, we (1) design a projection, an odor space, for the neural recording from the AL, which discriminates between distinct odorants trajectories (2) characterize scent recognition, i.e., decision-making based on olfactory signals and (3) infer the wiring of the neural circuit, the connectome of the AL. We show that the constructed model is consistent with biological observations, such as contrast enhancement and robustness to noise. The study suggests a data-driven approach to answer a key biological question in identifying how lateral inhibitory neurons can be wired to excitatory neurons to permit robust activity patterns.","",""
126,"Chia-Feng Juang, Ren-Bo Huang, Wei-Yuan Cheng","An Interval Type-2 Fuzzy-Neural Network With Support-Vector Regression for Noisy Regression Problems",2010,"","","","",87,"2022-07-13 09:29:07","","10.1109/TFUZZ.2010.2046904","","",,,,,126,10.50,42,3,12,"This paper proposes an interval type-2 fuzzy-neural network with support-vector regression (IT2FNN-SVR) for noisy regression problems. The antecedent part in each fuzzy rule of an IT2FNN-SVR uses interval type-2 fuzzy sets, and the consequent part is of the Takagi-Sugeno-Kang (TSK) type. The use of interval type-2 fuzzy sets helps improve the network's noise resistance. The network inputs may be numerical values or type-1 fuzzy sets, with the latter being used for further improvements in robustness. IT2FNN-SVR learning consists of both structure learning and parameter learning. The structure-learning algorithm is responsible for online rule generation. The parameters are optimized for structural-risk minimization using a two-phase linear SVR algorithm in order to endow the network with high generalization ability. IT2FNN-SVR performance is verified through comparisons with type-1 and type-2 fuzzy-logic systems and other regression models on noisy regression problems.","",""
30,"Yizhak Ben-Shabat, M. Lindenbaum, A. Fischer","Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds Using Convolutional Neural Networks",2018,"","","","",88,"2022-07-13 09:29:07","","10.1109/CVPR.2019.01035","","",,,,,30,7.50,10,3,4,"In this paper, we propose a normal estimation method for unstructured 3D point clouds. This method, called Nesti-Net, builds on a new local point cloud representation which consists of multi-scale point statistics (MuPS), estimated on a local coarse Gaussian grid. This representation is a suitable input to a CNN architecture. The normals are estimated using a mixture-of-experts (MoE) architecture, which relies on a data-driven approach for selecting the optimal scale around each point and encourages sub-network specialization. Interesting insights into the network's resource distribution are provided. The scale prediction significantly improves robustness to different noise levels, point density variations and different levels of detail. We achieve state-of-the-art results on a benchmark synthetic dataset and present qualitative results on real scanned scenes.","",""
188,"Shuai Li, Yunong Zhang, Long Jin","Kinematic Control of Redundant Manipulators Using Neural Networks",2017,"","","","",89,"2022-07-13 09:29:07","","10.1109/TNNLS.2016.2574363","","",,,,,188,37.60,63,3,5,"Redundancy resolution is a critical problem in the control of robotic manipulators. Recurrent neural networks (RNNs), as inherently parallel processing models for time-sequence processing, are potentially applicable for the motion control of manipulators. However, the development of neural models for high-accuracy and real-time control is a challenging problem. This paper identifies two limitations of the existing RNN solutions for manipulator control, i.e., position error accumulation and the convex restriction on the projection set, and overcomes them by proposing two modified neural network models. Our method allows nonconvex sets for projection operations, and control error does not accumulate over time in the presence of noise. Unlike most works in which RNNs are used to process time sequences, the proposed approach is model-based and training-free, which makes it possible to achieve fast tracking of reference signals with superior robustness and accuracy. Theoretical analysis reveals the global stability of a system under the control of the proposed neural networks. Simulation results confirm the effectiveness of the proposed control method in both the position regulation and tracking control of redundant PUMA 560 manipulators.","",""
18,"A. Omidvar, H. Shahhoseini","Intelligent IP traffic matrix estimation by neural network and genetic algorithm",2011,"","","","",90,"2022-07-13 09:29:07","","10.1109/WISP.2011.6051689","","",,,,,18,1.64,9,2,11,"Rapid growth of computer network scales has made traffic matrix estimation essential in network management. It can be used in load balancing, traffic detecting and so on. Since traffic should be considered temporally and spatially, prediction is complicated. Tracking dynamic changes of traffic, reducing estimation errors and increasing robustness to noise are factors which should be considered in estimation. In this paper, we propose a novel method to estimate traffic matrix. This approach combines artificial neural network and evolutionary algorithms. It uses autoregressive model with exogenous inputs (ARX) joined with genetic algorithm (GA) which we call it ARXGEN. GA is used in gaining optimized weights and biases. To evaluate our method, we did our simulations on Abilene data. Results prove that it can well track dynamic nature of traffic and has lower estimation errors. It is also more robust to noise.","",""
98,"Guocong Song, Wei Chai","Collaborative Learning for Deep Neural Networks",2018,"","","","",91,"2022-07-13 09:29:07","","","","",,,,,98,24.50,49,2,4,"We introduce collaborative learning in which multiple classifier heads of the same network are simultaneously trained on the same training data to improve generalization and robustness to label noise with no extra inference cost. It acquires the strengths from auxiliary training, multi-task learning and knowledge distillation. There are two important mechanisms involved in collaborative learning. First, the consensus of multiple views from different classifier heads on the same example provides supplementary information as well as regularization to each classifier, thereby improving generalization. Second, intermediate-level representation (ILR) sharing with backpropagation rescaling aggregates the gradient flows from all heads, which not only reduces training computational complexity, but also facilitates supervision to the shared layers. The empirical results on CIFAR and ImageNet datasets demonstrate that deep neural networks learned as a group in a collaborative way significantly reduce the generalization error and increase the robustness to label noise.","",""
14,"S. M. M. Vaghefi, R. Vaghefi","A novel multilayer neural network model for TOA-based localization in wireless sensor networks",2011,"","","","",92,"2022-07-13 09:29:07","","10.1109/IJCNN.2011.6033628","","",,,,,14,1.27,7,2,11,"A novel multilayer neural network model, called artificial synaptic network, was designed and implemented for single sensor localization with time-of-arrival (TOA) measurements. In the TOA localization problem, the location of a source sensor is estimated based on its distance from a number of anchor sensors. The measured distance values are noisy and the estimator should be able to handle different amounts of noise. Three neural network models: the proposed artificial synaptic network, a multi-layer perceptron network, and a generalized radial basis functions network were applied to the TOA localization problem. The performance of the models was compared with one another. The efficiency of the models was calculated based on the memory cost. The study result shows that the proposed artificial synaptic network has the lowest RMS error and highest efficiency. The robustness of the artificial synaptic network was compared with that of the least square (LS) method and the weighted least square (WLS) method. The Cramer-Rao lower bound (CRLB) of TOA localization was used as a benchmark. The model's robustness in high noise is better than the WLS method and remarkably close to the CRLB.","",""
27,"Abdelraouf Youcef Khodja, N. Guersi, M. Saadi, N. Boutasseta","Rolling element bearing fault diagnosis for rotating machinery using vibration spectrum imaging and convolutional neural networks",2020,"","","","",93,"2022-07-13 09:29:07","","10.1007/s00170-019-04726-7","","",,,,,27,13.50,7,4,2,"","",""
25,"A. Rusiecki","Trimmed categorical cross‐entropy for deep learning with label noise",2019,"","","","",94,"2022-07-13 09:29:07","","10.1049/EL.2018.7980","","",,,,,25,8.33,25,1,3,"Deep learning methods are nowadays considered as state-of-the-art approach in many sophisticated problems, such as computer vision, speech understanding or natural language processing. However, their performance relies on the quality of large annotated datasets. If the data are not well-annotated and label noise occur, such data-driven models become less reliable. In this Letter, the authors present very simple way to make the training process robust to noisy labels. Without changing network architecture and learning algorithm, the authors apply modified error measure that improves network generalisation when trained with label noise. Preliminary results obtained for deep convolutional neural networks, trained with novel trimmed categorical cross-entropy loss function, revealed its improved robustness for several levels of label noise.","",""
126,"Long Jin, Yunong Zhang, Shuai Li, Yinyan Zhang","Noise-Tolerant ZNN Models for Solving Time-Varying Zero-Finding Problems: A Control-Theoretic Approach",2017,"","","","",95,"2022-07-13 09:29:07","","10.1109/TAC.2016.2566880","","",,,,,126,25.20,32,4,5,"This technical note proposes a noise-tolerant zeroing neural network (NTZNN) design formula, and shows how recurrent (and recursive) methods for solving time-varying problems can be designed from the viewpoint of control. The NTZNN design formula provides a control-theoretic framework to deal with the convergence, stability and robustness issues of continuous-time (and discrete-time) models. NTZNN models derived from the proposed design formula demonstrate their advantages when applied to solving time-varying zero-finding problems in the presence of noises.","",""
116,"Zhouhua Peng, Jun Wang","Predictor-Based Neural Dynamic Surface Control for Uncertain Nonlinear Systems in Strict-Feedback Form",2017,"","","","",96,"2022-07-13 09:29:07","","10.1109/TNNLS.2016.2577342","","",,,,,116,23.20,58,2,5,"This paper presents a predictor-based neural dynamic surface control (PNDSC) design method for a class of uncertain nonlinear systems in a strict-feedback form. In contrast to existing NDSC approaches where the tracking errors are commonly used to update neural network weights, a predictor is proposed for every subsystem, and the prediction errors are employed to update the neural adaptation laws. The proposed scheme enables smooth and fast identification of system dynamics without incurring high-frequency oscillations, which are unavoidable using classical NDSC methods. Furthermore, the result is extended to the PNDSC with observer feedback, and its robustness against measurement noise is analyzed. Numerical and experimental results are given to demonstrate the efficacy of the proposed PNDSC architecture.","",""
68,"Yixin Cao, Lei Hou, Juan-Zi Li, Zhiyuan Liu","Neural Collective Entity Linking",2018,"","","","",97,"2022-07-13 09:29:07","","","","",,,,,68,17.00,17,4,4,"Entity Linking aims to link entity mentions in texts to knowledge bases, and neural models have achieved recent success in this task. However, most existing methods rely on local contexts to resolve entities independently, which may usually fail due to the data sparsity of local information. To address this issue, we propose a novel neural model for collective entity linking, named as NCEL. NCEL apply Graph Convolutional Network to integrate both local contextual features and global coherence information for entity linking. To improve the computation efficiency, we approximately perform graph convolution on a subgraph of adjacent entity mentions instead of those in the entire text. We further introduce an attention scheme to improve the robustness of NCEL to data noise and train the model on Wikipedia hyperlinks to avoid overfitting and domain bias. In experiments, we evaluate NCEL on five publicly available datasets to verify the linking performance as well as generalization ability. We also conduct an extensive analysis of time complexity, the impact of key modules, and qualitative results, which demonstrate the effectiveness and efficiency of our proposed method.","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",98,"2022-07-13 09:29:07","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
11,"J. Bouvrie, J. Slotine","Synchronization and Redundancy: Implications for Robustness of Neural Learning and Decision Making",2010,"","","","",99,"2022-07-13 09:29:07","","10.1162/NECO_a_00183","","",,,,,11,0.92,6,2,12,"Learning and decision making in the brain are key processes critical to survival, and yet are processes implemented by nonideal biological building blocks that can impose significant error. We explore quantitatively how the brain might cope with this inherent source of error by taking advantage of two ubiquitous mechanisms, redundancy and synchronization. In particular we consider a neural process whose goal is to learn a decision function by implementing a nonlinear gradient dynamics. The dynamics, however, are assumed to be corrupted by perturbations modeling the error, which might be incurred due to limitations of the biology, intrinsic neuronal noise, and imperfect measurements. We show that error, and the associated uncertainty surrounding a learned solution, can be controlled in large part by trading off synchronization strength among multiple redundant neural systems against the noise amplitude. The impact of the coupling between such redundant systems is quantified by the spectrum of the network Laplacian, and we discuss the role of network topology in synchronization and in reducing the effect of noise. We discuss range of situations in which the mechanisms we model arise in brain science and draw attention to experimental evidence suggesting that cortical circuits capable of implementing the computations of interest here can be found on several scales. Finally, simulations comparing theoretical bounds to the relevant empirical quantities show that the theoretical estimates we derive can be tight.","",""
116,"S. Mousavi, Weiqiang Zhu, Y. Sheng, G. Beroza","CRED: A Deep Residual Network of Convolutional and Recurrent Units for Earthquake Signal Detection",2018,"","","","",100,"2022-07-13 09:29:07","","10.1038/s41598-019-45748-1","","",,,,,116,29.00,29,4,4,"","",""
16,"Qunting Yang, Tieniu Gao, Li Fan","A novel robust watermarking scheme based on neural network",2010,"","","","",101,"2022-07-13 09:29:07","","10.1109/ICISS.2010.5655017","","",,,,,16,1.33,5,3,12,"A color image oblivious watermarking scheme based on neural network and discrete wavelet transform (DWT) is proposed in this paper. Three identical watermarks and some different expanded bit streams are adaptively embedded into the low frequency sub-bands generated from three channels for a color image, respectively. Due to the adaptive learning capabilities of neural network, the expanded bit streams could be used to train back propagation (BP) neural networks to represent the relationship among the neighbor wavelet coefficients. Based on the trained neural networks, three watermarking results can be extracted and then are voted to decide the final watermark. Extensive experiments illustrate that the new scheme possesses good robustness against different attacks including noise addition, shearing, scaling, luminance and distortion. And what's more, the scheme has excellent performance in term of imperceptibility and resistance to JPEG compression.","",""
22,"Yu Jin, Jiayi Zhang, B. Ai, Xiaodan Zhang","Channel Estimation for mmWave Massive MIMO With Convolutional Blind Denoising Network",2020,"","","","",102,"2022-07-13 09:29:07","","10.1109/LCOMM.2019.2952845","","",,,,,22,11.00,6,4,2,"Channel estimation is one of the foremost challenges for realizing practical millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems. To circumvent this problem, deep convolutional neural networks (CNNs) have been recently employed to achieve impressive success. However, current deep CNNs based channel estimators are only suitable to a small range of signal-to-noise ratios (SNRs). Unlike the existing works, the modified convolutional blind denoising network (CBDNet) is proposed to improve the robustness for noisy channel by adopting noise level estimation subnetwork, non-blind denosing subnetwork, and asymmetric joint loss functions for blind channel estimation. Furthermore, the CBDNet can adjust the estimated noise level map to interactively reduce the noise in the channel matrix. Numerical results demonstrate that the proposed CBDNet-based channel estimator can outperform the traditional channel estimators, traditional compressive sensing techniques and deep CNNs in terms of the normalized mean squared error. In addition, the CBDNet can be used over a large range of SNRs, which hugely reduce the cost of offline training.","",""
8,"S. Pontes-Filho, M. Liwicki","Bidirectional Learning for Robust Neural Networks",2018,"","","","",103,"2022-07-13 09:29:07","","10.1109/IJCNN.2019.8852120","","",,,,,8,2.00,4,2,4,"A multilayer perceptron can behave as a generative classifier by applying bidirectional learning (BL). It consists of training an undirected neural network to map input to output and vice-versa; therefore it can produce a classifier in one direction, and a generator in the opposite direction for the same data. The learning process of BL tries to reproduce the neuroplasticity stated in Hebbian theory using only backward propagation of errors. In this paper, two learning techniques are independently introduced which use BL for improving robustness to white noise static and adversarial examples. The first method is bidirectional propagation of errors, which the error propagation occurs in backward and forward directions. Motivated by the fact that its generative model receives as input a constant vector per class, we introduce as a second method the novel hybrid adversarial networks (HAN). Its generative model receives a random vector as input and its training is based on generative adversarial networks (GAN). To assess the performance of BL, we perform experiments using several architectures with fully and convolutional layers, with and without bias. Experimental results show that both methods improve robustness to white noise static and adversarial examples, and even increase accuracy, but have different behavior depending on the architecture and task, being more beneficial to use the one or the other. Nevertheless, HAN using a convolutional architecture with batch normalization presents outstanding robustness, reaching state-of-the-art accuracy on adversarial examples of hand-written digits.","",""
28,"Jun Wang, Tong Zheng, Peng Lei, Xiao Bai","Ground Target Classification in Noisy SAR Images Using Convolutional Neural Networks",2018,"","","","",104,"2022-07-13 09:29:07","","10.1109/JSTARS.2018.2871556","","",,,,,28,7.00,7,4,4,"Speckle noise is an inherent but annoying property in the synthetic aperture radar (SAR) imaging. In this paper we investigate the influence of speckle on the classical convolutional neural network (CNN) for SAR target classification. Then a dual stage coupled CNN architecture, named despeckling and classification coupled CNNs (DCC-CNNs), is proposed to distinguish multiple categories of ground targets in SAR images with strong and varying speckle. It first applies the despeckling sub-network for noise reduction. After that, residual speckle features as well as target information would be learned by the classification sub-network in order to solve the noise robustness problem of CNN. Besides, a new quantitative measure is developed for the quality assessment of SAR target images. It takes into account structural properties of the speckled SAR image of the target of interest and consistency with visual perception. Finally, a series of comparative experiments and discussions are carried out to validate the proposed assessment criterion and DCC-CNNs. Using synthetic SAR images based on the public MSTAR datasets, results show that the overall classification accuracy for ten ground target classes could be higher than 82% at a variety of speckle noise levels.","",""
24,"Rongqiang Du, Yanling Xu, Zhen Hou, Jun Shu, Shanben Chen","Strong noise image processing for vision-based seam tracking in robotic gas metal arc welding",2018,"","","","",105,"2022-07-13 09:29:07","","10.1007/S00170-018-3115-2","","",,,,,24,6.00,5,5,4,"","",""
23,"Yue Yan","Convolutional neural networks based on augmented training samples for synthetic aperture radar target recognition",2018,"","","","",106,"2022-07-13 09:29:07","","10.1117/1.JEI.27.2.023024","","",,,,,23,5.75,23,1,4,"Abstract. A synthetic aperture radar (SAR) automatic target recognition (ATR) method based on the convolutional neural networks (CNN) trained by augmented training samples is proposed. To enhance the robustness of CNN to various extended operating conditions (EOCs), the original training images are used to generate the noisy samples at different signal-to-noise ratios (SNRs), multiresolution representations, and partially occluded images. Then, the generated images together with the original ones are used to train a designed CNN for target recognition. The augmented training samples can contrapuntally improve the robustness of the trained CNN to the covered EOCs, i.e., the noise corruption, resolution variance, and partial occlusion. Moreover, the significantly larger training set effectively enhances the representation capability for other conditions, e.g., the standard operating condition (SOC), as well as the stability of the network. Therefore, better performance can be achieved by the proposed method for SAR ATR. For experimental evaluation, extensive experiments are conducted on the Moving and Stationary Target Acquisition and Recognition dataset under SOC and several typical EOCs.","",""
83,"P. Merolla, R. Appuswamy, J. Arthur, Steven K. Esser, D. Modha","Deep neural networks are robust to weight binarization and other non-linear distortions",2016,"","","","",107,"2022-07-13 09:29:07","","","","",,,,,83,13.83,17,5,6,"Recent results show that deep neural networks achieve excellent performance even when, during training, weights are quantized and projected to a binary representation. Here, we show that this is just the tip of the iceberg: these same networks, during testing, also exhibit a remarkable robustness to distortions beyond quantization, including additive and multiplicative noise, and a class of non-linear projections where binarization is just a special case. To quantify this robustness, we show that one such network achieves 11% test error on CIFAR-10 even with 0.68 effective bits per weight. Furthermore, we find that a common training heuristic--namely, projecting quantized weights during backpropagation--can be altered (or even removed) and networks still achieve a base level of robustness during testing. Specifically, training with weight projections other than quantization also works, as does simply clipping the weights, both of which have never been reported before. We confirm our results for CIFAR-10 and ImageNet datasets. Finally, drawing from these ideas, we propose a stochastic projection rule that leads to a new state of the art network with 7.64% test error on CIFAR-10 using no data augmentation.","",""
87,"D. Tian, L. Fan","A Brain MR Images Segmentation Method Based on SOM Neural Network",2007,"","","","",108,"2022-07-13 09:29:07","","10.1109/ICBBE.2007.179","","",,,,,87,5.80,44,2,15,"Image segmentation is an indispensable process in the visualization of human tissues, particularly during clinical analysis of magnetic resonance (MR) images. In this paper, a novel brain MR images segmentation method is presented based on self-organizing map (SOM) neural network. The method comprises two main steps: feature extraction and pixel classification based on SOM neural network. In traditional techniques, neural network's input is the feature vector extracted from the intensity of the pixel and of its n nearest neighbors, which introduces dependency on the gray levels spatial distribution, and thus the final segmentation results are prone to be effected by noise. To enhance the robustness of the method, we perform statistical transformation to the traditional feature vector as neural network's input. Simulated brain MR images with different noise levels and intensity inhomogeneities are segmented to demonstrate the superiority of the proposed method compared to the traditional technique.","",""
20,"C. Maha, E. Maher, B. A. Chokri","A blind audio watermarking scheme based on neural network and psychoacoustic model with error correcting code in wavelet domain",2008,"","","","",109,"2022-07-13 09:29:07","","10.1109/ISCCSP.2008.4537396","","",,,,,20,1.43,7,3,14,"Audio watermarking is a method that embeds inaudible information into digital audio data. This paper proposes an audio watermarking technique for protecting audio copyrights based on human psychoacoustic model (HPM), discrete wavelet transform (DWT), neural network (NN) and error correcting code. Our technique exploits frequency perceptual masking studied in HPM to guarantee that the embedded watermark is inaudible. To assure watermark embedding and extraction, neural network is used to memorize the relationships between a Wavelet central sample and its neighbors. To increase robustness of the scheme, the watermark is refined by the Hamming error correcting code while the encoded mark is embedded as new watermark in the transformed audio signal. Our audio watermarking algorithm is robust to common audio signal manipulations like MP3 compression, noise addition, silence addition, bit per sample conversion, noise reduction, dynamic changes and Notch filtering. Furthermore, it allows blind retrieval of embedded watermark which does not need the original audio and makes the watermark perceptually inaudible.","",""
28,"R. Gandhiraj, P. S. Sathidevi","Auditory-Based Wavelet Packet Filterbank for Speech Recognition Using Neural Network",2007,"","","","",110,"2022-07-13 09:29:07","","10.1109/ADCOM.2007.47","","",,,,,28,1.87,14,2,15,"A major problem of most speech recognition systems is their unsatisfactory robustness in noise. Human inner ear based `feature extraction' leads to very robust speech understanding in noise. This `Model of Auditory Periphery' is acting as front-end model of this speech recognition process. This paper describes two quantitative models for signal processing in auditory system (i) Gamma Tone Filter Bank (GTFB) and (ii) Wavelet Packet (WP) as front- ends for robust speech recognition. The auditory feature vectors had been used to train neural network. The classification of the feature vectors was done by the neural network using Back Propagation (BP) algorithm. The system performance was measured by recognition rate with various signal-to- noise ratios over -10 to 10 dB. The proposed system's performance was compared with various types of front-ends and recognition methods such as auditory features with Hidden Markov Model (HMM) & Layered Neural Network (LRNN), auditory features with Mel Frequency Cepstral Coefficient (MFCC) & LRNN and vocal tract model: MFCC & HMM, Dynamic time warping (DTW). The performances of proposed models with gamma tone filter bank and wavelet packet as front-ends were also compared. It had been identified that proposed system with wavelet packet as front-end and Back Propagation Neural Network (BPNN) as the recognition method is having good recognition rate over -10 to 10 dB. Both speaker independent and speaker dependent recognition systems had been designed, implemented and tested. Key words: auditory-based, speech recognition, wavelet packet, neural network","",""
34,"L. Boulogne, B. Wolf, M. Wiering, S. V. van Netten","Performance of neural networks for localizing moving objects with an artificial lateral line.",2017,"","","","",111,"2022-07-13 09:29:07","","10.1088/1748-3190/aa7fcb","","",,,,,34,6.80,9,4,5,"Fish are able to sense water flow velocities relative to their body with their mechanoreceptive lateral line organ. This organ consists of an array of flow detectors distributed along the fish body. Using the excitation of these individual detectors, fish can determine the location of nearby moving objects. Inspired by this sensory modality, it is shown here how neural networks can be used to extract an object's location from simulated excitation patterns, as can be measured along arrays of stationary artificial flow velocity sensors. The applicability, performance and robustness with respect to input noise of different neural network architectures are compared. When trained and tested under high signal to noise conditions (46 dB), the Extreme Learning Machine architecture performs best with a mean Euclidean error of 0.4% of the maximum depth of the field D, which is taken half the length of the sensor array. Under lower signal to noise conditions Echo State Networks, having recurrent connections, enhance the performance while the Multilayer Perceptron is shown to be the most noise robust architecture. Neural network performance decreased when the source moves close to the sensor array or to the sides of the array. For all considered architectures, increasing the number of detectors per array increased localization performance and robustness.","",""
24,"S. Fleming","Artificial neural network forecasting of nonlinear Markov processes",2007,"","","","",112,"2022-07-13 09:29:07","","10.1139/P07-037","","",,,,,24,1.60,24,1,15,"I assessed the performance characteristics of the feed-forward artificial neural network (ANN) as a first-order nonlinear Markov modelling technique. The ability to recover the underlying structure of five synthetic random time series was first tested. The method was then applied to an observed geophysical time series, and the results were compared against external empirical constraints and a simple representation of the underlying physics. The Monte Carlo experiments suggested that the ANN–Markov technique: (i) yields good prediction skill; (ii) in general, accurately retrieves the form of the iterative mapping, even for extremely noisy data; (iii) accomplishes the foregoing without any need to consider or adjust for the distributional characteristics of the data or driving noise; and (iv) accurately estimates the distribution of the strictly stochastic signal component. Application to a historical river-flow record again showed good forecast skill. Moreover, the robustness, flexibility, and simplicity o...","",""
12,"Taiki Ichishita, R. Fujii","Performance Evaluation of a Temporal Sequence Learning Spiking Neural Network",2007,"","","","",113,"2022-07-13 09:29:07","","10.1109/CIT.2007.64","","",,,,,12,0.80,6,2,15,"The performance evaluation of a temporal sequence learning spiking neural network was carried out. Neural network characteristics that were evaluated included: long temporal sequence length recognition, factors that affect size of the neural network, and network robustness against random input noise. Music melodies of various lengths were used as temporal sequential input data for the evaluation. Results have shown that the spiking neural network can be made to learn inter-spike time sequences comprised of as many as 900 inter-spike times. The size of the neural network was influenced by the amount and type of random noise used during the supervised learning phase. The spiking neural network system performance was approximately 90% accurate in recognizing sequences even in the presence of various types of random noise.","",""
141,"Seul Jung, T. Hsia","Neural network impedance force control of robot manipulator",1998,"","","","",114,"2022-07-13 09:29:07","","10.1109/41.679003","","",,,,,141,5.88,71,2,24,"The performance of an impedance controller for robot force tracking is affected by the uncertainties in both the robot dynamic model and environment stiffness. The purpose of this paper is to improve the controller robustness by applying the neural network (NN) technique to compensate for the uncertainties in the robot model. NN control techniques are applied to two impedance control methods: torque-based and position-based impedance control, which are distinguished by the way of the impedance functions being implemented. A novel error signal is proposed for the NN training. In addition, a trajectory modification algorithm is developed to determine the reference trajectory when the environment stiffness is unknown. The robustness analysis of this algorithm to force sensor noise and inaccurate environment position measurement is also presented. The performances of the two NN impedance control schemes are compared by computer simulations. Simulation results based on a three-degrees-of-freedom robot show that highly robust position/force tracking can be achieved in the presence of large uncertainties and force sensor noise.","",""
31,"W. Blackwell, F. Chen","Neural Network Applications in High-Resolution Atmospheric Remote Sensing",2005,"","","","",115,"2022-07-13 09:29:07","","","","",,,,,31,1.82,16,2,17,"n Estimation techniques based on neural networks are becoming more common in high-resolution atmospheric remote sensing largely because of the simplicity, flexibility, and ability of the neural network techniques to accurately represent complex multidimensional statistical relationships. Spaceborne atmospheric sounders with increasingly finer spatial and spectral resolution are generating formidable amounts of radiance data. This abundance of data presents two major challenges in the development of algorithms that retrieve geophysical information from the radiance measurements. The first challenge concerns the robustness of the retrieval operator and involves maximal use of the geophysical content of the radiance data with minimal interference from instrument and atmospheric noise. The second challenge is the implementation of the robust algorithm within a given computational budget. The neural network estimation techniques described in this article allow both of these challenges to be overcome. Sample results are presented for retrievals of (1) atmospheric temperature and moisture profiles and (2) precipitation rates.","",""
40,"C. Su, Mu-Chen Chen, H. Chan","Applying neural network and scatter search to optimize parameter design with dynamic characteristics",2005,"","","","",116,"2022-07-13 09:29:07","","10.1057/palgrave.jors.2601888","","",,,,,40,2.35,13,3,17,"","",""
110,"M. Napolitano, D. Windon, J. Casanova, M. Innocenti, G. Silvestri","Kalman filters and neural-network schemes for sensor validation in flight control systems",1998,"","","","",117,"2022-07-13 09:29:07","","10.1109/87.709495","","",,,,,110,4.58,22,5,24,"Detection, identification, and accommodation of sensor failures can be a challenging task for complex dynamic systems. This paper presents the comparison of two different approaches for the task of sensor failure detection, identification, and accommodation in a flight control system assumed to be without physical redundancy in the sensory capabilities. The first approach is based on the use of a set of online learning neural networks; the second approach is based on the use of a bank of Kalman filters. The objective is to evaluate the robustness of both schemes; the comparison is performed through testing of the schemes for several types of failures presenting different level of complexity in terms of detectability. The required computational effort for both schemes is also evaluated. For each of these failure types this comparison is performed at nominal conditions, that is with the system model and its noise perfectly modeled (with the Kalman filter scheme performing at nominal conditions), and at conditions, where discrepancies occur for the modeling of the system as well as the system and measurement noises. While the Kalman-filter-based scheme takes advantage of its robustness capabilities, the neural-network-based scheme, starting from a random numerical architecture, relies on the learning accumulated either online or from off-line simulations. The study reveals that online learning neural architectures have potential for online estimation purposes in a sensor validation scheme, particularly in the case of poorly modeled dynamics.","",""
23,"Sandeep Chandra Bollepalli, C. S. Sastry, S. Jana, Shivnarayan Patidar","Atrial fibrillation detection using convolutional neural networks",2017,"","","","",118,"2022-07-13 09:29:07","","10.22489/CINC.2017.163-226","","",,,,,23,4.60,6,4,5,"As part of the PhysioNet/Computing in Cardiology Challenge 2017, this work focuses on the classification of a single channel short electrocardiogram (ECG) signal into normal, atrial fibrillation (AF), others and noise classes. To this end, we propose a shallow convolutional neural network architecture which learns suitable features pertaining to each class while eliminating the need to extract the traditionally used ad hoc features. In particular, we first developed a robust R-peak detector and stacked sequence of fixed number of detected beats with R-peaks aligned. These stack of beats corresponding to a segment of ECG record are classified into one of the four aforementioned classes. To improve the robustness, multiple classifiers were trained to classify these segments. Overall record classification was then generated using an voting scheme from the classification results of individual segments. Our best submission result during the official phase has a score of 71% with F1 scores of 86%, 73% and 56% respectively for normal, AF and other classes respectively.","",""
1409,"David Snyder, D. Garcia-Romero, Gregory Sell, Daniel Povey, S. Khudanpur","X-Vectors: Robust DNN Embeddings for Speaker Recognition",2018,"","","","",119,"2022-07-13 09:29:07","","10.1109/ICASSP.2018.8461375","","",,,,,1409,352.25,282,5,4,"In this paper, we use data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition. The DNN, which is trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings that we call x-vectors. Prior studies have found that embeddings leverage large-scale training datasets better than i-vectors. However, it can be challenging to collect substantial quantities of labeled data for training. We use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness. The x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese. We find that while augmentation is beneficial in the PLDA classifier, it is not helpful in the i-vector extractor. However, the x-vector DNN effectively exploits data augmentation, due to its supervised training. As a result, the x-vectors achieve superior performance on the evaluation datasets.","",""
57,"T. Tian, K. Burrage","Stochastic neural network models for gene regulatory networks",2003,"","","","",120,"2022-07-13 09:29:07","","10.1109/CEC.2003.1299570","","",,,,,57,3.00,29,2,19,"Recent advances in gene-expression profiling technologies provide large amounts of gene expression data. This raises the possibility for a functional understanding of genome dynamics by means of mathematical modelling. As gene expression involves intrinsic noise, stochastic models are essential for better descriptions of gene regulatory networks. However, stochastic modelling for large scale gene expression data sets is still in the very early developmental stage. In this paper we present some stochastic models by introducing stochastic processes into neural network models that can describe intermediate regulation for large scale gene networks. Poisson random variables are used to represent chance events in the processes of synthesis and degradation. For expression data with normalized concentrations, exponential or normal random variables are used to realize fluctuations. Using a network with three genes, we show how to use stochastic simulations for studying robustness and stability properties of gene expression patterns under the influence of noise, and how to use stochastic models to predict statistical distributions of expression levels in population of cells. The discussion suggest that stochastic neural network models can give better description of gene regulatory networks and provide criteria for measuring the reasonableness o mathematical models.","",""
47,"R. Coggins, M. Jabri, B. Flower, S. Pickard","A hybrid analog and digital VLSI neural network for intracardiac morphology classification",1995,"","","","",121,"2022-07-13 09:29:07","","10.1109/4.384167","","",,,,,47,1.74,12,4,27,"Current Implantable Cardioverter Defibrillators (ICD's) use timing based decision trees for cardiac arrhythmia classification. Timing alone does not distinguish all rhythms for all patients. Hence, more computationally intensive morphology analysis is required for complete diagnosis. An analog VLSI neural network has been designed and tested to perform cardiac morphology classification tasks. Analog techniques were chosen to meet the strict power and area requirements of the implantable system while incurring the design difficulties of noise, drift and offsets inherent in analog approaches. The robustness of the neural network architecture however, to a large extent, overcomes these inherent shortcomings of the analog approach. The network is a 10:6:3 multilayer perceptron with on chip digital weight storage. The chip also includes a bucket brigade input to feed the Intracardiac Electrogram (ICEG) to the network and a Winner Take All circuit for converting classifications to a binary representation. The training system trained the network in loop and included a commercial implantable defibrillator in the signal processing path. The system has successfully distinguished two arrhythmia classes on a morphological basis for seven different patients with an average of 95% true positive and 97% true negative detections for the dangerous rhythm. The chip was implemented in 1.2 /spl mu/m CMOS and consumes less than 200 nW maximum average power from a 3 V supply in an area of 2.2/spl times/2.2 mm/sup 2/. >","",""
20,"Chin-Teng Lin, S.F. Liang, Chang-Moun Yeh, K. Fan","Fuzzy neural network design using support vector regression for function approximation with outliers",2005,"","","","",122,"2022-07-13 09:29:07","","10.1109/ICSMC.2005.1571568","","",,,,,20,1.18,5,4,17,"A fuzzy neural network based on support vector learning mechanism for function approximation is proposed in this paper. Support vector regression (SVR) is a novel method for tackling the problems of function approximation and regression estimation based on the statistical learning theory. SVR has been shown to have robust properties against noise. A novel support-vector-regression based fuzzy neural network (SVRFNN) by integrating SVR technology into FNN is developed. The SVRFNN combines the high accuracy and robustness of support vector regression (SVR) and the efficient human-like reasoning of FNN for function approximation. Experimental results show that the proposed SVFNN for function approximation can achieve good approximation performance with drastically reduced number of fuzzy kernel functions.","",""
23,"Yi Wang, B. Lawlor","Speaker recognition based on MFCC and BP neural networks",2017,"","","","",123,"2022-07-13 09:29:07","","10.1109/ISSC.2017.7983644","","",,,,,23,4.60,12,2,5,"Speaker recognition has been developed over many years and it comes with many different methods. MFCC is one of more the successful methods due to it being generally modeled on the human auditory system. It represents high success rate of recognition and strong robustness against noise in the lower frequency regions. However, in the higher frequency regions, it captures speaker characteristics information less effectively. In recent years, Artificial Neural Networks have become popular. This paper presents a speaker recognition method based on MFCC and Back-Propagation Neural Networks. Experimental studies have proven that the recognition rate is successful when the number of questionable speakers is not very larger. When the number of speakers increases, the rate of recognition decreases. The potential problems and solutions are discussed, the number of training samples must be larger than the number of network model weights, 2–10 times. When the number of speakers increases, the number of training samples required also increases significantly.","",""
38,"T. Zeppenfeld, A. Waibel","A hybrid neural network, dynamic programming word spotter",1992,"","","","",124,"2022-07-13 09:29:07","","10.1109/ICASSP.1992.226116","","",,,,,38,1.27,19,2,30,"A novel keyword-spotting system that combines both neural network and dynamic programming techniques is presented. This system makes use of the strengths of time delay neural networks (TDNNs), which include strong generalization ability, potential for parallel implementations, robustness to noise, and time shift invariant learning. Dynamic programming models are used by this system because they have the useful capability of time warping input speech patterns. This system was trained and tested on the Stonehenge Road Rally database, which is a 20-keyword-vocabulary, speaker-independent, continuous-speech corpus. Currently, this system performs at a figure of merit (FOM) rate of 82.5%. FOM is the detection rate averaged from 0 to 10 false alarms per keyword hour. This measure is explained in detail.<<ETX>>","",""
23,"Eliza A. b. Youmans, F. Lutze","Neural Network Control of Space Vehicle Intercept and Rendezvous Maneuvers",1998,"","","","",125,"2022-07-13 09:29:07","","10.2514/2.4206","","",,,,,23,0.96,12,2,24,"Neural networks are examined for use as optimal controllers. The effect of the addition of noise to the neural network input measurements is investigated to determine the performance robustness of the neural network controllers. These techniques are applied to the autonomous control of interceptor-to-target rendezvous missions. For this example, the target lies in a circular orbit and remains passive throughout the maneuver. The linearized Clohessy–Wiltshire equations with thrust are used to describe the relative motion of the two vehicles. Parameter optimization is used to generate the training data for the neural network designs. A combination of open-loop and closed-loop control is shown to work effectively for this problem.","",""
25,"Xiping Tao, Muhe Guo, Bo Zhang","A neural network approach to the elimination of road shadow for outdoor mobile robot",1997,"","","","",126,"2022-07-13 09:29:07","","10.1109/ICIPS.1997.669208","","",,,,,25,1.00,8,3,25,"A new method of road tracking oriented environmental noise elimination is presented for implementing navigation and control of land autonomous vehicles (ALV). The concept of vision based environmental noise is firstly introduced for the purpose of road and/or obstacle edge detection. Then, a representation of pyramid is proposed for vision processing. Furthermore, a fuzzy neural network is designed and implemented to recognize the environmental noises such as shadow and water prints on the road. With structure optimization by genetic algorithm and special training by classified samples, we use the network to guide our THMR-III (Tsinghua University Mobile Robot, Model 3) in the outdoor real world. Experiments have shown good properties for the ALV's ""perception-action"" behaviors, including obstacle avoidance, road following, wandering, etc. Although the work is still going on, we can see from the present results the better quality, adaptability and robustness of the above approach.","",""
26,"A. Sharaf, T. Lie, H. Gooi","Neural network based power system stabilizers",1993,"","","","",127,"2022-07-13 09:29:07","","10.1109/ANNES.1993.323018","","",,,,,26,0.90,9,3,29,"Novel power system artificial neural network (ANN) based power system stabilizers (PSSs) are presented. The two ANN-PSS designs are driven by the speed error and its rate of change. Other supplementary stabilizing signals such as voltage deviation, excursion error, and PSS output rate of change are utilized to ensure the best matching between the ANN-PSS design and the optimized conventional analog PSS benchmark model. The use of ANN based PSSs is motivated by their noise rejection and robustness under varying network topologies, loading conditions, parametric variations, and model uncertainties.<<ETX>>","",""
25,"L. Pau, F. Johansen","Neural network signal understanding for instrumentation",1990,"","","","",128,"2022-07-13 09:29:07","","10.1109/19.57233","","",,,,,25,0.78,13,2,32,"A report is presented on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation and its performance in terms of correct classification rates and robustness to noise are described. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control using functional link nets is given, and an explanation facility designed to help neural signal understanding is described. The results are compared to those obtained with a knowledge-based signal interpretation system using the same instrument and data. >","",""
32,"Mário A. T. Figueiredo, J. Leitão","Sequential and parallel image restoration: neural network implementations",1994,"","","","",129,"2022-07-13 09:29:07","","10.1109/83.336248","","",,,,,32,1.14,16,2,28,"Sequential and parallel image restoration algorithms and their implementations on neural networks are proposed. For images degraded by linear blur and contaminated by additive white Gaussian noise, maximum a posteriori (MAP) estimation and regularization theory lead to the same high dimension convex optimization problem. The commonly adopted strategy (in using neural networks for image restoration) is to map the objective function of the optimization problem into the energy of a predefined network, taking advantage of its energy minimization properties. Departing from this approach, we propose neural implementations of iterative minimization algorithms which are first proved to converge. The developed schemes are based on modified Hopfield (1985) networks of graded elements, with both sequential and parallel updating schedules. An algorithm supported on a fully standard Hopfield network (binary elements and zero autoconnections) is also considered. Robustness with respect to finite numerical precision is studied, and examples with real images are presented.","",""
26,"J. Ozard, P. Zakarauskas, P. Ko","An artificial neural network for range and depth discrimination in matched field processing",1991,"","","","",130,"2022-07-13 09:29:07","","10.1121/1.401860","","",,,,,26,0.84,9,3,31,"Associative feedforward neural networks with no hidden layers were applied to the problem of localizing a source in range and depth using the acoustic signal arriving at a vertical array of sensors. A highly processed form of the signal (excitations of an orthogonal basis) was used as input in order to increase the robustness of the trained network. The output layer consisted of one unit for each possible range and one unit for each possible depth of the source. The networks were trained with a signal‐to‐noise ratio (S/N) at the hydrophone of 50 dB, and then their performance was evaluated with S/Ns of 50 and 0 dB. Network weights were found for narrow and broad target shapes that correspond to narrow and broad beamshapes. The narrow target produced the beamformer with the lowest sidelobes and highest gains with acceptable but somewhat higher sensitivity to noise. Performance in the region for which the network was trained compared favorably with minimum variance beamforming.","",""
15,"Tadanobu Sato, Makoto Sato","Structural identification using neural network and Kalman filter algorithms",1997,"","","","",131,"2022-07-13 09:29:07","","10.2208/JSCEJ.1997.563_1","","",,,,,15,0.60,8,2,25,"The dynamic characteristics of a structural system are identified. The relevant neural network characteristics of a learning algorithm are discussed in the context of system identification. Because of the self-learning nature of the neural network the dynamic characteristics identified are strongly affected by the level of noise contained in the teaching signals. A method to identify the dynamic characteristics of a structural system proof against contaminating noise in teaching signals has been developed with the aid of the Kalman filtering technique. Numerical examples to identify dynamic response characteristics of linear and nonlinear structural systems are worked out to demonstrate the stability and robustness of the proposed algorithm.","",""
18,"Young-Sang Kim, B. Yum, Min Kim","Robust design of artificial neural network for roll force prediction in hot strip mill",2001,"","","","",132,"2022-07-13 09:29:07","","10.1109/IJCNN.2001.938817","","",,,,,18,0.86,6,3,21,"In the steel industry, a vast amount of data are gathered and stored in databases. These data usually exhibit high correlations, nonlinear relationships and low signal to noise ratios. Artificial neural networks (ANN) are known to be very useful for such data. However, selecting a suitable set of ANN parameter values is difficult even for an experienced user. This article proposes an experimental approach for determining ANN parameters in a robust manner for predicting the roll force in a hot strip mill process. Four design variables and two noise variables are included in the experiment, a full factorial design is adopted for the design matrix to estimate all main and two factor interaction effects, and the signal-to-noise (SN) ratio is used as a performance measure for achieving robustness. In the second experiment, only a fraction of the full factorial design is used as the design matrix and the results are compared with those from the full factorial experiment in terms of prediction accuracy. Experimental results show that the learning rate is the most significant parameter in terms of the SN ratio. The proposed method has a general applicability and can be used to alleviate the burden of selecting appropriate ANN parameter values.","",""
14,"T. Wong, T. Lo, H. Leung, J. Litva, É. Bossé","Low-angle radar tracking using radial basis function neural network",1993,"","","","",133,"2022-07-13 09:29:07","","10.1049/IP-F-2.1993.0045","","",,,,,14,0.48,3,5,29,"The authors apply the radial basis function (RBF) neural network to low-angle radar tracking. Computer simulations show that the RBF network is capable of tracking both stationary and moving targets with high accuracy. As well, the tracking performance of the RBF network is evaluated under different signal-to-noise ratio situations. Furthermore, real-life data are used to test the RBF network. The results demonstrate the robustness and effectiveness of the network in terms of its independence of array errors and of the nature of the noise background.","",""
17,"L. Kraft, D. Campagna","A Comparison of CMAC Neural Network and Traditional Adaptive Control Systems",1989,"","","","",134,"2022-07-13 09:29:07","","10.23919/ACC.1989.4790315","","",,,,,17,0.52,9,2,33,"A neural network based controller similar to Miller's CMAC method [6] is compared to a self-tuning regulator [2] and a Liapunov based model reference controller [8]. The three control algorithms are tested on exactly the same control problems. Results are obtained for the case where the system being controlled is linear and noise free, for the case where noise is added to the measurements, and for the case where a non-linear system is controlled. Comparisons made with respect to closed-loop system stability, speed of adaptation, noise rejection, robustness, the number of required calculations and system tracking performance indicate that the neural network approach exhibits the potential to solve some of the problems that have plagued more traditional adaptive control systems.","",""
17,"M. Cao, Yukai Ding, W. Ren, Quan Wang, M. Ragulskis, Z. Ding","Hierarchical Wavelet-Aided Neural Intelligent Identification of Structural Damage in Noisy Conditions",2017,"","","","",135,"2022-07-13 09:29:07","","10.3390/APP7040391","","",,,,,17,3.40,3,6,5,"A sophisticated hierarchical neural network model for intelligent assessment of structural damage is constructed by the synergetic action of auto-associative neural networks (AANNs) and Levenberg-Marquardt neural networks (LMNNs). With the model, AANNs aided by the wavelet packet transform are firstly employed to extract damage features from measured dynamic responses and LMNNs are then utilized to undertake damage pattern recognition. The synergetic functions endow the model with a unique mechanism of intelligent damage identification in structures. The model is applied for the identification of damage in a three-span continuous bridge, with particular emphasis on noise interference. The results show that the AANNs can produce a low-dimensional space of damage features, from which LMNNs can recognize both the location and the severity of structural damage with great accuracy and strong robustness against noise. The proposed model holds promise for developing viable intelligent damage identification technology for actual engineering structures.","",""
35,"Jingyi Hou, Xinxiao Wu, Yuchao Sun, Yunde Jia","Content-Attention Representation by Factorized Action-Scene Network for Action Recognition",2018,"","","","",136,"2022-07-13 09:29:07","","10.1109/TMM.2017.2771462","","",,,,,35,8.75,9,4,4,"During action recognition in videos, irrelevant motions in the background can greatly degrade the performance of recognizing specific actions with which we actually concern ourself here. In this paper, a novel deep neural network, called factorized action-scene network (FASNet), is proposed to encode and fuse the most relevant and informative semantic cues for action recognition. Specifically, we decompose the FASNet into two components. One is a newly designed encoding network, named content attention network (CANet), which encodes local spatial–temporal features to learn the action representations with good robustness to the noise of irrelevant motions. The other is a fusion network, which integrates the pretrained CANet to fuse the encoded spatial–temporal features with contextual scene feature extracted from the same video, for learning more descriptive and discriminative action representations. Moreover, different from the existing deep learning based tasks for generic action recognition, which applies softmax loss function as the training guidance, we formulate two loss functions for guiding the proposed model to accomplish more specific action recognition tasks, i.e., the multilabel correlation loss for multilabel action recognition and the triplet loss for complex event detection. Extensive experiments on the Hollywood2 dataset and the TRECVID MEDTest 14 dataset show that our method achieves superior performance compared with the state-of-the-art methods.","",""
44,"V. Mitra, Weiqi Wang, H. Franco, Yun Lei, C. Bartels, M. Graciarena","Evaluating robust features on deep neural networks for speech recognition in noisy and channel mismatched conditions",2014,"","","","",137,"2022-07-13 09:29:07","","","","",,,,,44,5.50,7,6,8,"Deep Neural Network (DNN) based acoustic models have shown significant improvement over their Gaussian Mixture Model (GMM) counterparts in the last few years. While several studies exist that evaluate the performance of GMM systems under noisy and channel degraded conditions, noise robustness studies on DNN systems have been far fewer. In this work we present a study exploring both conventional DNNs and deep Convolutional Neural Networks (CNN) for noiseand channel-degraded speech recognition tasks using the Aurora4 dataset. We compare the baseline mel-filterbank energies with noise-robust features that we have proposed earlier and show that the use of robust features helps to improve the performance of DNNs or CNNs compared to melfilterbank energies. We also show that vocal tract length normalization has a positive role in improving the performance of the robust acoustic features. Finally, we show that by combining multiple systems together we can achieve even further improvement in recognition accuracy.","",""
11,"D. Schonfeld","On the hysteresis and robustness of Hopfield neural networks",1993,"","","","",138,"2022-07-13 09:29:07","","10.1109/82.251846","","",,,,,11,0.38,11,1,29,"The effect of noise degradation on the Hopfield neural network is studied. The notion of a hysteresis network is defined. A noisy Hopfield neural network is subsequently proven to be a hysteresis network. The effect of the hysteresis phenomenon on the robustness of the Hopfield neural network to noise degradation is then investigated. An optimal Hopfield neural network is defined as the Hopfield neural network which minimizes an upper-bound on the probability of error. The minimal robustness indicator of a Hopfield neural network is defined. The upper bound on the probability of error of a noisy Hopfield neural network is derived in terms of the minimal robustness indicator. We finally prove that an optimal Hopfield neural network is obtained when the minimal robustness indicator is maximized. >","",""
40,"M. Kitahara, Masaki Kobayashi","Projection Rule for Rotor Hopfield Neural Networks",2014,"","","","",139,"2022-07-13 09:29:07","","10.1109/TNNLS.2013.2292706","","",,,,,40,5.00,20,2,8,"A rotor Hopfield neural network (RHNN) is an extension of a complex-valued Hopfield neural network (CHNN). RHNNs have some excellent properties. For example, the storage capacity of an RHNN is twice that of a CHNN. The most important property of an RHNN is that it does not store rotated patterns of training patterns, unlike CHNNs, which have less noise robustness because they store rotated patterns. However, conventional learning methods for RHNNs, such as Hebbian learning rule and gradient descent learning rules, present difficulties with regard to, for example, storage capacity, noise robustness, and learning time. In this paper, we propose a projection rule for RHNN and demonstrate that the noise robustness of RHNN is better than that of CHNN. The proposed algorithm improves the noise robustness of RHNN. As the number of training patterns increases, the noise robustness of CHNN rapidly deteriorates. On the other hand, the noise robustness of RHNN reduces less rapidly for the same case. Moreover, RHNN can easily recover from rotated patterns, unlike CHNN. We show this ability by computer simulation.","",""
6,"R. Masuoka","Noise robustness of EBNN learning",1993,"","","","",140,"2022-07-13 09:29:07","","10.1109/IJCNN.1993.716972","","",,,,,6,0.21,6,1,29,"A variety of methods have recently been proposed for constraining neural networks to fit various constraints while being trained. One such approach is to constrain the function approximated by the network to fit desired slopes, or derivatives. Such slopes may be provided by the designer, as in Simard's character recognizer network which was constrained so that the slope of the output with respect to translations, rotations, etc. of the input should be zero. Alternatively, target slopes may be generated automatically by program as in explanation based neural network (EBNN) learning. While slope information is known to improve generalization, sometimes slope information as well as value information is corrupted by noise. This paper explores the effects of noise in value and slope information on EBNN learning, compared with standard backpropagation. Experimental results show several characteristics of noise robustness of EBNN learning.","",""
174,"S. Sreenivasan, I. Fiete","Grid cells generate an analog error-correcting code for singularly precise neural computation",2011,"","","","",141,"2022-07-13 09:29:07","","10.1038/nn.2901","","",,,,,174,15.82,87,2,11,"","",""
18,"Dou Quan, Shuang Wang, Mengdan Ning, T. Xiong, L. Jiao","Using deep neural networks for synthetic aperture radar image registration",2016,"","","","",142,"2022-07-13 09:29:07","","10.1109/IGARSS.2016.7729723","","",,,,,18,3.00,4,5,6,"At present, the performance of image registration mainly depends on the extracted features in feature-based image registration. However, due to the speckle noise, synthetic aperture radar (SAR) image registration will have a lower accuracy and less robustness. For this purpose, we design a deep neural network (DNN) for SAR image registration, using the DNN to learn the image features, automatically. The deep learning could learn the more essential features of the images, which are make the image registration to achieve more robust features and accurate matching. Moreover, this paper proposed a new strategy to remove the wrong matching points based on the RANSAC. The experimental results on SAR image registration show that this image registration method based on DNN have a better performance, and the new RANSAC strategy could eliminate many wrong matching points and get a good transformational model.","",""
18,"S. Bianco, Luigi Celona, R. Schettini","Robust smile detection using convolutional neural networks",2016,"","","","",143,"2022-07-13 09:29:07","","10.1117/1.JEI.25.6.063002","","",,,,,18,3.00,6,3,6,"Abstract. We present a fully automated approach for smile detection. Faces are detected using a multiview face detector and aligned and scaled using automatically detected eye locations. Then, we use a convolutional neural network (CNN) to determine whether it is a smiling face or not. To this end, we investigate different shallow CNN architectures that can be trained even when the amount of learning data is limited. We evaluate our complete processing pipeline on the largest publicly available image database for smile detection in an uncontrolled scenario. We investigate the robustness of the method to different kinds of geometric transformations (rotation, translation, and scaling) due to imprecise face localization, and to several kinds of distortions (compression, noise, and blur). To the best of our knowledge, this is the first time that this type of investigation has been performed for smile detection. Experimental results show that our proposal outperforms state-of-the-art methods on both high- and low-quality images.","",""
16,"Kang Hyun Lee, S. Kang, Woohyun Kang, N. Kim","Two-stage noise aware training using asymmetric deep denoising autoencoder",2016,"","","","",144,"2022-07-13 09:29:07","","10.1109/ICASSP.2016.7472782","","",,,,,16,2.67,4,4,6,"Ever since the deep neural network (DNN)-based acoustic model appeared, the recognition performance of automatic speech recognition has been greatly improved. Due to this achievement, various researches on DNN-based technique for noise robustness are also in progress. Among these approaches, the noise-aware training (NAT) technique which aims to improve the inherent robustness of DNN using noise estimates has shown remarkable performance. However, despite the great performance, we cannot be certain whether NAT is an optimal method for sufficiently utilizing the inherent robustness of DNN. In this paper, we propose a novel technique which helps the DNN to address the complex connection between the input and target vectors of NAT smoothly. The proposed method outperformed the conventional NAT in Aurora-5 task.","",""
32,"Jürgen T. Geiger, F. Weninger, J. Gemmeke, M. Wöllmer, Björn Schuller, G. Rigoll","Memory-Enhanced Neural Networks and NMF for Robust ASR",2014,"","","","",145,"2022-07-13 09:29:07","","10.1109/TASLP.2014.2318514","","",,,,,32,4.00,5,6,8,"In this article we address the problem of distant speech recognition for reverberant noisy environments. Speech enhancement methods, e. g., using non-negative matrix factorization (NMF), are succesful in improving the robustness of ASR systems. Furthermore, discriminative training and feature transformations are employed to increase the robustness of traditional systems using Gaussian mixture models (GMM). On the other hand, acoustic models based on deep neural networks (DNN) were recently shown to outperform GMMs. In this work, we combine a state-of-the art GMM system with a deep Long Short-Term Memory (LSTM) recurrent neural network in a double-stream architecture. Such networks use memory cells in the hidden units, enabling them to learn long-range temporal context, and thus increasing the robustness against noise and reverberation. The network is trained to predict frame-wise phoneme estimates, which are converted into observation likelihoods to be used as an acoustic model. It is of particular interest whether the LSTM system is capable of improving a robust state-of-the-art GMM system, which is confirmed in the experimental results. In addition, we investigate the efficiency of NMF for speech enhancement on the front-end side. Experiments are conducted on the medium-vocabulary task of the 2nd `CHiME' Speech Separation and Recognition Challenge, which includes reverberation and highly variable noise. Experimental results show that the average word error rate of the challenge baseline is reduced by 64% relative. The best challenge entry, a noise-robust state-of-the-art recognition system, is outperformed by 25% relative.","",""
31,"Jitong Chen, Yuxuan Wang, Deliang Wang","A feature study for classification-based speech separation at very low signal-to-noise ratio",2014,"","","","",146,"2022-07-13 09:29:07","","10.1109/ICASSP.2014.6854965","","",,,,,31,3.88,10,3,8,"Speech separation is a challenging problem at low signal-to-noise ratios (SNRs). Separation can be formulated as a classification problem. In this study, we focus on the SNR level of -5 dB in which speech is generally dominated by background noise. In such a low SNR condition, extracting robust features from a noisy mixture is crucial for successful classification. Using a common neural network classifier, we systematically compare separation performance of many monaural features. In addition, we propose a new feature called Multi-Resolution Cochleagram (MRCG), which is extracted from four cochlea-grams of different resolutions to capture both local information and spectrotemporal context. Comparisons using two non-stationary noises show a range of feature robustness for speech separation with the proposed MRCG performing the best. We also find that ARMA filtering, a post-processing technique previously used for robust speech recognition, improves speech separation performance by smoothing the temporal trajectories of feature dimensions.","",""
24,"Brian Gardner, I. Sporea, André Grüning","Learning Spatiotemporally Encoded Pattern Transformations in Structured Spiking Neural Networks",2015,"","","","",147,"2022-07-13 09:29:07","","10.1162/NECO_a_00790","","",,,,,24,3.43,8,3,7,"Information encoding in the nervous system is supported through the precise spike timings of neurons; however, an understanding of the underlying processes by which such representations are formed in the first place remains an open question. Here we examine how multilayered networks of spiking neurons can learn to encode for input patterns using a fully temporal coding scheme. To this end, we introduce a new supervised learning rule, MultilayerSpiker, that can train spiking networks containing hidden layer neurons to perform transformations between spatiotemporal input and output spike patterns. The performance of the proposed learning rule is demonstrated in terms of the number of pattern mappings it can learn, the complexity of network structures it can be used on, and its classification accuracy when using multispike-based encodings. In particular, the learning rule displays robustness against input noise and can generalize well on an example data set. Our approach contributes to both a systematic understanding of how computations might take place in the nervous system and a learning rule that displays strong technical capability.","",""
21,"Masaki Kobayashi","Attractors accompanied with a training pattern of multivalued hopfield neural networks",2015,"","","","",148,"2022-07-13 09:29:07","","10.1002/tee.22053","","",,,,,21,3.00,21,1,7,"Recently, multivalued Hopfield neural networks, such as complex‐valued Hopfield neural networks, and their applications have been studied by many researchers. In their application, low noise robustness is an important problem. Too many attractors accompanied with training patterns damage the noise robustness. Rotated patterns are well‐known attractors of complex‐valued Hopfield neural networks. In the present work, we reveal that any other patterns are never attractors in complex‐valued Hopfield neural networks with a training pattern. We also prove a similar result for rotor Hopfield neural network. In addition, we investigate the relation between noise robustness and the number of attractors. © 2014 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc.","",""
283,"N. Samuel, Tzvi Diskin, A. Wiesel","Deep MIMO detection",2017,"","","","",149,"2022-07-13 09:29:07","","10.1109/SPAWC.2017.8227772","","",,,,,283,56.60,94,3,5,"In this paper, we consider the use of deep neural networks in the context of Multiple-Input-Multiple-Output (MIMO) detection. We give a brief introduction to deep learning and propose a modern neural network architecture suitable for this detection task. First, we consider the case in which the MIMO channel is constant, and we learn a detector for a specific system. Next, we consider the harder case in which the parameters are known yet changing and a single detector must be learned for all multiple varying channels. We demonstrate the performance of our deep MIMO detector using numerical simulations in comparison to competing methods including approximate message passing and semidefinite relaxation. The results show that deep networks can achieve state of the art accuracy with significantly lower complexity while providing robustness against ill conditioned channels and mis-specified noise variance.","",""
13,"A. Jalalvand, W. D. Neve, R. Walle, J. Martens","Towards using Reservoir Computing Networks for noise-robust image recognition",2016,"","","","",150,"2022-07-13 09:29:07","","10.1109/IJCNN.2016.7727398","","",,,,,13,2.17,3,4,6,"Reservoir Computing Network (RCN) is a special type of the single layer recurrent neural networks, in which the input and the recurrent connections are randomly generated and only the output weights are trained. Besides the ability to process temporal information, the key points of RCN are easy training and robustness against noise. Recently, we introduced a simple strategy to tune the parameters of RCN resulted in an effective and noise-robust RCN-based model for speech recognition. The aim of this work is to extend that study to the field of image processing. In particular, we investigate the potential of RCNs in achieving a competitive performance on the well-known MNIST dataset by following the aforementioned parameter optimizing strategy. Moreover, we achieve good noise robust recognition by utilizing such a network to denoise images and supplying them to a recognizer that is solely trained on clean images. The conducted experiments demonstrate that the proposed RCN-based handwritten digit recognizer achieves an error rate of 0.81 percent on the clean test data of the MNIST benchmark and that the proposed RCN-based denoiser can effectively reduce the error rate on the various types of noise.","",""
49,"Long Jin, Jingkun Yan, Xiujuan Du, Xiuchun Xiao, Dongyang Fu","RNN for Solving Time-Variant Generalized Sylvester Equation With Applications to Robots and Acoustic Source Localization",2020,"","","","",151,"2022-07-13 09:29:07","","10.1109/TII.2020.2964817","","",,,,,49,24.50,10,5,2,"A generalized Sylvester equation is a special formulation containing the Sylvester equation, the Lyapunov equation and the Stein equation, which is often encountered in various fields. However, the time-variant generalized Sylvester equation (TVGSE) is rarely investigated in the existing literature. In this article, we propose a noise-suppressing recurrent neural network (NSRNN) model activated by saturation-allowed functions to solve the TVGSE. For comparison, the existing zeroing neural network (ZNN) models and some improved ZNN models are introduced. Additionally, theoretical analysis on the convergence and robustness of the NSRNN model is given. Furthermore, computer simulations on illustrative examples and applications to robots and acoustic source localization are carried out. Validation results synthesized by the NSRNN model and other ZNN models are provided to illustrate the ability in solving the TVGSE and dealing with noises of the NSRNN model, and the inaction of other ZNN models to noises.","",""
15,"K. Aydin, O. Kisi","Damage diagnosis in beam-like structures by artificial neural networks",2015,"","","","",152,"2022-07-13 09:29:07","","10.3846/13923730.2014.890663","","",,,,,15,2.14,8,2,7,"AbstractApplicability of artificial neural networks is examined in determining the natural frequencies of intact beams and crack parameters of damaged beams. Multi-layer perceptron (MLP) and radial basis neural networks (RBNN) are utilized for training and validation of input data. In the first part of the study, the first four frequencies of free vibration are predicted based on beam properties by the networks. Showing the effectiveness of the neural networks in predicting the vibrational frequencies, the second part of the study is carried out. At this stage of the inverse problem, the frequencies and mode shape rotation deviations in addition to beam properties are used as input to the networks to determine the crack parameters. Different hidden nodes, epochs and spread values are tried to find the optimal neural networks that give the lowest error estimates. In both parts of the study, the RBNN model performs better. The robustness of the network models in the presence of noise is also shown. It is sh...","",""
18,"Florent Bocquelet, T. Hueber, Laurent Girin, P. Badin, B. Yvert","Robust articulatory speech synthesis using deep neural networks for BCI applications",2014,"","","","",153,"2022-07-13 09:29:07","","","","",,,,,18,2.25,4,5,8,"Brain-Computer Interfaces (BCIs) usually propose typing strategies to restore communication for paralyzed and aphasic people. A more natural way would be to use speech BCI directly controlling a speech synthesizer. Toward this goal, a prerequisite is the development a synthesizer that should i) produce intelligible speech, ii) run in real time, iii) depend on as few parameters as possible, and iv) be robust to error fluctuations on the control parameters. In this context, we describe here an articulatory-to-acoustic mapping approach based on deep neural network (DNN) trained on electromagnetic articulography (EMA) data recorded synchronously with produced speech sounds. On this corpus, the DNN-based model provided a speech synthesis quality (as assessed by automatic speech recognition and behavioral testing) comparable to a state-of-the-art Gaussian mixture model (GMM), yet showing higher robustness when noise was added to the EMA coordinates. Moreover, to envision BCI applications, this robustness was also assessed when the space covered by the 12 original articulatory parameters was reduced to 7 parameters using deep auto-encoders (DAE). Given that this method can be implemented in real time, DNN-based articulatory speech synthesis seems a good candidate for speech BCI applications. Index Terms: articulatory speech synthesis, brain computer interface (BCI), deep neural networks, deep auto-encoder, EMA, noise robustness, dimensionality reduction","",""
146,"Jong Wook Kim, J. Salamon, P. Li, J. Bello","Crepe: A Convolutional Representation for Pitch Estimation",2018,"","","","",154,"2022-07-13 09:29:07","","10.1109/ICASSP.2018.8461329","","",,,,,146,36.50,37,4,4,"The task of estimating the fundamental frequency of a monophonic sound recording, also known as pitch tracking, is fundamental to audio processing with multiple applications in speech processing and music information retrieval. To date, the best performing techniques, such as the pYIN algorithm, are based on a combination of DSP pipelines and heuristics. While such techniques perform very well on average, there remain many cases in which they fail to correctly estimate the pitch. In this paper, we propose a data-driven pitch tracking algorithm, CREPE, which is based on a deep convolutional neural network that operates directly on the time-domain waveform. We show that the proposed model produces state-of-the-art results, performing equally or better than pYIN. Furthermore, we evaluate the model's generalizability in terms of noise robustness. A pre-trained version of CREPE is made freely available as an open-source Python module for easy application.","",""
27,"Kevin Menden, M. Marouf, Sergio Oller, Anupriya Dalmia, D. S. Magruder, K. Kloiber, P. Heutink, S. Bonn","Deep learning–based cell composition analysis from tissue expression profiles",2020,"","","","",155,"2022-07-13 09:29:07","","10.1126/sciadv.aba2619","","",,,,,27,13.50,3,8,2,"Scaden enables robust cell type deconvolution of complex samples across data types, using a deep learning–based model. We present Scaden, a deep neural network for cell deconvolution that uses gene expression information to infer the cellular composition of tissues. Scaden is trained on single-cell RNA sequencing (RNA-seq) data to engineer discriminative features that confer robustness to bias and noise, making complex data preprocessing and feature selection unnecessary. We demonstrate that Scaden outperforms existing deconvolution algorithms in both precision and robustness. A single trained network reliably deconvolves bulk RNA-seq and microarray, human and mouse tissue expression data and leverages the combined information of multiple datasets. Because of this stability and flexibility, we surmise that deep learning will become an algorithmic mainstay for cell deconvolution of various data types. Scaden’s software package and web application are easy to use on new as well as diverse existing expression datasets available in public resources, deepening the molecular and cellular understanding of developmental and disease processes.","",""
33,"F. Schäfer, M. Kloc, C. Bruder, N. Lörch","A differentiable programming method for quantum control",2020,"","","","",156,"2022-07-13 09:29:07","","10.1088/2632-2153/AB9802","","",,,,,33,16.50,8,4,2,"Optimal control is highly desirable in many current quantum systems, especially to realize tasks in quantum information processing. We introduce a method based on differentiable programming to leverage explicit knowledge of the differential equations governing the dynamics of the system. In particular, a control agent is represented as a neural network that maps the state of the system at a given time to a control pulse. The parameters of this agent are optimized via gradient information obtained by direct differentiation through both the neural network \emph{and} the differential equation of the system. This fully differentiable reinforcement learning approach ultimately yields time-dependent control parameters optimizing a desired figure of merit. We demonstrate the method's viability and robustness to noise in eigenstate preparation tasks for three systems: a~single qubit, a~chain of qubits, and a quantum parametric oscillator.","",""
50,"Kunjin Chen, Jun Hu, Yu Zhang, Zhanqing Yu, Jinliang He","Fault Location in Power Distribution Systems via Deep Graph Convolutional Networks",2018,"","","","",157,"2022-07-13 09:29:07","","10.1109/JSAC.2019.2951964","","",,,,,50,12.50,10,5,4,"This paper develops a novel graph convolutional network (GCN) framework for fault location in power distribution networks. The proposed approach integrates multiple measurements at different buses while taking system topology into account. The effectiveness of the GCN model is corroborated by the IEEE 123 bus benchmark system. Simulation results show that the GCN model significantly outperforms other widely-used machine learning schemes with very high fault location accuracy. In addition, the proposed approach is robust to measurement noise and data loss errors. Data visualization results of two competing neural networks are presented to explore the mechanism of GCNs superior performance. A data augmentation procedure is proposed to increase the robustness of the model under various levels of noise and data loss errors. Further experiments show that the model can adapt to topology changes of distribution networks and perform well with a limited number of measured buses.","",""
17,"J. Schwabedal, A. Neiman, A. Shilnikov","Robust design of polyrhythmic neural circuits.",2014,"","","","",158,"2022-07-13 09:29:07","","10.1103/PHYSREVE.90.022715","","",,,,,17,2.13,6,3,8,"Neural circuit motifs producing coexistent rhythmic patterns are treated as building blocks of multifunctional neuronal networks. We study the robustness of such a motif of inhibitory model neurons to reliably sustain bursting polyrhythms under random perturbations. Without noise, the exponential stability of each of the coexisting rhythms increases with strengthened synaptic coupling, thus indicating an increased robustness. Conversely, after adding noise we find that noise-induced rhythm switching intensifies if the coupling strength is increased beyond a critical value, indicating a decreased robustness. We analyze this stochastic arrhythmia and develop a generic description of its dynamic mechanism. Based on our mechanistic insight, we show how physiological parameters of neuronal dynamics and network coupling can be balanced to enhance rhythm robustness against noise. Our findings are applicable to a broad class of relaxation-oscillator networks, including Fitzhugh-Nagumo and other Hodgkin-Huxley-type networks.","",""
13,"C. Monterola, C. Saloma","Noise-driven manifestation of learning in mature neural networks.",2002,"","","","",159,"2022-07-13 09:29:07","","10.1103/PHYSREVLETT.89.188102","","",,,,,13,0.65,7,2,20,"We show that the generalization capability of a mature thresholding neural network to process above-threshold disturbances in a noise-free environment is extended to subthreshold disturbances by ambient noise without retraining. The ability to benefit from noise is intrinsic and does not have to be learned separately. Nonlinear dependence of sensitivity with noise strength is significantly narrower than in individual threshold systems. Noise has a minimal effect on network performance for above-threshold signals. We resolve two seemingly contradictory responses of trained networks to noise-their ability to benefit from its presence and their robustness against noisy strong disturbances.","",""
142,"Hyeji Kim, Yihan Jiang, Ranvir Rana, Sreeram Kannan, Sewoong Oh, P. Viswanath","Communication Algorithms via Deep Learning",2018,"","","","",160,"2022-07-13 09:29:07","","","","",,,,,142,35.50,24,6,4,"Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parameterized by recurrent neural network (RNN) architectures. We show that creatively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong generalizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.","",""
268,"Philip Bachman, O. Alsharif, Doina Precup","Learning with Pseudo-Ensembles",2014,"","","","",161,"2022-07-13 09:29:07","","","","",,,,,268,33.50,89,3,8,"We formalize the notion of a pseudo-ensemble, a (possibly infinite) collection of child models spawned from a parent model by perturbing it according to some noise process. E.g., dropout [9] in a deep neural network trains a pseudo-ensemble of child subnetworks generated by randomly masking nodes in the parent network. We examine the relationship of pseudo-ensembles, which involve perturbation in model-space, to standard ensemble methods and existing notions of robustness, which focus on perturbation in observation-space. We present a novel regularizer based on making the behavior of a pseudo-ensemble robust with respect to the noise process generating it. In the fully-supervised setting, our regularizer matches the performance of dropout. But, unlike dropout, our regularizer naturally extends to the semi-supervised setting, where it produces state-of-the-art results. We provide a case study in which we transform the Recursive Neural Tensor Network of [19] into a pseudo-ensemble, which significantly improves its performance on a real-world sentiment analysis benchmark.","",""
69,"Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L. Hamilton","CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text",2019,"","","","",162,"2022-07-13 09:29:07","","10.18653/v1/D19-1458","","",,,,,69,23.00,14,5,3,"The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by the classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model’s ability for systematic generalization by evaluating on held-out combinations of logical rules, and allows us to evaluate a model’s robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs—with the graph-based model exhibiting both stronger generalization and greater robustness.","",""
108,"Xuanxuan Gao, Shi Jin, Chao-Kai Wen, Geoffrey Y. Li","ComNet: Combination of Deep Learning and Expert Knowledge in OFDM Receivers",2018,"","","","",163,"2022-07-13 09:29:07","","10.1109/LCOMM.2018.2877965","","",,,,,108,27.00,27,4,4,"In this letter, we propose a model-driven deep learning (DL) approach that combines DL with the expert knowledge to replace the existing orthogonal frequency-division multiplexing receiver in wireless communications. Different from the data-driven fully connected deep neural network (FC-DNN) method, we adopt the block-by-block signal processing method that divides the receiver into channel estimation subnet and signal detection subnet. Each subnet is constructed by a DNN and uses the existing simple and traditional solution as initialization. The proposed model-driven DL receiver offers more accurate channel estimation comparing with the linear minimum mean-squared error method and exhibits higher data recovery accuracy comparing with the existing methods and FC-DNN. Simulation results further demonstrate the robustness of the proposed approach in terms of signal-to-noise ratio and its superiority to the FC-DNN approach in the computational complexities or the memory usage.","",""
99,"Suraj Srinivas, F. Fleuret","Knowledge Transfer with Jacobian Matching",2018,"","","","",164,"2022-07-13 09:29:07","","","","",,,,,99,24.75,50,2,4,"Classical distillation methods transfer representations from a ""teacher"" neural network to a ""student"" network by matching their output activations. Recent methods also match the Jacobians, or the gradient of output activations with the input. However, this involves making some ad hoc decisions, in particular, the choice of the loss function.  In this paper, we first establish an equivalence between Jacobian matching and distillation with input noise, from which we derive appropriate loss functions for Jacobian matching. We then rely on this analysis to apply Jacobian matching to transfer learning by establishing equivalence of a recent transfer learning procedure to distillation.  We then show experimentally on standard image datasets that Jacobian-based penalties improve distillation, robustness to noisy inputs, and transfer learning.","",""
54,"P. Wiecha, A. Lecestre, N. Mallet, G. Larrieu","Pushing the limits of optical information storage using deep learning",2018,"","","","",165,"2022-07-13 09:29:07","","10.1038/s41565-018-0346-1","","",,,,,54,13.50,14,4,4,"","",""
46,"Yun Long, Xueyuan She, S. Mukhopadhyay","Design of Reliable DNN Accelerator with Un-reliable ReRAM",2019,"","","","",166,"2022-07-13 09:29:07","","10.23919/DATE.2019.8715178","","",,,,,46,15.33,15,3,3,"This paper presents an algorithmic approach to design reliable ReRAM based Processing-in-Memory (PIM) architecture for Deep Neural Network (DNN) acceleration under intrinsic stochastic behavior of ReRAM devices. We employ the dynamical fixed point (DFP) data representation format to adaptively change the decimal point location based on the data range, minimizing the unused most significant bits (MSBs). Further, we propose a device variability aware (DVA) training methodology where stochastic noise is added to the parameters during training to enhance the robustness of network to the parameter’s variation. Simulations indicate that, on average, the proposed algorithms improve the computing accuracy by more than 20% considering various benchmark DNNs (convolutional and recurrent). Moreover, the proposed approach enhances robustness of the DNN to noisy input data.","",""
184,"Aditi Zear, Ashutosh Kumar Singh, Pardeep Kumar","A proposed secure multiple watermarking technique based on DWT, DCT and SVD for application in medicine",2018,"","","","",167,"2022-07-13 09:29:07","","10.1007/s11042-016-3862-8","","",,,,,184,46.00,61,3,4,"","",""
38,"Teng Zhang, Shaowei Jiang, Zixin Zhao, Krishna Dixit, Xiaofei Zhou, J. Hou, Yongbing Zhang, C. Yan","Rapid and robust two-dimensional phase unwrapping via deep learning.",2019,"","","","",168,"2022-07-13 09:29:07","","10.1364/OE.27.023173","","",,,,,38,12.67,5,8,3,"Two-dimensional phase unwrapping algorithms are widely used in optical metrology and measurements. The high noise from interference measurements, however, often leads to the failure of conventional phase unwrapping algorithms. In this paper, we propose a deep convolutional neural network (DCNN) based method to perform rapid and robust two-dimensional phase unwrapping. In our approach, we employ a DCNN architecture, DeepLabV3+, with noise suppression and strong feature representation capabilities. The employed DCNN is first used to perform semantic segmentation to obtain the segmentation result of the wrapped phase map. We then combine the wrapped phase map with the segmentation result to generate the unwrapped phase. We benchmarked our results by comparing them with well-established methods. The reported approach out-performed the conventional path-dependent and path-independent algorithms. We also tested the robustness of the reported approach using interference measurements from optical metrology setups. Our results, again, clearly out-performed the conventional phase unwrap algorithms. The reported approach may find applications in optical metrology and microscopy imaging.","",""
38,"Donghan Lee, Jeong-ho Kim, Dae-woo Lee","Robust Concrete Crack Detection Using Deep Learning-Based Semantic Segmentation",2019,"","","","",169,"2022-07-13 09:29:07","","10.1007/S42405-018-0120-5","","",,,,,38,12.67,13,3,3,"","",""
34,"Wenwu Xie, Sheng Hu, Chao Yu, Peng Zhu, Xin Peng, Jingcheng Ouyang","Deep Learning in Digital Modulation Recognition Using High Order Cumulants",2019,"","","","",170,"2022-07-13 09:29:07","","10.1109/ACCESS.2019.2916833","","",,,,,34,11.33,6,6,3,"By considering the different cumulant combinations of the 2FSK, 4FSK, 2PSK, 4PSK, 2ASK, and 4ASK, this paper established new identification parameters to achieve the recognition of those digital modulations. The deep neural network (DNN) was also employed to improve the recognition rate, which was designed to classify the signal based on the distinct feature of each signal type that was extracted with high order cumulants. The extensive simulations demonstrated the exceptional classification performance for new key features based on high order cumulants. The overall success rate of the proposed algorithm was over 99% at the signal to noise ratio (SNR) of −5 dB and 100% at the SNR of −2 dB. The results of the experiments also showed the robustness of the proposed method for a variety of conditions, such as frequency offset, multi-path, and so on.","",""
42,"Mingliang Xu, Hao Su, Yafei Li, Xi Li, Jing Liao, J. Niu, Pei Lv, Bing Zhou","Stylized Aesthetic QR Code",2018,"","","","",171,"2022-07-13 09:29:07","","10.1109/TMM.2019.2891420","","",,,,,42,10.50,5,8,4,"With the continued proliferation of smart mobile devices, the Quick Response (QR) code has become one of the most-used types of two-dimensional code in the world. Aiming at beautifying the visual-unpleasant appearance of QR codes, existing works have developed a series of techniques. However, these works still leave much to be desired, such as personalization, artistry, and robustness. To address these issues, in this paper, we propose a novel type of aesthetic QR codes, Stylized aEsthEtic (SEE) QR code, and a three-stage approach to automatically produce such robust style-oriented codes. Specifically, in the first stage, we propose a method to generate an optimized baseline aesthetic QR code, which reduces the visual contrast between the noise-like black/white modules and the blended image. In the second stage, to obtain an art style QR code, we tailor an appropriate neural style transformation network to endow the baseline aesthetic QR code with artistic elements. In the third stage, we design a module-based robustness-optimization mechanism to ensure the performance robust by balancing two competing terms: visual quality and readability. Extensive experiments demonstrate that the SEE QR code has high quality in terms of both visual appearance and robustness and also offers a greater variety of personalized choices to users.","",""
689,"L. Yin, Ruikang Yang, M. Gabbouj, Y. Neuvo","Weighted median filters: a tutorial",1996,"","","","",172,"2022-07-13 09:29:07","","10.1109/82.486465","","",,,,,689,26.50,172,4,26,"Weighted Median (WM) filters have the robustness and edge preserving capability of the classical median filter and resemble linear FIR filters in certain properties. Furthermore, WM filters belong to the broad class of nonlinear filters called stack filters. This enables the use of the tools developed for the latter class in characterizing and analyzing the behavior and properties of WM filters, e.g. noise attenuation capability. The fact that WM filters are threshold functions allows the use of neural network training methods to obtain adaptive WM filters. In this tutorial paper we trace the development of the theory of WM filtering from its beginnings in the median filter to the recently developed theory of optimal weighted median filtering. Applications discussed include: idempotent weighted median filters for speech processing, adaptive weighted median and optimal weighted median filters for image and image sequence restoration, weighted medians as robust predictors in DPCM coding and Quincunx coding, and weighted median filters in scan rate conversion in normal TV and HDTV systems.","",""
154,"Pedro Tabacof, E. Valle","Exploring the space of adversarial images",2015,"","","","",173,"2022-07-13 09:29:07","","10.1109/IJCNN.2016.7727230","","",,,,,154,22.00,77,2,7,"Adversarial examples have raised questions regarding the robustness and security of deep neural networks. In this work we formalize the problem of adversarial images given a pretrained classifier, showing that even in the linear case the resulting optimization problem is nonconvex. We generate adversarial images using shallow and deep classifiers on the MNIST and ImageNet datasets. We probe the pixel space of adversarial images using noise of varying intensity and distribution. We bring novel visualizations that showcase the phenomenon and its high variability. We show that adversarial images appear in large regions in the pixel space, but that, for the same task, a shallow classifier seems more robust to adversarial images than a deep convolutional network.","",""
21,"Kevin Menden, M. Marouf, Sergio Oller, Anupriya Dalmia, K. Kloiber, P. Heutink, S. Bonn","Deep-learning-based cell composition analysis from tissue expression profiles",2019,"","","","",174,"2022-07-13 09:29:07","","10.1101/659227","","",,,,,21,7.00,3,7,3,"We present Scaden, a deep neural network for cell deconvolution that uses gene expression information to infer the cellular composition of tissues. Scaden is trained on single cell RNA-seq data to engineer discriminative features that confer robustness to bias and noise, making complex data preprocessing and feature selection unnecessary. We demonstrate that Scaden outperforms existing deconvolution algorithms in both precision and robustness. A single trained network reliably deconvolves bulk RNA-seq and microarray, human and mouse tissue expression data and leverages the combined information of multiple data sets. Due to this stability and flexibility, we surmise that deep learning will become an algorithmic mainstay for cell deconvolution of various data types. Scaden’s comprehensive software package is easy to use on novel as well as diverse existing expression datasets available in public resources, deepening the molecular and cellular understanding of developmental and disease processes.","",""
19,"Zihan Wang, Z. Ren, Chunyu He, Peng Zhang, Yue Hu","Robust Embedding with Multi-Level Structures for Link Prediction",2019,"","","","",175,"2022-07-13 09:29:07","","10.24963/ijcai.2019/728","","",,,,,19,6.33,4,5,3,"Knowledge Graph (KG) embedding has become crucial for the task of link prediction. Recent work applies encoder-decoder models to tackle this problem, where an encoder is formulated as a graph neural network (GNN) and a decoder is represented by an embedding method. These approaches enforce embedding techniques with structure information. Unfortunately, existing GNN-based frameworks still confront 3 severe problems: low representational power, stacking in a flat way, and poor robustness to noise. In this work, we propose a novel multi-level graph neural network (M-GNN) to address the above challenges. We first identify an injective aggregate scheme and design a powerful GNN layer using multi-layer perceptrons (MLPs). Then, we define graph coarsening schemes for various kinds of relations, and stack GNN layers on a series of coarsened graphs, so as to model hierarchical structures. Furthermore, attention mechanisms are adopted so that our approach can make predictions accurately even on the noisy knowledge graph. Results on WN18 and FB15k datasets show that our approach is effective in the standard link prediction task, significantly and consistently outperforming competitive baselines. Furthermore, robustness analysis on FB15k-237 dataset demonstrates that our proposed M-GNN is highly robust to sparsity and noise. ","",""
76,"Brian DePasquale, Christopher J. Cueva, Kanaka Rajan, G. S. Escola, L. Abbott","full-FORCE: A target-based method for training recurrent networks",2017,"","","","",176,"2022-07-13 09:29:07","","10.1371/journal.pone.0191527","","",,,,,76,15.20,15,5,5,"Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transformations. The method introduces a second network during training to provide suitable “target” dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network.","",""
39,"Guo-Quan Jiang, Cui-Jun Zhao","The Research of Data Mining Based on Neural Networks",,"","","","",177,"2022-07-13 09:29:07","","","","",,,,,39,0.00,20,2,,"The traditional data mining algorithms are hard to apply on noisy data, redundant information, incomplete data and sparse data in database, or the application effects are not good. But neural network have many virtues such as robustness, parallelism and anti-noise, so it is very effective on data mining in large and real databases. This paper expounds the process of data mining based neural network in detail, discusses the algorithms of classifying and clustering, indicates the problems at present and makes an expectation for the development.","",""
44,"Sining Sun, Ching-feng Yeh, Mari Ostendorf, M. Hwang, Lei Xie","Training Augmentation with Adversarial Examples for Robust Speech Recognition",2018,"","","","",178,"2022-07-13 09:29:07","","10.21437/Interspeech.2018-1247","","",,,,,44,11.00,9,5,4,"This paper explores the use of adversarial examples in training speech recognition systems to increase robustness of deep neural network acoustic models. During training, the fast gradient sign method is used to generate adversarial examples augmenting the original training data. Different from conventional data augmentation based on data transformations, the examples are dynamically generated based on current acoustic model parameters. We assess the impact of adversarial data augmentation in experiments on the Aurora-4 and CHiME-4 single-channel tasks, showing improved robustness against noise and channel variation. Further improvement is obtained when combining adversarial examples with teacher/student training, leading to a 23% relative word error rate reduction on Aurora-4.","",""
98,"Zhong-Qiu Wang, Deliang Wang","A Joint Training Framework for Robust Automatic Speech Recognition",2016,"","","","",179,"2022-07-13 09:29:07","","10.1109/TASLP.2016.2528171","","",,,,,98,16.33,49,2,6,"Robustness against noise and reverberation is critical for ASR systems deployed in real-world environments. In robust ASR, corrupted speech is normally enhanced using speech separation or enhancement algorithms before recognition. This paper presents a novel joint training framework for speech separation and recognition. The key idea is to concatenate a deep neural network (DNN) based speech separation frontend and a DNN-based acoustic model to build a larger neural network, and jointly adjust the weights in each module. This way, the separation frontend is able to provide enhanced speech desired by the acoustic model and the acoustic model can guide the separation frontend to produce more discriminative enhancement. In addition, we apply sequence training to the jointly trained DNN so that the linguistic information contained in the acoustic and language models can be back-propagated to influence the separation frontend at the training stage. To further improve the robustness, we add more noise- and reverberation-robust features for acoustic modeling. At the test stage, utterance-level unsupervised adaptation is performed to adapt the jointly trained network by learning a linear transformation of the input of the separation frontend. The resulting sequence-discriminative jointly-trained multistream system with run-time adaptation achieves 10.63% average word error rate (WER) on the test set of the reverberant and noisy CHiME-2 dataset (task-2), which represents the best performance on this dataset and a 22.75% error reduction over the best existing method.","",""
161,"Miao Hu, Hai Helen Li, Qing Wu, G. Rose","Hardware realization of BSB recall function using memristor crossbar arrays",2012,"","","","",180,"2022-07-13 09:29:07","","10.1145/2228360.2228448","","",,,,,161,16.10,40,4,10,"The Brain-State-in-a-Box (BSB) model is an auto-associative neural network that has been widely used in optical character recognition and image processing. Traditionally, the BSB model was realized at software level and carried out on high-performance computing clusters. To improve computation efficiency and reduce resources requirement, we propose a hardware realization by utilizing memristor crossbar arrays. In this work, we explore the potential of a memristor crossbar array as an auto-associative memory. More specificly, the recall function of a multi-answer character recognition based on BSB model was realized. The robustness of the proposed BSB circuit was analyzed and evaluated based on massive Monte-Carlo simulations, considering input defects, process variations, and electrical fluctuations. The physical constrains when implementing a neural network with memristor crossbar array have also been discussed. Our results show that the BSB circuit has a high tolerance to random noise. Comparably, the correlations between memristor arrays introduces directional noise and hence dominates the quality of circuits.","",""
95,"Eric Hunsberger, C. Eliasmith","Training Spiking Deep Networks for Neuromorphic Hardware",2016,"","","","",181,"2022-07-13 09:29:07","","10.13140/RG.2.2.10967.06566","","",,,,,95,15.83,48,2,6,"We describe a method to train spiking deep networks that can be run using leaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results for spiking LIF networks on five datasets, including the large ImageNet ILSVRC-2012 benchmark. Our method for transforming deep artificial neural networks into spiking networks is scalable and works with a wide range of neural nonlinearities. We achieve these results by softening the neural response function, such that its derivative remains bounded, and by training the network with noise to provide robustness against the variability introduced by spikes. Our analysis shows that implementations of these networks on neuromorphic hardware will be many times more power-efficient than the equivalent non-spiking networks on traditional hardware.","",""
27,"Qinglong Li, Xueliang Zhang, Hao Li","Online Direction of Arrival Estimation Based on Deep Learning",2018,"","","","",182,"2022-07-13 09:29:07","","10.1109/ICASSP.2018.8461386","","",,,,,27,6.75,9,3,4,"Direction of arrival (DOA) estimation is an important topic in microphone array processing. Conventional methods work well in relatively clean conditions but suffer from noise and reverberation distortions. Recently, deep learning-based methods show the robustness to noise and reverberation. However, the performance is degraded rapidly or even model cannot work when microphone array structure changes. So it has to retrain the model with new data, which is a huge work. In this paper, we propose a supervised learning algorithm for DOA estimation combining convolutional neural network (CNN) and long short term memory (LSTM). Experimental results show that the proposed method can improve the accuracy significantly. In addition, due to an input feature design, the proposed method can adapt to a new microphone array conveniently only use a very small amount of data.","",""
28,"Adam Knowles, A. Hussain, W. E. Deredy, P. Lisboa, C. Dunis","Higher Order Neural Networks with Bayesian Confidence Measure for the Prediction of the EUR/USD Exchange Rate",2009,"","","","",183,"2022-07-13 09:29:07","","10.4018/978-1-59904-897-0.CH002","","",,,,,28,2.15,6,5,13,"Multi-layer perceptrons (MLP) are the most common type of neural network in use, and their ability to perform complex non-linear mappings and tolerance to noise in data is well documented. However, MLPs also suffer long training times and often reach only local optima. Another type of network is the higher-order neural network (HONN) where joint activation terms are used, relieving the network of the task of learning the relationships between the inputs. The predictive performance of the network is tested with the EUR/USD exchange rate and evaluated using standard financial criteria including the annualized return on investment, which shows a 8% increase in the return compared with the MLP. The output of the networks that give the highest annualized return in each category was subjected to a Bayesian based confidence measure. This performance improvement may be explained by the explicit and parsimonious representation of high order terms in higher-order neural networks, which combines robustness against noise typical of distributed models together with the ability to accurately model higher-order interactions for long-term forecasting. The effectiveness of the confidence measure is explained by examining the distribution of each network's output. We speculate the distribution could be taken into account during training, thus enabling us to produce neural networks with the properties to take advantage of the confidence measure.","",""
68,"Thomas Drugman, Y. Stylianou, Yusuke Kida, M. Akamine","Voice Activity Detection: Merging Source and Filter-based Information",2016,"","","","",184,"2022-07-13 09:29:07","","10.1109/LSP.2015.2495219","","",,,,,68,11.33,17,4,6,"Voice Activity Detection (VAD) refers to the problem of distinguishing speech segments from background noise. Numerous approaches have been proposed for this purpose. Some are based on features derived from the power spectral density, others exploit the periodicity of the signal. The goal of this letter is to investigate the joint use of source and filter-based features. Interestingly, a mutual information-based assessment shows superior discrimination power for the source-related features, especially the proposed ones. The features are further the input of an artificial neural network-based classifier trained on a multi-condition database. Two strategies are proposed to merge source and filter information: feature and decision fusion. Our experiments indicate an absolute reduction of 3% of the equal error rate when using decision fusion. The final proposed system is compared to four state-of-the-art methods on 150 minutes of data recorded in real environments. Thanks to the robustness of its source-related features, its multi-condition training and its efficient information fusion, the proposed system yields over the best state-of-the-art VAD a substantial increase of accuracy across all conditions (24% absolute on average).","",""
92,"Xiaojia Zhao, Yuxuan Wang, Deliang Wang","Robust Speaker Identification in Noisy and Reverberant Conditions",2014,"","","","",185,"2022-07-13 09:29:07","","10.1109/TASLP.2014.2308398","","",,,,,92,11.50,31,3,8,"Robustness of speaker recognition systems is crucial for real-world applications, which typically contain both additive noise and room reverberation. However, the combined effects of additive noise and convolutive reverberation have been rarely studied in speaker identification (SID). This paper addresses this issue in two phases. We first remove background noise through binary masking using a deep neural network classifier. Then we perform robust SID with speaker models trained in selected reverberant conditions, on the basis of bounded marginalization and direct masking. Evaluation results show that the proposed system substantially improves SID performance over related systems in a wide range of reverberation time and signal-to-noise ratios.","",""
84,"Siqin Tao, Tao Zhang, Jun Yang, Xueqian Wang, Weining Lu","Bearing fault diagnosis method based on stacked autoencoder and softmax regression",2015,"","","","",186,"2022-07-13 09:29:07","","10.1109/CHICC.2015.7260634","","",,,,,84,12.00,17,5,7,"As bearings are the most common components of mechanical structure, it will be helpful to research bearing fault and diagnose the fault as early as possible in case of suffering greater losses. This paper proposes a deep neural network algorithm framework for bearing fault diagnosis based on stacked autoencoder and softmax regression. The simulation results verify the feasibility of the algorithm and show the excellent classification performance. In addition, this deep neural network represents strong robustness and eliminates the impact of noise remarkably. Last but not least, an integrated deep neural network method consisting of ten different structure parameter networks is proposed and it has better generalization capability.","",""
40,"Vanika Singhal, H. Aggarwal, Snigdha Tariyal, A. Majumdar","Discriminative Robust Deep Dictionary Learning for Hyperspectral Image Classification",2017,"","","","",187,"2022-07-13 09:29:07","","10.1109/TGRS.2017.2704590","","",,,,,40,8.00,10,4,5,"This paper proposes a new framework for deep learning that has been particularly tailored for hyperspectral image classification. We learn multiple levels of dictionaries in a robust fashion. The last layer is discriminative that learns a linear classifier. The training proceeds greedily; at a time, a single level of dictionary is learned and the coefficients used to train the next level. The coefficients from the final level are used for classification. Robustness is incorporated by minimizing the absolute deviations instead of the more popular Euclidean norm. The inbuilt robustness helps combat mixed noise (Gaussian and sparse) present in hyperspectral images. Results show that our proposed techniques outperform all other deep learning methods—deep belief network, stacked autoencoder, and convolutional neural network. The experiments have been carried out on both benchmark deep learning data sets (MNIST, CIFAR-10, and Street View House Numbers) as well as on real hyperspectral imaging data sets.","",""
55,"Dmitriy Serdyuk, Kartik Audhkhasi, Philemon Brakel, B. Ramabhadran, Samuel Thomas, Yoshua Bengio","Invariant Representations for Noisy Speech Recognition",2016,"","","","",188,"2022-07-13 09:29:07","","","","",,,,,55,9.17,9,6,6,"Modern automatic speech recognition (ASR) systems need to be robust under acoustic variability arising from environmental, speaker, channel, and recording conditions. Ensuring such robustness to variability is a challenge in modern day neural network-based ASR systems, especially when all types of variability are not seen during training. We attempt to address this problem by encouraging the neural network acoustic model to learn invariant feature representations. We use ideas from recent research on image generation using Generative Adversarial Networks and domain adaptation ideas extending adversarial gradient-based training. A recent work from Ganin et al. proposes to use adversarial training for image domain adaptation by using an intermediate representation from the main target classification network to deteriorate the domain classifier performance through a separate neural network. Our work focuses on investigating neural architectures which produce representations invariant to noise conditions for ASR. We evaluate the proposed architecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We show that our method generalizes better than the standard multi-condition training especially when only a few noise categories are seen during training.","",""
67,"R. Hoptroff","The principles and practice of time series forecasting and business modelling using neural nets",1993,"","","","",189,"2022-07-13 09:29:07","","10.1007/BF01411375","","",,,,,67,2.31,67,1,29,"","",""
55,"P. Rizzo, I. Bartoli, A. Marzani, F. L. D. Scalea","Defect Classification in Pipes by Neural Networks Using Multiple Guided Ultrasonic Wave Features Extracted After Wavelet Processing",2005,"","","","",190,"2022-07-13 09:29:07","","10.1115/1.1990213","","",,,,,55,3.24,14,4,17,"This paper casts pipe inspection by ultrasonic guided waves in a feature extraction and automatic classification framework. The specific defect under investigation is a small notch cut in an ASTM-A53-F steel pipe at depths ranging from 1% to 17% of the pipe cross-sectional area. A semi-analytical finite element method is first used to model wave propagation in the pipe. In the experiment, reflection measurements are taken and six features are extracted from the discrete wavelet decomposition of the raw signals and from the Hilbert and Fourier transforms of the reconstructed signals. A six-dimensional damage index is then constructed, and it is fed to an artificial neural network that classifies the size and the location of the notch. Overall, the wavelet-based multifeature analysis demonstrates good classification performance and robustness against noise and changes in some of the operating parameters.","",""
35,"Khaldoon A. Bani-Hani","Vibration control of wind‐induced response of tall buildings with an active tuned mass damper using neural networks",2007,"","","","",191,"2022-07-13 09:29:07","","10.1002/STC.85","","",,,,,35,2.33,35,1,15,"This paper introduces a new robust neural network methodology for vibration mitigation of tall building under wind excitation. The building considered is a 76‐storey 306 m concrete office tower controlled by an active tuned mass damper (ATMD). The control strategy proposes two neural network (NN) models functioning together online to control the building. The first NN predicts the building's future responses and the second mimics the inverse dynamics of the building control force model, and operates on the future response with set of if–then rules to issue the required control force. Next, both NN models operate jointly to train a separate feed‐forward neural network model designated as the NN controller (NNC). The efficacy of the two neural networks as well as the NN controller are examined and compared with a linear quadratic Gaussian controller. The controllers' performance and robustness are verified and presented, with stiffness uncertainty, time‐delay, measurements' noise and some sensor failure. The results reveal the robustness and the effectiveness of the proposed method in alleviating wind‐induced vibration for tall buildings. Copyright © 2005 John Wiley & Sons, Ltd.","",""
24,"M. Zerikat, S. Chekroun","Adaptation Learning Speed Control for a High- Performance Induction Motor using Neural Networks",2008,"","","","",192,"2022-07-13 09:29:07","","10.5281/ZENODO.1074492","","",,,,,24,1.71,12,2,14,"This paper proposes an effective adaptation learning algorithm based on artificial neural networks for speed control of an induction motor assumed to operate in a high-performance drives environment. The structure scheme consists of a neural network controller and an algorithm for changing the NN weights in order that the motor speed can accurately track of the reference command. This paper also makes uses a very realistic and practical scheme to estimate and adaptively learn the noise content in the speed load torque characteristic of the motor. The availability of the proposed controller is verified by through a laboratory implementation and under computation simulations with Matlab-software. The process is also tested for the tracking property using different types of reference signals. The performance and robustness of the proposed control scheme have evaluated under a variety of operating conditions of the induction motor drives. The obtained results demonstrate the effectiveness of the proposed control scheme system performances, both in steady state error in speed and dynamic conditions, was found to be excellent and those is not overshoot.","",""
74,"A. Ghosh, S. Raisinghani, Sunil Khubchandani","Estimation of Aircraft Lateral-Directional Parameters Using Neural Networks",1998,"","","","",193,"2022-07-13 09:29:07","","10.2514/2.2407","","",,,,,74,3.08,25,3,24,"A recently proposed method (christened ‘ ‘ the Delta method’ ’) of estimating aircraft parameters from e ight data using feed-forward neural networks is applied for the extraction of lateral ‐directional parameters from simulated as well as real-e ight data. The neural network is trained using aircraft motion and control variables as the network inputs and aerodynamic coefe cients as the network outputs; the trained network is used to predict aerodynamic coefe cients for a suitably modie ed input e le. An appropriate interpretation and manipulation of such input ‐output e les yields the estimates of the parameters. Flight data for lateral ‐directional dynamics are analyzed for various combinations and types of control inputs, and suitable control input forms are identie ed for better estimation via the proposed method. Robustness of the method with respect to measurement noise is demonstrated by its applicability to simulated e ight data with pseudomeasurement noise, and to real-e ight data.","",""
20,"Alireza Alemi, Christian K. Machens, S. Denéve, J. Slotine","Learning Nonlinear Dynamics in Efficient, Balanced Spiking Networks Using Local Plasticity Rules",2018,"","","","",194,"2022-07-13 09:29:07","","10.1609/aaai.v32i1.11320","","",,,,,20,5.00,5,4,4,"    The brain uses spikes in neural circuits to perform many dynamical computations. The computations are performed with properties such as spiking efficiency, i.e. minimal number of spikes, and robustness to noise. A major obstacle for learning computations in artificial spiking neural networks with such desired biological properties is due to lack of our understanding of how biological spiking neural networks learn computations. Here, we consider the credit assignment problem, i.e. determining the local contribution of each synapse to the network's global output error, for learning nonlinear dynamical computations in a spiking network with the desired properties of biological networks. We approach this problem by fusing the theory of efficient, balanced neural networks (EBN) with nonlinear adaptive control theory to propose a local learning rule. Locality of learning rules are ensured by feeding back into the network its own error, resulting in a learning rule depending solely on presynaptic inputs and error feedbacks. The spiking efficiency and robustness of the network are guaranteed by maintaining a tight excitatory/inhibitory balance, ensuring that each spike represents a local projection of the global output error and minimizes a loss function. The resulting networks can learn to implement complex dynamics with very small numbers of neurons and spikes, exhibit the same spike train variability as observed experimentally, and are extremely robust to noise and neuronal loss.   ","",""
20,"Zhishun Wang, B. Peterson","Constrained Least Absolute Deviation Neural Networks",2008,"","","","",195,"2022-07-13 09:29:07","","10.1109/TNN.2007.905840","","",,,,,20,1.43,10,2,14,"It is well known that least absolute deviation (LAD) criterion or -norm used for estimation of parameters is characterized by robustness, i.e., the estimated parameters are totally resistant (insensitive) to large changes in the sampled data. This is an extremely useful feature, especially, when the sampled data are known to be contaminated by occasionally occurring outliers or by spiky noise. In our previous works, we have proposed the least absolute deviation neural network (LADNN) to solve unconstrained LAD problems. The theoretical proofs and numerical simulations have shown that the LADNN is Lyapunov-stable and it can globally converge to the exact solution to a given unconstrained LAD problem. We have also demonstrated its excellent application value in time-delay estimation. More generally, a practical LAD application problem may contain some linear constraints, such as a set of equalities and/or inequalities, which is called constrained LAD problem, whereas the unconstrained LAD can be considered as a special form of the constrained LAD. In this paper, we present a new neural network called constrained least absolute deviation neural network (CLADNN) to solve general constrained LAD problems. Theoretical proofs and numerical simulations demonstrate that the proposed CLADNN is Lyapunov stable and globally converges to the exact solution to a given constrained LAD problem, independent of initial values. The numerical simulations have also illustrated that the proposed CLADNN can be used to robustly estimate parameters for nonlinear curve fitting, which is extensively used in signal and image processing.","",""
25,"H. S. Tan","Fourier neural networks and generalized single hidden layer networks in aircraft engine fault diagnostics",2006,"","","","",196,"2022-07-13 09:29:07","","10.1115/1.2179465","","",,,,,25,1.56,25,1,16,"The conventional approach to neural network-based aircraft engine fault diagnostics has been mainly via multilayer feed-forward systems with sigmoidal hidden neurons trained by back propagation as well as radial basis function networks. In this paper, we explore two novel approaches to the fault-classification problem using (i) Fourier neural networks, which synthesizes the approximation capability of multidimensional Fourier transforms and gradient-descent learning, and (ii) a class of generalized single hidden layer networks (GSLN), which self-structures via Gram-Schmidt orthonormalization. Using a simulation program for the F404 engine, we generate steady-state engine parameters corresponding to a set of combined two-module deficiencies and require various neural networks to classify the multiple faults. We show that, compared to the conventional network architecture, the Fourier neural network exhibits stronger noise robustness and the GSLNs converge at a much superior speed.","",""
40,"S. Bianco, M. Buzzelli, Davide Mazzini, R. Schettini","Logo Recognition Using CNN Features",2015,"","","","",197,"2022-07-13 09:29:07","","10.1007/978-3-319-23234-8_41","","",,,,,40,5.71,10,4,7,"","",""
62,"B. Javidi, J. Li, Q. Tang","Optical implementation of neural networks for face recognition by the use of nonlinear joint transform correlators.",1995,"","","","",198,"2022-07-13 09:29:07","","10.1364/AO.34.003950","","",,,,,62,2.30,21,3,27,"We describe a nonlinear joint transform correlator-based two-layer neural network that uses a supervised learning algorithm for real-time face recognition. The system is trained with a sequence of facial images and is able to classify an input face image in real time. Computer simulations and optical experimental results are presented. The processor can be manufactured into a compact low-cost optoelectronic system. The use of the nonlinear joint transform correlator provides good noise robustness and good image discrimination.","",""
52,"Jie Zhang, A. Morris","On-line process fault diagnosis using fuzzy neural networks",1994,"","","","",199,"2022-07-13 09:29:07","","10.1049/ISE.1994.0005","","",,,,,52,1.86,26,2,28,"The paper describes a new technique for online process fault diagnosis using fuzzy neural networks. The fuzzy neural network considered in this paper is obtained by adding a fuzzification layer to a conventional feed-forward neural network. The fuzzification layer converts the increment in each online measurement and controller output into three fuzzy sets; 'increase', 'steady' and 'decrease', with corresponding membership functions. The feed-forward neural network then classifies abnormalities, represented by fuzzy increments in online measurements and controller outputs, into various categories. The fuzzification layer can compress training data, and thereby ease training effort. Robustness of the diagnosis system is enhanced by adopting a fuzzy approach in representing abnormalities in the process. Applications of the proposed technique to the fault diagnosis of a continuous stirred tank reactor system demonstrate that the technique is robust to measurement noise, capable of diagnosing incipient faults, and requires fewer training data examples than a conventional network approach. >","",""
30,"R. D. Clay, C. Séquin","Fault tolerance training improves generalization and robustness",1992,"","","","",200,"2022-07-13 09:29:07","","10.1109/IJCNN.1992.287094","","",,,,,30,1.00,15,2,30,"A recurrent theme in the neural network literature is that noise is good. Other researchers have presented experimental evidence of improvements due to adding noise to the input data, randomly presenting data rather than cycling through it, truncating bits of the weights, using ad hoc modifications of the error signal, stochastic updating, and others. Another source of noise, one that also forces the network to develop a more robust internal representation, is proposed. During training, one randomly introduces the types of failures that one might expect to occur during operation. It is shown how this leads to significant improvements in the network's ability to avoid the overfitting problem, generalize to new data, and cope with internal failures.<<ETX>>","",""
