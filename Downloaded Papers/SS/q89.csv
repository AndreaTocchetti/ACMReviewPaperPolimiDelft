Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
2,"Sunny Raj","Towards Robust Artificial Intelligence Systems",2020,"","","","",1,"2022-07-13 09:33:38","","","","",,,,,2,1.00,2,1,2,"Adoption of deep neural networks (DNNs) into safety-critical and high-assurance systems has been hindered by the inability of DNNs to handle adversarial and out-of-distribution input. State-ofthe-art DNNs misclassify adversarial input and give high confidence output for out-of-distribution input. We attempt to solve this problem by employing two approaches, first, by detecting adversarial input and, second, by developing a confidence metric that can indicate when a DNN system has reached its limits and is not performing to the desired specifications. The effectiveness of our method at detecting adversarial input is demonstrated against the popular DeepFool adversarial image generation method. On a benchmark of 50,000 randomly chosen ImageNet adversarial images generated for CaffeNet and GoogLeNet DNNs, our method can recover the correct label with 95.76% and 97.43% accuracy, respectively. The proposed attribution-based confidence (ABC) metric utilizes attributions used to explain DNN output to characterize whether an output corresponding to an input to the DNN can be trusted. The attribution based approach removes the need to store training or test data or to train an ensemble of models to obtain confidence scores. Hence, the ABC metric can be used when only the trained DNN is available during inference. We test the effectiveness of the ABC metric against both adversarial and out-of-distribution input. We experimental demonstrate that the ABC metric is high for ImageNet input and low for adversarial input generated by FGSM, PGD, DeepFool, CW, and adversarial patch methods. For a DNN trained on MNIST images, ABC metric is high for in-distribution MNIST input and low for out-of-distribution Fashion-MNIST and notMNIST input.","",""
0,"W. Ho, Tianhao Huang, Po-Yuan Yang, J. Chou, Hong-Siang Huang, Li-Chung Chi, Fu-I Chou, J. Tsai","Artificial intelligence classification model for macular degeneration images: a robust optimization framework for residual neural networks",2021,"","","","",2,"2022-07-13 09:33:38","","10.1186/s12859-021-04085-9","","",,,,,0,0.00,0,8,1,"","",""
7,"Vinicius M. Alves, S. Auerbach, N. Kleinstreuer, J. Rooney, E. Muratov, I. Rusyn, A. Tropsha, Charles Schmitt","Curated Data In — Trustworthy In Silico Models Out: The Impact of Data Quality on the Reliability of Artificial Intelligence Models as Alternatives to Animal Testing",2021,"","","","",3,"2022-07-13 09:33:38","","10.1177/02611929211029635","","",,,,,7,7.00,1,8,1,"New Approach Methodologies (NAMs) that employ artificial intelligence (AI) for predicting adverse effects of chemicals have generated optimistic expectations as alternatives to animal testing. However, the major underappreciated challenge in developing robust and predictive AI models is the impact of the quality of the input data on the model accuracy. Indeed, poor data reproducibility and quality have been frequently cited as factors contributing to the crisis in biomedical research, as well as similar shortcomings in the fields of toxicology and chemistry. In this article, we review the most recent efforts to improve confidence in the robustness of toxicological data and investigate the impact that data curation has on the confidence in model predictions. We also present two case studies demonstrating the effect of data curation on the performance of AI models for predicting skin sensitisation and skin irritation. We show that, whereas models generated with uncurated data had a 7–24% higher correct classification rate (CCR), the perceived performance was, in fact, inflated owing to the high number of duplicates in the training set. We assert that data curation is a critical step in building computational models, to help ensure that reliable predictions of chemical toxicity are achieved through use of the models.","",""
0,"Camila Bermond Ruezzene, Renato Billia de Miranda, Talyson de Melo Bolleli, F. F. Mauad","Filling and validating rainfall data based on statistical techniques and artificial intelligence",2021,"","","","",4,"2022-07-13 09:33:38","","10.4136/ambi-agua.2767","","",,,,,0,0.00,0,4,1,"The study of the hydric regime of rainfall helps in management analysis and decision-making in hydrographic basins, but a fundamental condition is the need for continuous time series of data. Therefore, this study compared gap filling methods in precipitation data and validated them using robust statistical techniques. Precipitation data from the municipality of Itirapina, which has four monitoring stations, were used. Four gap filling techniques were used, namely: normal ratio method, inverse distance weighting, multiple regression and artificial neural networks, in the period from 1979 to 1989. For validation and performance evaluation, the coefficient of determination (R²), mean absolute error (MAE), mean squared error (RMSE), Nash-Sutcliffe coefficient (Nash), agreement index (D), confidence index were used (C) and through non-parametric techniques with Mann-Witney and Kruskal-Wallis test. Excellent performances of real data were verified in comparison with estimated data, with values above 0.8 of the coefficient of determination (R²) and of Nash. Kruskal-Wallis and Mann-Whitney tests were not significant in Stations C1 and C2, demonstrating that there is a difference between real and estimated data and between the proposed methods. It was concluded that the multiple regression and neural network methods showed the best performance. From this study, efficient tools were found to fill the gap, thus promoting better management and operation of water resources.  Keywords: artificial neural networks, inverse distance weighting, multiple regression, normal ratio method.","",""
2,"D. Denkenberger, A. Sandberg, R. Tieman, J. Pearce","Long Term Cost-Effectiveness of Resilient Foods for Global Catastrophes Compared to Artificial General Intelligence Safety",2021,"","","","",5,"2022-07-13 09:33:38","","10.31219/osf.io/vrmpf","","",,,,,2,2.00,1,4,1,"Global agricultural catastrophes, which include nuclear winter and abrupt climate change, could have long-term consequences on humanity such as the collapse and nonrecovery of civilization. Using Monte Carlo (probabilistic) models, we analyze the long-term cost-effectiveness of resilient foods (alternative foods) - roughly those independent of sunlight such as mushrooms. One version of the model populated partly by a survey of global catastrophic risk researchers finds the confidence that resilient foods is more cost effective than artificial general intelligence safety is ~86% and ~99% for the 100 millionth dollar spent on resilient foods at the margin now, respectively. Another version of the model based on one of the authors produced ~95% and ~99% confidence, respectively. Considering uncertainty represented within our models, our result is robust: reverting the conclusion required simultaneously changing the 3-5 most important parameters to the pessimistic ends. However, as predicting the long-run trajectory of human civilization is extremely difficult, and model and theory uncertainties are very large, this significantly reduces our overall confidence. Because the agricultural catastrophes could happen immediately and because existing expertise relevant to resilient foods could be co-opted by charitable giving, it is likely optimal to spend most of the money for resilient foods in the next few years. Both cause areas generally save expected current lives inexpensively and should attract greater investment.","",""
0,"Fahd Saghir, Helenio Gilabert, Bernardo Martin Mancuso","Application of Augmented Intelligence and Edge Analytics In Upstream Production Operations: An Innovative Approach for Optimizing Artificial Lift Systems Performance",2020,"","","","",6,"2022-07-13 09:33:38","","10.2118/201516-ms","","",,,,,0,0.00,0,3,2,"  With the advent of robust and powerful IIoT Edge Devices, it is now possible to deploy Machine Learning models at the boundaries of a production network, i.e. using Smart Nodes directly at the wellhead that runs analytics in near real-time. These Smart Nodes, when paired with Augmented Intelligence capabilities, allow subject matter experts to interact with Machine Learning models and help improve their accuracy over time. This, in turn, helps increase confidence in data-based results and enables operators to make informed decisions.  This paper will define and discuss an end-to-end architecture on how Augmented Intelligence, in tandem with Edge Analytics, can be implemented in the upstream production environment. Results, methodologies and lessons learnt from an Edge Analytics solution deployed on Rod Pump wells will be discussed in this paper.","",""
1,"D. Denkenberger, A. Sandberg, R. Tieman, J. Pearce","Long term cost-effectiveness of resilient foods for global catastrophes compared to artificial general intelligence",2022,"","","","",7,"2022-07-13 09:33:38","","","","",,,,,1,1.00,0,4,1,"Global agricultural catastrophes, which include nuclear winter and abrupt climate change, could have long-term consequences on humanity such as the collapse and nonrecovery of civilization. Using Monte Carlo (probabilistic) models, we analyze the long-term cost-effectiveness of resilient foods (alternative foods) - roughly those independent of sunlight such as mushrooms. One version of the model populated partly by a survey of global catastrophic risk researchers finds the confidence that resilient foods is more cost effective than artificial general intelligence safety is the 100 millionth on resilient the margin now, respectively. Another version of the model based on one of the authors produced and ∼ 99% confidence, respectively. Considering uncertainty represented within our models, our result is robust: reverting the conclusion required simultaneously changing the 3-5 most important parameters to the pessimistic ends. However, as predicting the long-run trajectory of human civilization is extremely difficult, and model and theory uncertainties are very large, this significantly reduces our overall confidence. Because the agricultural catastrophes could happen immediately and because existing expertise relevant to resilient foods could be co-opted by charitable giving, it is likely optimal to spend most of the money for resilient foods in the next few years. Both cause areas generally save expected current lives inexpensively and should attract greater investment.","",""
2,"Daniel N. Cassenti, Lance M. Kaplan","Robust uncertainty representation in human-AI collaboration",2021,"","","","",8,"2022-07-13 09:33:38","","10.1117/12.2584818","","",,,,,2,2.00,1,2,1,"Uncertainty represents the quantification of the spread of the distribution of possible ground truths that can be inferred from observed evidence. As such, uncertainty is one of the major factors in determining confidence when making decisions (i.e., uncertainty and confidence are in an inverse relationship). Bayesian statistics and subjective logic provide tools for Artificial Intelligence (AI) to derive uncertainty quantification. These processes require base rates, which are large-population determinations of probabilities that are not contextualized for the specific situation. The AI computes probabilities based upon the specific situation and context in light of historical (or training) data. As more evidence/training data is available for the context, the base rate gets washed out in the probability calculation. For most Army applications, an AI does not act or decide on its own with the rare exception of complete automaticity, but rather in collaboration with at least one human user. In this paper, we propose that the ways AI represents uncertainty ought to be optimally aligned with human preferences to provide best possible human-AI collaborative performance. Exploring this topic requires human-subjects experimentation to test how well users understand different representations of uncertainty that include base-rate information, which quantifies belief in predictions. Variations of these experiments could include different types of training to interpret uncertainty representations.","",""
0,"Chuan Zhou, Duohe Ma, Tianwei Zhang, Liming Wang","Generating Adversarial Examples for Robust Deception against Image Transfer and Reloading",2021,"","","","",9,"2022-07-13 09:33:38","","10.1109/icaice54393.2021.00159","","",,,,,0,0.00,0,4,1,"Adversarial examples play an irreplaceable role in evaluating DNNs' security and robustness. It's essential to understanding the adversarial examples' effectiveness to utilize them for model improvement. In this paper, we explore the impact of input transformation on adversarial examples. First, we discover a new phenomenon. The process of RELOAD or TRANSFER may deactivate adversarial examples' malicious functionality. The reason is that these processes would reduce pixel precision, which counters the perturbation added by the adversary. We validate this finding on different mainstream adversarial algorithms. Second, we propose a novel Confidence Iteration method, which can generate more robust adversarial examples. The key idea is to set the confidence threshold and add the pixel loss caused by image reloading or transferring into the calculation. We integrate our solution with existing adversarial algorithms. Experiments indicate that such integration can significantly increase the adversarial attacks' success rate.","",""
0,"P. Onyechi, C. Ihueze","Optimization and Intelligence Modelling of Residual Stresses in Mild Steel Plate Weldments Obtained Using Gas Tungsten Arc Welding Process",2021,"","","","",10,"2022-07-13 09:33:38","","","","",,,,,0,0.00,0,2,1,"This paper aimed at optimizing the process parameters and intelligence modelling of residual stresses in mild steel plate weldments obtained using Gas Tungsten Arc Welding (GTAW) process. Taguchi robust design and intelligent modeling techniques (artificial neural networks and extreme learning machine) were used to model the experimental results. In designing the experimental runs for this research, Taguchi design of experiment which consists of four controllable parameters at 3-levels of design for which we chose the L9 orthogonal array was used. Signaltonoise ratio (S/N) which is an important quality characteristics of Taguchi method employed the smaller-the-better criterion for residual stress response. Minitab 16 Software was used for analysis of signal-to-noise ratio and ANOVA was used to validate the results at 95% confidence level. The ANN and ELM model simulations were carried out in MATLAB 2018a environment at three different hidden neural nodes of 10, 20 and 30 neurons for thirty (30) experimental runs. ELM model showed a very good model fit at 30 neural nodes with a coefficient of determination (R) value of 99.2% which is far better than that of ANN and regression models which has R values of 96.5% and 92.4% respectively. By comparing the experimental results with those obtained using ANN and ELM models, it can be concluded that the ELM model is more efficient in predicting residual stress in mild steel plate weldments.","",""
0,"S. Rajtmajer, Christopher Griffin, Jian Wu, Robert Fraleigh, Laxmaan Balaji, A. Squicciarini, A. Kwasnica, D. Pennock, Michael Mclaughlin, Timothy J. Fritton, Nishanth Nakshatri, A. Menon, Sai Ajay Modukuri, Rajal Nivargi, Xin Wei, C. Lee Giles","A Synthetic Prediction Market for Estimating Confidence in Published Work",2021,"","","","",11,"2022-07-13 09:33:38","","10.1609/aaai.v36i11.21733","","",,,,,0,0.00,0,16,1,"Explainably estimating confidence in published scholarly work offers opportunity for faster and more robust scientific progress. We develop a synthetic prediction market to assess the credibility of published claims in the social and behavioral sciences literature. We demonstrate our system and detail our findings using a collection of known replication projects. We suggest that this work lays the foundation for a research agenda that creatively uses AI for peer review.","",""
1,"Q. Fan, E. Zou, Gangbo Sun","A robust object tracking method for infrared target",2020,"","","","",12,"2022-07-13 09:33:38","","10.1117/12.2550669","","",,,,,1,0.50,0,3,2,"Visual object tracking is one of the most attractive issue in computer vision. Recently, deep neural network has been widely developed in object tracking and showing great accuracy. In general, the accuracy of tracking task decreases dramatically when the background becomes complex or occluded. Here, we propose an end-to-end lightweight Siamese convolution neural network to achieve fast and robust target tracking especially for infrared target. The network structure replaces the hand-crafted features by the multi-layers deep convolution features of the target, so that higher precision can be achieved. Specifically, object location is updated in every frame by refreshing a response-map. However, the success rate of tracking task decreases dramatically when the background becomes complex or occluded. Consequently, a simple and robust anti-occlusion tracking method is presented. The tracking accuracy is evaluated during tracking process by computing the tracking confidence parameters. The parameters are composed of two parts: target confusion degree which indicates the degree of background interference and target occlusion degree which indicates the degree of target occlusion. Once the target is occluded, the location of the target object is corrected immediately. Experimental results demonstrate that the proposed framework achieves state-of-the-art performance on the popular OTB50 and OTB100 benchmarks.","",""
0,"Wai Mun Wong, Christopher Lim, Chia-Da Lee, Lilian Wang, Shih-Che Chen, Pei-Kuei Tsung","KRF-SLAM: A Robust AI Slam Based On Keypoint Resampling And Fusion",2020,"","","","",13,"2022-07-13 09:33:38","","10.1109/ICIP40778.2020.9191192","","",,,,,0,0.00,0,6,2,"Artificial Intelligence (AI) based feature extractors provide new possibility in the localization problem because of trainable characteristic. In this paper, the confidence information from AI learning process is used to further improve the accuracy. By resampling interest points based on different confidence thresholds, we are able to pixel-stack highlyconfident interest points to increase their bias for pose optimization. Then, the complementary descriptors are used to describe the pixel stacked interest points. As the result, the proposed Keypoint Resampling and Fusion (KRF) method improves the absolute trajectory error by 40% over state-of the-art vision SLAM algorithm on TUM Freiburg dataset. It is also more robust against tracking lost, and is compatible with existing optimizers.","",""
1,"Jiang Su-peng, Xiang Wei, Yunpeng Liu","Robust template matching algorithm with multi-feature using best-buddies similarity",2020,"","","","",14,"2022-07-13 09:33:38","","10.1117/12.2552038","","",,,,,1,0.50,0,3,2,"In order to solve the problem of matching failure of BBS (Best-Buddies Similarity) algorithm when the target image has a partial occlusion, cluttered background, imbalance illumination, and nonrigid deformation. A multi-feature template matching algorithm based on the BBS algorithm is proposed in this paper. On the basis of the location features and appearance features, we add HOG (Histogram of Oriented Gradients) features to make full use of the color, position and structural contour of the target image to match. In addition, we also perform mean filtering on the confidence map. The experimental results show that the AUC (Area Under Curve) score of the proposed algorithm is 0.6119, which is 6.38% higher than the BBS algorithm. Moreover, our algorithm has stronger robustness and higher matching accuracy.","",""
34,"Petrônio L. Braga, Adriano Oliveira, S. Meira","Software Effort Estimation Using Machine Learning Techniques with Robust Confidence Intervals",2007,"","","","",15,"2022-07-13 09:33:38","","10.1109/HIS.2007.56","","",,,,,34,2.27,11,3,15,"The precision and reliability of the estimation of the effort of software projects is very important for the competitiveness of software companies. Good estimates play a very important role in the management of software projects. Most methods proposed for effort estimation, including methods based on machine learning, provide only an estimate of the effort for a novel project. In this paper we introduce a method based on machine learning which gives the estimation of the effort together with a confidence interval for it. In our method, we propose to employ robust confidence intervals, which do not depend on the form of probability distribution of the errors in the training set. We report on a number of experiments using two datasets aimed to compare machine learning techniques for software effort estimation and to show that robust confidence intervals for the effort estimation can be successfully built.","",""
17,"S. Bharati, Soumyaroop Nandi, Yuanwei Wu, Yao Sui, Guanghui Wang","Fast and Robust Object Tracking with Adaptive Detection",2016,"","","","",16,"2022-07-13 09:33:38","","10.1109/ICTAI.2016.0112","","",,,,,17,2.83,3,5,6,"Object detection and tracking is an important research topic in computer vision with numerous practical applications. Although great progress has been made both in object detection and tracking, it is still a big challenge in automatic real-time applications. In this paper, a fast and robust approach is proposed by integrating an adaptive object detection technique within a kernelized correlation filter (KCF) framework. The KCF tracker is automatically initialized via salient object detection and localization. An adaptive object detection strategy is proposed to refine the location and boundary of the object when the tracking confidence value is below a certain threshold. In addition, a reliable post-processing technique is designed to accurately localize the object from a saliency map. Extensive quantitative and qualitative experiments on the challenging datasets have been performed to verify the proposed approach, which also demonstrates that our approach greatly outperforms the stateof-the-art methods in terms of tracking speed and accuracy.","",""
22,"M. Mitchell","Why AI is harder than we think",2021,"","","","",17,"2022-07-13 09:33:38","","10.1145/3449639.3465421","","",,,,,22,22.00,22,1,1,"Since its beginning in the 1950s, the field of artificial intelligence has cycled several times between periods of optimistic predictions and massive investment (""AI Spring"") and periods of disappointment, loss of confidence, and reduced funding (""AI Winter""). Even with today's seemingly fast pace of AI breakthroughs, the development of long-promised technologies such as self-driving cars, housekeeping robots, and conversational companions has turned out to be much harder than many people expected. One reason for these repeating cycles is our limited understanding of the nature and complexity of intelligence itself. In this talk I will discuss some fallacies in common assumptions made by AI researchers, which can lead to overconfident predictions about the field. I will also speculate on what is needed for the grand challenge of making AI systems more robust, general, and adaptable --- in short, more intelligent.","",""
29,"J. G. M. S. Decanini, Mauro Tonelli-Neto, C. R. Minussi","Robust fault diagnosis in power distribution systems based on fuzzy ARTMAP neural network-aided evidence theory",2012,"","","","",18,"2022-07-13 09:33:38","","10.1049/IET-GTD.2012.0028","","",,,,,29,2.90,10,3,10,"The present study proposes a methodology for the automatic diagnosis of short-circuit faults in distribution systems using modern techniques for signal analysis and artificial intelligence. This support tool for decision making accelerates the restoration process, providing greater security, reliability and profitability to utilities. The fault detection procedure is performed using statistical and direct analyses of the current waveforms in the wavelet domain. Current and voltage signal features are extracted using discrete wavelet transform, multi-resolution analysis and energy concept. These behavioural indices correspond to the input vectors of three parallel sets of fuzzy ARTMAP neural networks. The network outcomes are integrated by the Dempster-Shafer theory, giving quantitative information about the diagnosis and its reliability. Tests were carried out using a practical distribution feeder from a Brazilian electric utility, and the results show that the method is efficient with a high level of confidence.","",""
105,"M. Yamada, Yutaka Saito, Hitoshi Imaoka, M. Saiko, Shigemi Yamada, Hiroko Kondo, H. Takamaru, T. Sakamoto, J. Sese, A. Kuchiba, Taro Shibata, R. Hamamoto","Development of a real-time endoscopic image diagnosis support system using deep learning technology in colonoscopy",2019,"","","","",19,"2022-07-13 09:33:38","","10.1038/s41598-019-50567-5","","",,,,,105,35.00,11,12,3,"","",""
2,"Aidan Murphy, Gráinne Murphy, Jorge Amaral, D. M. Dias, Enrique Naredo, C. Ryan","Towards Incorporating Human Knowledge in Fuzzy Pattern Tree Evolution",2021,"","","","",20,"2022-07-13 09:33:38","","10.1007/978-3-030-72812-0_5","","",,,,,2,2.00,0,6,1,"","",""
1,"Anuj Tambwekar, Anirudh Maiya, S. Dhavala, Snehanshu Saha","Estimation and Applications of Quantiles in Deep Binary Classification",2021,"","","","",21,"2022-07-13 09:33:38","","10.1109/tai.2021.3115078","","",,,,,1,1.00,0,4,1,"Conditional quantiles obtained via regression are used as a robust alternative to classical conditional means in econometrics and statistics, as they can capture the uncertainty in a prediction, and model tail behaviors, while making very few distributional assumptions. In this work, we extend the notion of conditional quantiles to the binary classification setting—allowing us to quantify the uncertainty in the predictions, increase resilience to label noise, and provide new insights into the functions learnt by the models. We accomplish this by defining a new loss called binary quantile regression loss. We compute the Lipschitz constant of the proposed loss and show that its curvature is bounded under some regularity conditions. These properties are later used to characterize the error rates of the learning algorithms and to accelerate the training regime with using Lipschitz adaptive learning rates. We leverage the estimated quantiles to obtain individualized confidence scores that provide an accurate measure of a prediction being misclassified. We aggregate these scores to provide two additional metrics, namely, confidence score and retention rate, which can be used to withhold decisions and increase model accuracy. We also study the robustness of the proposed nonparametric binary quantile classification framework, and finally, we demonstrate that quantiles aid in explainability as they can be used to obtain several univariate summary statistics that can be directly applied to existing explanation tools.","",""
20,"I. Cortés-Ciriano, A. Bender","Concepts and Applications of Conformal Prediction in Computational Drug Discovery",2019,"","","","",22,"2022-07-13 09:33:38","","10.1039/9781788016841-00063","","",,,,,20,6.67,10,2,3,"Estimating the reliability of individual predictions is key to increase the adoption of computational models and artificial intelligence in preclinical drug discovery, as well as to foster its application to guide decision making in clinical settings. Among the large number of algorithms developed over the last decades to compute prediction errors, Conformal Prediction (CP) has gained increasing attention in the computational drug discovery community. A major reason for its recent popularity is the ease of interpretation of the computed prediction errors in both classification and regression tasks. For instance, at a confidence level of 90% the true value will be within the predicted confidence intervals in at least 90% of the cases. This so called validity of conformal predictors is guaranteed by the robust mathematical foundation underlying CP. The versatility of CP relies on its minimal computational footprint, as it can be easily coupled to any machine learning algorithm at little computational cost. In this review, we summarize underlying concepts and practical applications of CP with a particular focus on virtual screening and activity modelling, and list open source implementations of relevant software. Finally, we describe the current limitations in the field, and provide a perspective on future opportunities for CP in preclinical and clinical drug discovery.","",""
1,"Hussah Talal, Rachid Zagrouba","MADS Based on DL Techniques on the Internet of Things (IoT): Survey",2021,"","","","",23,"2022-07-13 09:33:38","","10.3390/electronics10212598","","",,,,,1,1.00,1,2,1,"Technologically speaking, humanity lives in an age of evolution, prosperity, and great development, as a new generation of the Internet has emerged; it is the Internet of Things (IoT) which controls all aspects of lives, from the different devices of the home to the large industries. Despite the tremendous benefits offered by IoT, still there are some challenges regarding privacy and information security. The traditional techniques used in Malware Anomaly Detection Systems (MADS) could not give us as robust protection as we need in IoT environments. Therefore, it needed to be replaced with Deep Learning (DL) techniques to improve the MADS and provide the intelligence solutions to protect against malware, attacks, and intrusions, in order to preserve the privacy of users and increase their confidence in and dependence on IoT systems. This research presents a comprehensive study on security solutions in IoT applications, Intrusion Detection Systems (IDS), Malware Detection Systems (MDS), and the role of artificial intelligent (AI) in improving security in IoT.","",""
0,"E. Blasch, Haoran Li, Zhihao Ma, Yang Weng","The Powerful Use of AI in the Energy Sector: Intelligent Forecasting",2021,"","","","",24,"2022-07-13 09:33:38","","","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) techniques continue to broaden across governmental and public sectors, such as power and energy which serve as critical infrastructures for most societal operations. However, due to the requirements of reliability, accountability, and explainability, it is risky to directly apply AI-based methods to power systems because society cannot afford cascading failures and large-scale blackouts, which easily cost billions of dollars. To meet society requirements, this paper proposes a methodology to develop, deploy, and evaluate AI systems in the energy sector by: (1) understanding the power system measurements with physics, (2) designing AI algorithms to forecast the need, (3) developing robust and accountable AI methods, and (4) creating reliable measures to evaluate the performance of the AI model. The goal is to provide a high level of confidence to energy utility users. For illustration purposes, the paper uses power system event forecasting (PEF) as an example, which carefully analyzes synchrophasor patterns measured by the Phasor Measurement Units (PMUs). Such a physical understanding leads to a data-driven framework that reduces the dimensionality with physics and forecasts the event with high credibility. Specifically, for dimensionality reduction, machine learning arranges physical information from different dimensions, resulting inefficient information extraction. For event forecasting, the supervised learning model fuses the results of different models to increase the confidence. Finally, comprehensive experiments demonstrate the high accuracy, efficiency, and reliability as compared to other state-of-the-art machine learning methods.","",""
0,"Tapadhir Das, R. Shukla, S. Sengupta","The Devil is in the Details: Confident & Explainable Anomaly Detector for Software-Defined Networks",2021,"","","","",25,"2022-07-13 09:33:38","","10.1109/nca53618.2021.9685157","","",,,,,0,0.00,0,3,1,"Deployment of SDN control plane in high-end servers allow many network applications to be automated and easily managed. In this paper, we propose an SDN anomaly detection application, Confident and Explainable Anomaly Detector (CEAD), that automatically detects malicious network flows in SDN-based network architectures. The proposed application employs a set of Machine Learning (ML) classifiers to improve the confidence score of a prediction, thereby creating improved trust upon the prediction, while providing interpretability to the anomaly detector. The method utilizes the Explainable Artificial Intelligence (XAI) framework to provide interpretation to predictions to unearth network features that establish the most influence between predicted anomaly types. Results show that the proposed framework can achieve efficient anomaly detection performance, with near perfect confidence scores. Analysis with XAI highlights that byte and packet transmissions, and their robust statistics, can be significant indicators for prevalence of any attacks. Results also indicate that a subset of influential features can generally be used to decipher between normal and anomalous flow, while certain dataset features can be specifically influential in detecting specific attack types. This can lead to more efficient network resource utilization.","",""
0,"E. F. Neto, G. P. Oliveira, R. M. Magalhães, L. Batista, L. A. F. Cabral, Moisés D. Santos","Cumulative oil production in flow unit-crossing wells estimated by multilayer perceptron networks",2021,"","","","",26,"2022-07-13 09:33:38","","10.1007/s13202-021-01170-w","","",,,,,0,0.00,0,6,1,"","",""
0,"Weijie Kang, Junjie Xue, Jiyang Xiao, Haizhen Zhu, Jianfeng Li, Changjun Li","Multimode Generative Adversarial Networks for Sequence Data Generation",2021,"","","","",27,"2022-07-13 09:33:38","","10.1088/1742-6596/1827/1/012209","","",,,,,0,0.00,0,6,1,"As a new type of artificial intelligence technology, generative adversarial network (GAN) has good data understanding and generation capabilities, and has a wide range of application prospects in the fields of image and speech. However, due to the lack of prior knowledge, its training process is less robust and prone to occur the pattern ignore. Its development is restricted to a certain extent, and its application scope still needs to be expanded. To solve the above problems, this paper introduces a knowledge confidence multimode GAN (KC-MGAN) algorithm, calculates the confidence of the input data through the reasoning method, and then puts the confidence and the input data into the GAN system to generate new sample data. During the training process, the confidence of the input data is continuously calculated, while the generated data samples are continuously evaluated. The training process will end until the GAN system reaches a stable condition. Finally, this paper takes the generation of UAV flight trajectory data as an example to verify the effectiveness of the proposed method. Some explorations have been made for the application of data generation and GAN’s training mode with the prior knowledge.","",""
0,"Suruchi Gupta, I. Ullah, M. Madden","Coyote: A Dataset of Challenging Scenarios in Visual Perception for Autonomous Vehicles",2021,"","","","",28,"2022-07-13 09:33:38","","","","",,,,,0,0.00,0,3,1,"Recent advances in Artificial Intelligence have immense potential for the realization of self-driving applications. In particular, deep neural networks are being applied to object detection and semantic segmentation, to support the operation of semiautonomous vehicles. While full Level 5 autonomy is not yet available, elements of these technologies are being brought to market in advanced driver assistance systems that provide partial automation at Level 2 and 3. However, multiple studies have demonstrated that current state-of-the-art deep learning models can make high-confidence but incorrect predictions. In the context of a critical application such as understanding the scene in front of a vehicle, which must be robust, accurate and in real-time, such failures raise concerns; most significantly, they may pose a substantial threat to the safety of the vehicle’s occupants and other people with whom the vehicle shares the road. To examine the challenges of current computer vision approaches in the context of autonomous and semi-autonomous vehicles, we have created a new test dataset, called Coyote1, with photographs that can be understood correctly by humans but might not be successfully parsed by current state-of-theart image recognition systems. The dataset has 894 photographs with over 1700 ground-truth labels, grouped into 6 broad categories. We have tested the dataset against existing stateof-the-art object detection (YOLOv3 & Faster RCNN) and semantic segmentation (DeepLabv3) models to measure the models’ performance and identify situations that might be a source of risk to transportation safety. Our results demonstrate that these models can be confused for various adversarial examples resulting in lower performance than expected: YOLOv3 achieves an accuracy of 49% and precision of 62%, while Faster R-CNN achieves an accuracy of 52% and precision of 60%. ∗Contact Author https://github.com/Suruchidgupta/ UniversalAdversarialChallenges-AutonomousVehicles","",""
0,"Rakesh Choudhary, Dhadma Balachandran, Jonathan Folmsbee, Jawaria Rahman, M. Brandwein, Scott Doyle","Automatic flagging of AI segmentation errors in computational pathology",2022,"","","","",29,"2022-07-13 09:33:38","","10.1117/12.2613194","","",,,,,0,0.00,0,6,1,"Active Learning (AL) is an artificial intelligence (AI) training paradigm that improves training efficiency in cases where labeled training is hard to obtain. In AL, unlabeled samples are selected for annotation using a bootstrap classifier to identify samples whose informational content is not represented in the current training set. Given a small number of samples, this optimizes training by focusing annotation on “informative” samples. For computational pathology, identifying the most-informative samples is non-trivial, particularly for segmentation. In this work, we develop a feature-driven approach to identifying informative samples. We use a feature extraction pipeline operating on segmentation results to find “outlier” samples which are likely incorrectly segmented. This process allows us to automatically flag samples for re-annotation based on architecture of segmentation (compared with less robust confidence-based approaches). We apply this process to the problem of segmenting oral cavity cancer (OCC) H&E stained whole-slide images (WSIs), where the architecture of OCC tumor growth is an aggressive pathological indicator. Improving segmentation requires costly annotation of WSIs; thus, we seek to employ an AL approach to improve annotation efficiency. Our results show that, while outlier features alone are not sufficient to flag samples for re-annotation, we can identify some WSIs which fail segmentation.","",""
0,"Neythen J. Treloar, Nathan Braniff, B. Ingalls, C. Barnes","Deep Reinforcement Learning for Optimal Experimental Design in Biology",2022,"","","","",30,"2022-07-13 09:33:38","","10.1101/2022.05.09.491138","","",,,,,0,0.00,0,4,1,"The field of optimal experimental design uses mathematical techniques to determine experiments that are maximally informative from a given experimental setup. Here we apply a technique from artificial intelligence—reinforcement learning—to the optimal experimental design task of maximizing confidence in estimates of model parameter values. We show that a reinforcement learning approach performs favourably in comparison with a one-step ahead optimisation algorithm and a model predictive controller for the inference of bacterial growth parameters in a simulated chemostat. Further, we demonstrate the ability of reinforcement learning to train over a distribution of parameters, indicating that this approach is robust to parametric uncertainty. 1 Author summary Biological systems are often complex and typically exhibit non-linear behaviour, making accurate model parametrisation difficult. Optimal experimental design tools help address this problem by identifying experiments that are predicted to provide maximally accurate parameter estimates. In this work we use reinforcement learning, an artificial intelligence method, to determine such experiments. Our simulation studies show that this approach allows uncertainty in model parameterisation to be directly incorporated into the search for optimal experiments, opening a practical avenue for training an experimental controller without confident knowledge of the system’s parameter values. We present this method as complementary to existing optimisation approaches and we anticipate that artificial intelligence has a fundamental role to play in the future of optimal experimental design.","",""
0,"Aidan Murphy, Gráinne Murphy, D. M. Dias, Jorge Amaral, Enrique Naredo, C. Ryan","Human in the Loop Fuzzy Pattern Tree Evolution",2022,"","","","",31,"2022-07-13 09:33:38","","10.1007/s42979-022-01044-w","","",,,,,0,0.00,0,6,1,"","",""
0,"Xin Qiu, R. Miikkulainen","Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model",2020,"","","","",32,"2022-07-13 09:33:38","","10.1609/aaai.v36i7.20773","","",,,,,0,0.00,0,2,2,"As neural network classifiers are deployed in real-world applications, it is crucial that their failures can be detected reliably. One practical solution is to assign confidence scores to each prediction, then use these scores to filter out possible misclassifications. However, existing confidence metrics are not yet sufficiently reliable for this role. This paper presents a new framework that produces a quantitative metric for detecting misclassification errors. This framework, RED, builds an error detector on top of the base classifier and estimates uncertainty of the detection scores using Gaussian Processes. Experimental comparisons with other error detection methods on 125 UCI datasets demonstrate that this approach is effective. Further implementations on two probabilistic base classifiers and two large deep learning architecture in vision tasks further confirm that the method is robust and scalable. Third, an empirical analysis of RED with out-of-distribution and adversarial samples shows that the method can be used not only to detect errors but also to understand where they come from. RED can thereby be used to improve trustworthiness of neural network classifiers more broadly in the future.","",""
29,"M. Ertz, É. Boily","The Rise of the Digital Economy: Thoughts on Blockchain Technology and Cryptocurrencies for the Collaborative Economy",2019,"","","","",33,"2022-07-13 09:33:38","","10.2139/ssrn.3502730","","",,,,,29,9.67,15,2,3,"Abstract This study highlights the potential impacts of blockchain technology on the collaborative economy (CE), colloquially known as the sharing economy. This conceptual review first analyzes how the CE intersects with the blockchain technology. Collaborative consumption involves an intensification of peer-to-peer trade, underpinned by robust digital infrastructures and processes, hence an increased use of new technologies and a redefinition of business activities. As an inherently connected economy, the CE is, therefore, prone to integrating the most recent technological advances including artificial intelligence, big data analysis, augmented reality, the smart grid, and blockchain technology. This review then furthers the examination of the organizational and managerial implications related to the use of blockchain technology in terms of governance, transaction costs, and user confidence. A closing case finally examines the role of a prominent social networking site (i.e., Facebook) in the CE-blockchain nexus.","",""
3,"M. Ertz, É. Boily","When Giants Meet",2020,"","","","",34,"2022-07-13 09:33:38","","10.4018/978-1-7998-4543-0.ch005","","",,,,,3,1.50,2,2,2,"The collaborative economy (CE) involves an intensification of direct or intermediated peer-to-peer trade, underpinned by robust digital infrastructures and processes, hence an increased use of new technologies and a redefinition of business activities. As an inherently connected economy, the CE is, therefore, prone to integrating the most recent technological advances including artificial intelligence, big data analysis, augmented reality, the smart grid, and blockchain technology. As an innovative payment and finance technology, the blockchain and cryptocurrencies could have potential implications for the CE. This chapter consists of a conceptual review analyzing how the CE connects with the blockchain technology. The chapter presents subsequently the organizational and managerial implications related to the use of blockchain technology in terms of governance, transaction costs, and user confidence. An illustrative case further examines the role of a prominent social media in the CE-blockchain nexus.","",""
1,"Junbin Chen, Longcan Liu, Ruyi Huang, Weihua Li","Deep Feature-aligned Convolutional Neural Network for Machinery Fault Diagnosis",2020,"","","","",35,"2022-07-13 09:33:38","","10.1109/ICSMD50554.2020.9261675","","",,,,,1,0.50,0,4,2,"Convolutional neural network (CNN) has been witness to remarkable development and application over the past decade in the field of fault diagnosis. However, it has an obvious limitation that the property of shift-invariance in CNN is not robust enough, resulting in insufficient robustness of feature extraction, which is manifested by fluctuant prediction accuracy and confidence. Aiming at overcoming such limitation, in this paper, a deep feature alignment method is proposed for extracting aligned features from periodical vibration signals, and applied for the fault diagnosis of rotating machinery. First, considering the periodicity of bearing vibration signals, a feature-aligned CNN (FACNN) architecture is constructed to improve the shift-invariance of CNN. Second, the performance of the proposed structure is compared with the traditional CNN in three aspects: diagnosis accuracy, prediction confidence and feature robustness. Finally, a bearing fault diagnosis case was carried out on an experimental setup of machine tool to validate the effectiveness of FACNN. Experimental results have shown the FACNN outperforms the traditional CNN in the task of fault diagnosis for rotating machinery.","",""
0,"Sanghyuk Lee, Sang-Gue Park, Chan Kyu Lee, Yaeji Lim","Statistical analysis of the employment future for Korea",2020,"","","","",36,"2022-07-13 09:33:38","","10.29220/csam.2020.27.4.459","","",,,,,0,0.00,0,4,2,"We examine the rate of substitution of jobs by artificial intelligence using a score called the “weighted ability rate of substitution (WARS).”WARS is a indicator that represents each job’s potential for substitution by automation and digitalization. Since the conventionalWARS is sensitive to the particular responses from the employees, we consider a robust version of the indicator. In this paper, we propose the individualized WARS, which is a modification of the conventional WARS, and compute robust averages and confidence intervals for inference. In addition, we use the clustering method to statistically classify jobs according to the proposed individualized WARS. The proposed method is applied to Korean job data, and proposed WARS are computed for five future years. Also, we observe that 747 jobs are well-clustered according to the substitution levels.","",""
69,"Gilbert Lim, Yuan Cheng, W. Hsu, M. Lee","Integrated Optic Disc and Cup Segmentation with Deep Learning",2015,"","","","",37,"2022-07-13 09:33:38","","10.1109/ICTAI.2015.36","","",,,,,69,9.86,17,4,7,"Glaucoma is a widespread ocular disorder leading to irreversible loss of vision. Therefore, there is a pressing need for cost-effective screening, such that preventive measures can be taken. This can be achieved with an accurate segmentation of the optic disc and cup from retinal images to obtain the cup-to-disc ratio. We describe a comprehensive solution based on applying convolutional neural networks to feature exaggerated inputs emphasizing disc pallor without blood vessel obstruction, as well as the degree of vessel kinking. The produced raw probability maps then undergo a robust refinement procedure that takes into account prior knowledge about retinal structures. Analysis of these probability maps further allows us to obtain a confidence estimate on the correctness of the segmentation, which can be used to direct the most challenging cases for manual inspection. Tests on two large real-world databases, including the publicly-available MESSIDOR collection, demonstrate the effectiveness of our proposed system.","",""
21,"H. Zaidi, A. Alavi, I. E. Naqa","Novel Quantitative PET Techniques for Clinical Decision Support in Oncology.",2018,"","","","",38,"2022-07-13 09:33:38","","10.1053/j.semnuclmed.2018.07.003","","",,,,,21,5.25,7,3,4,"Quantitative image analysis has deep roots in the usage of positron emission tomography (PET) in clinical and research settings to address a wide variety of diseases. It has been extensively employed to assess molecular and physiological biomarkers in vivo in healthy and disease states, in oncology, cardiology, neurology, and psychiatry. Quantitative PET allows relating the time-varying activity concentration in tissues/organs of interest and the basic functional parameters governing the biological processes being studied. Yet, quantitative PET is challenged by a number of degrading physical factors related to the physics of PET imaging, the limitations of the instrumentation used, and the physiological status of the patient. Moreover, there is no consensus on the most reliable and robust image-derived PET metric(s) that can be used with confidence in clinical oncology owing to the discrepancies between the conclusions reported in the literature. There is also increasing interest in the use of artificial intelligence based techniques, particularly machine learning and deep learning techniques in a variety of applications to extract quantitative features (radiomics) from PET including image segmentation and outcome prediction in clinical oncology. These novel techniques are revolutionizing clinical practice and are now offering unique capabilities to the clinical molecular imaging community and biomedical researchers at large. In this report, we summarize recent developments and future tendencies in quantitative PET imaging and present example applications in clinical decision support to illustrate its potential in the context of clinical oncology.","",""
5,"Xiaoyang Huang, Jiancheng Yang, Linguo Li, Haoran Deng, Bingbing Ni, Yi Xu","Evaluating and Boosting Uncertainty Quantification in Classification",2019,"","","","",39,"2022-07-13 09:33:38","","","","",,,,,5,1.67,1,6,3,"Emergence of artificial intelligence techniques in biomedical applications urges the researchers to pay more attention on the uncertainty quantification (UQ) in machine-assisted medical decision making. For classification tasks, prior studies on UQ are difficult to compare with each other, due to the lack of a unified quantitative evaluation metric. Considering that well-performing UQ models ought to know when the classification models act incorrectly, we design a new evaluation metric, area under Confidence-Classification Characteristic curves (AUCCC), to quantitatively evaluate the performance of the UQ models. AUCCC is threshold-free, robust to perturbation, and insensitive to the classification performance. We evaluate several UQ methods (e.g., max softmax output) with AUCCC to validate its effectiveness. Furthermore, a simple scheme, named Uncertainty Distillation (UDist), is developed to boost the UQ performance, where a confidence model is distilling the confidence estimated by deep ensembles. The proposed method is easy to implement; it consistently outperforms strong baselines on natural and medical image datasets in our experiments.","",""
8,"H. Lau, Thomas Ou, Melvyn Sim","Robust temporal constraint network",2005,"","","","",40,"2022-07-13 09:33:38","","10.1109/ICTAI.2005.111","","",,,,,8,0.47,3,3,17,"In this paper, we propose the robust temporal constraint network (RTCN) model for simple temporal constraint networks where activity durations are bounded by random variables. The problem is to determine whether such temporal network can be executed with failure probability less than a given 0 les epsi les 1 for each possible instantiation of the random variables, and if so, how one might find a feasible schedule with each given instantiation. The advantage of our model is that one can vary the value of epsi to control the level of conservativeness of the solution. We present a computationally tractable and efficient approach to solve these RTCN problems. We study the effects the density of temporal constraint networks have on its makespan under different confidence levels. We also apply RTCN to solve the stochastic project crashing problem","",""
2,"Diego Aparicio, M. L. Prado","How Hard Is It to Pick the Right Model? MCS and Backtest Overfitting",2017,"","","","",41,"2022-07-13 09:33:38","","10.2139/ssrn.3044740","","",,,,,2,0.40,1,2,5,"Recent advances in machine learning, artificial intelligence, and the availability of billions of high frequency data signals have made model selection a challenging and pressing need. However, most of the model selection methods available in modern finance are subject to backtest overfitting. This is the probability that one will select a financial strategy that outperforms during backtest, but underperforms in practice. We evaluate the performance of the novel model confidence set (MCS) introduced in Hansen et al. (2011a) in a simple machine learning trading strategy problem. We find that MCS is not robust to multiple testing and that it requires a very high signal-to-noise ratio to be utilizable. More generally, we raise awareness on the limitations of model selection in finance.","",""
17,"T. Pham, Hong Le, Nang-Toan Do","Offline handwritten signature verification using local and global features",2015,"","","","",42,"2022-07-13 09:33:38","","10.1007/s10472-014-9427-5","","",,,,,17,2.43,6,3,7,"","",""
4,"A. Mazyad, F. Teytaud, C. Fonlupt","MONTE-CARLO TREE SEARCH FOR THE ""MR JACK"" BOARD GAME",2015,"","","","",43,"2022-07-13 09:33:38","","10.5121/IJSCAI.2015.4101","","",,,,,4,0.57,1,3,7,"Recently the use of the Monte-Carlo Tree Search algorithm, and in  particular its most famous implementation, the Upper Confidence Tree can be  seen has a key moment for artificial intelligence in games. This family of algorithms  provides huge improvements in numerous games, such as Go, Havannah,  Hex or Amazon. In this paper we study the use of this algorithm on the game of  Mr Jack and in particular how to deal with a specific decision-making process.  Mr Jack is a 2-player game, from the family of board games. We will present  the difficulties of designing an artificial intelligence for this kind of games, and  we show that Monte-Carlo Tree Search is robust enough to be competitive in this  game with a smart approach","",""
21,"Paul M. Goldwater, T. Fogarty","Protecting the Solution: A ‘High-Tech.’ Method to Guarantee Individual Effort in Accounting Classes",2007,"","","","",44,"2022-07-13 09:33:38","","10.1080/09639280701234344","","",,,,,21,1.40,11,2,15,"Abstract Advocates of the case method in accounting education have provided strong arguments in favour of this classroom approach. However, a primary objection has been unanswered. Cases generate ‘canned’ solutions that, when passed between students, jeopardize the accountability of individual efforts and the educational value of the exercise. Although students have leveraged computer technology to exacerbate this problem, academic staff generally have not ‘fought fire with fire.’ This paper shows how computer technology, through the use of artificial intelligence, can restore the confidence that each student will work his/her own case solution and, therefore, will extract the intended educational value from the effort. With computer technology made to act intelligently, the case method in accounting classes should become more robust as a primary pedagogical device. *The authors are willing to share the data in this paper","",""
0,"Lingnan Ge, K. Shirai, Yubo Ge","Enhancing Robustness of Speech Recognition by Approach of Feature with Confident Weight",2006,"","","","",45,"2022-07-13 09:33:38","","10.5555/1166890.1166910","","",,,,,0,0.00,0,3,16,"Enhancement of robustness has become one of research focuses of acoustic speech recognition system. In recent works, Missing Feature Theory (MFT) has been proved an available and considerable solution for robust speech recognition based on either ignoring or compensating the unreliable components of feature vectors corrupted mainly by band-limited background noise. Because of MFA classifying in binary way and necessarily of dealing with the cepstral feature, this paper proposes three new approaches based on confidence analysis. Approach of Feature with Confident Weight(AFCW) estimates the confidence of each feature component as its weight and describes the effect of noise in a more precise way. The other two approaches, SC(Simple Cepstral)- and TC(Total Cepstral)-AFCW, can be regarded as AFCW on cepstral domain. Experimental results show proposed approaches could improve the recognition accuracy significantly in adverse environment, including stationary and non-stationary noise environments.","",""
1,"Paul M. Goldwater, T. Fogarty","RESPONDING TO THE CHALLENGE OF ACADEMIC INTEGRITY IN DISTANCE LEARNING: USING EXCEL TO GUARANTEE INDIVIDUAL EFFORT",2005,"","","","",46,"2022-07-13 09:33:38","","10.48009/1_iis_2005_231-237","","",,,,,1,0.06,1,2,17,"The distance learning environment is highly dependent upon assignment-based assessment. Whereas the business academy may seem well prepared for this transition with the emergence of the case method, a primary objection has been unanswered. Cases generate ""canned"" solutions that, when passed between students, jeopardize the accountability of individual efforts and the educational value of the exercise. Although students have leveraged computer technology to exacerbate this problem, the professoriate generally has not ""fought fire with fire."" Through the use of artificial intelligence can restore the confidence that each student will work his/her own case solution and will therefore extract the intended educational purpose from the effort. With computer technology made to act intelligently, assessments given to students should become more robust as a primary pedagogical device of distance learning. One of the least recognized challenges of the distance learning environment pertains to the need to reconfigure student evaluation. This paper describes the problem and proposes a solution based on artificial intelligence concepts that is deliverable within conventional software. The ability to rapidly transfer data and to instantaneously communicate simultaneously makes distance learning possible and threatens its integrity. Much more than with the ""face-to-face"" learning environment, instructors are heavily dependent upon assignments completed under uncontrolled circumstances. While this packaging of educational material can come closer to addressing the factual richness of the setting, they may be ineffective as measures of student ability. If instructors ignore the prospect that students exchange solutions, individual evaluation is considerably compromised. In this paper, we suggest that computer technology and artificial intelligence can be better brought to bear on the production of case materials so that academic integrity can be maintained. THE NATURE OF THE PROBLEM Concern over the integrity of the solution remains a legitimate concern in the traditional educational environment. Unlike tests, instructors have little control over the actual inputs of individual students when cases are a major part of the course. When cases include expectations that students produce written solutions that are to be graded, individual accountability is at issue. Notwithstanding ethical codes to the contrary, students, in the preparation of their written responses, may ""borrow"" solutions prepared by other students. This may occur between students in the current year's class, or through more systematic means, between students taking the class in different terms. Fraternities and sororities are notorious in the maintenance of files containing solutions to cases, as well as other materials, in order to reduce the necessary effort of each","",""
5,"Yongwon Lee, S. Clearwater","Tools for automating experiment design: a machine learning approach",1992,"","","","",47,"2022-07-13 09:33:38","","10.1109/TAI.1992.246423","","",,,,,5,0.17,3,2,30,"Work that uses an inductive learning tool, HEP-RL (high-energy-physics rule learner), in the design of a very complex artifact, a high-energy-physics experiment, is reported. The important contribution is the observation that the results of learning provide a more complete and robust design. This is because there were end users of the learning able to suggest constraints beyond the usual simple coverage metrics. This allowed for more confidence in the design.<<ETX>>","",""
1,"T. Bearse, M. L. Lynch","An improved technique for applying fuzzy logic in a model-based diagnostics reasoner",1999,"","","","",48,"2022-07-13 09:33:38","","10.1109/AERO.1999.789774","","",,,,,1,0.04,1,2,23,"The authors apply an improved technique based on fuzzy logic to fulfill the requirement to compute a fault hypothesis in a model-based diagnostic reasoner. The primary focus of the paper is to extend previous work and illustrate the use of the improved algorithm. The paper deals primarily with two types of uncertainty: test outcome uncertainty and inference uncertainty. The issue of conflict detection and conclusion rehabilitation is addressed. This proposed fuzzy logic approach uses the confidence parameters defined in the IEEE 1232: Artificial Intelligence Exchange and Service Tie to All Test Environments (AI-ESTATE) standard to provide a robust reasoning under uncertainty capability.","",""
14,"M. Najafzadeh, G. Oliveto","More reliable predictions of clear-water scour depth at pile groups by robust artificial intelligence techniques while preserving physical consistency",2021,"","","","",49,"2022-07-13 09:33:38","","10.1007/s00500-020-05567-3","","",,,,,14,14.00,7,2,1,"","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",50,"2022-07-13 09:33:38","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",51,"2022-07-13 09:33:38","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",52,"2022-07-13 09:33:38","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
3,"Dercilio Junior Verly Lopes, G. S. Bobadilha, Karl Michael Grebner","A fast and robust artificial intelligence technique for wood knot detection",2020,"","","","",53,"2022-07-13 09:33:38","","10.15376/BIORES.15.4.9351-9361","","",,,,,3,1.50,1,3,2,"This study reports the feasibility of using deep convolutional neural networks (CNN), for automatically detecting knots on the surface of wood with high speed and accuracy. A limited dataset of 921 images were photographed in different contexts and divided into 80:20 ratio for training and validation, respectively. The “You only look once” (YoloV3) CNN-based architecture was adopted for training the neural network. The Adam gradient descent optimizer algorithm was used to iteratively minimize the generalized intersection-over-union loss function. Knots on the surface of wood were manually annotated. Images and annotations were analyzed by a stack of convolutional and fully connected layers with skipped connections. After training, model checkpoint was created and inferences on the validation set were made. The quality of results was assessed by several metrics: precision, recall, F1-score, average precision, and precision x recall curve. Results indicated that YoloV3 provided knot detection time of approximately 0.0102 s per knot with a relatively low false positive and false negative ratios. Precision, recall, f1-score metrics reached 0.77, 0.79, and 0.78, respectively. The average precision was 80%. With an adequate number of images, it is possible to improve this tool for use within sawmills in the forms of both workstation and mobile device applications.","",""
120,"Hoang Nguyen, X. Bui","Predicting Blast-Induced Air Overpressure: A Robust Artificial Intelligence System Based on Artificial Neural Networks and Random Forest",2018,"","","","",54,"2022-07-13 09:33:38","","10.1007/s11053-018-9424-1","","",,,,,120,30.00,60,2,4,"","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",55,"2022-07-13 09:33:38","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
7,"Melanie T Odenkirk, D. Reif, E. Baker","Multiomic Big Data Analysis Challenges: Increasing Confidence in the Interpretation of Artificial Intelligence Assessments.",2021,"","","","",56,"2022-07-13 09:33:38","","10.1021/acs.analchem.0c04850","","",,,,,7,7.00,2,3,1,"The need for holistic molecular measurements to better understand disease initiation, development, diagnosis, and therapy has led to an increasing number of multiomic analyses. The wealth of information available from multiomic assessments, however, requires both the evaluation and interpretation of extremely large data sets, limiting analysis throughput and ease of adoption. Computational methods utilizing artificial intelligence (AI) provide the most promising way to address these challenges, yet despite the conceptual benefits of AI and its successful application in singular omic studies, the widespread use of AI in multiomic studies remains limited. Here, we discuss present and future capabilities of AI techniques in multiomic studies while introducing analytical checks and balances to validate the computational conclusions.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",57,"2022-07-13 09:33:38","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
0,"B. Herman, W. Sirichokchatchawan, C. Nantasenamat, S. Pongpanich","Artificial intelligence in overcoming rifampicin resistant-screening challenges in Indonesia: a qualitative study on the user experience of CUHAS-ROBUST",2021,"","","","",58,"2022-07-13 09:33:38","","10.1108/jhr-11-2020-0535","","",,,,,0,0.00,0,4,1,"PurposeThe Chulalongkorn-Hasanuddin Rifampicin-Resistant Tuberculosis Screening Tool (CUHAS-ROBUST) is an artificial intelligence–based (AI–based) application for rifampicin-resistant tuberculosis (RR-TB) screening. This study aims to elaborate on the drug-resistant TB (DR-TB) problem and the impact of CUHAS-ROBUST implementation on RR-TB screening.Design/methodology/approachA qualitative approach with content analysis was performed from September 2020 to October 2020. Medical staff from the primary care center were invited online for application trials and in-depth video call interviews. Transcripts were derived as a data source. An inductive thematic data saturation technique was conducted. Descriptive data of participants, user experience and the impact on the health service were summarizedFindingsA total of 33 participants were selected from eight major islands in Indonesia. The findings show that DR-TB is a new threat, and its diagnosis faces obstacles particularly prolonged waiting time and inevitable delayed treatment. Despite overcoming the RR-TB screening problems with fast prediction, the dubious screening performance, and the reliability of data collection for input parameters were the main concerns of CUHAS-ROBUST. Nevertheless, this application increases the confidence in decision-making, promotes medical procedure compliance, active surveillance and enhancing a low-cost screening approach.Originality/valueThe CUHAS-ROBUST achieved its purpose as a tool for clinical decision-making in RR-TB screening. Moreover, this study demonstrates AI roles in enhancing health-care quality and boost public health efforts against tuberculosis.","",""
7,"O. H. Maghsoudi, A. Gastounioti, Christopher Scott, L. Pantalone, Fang-Fang Wu, E. Cohen, S. Winham, E. Conant, C. Vachon, D. Kontos","Deep-LIBRA: Artificial intelligence method for robust quantification of breast density with independent validation in breast cancer risk assessment",2020,"","","","",59,"2022-07-13 09:33:38","","10.1016/j.media.2021.102138","","",,,,,7,3.50,1,10,2,"","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",60,"2022-07-13 09:33:38","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
17,"Y. Samuel, Jean George, Jim Samuel","Beyond STEM, How Can Women Engage Big Data, Analytics, Robotics and Artificial Intelligence? An Exploratory Analysis of Confidence and Educational Factors in the Emerging Technology Waves Influencing the Role of, and Impact Upon, Women",2020,"","","","",61,"2022-07-13 09:33:38","","10.2139/ssrn.3735279","","",,,,,17,8.50,6,3,2,"In spite of the rapidly advancing global technological environment, the professional participation of women in technology, big data, analytics, artificial intelligence and information systems related domains remains proportionately low. Furthermore, it is of no less concern that the number of women in leadership in these domains are in even lower proportions. In spite of numerous initiatives to improve the participation of women in technological domains, there is an increasing need to gain additional insights into this phenomenon especially since it occurs in nations and geographies which have seen a sharp rise in overall female education, without such increase translating into a corresponding spurt in information systems and technological roles for women. The present paper presents findings from an exploratory analysis and outlines a framework to gain insights into educational factors in the emerging technology waves influencing the role of, and impact upon, women. We specifically identify ways for learning and self-efficacy as key factors, which together lead us to the Advancement of Women in Technology (AWT) insights framework. Based on the AWT framework, we also proposition principles that can be used to encourage higher professional engagement of women in emerging and advanced technologies. Key Words- Women's Education, Technology, Artificial Intelligence, Knowing, Confidence, Self-Efficacy, Learning.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",62,"2022-07-13 09:33:38","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",63,"2022-07-13 09:33:38","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
72,"Songhee Oh, J. Kim, Sung-Woo Choi, Hee Jeong Lee, Jungrak Hong, S. Kwon","Physician Confidence in Artificial Intelligence: An Online Mobile Survey",2018,"","","","",64,"2022-07-13 09:33:38","","10.2196/12422","","",,,,,72,18.00,12,6,4,"Background It is expected that artificial intelligence (AI) will be used extensively in the medical field in the future. Objective The purpose of this study is to investigate the awareness of AI among Korean doctors and to assess physicians’ attitudes toward the medical application of AI. Methods We conducted an online survey composed of 11 closed-ended questions using Google Forms. The survey consisted of questions regarding the recognition of and attitudes toward AI, the development direction of AI in medicine, and the possible risks of using AI in the medical field. Results A total of 669 participants completed the survey. Only 40 (5.9%) answered that they had good familiarity with AI. However, most participants considered AI useful in the medical field (558/669, 83.4% agreement). The advantage of using AI was seen as the ability to analyze vast amounts of high-quality, clinically relevant data in real time. Respondents agreed that the area of medicine in which AI would be most useful is disease diagnosis (558/669, 83.4% agreement). One possible problem cited by the participants was that AI would not be able to assist in unexpected situations owing to inadequate information (196/669, 29.3%). Less than half of the participants(294/669, 43.9%) agreed that AI is diagnostically superior to human doctors. Only 237 (35.4%) answered that they agreed that AI could replace them in their jobs. Conclusions This study suggests that Korean doctors and medical students have favorable attitudes toward AI in the medical field. The majority of physicians surveyed believed that AI will not replace their roles in the future.","",""
44,"A. Goli, H. Zare, R. Tavakkoli-Moghaddam, A. Sadeghieh","Hybrid artificial intelligence and robust optimization for a multi-objective product portfolio problem Case study: The dairy products industry",2019,"","","","",65,"2022-07-13 09:33:38","","10.1016/j.cie.2019.106090","","",,,,,44,14.67,11,4,3,"","",""
8,"Ying-Ying Yang, B. Shulruf","An expert-led and artificial intelligence system-assisted tutoring course to improve the confidence of Chinese medical interns in suturing and ligature skills: a prospective pilot study",2019,"","","","",66,"2022-07-13 09:33:38","","10.3352/jeehp.2019.16.7","","",,,,,8,2.67,4,2,3,"Purpose Lack of confidence in suturing/ligature skills due to insufficient practice and assessments is common among novice Chinese medical interns. This study aimed to improve the skill acquisition of medical interns through a new intervention program. Methods In addition to regular clinical training, expert-led or expert-led plus artificial intelligence (AI) system tutoring courses were implemented during the first 2 weeks of the surgical block. Interns could voluntarily join the regular (no additional tutoring), expert-led tutoring, or expert-led+AI tutoring groups freely. In the regular group, interns (n=25) did not receive additional tutoring. The expert-led group received 3-hour expert-led tutoring and in-training formative assessments after 2 practice sessions. After a similar expert-led course, the expert-led+AI group (n=23) practiced and assessed their skills on an AI system. Through a comparison with the internal standard, the system automatically recorded and evaluated every intern’s suturing/ligature skills. In the expert-led+AI group, performance and confidence were compared between interns who participated in 1, 2, or 3 AI practice sessions. Results The end-of-surgical block objective structured clinical examination (OSCE) performance and self-assessed confidence in suturing/ligature skills were highest in the expert-led+AI group. In comparison with the expert-led group, the expert-led+AI group showed similar performance in the in-training assessment and greater improvement in the end-of-surgical block OSCE. In the expert-led+AI group, the best performance and highest post-OSCE confidence were noted in those who engaged in 3 AI practice sessions. Conclusion This pilot study demonstrated the potential value of incorporating an additional expert-led+AI system–assisted tutoring course into the regular surgical curriculum.","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",67,"2022-07-13 09:33:38","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",68,"2022-07-13 09:33:38","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
0,"E. Gibson, B. Georgescu, Pascal Ceccaldi, Pierre-Hugo Trigan, Y. Yoo, Jyotipriya Das, Thomas J. Re, Vishwanath Rs, A. Balachandran, Eva Eibenberger, A. Chekkoury, B. Brehm, U. Bodanapally, S. Nicolaou, P. Sanelli, T. Schroeppel, T. Flohr, D. Comaniciu, Y. Lui","Artificial Intelligence with Statistical Confidence Scores for Detection of Acute or Subacute Hemorrhage on Noncontrast CT Head Scans.",2022,"","","","",69,"2022-07-13 09:33:38","","10.1148/ryai.210115","","",,,,,0,0.00,0,19,1,"Purpose To present a method that automatically detects, subtypes, and locates acute or subacute intracranial hemorrhage (ICH) on noncontrast CT (NCCT) head scans; generates detection confidence scores to identify high-confidence data subsets with higher accuracy; and improves radiology worklist prioritization. Such scores may enable clinicians to better use artificial intelligence (AI) tools.   Materials and Methods This retrospective study included 46 057 studies from seven ""internal"" centers for development (training, architecture selection, hyperparameter tuning, and operating-point calibration; n = 25 946) and evaluation (n = 2947) and three ""external"" centers for calibration (n = 400) and evaluation (n = 16  764). Internal centers contributed developmental data, whereas external centers did not. Deep neural networks predicted the presence of ICH and subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and/or epidural hemorrhage) and segmentations per case. Two ICH confidence scores are discussed: a calibrated classifier entropy score and a Dempster-Shafer score. Evaluation was completed by using receiver operating characteristic curve analysis and report turnaround time (RTAT) modeling on the evaluation set and on confidence score-defined subsets using bootstrapping.   Results The areas under the receiver operating characteristic curve for ICH were 0.97 (0.97, 0.98) and 0.95 (0.94, 0.95) on internal and external center data, respectively. On 80% of the data stratified by calibrated classifier and Dempster-Shafer scores, the system improved the Youden indexes, increasing them from 0.84 to 0.93 (calibrated classifier) and from 0.84 to 0.92 (Dempster-Shafer) for internal centers and increasing them from 0.78 to 0.88 (calibrated classifier) and from 0.78 to 0.89 (Dempster-Shafer) for external centers (P < .001). Models estimated shorter RTAT for AI-prioritized worklists with confidence measures than for AI-prioritized worklists without confidence measures, shortening RTAT by 27% (calibrated classifier) and 27% (Dempster-Shafer) for internal centers and shortening RTAT by 25% (calibrated classifier) and 27% (Dempster-Shafer) for external centers (P < .001).   Conclusion AI that provided statistical confidence measures for ICH detection on NCCT scans reliably detected and subtyped hemorrhages, identified high-confidence predictions, and improved worklist prioritization in simulation.Keywords: CT, Head/Neck, Hemorrhage, Convolutional Neural Network (CNN) Supplemental material is available for this article. © RSNA, 2022.","",""
0,"Qinmin Ma","Design of High-Confidence Embedded Operating System based on Artificial Intelligence and Smart Chips",2022,"","","","",70,"2022-07-13 09:33:38","","10.1109/ICAIS53314.2022.9742917","","",,,,,0,0.00,0,1,1,"Design of the high-confidence embedded operating system based on artificial intelligence and smart chips is studied in this paper. The cooperative physical layer security system is regarded as a state machine. Relay nodes with untrusted behavior will affect the physical layer security of the system, and the system tries to prevent the untrusted behavior of relay nodes. While implementing public verification, it realizes the protection of data privacy. The third party can directly verify the data holding of the data stored in the cloud without verification by the user, and in the process of system expansion and growth, software can ensure vigorous vitality. For the verification, the smart chips are combined for the systematic implementations. The experimental results have shown the satisfactory results.","",""
46,"Alison Lui, George William Lamb","Artificial intelligence and augmented intelligence collaboration: regaining trust and confidence in the financial sector",2018,"","","","",71,"2022-07-13 09:33:38","","10.1080/13600834.2018.1488659","","",,,,,46,11.50,23,2,4,"ABSTRACT Robots and chatbots are sophisticated. Artificial intelligence (AI) is increasingly popular in the financial industry due to its ability to provide customers with cheap, efficient and personalised services. This article uses doctrinal sources and a case study to show that many banks and FinTech start-ups are investing in AI. Yet, there are a number of challenges arising from the use of AI which could undermine trust and confidence amongst consumers. This article features the issue of bias and discrimination in banking. There is evidence that algorithms discriminate against certain races and gender. Legislative gaps in the Equality Act 2010 and the General Data Protection Regime will be analysed. Ultimately, human beings are still needed to input, train and help machines to learn. Fortunately, the FCA are leading in regulating technology, from the launch of regulatory sandboxes to their co-operative collaboration with FinTech start-ups on regulatory matters. Augmented intelligence collaboration is needed to enable industry players and regulators to provide seamless regulation and financial stability. The future of AI regulation is inter-disciplinary in approach.","",""
10,"S. Lennartz, Thomas Dratsch, D. Zopfs, T. Persigehl, D. Maintz, N. Grosse Hokamp, D. Pinto dos Santos","Use and Control of Artificial Intelligence in Patients Across the Medical Workflow: Single-Center Questionnaire Study of Patient Perspectives",2021,"","","","",72,"2022-07-13 09:33:38","","10.2196/24221","","",,,,,10,10.00,1,7,1,"Background Artificial intelligence (AI) is gaining increasing importance in many medical specialties, yet data on patients’ opinions on the use of AI in medicine are scarce. Objective This study aimed to investigate patients’ opinions on the use of AI in different aspects of the medical workflow and the level of control and supervision under which they would deem the application of AI in medicine acceptable. Methods Patients scheduled for computed tomography or magnetic resonance imaging voluntarily participated in an anonymized questionnaire between February 10, 2020, and May 24, 2020. Patient information, confidence in physicians vs AI in different clinical tasks, opinions on the control of AI, preference in cases of disagreement between AI and physicians, and acceptance of the use of AI for diagnosing and treating diseases of different severity were recorded. Results In total, 229 patients participated. Patients favored physicians over AI for all clinical tasks except for treatment planning based on current scientific evidence. In case of disagreement between physicians and AI regarding diagnosis and treatment planning, most patients preferred the physician’s opinion to AI (96.2% [153/159] vs 3.8% [6/159] and 94.8% [146/154] vs 5.2% [8/154], respectively; P=.001). AI supervised by a physician was considered more acceptable than AI without physician supervision at diagnosis (confidence rating 3.90 [SD 1.20] vs 1.64 [SD 1.03], respectively; P=.001) and therapy (3.77 [SD 1.18] vs 1.57 [SD 0.96], respectively; P=.001). Conclusions Patients favored physicians over AI in most clinical tasks and strongly preferred an application of AI with physician supervision. However, patients acknowledged that AI could help physicians integrate the most recent scientific evidence into medical care. Application of AI in medicine should be disclosed and controlled to protect patient interests and meet ethical standards.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",73,"2022-07-13 09:33:38","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
2,"B. Nair, Yakov Diskin, V. Asari","Multi-modal low cost mobile indoor surveillance system on the Robust Artificial Intelligence-based Defense Electro Robot (RAIDER)",2012,"","","","",74,"2022-07-13 09:33:38","","10.1117/12.930353","","",,,,,2,0.20,1,3,10,"We present an autonomous system capable of performing security check routines. The surveillance machine, the Clearpath Husky robotic platform, is equipped with three IP cameras with different orientations for the surveillance tasks of face recognition, human activity recognition, autonomous navigation and 3D reconstruction of its environment. Combining the computer vision algorithms onto a robotic machine has given birth to the Robust Artificial Intelligencebased Defense Electro-Robot (RAIDER). The end purpose of the RAIDER is to conduct a patrolling routine on a single floor of a building several times a day. As the RAIDER travels down the corridors off-line algorithms use two of the RAIDER's side mounted cameras to perform a 3D reconstruction from monocular vision technique that updates a 3D model to the most current state of the indoor environment. Using frames from the front mounted camera, positioned at the human eye level, the system performs face recognition with real time training of unknown subjects. Human activity recognition algorithm will also be implemented in which each detected person is assigned to a set of action classes picked to classify ordinary and harmful student activities in a hallway setting.The system is designed to detect changes and irregularities within an environment as well as familiarize with regular faces and actions to distinguish potentially dangerous behavior. In this paper, we present the various algorithms and their modifications which when implemented on the RAIDER serves the purpose of indoor surveillance.","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",75,"2022-07-13 09:33:38","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
9,"Seunghyeon Kim, Yeon-Hee Lee, Yung-kyun Noh, F. Park, Q-Schick Auh","Age-group determination of living individuals using first molar images based on artificial intelligence",2021,"","","","",76,"2022-07-13 09:33:38","","10.1038/s41598-020-80182-8","","",,,,,9,9.00,2,5,1,"","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",77,"2022-07-13 09:33:38","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",78,"2022-07-13 09:33:38","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
10,"A. C. Horta, A. Silva, C. Sargo, V. M. Gonçalves, T. C. Zangirolami, Roberto Campos Giordano","Robust artificial intelligence tool for automatic start-up of the supplementary medium feeding in recombinant E. coli cultivations",2011,"","","","",79,"2022-07-13 09:33:38","","10.1007/s00449-011-0540-0","","",,,,,10,0.91,2,6,11,"","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",80,"2022-07-13 09:33:38","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",81,"2022-07-13 09:33:38","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
5,"D. Giansanti, Lisa Monoscalco","A smartphone-based survey in mHealth to investigate the introduction of the artificial intelligence into cardiology.",2020,"","","","",82,"2022-07-13 09:33:38","","10.21037/MHEALTH-19-188","","",,,,,5,2.50,3,2,2,"Background There is an increasing discussion concerning the integration of artificial intelligence (AI) into medical decision-making. AI science is a branch of engineering that implements novel concepts to resolve complex challenges and defined as the theory and development of computer systems to perform tasks which would normally require human intelligence. AI could aid cardiologists in improving decision-making, workflow, productivity, cost-effectiveness, and ultimately, patient outcomes. The present study proposes a tool for a positioning exercise in cardiology using mobile technology.   Methods This study is based on a dedicated tool with electronic surveys that collect the opinions, requirements, and desires of the interested actors including both laypeople and professionals.   Results The tool was tested on 30 cardiologists and 30 subjects not involved in health care. The data-analysis revealed several clear trends on the cardiologists: (I) a high desire to invest in AI; (II) high confidence in the use of AI in several fields of cardiology from risk prevention to diagnostics in medical imaging; (III) low confidence in the use of AI in quality control procedures; (IV) a strong belief that ethical issues are hampering the diffusion of AI to different fields. The data-analysis on the 30 subjects not involved in health care highlighted that AI is still not well known and therefore looked with suspicious.   Conclusions The integration of AI with telemedicine and e-health is a key issue for the health care. The study highlights how the mobile technology-based positioning exercises in mHealth can be useful for health care decision makers.","",""
4,"O. L. Saldanha, P. Quirke, N. West, J. James, M. Loughrey, H. Grabsch, M. Salto‐Tellez, E. Alwers, Didem Cifci, Narmin Ghaffari Laleh, T. Seibel, Richard Gray, G. Hutchins, H. Brenner, T. Yuan, T. Brinker, J. Chang-Claude, Firas Khader, A. Schuppert, T. Luedde, S. Foersch, H. Muti, C. Trautwein, M. Hoffmeister, D. Truhn, J. Kather","Swarm learning for decentralized artificial intelligence in cancer histopathology",2021,"","","","",83,"2022-07-13 09:33:38","","10.1038/s41591-022-01768-5","","",,,,,4,4.00,0,26,1,"","",""
61,"I. Barua, D. Vinsard, Henriette C. Jodal, M. Løberg, M. Kalager, Ø. Holme, M. Misawa, M. Bretthauer, Y. Mori","Artificial Intelligence for Polyp Detection during Colonoscopy: A Systematic Review and Meta-Analysis.",2020,"","","","",84,"2022-07-13 09:33:38","","10.1055/a-1201-7165","","",,,,,61,30.50,7,9,2,"BACKGROUND AND STUDY AIMS Artificial intelligence (AI)-based polyp detection systems during colonoscopy aim at increasing lesion detection and improving colonoscopy quality.   PATIENTS AND METHODS We performed a systematic review and meta-analysis of prospective trials to determine the value of AI-based polyp detection systems for detection of polyps and colorectal cancer. We performed systematic searches in MEDLINE, EMBASE and Cochrane CENTRAL. Independent reviewers screened studies and assessed eligibility, certainty of evidence, and risk of bias. We compared colonoscopy with and without AI by calculating relative and absolute risk and mean differences for detection of polyps, adenomas, and colorectal cancer.   RESULTS Five randomized trials were eligible for analyses. Colonoscopy with AI increased adenoma detection rates (ADRs) and polyp detection rates (PDRs) compared to colonoscopy without AI: ADR with AI 29.6% [95% confidence interval, 22.2-37.0], versus 19.3% [12.7-25.9] without AI (relative risk (RR) 1.52, [1.31-1.77], high certainty); PDR 45.4% [41.1-49.8] with AI, versus 30.6% [26.5-34.6] without AI (RR 1.48, [1.37-1.60], high certainty). There was no difference in detection of advanced adenomas between the two groups (mean number of advanced adenomas per colonoscopy 0.03 for each, high certainty). Mean number of adenomas per colonoscopy were higher for small adenomas (≤5 mm) with AI compared to non-AI colonoscopy (mean difference 0.15, [0.12-0.18]), but not for larger adenomas (>5-≤10mm: mean difference 0.03, [0.01-0.05]; >10 mm: mean difference 0.01, [0.00-0.02], high certainty). Data on cancer are unavailable.   CONCLUSIONS AI-based polyp detection systems during colonoscopy increase detection of small, non-advanced adenomas and polyps, but not advanced adenomas.","",""
25,"P. Phillips, Carina A. Hahn, Peter C. Fontana, David A. Broniatowski, Mark A. Przybocki","Four Principles of Explainable Artificial Intelligence",2020,"","","","",85,"2022-07-13 09:33:38","","10.6028/nist.ir.8312-draft","","",,,,,25,12.50,5,5,2,"We introduce four principles for explainable artificial intelligence (AI) that comprise fundamental properties for explainable AI systems. We propose that explainable AI systems deliver accompanying evidence or reasons for outcomes and processes; provide explanations that are understandable to individual users; provide explanations that correctly reflect the system’s process for generating the output; and that a system only operates under conditions for which it was designed and when it reaches sufficient confidence in its output. We have termed these four principles as explanation, meaningful, explanation accuracy, and knowledge limits, respectively. Through significant stakeholder engagement, these four principles were developed to encompass the multidisciplinary nature of explainable AI, including the fields of computer science, engineering, and psychology. Because one-sizefits-all explanations do not exist, different users will require different types of explanations. We present five categories of explanation and summarize theories of explainable AI. We give an overview of the algorithms in the field that cover the major classes of explainable algorithms. As a baseline comparison, we assess how well explanations provided by people follow our four principles. This assessment provides insights to the challenges of designing explainable AI systems.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",86,"2022-07-13 09:33:38","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
54,"I. Castiglioni, D. Ippolito, M. Interlenghi, C. Monti, C. Salvatore, S. Schiaffino, Annalisa Polidori, Davide Gandola, C. Messa, F. Sardanelli","Artificial intelligence applied on chest X-ray can aid in the diagnosis of COVID-19 infection: a first experience from Lombardy, Italy",2020,"","","","",87,"2022-07-13 09:33:38","","10.1101/2020.04.08.20040907","","",,,,,54,27.00,5,10,2,"Objectives We tested artificial intelligence (AI) to support the diagnosis of COVID-19 using chest X-ray (CXR). Diagnostic performance was computed for a system trained on CXRs of Italian subjects from two hospitals in Lombardy, Italy. Methods We used for training and internal testing an ensemble of ten convolutional neural networks (CNNs) with mainly bedside CXRs of 250 COVID-19 and 250 non-COVID-19 subjects from two hospitals. We then tested such system on bedside CXRs of an independent group of 110 patients (74 COVID-19, 36 non COVID-19) from one of the two hospitals. A retrospective reading was performed by two radiologists in the absence of any clinical information, with the aim to differentiate COVID-19 from non-COVID-19 patients. Real-time polymerase chain reaction served as reference standard. Results At 10-fold cross-validation, our AI model classified COVID-19 and non COVID-19 patients with 0.78 sensitivity (95% confidence interval [CI] 0.74-0.81), 0.82 specificity (95% CI 0.78-0.85) and 0.89 area under the curve (AUC) (95% CI 0.86-0.91). For the independent dataset, AI showed 0.80 sensitivity (95% CI 0.72-0.86) (59/74), 0.81 specificity (29/36) (95% CI 0.73-0.87), and 0.81 AUC (95% CI 0.73-0.87). Radiologists reading obtained 0.63 sensitivity (95% CI 0.52-0.74) and 0.78 specificity (95% CI 0.61-0.90) in one centre and 0.64 sensitivity (95% CI 0.52-0.74) and 0.86 specificity (95% CI 0.71-0.95) in the other. Conclusions This preliminary experience based on ten CNNs trained on a limited training dataset shows an interesting potential of AI for COVID-19 diagnosis. Such tool is in training with new CXRs to further increase its performance.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",88,"2022-07-13 09:33:38","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
3,"Amy Papadopoulos, J. Salinas, Cindy Crump","Computational modeling approaches to characterize risk and achieve safe, effective, and trusted designs in the development of artificial intelligence and autonomous closed-loop medical systems",2021,"","","","",89,"2022-07-13 09:33:38","","10.1117/12.2586101","","",,,,,3,3.00,1,3,1,"While software using artificial intelligence and machine learning (AI/ML) is pervasive in many areas of society today, the use of these technologies to diagnose and treat medical conditions is limited due to a number of challenges associated with the trustworthiness of the results. This may include the inability to fully explain how an algorithm works inherent to the black-box nature of the system. Additionally, AI/ML may create a potential for bias and artifacts that cannot be validated due to the same limitations. In a medical application, the lack of transparency in how the system operates may lead to a loss of trust by users. Bayesian approaches that use computational modeling to quantify the level of uncertainty in a given result may provide a path towards improved confidence and use. In this paper, evidence from studies in a range of medical applications is presented and discussed, showing how Bayesian approaches can help to foster trust. A retrospective study using a publicly available dataset explored the feasibility of creating predictive models for early intervention in a Type 1 diabetes population. Creating the perfect model was not the goal of the exercise, rather the study aimed to demonstrate how Bayesian methods could be used to identify areas of uncertainty during model development. Feature selection was based on analytical assessment of various patterns found in the data. Models were trained, validated, and tested, generating uncertainty estimates. A two-feature Gaussian Naïve Bayes (GNB) model, using the previous five minutes and ten minutes of blood glucose values, showed similar results for predictive accuracy as a threefeature model that included average change over the preceding 30 minutes. The two-feature model was selected because it allowed for a more easily understood visualization of uncertainty. The 2-feature GNB achieved an AUC = .94. The model showed good sensitivity for exceeding the < 180 mg/dl limit, obtaining threshold prediction = 89.8% and normal range prediction = 90.8%. The sensitivity was lower for the < 70 mg/dl limit, attaining a sensitivity = 77.5%. Posterior probabilities showed differing levels of uncertainty in the prediction of high and low out-of-range conditions. The model demonstrated the feasibility of providing robust parameter estimates. Bayesian machine learning approaches to model uncertainty may improve the transparency, explainability, and applicability of AI/ML in medical treatment, realizing the promise to improve patient safety and outcomes.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",90,"2022-07-13 09:33:38","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",91,"2022-07-13 09:33:38","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",92,"2022-07-13 09:33:38","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",93,"2022-07-13 09:33:38","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",94,"2022-07-13 09:33:38","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
99,"H. Bai, Robin Wang, Z. Xiong, B. Hsieh, Ken Chang, K. Halsey, Thi My Linh Tran, Ji Whae Choi, Dong-Cui Wang, Linbo Shi, J. Mei, Xiao-Long Jiang, I. Pan, Qiuhua Zeng, P. Hu, Yi-Hui Li, F. Fu, Raymond Y Huang, R. Sebro, Qi-Zhi Yu, M. Atalay, W. Liao","Artificial Intelligence Augmentation of Radiologist Performance in Distinguishing COVID-19 from Pneumonia of Other Origin at Chest CT",2021,"","","","",95,"2022-07-13 09:33:38","","10.1148/radiol.2021219004","","",,,,,99,99.00,10,22,1,"Background Coronavirus disease 2019 (COVID-19) and pneumonia of other diseases share similar CT characteristics, which contributes to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system for differentiating COVID-19 and other pneumonia at chest CT and assessing radiologist performance without and with AI assistance. Materials and Methods A total of 521 patients with positive reverse transcription polymerase chain reaction results for COVID-19 and abnormal chest CT findings were retrospectively identified from 10 hospitals from January 2020 to April 2020. A total of 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia at chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by a two-layer fully connected neural network to pool slices together. The final cohort of 1186 patients (132 583 CT slices) was divided into training, validation, and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance in separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results The final model achieved a test accuracy of 96% (95% confidence interval [CI]: 90%, 98%), a sensitivity of 95% (95% CI: 83%, 100%), and a specificity of 96% (95% CI: 88%, 99%) with area under the receiver operating characteristic curve of 0.95 and area under the precision-recall curve of 0.90. On independent testing, this model achieved an accuracy of 87% (95% CI: 82%, 90%), a sensitivity of 89% (95% CI: 81%, 94%), and a specificity of 86% (95% CI: 80%, 90%) with area under the receiver operating characteristic curve of 0.90 and area under the precision-recall curve of 0.87. Assisted by the probabilities of the model, the radiologists achieved a higher average test accuracy (90% vs 85%, &#916; = 5, P < .001), sensitivity (88% vs 79%, &#916; = 9, P < .001), and specificity (91% vs 88%, &#916; = 3, P = .001). Conclusion Artificial intelligence assistance improved radiologists' performance in distinguishing coronavirus disease 2019 pneumonia from non-coronavirus disease 2019 pneumonia at chest CT. © RSNA, 2020 Online supplemental material is available for this article.","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",96,"2022-07-13 09:33:38","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",97,"2022-07-13 09:33:38","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",98,"2022-07-13 09:33:38","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
23,"K. Lång, M. Dustler, Victor Dahlblom, A. Åkesson, I. Andersson, S. Zackrisson","Identifying normal mammograms in a large screening population using artificial intelligence",2020,"","","","",99,"2022-07-13 09:33:38","","10.1007/s00330-020-07165-1","","",,,,,23,11.50,4,6,2,"","",""
24,"T. Jutzi, E. Krieghoff-Henning, T. Holland-Letz, J. Utikal, A. Hauschild, D. Schadendorf, W. Sondermann, S. Fröhling, A. Hekler, Max Schmitt, R. Maron, T. Brinker","Artificial Intelligence in Skin Cancer Diagnostics: The Patients' Perspective",2020,"","","","",100,"2022-07-13 09:33:38","","10.3389/fmed.2020.00233","","",,,,,24,12.00,2,12,2,"Background: Artificial intelligence (AI) has shown promise in numerous experimental studies, particularly in skin cancer diagnostics. Translation of these findings into the clinic is the logical next step. This translation can only be successful if patients' concerns and questions are addressed suitably. We therefore conducted a survey to evaluate the patients' view of artificial intelligence in melanoma diagnostics in Germany, with a particular focus on patients with a history of melanoma. Participants and Methods: A web-based questionnaire was designed using LimeSurvey, sent by e-mail to university hospitals and melanoma support groups and advertised on social media. The anonymous questionnaire evaluated patients' expectations and concerns toward artificial intelligence in general as well as their attitudes toward different application scenarios. Descriptive analysis was performed with expression of categorical variables as percentages and 95% confidence intervals. Statistical tests were performed to investigate associations between sociodemographic data and selected items of the questionnaire. Results: 298 individuals (154 with a melanoma diagnosis, 143 without) responded to the questionnaire. About 94% [95% CI = 0.91–0.97] of respondents supported the use of artificial intelligence in medical approaches. 88% [95% CI = 0.85–0.92] would even make their own health data anonymously available for the further development of AI-based applications in medicine. Only 41% [95% CI = 0.35–0.46] of respondents were amenable to the use of artificial intelligence as stand-alone system, 94% [95% CI = 0.92–0.97] to its use as assistance system for physicians. In sub-group analyses, only minor differences were detectable. Respondents with a previous history of melanoma were more amenable to the use of AI applications for early detection even at home. They would prefer an application scenario where physician and AI classify the lesions independently. With respect to AI-based applications in medicine, patients were concerned about insufficient data protection, impersonality and susceptibility to errors, but expected faster, more precise and unbiased diagnostics, less diagnostic errors and support for physicians. Conclusions: The vast majority of participants exhibited a positive attitude toward the use of artificial intelligence in melanoma diagnostics, especially as an assistance system.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",101,"2022-07-13 09:33:38","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",102,"2022-07-13 09:33:38","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
43,"Stuart J. Russell, Thomas G. Dietterich, Eric Horvitz, B. Selman, F. Rossi, D. Hassabis, S. Legg, Mustafa Suleyman, D. George, D. Phoenix","Letter to the Editor: Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter",2015,"","","","",103,"2022-07-13 09:33:38","","10.1609/aimag.v36i4.2621","","",,,,,43,6.14,4,10,7,"Artificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents — systems that perceive and act in some environment. In this context, ""intelligence"" is related to statistical and economic notions of rationality — colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic and decision-theoretic representations and statistical learning methods has led to a large degree of integration and cross-fertilization among AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition, image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems. As capabilities in these areas and others cross the threshold from laboratory research to economically valuable technologies, a virtuous cycle takes hold whereby even small improvements in performance are worth large sums of money, prompting greater investments in research. There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. The progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008–09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do. The attached research priorities document [see page X] gives many examples of such research directions that can help maximize the societal benefit of AI. This research is by necessity interdisciplinary, because it involves both society and AI. It ranges from economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself. In summary, we believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",104,"2022-07-13 09:33:38","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",105,"2022-07-13 09:33:38","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
15,"Forrest E. Morgan, Benjamin Boudreaux, A. Lohn, Mark Ashby, Christian Curriden, K. Klima, Derek Grossman","Military Applications of Artificial Intelligence: Ethical Concerns in an Uncertain World",2020,"","","","",106,"2022-07-13 09:33:38","","10.7249/rr3139","","",,,,,15,7.50,2,7,2,"The authors examine the ethical considerations, benefits, and risks of military applications of artificial intelligence. Comparing development efforts in the United States, China, and Russia (as well as various positions on proposals to regulate or ban autonomous weapons), the authors point to a need for the United States to continue to pursue advantages in the field and explore confidence-building and risk-reduction measures with other states.","",""
16,"Aurélie Jean","[A brief history of artificial intelligence].",2020,"","","","",107,"2022-07-13 09:33:38","","10.1051/medsci/2020189","","",,,,,16,8.00,16,1,2,"For more than a decade, we have witnessed an acceleration in the development and the adoption of artificial intelligence (AI) technologies. In medicine, it impacts clinical and fundamental research, hospital practices, medical examinations, hospital care or logistics. These in turn contribute to improvements in diagnostics and prognostics, and to improvements in personalised and targeted medicine, advanced observation and analysis technologies, or surgery and other assistance robots. Many challenges in AI and medicine, such as data digitalisation, medical data privacy, algorithm explicability, inclusive AI system development or their reproducibility, have to be tackled in order to build the confidence of medical practitioners in these technologies. This will be possible by mastering the key concepts via a brief history of artificial intelligence.","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",108,"2022-07-13 09:33:38","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",109,"2022-07-13 09:33:38","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",110,"2022-07-13 09:33:38","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
11,"I. Linkov, S. Galaitsi, Benjamin D. Trump, J. Keisler, A. Kott","Cybertrust: From Explainable to Actionable and Interpretable Artificial Intelligence",2020,"","","","",111,"2022-07-13 09:33:38","","10.1109/MC.2020.2993623","","",,,,,11,5.50,2,5,2,"We argue that artificial intelligence (AI) systems should be designed with features that build trust by bringing decision-analytic perspectives into AI. Actionable and interpretable AI will incorporate explicit quantifications and visualizations of user confidence in AI recommendations.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",112,"2022-07-13 09:33:38","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
10,"Yun Dai, C. Chai, Pei-Yi Lin, M. Jong, Yanmei Guo, Jianjun Qin","Promoting Students’ Well-Being by Developing Their Readiness for the Artificial Intelligence Age",2020,"","","","",113,"2022-07-13 09:33:38","","10.3390/su12166597","","",,,,,10,5.00,2,6,2,"This study developed and validated an instrument to measure students’ readiness to learn about artificial intelligence (AI). The designed survey questionnaire was administrated in a school district in Beijing after an AI course was developed and implemented. The collected data and analytical results provided insights regarding the self-reported perceptions of primary students’ AI readiness and enabled the identification of factors that may influence this parameter. The results indicated that AI literacy was not predictive of AI readiness. The influences of AI literacy were mediated by the students’ confidence and perception of AI relevance. The students’ AI readiness was not influenced by a reduction in their anxiety regarding AI and an enhancement in their AI literacy. Male students reported a higher confidence, relevance, and readiness for AI than female students did. The sentiments reflected by the open-ended responses of the students indicated that the students were generally excited to learn about AI and viewed AI as a powerful and useful technology. The student sentiments confirmed the quantitative findings. The validated survey can help teachers better understand and monitor students’ learning, as well as reflect on the design of the AI curriculum and the associated teaching effectiveness.","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",114,"2022-07-13 09:33:38","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
8,"Steven Lockey, N. Gillespie, Caitlin Curtis","Trust in Artificial Intelligence: Australian Insights",2020,"","","","",115,"2022-07-13 09:33:38","","10.14264/b32f129","","",,,,,8,4.00,3,3,2,"Artificial Intelligence (AI) is the cornerstone technology of the Fourth Industrial Revolution and is enabling rapid innovation with many potential benefits for Australian society (e.g. enhanced healthcare diagnostics, transportation optimisation) and business (e.g. enhanced efficiency and competitiveness). The COVID-19 pandemic has accelerated the uptake of advanced technology, and investment in AI continues to grow exponentially.AI also poses considerable risks and challenges to society which raises concerns about whether AI systems are worthy of trust. These concerns have been fuelled by high profile cases of AI use that were biased, discriminatory, manipulative, unlawful, or violated privacy or other human rights. Without public confidence that AI is being developed and used in an ethical and trustworthy manner, it will not be trusted and its full potential will not be realised. To echo the sentiment of Dr Alan Finkel AO, Australia’s Chief Scientist, acceptance of AI rests on “the essential foundation of trust”. Are we capable of extending our trust to AI?This national survey is the first to take a deep dive into answering this question and understanding community trust and expectations in relation to AI. To do this, we surveyed a nationally representative sample of over 2,500 Australian citizens in June to July 2020. Our findings provide important and timely research insights into the public’s trust and attitudes towards AI and lay out a pathway for strengthening trust and acceptance of AI systems.Key findings include:              - Trust is central to the acceptance of AI, and is influenced by four key drivers;              - Australians have low trust in AI systems but generally ‘accept’ or ‘tolerate’ AI;              - Australians expect AI to be regulated and carefully managed;              - Australians expect organisations to uphold the principles of trustworthy AI;              - Australians feel comfortable with some but not all uses of AI at work;              - Australians want to know more about AI but currently have low awareness and understanding of AI and its uses.We draw out the implications of the findings for government, business and NGOs and provide a roadmap to enhancing public trust in AI highlighting three key actions:              - Live up to Australian’s expectations of trustworthy AI              - Strengthen the regulatory framework for governing AI              - Strengthen Australia’s AI literacy","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",116,"2022-07-13 09:33:38","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",117,"2022-07-13 09:33:38","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
8,"A. Habib, E. Wong, R. Sacks, N. Singh","Artificial intelligence to detect tympanic membrane perforations.",2020,"","","","",118,"2022-07-13 09:33:38","","10.1017/s0022215120000717","","",,,,,8,4.00,2,4,2,"OBJECTIVE To explore the feasibility of constructing a proof-of-concept artificial intelligence algorithm to detect tympanic membrane perforations, for future application in under-resourced rural settings.   METHODS A retrospective review was conducted of otoscopic images analysed using transfer learning with Google's Inception-V3 convolutional neural network architecture. The 'gold standard' 'ground truth' was defined by otolaryngologists. Perforation size was categorised as less than one-third (small), one-third to two-thirds (medium), or more than two-thirds (large) of the total tympanic membrane diameter.   RESULTS A total of 233 tympanic membrane images were used (183 for training, 50 for testing). The algorithm correctly identified intact and perforated tympanic membranes (overall accuracy = 76.0 per cent, 95 per cent confidence interval = 62.1-86.0 per cent); the area under the curve was 0.867 (95 per cent confidence interval = 0.771-0.963).   CONCLUSION A proof-of-concept image-classification artificial intelligence algorithm can be used to detect tympanic membrane perforations and, with further development, may prove to be a valuable tool for ear disease screening. Future endeavours are warranted to develop a point-of-care tool for healthcare workers in areas distant from otolaryngology.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",119,"2022-07-13 09:33:38","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
6,"Taehyun Ha, Y. Sah, Yuri Park, Sangwon Lee","Examining the effects of power status of an explainable artificial intelligence system on users’ perceptions",2020,"","","","",120,"2022-07-13 09:33:38","","10.1080/0144929X.2020.1846789","","",,,,,6,3.00,2,4,2,"ABSTRACT Contrary to the traditional concept of artificial intelligence, explainable artificial intelligence (XAI) aims to provide explanations for the prediction results and make users perceive the system as being reliable. However, despite its importance, only a few studies have investigated how the explanations of an XAI system should be designed. This study investigates how people attribute the perceived ability of XAI systems based on perceived attributional qualities and how the power status of the XAI and anthropomorphism affect the attribution process. In a laboratory experiment, participants (N = 500) read a scenarios of using an XAI system with either lower or higher power status and reported their perceptions of the system. Results indicated that an XAI system with a higher power status caused users to perceive the outputs of the XAI system to be more controllable by intention, and higher perceived stability and uncontrollability resulted in greater confidence in the system’s ability. The effect of perceived controllability on perceived ability was moderated by the extent to which participants anthropomorphised the system. Several design implications for XAI systems are suggested based on our findings.","",""
6,"I. Dumic-Cule, T. Oreskovic, B. Brkljačić, M. Kujundžić Tiljak, Stjepan Oreskovic","The importance of introducing artificial intelligence to the medical curriculum – assessing practitioners’ perspectives",2020,"","","","",121,"2022-07-13 09:33:38","","10.3325/cmj.2020.61.457","","",,,,,6,3.00,1,5,2,"Aim To assess the attitude about the importance of introducing education on artificial intelligence (AI) in medical schools’ curricula among physicians whose everyday job is significantly impacted by AI. Methods An anonymous questionnaire was distributed at the national level in Croatia among radiologists and radiology residents practicing in primary, secondary, and tertiary health care institutions, both in the private and the public sectors. The overall response rate was 45% (144 of 321). Results A large majority of participants – 89.6% (95% Agresti-Coull confidence interval 0.83-0.94) agreed on the need for education on AI to be included in medical curricula. Answers revealed a very high support across age groups and regardless of subspecialty area. A slightly higher support was present among physicians working in university hospitals compared with those in primary care centers, and among radiology residents compared with radiologists – but these estimated differences are uncertain, and the support levels were clearly high across the considered variables. Conclusion Since medical students have previously been shown to support introducing education on AI, a growing literature argues the same for reasons here reviewed, and physicians practicing a highly relevant area (radiology) overwhelmingly agree, we conclude that medical schools should indeed take steps to keep pace with technological progress in medicine by including education on AI in their curricula, be it as part of existing or new courses.","",""
6,"T. York, Heloise Jenney, G. Jones","Clinician and computer: a study on patient perceptions of artificial intelligence in skeletal radiography",2020,"","","","",122,"2022-07-13 09:33:38","","10.1136/bmjhci-2020-100233","","",,,,,6,3.00,2,3,2,"Background Up to half of all musculoskeletal injuries are investigated with plain radiographs. However, high rates of image interpretation error mean that novel solutions such as artificial intelligence (AI) are being explored. Objectives To determine patient confidence in clinician-led radiograph interpretation, the perception of AI-assisted interpretation and management, and to identify factors which might influence these views. Methods A novel questionnaire was distributed to patients attending fracture clinic in a large inner-city teaching hospital. Categorical and Likert scale questions were used to assess participant demographics, daily electronics use, pain score and perceptions towards AI used to assist in interpretation of their radiographs, and guide management. Results 216 questionnaires were included (M=126, F=90). Significantly higher confidence in clinician rather than AI-assisted interpretation was observed (clinician=9.20, SD=1.27 vs AI=7.06, SD=2.13), 95.4% reported favouring clinician over AI-performed interpretation in the event of disagreement. Small positive correlations were observed between younger age/educational achievement and confidence in AI-assistance. Students demonstrated similarly increased confidence (8.43, SD 1.80), and were over-represented in the minority who indicated a preference for AI-assessment over their clinicians (50%). Conclusions Participant’s held the clinician’s assessment in the highest regard and expressed a clear preference for it over the hypothetical AI assessment. However, robust confidence scores for the role of AI-assistance in interpreting skeletal imaging suggest patients view the technology favourably. Findings indicate that younger, more educated patients are potentially more comfortable with a role for AI-assistance however further research is needed to overcome the small number of responses on which these observations are based.","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",123,"2022-07-13 09:33:38","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",124,"2022-07-13 09:33:38","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",125,"2022-07-13 09:33:38","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
4,"K. Jain","Artificial Intelligence Applications in handling the Infectious Diseases",2020,"","","","",126,"2022-07-13 09:33:38","","10.35248/2167-1079.20.10.351","","",,,,,4,2.00,4,1,2,"Infectious diseases can be caused by direct or indirect transmission of   microorganisms such as virus, bacteria, parasites or fungi. The spread of   these diseases and infection may cause global pandemic like COVID 19.   Advancement of Artificial Intelligence can help the scientists in predicting   the infectious diseases to contain the spread of pandemic, understanding   the behavior of microorganisms and also help in faster drug discovery to   contain the disease. Artificial Intelligence provides new confidence to not   only preempt, prevent and control the spread of infectious diseases, but it   also helps the scientists in faster clinical trials and identification of effective   drug discovery for tacking the diseases. Artificial Intelligence is at the   cusp of revolutionizing the healthcare system via focused, disease specific   analysis and interventions to promote faster, more reliable and economical   healthcare solutions for the well-being of human kind. This article discusses   potential applications of AI which can assist the health institutions and global   community health by combating the rise of infectious diseases.","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",127,"2022-07-13 09:33:38","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",128,"2022-07-13 09:33:38","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",129,"2022-07-13 09:33:38","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",130,"2022-07-13 09:33:38","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",131,"2022-07-13 09:33:38","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
13,"M. Ghasemi, A. Nassef, M. Al-Dhaifallah, Hegazy Rezk","Performance improvement of microbial fuel cell through artificial intelligence",2020,"","","","",132,"2022-07-13 09:33:38","","10.1002/er.5484","","",,,,,13,6.50,3,4,2,"The current work introduces an enhancement in the performance of the microbial fuel cell through estimating the optimal set of controlling parameters. The maximization of both power density (PD) and the percentage of chemical oxygen demand (COD) removal were considered as the enhancement in the cell's performance. Three main parameters in terms of performance as well as commercialization are the system's inputs; the Pt which takes the range of 0.1‐0.5 mg/cm2, the degree of sulphonation in sulfonated‐poly‐ether‐ether‐ketone that changes in the range of 20‐80%, and the rate of aeration of cathode which varies between 10 and 150 mL/min. From the experimental dataset, two robust adaptive neuro‐fuzzy inference system models based on the fuzzy logic technique have been constructed. The comparisons between the models' outputs and the experimental data showed well‐fitting in both training and testing datasets. The mean squared errors of the PD model, for testing and whole datasets, were found 2.575 and 0.909 while for the COD model it showed 19.242 and 6.791, respectively. Then, based on the two fuzzy models, a Particle Swarm Optimization algorithm has been used to determine the best parameters that maximize both of the PD and the COD removal of the cell. The optimization process was utilized for single and multi‐object optimization processes. In the single optimization, the resulting maximums of the PD and the COD removal were found 62.844 (mW/m2) and 99.99 (%), respectively. Whereas, in the multi‐object optimization, the values of 61.787 (mW/m2) and 96.21 (%) were reached as the maximums for the PD and COD, respectively. This implies that, in both cases of optimization processes, the adopted methodology can efficiently enhance the microbial fuel cell performances than the previous work.","",""
17,"Shengjie Xu, Y. Qian, R. Hu","Data-Driven Edge Intelligence for Robust Network Anomaly Detection",2020,"","","","",133,"2022-07-13 09:33:38","","10.1109/TNSE.2019.2936466","","",,,,,17,8.50,6,3,2,"The advancement of networking platforms for assured online services requires robust and effective network intelligence systems against anomalous events and malicious threats. With the rapid development of modern communication technologies, artificial intelligence, and the revolution of computing devices, cloud computing empowered network intelligence will inevitably become a core platform for various smart applications. While cloud computing provides strong and powerful computation, storage, and networking services to detect and defend cyber threats, edge computing on the other hand will deliver more benefits in specific yet potential critical areas. In this paper, we present a study on the data-driven edge intelligence for robust network anomaly detection. We first highlight the main motivations for edge intelligence, and then propose an intelligence system empowered by edge computing for network anomaly detection. We further propose a scheme on the data-driven robust network anomaly detection. In the proposed scheme, four phases are designed to incorporate with data-driven approaches to train a learning model which is able to detect and identify a network anomaly in a robust way. In the performance evaluations with data experiments, we demonstrate that the proposed scheme achieves the robustness of trained model and the efficiency on the detection of specific anomalies.","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",134,"2022-07-13 09:33:38","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",135,"2022-07-13 09:33:38","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
20,"Y. Wang, L. Baratto, K. Hawk, Ashok J Theruvath, Allison Pribnow, A. Thakor, S. Gatidis, Rong Lu, Santosh E. Gummidipundi, J. Garcia-Diaz, D. Rubin, H. Daldrup-Link","Artificial intelligence enables whole-body positron emission tomography scans with minimal radiation exposure",2021,"","","","",136,"2022-07-13 09:33:38","","10.1007/s00259-021-05197-3","","",,,,,20,20.00,2,12,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",137,"2022-07-13 09:33:38","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",138,"2022-07-13 09:33:38","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",139,"2022-07-13 09:33:38","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
6,"S. Jaekel, Bastian Scholz","Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft",2015,"","","","",140,"2022-07-13 09:33:38","","10.1109/AERO.2015.7119180","","",,,,,6,0.86,3,2,7,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.","",""
3,"D. Denkenberger, Anders Sandberg, R. Tieman, J. Pearce","Long-term cost-effectiveness of interventions for loss of electricity/industry compared to artificial general intelligence safety",2021,"","","","",141,"2022-07-13 09:33:38","","10.1186/s40309-021-00178-z","","",,,,,3,3.00,1,4,1,"","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",142,"2022-07-13 09:33:38","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",143,"2022-07-13 09:33:38","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
151,"S. Goldenberg, G. Nir, S. Salcudean","A new era: artificial intelligence and machine learning in prostate cancer",2019,"","","","",144,"2022-07-13 09:33:38","","10.1038/s41585-019-0193-3","","",,,,,151,50.33,50,3,3,"","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",145,"2022-07-13 09:33:38","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",146,"2022-07-13 09:33:38","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",147,"2022-07-13 09:33:38","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",148,"2022-07-13 09:33:38","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",149,"2022-07-13 09:33:38","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
61,"E. Conant, A. Toledano, S. Periaswamy, S. Fotin, Jonathan Go, Justin E. Boatsman, J. Hoffmeister","Improving Accuracy and Efficiency with Concurrent Use of Artificial Intelligence for Digital Breast Tomosynthesis.",2019,"","","","",150,"2022-07-13 09:33:38","","10.1148/RYAI.2019180096","","",,,,,61,20.33,9,7,3,"Purpose To evaluate the use of artificial intelligence (AI) to shorten digital breast tomosynthesis (DBT) reading time while maintaining or improving accuracy.   Materials and Methods A deep learning AI system was developed to identify suspicious soft-tissue and calcified lesions in DBT images. A reader study compared the performance of 24 radiologists (13 of whom were breast subspecialists) reading 260 DBT examinations (including 65 cancer cases) both with and without AI. Readings occurred in two sessions separated by at least 4 weeks. Area under the receiver operating characteristic curve (AUC), reading time, sensitivity, specificity, and recall rate were evaluated with statistical methods for multireader, multicase studies.   Results Radiologist performance for the detection of malignant lesions, measured by mean AUC, increased 0.057 with the use of AI (95% confidence interval [CI]: 0.028, 0.087; P < .01), from 0.795 without AI to 0.852 with AI. Reading time decreased 52.7% (95% CI: 41.8%, 61.5%; P < .01), from 64.1 seconds without to 30.4 seconds with AI. Sensitivity increased from 77.0% without AI to 85.0% with AI (8.0%; 95% CI: 2.6%, 13.4%; P < .01), specificity increased from 62.7% without to 69.6% with AI (6.9%; 95% CI: 3.0%, 10.8%; noninferiority P < .01), and recall rate for noncancers decreased from 38.0% without to 30.9% with AI (7.2%; 95% CI: 3.1%, 11.2%; noninferiority P < .01).   Conclusion The concurrent use of an accurate DBT AI system was found to improve cancer detection efficacy in a reader study that demonstrated increases in AUC, sensitivity, and specificity and a reduction in recall rate and reading time.© RSNA, 2019See also the commentary by Hsu and Hoyt in this issue.","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",151,"2022-07-13 09:33:38","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
47,"T. Phong, Trong Trinh Phan, Indra Prakash, S. Singh, A. Shirzadi, K. Chapi, H. Ly, Lanh Si Ho, Nguyen Kim Quoc, B. Pham","Landslide susceptibility modeling using different artificial intelligence methods: a case study at Muong Lay district, Vietnam",2019,"","","","",152,"2022-07-13 09:33:38","","10.1080/10106049.2019.1665715","","",,,,,47,15.67,5,10,3,"Abstract Landslide is a natural hazard which causes huge loss of properties and human life in many places of the world. Mapping of landslide susceptibility is an important task for preventing and combating the landslides problems. Main objective of this study is to use different artificial intelligence methods namely support vector machines (SVM), artificial neural networks (ANN), logistic regression (LR), and reduced error-pruning tree (REPT) in the development of models for landslide susceptibility mapping of Muong Lay district of Vietnam. In total data of 217 landslide locations of the study area was used for the development and evaluation of the models. Nine landslide-conditioning factors were used for generating the datasets for training and validating the models. Results show that the SVM outperformed all other methods namely ANN, LR and REPT. Thus, it can be suggested that the SVM method is more useful in developing accurate and robust landslide prediction model.","",""
49,"J. Kwon, Kyung-Hee Kim, K. Jeon, Sang Eun Lee, Hae-Young Lee, Hyun-Jai Cho, Jin-oh Choi, E. Jeon, Min-Seok Kim, Jae-Joong Kim, K. Hwang, S. Chae, S. Baek, Seok‐Min Kang, D. Choi, B. Yoo, Kyehun Kim, Hyun-Young Park, M. Cho, B. Oh","Artificial intelligence algorithm for predicting mortality of patients with acute heart failure",2019,"","","","",153,"2022-07-13 09:33:38","","10.1371/journal.pone.0219302","","",,,,,49,16.33,5,20,3,"Aims This study aimed to develop and validate deep-learning-based artificial intelligence algorithm for predicting mortality of AHF (DAHF). Methods and results 12,654 dataset from 2165 patients with AHF in two hospitals were used as train data for DAHF development, and 4759 dataset from 4759 patients with AHF in 10 hospitals enrolled to the Korean AHF registry were used as performance test data. The endpoints were in-hospital, 12-month, and 36-month mortality. We compared the DAHF performance with the Get with the Guidelines–Heart Failure (GWTG-HF) score, Meta-Analysis Global Group in Chronic Heart Failure (MAGGIC) score, and other machine-learning models by using the test data. Area under the receiver operating characteristic curve of the DAHF were 0.880 (95% confidence interval, 0.876–0.884) for predicting in-hospital mortality; these results significantly outperformed those of the GWTG-HF (0.728 [0.720–0.737]) and other machine-learning models. For predicting 12- and 36-month endpoints, DAHF (0.782 and 0.813) significantly outperformed MAGGIC score (0.718 and 0.729). During the 36-month follow-up, the high-risk group, defined by the DAHF, had a significantly higher mortality rate than the low-risk group(p<0.001). Conclusion DAHF predicted the in-hospital and long-term mortality of patients with AHF more accurately than the existing risk scores and other machine-learning models.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",154,"2022-07-13 09:33:38","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",155,"2022-07-13 09:33:38","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",156,"2022-07-13 09:33:38","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
17,"W. Bulten, K. Kartasalo, Po-Hsuan Cameron Chen, P. Ström, H. Pinckaers, K. Nagpal, Yuannan Cai, David F. Steiner, H. V. van Boven, Robert Vink, C. Hulsbergen–van de Kaa, J. A. van der Laak, M. Amin, A. Evans, T. van der Kwast, Robert Allan, P. Humphrey, H. Grönberg, H. Samaratunga, B. Delahunt, T. Tsuzuki, T. Häkkinen, L. Egevad, Maggie Demkin, Sohier Dane, Fraser Tan, Masi Valkonen, G. Corrado, L. Peng, C. Mermel, P. Ruusuvuori, G. Litjens, M. Eklund","Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge",2022,"","","","",157,"2022-07-13 09:33:38","","10.1038/s41591-021-01620-2","","",,,,,17,17.00,2,33,1,"","",""
12,"H. Ibrahim, Xiaoxuan Liu, S. C. Rivera, D. Moher, A. Chan, M. Sydes, M. Calvert, A. Denniston","Reporting guidelines for clinical trials of artificial intelligence interventions: the SPIRIT-AI and CONSORT-AI guidelines",2021,"","","","",158,"2022-07-13 09:33:38","","10.1186/s13063-020-04951-6","","",,,,,12,12.00,2,8,1,"","",""
22,"Rushikesh S. Joshi, Alexander F. Haddad, Darryl Lau, C. Ames","Artificial Intelligence for Adult Spinal Deformity",2019,"","","","",159,"2022-07-13 09:33:38","","10.14245/ns.1938414.207","","",,,,,22,7.33,6,4,3,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery.","",""
21,"D. Ting, M. Ang, J. Mehta, D. Ting","Artificial intelligence-assisted telemedicine platform for cataract screening and management: a potential model of care for global eye health",2019,"","","","",160,"2022-07-13 09:33:38","","10.1136/bjophthalmol-2019-315025","","",,,,,21,7.00,5,4,3,"Artificial intelligence (AI) is the fourth industrial revolution.1 Deep learning is a robust machine learning technique that uses convolutional neural network to perform multilevel data abstraction without the need for manual feature engineering.2 In ophthalmology, many studies showed comparable, if not better, diagnostic performance in using AI to screen, diagnose, predict and monitor various eye conditions on fundus photographs and optical coherence tomography,3 4 including diabetic retinopathy (DR),5 age-related macular degeneration,6 glaucoma,7 retinopathy of prematurity (ROP).8   To date, many countries have reported well-established telemedicine programme to screen for DR and ROP,9–12 but limited for cataracts. Cataract is the leading cause of reversible blindness, affecting approximately 12.6 million (3.4–28.7 million) worldwide.13 14 The prevalence of cataract-related visual impairment also varies between high-income and low-income countries, with the latter having poorer access to tertiary care.13 In this issue, Wu et al 15 reported an AI-integrated telemedicine platform to screen and refer patients with cataract. This article consists of two parts: (1) the first part focusing on the AI system in detection of three tasks (capture mode, cataract diagnosis and referable cataract) and (2) the second part describing how these AI algorithms could be integrated in the telemedicine platform for real-world operational use. In this study, the referable cases were defined as: (1) grade 3 and grade 4 nuclear sclerotic …","",""
16,"K. Denecke, E. Gabarron, R. Grainger, S. Konstantinidis, A. Lau, O. Rivera-Romero, T. Miron-Shatz, M. Merolli","Artificial Intelligence for Participatory Health: Applications, Impact, and Future Implications",2019,"","","","",161,"2022-07-13 09:33:38","","10.1055/s-0039-1677902","","",,,,,16,5.33,2,8,3,"Summary Objective : Artificial intelligence (AI) provides people and professionals working in the field of participatory health informatics an opportunity to derive robust insights from a variety of online sources. The objective of this paper is to identify current state of the art and application areas of AI in the context of participatory health. Methods : A search was conducted across seven databases (PubMed, Embase, CINAHL, PsychInfo, ACM Digital Library, IEEExplore, and SCOPUS), covering articles published since 2013. Additionally, clinical trials involving AI in participatory health contexts registered at clinicaltrials.gov were collected and analyzed. Results : Twenty-two articles and 12 trials were selected for review. The most common application of AI in participatory health was the secondary analysis of social media data: self-reported data including patient experiences with healthcare facilities, reports of adverse drug reactions, safety and efficacy concerns about over-the-counter medications, and other perspectives on medications. Other application areas included determining which online forum threads required moderator assistance, identifying users who were likely to drop out from a forum, extracting terms used in an online forum to learn its vocabulary, highlighting contextual information that is missing from online questions and answers, and paraphrasing technical medical terms for consumers. Conclusions : While AI for supporting participatory health is still in its infancy, there are a number of important research priorities that should be considered for the advancement of the field. Further research evaluating the impact of AI in participatory health informatics on the psychosocial wellbeing of individuals would help in facilitating the wider acceptance of AI into the healthcare ecosystem.","",""
0,"R. Philipsen, P. Brauner, Hannah Biermann, M. Ziefle","I Am What I Am – Roles for Artificial Intelligence from the Users’ Perspective",2022,"","","","",162,"2022-07-13 09:33:38","","10.54941/ahfe1001453","","",,,,,0,0.00,0,4,1,"With increasing digitization, intelligent software systems are taking over more tasks in everyday human life, both in private and professional contexts. So-called artificial intelligence (AI) ranges from subtle and often unnoticed improvements in daily life, optimizations in data evaluation, assistance systems with which the people interact directly, to perhaps artificial anthropomorphic entities in the future. How-ever, no etiquette yet exists for integrating AI into the human living environment, which has evolved over millennia for human interaction. This paper addresses what roles AI may take, what knowledge AI may have, and how this is influenced by user characteristics. The results show that roles with personal relationships, such as an AI as a friend or partner, are not preferred by users. The higher the confidence in an AI's handling of data, the more likely personal roles are seen as an option for the AI, while the preference for subordinate roles, such as an AI as a servant or a subject, depends on general technology acceptance and belief in a dangerous world. The role attribution is independent from the usage intention and the semantic perception of artificial intelligence, which differs only slightly, e.g., in terms of morality and controllability, from the perception of human intelligence.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",163,"2022-07-13 09:33:38","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
0,"Zhang Meng, Nan Li","Simulation of English Word Order Sorting Based on Semionline Model and Artificial Intelligence",2022,"","","","",164,"2022-07-13 09:33:38","","10.1155/2022/5999853","","",,,,,0,0.00,0,2,1,"To improve the word order ranking effect of English language retrieval, based on machine learning algorithms, this paper combines a semionline model to construct an artificial intelligence ranking model for English word order based on a semionline model and establishes a semisupervised ELM regression model. Moreover, this paper derives the mathematical model of semisupervised ELM in detail and uses FCM clustering to screen credible samples, ELM collaborative training to mark each other's samples, and the marked samples to calculate the output weights of semisupervised ELM regression. In addition, based on continuous learning of OSELMR, this paper uses confidence evaluation to screen out credible unlabeled samples, OSELM collaborative training to mark the credible samples with each other, and credible unlabeled samples to calculate the output weight of SSOSELMR. Finally, this paper designs a control experiment to analyze the model algorithm, compares and counts the parameters, and draws a statistical graph. The research results show that the model constructed in this paper is effective.","",""
19,"E. O. Kontis, T. Papadopoulos, M. Syed, E. Guillo‐Sansano, G. Burt, G. Papagiannis","Artificial-Intelligence Method for the Derivation of Generic Aggregated Dynamic Equivalent Models",2019,"","","","",165,"2022-07-13 09:33:38","","10.1109/TPWRS.2019.2894185","","",,,,,19,6.33,3,6,3,"Aggregated equivalent models for the dynamic analysis of active distribution networks (ADNs) can be efficiently developed using dynamic responses recorded through field measurements. However, equivalent model parameters are highly affected from the time-varying composition of power system loads and the stochastic behavior of distributed generators. Thus, equivalent models, developed through in situ measurements, are valid only for the operating conditions from which they have been derived. To overcome this issue, in this paper, a new method is proposed for the derivation of generic aggregated dynamic equivalent models, i.e., for equivalent models that can be used for the dynamic analysis of a wide range of network conditions. The method incorporates clustering and artificial neural network techniques to derive robust sets of parameters for a variable-order dynamic equivalent model. The effectiveness of the proposed method is evaluated using measurements recorded on a laboratory-scale ADN, while its performance is compared with a conventional technique. The corresponding results reveal the applicability of the proposed approach for the analysis and simulation of a wide range of distinct network conditions.","",""
10,"P. Borrelli, Reza Kaboteh, Olof Enqvist, J. Ulén, E. Trägårdh, H. Kjölhede, L. Edenbrandt","Artificial intelligence-aided CT segmentation for body composition analysis: a validation study",2021,"","","","",166,"2022-07-13 09:33:38","","10.1186/s41747-021-00210-8","","",,,,,10,10.00,1,7,1,"","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",167,"2022-07-13 09:33:38","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",168,"2022-07-13 09:33:38","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",169,"2022-07-13 09:33:38","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
27,"Óscar Álvarez-Machancoses, J. Fernández-Martínez","Using artificial intelligence methods to speed up drug discovery",2019,"","","","",170,"2022-07-13 09:33:38","","10.1080/17460441.2019.1621284","","",,,,,27,9.00,14,2,3,"ABSTRACT Introduction: Drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. Due to the high complexity of genomic data, AI techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. Phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. Phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). This imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. Areas covered: In this paper, the authors present AI methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. Expert opinion: AI is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. The use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","",""
3,"","Using Natural and Artificial Intelligence in the Talent Management System",2019,"","","","",171,"2022-07-13 09:33:38","","10.35940/ijrte.c6152.098319","","",,,,,3,1.00,0,0,3,"The article describes the nature of the use of natural and artificial intelligence in the talent management system in the Moscow Region. The extent of using talent management technology, the tools, the ratio of demand for natural and artificial intelligence in talent management, and the level of employee confidence in man (robot) in management are analyzed. It is revealed and substantiated that personnel management services and the management of companies do not effectively use natural intelligence in the framework of the talent management system, relying on chance and a typical approach. Ambiguity in the assessment of artificial intelligence by both employees and company management was revealed. Increased use and fears of the negative impact of artificial intelligence become opposing factors in talent management. It is proposed to quickly implement advanced technologies based on artificial intelligence, with no harm to the human and his potential. It is also proposed to constantly keep in focus the risks of intercepting initiatives in the management of artificial intelligence and the crowding out of a person from the labor market. The main advantage of the article is an integrated approach to the study of the pattern of using natural and artificial intelligence in the talent management system. The authors considered the issue of identifying the ratio of artificial and natural intelligence in talent management for the first time. The results can serve as a basis for further research in the system of human resource management, as well as good support for making management decisions in the implementation of artificial intelligence in business processes and organization management.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",172,"2022-07-13 09:33:38","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",173,"2022-07-13 09:33:38","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
0,"Charles Tian, Yu Sun","AI_Birder: An Intelligent Mobile Application to Automate Bird Classification using Artificial Intelligence and Deep Learning",2022,"","","","",174,"2022-07-13 09:33:38","","10.5121/csit.2022.121005","","",,,,,0,0.00,0,2,1,"Birds are everywhere around us and are easy to spot. However, for many beginner birders, identifying the birds is a hard task [8]. There are many apps that help the birder to identify the birds, but they are often too complicated and require good internet to give a result. A better app is needed so that birders can identify birds while not depending on internet connection. My app, AI_Bider, is mainly built in android studio using flutter and firebase, and the AI engine is coded with TensorFlow and trained with images from the internet [9]. To test my AI engine, I made six different prototypes, each having a different number of times that the code will train from the dataset of pictures. I then selected 5 birds that are in my dataset and found 5 pictures on the internet for each of them, which I then uploaded to the app. My app will then give me 3 bird species that most closely resemble the image, as well as the app’s confidence in its choices, which are listed as percentages. I recorded down the percentages of accuracy for each picture. After taking the average percentage of all the models, I selected the most successful model, which had an average percent of accuracy of 79%.","",""
9,"Nawaf H. M. M. Shrifan, M. F. Akbar, N. Isa","Prospect of Using Artificial Intelligence for Microwave Nondestructive Testing Technique: A Review",2019,"","","","",175,"2022-07-13 09:33:38","","10.1109/ACCESS.2019.2934143","","",,,,,9,3.00,3,3,3,"The development in materials technology has produced stronger, lighter, stiffer, and more durable electrically insulating composites which are replacing metals in many applications. These composites require alternative inspection techniques because the conventional nondestructive testing (NDT) techniques such as thermography, eddy currents, ultrasonic, X-ray and magnetic particles have limitations of inspecting them. Microwave NDT technique employing open-ended rectangular waveguides (OERW) has emerged as a promising approach to detect the defects in both metal and composite materials. Despite its promising results over conventional NDT techniques, OERW microwave NDT technique has shown numerous limitations in terms of poor spatial resolution due to the stand-off distance variations, inspection area irregularities and quantitative estimation in imaging the size of defects. Microwave NDT employing OERW in conjunction with robust artificial intelligence approaches have tremendous potential and viability for evaluating composite structures for the purpose mentioned here. Artificial intelligence techniques with signal processing techniques are highly possible to enhance the efficiency and resolution of microwave NDT technique because the impact of artificial intelligence approaches is proven in various conventional NDT techniques. This paper provides a comprehensive review of NDT techniques as well as the prospect of using artificial intelligence approaches in microwave NDT technique with regards to other conventional NDT techniques.","",""
13,"K. Schaefer, Jean Oh, Derya Aksaray, D. Barber","Integrating Context into Artificial Intelligence: Research from the Robotics Collaborative Technology Alliance",2019,"","","","",176,"2022-07-13 09:33:38","","10.1609/aimag.v40i3.2865","","",,,,,13,4.33,3,4,3,"Applying context to a situation, task, or system state provides meaning and advances understanding that can affect future decisions or actions. Although people are naturally good at perceiving contextual understanding and inferring missing pieces of information using various alternative sources, this process is difficult for AI systems or robots, especially in high-uncertainty and unstructured operations. Integration of context-driven AI is important for future robotic capabilities to support the development of situation awareness, calibrate appropriate trust, and improve team performance in collaborative human-robot teams. This article highlights advances in context-driven AI for human-robot teaming by the Army Research Laboratory’s Robotics Collaborative Technology Alliance. Avenues of research discussed include how context enables robots to fill in the gaps to make effective decisions more quickly, supports more robust behaviors, and augments robot communications to suit the needs of the team under a variety of environments and team organizations and across missions.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",177,"2022-07-13 09:33:38","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",178,"2022-07-13 09:33:38","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",179,"2022-07-13 09:33:38","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",180,"2022-07-13 09:33:38","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",181,"2022-07-13 09:33:38","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",182,"2022-07-13 09:33:38","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",183,"2022-07-13 09:33:38","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",184,"2022-07-13 09:33:38","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
6,"Francisco Javier Abarca-Álvarez, F. S. Campos-Sánchez, Fernando Osuna-Pérez","Urban Shape and Built Density Metrics through the Analysis of European Urban Fabrics Using Artificial Intelligence",2019,"","","","",185,"2022-07-13 09:33:38","","10.3390/su11236622","","",,,,,6,2.00,2,3,3,"In recent decades, the concept of urban density has been considered key to the creation of sustainable urban fabrics. However, when it comes to measuring the built density, a difficulty has been observed in defining valid measurement indicators universally. With the intention of identifying the variables that allow the best characterization of the shape of urban fabrics and of obtaining the metrics of their density, a multi-variable analysis methodology from the field of artificial intelligence is proposed. The main objective of this paper was to evaluate the capacity and interest of such a methodology from standard indicators of the built density, measured at various urban scales, (i) to cluster differentiated urban profiles in a robust way by assessing the results statistically, and (ii) to obtain the metrics that characterize them with an identity. As a case study, this methodology was applied to the state of the art European urban fabrics (N = 117) by simultaneously integrating 13 regular parameters to qualify urban shape and density. It was verified that the profiles obtained were more robust than those based on a limited number of indicators, evidencing that the proposed methodology offers operational opportunities in urban management by allowing the comparison of a fabric with the identified profiles.","",""
8,"R. Rava, B. Peterson, Samantha E. Seymour, K. Snyder, M. Mokin, M. Waqas, Y. Hoi, J. Davies, E. Levy, A. Siddiqui, C. Ionita","Validation of an artificial intelligence-driven large vessel occlusion detection algorithm for acute ischemic stroke patients",2021,"","","","",186,"2022-07-13 09:33:38","","10.1177/1971400921998952","","",,,,,8,8.00,1,11,1,"Rapid and accurate diagnosis of large vessel occlusions (LVOs) in acute ischemic stroke (AIS) patients using automated software could improve clinical workflow in determining thrombectomy in eligible patients. Artificial intelligence-based methods could accomplish this; however, their performance in various clinical scenarios, relative to clinical experts, must be thoroughly investigated. We aimed to assess the ability of Canon’s AUTOStroke Solution LVO application in properly detecting and locating LVOs in AIS patients. Data from 202 LVO and 101 non-LVO AIS patients who presented with stroke-like symptoms between March 2019 and February 2020 were collected retrospectively. LVO patients had either an internal carotid artery (ICA) (n = 59), M1 middle cerebral artery (MCA) (n = 82) or M2 MCA (n = 61) occlusion. Computed tomography angiography (CTA) scans from each patient were pushed to the automation platform and analyzed. The algorithm’s ability to detect LVOs was assessed using accuracy, sensitivity and Matthews correlation coefficients (MCCs) for each occlusion type. The following results were calculated for each occlusion type in the study (accuracy, sensitivity, MCC): ICA = (0.95, 0.90, 0.89), M1 MCA = (0.89, 0.77, 0.78) and M2 MCA = (0.80, 0.51, 0.59). For the non-LVO cohort, 98% (99/101) of cases were correctly predicted as LVO negative. Processing time for each case was 69.8 ± 1.1 seconds (95% confidence interval). Canon’s AUTOStroke Solution LVO application was able to accurately identify ICA and M1 MCA occlusions in addition to almost perfectly assessing when an LVO was not present. M2 MCA occlusion detection needs further improvement based on the sensitivity results displayed by the LVO detection algorithm.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",187,"2022-07-13 09:33:38","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
6,"Jinwoo Cho, ByeongTak Lee, J. Kwon, Yeha Lee, Hyunho Park, B. Oh, K. Jeon, Jinsik Park, Kyung-Hee Kim","Artificial Intelligence Algorithm for Screening Heart Failure with Reduced Ejection Fraction Using Electrocardiography.",2021,"","","","",188,"2022-07-13 09:33:38","","10.1097/MAT.0000000000001218","","",,,,,6,6.00,1,9,1,"Although heart failure with reduced ejection fraction (HFrEF) is a common clinical syndrome and can be modified by the administration of appropriate medical therapy, there is no adequate tool available to perform reliable, economical, early-stage screening. To meet this need, we developed an interpretable artificial intelligence (AI) algorithm for HFrEF screening using electrocardiography (ECG) and validated its performance. This retrospective cohort study included two hospitals. An AI algorithm based on a convolutional neural network was developed using 39,371 ECG results from 17,127 patients. The internal validation included 3,470 ECGs from 2,908 patients. Furthermore, we conducted external validation using 4,362 ECGs from 4,176 patients from another hospital to verify the applicability of the algorithm across different centers. The end-point was to detect HFrEF, defined as an ejection fraction <40%. We also visualized the regions in 12 lead ECG that affected HFrEF detection in the AI algorithm and compared this to the previously documented literature. During the internal and external validation, the areas under the curves of the AI algorithm using a 12 lead ECG for detecting HFrEF were 0.913 (95% confidence interval, 0.902-0.925) and 0.961 (0.951-0.971), respectively, and the areas under the curves of the AI algorithm using a single-lead ECG were 0.874 (0.859-0.890) and 0.929 (0.911-0.946), respectively. The deep learning-based AI algorithm performed HFrEF detection well using not only a 12 lead but also a single-lead ECG. These results suggest that HFrEF can be screened not only using a 12 lead ECG, as is typical of a conventional ECG machine, but also with a single-lead ECG performed by a wearable device employing the AI algorithm, thereby preventing irreversible disease progression and mortality.","",""
95,"D. Milea, R. Najjar, Jiang Zhubo, D. Ting, C. Vasseneix, Xinxing Xu, Masoud Aghsaei Fard, P. Fonseca, K. Vanikieti, W. Lagrèze, C. La Morgia, C. Cheung, S. Hamann, C. Chiquet, Nicolae Sanda, Hui Yang, L. Mejico, M. Rougier, R. Kho, Tran Thi Ha Chau, S. Singhal, P. Gohier, C. Clermont-Vignal, Ching-Yu Cheng, J. Jonas, P. Yu-Wai-Man, C. Fraser, John J. Chen, S. Ambika, N. Miller, Yong Liu, N. Newman, T. Wong, V. Biousse","Artificial Intelligence to Detect Papilledema from Ocular Fundus Photographs.",2020,"","","","",189,"2022-07-13 09:33:38","","10.1056/NEJMoa1917130","","",,,,,95,47.50,10,34,2,"BACKGROUND Nonophthalmologist physicians do not confidently perform direct ophthalmoscopy. The use of artificial intelligence to detect papilledema and other optic-disk abnormalities from fundus photographs has not been well studied.   METHODS We trained, validated, and externally tested a deep-learning system to classify optic disks as being normal or having papilledema or other abnormalities from 15,846 retrospectively collected ocular fundus photographs that had been obtained with pharmacologic pupillary dilation and various digital cameras in persons from multiple ethnic populations. Of these photographs, 14,341 from 19 sites in 11 countries were used for training and validation, and 1505 photographs from 5 other sites were used for external testing. Performance at classifying the optic-disk appearance was evaluated by calculating the area under the receiver-operating-characteristic curve (AUC), sensitivity, and specificity, as compared with a reference standard of clinical diagnoses by neuro-ophthalmologists.   RESULTS The training and validation data sets from 6779 patients included 14,341 photographs: 9156 of normal disks, 2148 of disks with papilledema, and 3037 of disks with other abnormalities. The percentage classified as being normal ranged across sites from 9.8 to 100%; the percentage classified as having papilledema ranged across sites from zero to 59.5%. In the validation set, the system discriminated disks with papilledema from normal disks and disks with nonpapilledema abnormalities with an AUC of 0.99 (95% confidence interval [CI], 0.98 to 0.99) and normal from abnormal disks with an AUC of 0.99 (95% CI, 0.99 to 0.99). In the external-testing data set of 1505 photographs, the system had an AUC for the detection of papilledema of 0.96 (95% CI, 0.95 to 0.97), a sensitivity of 96.4% (95% CI, 93.9 to 98.3), and a specificity of 84.7% (95% CI, 82.3 to 87.1).   CONCLUSIONS A deep-learning system using fundus photographs with pharmacologically dilated pupils differentiated among optic disks with papilledema, normal disks, and disks with nonpapilledema abnormalities. (Funded by the Singapore National Medical Research Council and the SingHealth Duke-NUS Ophthalmology and Visual Sciences Academic Clinical Program.).","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",190,"2022-07-13 09:33:38","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
65,"C. Sit, R. Srinivasan, A. Amlani, K. Muthuswamy, A. Azam, L. Monzon, D. Poon","Attitudes and perceptions of UK medical students towards artificial intelligence and radiology: a multicentre survey",2020,"","","","",191,"2022-07-13 09:33:38","","10.1186/s13244-019-0830-7","","",,,,,65,32.50,9,7,2,"","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",192,"2022-07-13 09:33:38","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",193,"2022-07-13 09:33:38","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",194,"2022-07-13 09:33:38","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",195,"2022-07-13 09:33:38","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",196,"2022-07-13 09:33:38","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",197,"2022-07-13 09:33:38","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",198,"2022-07-13 09:33:38","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",199,"2022-07-13 09:33:38","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",200,"2022-07-13 09:33:38","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
