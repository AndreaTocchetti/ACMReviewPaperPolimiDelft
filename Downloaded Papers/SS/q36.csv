Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
161,"A. Bhagoji, Daniel Cullina, Chawin Sitawarin, Prateek Mittal","Enhancing robustness of machine learning systems via data transformations",2017,"","","","",1,"2022-07-13 09:23:39","","10.1109/CISS.2018.8362326","","",,,,,161,32.20,40,4,5,"We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification.","",""
0,"Jianbo Chen","Towards Interpretability and Robustness of Machine Learning Models",2019,"","","","",2,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,3,"Author(s): Chen, Jianbo | Advisor(s): Jordan, Michael I; Wainwright, Martin J | Abstract: Modern machine learning models can be difficult to probe and understand after they have been trained. This is a major problem for the field, with consequences for trustworthiness, diagnostics, debugging, robustness, and a range of other engineering and human interaction issues surrounding the deployment of a model. Another problem of modern machine learning models is their vulnerability to small adversarial perturbations to the input, which incurs a security risk when they are applied to critical areas.In this thesis, we develop systematic and efficient tools for interpreting machine learning models and evaluating their adversarial robustness. Part I focuses on model interpretation. We derive an efficient feature scoring method by exploiting the graph structure in data. We also develop a learning-based method under an information-based framework. As an attempt to leverage prior knowledge about what constitutes a satisfying interpretation in a given domain, we propose a systematic approach to exploiting syntactic constituency structure by leveraging a parse tree for interpretation of models in the setting of linguistic data. Part II focuses on the evaluation of adversarial robustness. We first propose a probabilistic framework for generating adversarial examples on discrete data, and develop two algorithms to implement it. We also introduce a novel attack method in the setting where the attacker has access to model decisions alone. We investigate the robustness of various machine learning models and existing defense mechanisms under the proposed attack method. In Part III, we build a connection between the two fields by developing a method for detecting adversarial examples via tools in model interpretation.","",""
0,"J. Z. Pan, Nicholas Zufelt","On Intrinsic Dataset Properties for Adversarial Machine Learning",2020,"","","","",3,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,2,"Deep neural networks (DNNs) have played a key role in a wide range of machine learning applications. However, DNN classifiers are vulnerable to human-imperceptible adversarial perturbations, which can cause them to misclassify inputs with high confidence. Thus, creating robust DNNs which can defend against malicious examples is critical in applications where security plays a major role. In this paper, we study the effect of intrinsic dataset properties on the performance of adversarial attack and defense methods, testing on five popular image classification datasets - MNIST, Fashion-MNIST, CIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play key roles in attack and defense success. Our discoveries highlight that dataset design and data preprocessing steps are important to boost the adversarial robustness of DNNs. To our best knowledge, this is the first comprehensive work that studies the effect of intrinsic dataset properties on adversarial machine learning.","",""
0,"A. Ke, Jian Huang, Jing Wang, Jiping He","Improving the Robustness of Human-Machine Interactive Control for Myoelectric Prosthetic Hand During Arm Position Changing",2022,"","","","",4,"2022-07-13 09:23:39","","10.3389/fnbot.2022.853773","","",,,,,0,0.00,0,4,1,"Robust classification of natural hand grasp type based on electromyography (EMG) still has some shortcomings in the practical prosthetic hand control, owing to the influence of dynamic arm position changing during hand actions. This study provided a framework for robust hand grasp type classification during dynamic arm position changes, improving both the “hardware” and “algorithm” components. In the hardware aspect, co-located synchronous EMG and force myography (FMG) signals are adopted as the multi-modal strategy. In the algorithm aspect, a sequential decision algorithm is proposed by combining the RNN-based deep learning model with a knowledge-based post-processing model. Experimental results showed that the classification accuracy of multi-modal EMG-FMG signals was increased by more than 10% compared with the EMG-only signal. Moreover, the classification accuracy of the proposed sequential decision algorithm improved the accuracy by more than 4% compared with other baseline models when using both EMG and FMG signals.","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",5,"2022-07-13 09:23:39","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
0,"Svitlana Volkova, Dustin L. Arendt, Emily Saldanha, M. Glenski, Ellyn Ayton, Joseph A. Cottam, Sinan G. Aksoy, Brett Jefferson, Karthnik Shrivaram","Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",2021,"","","","",6,"2022-07-13 09:23:39","","10.1007/s10588-021-09351-y","","",,,,,0,0.00,0,9,1,"","",""
3,"Jivitesh Sharma, Rohan Kumar Yadav, Ole-Christoffer Granmo, Lei Jiao","Human Interpretable AI: Enhancing Tsetlin Machine Stochasticity with Drop Clause",2021,"","","","",7,"2022-07-13 09:23:39","","","","",,,,,3,3.00,1,4,1,"In this article, we introduce a novel variant of the Tsetlin machine (TM) that randomly drops clauses, the key learning elements of a TM. In effect, TM with drop clause ignores a random selection of the clauses in each epoch, selected according to a predefined probability. In this way, additional stochasticity is introduced in the learning phase of TM. Along with producing more distinct and well-structured patterns that improve the performance, we also show that dropping clauses increases learning robustness. To explore the effects clause dropping has on accuracy, training time, and interpretability, we conduct extensive experiments on various benchmark datasets in natural language processing (NLP) (IMDb and SST2) as well as computer vision (MNIST and CIFAR10). In brief, we observe from +2% to +4% increase in accuracy and 2× to 4× faster learning. We further employ the Convolutional TM to document interpretable results on the CIFAR10 dataset. To the best of our knowledge, this is the first time an interpretable machine learning algorithm has been used to produce pixel-level human-interpretable results on CIFAR10. Also, unlike previous interpretable methods that focus on attention visualisation or gradient interpretability, we show that the TM is a more general interpretable method. That is, by producing rule-based propositional logic expressions that are human-interpretable, the TM can explain how it classifies a particular instance at the pixel level for computer vision and at the word level for NLP.","",""
17,"V. Mir, evská, M. Luštrek, M. Gams","Combining machine learning and expert knowledge for classifying human posture",2009,"","","","",8,"2022-07-13 09:23:39","","","","",,,,,17,1.31,4,4,13,"This paper presents a rule engine for classifying h uman posture according to information about the location f body parts. The rule engine was developed by enrich i g decision trees with expert knowledge. Results show 5 percentage points improvement in accuracy compared to support vector machines and a significant 11 percentage points compared to decision trees. The incorporation of expert knowledge overcomes the problem of classifier over-fitting observed with classifiers induced with machine learning. Better robustness of the posture classification rule engin e is expected in real-life tests in comparison to classi fiers induced with machine learning.","",""
8,"Hal S. Greenwald, Carsten K. Oertel","Future Directions in Machine Learning",2017,"","","","",9,"2022-07-13 09:23:39","","10.3389/frobt.2016.00079","","",,,,,8,1.60,4,2,5,"Current machine learning algorithms identify statistical regularities in complex data sets and are regularly used across a range of application domains, but they lack the robustness and generalizability associated with human learning. If machine learning techniques could enable computers to learn from fewer examples, transfer knowledge between tasks, and adapt to changing contexts and environments, the results would have very broad scientific and societal impacts. Increased processing and memory resources have enabled larger, more capable learning models, but there is growing recognition that even greater computing resources would not be sufficient to yield algorithms capable of learning from a few examples and generalizing beyond initial training sets. This paper presents perspectives on feature selection, representation schemes and interpretability, transfer learning, continuous learning, and learning and adaptation in time-varying contexts and environments, five key areas that are essential for advancing machine learning capabilities. Appropriate learning tasks that require these capabilities can demonstrate the strengths of novel machine learning approaches that could address these challenges.","",""
1,"Nemir Al-Azzawi","Human Action Recognition based on Hybrid Deep Learning Model and Shearlet Transform",2020,"","","","",10,"2022-07-13 09:23:39","","10.1109/ICITEE49829.2020.9271687","","",,,,,1,0.50,1,1,2,"The hybrid deep learning model has become common in all recent studies dealing with machine vision and human action recognition. Most of the accuracy in revealing knowledge of machine vision is in extracting important features, including segmentation of the image. This paper proposes a new model for recognizing human actions from video sequences by integrating repetitive, gated recurrent neural networks across multiple scales with shearlet-based image segmentation extraction. Segmentations are the most critical information to distinguish human action. The feature extraction can impact the complexity of the calculation and the performance of the algorithm. The idea is to increase training robustness and improve segmentation through the use of the shearlet transform. Hence, the video classification based on a recurrent neural network and shearlet transform will work optimally. The proposed approach is evaluated on human activity videos using KTH, UCF-101, and UCF Sports Action datasets. The experimental results showed state-of-the-art performance in comparison to current methods. The average resulting classification accuracy is 95.1% for the KTH datasets. That was the optimal case in our proposed model reached.","",""
2,"K. Yan, Adam P. Harrison","Interpretable Medical Image Classification with Self-Supervised Anatomical Embedding and Prior Knowledge",2021,"","","","",11,"2022-07-13 09:23:39","","","","",,,,,2,2.00,1,2,1,"In medical image analysis tasks, it is important to make machine learning models focus on correct anatomical locations, so as to improve interpretability and robustness of the model. We adopt a latest algorithm called self-supervised anatomical embedding (SAM) to locate point of interest (POI) on computed tomography (CT) scans. SAM can detect arbitrary POI with only one labeled sample needed. Then, we can extract targeted features from the POIs to train a simple prediction model guided by clinical prior knowledge. This approach mimics the practice of human radiologists, thus is interpretable, controllable, and robust. We illustrate our approach on the application of CT contrast phase classification and it outperforms an existing deep learning based method trained on the whole image.","",""
0,"Bernat Coma-Puig, J. Carmona","A Human-in-the-Loop Approach based on Explainability to Improve NTL Detection",2020,"","","","",12,"2022-07-13 09:23:39","","10.1109/ICDMW53433.2021.00123","","",,,,,0,0.00,0,2,2,"Implementing systems based on Machine Learning to detect fraud and other Non-Technical Losses (NTL) is challenging: the data available is biased, and the algorithms currently used are black-boxes that cannot be either easily trusted or understood by stakeholders. This work explains our human-in-the-loop approach to mitigate these problems in a real system that uses a supervised model to detect Non-Technical Losses (NTL) for an international utility company from Spain. This approach exploits human knowledge (e.g. from the data scientists or the company’s stakeholders) and the information provided by explanatory methods to guide the system during the training process. This simple, efficient method that can be easily implemented in other industrial projects is tested in a real dataset and the results show that the derived prediction model is better in terms of accuracy, interpretability, robustness and flexibility.","",""
38,"L. Mo, Fan Li, Yanjia Zhu, Anjie Huang","Human physical activity recognition based on computer vision with deep learning model",2016,"","","","",13,"2022-07-13 09:23:39","","10.1109/I2MTC.2016.7520541","","",,,,,38,6.33,10,4,6,"Human activity recognition is an active research area in the computer science because it is widely used in the fields of the security monitoring, health assessment, human machine interaction and other human related content searching. In this paper, a computer vision model based on the deep learning algorithm is proposed, which can recognize the human physical activity based on the skeleton data of the human body from the sensor of Microsoft Kinect. This model uses the human skeletons data from the CAD-60 dataset to recognize the human physical activity without using any prior knowledge. It can reduce the works on the stage of data preprocessing and feature extraction. It can also improve the generalization performance and robustness of the model, and give a better understanding of the human physical activity. Different tricks which can improve the performance of the neural networks, such as some regularization methods and other activation functions are tested. Finally, a convolutional neural network is used for the feature extraction, and a multilayer perceptron is used as the following classifier. The model can recognize twelve types of activities and the accuracy rate is 81.8%. It demonstrates that it is very effective to use the convolutional neural network to supervised learning and this model applies to human physical activity recognition.","",""
1,"Zhaoyuan Yang, Yang Zhao, Weizhong Yan","Adversarial Vulnerability in Doppler-based Human Activity Recognition",2020,"","","","",14,"2022-07-13 09:23:39","","10.1109/IJCNN48605.2020.9207686","","",,,,,1,0.50,0,3,2,"Human activity recognition (HAR) is an important task in many internet of things (IoT) applications. In recent years, significant efforts have been made towards achieving the highest possible recognition performance (accuracy and robustness) by using advanced machine learning techniques, including deep learning. However, to the best of our knowledge, the adversarial vulnerability of the Doppler sensor-based HAR systems has not been studied. In other domains such as computer vision, the vulnerability of deep learning algorithms to adversarial samples has attracted tremendous research interests in the past few years. In this work, we investigate the adversarial vulnerability of the Doppler-based human activity recognition system. Using a case study we demonstrate that the adversarial examples can significantly degrade the performance of the human activity recognition. Specifically, the basic iterative method (BIM) attack can reduce classification accuracy by as much as 85%. We also discuss different types of attacks, e.g., data poisoning attacks and potential strategies of protecting the Doppler-based HAR systems against adversarial attacks.","",""
0,"Jan Scholten, Daan Wout, C. Celemin, J. Kober","Deep Reinforcement Learning with Feedback-based Exploration",2019,"","","","",15,"2022-07-13 09:23:39","","10.1109/CDC40024.2019.9029503","","",,,,,0,0.00,0,4,3,"Deep Reinforcement Learning has enabled the control of increasingly complex and high-dimensional problems. However, the need of vast amounts of data before reasonable performance is attained prevents its widespread application. We employ binary corrective feedback as a general and intuitive manner to incorporate human intuition and domain knowledge in model-free machine learning. The uncertainty in the policy and the corrective feedback is combined directly in the action space as probabilistic conditional exploration. As a result, the greatest part of the otherwise ignorant learning process can be avoided. We demonstrate the proposed method, Predictive Probabilistic Merging of Policies (PPMP), in combination with DDPG. In experiments on continuous control problems of the OpenAI Gym, we achieve drastic improvements in sample efficiency, final performance, and robustness to erroneous feedback, both for human and synthetic feedback. Additionally, we show solutions beyond the demonstrated knowledge.","",""
5,"M. Selfridge, D. J. Dickerson, S. F. Biggs","Cognitive Expert Systems and Machine Learning: Artificial Intelligence Research at the University of Connecticut",1987,"","","","",16,"2022-07-13 09:23:39","","10.1609/AIMAG.V8I1.577","","",,,,,5,0.14,2,3,35,"In order for next-generation expert systems to demonstrate the performance, robustness, flexibility, and learning ability of human experts, they will have to be based on cognitive models of expert human reasoning and learning. We call such next-generation systems cognitive expert systems. Research at the Artificial Intelligence Laboratory at the University of Connecticut is directed toward understanding the principles underlying cognitive expert systems and developing computer programs embodying those principles. The Causal Model Acquisition System (CMACS) learns causal models of physical mechanisms by understanding real-world natural language explanations of those mechanisms. The going Concern Expert ( GCX) uses business and environmental knowledge to assess whether a company will remain in business for at least the following year. The Business Information System (BIS) acquires business and environmental knowledge from in-depth reading of real-world news stories. These systems are based on theories of expert human reasoning and learning, and thus represent steps toward next-generation cognitive expert systems.","",""
0,"Syed Irfan Ali Meerza, Mohammad M. Uzzal","Self Modeling and Gait Control of Quadruped Robot Using Q-Learning Based Particle Swarm Optimization",2019,"","","","",17,"2022-07-13 09:23:39","","10.53799/ajse.v18i3.24","","",,,,,0,0.00,0,2,3,"In the realm of the living creature human and animals create their body schema by the learning they gather while they interact with the real world. They can also remodel the schema if they have any uncertain changes in their body. This kind of robustness is still not achieved by any machine or artificial system. Researchers are trying to build the machines resilient so that machines can explore the unknown space. In this paper, we used Particle Swarm Optimization (PSO) which a population based algorithm to allow a quadruped robot to learn its body schema using a gyroscopic sensor and real world interaction. We added Q- Value based learning (Q-Learning),s an actor-critic scheme to aid PSO to learn faster and avoid being trap in local optima. Robot creates an imaginary model of its own body which include imaginary gaits using a very little prior knowledge. The robot aims to use the gaits to achieve stability and predictive movements. I can also detect changes in its body and adopt the changes, which leads to a damage diagnosis system. We tested the algorithm using graphics simulator and verified using a 3D printed quadruped robot with 12 actuators.","",""
7,"Jimmy J. Lin","The Simplest Thing That Can Possibly Work: (Pseudo-)Relevance Feedback via Text Classification",2019,"","","","",18,"2022-07-13 09:23:39","","10.1145/3471158.3472261","","",,,,,7,2.33,7,1,3,"Motivated by recent commentary that has questioned today's pursuit of ever-more complex models and mathematical formalisms in applied machine learning and whether meaningful empirical progress is actually being made, this paper tackles the decades-old problem of pseudo-relevance feedback with ""the simplest thing that can possibly work"". We present a technique based on training a document relevance classifier for each information need using pseudo-labels from an initial ranked list and then applying the classifier to rerank the retrieved documents. Experiments demonstrate significant improvements across a number of standard newswire collections, with initial rankings supplied by bag-of-words BM25 as well as from query expansion. Further evaluations in the TREC-COVID challenge using human relevance judgments verify the effectiveness and robustness of our proposed technique. While this simple idea draws elements from several well-known threads in the literature, to our knowledge this exact combination has not previously been proposed and rigorously evaluated.","",""
1,"Wenlu Zhang, Lusi Li, Vincent Cheong, Bo Fu, Mehrdad Aliasgari","Deep Encoder-Decoder Neural Networks for Retinal Blood Vessels Dense Prediction",2021,"","","","",19,"2022-07-13 09:23:39","","10.2991/ijcis.d.210308.001","","",,,,,1,1.00,0,5,1,"Automatic segmentation of retinal blood vessels from fundus images is of great importance in assessing the condition of vascular network in human eyes. The task is primary challenging due to the low contrast of images, the variety of vessels and potential pathology. Previous studies have proposed shallow machine learning based methods to tackle the problem. However, these methods require specific domain knowledge, and the efficiency and robustness of these methods are not satisfactory for medical diagnosis. In recent years, deep learning models have made great progress in various segmentation tasks. In particular, Fully Convolutional Network and U-net have achieved promising results in end-to-end dense prediction tasks. In this study, we propose a novel encoder-decoder architecture based on the vanilla U-net architecture for retinal blood vessels segmentation. The proposed deep learning architecture integrates hybrid dilation convolutions and pixel transposed convolutions in the encoderdecoder model. Such design enables global dense feature extraction and resolves the common “gridding” and “checkerboard” issues in the regular U-net. Furthermore, the proposed network can be efficiently and directly implemented for any semantic segmentation applications. We evaluate the proposed network on two retinal blood vessels data sets. The experimental results show that our proposed model outperforms the baseline U-net model.","",""
3,"Yuanlu Xu, Wenguan Wang, Tengyu Liu, Xiaobai Liu, Jianwen Xie, Song-Chun Zhu","Monocular 3D Pose Estimation via Pose Grammar and Data Augmentation.",2021,"","","","",20,"2022-07-13 09:23:39","","10.1109/TPAMI.2021.3087695","","",,,,,3,3.00,1,6,1,"In this paper, we propose a pose grammar to tackle the problem of 3D human pose estimation from a monocular RGB image. Our model takes estimated 2D pose as the input and learns a generalized 2D-3D mapping function to leverage into 3D pose. The proposed model consists of a base network which efficiently captures pose-aligned features and a hierarchy of Bi-directional RNNs (BRNNs) on the top to explicitly incorporate a set of knowledge regarding human body configuration (i.e., kinematics, symmetry, motor coordination). The proposed model thus enforces high-level constraints over human poses. In learning, we develop a data augmentation algorithm to further improve model robustness against appearance variations and cross-view generalization ability. We validate our method on public 3D human pose benchmarks and propose a new evaluation protocol working on cross-view setting to verify the generalization capability of different methods. We empirically observe that most state-of-the-art methods encounter difficulty under such setting while our method can well handle such challenges.","",""
2,"Wenyan Yang, N. Strokina, N. Serbenyuk, J. Pajarinen, R. Ghabcheloo, J. Vihonen, M. M. Aref, Joni-Kristian Kämäräinen","Neural Network Controller for Autonomous Pile Loading Revised",2021,"","","","",21,"2022-07-13 09:23:39","","10.1109/ICRA48506.2021.9561804","","",,,,,2,2.00,0,8,1,"We have recently proposed two pile loading controllers that learn from human demonstrations: a neural network (NNet) [1] and a random forest (RF) controller [2]. In the field experiments the RF controller obtained clearly better success rates. In this work, the previous findings are drastically revised by experimenting summer time trained controllers in winter conditions. The winter experiments revealed a need for additional sensors, more training data, and a controller that can take advantage of these. Therefore, we propose a revised neural controller (NNetV2) which has a more expressive structure and uses a neural attention mechanism to focus on important parts of the sensor and control signals. Using the same data and sensors to train and test the three controllers, NNetV2 achieves better robustness against drastically changing conditions and superior success rate. To the best of our knowledge, this is the first work testing a learning-based controller for a heavy-duty machine in drastically varying outdoor conditions and delivering high success rate in winter, being trained in summer.","",""
0,"M. Bender, Sven Panz","A general framework for the identification and categorization of risks: an application to the context of financial markets",2021,"","","","",22,"2022-07-13 09:23:39","","10.21314/jor.2021.004","","",,,,,0,0.00,0,2,1,"Risk represents a significant part of human interaction and must be considered in decision-making processes across diverse business and research areas. Further, the disregard or unawareness of certain risks may result in inappropriate decisionmaking processes and inadequate risk management practices that may negatively influence firms’ performance. This paper is, to the best of our knowledge, the first to develop an algorithm-based and generally applicable framework that generates an extensive and integrated identification and categorization scheme of certain risks by using text mining and machine learning approaches. To demonstrate the applicability of our framework, we apply our approach to the context of financial markets, identify 193 financial market risks and sort them into five categories by using common machine learning techniques. To evaluate the general applicability, we additionally apply our derived framework to the context of information systems. Finally, we obtain strong indications of the robustness and superiority of our derived framework Corresponding author: S. Panz Print ISSN 1465-1211 jOnline ISSN 1755-2842 c 2021 Infopro Digital Risk (IP) Limited","",""
0,"Kamal Hakimzadeh, Patrick K. Nicholson, Diego Lugones","Auto-Scaling with Apprenticeship Learning",2018,"","","","",23,"2022-07-13 09:23:39","","10.1145/3267809.3275454","","",,,,,0,0.00,0,3,4,"Current practices for provisioning and autoscaling applications in cloud are limited and require expert knowledge to deliver acceptable quality of service (QoS). The complexity of the cloud stack requires an iterative process to tune several parameters with robustness to varying workloads, software or hardware upgrades, failures, resource interference, etc. Usually, this process is performed by humans, which limits the agility to adapt to stack changes. The need for human expertise relates to the fact that different applications can have different and highly specific key performance indicators (KPI’s). Experts can configure provisioning and autoscaling actions based on application KPIs but that process needs to be repeated for the various combinations of applications, services, and platforms. That is, the KPI-based rules for one platform do not necessarily apply to other environments given the multiplicity of variables that can affect such rules. Recently, several proposals have included machine learning to remove some of the complexity and human intervention. Still, these techniques require significant amounts of data (e.g., in case of techniques based on deep learning), or a considerable number of iterations to converge to the appropriate rules (e.g., in case of techniques based on reinforcement learning). These limitations can be prohibitive in cloud because 1) the amount of data required can be difficult to obtain, particularly in multi-vendor environments with management policies and specific infrastructure conditions that limit data access, and 2) the number of parameters (or dimensions) to explore can be be unfeasible, even for simple applications. To overcome these problems, we propose a solution that differentiate from others in two major aspects. First, our proposal is generic and portable to different environments, and robust to changes in the stack. We achieve this by training a model that (indirectly) requires application specific KPIs one time: during the training phase. However, when deployed, the model only requires platform utilization metrics that are common to all infrastructures (e.g., CPU, Memory, IO, etc.). Second, we reduce the data requirements and exploration space by using apprenticeship learning (also called learning from demonstration) which makes use of an expert","",""
35,"M. R. Mendoza, G. C. da Fonseca, Guilherme Loss-Morais, Ronnie Alves, R. Margis, A. Bazzan","RFMirTarget: Predicting Human MicroRNA Target Genes with a Random Forest Classifier",2013,"","","","",24,"2022-07-13 09:23:39","","10.1371/journal.pone.0070153","","",,,,,35,3.89,6,6,9,"MicroRNAs are key regulators of eukaryotic gene expression whose fundamental role has already been identified in many cell pathways. The correct identification of miRNAs targets is still a major challenge in bioinformatics and has motivated the development of several computational methods to overcome inherent limitations of experimental analysis. Indeed, the best results reported so far in terms of specificity and sensitivity are associated to machine learning-based methods for microRNA-target prediction. Following this trend, in the current paper we discuss and explore a microRNA-target prediction method based on a random forest classifier, namely RFMirTarget. Despite its well-known robustness regarding general classifying tasks, to the best of our knowledge, random forest have not been deeply explored for the specific context of predicting microRNAs targets. Our framework first analyzes alignments between candidate microRNA-target pairs and extracts a set of structural, thermodynamics, alignment, seed and position-based features, upon which classification is performed. Experiments have shown that RFMirTarget outperforms several well-known classifiers with statistical significance, and that its performance is not impaired by the class imbalance problem or features correlation. Moreover, comparing it against other algorithms for microRNA target prediction using independent test data sets from TarBase and starBase, we observe a very promising performance, with higher sensitivity in relation to other methods. Finally, tests performed with RFMirTarget show the benefits of feature selection even for a classifier with embedded feature importance analysis, and the consistency between relevant features identified and important biological properties for effective microRNA-target gene alignment.","",""
0,"Hans J. G. A. Dolfing","Whole page recognition of historical handwriting",2020,"","","","",25,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,2,"Historical handwritten documents guard an important part of human knowledge only within reach of a few scholars and experts. Recent developments in machine learning and handwriting research have the potential of rendering this information accessible and searchable to a larger audience. To this end, we investigate an end-to-end inference approach without text localization which takes a handwritten page and transcribes its full text. No explicit character, word or line segmentation is involved in inference which is why we call this approach ""segmentation free"". We explore its robustness and accuracy compared to a line-by-line segmented approach based on the IAM, RODRIGO and ScribbleLens corpora, in three languages with handwriting styles spanning 400 years. We concentrate on model types and sizes which can be deployed on a hand-held or embedded device. We conclude that a whole page inference approach without text localization and segmentation is competitive.","",""
3,"Taesik Gong, A. Ramos, S. Bhattacharya, Akhil Mathur, F. Kawsar","AudiDoS: Real-Time Denial-of-Service Adversarial Attacks on Deep Audio Models",2019,"","","","",26,"2022-07-13 09:23:39","","10.1109/ICMLA.2019.00167","","",,,,,3,1.00,1,5,3,"Deep learning has enabled personal and IoT devices to rethink microphones as a multi-purpose sensor for understanding conversation and the surrounding environment. This resulted in a proliferation of Voice Controllable Systems (VCS) around us. The increasing popularity of such systems is also prone to attracting miscreants, who often want to take advantage of the VCS without the knowledge of the user. Consequently, understanding the robustness of VCS, especially under adversarial attacks, has become an important research topic. Although there exists some previous work on audio adversarial attacks, their scopes are limited to embedding the attacks onto pre-recorded music clips, which when played through speakers cause VCS to misbehave. As an attack-audio needs to be played, the occurrence of this type of attacks can be suspected by a human listener. In this paper, we focus on audio-based Denial-of-Service (DoS) attack, which is unexplored in the literature. Contrary to previous work, we show that adversarial audio attacks in real-time and overthe-air are possible, while a user interacts with VCS. We show that the attacks are effective regardless of the user's command and interaction timings. In this paper, we present a first-of-itskind imperceptible and always-on universal audio perturbation technique that enables such DoS attack to be successful. We thoroughly evaluate the performance of the attacking scheme across (i) two learning tasks, (ii) two model architectures and (iii) three datasets. We demonstrate that the attack can introduce as high as 78% error rate in audio recognition tasks.","",""
0,"B. Mukunthan","A NEURAL NETWORK APPROACH FOR THE PRECISE PATTERN RECOGNITION OF HUMAN DNA",2012,"","","","",27,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,10,"The primary goal of bio informatics and neural networks solely is to increase our understanding of biological processes and focus on developing and applying computationally intensive techniques (e.g., pattern recognition, data mining, machine learning algorithms, and visualization) to achieve this goal. The neural networks exhibit characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, parallel and high speed information processing. Neural networks learn by examples they can therefore be trained with known examples of a problem to ‘acquire’ knowledge about it. Once appropriately trained, the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. The perfect blend made of bioinformatics and neural networks results in efficient pattern analysis techniques. The conventional techniques and algorithms employed by forensic scientists to assist in the identification of individuals on the basis of their respective DNA profiles involves more computational steps and mathematical formulas that leads to more time and space complexity resulting in complicated and less efficient algorithms which can be shorted out by emerging Artificial Neural Network approach.","",""
46,"Reinhold Scherer, J. Faller, David Balderas, E. Friedrich, M. Pröll, B. Allison, G. Müller-Putz","Brain–computer interfacing: more than the sum of its parts",2013,"","","","",28,"2022-07-13 09:23:39","","10.1007/s00500-012-0895-4","","",,,,,46,5.11,7,7,9,"","",""
0,"E. Ali","Unsupervised Anomaly Isolation and Steady State Detection for Monitoring Dynamic Systems",2019,"","","","",29,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,3,"This paper deals with the problem of modelling and monitoring the fault-free states of an industrial  process without complete knowledge about the entire machine components. The aim thereby is to automatically  detect the deviations in performance as fault symptoms. For that type of data-based modelling, the algorithms  of clustering are selected with an emphasis on the computational load and application complexity. Kohonen  neural networks (self-organizing maps) are found suitable for the task due to the ability to efficiently operate on  high dimensional data and because of their robustness against uncertainties. They reveal drawbacks from the  perspective of identifying the deviating variable in the input space. A novel structure is designed to solve this  dilemma by combining multi one-dimensional domains and their statistical relationships, where Kohonen and  Bayesian algorithms would be directly applicable. The structure is introduced and applied to simulate the  human supervisors in the way of learning normal operation and hence, attempts to automatically identify the  deviating variable in a high amount of data. An example application is proposed for detecting the wear  degradation fault in a real electrohydraulic drive that widely used in many industrial machines. The algorithm  can be realized locally or integrated remotely in cloud architectures.","",""
24,"L. Stetson, Taylor Pearl, Yanwen Chen, J. Barnholtz-Sloan","Computational identification of multi-omic correlates of anticancer therapeutic response",2014,"","","","",30,"2022-07-13 09:23:39","","10.1186/1471-2164-15-S7-S2","","",,,,,24,3.00,6,4,8,"","",""
29,"Shengjun Li, Rui-min Shen","Fuzzy cognitive map learning based on improved nonlinear Hebbian rule",2004,"","","","",31,"2022-07-13 09:23:39","","10.1109/ICMLC.2004.1382183","","",,,,,29,1.61,15,2,18,"Fuzzy cognitive map (FCM) is a powerful soft computing technique for modeling complex systems. It is a combination of fuzzy logic theory and neural networks. Developing of FCM is easy and adaptable based on human knowledge and experience. On the other hand, the main dependence on experts' knowledge and opinion, and the potential convergence to undesire steady states are the shortcomings of FCMs. Learning methods are good choices used to overcome the shortcomings and strengthen the efficiency and robustness of FCM. This paper proposes one improved Hebbian algorithm on non-linear units for training FCMs. With the proposed learning procedure, FCM can modify its fuzzy causal web as casual pattern change and update their causal knowledge as experts.","",""
2,"Qianqian Wu, Jianzhi Lang, Songjie Wei, Mi-lin Ren, E. Seidel","A Novel Construction of Correlation-Based Image CAPTCHA with Random Walk",2018,"","","","",32,"2022-07-13 09:23:39","","10.1007/978-981-10-8971-8_31","","",,,,,2,0.50,0,5,4,"","",""
12,"C. Bauckhage, M. Hanheide, S. Wrede, Thomas Käster, M. Pfeiffer, G. Sagerer","Vision Systems with the Human in the Loop",2005,"","","","",33,"2022-07-13 09:23:39","","10.1155/ASP.2005.2375","","",,,,,12,0.71,2,6,17,"The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.","",""
0,"E. Ali, J. Weber","Unsupervised Anomaly Isolation for Condition Monitoring Systems",2018,"","","","",34,"2022-07-13 09:23:39","","10.1109/EECS.2018.00096","","",,,,,0,0.00,0,2,4,"This paper deals with the problem of modelling and monitoring the fault-free states of an industrial process without complete knowledge about the entire machine components. The aim thereby is to automatically detect the deviations in performance as fault symptoms. For that type of data-based modelling, the algorithms of clustering are selected with an emphasis on the computational load and application complexity. Kohonen neural networks (self-organizing maps) are found suitable for the task due to the ability to efficiently operate on high dimensional data and because of their robustness against uncertainties. They reveal drawbacks from the perspective of identifying the deviating variable in the input space. A novel structure is designed to solve this dilemma by combining multi one-dimensional domains and their statistical relationships, where Kohonen and Bayesian algorithms would be directly applicable. The structure is introduced and applied to simulate the human supervisors in the way of learning normal operation and hence, attempts to automatically identify the deviating variable in a high amount of data. An example application is proposed for detecting the wear degradation fault in a real electrohydraulic drive that widely used in many industrial machines. The algorithm can be realized locally or integrated remotely in cloud architectures.","",""
1,"W. Waegeman, B. Baets, L. Boullart","Integrating Expert Knowledge into Kernel-based Preference Models",2008,"","","","",35,"2022-07-13 09:23:39","","","","",,,,,1,0.07,0,3,14,"In multi-criteria decision making (MCDM) and fuzzy modeling, preference models are typically constructed by interacting with the human decision maker (DM). When the DM experiences difficulties to specify precise for all parameters of the model, inference and elicitation procedures can assist him/her to find a satisfactory model and to assess unlabelled examples. In a related but more statistical way, machine learning algorithms can also infer preference models with similar setups and purposes, but here less interaction with the DM is integrated. We present a hybrid approach that combines the best of both worlds. It consists of a general kernel-based framework for constructing and inferring preference models, in which expert knowledge can be included. Additive models, for which interpretability is preserved, and utility models can be considered as special cases. Besides generality, important benefits of this approach are its robustness to noise and good scalability. We show in detail how this framework can be utilized to aggregate single-criterion outranking relations, resulting in a flexible class of preference models for which domain knowledge can be specified by a DM.","",""
7,"Y. Ying, Han Wang","Dynamic random regression forests for real-time head pose estimation",2013,"","","","",36,"2022-07-13 09:23:39","","10.1007/s00138-013-0524-y","","",,,,,7,0.78,4,2,9,"","",""
8,"Jingyu Liu, M. Jamshidi, S. Pourbabak","Human cardiovascular system identification and application using a hybrid method of auto-regression and neuro-fuzzy inference systems",2004,"","","","",37,"2022-07-13 09:23:39","","10.1109/ICMLC.2004.1384559","","",,,,,8,0.44,3,3,18,"By far the most popular technique for mathematical identification of the cardiovascular system is auto-regressive moving average model based on linear assumption. However, the cardiovascular system regulated by autonomic nervous functions is a complex, unclear, and non-linear system. An effective hybrid approach, which has parallel modular structure of auto-regressive and neuro-fuzzy inference system, is proposed to identify cardiovascular linear mechanism of heart function and non-linear autonomic nervous regulation functions respectively. Auto-regressive is an efficient method to identify the stationary time series. Fuzzy set theory is very suitable to systems with uncertainties and expert knowledge. Neuro-fuzzy inference paradigm imports the auto-learning property into fuzzy logic engine, therefore extracts some knowledge from data automatically. Properties of this novel approach are evaluated based on three subjects' clinic data in term of accuracy, robustness, physiological meaning, and potential implementation in clinical problems. Modified pulse wave contour cardiac output measurement is introduced being an example of real world implementation.","",""
0,"Yves Peirsman, Mirella Lapata","Knowledge-Lean Approaches to Metonymy Recognition",2005,"","","","",38,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,17,"Current approaches to metonymy recognition are mainly supervised, relying heavily on the manual annotation of training and test data. This forms a considerable hindrance to their application on a wider scale. This dissertation therefore aims to relieve the knowledge acquisition bottleneck with respect to metonymy recognition by examining knowledge-lean approaches that reduce this need for human effort. This investigation involves the study of three algorithms that constitute an entire spectrum of machine learning approaches — unsupervised, supervised and semi-supervised ones. Chapter 2 will discuss an unsupervised approach to metonymy recognition, and will show that promising results can be reached when the data are automatically annotated with grammatical information. Although the robustness of these systems is limited, they can serve as a pre-processing step for the selection of useful training data, thereby reducing the workload for human annotators. Chapter 3 will investigate memory-based learning, a “lazy” supervised algorithm. This algorithm, which relies on an extremely simple learning stage, is able to replicate the results of more complex systems. Yet, it will also become clear that the performance of this algorithm, like that of others in the literature, depends heavily on grammatical annotation. Finally, chapter 4 will present a semi-supervised algorithm that produces very promising results with only ten labelled training instances. In addition, it will be shown that less than half of the training data from chapter 3 can lead to the same performance as the entire set. Semantic information in particular will prove very useful in this respect. In short, this dissertation presents experimental results which indicate that the knowledge acquisition bottleneck in metonymy recognition can be relieved with unsupervised and semi-supervised methods. These approaches may make the extension of current algorithms to a wide-scale metonymy resolution system a much more feasible task.","",""
0,"A. Homaifar, H. Hawari, Chafic W. Bou-Saba, A. Esterline, A. Iran-Nejad, E. Tunstel","Soft computing for agent-based decision making using the biofunctional theory of knowledge",2005,"","","","",39,"2022-07-13 09:23:39","","10.1109/ICSMC.2005.1571183","","",,,,,0,0.00,0,6,17,"This paper applies the biofunctional model of human learning to the implementation of a learning machine that is effective in navigating complex environments. The target model is rule-based and is highly flexible in establishing the relation between any state-action pair. The learning machine is designed using X classifier systems and a fuzzy logic controller (FLC). A learning machine is built in simulation that closely approximates the learning characteristics of the human brain as described by the theory of biofunctional cognition. The methodology is tested with experiments using both single and multiple agents. We also investigated the effectiveness of biofunctionality using competitive and cooperative modes. Furthermore, we studied the robustness of our approach. Our results show that the integration of a FLC and an X classifier system, realizing a biofunctional model, provides a methodology for constructing very effective learning machines.","",""
0,"A. Larson, R. Voyles","Programming Robot Behavior Primitives through Human Demonstration",2000,"","","","",40,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,22,"Robotic systems are capable of complex behavior by sequencing simpler skills called primitives (Voyles, Morrow, & Khosla 1997). A primitive is a sensor/actuator mapping robust enough to perform appropriately in various situations. Programming one primitive can be tedious and requires an accurate translation of human knowledge to machine code. Once a sufficient set of primitives is coded, the user must write code to sequence the primitives ‐ also tedious and difficult. Programming by human demonstration addresses these problems of acquiring and combining primitives. To create primitives, programming by demonstration can be implemented with a supervised learning technique such as artificial neural networks (ANN) to learn a sensor/actuator mapping. Problems exist with such techniques, however, including creating a training set which is comprehensive (for robustness) and concise (for efficienttraining). Here, we present a method for nonexpert users to collect “good” training data from an intuitive understanding of task behavior, not from knowledge of the underlying learning mechanism.","",""
0,"Thin Nguyen, Dinh Q. Phung, Wei Luo, T. Tran, S. Venkatesh","iPoll: Automatic Polling Using Online Search",2014,"","","","",41,"2022-07-13 09:23:39","","10.1007/978-3-319-11749-2_21","","",,,,,0,0.00,0,5,8,"","",""
9,"A. W. Example","Belief Propagation in Fuzzy Bayesian Networks",2008,"","","","",42,"2022-07-13 09:23:39","","","","",,,,,9,0.64,9,1,14,"Fuzzy Bayesian networks (FBN) are a graphical machine learning model representation with variables which are simultaneously fuzzy and uncertain[2]. Bayesian networks (BN) are commonly used in machine learning. This is due to their statistical rationality, capacity for rigorous causal inference, and robustness in the face of noisy, partially missing and realistic data. They are also more easily human-interpretable than other machine learning representations such as neural networks, and experts can specify prior knowledge in a principled manner to guide the machine learning search. A wide range of search algorithms have been developed for structural and parameter inference, including structural EM [3] and MCMC. Classically, Bayesian networks use continuous (Gaussian) or multinomial variables. Similarly, a fuzzy model has a wide range of advantages. Fuzzy models are also robust in the face of noise-corrupted data. The use of linguistic terms aids human comprehension of the learnt model, and they are particularly useful when the data is insufficient to formulate a precise model. The need to specify membership functions also forces the designer to consider the semantic interpretation of the model parameterisation and construction more explicitly. For these reasons, FBN (which combine these advantages) may be useful. Theoretical analysis in current research[1] indicates that fuzzy variables can be more expressive than multinomial or continuous variables. FBN may also be used as part of an integrated sequence of machine learning techniques that include reversible dimensionality reduction techniques such as fuzzy cover clustering algorithms. This may allow larger problems to be addressed with FBN than with classic BN.","",""
0,"Peer-Olaf Siebers","Hongmei He (intelligent System Lab, University of Bristol): Soft Computing Approaches under the Framework of Hierarchical Decision Making or Classification System",2010,"","","","",43,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,12,"Hongmei He (Intelligent System Lab, University of Bristol): Soft Computing Approaches Under the Framework of Hierarchical Decision Making or Classification System With the development of AI, we can see there are a surprising number of the brain functions of the human Intelligent System (IS) are quite similar to those of an artificial IS, since most artificial ISs are modelled through naturally emulating human intelligence. A wide variety of approaches have been utilised in the functional design of artificial ISs. For example, fuzzy logic for robustness, decision trees for the transparency of reasoning, machine learning for knowledge learning, semantics for understandability, probabilistic reasoning, and neural computing, etc.","",""
0,"Bordeaux-Sud-Ouest","Project-Team FLOWERS Flowing Epigenetic Robots and Systems",2009,"","","","",44,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,13,"In spite of considerable and impressive work in artificial intelligence, machine learning, and pattern recognition in the past 50 years, we have no machine capable of adapting to the physical and social environment with the flexibility, robustness and versatility of a 6-months old human child. Instead of trying to simulate directly the adult’s intelligence, EXPLORERS proposes to focus on the developmental processes that give rise to intelligence in infants by re-implementing them in machines. Framed in the developmental/epigenetic robotics research agenda, and grounded in research in human developmental psychology, its main target is to build robotic machines capable of autonomously learning and re-using a variety of skills and know-how that were not specified at design time, and with initially limited knowledge of the body and of the environment in which it will operate. This implies several fundamental issues: How can a robot discover its body and its relationships with the physical and social environment? How can it learn new skills without the intervention of an engineer? What internal motivations shall guide its exploration of vast spaces of skills? Can it learn through natural social interactions with humans? How to represent the learnt skills and how can they be re-used? EXPLORERS attacks directly those questions by proposing a series of scientific and technological advances: 1) we will formalize and implement sophisticated systems of intrinsic motivation, responsible of organized spontaneous exploration in humans, for the regulation of the growth of complexity of learning situations; 2) intrinsic motivation systems will be used to drive the learning of forward/anticipative sensorimotor models in high-dimensional multimodal spaces, as well as the building of reusable behavioural macros; 3) intrinsically motivated exploration will be coupled with social guidance from non-engineer humans; 4) an informationtheoretic framework will complement intrinsically motivated exploration to allow for the inference of body maps; 5) we will show how learnt basic sensorimotor skills can be re-used to learn the meaning of early concrete words, pushing forward human-robot mutual understanding. Furthermore, we will setup large scale experiments, in order to show how these advances can allow a high-dimensional multimodal robot to learn collections of skills continuously in a weeks-to-months time scale. This project not only addresses fundamental scientific questions, but also relates to important societal issues: personal home robots are bound to become part of everyday life in the 21st century, in particular as helpful social companions in an aging society. EXPLORERS’ objectives converge to the challenges implied by this vision: robots will have to be able to adapt and learn new skills in the unknown homes of users who are not engineers. The ERC EXPLORERS is a central scientific driver of the FLOWERS team. 8.4. International Initiatives 8.4.1. Inria International Partners • Luis Montesano, University of Zaragoza, Spain. Manuel Lopes collaborated with Luis Montesano on several topics. Recently on active learning approaches for grasping point learning [103] and clustering activities. • Francisco Melo Instituto Superior Técnico, Portugal. Manuel Lopes collaborated with Francisco Melo on the development of active learning for inverse reinforcement learning. Recent developments consider the extension to more cues available to the learner and sampling complexity on the algorithm. • José Santos-Victor, Instituto Superior Técnico, Portugal. Manuel Lopes collaborated with José Santos-Victor on the extension of affordances models to higher levels of representations, e.g. relational models. • Maya Cakmak, Andrea Thomaz, Georgia Tech, USA. Manuel Lopes collaborated with Maya Cakmak on the development of optimal teaching algorithms for sequential decision problems (modeled as markov decision processes). The algorithm provides optimal demonstrations for systems that learn using inverse reinforcement learning. The joint work considers not only the algorithmic aspects but also a comparison with human behavior and the possibility of using insights from the algorithm to elicit better teaching behavior on humans [32]. 50 Activity Report INRIA 2012 • Marc Toussaint, Tobias Lang, Free University of Berlin, Germany. Manuel Lopes and PierreYves Oudeyer are collaborating with FUB in the unification of exploration algorithms based on intrinsic motivation with methods for exploration in reinforcement learning such asRmax. We intend to develop a general framework for exploration in non-stationary domains [46]. Another project consider how to learn efficient representation for robotic hierarchical planning [44]. • Todd Hester and Peter Stone, University of Texas, USA ( 2012 ) Peter Stone is a leading expert on reinforcement learning applied to real robots ( he won the RobotCup competition several times) and to multi-agent problems. We started this collaboration by introducing a new method to automatically select the best exploration strategy to use in a particular problem [42]. Future directions of the collaboration will include ad-hoc teams, exploration in continuous space and human-guided machine learning. • Jacqueline Gottlieb and Adrien Baranes, Columbia University, New-York, US. Pierre-Yves Oudeyer and Manuel Lopes continued a collaboration with Jacqueline Gottlied, neuroscientist at Columbia University and specialist of visual attention and exploration in monkeys, and Adrien Baranes, postdoc in Gottlieb’s lab and previously working in Flowers team. An experimental setup with brain imaging and behavioural observations of monkeys, and made to evaluate new families of computational models of visual attention and exploration (some of which developped in the team around the concept of intrinsic motivation) is being elaborated. • Louis ten Bosch, Radboud University, The Netherlands. Pierre-Yves Oudeyer and David Filliat continued to work with Louis ten Bosch on the modelling of multimodal language acquisition using techniques based on Non-Negative Matrix Factorization. We showed that these techniques can allow a robot to discover audio-video invariants starting from a continuous unlabelled and unsegmented flow of low-level auditory and visual stimuli. A journal article is in preparation. • Britta Wrede, Katharina Rohlfing, Jochen Steil and Sebastian Wrede, Bielefeld University, Germany, Jun Tani KAIST, South Korea. Pierre-Yves Oudeyer collaborated with Wrede, Rohlfing, Steil, Wrede and Tani on the elaboration of a novel conceptual vision of teleoogical language and action development in robots. This led to the publication of a joint workshop article [64]. • Michael A. Arbib, University of Southern California (Los Angeles, USA). Clément Moulin-Frier is continuing his collaborative work with Michael Arbib since his 6-month visit at USC in 2009. See the section entitled “Recognizing speech in a novel accent: the Motor Theory of Speech Perception reframed” for more information. • Paul Vogt (Tillburg University, The Netherlands), Linda Smith (Indiana University, Bloomington, US), Aslo Ozyurek (Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands), Tony Belpaeme (University of Plymouth, UK). Pierre-Yves Oudeyer began collaboration with partners of the NWO SCMSC project to set up a research network on modeling of social cognition and symbolic communication. • Michael Gienger from Honda Research Institute Europe. Alexander Gepperth collaborated with Principal Scientist Dr.Michael Gienger from Honda Research Institute Europe GmbH about robotic grasping: this activity will result in a jointly supervised internship (""stage de fine d’études"") and a publication. • Ursula Korner from Honda Research Institute Europe. Alexander Gepperth collaborated with Dr. Usula Körner of Honda Research Institute Europe GmbH, Offenbach (Germany), on the topic of biologically inspired learning architectures for visual categorization of behaviorally relevant entities. This work is intended to be summitted to the International Conference on Development and Learning, as well as the journal ""Frontiers in Cognitive Systems"". • Michael Garcia Ortiz, Laboratory for Cognitive Robotics (CoR-Lab) in Bielefeld, Germany. Alexander Gepperth collaborated with Michael Garcia Ortiz, a PhD student from the Laboratory for Cognitive Robotics (CoR-Lab) in Bielefeld, Germany, on the exploitation of scene context for object detection in intelligent vehicles. This collaboration resulted in the submission of a journal publication to the journal ”Neurocomputing”. Project-Team FLOWERS 51 • Martha White and Richard Sutton from the University of Alberta, Canada. Thomas Degris collaborated with Martha White and Richard Sutton on the paper “Off-Policy Actor–Critic” [38]. • Patrick Pilarski and Richard Sutton from the University of Alberta (Canada). Thomas Degris collaborated with Patrick Pilarski on the following papers: “Model-Free Reinforcement Learning with Continuous Action in Practice” [37], “Apprentissage par Renforcement sans Modèle et avec Action Continue” [65], “Dynamic Switching and Real-time Machine Learning for Improved Human Control of Assistive Biomedical Robots” [57], “Towards Prediction-Based Prosthetic Control” [58], and “Prediction and Anticipation for Adaptive Artificial Limbs” [27]. • Joseph Modayil from the University of Alberta, Canada. Thomas Degris collaborated with Joseph Modayil on the following paper: “Scaling-up Knowledge for a Cognizant Robot” [35]. • Ashique Rupam Mahmood from the University of Alberta, Canada. Thomas Degris collaborated with Ashique Rupam Mahmood on the following paper: “Tuning-Free Step-Size Adaptation” [50]. 8.5. International Research Visitors 8.5.1. Visits of International Scientists • Andrew Barto, Reinforcement learning and intrinsic motivation, University of Massachusetts Amherst, USA (oct 2012) • Adam White, Reinforcement Learning and Art","",""
1,"E. Kitsios, M. Doumpos, C. Zopounidis","CREDIT CARD APPLICATION ASSESSMENT USING A NEURO-FUZZY CLASSIFICATION SYSTEM",2006,"","","","",45,"2022-07-13 09:23:39","","10.25102/FER.2006.01.01","","",,,,,1,0.06,0,3,16,"Credit cards constitute one of the most common forms of consumer loans. The main purpose of this paper is to apply fuzzy data analysis to the credit scoring problem. A neuro-fuzzy classification technique is compared to the logistic regression approach and novel machine learning algorithms that are currently being investigated as credit scoring methods. The 10-fold cross-validation procedure is performed to analyze the generalization properties and the robustness of the developed models. Neuro-fuzzy classification systems allow for prior knowledge to be imbedded in the analysis and utilize human expertise in the form of fuzzy if then rules to provide an insight into the reasoning mechanism behind the credit approval/rejection decision. This feature is particularly useful in financial applications such as credit granting, where credit analysts should be in a position to provide an explanation for their decisions.","",""
39,"Changyu Deng, Xunbi A. Ji, Colton Rainey, Jian-yu Zhang, Wei Lu","Integrating Machine Learning with Human Knowledge",2020,"","","","",46,"2022-07-13 09:23:39","","10.1016/j.isci.2020.101656","","",,,,,39,19.50,8,5,2,"","",""
1,"Anupam Datta, Matt Fredrikson, Klas Leino, Kaiji Lu, S. Sen, Zifan Wang","Machine Learning Explainability and Robustness: Connected at the Hip",2021,"","","","",47,"2022-07-13 09:23:39","","10.1145/3447548.3470806","","",,,,,1,1.00,0,6,1,"This tutorial examines the synergistic relationship between explainability methods for machine learning and a significant problem related to model quality: robustness against adversarial perturbations. We begin with a broad overview of approaches to explainable AI, before narrowing our focus to post-hoc explanation methods for predictive models. We discuss perspectives on what constitutes a ""good'' explanation in various settings, with an emphasis on axiomatic justifications for various explanation methods. In doing so, we will highlight the importance of an explanation method's faithfulness to the target model, as this property allows one to distinguish between explanations that are unintelligible because of the method used to produce them, and cases where a seemingly poor explanation points to model quality issues. Next, we introduce concepts surrounding adversarial robustness, including adversarial attacks as well as a range of corresponding state-of-the-art defenses. Finally, building on the knowledge presented thus far, we present key insights from the recent literature on the connections between explainability and robustness, showing that many commonly-perceived explainability issues may be caused by non-robust model behavior. Accordingly, a careful study of adversarial examples and robustness can lead to models whose explanations better appeal to human intuition and domain knowledge.","",""
27,"Masahiro Mitsuhara, Hiroshi Fukui, Yusuke Sakashita, Takanori Ogata, Tsubasa Hirakawa, Takayoshi Yamashita, H. Fujiyoshi","Embedding Human Knowledge in Deep Neural Network via Attention Map",2019,"","","","",48,"2022-07-13 09:23:39","","10.5220/0010335806260636","","",,,,,27,9.00,4,7,3,"In this work, we aim to realize a method for embedding human knowledge into deep neural networks. While the conventional method to embed human knowledge has been applied for non-deep machine learning, it is challenging to apply it for deep learning models due to the enormous number of model parameters. To tackle this problem, we focus on the attention mechanism of an attention branch network (ABN). In this paper, we propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert. Our fine-tuning method can train a network so that the output attention map corresponds to the edited ones. As a result, the fine-tuned network can output an attention map that takes into account human knowledge. Experimental results with ImageNet, CUB-200-2010, and IDRiD demonstrate that it is possible to obtain a clear attention map for a visual explanation and improve the classification performance. Our findings can be a novel framework for optimizing networks through human intuitive editing via a visual interface and suggest new possibilities for human-machine cooperation in addition to the improvement of visual explanations.","",""
2,"Xiawu Zheng, Yang Zhang, Sirui Hong, Huixia Li, Lang Tang, Youcheng Xiong, Jin Zhou, Yan Wang, Xiaoshuai Sun, P. Zhu, Chenglin Wu, Rongrong Ji","Evolving Fully Automated Machine Learning via Life-Long Knowledge Anchors",2021,"","","","",49,"2022-07-13 09:23:39","","10.1109/TPAMI.2021.3069250","","",,,,,2,2.00,0,12,1,"Automated machine learning (AutoML) has achieved remarkable progress on various tasks, which is attributed to its minimal involvement of manual feature and model designs. However, most of existing AutoML pipelines only touch parts of the full machine learning pipeline, e.g., neural architecture search or optimizer selection. This leaves potentially important components such as data cleaning and model ensemble out of the optimization, and still results in considerable human involvement and suboptimal performance. The main challenges lie in the huge search space assembling all possibilities over all components, as well as the generalization ability over different tasks like image, text, and tabular etc. In this paper, we present a first-of-its-kind fully AutoML pipeline, to comprehensively automate data preprocessing, feature engineering, model generation/selection/training and ensemble for an arbitrary dataset and evaluation metric. Our innovation lies in the comprehensive scope of a learning pipeline, with a novel “life-long” knowledge anchor design to fundamentally accelerate the search over the full search space. Such knowledge anchors record detailed information of pipelines and integrates them with an evolutionary algorithm for joint optimization across components. Experiments demonstrate that the result pipeline achieves state-of-the-art performance on multiple datasets and modalities. Specifically, the proposed framework was extensively evaluated in the NeurIPS 2019 AutoDL challenge, and won the only champion with a significant gap against other approaches, on all the image, video, speech, text and tabular tracks.","",""
0,"Ahmed Reda Ali, M. Jaya, E. A. Jones","Machine Learning Strategies for Accurate Log Prediction in Reservoir Characterization: Self-Calibrating Versus Domain-Knowledge",2021,"","","","",50,"2022-07-13 09:23:39","","10.2118/205602-ms","","",,,,,0,0.00,0,3,1,"  Petrophysical evaluation is a crucial task for reservoir characterization but it is often complicated, time-consuming and associated with uncertainties. Moreover, this job is subjective and ambiguous depending on the petrophysicist's experience. Utilizing the flourishing Artificial Intelligence (AI)/Machine Learning (ML) is a way to build an automating process with minimal human intervention, improving consistency and efficiency of well log prediction and interpretation. Nowadays, the argument is whether AI-ML should base on a statistically self-calibrating or knowledge-based prediction framework! In this study, we develop a petrophysically knowledge-based AI-ML workflow that upscale sparsely-sampled core porosity and permeability into continuous curves along the entire well interval.  AI-ML focuses on making predictions from analyzing data by learning and identifying patterns. The accuracy of the self-calibrating statistical models is heavily dependent on the volume of training data. The proposed AI-ML workflow uses raw well logs (gamma-ray, neutron and density) to predict porosity and permeability over the well interval using sparsely core data. The challenge in building the AI-ML model is the number of data points used for training showed an imbalance in the relative sampling of plugs, i.e. the number of core data (used as target variable) is less than 10%. Ensemble learning and stacking ML approaches are used to obtain maximum predictive performance of self-calibrating learning strategy.  Alternatively, a new petrophysical workflow is established to debrief the domain experience in the feature selection that is used as an important weight in the regression problem. This helps ML model to learn more accurately by discovering hidden relationships between independent and target variables. This workflow is the inference engine of the AI-ML model to extract relevant domain-knowledge within the system that leads to more accurate predictions.  The proposed knowledge-driven ML strategy achieved a prediction accuracy of R2 score = 87% (Correlation Coefficient (CC) of 96%). This is a significant improvement by R2 = 57% (CC = 62%) compared to the best performing self-calibrating ML models. The predicted properties are upscaled automatically to predict uncored intervals, improving data coverage and property population in reservoir models leading to the improvement of the model robustness. The high prediction accuracy demonstrates the potential of knowledge-driven AI-ML strategy in predicting rock properties under data sparsity and limitations and saving significant cost and time.  This paper describes an AI-ML workflow that predicts high-resolution continuous porosity and permeability logs from imbalanced and sparse core plug data. The method successfully incorporates new type petrophysical facies weight as a feature augmentation engine for ML domain-knowledge framework. The workflow consisted of petrophysical treatment of raw data includes log quality control, preconditioning, processing, features augmentation and labelling, followed by feature selection to impersonate domain experience.","",""
0,"S. Chujfi, C. Meinel","Machine Learning and Human Cognition Combined to Enhance Knowledge Discovery Fidelity",2019,"","","","",51,"2022-07-13 09:23:39","","10.1109/CogMI48466.2019.00010","","",,,,,0,0.00,0,2,3,"The objective of this work is knowledge discovery in large-scale audio files by performing a Cognitive Analysis – CA –, where the knowledge is extracted from transcribed customer service conversations taking into consideration individual cognitive styles to mimic the human cognitive process and maximize the correct meaning interpretation information in a given context. We make the following three contributions: (i) integrate a Cyber Cognitive Identity model – CCI – that states the cognitive profile an individual has for interacting in cyberspace, which yields superior fidelity to identify the meaning of spoken sentences following Sternberg's Thinking Style Inventory (TSI). In particular it guides an analysis grounded in peers' cognitive styles to index words by dimension; (ii) a novel method that extends the Latent Dirichlet Allocation (LDA) approach to a multidimensional partially supervised machine learning model with the help of the psychological activation theory Adaptive Control of Thought – ACT; (iii) an improvement of the Exploratory Data Analysis – EDA–suggested by De Mast and Trip, envisioned as an extended approach to obtain high-fidelity data where topics of a three-dimensional corpus are clustered according to cognitive categorizations. Using speech-to-text software, we transcribed and evaluated 27 500 calls from 206 German-speaking teleworkers combining these three complementary methods and achieved significant fidelity to generate a hypothesis based on individuals' cognitive affinities.","",""
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",52,"2022-07-13 09:23:39","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
2,"T. Schmid","Using Learning Algorithms to Create, Exploit and Maintain Knowledge Bases: Principles of Constructivist Machine Learning",2020,"","","","",53,"2022-07-13 09:23:39","","","","",,,,,2,1.00,2,1,2,"Recently, interest has grown in connecting modern machine learning approaches with traditional expert systems. This can mean, e.g, to identify patterns with neural networks and integrate them with knowledge graphs. While such combined systems offer a variety of advantages, few domainindependent approaches are known to make a hybrid artificial intelligence applicable without human interaction. To this end, we present the implementation of a constructivist machine learning framework (conML). This novel paradigm uses machine learning to manage a knowledge base and thereby allows for both raw data-based and symbolic information processing on the same internal knowledge representation. Based on axioms for a constructivist machine learning, we describe which operations are required to create, exploit and maintain a knowledge base and how these operations may be implemented with machine learning techniques. The major practical obstacle in this approach is to implement an automated deconstruction process that avoids ambiguity, handles continuous learning and allows knowledge abstraction. As we demonstrate, however, these obstacles can be overcome and constructivist machine learning can be put into practice. Combining machine learning and knowledge engineering is currently considered a potential game changing advancement in artificial intelligence. Neural networks and other machine learning techniques have proven strength in adapting to highly complex patterns and relationships, but are unable to represent existing knowledge explicitly and in an abstract fashion as expert systems can. Expert systems, on the other hand, operate on human-understandable knowledge representations but are highly domain-specific and, moreover, unable to process real-world data directly as machine learning can. Therefore, it is expected that joining both fields will produce a hybrid artificial intelligence that is “explainable, compliant and grounded in domain knowledge” (Martin et al. 2019). Such systems may, e.g., be able to identify patterns with neural networks and integrate them with knowledge graphs (Subasic, Yin, and Lin 2019). Copyright 2020 held by the author(s). In A. Martin, K. Hinkelmann, H.-G. Fill, A. Gerber, D. Lenat, R. Stolle, F. van Harmelen (Eds.), Proceedings of the AAAI 2020 Spring Symposium on Combining Machine Learning and Knowledge Engineering in Practice (AAAI-MAKE 2020). Stanford University, Palo Alto, California, USA, March 23-25, 2020. In fact, the idea of a hybrid artificial intelligence has been discussed for more than 30 years (Gallant 1988; Hendler 1989; Skeirik 1990; Levey 1991; Morik et al. 1993). So far, however, most research in this field focuses on specific knowledge or application domains like medical diagnosis (Hudson, Cohen, and Anderson 1991; Karabatak and Ince 2009; Herrmann 1995). This is to a large extent due to the fact that knowledge bases are typically created manually, which is a highly time-consuming task that requires detailled knowledge of the domain (Kidd 2012). No less timeconsuming are exploitation and maintenance of knowledge bases, which are typical follow-up phases within the life cycle of a knowledge base. While some progress has been made in employing algorithms for these tasks, several major challenges for an automated management of knowledge bases are still considered unresolved (Martinez-Gil 2015). Considering recent performance advancements in machine learning, manually managed knowledge bases obviously constitute a serious bottleneck in creating efficient hybrid systems. For truely automated systems, however, an implementable semantic interface between inductive machine learning and deductive expert systems is required. To this end, we have introduced a constructivist machine learning paradigm (Schmid 2019) based on the concept of learnable models and their storage in a knowledge base. While machine learning is currently dominated by neuro-inspired approaches, constructivist theories root in educational research (Fox 2001) and, so far, few actual implementations have been proposed for a constructivist machine learning (Drescher 1989; Quartz 1993). Central challenge for putting this into practice is the implementation of an automated deconstruction process, which to the best of our knowledge has only once been addressed successfully (Schmid 2018). Based on this paradigm, we designed a prototype for a constructivist machine learning that employs a meta databased knowledge base. Here, we present the underlying operationalizations and concepts required to put constructivist machine learning into practice. The rest of the paper is organized as follows: In section I, we lay out guidelines for automated knowledge base management. In section II, we define Stachowiak-like models as building blocks for knowledge representations. In section III, we introduce principles for constructivist machine learning processes. In section IV, we summarize our approach and point out future goals. Data Set or Stream Representation Knowledge Base select learn integrate","",""
3,"M. Halgamuge","Supervised Machine Learning Algorithms for Bioelectromagnetics: Prediction Models and Feature Selection Techniques Using Data from Weak Radiofrequency Radiation Effect on Human and Animals Cells",2020,"","","","",54,"2022-07-13 09:23:39","","10.3390/ijerph17124595","","",,,,,3,1.50,3,1,2,"The emergence of new technologies to incorporate and analyze data with high-performance computing has expanded our capability to accurately predict any incident. Supervised Machine learning (ML) can be utilized for a fast and consistent prediction, and to obtain the underlying pattern of the data better. We develop a prediction strategy, for the first time, using supervised ML to observe the possible impact of weak radiofrequency electromagnetic field (RF-EMF) on human and animal cells without performing in-vitro laboratory experiments. We extracted laboratory experimental data from 300 peer-reviewed scientific publications (1990–2015) describing 1127 experimental case studies of human and animal cells response to RF-EMF. We used domain knowledge, Principal Component Analysis (PCA), and the Chi-squared feature selection techniques to select six optimal features for computation and cost-efficiency. We then develop grouping or clustering strategies to allocate these selected features into five different laboratory experiment scenarios. The dataset has been tested with ten different classifiers, and the outputs are estimated using the k-fold cross-validation method. The assessment of a classifier’s prediction performance is critical for assessing its suitability. Hence, a detailed comparison of the percentage of the model accuracy (PCC), Root Mean Squared Error (RMSE), precision, sensitivity (recall), 1 − specificity, Area under the ROC Curve (AUC), and precision-recall (PRC Area) for each classification method were observed. Our findings suggest that the Random Forest algorithm exceeds in all groups in terms of all performance measures and shows AUC = 0.903 where k-fold = 60. A robust correlation was observed in the specific absorption rate (SAR) with frequency and cumulative effect or exposure time with SAR×time (impact of accumulated SAR within the exposure time) of RF-EMF. In contrast, the relationship between frequency and exposure time was not significant. In future, with more experimental data, the sample size can be increased, leading to more accurate work.","",""
5,"Haohan Wang, Zeyi Huang, Hanlin Zhang, Eric P. Xing","Toward Learning Human-aligned Cross-domain Robust Models by Countering Misaligned Features",2021,"","","","",55,"2022-07-13 09:23:39","","","","",,,,,5,5.00,1,4,1,"Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective as-suming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available here.","",""
0,"Ying Zhao, Lauren Jones","Integrating Human Reasoning and Machine Learning to Classify Cyber Attacks",2020,"","","","",56,"2022-07-13 09:23:39","","10.1007/978-3-030-55692-1_8","","",,,,,0,0.00,0,2,2,"","",""
1,"Yuntian Chen, Dongxiao Zhang","Integration of knowledge and data in machine learning",2022,"","","","",57,"2022-07-13 09:23:39","","","","",,,,,1,1.00,1,2,1,"Scientiﬁc research’s mandate is to comprehend and explore the world, as well as to improve it based on experience and knowledge. Knowledge embedding and knowledge discovery are two signif-icant methods of integrating knowledge and data. Through knowledge embedding, the barriers between knowledge and data can be eliminated, and machine learning models with physical common sense can be established. Meanwhile, humans’ understanding of the world is always limited, and knowledge discovery takes advantage of machine learning to extract new knowledge from observations. Knowledge discovery can not only assist researchers to better grasp the nature of physics, but it can also support them in conducting knowledge embedding research. A closed loop of knowledge generation and usage are formed by combining knowledge embedding with knowledge discovery, which can improve the robustness and accuracy of models and uncover previously unknown scientiﬁc principles. This study summarizes and ana-lyzes extant literature, as well as identiﬁes research gaps and future opportunities.","",""
3,"F. Lécué, B. Abeloos, Jonathan Anctil, Manuel Bergeron, Damien Dalla-Rosa, Simon Corbeil-Letourneau, Florian Martet, Tanguy Pommellet, L. Salvan, Simon Veilleux, M. Ziaeefard","Thales XAI Platform: Adaptable Explanation of Machine Learning Systems - A Knowledge Graphs Perspective",2019,"","","","",58,"2022-07-13 09:23:39","","","","",,,,,3,1.00,0,11,3,"Explanation in Machine Learning systems has been identified to be the main asset to have for large scale deployment of Artificial Intelligence (AI) in critical systems. Explanations could be example-, features-, semantics-based or even counterfactual to potentially action on an AI system; they could be represented in many different ways e.g., textual, graphical, or visual. All representations serve different means, purpose and operators. We built the first-of-its-kind XAI (eXplainable AI) platform for critical systems i.e., Thales XAI Platform which aims at serving explanations through various forms. This paper emphasizes on the semantics-based explanations for Machine Learning systems. 1 Explainable AI in Critical Systems Motivation: The current hype of Artificial Intelligence (AI) mostly refers to the success of Machine Learning (ML) and its sub-domain of deep learning. However industries operating with critical systems are either highly regulated, or require high level of certification and robustness. Therefore, such industry constraints do limit the adoption of non deterministic and ML systems. Answers to the question of explainability will be intrinsically connected to the adoption of AI in industry at scale. Indeed explanation, which could be used for debugging intelligent systems or deciding to follow a recommendation in real-time, will increase acceptance and (business) user trust. Explainable AI (XAI) is now referring to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. Focus: Thales XAI Platform is designed to provide explanation for a ML task (classification, regression, object detection, segmentation). Although Thales XAI Platform does provide different levels of explanation e.g., example-based, featuresbased, counterfactual using textual and visual representations, we emphasis only on the semantics-based explanation through knowledge graphs. ? Copyright c © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Critical Applications: From adapting a plane trajectory, stopping a train, refitting a boat to reconfiguring a satellite, all are examples of critical situations where explanation is a must-to-have to follow an AI system decision. 2 Why Knowledge Graphs for Explainable AI? State-of-the-Art Limitations: Most approaches limits explanation of ML systems to features involved in the data and model, or at best to examples, prototypes or counterfactuals. Explanation should go beyond correlation (features importance) and numerical similarity (local explanation). Opportunity: By expanding and linking initial (training, validation and test) data with entities in knowledge graphs, (i) context is encoded, (ii) connections and relations are exposed, and (iii) inference and causation are natively supported. Knowledge graphs are used for encoding better representation of data, structuring a ML model in a more interpretable way, and adopt a semantic similarity for local (instance-based) and global (model-based) explanation. 3 Thales XAI Platform: A Knowledge Graph Perspective (Semantic) Perspective: The platform is combining ML and reasoning functionalities to expose a human-like rational as explanation when (i) recognizing an object (in a raw image) of any class in a knowledge graph, (ii) predicting a link in a knowledge graph. Thales XAI Platform is using state-of-the-art Semantic Web tools for enriching input, output (class) data with DBpedia (4, 233, 000 resources) and domain-specific knowledge graphs, usually enterprise knowledge graphs. This is a crucial step for contextualizing training, validation, test data. Explainable ML Classifications: Starting from raw images, as unstructured data, but with class labels augmented with a domain knowledge graph, Thales XAI Platform relies on existing neural network architectures to build the most appropriate models. All confidence scores of output classes on any input image are updated based on the semantic description of the output classes. For instance, an input classified as a car will have a higher overall confidence score in case some properties of car in the knowledge graph are retrieved e.g., having wheels, being on a road. In addition the platform is embedding naturally explanation i.e., properties of the objects retrieved in both the raw data and knowledge graph. Explainable Relational Learning: Starting from relational data, structured as graph, and augmented with a domain knowledge graph, Thales XAI Platform relies on existing knowledge graph embeddings frameworks to build the most appropriate models. Explanation of any link prediction is retrieved by identifying representative hotspots in the knowledge graph i.e., connected parts of the graphs that negatively impact prediction accuracy when removed.","",""
3,"H. Vardhan, P. Völgyesi, J. Sztipanovits","Machine learning assisted propeller design",2021,"","","","",59,"2022-07-13 09:23:39","","10.1145/3450267.3452001","","",,,,,3,3.00,1,3,1,"Propellers are one of the most widely used propulsive devices for generating thrust from rotational engine motion both in marine vehicles and subsonic air-crafts. Due to their simplicity, robustness and high efficiency, propellers remained the mainstream design choice over the last hundred years. On the other hand, finding the optimal application-specific geometry is still challenging. This work in progress report describes application of modern and rapidly developing Machine Learning (ML) techniques to gain novel designs. We rely on a rich set of preexisting parametric design patterns and accumulated engineering knowledge supplemented by high-fidelity simulation models to formulate the design process as a supervised learning problem. The aim of our work is to develop and evaluate machine learning models for the parametric design of propellers based on application-specific constraints. While the application of ML techniques in optimal propeller design is at a very nascent level, we believe that our early results are promising with a potentially significant impact on the overall design process. The ML-assisted design flow allows for a more automated design space exploration process with less dependency on human intuition and engineering guidance.","",""
0,"Julius Polz, Lennart Schmidt, Luca Glawion, Maximilian Graf, Christian Werner, C. Chwala, H. Mollenhauer, C. Rebmann, H. Kunstmann, J. Bumberger","Supervised and unsupervised machine-learning for automated quality control of environmental sensor data",2021,"","","","",60,"2022-07-13 09:23:39","","10.5194/EGUSPHERE-EGU21-14485","","",,,,,0,0.00,0,10,1,"<p>We can observe a global decrease of well maintained weather stations by meteorological services and governmental institutes. At the same time, environmental sensor data is increasing through the use of opportunistic or remote sensing approaches. Overall, the trend for environmental sensor networks is strongly going towards automated routines, especially for quality-control (QC) to provide usable data in near real-time. A common QC scenario is that data is being flagged manually using expert knowledge and visual inspection by humans. To reduce this tedious process and to enable near-real time data provision, machine-learning (ML) algorithms exhibit a high potential as they can be designed to imitate the experts actions.&#160;</p><p>Here we address these three common challenges when applying ML for QC: 1) Robustness to missing values in the input data. 2) Availability of training data, i.e. manual quality flags that mark erroneous data points. And 3) Generalization of the model regarding non-stationary behavior of one&#160; experimental system or changes in the experimental setup when applied to a different study area. We approach the QC problem and the related issues both as a supervised and an unsupervised learning problem using deep neural networks on the one hand and dimensionality reduction combined with clustering algorithms on the other.</p><p>We compare the different ML algorithms on two time-series datasets to test their applicability across scales and domains. One dataset consists of signal levels of 4000 commercial microwave links distributed all over Germany that can be used to monitor precipitation. The second dataset contains time-series of soil moisture and temperature from 120 sensors deployed at a small-scale measurement plot at the TERENO site &#8220;Hohes Holz&#8221;.</p><p>First results show that supervised ML provides an optimized performance for QC for an experimental system not subject to change and at the cost of a laborious preparation of the training data. The unsupervised approach is also able to separate valid from erroneous data at reasonable accuracy. However, it provides the additional benefit that it does not require manual flags and can thus be retrained more easily in case the system is subject to significant changes.&#160;</p><p>In this presentation, we discuss the performance, advantages and drawbacks of the proposed ML routines to tackle the aforementioned challenges. Thus, we aim to provide a starting point for researchers in the promising field of ML application for automated QC of environmental sensor data.</p>","",""
0,"Eike Petersen, Yannik Potdevin, Esfandiar Mohammadi, S. Zidowitz, Sabrina Breyer, Dirk Nowotka, Sandra Henn, Ludwig Pechmann, M. Leucker, P. Rostalski, C. Herzog","Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Technical Challenges and Solutions",2021,"","","","",61,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,11,1,"Machine learning is expected to fuel significant improvements in medical care. To ensure that fundamental principles such as beneficence, respect for human autonomy, prevention of harm, justice, privacy, and transparency are respected, medical machine learning applications must be developed responsibly. A large number of high-level declarations of ethical principles have been put forth for this purpose, but there is a severe lack of technical guidelines explicating the practical consequences for medical machine learning. Similarly, there is currently considerable uncertainty regarding the exact regulatory requirements placed upon medical machine learning systems. In this paper, we survey the technical challenges involved in creating medical machine learning systems responsibly and in conformity with existing regulations, as well as possible solutions to address these challenges. We begin by providing a brief overview of existing regulations affecting medical machine learning, showing that properties such as safety, robustness, reliability, privacy, security, transparency, explainability, and nondiscrimination are all demanded already by existing law and regulations — albeit, in many cases, to an uncertain degree. Next, we discuss the key technical obstacles to achieving these desirable properties, and important techniques to overcome those barriers in the medical context. Since most of the technical challenges are very young and new problems frequently emerge, the scientific discourse is rapidly evolving and has not yet converged on clear best-practice solutions. Nevertheless, we aim to illuminate the underlying technical challenges, possible ways for addressing them, and their respective merits and drawbacks. In particular, we notice that distribution shift, spurious correlations, model underspecification, and data scarcity represent severe challenges in the medical context (and others) that are very difficult to solve with classical black-box deep neural networks. Important measures that may help to address these challenges include the use of large and representative datasets and federated learning as a means to that end, the careful exploitation of domain knowledge wherever feasible, the use of inherently transparent models, comprehensive model testing and verification, as well as stakeholder inclusion. ar X iv :2 10 7. 09 54 6v 1 [ cs .L G ] 2 0 Ju l 2 02 1","",""
0,"A. Martin, K. Hinkelmann","AAAI-MAKE 2021: Combining Machine Learning and Knowledge Engineering",2021,"","","","",62,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,1,"The AAAI 2021 Spring Symposium on Combining Machine Learning and Knowledge Engineering (AAAI-MAKE 2021) brought together researchers and practitioners from the machine learning and knowledge engineering fields to reflect two years later the progress on the combination of machine learning and knowledge engineering after it has been raised in the 2019 AAAI spring symposium series for the first time. With great success, many current AI solutions rely on machine/deep learning approaches, which help to solve complex tasks based on real-world data. It is most suitable for building AI systems when knowledge is not known or is tacit. While machine learning is now able to master data-intensive learning tasks, there are still some challenges. Many tasks require large amounts of training data, especially tasks where events to be predicted are rare. Often, machine output serves merely as a basis for decisions, which humans finally make. Knowledge engineering and knowledge-based systems, which make expert knowledge explicit and accessible, are often based on logic and explain their conclusions. These systems typically require a higher initial effort during development than systems that use machine learning approaches. However, symbolic machine learning and ontology learning approaches are promising for reducing the effort of knowledge engineering. Because of machine learning and knowledge engineering’s complementary strengths and weaknesses, there is a demand in business to integrate and combine both AI methods for complex business scenarios. Focusing on only one aspect will not exploit the full potential of AI. Two years after the first AAAI-MAKE symposium held in 2019 at Stanford University, the 2021 edition was held as a virtual event. The remarkable number of submissions showed a tremendous demand for combined/hybrid AI approaches. These proceedings are a collection of presented papers contributing to the symposium’s aim of combining machine learning and knowledge engineering as well as other hybrid AI and neuro-symbolic approaches/methods.","",""
0,"S. Pande, Bineet Kumar Jha","Character Recognition System for Devanagari Script Using Machine Learning Approach",2021,"","","","",63,"2022-07-13 09:23:39","","10.1109/ICCMC51019.2021.9418028","","",,,,,0,0.00,0,2,1,"It is a very difficult task to manually process the handwritten documents due to varieties of handwritten scripts and lack of associated language dictionary to interpret documents. Most of the large companies as well as small-scale industries want to automate the process of script recognition. The big challenge is to make machines recognize the hand-printed scripts. Humans can recognize handwritten or hand-printed words after gaining knowledge of a specific language. In the same way, machines should be trained to recognize the handwritten scripts. This process of transferring human knowledge to computers should be automated. The proposed research work attempts to automate the character recognition system for Devanagari script using various machine learning classifiers like Decision Tree classifier, Nearest Centroid classifier, K Nearest Neighbors classifier, Extra Trees classifiers and Random Forest classifier. The performance of all the classifiers is evaluated using accuracy parameter as success criteria. The Extra Trees classifiers and Random Forest classifier is proved to better than other classifiers with 78% and 77% of accuracy respectively. The robustness to picture quality, writing style, font size is the novelty of the OCR system which makes it ideal to use.","",""
1,"Michael Walch","Knowledge Engineering and Machine Learning for Design and Use in Cyber-Physical Environments",2019,"","","","",64,"2022-07-13 09:23:39","","","","",,,,,1,0.33,1,1,3,"A required task for developing cyber-physical systems (CPS) with people and business aspects in the loop is to capture human knowledge & design in an explicit manner. Knowledge engineering can be applied to tackle this task. Thereby, the idea is to utilize human knowledge & design in an automated manner throughout the life-cycle of CPS. In particular, one challenge is to connect conceptual models and operation environments. The former focuses on capturing and decomposing human knowledge & design about people, businesses, and CPS using semi-formal concepts that can be executed through procedures for sequential semantics, while the latter focuses on continuous-time models and CPS that operate in the physical world at run-time. By connecting conceptual models and operation environments in an intelligent manner, the s*IoT conceptual modeling approach is able to align two levels of iterpretability: one for people concerned with feasible, desirable, and viable designs and one for efficient, automated, and reliable use of CPSs. Therby, s*IoT supersedes the approach of developing application-specific interfaces between conceptual models and operation environments. Rather, s*IoT employs the semantic web stack to reduce the human effort for developing application-specific interfaces. While this is a promising approach, the question is if the integration of machine-learning approaches offers additional benefits for s*IoT, as machine-learning approaches can presumably further eliminate human effort associated with technologies from the semantic web stack. This paper presents an arguable opinion about the issue.","",""
4,"Alexandra Renouard, A. Maggi, M. Grunberg, C. Doubre, C. Hibert","Toward False Event Detection and Quarry Blast versus Earthquake Discrimination in an Operational Setting Using Semiautomated Machine Learning",2021,"","","","",65,"2022-07-13 09:23:39","","10.1785/0220200305","","",,,,,4,4.00,1,5,1,"  Small-magnitude earthquakes shed light on the spatial and magnitude distribution of natural seismicity, as well as its rate and occurrence, especially in stable continental regions where natural seismicity remains difficult to explain under slow strain-rate conditions. However, capturing them in catalogs is strongly hindered by signal-to-noise ratio issues, resulting in high rates of false and man-made events also being detected. Accurate and robust discrimination of these events is critical for optimally detecting small earthquakes. This requires uncovering recurrent salient features that can rapidly distinguish first false events from real events, then earthquakes from man-made events (mainly quarry blasts), despite high signal variability and noise content. In this study, we combined the complementary strengths of human and interpretable rule-based machine-learning algorithms for solving this classification problem. We used human expert knowledge to co-create two reliable machine-learning classifiers through human-assisted selection of classification features and review of events with uncertain classifier predictions. The two classifiers are integrated into the SeisComP3 operational monitoring system. The first one discards false events from the set of events obtained with a low short-term average/long-term average threshold; the second one labels the remaining events as either earthquakes or quarry blasts. When run in an operational setting, the first classifier correctly detected more than 99% of false events and just over 93% of earthquakes; the second classifier correctly labeled 95% of quarry blasts and 96% of earthquakes. After a manual review of the second classifier low-confidence outputs, the final catalog contained fewer than 2% of misclassified events. These results confirm that machine learning strengthens the quality of earthquake catalogs and that the performance of machine-learning classifiers can be improved through human expertise. Our study promotes a broader implication of hybrid intelligence monitoring within seismological observatories.","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",66,"2022-07-13 09:23:39","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",67,"2022-07-13 09:23:39","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
1,"J. Ani, Mirajul Islam, Nushrat Jahan Ria, Sharmin Akter, Abu Kaisar Mohammad Masum","Estimating Gender Based On Bengali Conventional Full Name With Various Machine Learning Techniques",2021,"","","","",68,"2022-07-13 09:23:39","","10.1109/ICCCNT51525.2021.9579927","","",,,,,1,1.00,0,5,1,"For finding patterns in data, machine learning models are being trained. Gender relations psychology looks for social norms like inter dimensionality, beliefs, social experience and self-perception, and self-respect. Training on gender based text NLP models unknowingly become acquainted with unusual patterns. In this paper, we represent gender recognition by using Bengali conventional full names. We present a review and interpretation of gender classification based on individual names in this correspondence. These days, NLP has demonstrated excellent execution in identifying human gender. In the field of knowledge, gender classification is a demonstrative binary classification phenomenon. We've used a total of seven algorithms in this research. We were added to the dataset with details regarding which features are currently used for prediction along with that it determines how these features are affected by data preprocessing model initialization and architecture selection. Our research compares those classifiers, examines the impact of pretraining moreover, assesses the robustness of the alignment preprocessing through the confusion matrix.. The proposed Neural Network outperforms most approaches and is much more reliable than other models. This model has the best weighted precision of all the models, with such a 73.04 % accuracy score.","",""
1,"Samuel Manoharan J","Flawless Detection of Herbal Plant Leaf by Machine Learning Classifier Through Two Stage Authentication Procedure",2021,"","","","",69,"2022-07-13 09:23:39","","10.36548/jaicn.2021.2.005","","",,,,,1,1.00,1,1,1,"Herbal plants are crucial to human existence for medical reasons, and they can also provide free oxygen to the environment. Many herbal plants are rich in therapeutic goods and also it includes the active elements that will benefit future generations. Many valuable plant species are being extinguished and destroyed as a result of factors such as global warming, population growth, occupational secrecy, a lack of government support for research, and a lack of knowledge about therapeutic plants. Due to the lag of dimensional factors such as length and width, many existing algorithms fail to recognize herbal leaf in all seasons with the maximum accuracy. Henceforth, the proposed algorithm focuses on the incomplete problems in the datasets in order to improve the detection rate for herbal leaf identification. The inclusions of dimension factors in the datasets are performing good results in the image segmentation process. The obtained result has been validated with a machine learning classifier when combined with ex-or gate operation is called deep knowledge-based identification. This two-stage authentication (TSA) procedure is improving the recognition rate required for the detection of herbal leaf. This fusion of image segmentation with machine learning is providing good robustness for the proposed architecture. Besides, intelligent selection of image segmentation techniques to segment the leaf from the image is improving the detection accuracy. This procedure is addressing and answering the drawbacks associated with the detection of the herbal leaf by using many Machine Learning (ML) approaches. Also, it improves the rate of detection and minimizes the classification error. From the results, it is evident that the proposed method has obtained better accuracy and other performance measures.","",""
1,"Yew Kee Wong","Machine Learning and Deep Learning Technologies",2021,"","","","",70,"2022-07-13 09:23:39","","10.5121/csit.2021.111214","","",,,,,1,1.00,1,1,1,"In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studied and provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using machine learning, which is the application of advanced deep learning techniques on big data. This paper aims to analyse some of the different machine learning and deep learning algorithms and methods, aswell as the opportunities provided by the AI applications in various decision making domains.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",71,"2022-07-13 09:23:39","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
3,"J. Nuamah, Younho Seong","A Machine Learning Approach to Predict Human Judgments in Compensatory and Noncompensatory Judgment Tasks",2019,"","","","",72,"2022-07-13 09:23:39","","10.1109/THMS.2019.2892436","","",,,,,3,1.00,2,2,3,"Traditionally, in judgment analysis, multiple linear regression based lens model, which assumes decision makers assess every cue, weigh, and combine them to make overall judgments, has been used to model and analyze human judgments. However, linear regression assumptions are limited in situations where logical rules for making decisions are not consistent with a weighting and summing formula. In this study, we sought to extend the body of knowledge in the judgment analysis research by adopting the rule-based lens model and using machine learning models to predict human judgments in compensatory and noncompensatory judgment tasks. Overall, the selected machine learning models outperformed the linear logistic regression (LgR) model in both compensatory and noncompensatory tasks. Our own results suggest that, at least for the present application, machine learning models may be better at predicting human judgments in compensatory and noncompensatory judgment tasks than linear multiple LgR models. We conclude that machine learning algorithms can yield useful models for training and decision support applications.","",""
0,"J. Manoharan","Flawless Detection of Herbal Plant Leaf by Machine Learning Classifier Through Two Stage Authentication Procedure",2021,"","","","",73,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,1,"Herbal plants are crucial to human existence for medical reasons, and they can also provide free oxygen to the environment. Many herbal plants are rich in therapeutic goods and also it includes the active elements that will benefit future generations. Many valuable plant species are being extinguished and destroyed as a result of factors such as global warming, population growth, occupational secrecy, a lack of government support for research, and a lack of knowledge about therapeutic plants. Due to the lag of dimensional factors such as length and width, many existing algorithms fail to recognize herbal leaf in all seasons with the maximum accuracy. Henceforth, the proposed algorithm focuses on the incomplete problems in the datasets in order to improve the detection rate for herbal leaf identification. The inclusions of dimension factors in the datasets are performing good results in the image segmentation process. The obtained result has been validated with a machine learning classifier when combined with ex-or gate operation is called deep knowledge-based identification. This two-stage authentication (TSA) procedure is improving the recognition rate required for the detection of herbal leaf. This fusion of image segmentation with machine learning is providing good robustness for the proposed architecture. Besides, intelligent selection of image segmentation techniques to segment the leaf from the image is improving the detection accuracy. This procedure is addressing and answering the drawbacks associated with the detection of the herbal leaf by using many Machine Learning (ML) approaches. Also, it improves the rate of detection and minimizes Journal of Artificial Intelligence and Capsule Networks (2021) Vol.03/ No.02 Pages: 125-139 http://irojournals.com/aicn/ DOI: https://doi.org/10.36548/jaicn.2021.2.005 126 ISSN: 2582-2012 (online) Submitted: 11.05.2021 Revised: 30.05.2021 Accepted: 16.06.2021 Published: 22.06.2021 the classification error. From the results, it is evident that the proposed method has obtained better accuracy and other performance measures.","",""
0,"Yew Kee Wong","The Difference of Machine Learning and Deep Learning Algorithms",2021,"","","","",74,"2022-07-13 09:23:39","","10.5121/csit.2021.111519","","",,,,,0,0.00,0,1,1,"In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studiedand provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using big data analytics, which is the application of advanced analytics techniques on big data. This paper aims to analyse some of the different machine learning algorithms and methods which can be applied to big data analysis, as well as the opportunities provided by the application of big data analytics in various decision making domains.","",""
1,"Parthasarathi Pattnayak, Amiya Ranjan Panda","Innovation on Machine Learning in Healthcare Services—An Introduction",2021,"","","","",75,"2022-07-13 09:23:39","","10.1007/978-981-33-4698-7_1","","",,,,,1,1.00,1,2,1,"","",""
0,"Nofe Alganmi","Machine learning for the exploitation of high throughput omics data: a case study on identifying circadian disruption from human blood transcriptomic data",2019,"","","","",76,"2022-07-13 09:23:39","","10.15126/THESIS.00850560","","",,,,,0,0.00,0,1,3,"The DNA microarray is a high throughput technology that is able to scan thousands of genes simultaneously and read their expression level. However, there are many challenges associated with data. One of the main opportunities is the curse of dimensionality which makes it difficult to learn without overfitting. Therefore, we proposed an unsupervised nonlinear machine learning framework to explore the circadian rhythmic features as a case study. Auto-encoder is capable of automatically learn the microarray data features and reveal knowledge that can help in designing the complex relations between the features for a circadian disorder in the future. Features derived from unsupervised algorithms can serve as input features to supervised learning, used to build discriminative markers, and directly used as functional modules. The constructed features are typically compressed representation of input data in a lower dimension. They maintain essential information in the input but are better organized than the input with less noise or artifacts. Therefore, it is easier to build classifiers on the summarized features than raw input data, and the success of a classifier heavily depends on the choice of data representation We proved our finding using machine learning classification framework. With our representation, we could enhance simple linear SVM accuracy from 63% to 75%    We also proposed a novel machine learning approach to evaluating the circadian disruption using robust regression as a contextual anomaly detection method. The main aspect of novelty in this work is coming from applying a point anomaly detection technique with respect to a circadian rhythmicity context. To the best of our knowledge, this work is the first which introduced the use of NR1D1/NR1D2 clock genes as prior knowledge to detect genes pathways involved in response to sleep disruption. In the Circadian Disruption Detection (CDD) model, we implemented and validated a model that successfully model the normal samples. While in anomalies samples i.e. samples with significant transcription effect under the circadian disruption, the model was acting poorly. Results of the analysis of variance (ANOVA) and t-test show the benefits of using our robust multi-regression errors as a biological biomarker to detect sleep deprivation using genes microarray data. we found that there was a significant difference between the error distribution for the normal sleep and the anomalies samples at the p<0.05 level. The model used to identify a quantitative measurement for sleep disruption in human regardless of the time of the day.","",""
1,"Seungwoong Ha, Hawoong Jeong","Discovering conservation laws from trajectories via machine learning",2021,"","","","",77,"2022-07-13 09:23:39","","","","",,,,,1,1.00,1,2,1,"Invariants and conservation laws convey critical information about the underlying dynamics of a system, yet it is generally infeasible to find them from large-scale data without any prior knowledge or human insight. We propose ConservNet to achieve this goal, a neural network that spontaneously discovers a conserved quantity from grouped data where the members of each group share invariants, similar to a general experimental setting where trajectories from different trials are observed. As a neural network trained with a novel and intuitive loss function called noise-variance loss, ConservNet learns the hidden invariants in each group of multi-dimensional observables in a data-driven, endto-end manner. Our model successfully discovers underlying invariants from the simulated systems having invariants as well as a real-world double pendulum trajectory. Since the model is robust to various noises and data conditions compared to baseline, our approach is directly applicable to experimental data for discovering hidden conservation laws and further, general relationships between variables.","",""
1,"K. Belesova, M. Callaghan, J. Minx, F. Creutzig, C. Turcu, E. Hutchinson, J. Milner, M. Crane, A. Haines, M. Davies, P. Wilkinson","Climate action for health and wellbeing in cities: a protocol for the systematic development of a database of peer-reviewed studies using machine learning methods",2021,"","","","",78,"2022-07-13 09:23:39","","10.12688/wellcomeopenres.16570.1","","",,,,,1,1.00,0,11,1,"Cities produce more than 70% of global greenhouse gas emissions. Action by cities is therefore crucial for climate change mitigation as well as for safeguarding the health and wellbeing of their populations under climate change. Many city governments have made ambitious commitments to climate change mitigation and adaptation and implemented a range of actions to address them. However, a systematic record and synthesis of the findings of evaluations of the effect of such actions on human health and wellbeing is currently lacking. This, in turn, impedes the development of robust knowledge on what constitutes high-impact climate actions of benefit to human health and wellbeing, which can inform future action plans, their implementation and scale-up. The development of a systematic record of studies reporting climate and health actions in cities is made challenging by the broad landscape of relevant literature scattered across many disciplines and sectors, which is challenging to effectively consolidate using traditional literature review methods. This protocol reports an innovative approach for the systematic development of a database of studies of climate change mitigation and adaptation actions implemented in cities, and their benefits (or disbenefits) for human health and wellbeing, derived from peer-reviewed academic literature. Our approach draws on extensive tailored search strategies and machine learning methods for article classification and tagging to generate a database for subsequent systematic reviews addressing questions of importance to urban decision-makers on climate actions in cities for human health and wellbeing.","",""
230,"Quanming Yao, Mengshuo Wang, H. Escalante, I. Guyon, Yi-Qi Hu, Yu-Feng Li, Wei-Wei Tu, Qiang Yang, Yang Yu","Taking Human out of Learning Applications: A Survey on Automated Machine Learning",2018,"","","","",79,"2022-07-13 09:23:39","","","","",,,,,230,57.50,26,9,4,"Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, human experts are heavily involved in every aspect of machine learning. In order to make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date but also can guide the design for new methods. Subsequently, we categorize and review the existing works from two aspects, i.e., the problem setup and the employed techniques. Finally, we provide a detailed analysis of AutoML approaches and explain the reasons underneath their successful applications. We hope this survey can serve as not only an insightful guideline for AutoML beginners but also an inspiration for future research.","",""
550,"F. Hutter, Lars Kotthoff, J. Vanschoren","Automated Machine Learning: Methods, Systems, Challenges",2019,"","","","",80,"2022-07-13 09:23:39","","10.1007/978-3-030-05318-5","","",,,,,550,183.33,183,3,3,"","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",81,"2022-07-13 09:23:39","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
0,"Swagatam Biswas, Sheikh Rafiul Islam","Machine Learning-Enabled Human Activity Recognition System for Humanoid Robot",2021,"","","","",82,"2022-07-13 09:23:39","","10.1007/978-981-16-0598-7_2","","",,,,,0,0.00,0,2,1,"","",""
2328,"Nicolas Papernot, P. Mcdaniel, Ian J. Goodfellow, S. Jha, Z. B. Celik, A. Swami","Practical Black-Box Attacks against Machine Learning",2016,"","","","",83,"2022-07-13 09:23:39","","10.1145/3052973.3053009","","",,,,,2328,388.00,388,6,6,"Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",84,"2022-07-13 09:23:39","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
7,"Jina Suh, S. Ghorashi, Gonzalo A. Ramos, N. Chen, S. Drucker, J. Verwey, P. Simard","AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning",2019,"","","","",85,"2022-07-13 09:23:39","","10.1145/3241379","","",,,,,7,2.33,1,7,3,"When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.","",""
12,"Lixiang Hong, Jinjian Lin, Shuya Li, Fangping Wan, Hui Yang, Tao Jiang, Dan Zhao, Jianyang Zeng","A novel machine learning framework for automated biomedical relation extraction from large-scale literature repositories",2020,"","","","",86,"2022-07-13 09:23:39","","10.1038/s42256-020-0189-y","","",,,,,12,6.00,2,8,2,"","",""
2,"A. Smart, Larry James, B. Hutchinson, Simone Wu, Shannon Vallor","Why Reliabilism Is not Enough: Epistemic and Moral Justification in Machine Learning",2020,"","","","",87,"2022-07-13 09:23:39","","10.1145/3375627.3375866","","",,,,,2,1.00,0,5,2,"In this paper we argue that standard calls for explainability that focus on the epistemic inscrutability of black-box machine learning models may be misplaced. If we presume, for the sake of this paper, that machine learning can be a source of knowledge, then it makes sense to wonder what kind of \em justification it involves. How do we rationalize on the one hand the seeming justificatory black box with the observed wide adoption of machine learning? We argue that, in general, people implicitly adoptreliabilism regarding machine learning. Reliabilism is an epistemological theory of epistemic justification according to which a belief is warranted if it has been produced by a reliable process or method \citegoldman2012reliabilism. We argue that, in cases where model deployments require \em moral justification, reliabilism is not sufficient, and instead justifying deployment requires establishing robust human processes as a moral ""wrapper'' around machine outputs. We then suggest that, in certain high-stakes domains with moral consequences, reliabilism does not provide another kind of necessary justification---moral justification. Finally, we offer cautions relevant to the (implicit or explicit) adoption of the reliabilist interpretation of machine learning.","",""
1,"L. Zaadnoordijk, Tarek R. Besold, R. Cusack","The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons from Infant Learning",2020,"","","","",88,"2022-07-13 09:23:39","","","","",,,,,1,0.50,0,3,2,"After a surge in popularity of supervised Deep Learning, the desire to reduce the dependence on curated, labelled data sets and to leverage the vast quantities of unlabelled data available recently triggered renewed interest in unsupervised learning algorithms. Despite a significantly improved performance due to approaches such as the identification of disentangled latent representations, contrastive learning, and clustering optimisations, the performance of unsupervised machine learning still falls short of its hypothesised potential. Machine learning has previously taken inspiration from neuroscience and cognitive science with great success. However, this has mostly been based on adult learners with access to labels and a vast amount of prior knowledge. In order to push unsupervised machine learning forward, we argue that developmental science of infant cognition might hold the key to unlocking the next generation of unsupervised learning approaches. Conceptually, human infant learning is the closest biological parallel to artificial unsupervised learning, as infants too must learn useful representations from unlabelled data. In contrast to machine learning, these new representations are learned rapidly and from relatively few examples. Moreover, infants learn robust representations that can be used flexibly and efficiently in a number of different tasks and contexts. We identify five crucial factors enabling infants' quality and speed of learning, assess the extent to which these have already been exploited in machine learning, and propose how further adoption of these factors can give rise to previously unseen performance levels in unsupervised learning.","",""
1,"K. Kalaiselvi, D. Karthika","Identifying Diseases and Diagnosis Using Machine Learning",2020,"","","","",89,"2022-07-13 09:23:39","","10.1007/978-3-030-40850-3_16","","",,,,,1,0.50,1,2,2,"","",""
0,"Yanning Cai, Qian Dong, Anlan Li","Application and research progress of machine learning in Bioinformatics",2020,"","","","",90,"2022-07-13 09:23:39","","10.1109/CVIDL51233.2020.00-69","","",,,,,0,0.00,0,3,2,"Artificial intelligence is an important branch of computer science, and machine learning is an important component of artificial intelligence. Machine learning enables computers to simulate human learning behavior, acquire knowledge and life skills spontaneously through learning, and constantly improve their performance in the process of learning, so as to achieve self-improvement. Bioinformatics is an interdisciplinary subject that applies mathematics and computer science to the index, classification and analysis of biomolecular information. Due to the characteristics and requirements of data in bioinformatics, many algorithms of artificial intelligence, especially machine learning, have been widely used in this field, which has greatly promoted the development of bioinformatics. This paper reviews the application and research progress of machine learning technology in bioinformatics.","",""
0,"M. Hecht, Jaron Chen, Phanitta Chomsinsap","CLAIM: An Enhanced Machine Learning Technique for Discrepancy Report Analysis",2020,"","","","",91,"2022-07-13 09:23:39","","10.1109/RAMS48030.2020.9153691","","",,,,,0,0.00,0,3,2,"CLAIM is a tool for analyzing and classifying discrepancy reports that allows for the incorporation of domain expert knowledge into a semi-supervised machine learning (ML) process (a semi-supervised learning uses a small number of manually labeled data and a much larger amount of unlabeled for training a machine learning algorithm). By using this domain knowledge, classification accuracy is higher than conventional ML approaches. The advantages are particularly apparent with small, imbalanced data sets that are quite common in discrepancy report data sets (an imbalanced data set has an unequal distribution of documents categories within each category). The CLAIM method is robust against human bias and can tolerate misclassifications of up to 20% of the training set. The increased accuracy of the CLAIM methodology makes ML a viable tool for safety, reliability, and software development process decision making. The modest human labor requirement enables use of the method under circumstances that previously made free text discrepancy report analysis infeasible due to resource, scheduling, and cost constraints.","",""
1,"Nikola Bakaric, Davor Nikolić","Automated phonetic transcription of Croatian folklore genres using supervised machine learning",2020,"","","","",92,"2022-07-13 09:23:39","","10.17234/INFUTURE.2019.16","","",,,,,1,0.50,1,2,2,"This paper aims to detect the possibilities of automatic text transcription for the purpose of preparing a corpus for further natural language processing analysis. The corpus contains various Croatian folklore genres. The transcription goal is to have one character represent one phoneme and remove spaces between accentuated and non-accentuated words. This knowledge independent system is trained using supervised learning methods and applied to the rest of the corpus using classifiers such as the naïve Bayes, k-nearest neighbour, support vector machine and others. The results are compared to a human-annotated sample to determine accuracy.","",""
4,"R. R. Batcha, M. Geetha","A Survey on IOT Based on Renewable Energy for Efficient Energy Conservation Using Machine Learning Approaches",2020,"","","","",93,"2022-07-13 09:23:39","","10.1109/ICETCE48199.2020.9091737","","",,,,,4,2.00,2,2,2,"The Internet of Things has a vision in which the web extends into this present reality which is followed by daily posts. The IoT allows articles to be detected or remotely controlled over existing system frameworks, opening doors for the unadulterated incorporation of the physical world into PC-based frameworks and providing improved efficiency, accuracy, and monetary advantage despite reduced human mediation. This breakthrough has various applications, such as urban communities focused on solar power, smart cities, micro matrices, and lights on Solar Road, etc. AI is when calculations decode gigantic knowledge arrangements to the PCs so that they can function without specific programming. This, for the most part, focuses on the development of different PC programs which may change when exposed to new information. During this period renewable vitality developed at a rate faster than some other time in history. These days people groups confronting the issue of confinement of non-sustainable power sources, so to take care of this issue the best arrangement is to utilize sustainable power sources like solar oriented vitality. Solar dependence is the planet's fastest-growing sustainable power source, steadily increasing by a standard of 40 percent in the overall limit. AI can be utilized in Probabilistic Energy Forecasting. The fundamental reason behind this is to gauge the likelihood appropriation of solar oriented power age from more than one solar-based ranch all the while. In this paper, we examined -the study on how IOT assumes a significant job in solar-powered vitality and how AI approaches are utilized in solar oriented vitality.","",""
1,"N. Howard, Naima Chouikhi, Ahsan Adeel, Katelyn Dial, Adam Howard, A. Hussain","BrainOS: A Novel Artificial Brain-Alike Automatic Machine Learning Framework",2020,"","","","",94,"2022-07-13 09:23:39","","10.3389/fncom.2020.00016","","",,,,,1,0.50,0,6,2,"Human intelligence is constituted by a multitude of cognitive functions activated either directly or indirectly by external stimuli of various kinds. Computational approaches to the cognitive sciences and to neuroscience are partly premised on the idea that computational simulations of such cognitive functions and brain operations suspected to correspond to them can help to further uncover knowledge about those functions and operations, specifically, how they might work together. These approaches are also partly premised on the idea that empirical neuroscience research, whether following on from such a simulation (as indeed simulation and empirical research are complementary) or otherwise, could help us build better artificially intelligent systems. This is based on the assumption that principles by which the brain seemingly operate, to the extent that it can be understood as computational, should at least be tested as principles for the operation of artificial systems. This paper explores some of the principles of the brain that seem to be responsible for its autonomous, problem-adaptive nature. The brain operating system (BrainOS) explicated here is an introduction to ongoing work aiming to create a robust, integrated model, combining the connectionist paradigm underlying neural networks and the symbolic paradigm underlying much else of AI. BrainOS is an automatic approach that selects the most appropriate model based on the (a) input at hand, (b) prior experience (a history of results of prior problem solving attempts), and (c) world knowledge (represented in the symbolic way and used as a means to explain its approach). It is able to accept diverse and mixed input data types, process histories and objectives, extract knowledge and infer a situational context. BrainOS is designed to be efficient through its ability to not only choose the most suitable learning model but to effectively calibrate it based on the task at hand.","",""
1,"Shengping Zhang, Huiyu Zhou, Dong Xu, M. E. Celebi, T. Bouwmans","Introduction to the Special Issue on Multimodal Machine Learning for Human Behavior Analysis",2020,"","","","",95,"2022-07-13 09:23:39","","10.1145/3381917","","",,,,,1,0.50,0,5,2,"Analyzing human behaviors in multimedia data has become one of the most interesting topics in intelligent multimedia perception. Recently, with the widespread availability of advanced visual and nonvisual sensors and a growing need for a user-friendly interface, integrating multimodality data for human behavior analysis, has received a great deal of research interests from the community of multimedia analysis. Compared to the traditional single-modality human behavior analysis, multimodality human behavior analysis provides deeper-level understanding of human identification and event detection, and a more comprehensive perspective for understanding the intrinsic interaction and connections of humans. Although the studies of human behavior analysis in multimodality data are invaluable for both academia and industry, there are many fundamental problems unsolved so far, such as learning representation of human appearance and behaviors from multiple modalities, mapping data from one modality to another to achieve cross-modality human behavior analysis, identifying and utilizing relations between elements from two or more different modalities for comprehensive behavior analysis, fusing information from two or more modalities to perform a more accurate prediction, transferring knowledge between modalities and their representations, and recovering missing modality data given the observed ones. This special issue accepted nine articles that address the challenging issues of multimodal machine learning for human behavior analysis. The first three articles focus on modeling multiple features using sparse coding. In particular, “Robust Visual Tracking Using Kernel Sparse Coding on Multiple Covariance Descriptors” proposes to use covariance matrices as descriptors to represent multiple features and then performs tracking in a sparse representation framework. “CovLets: A Second Order Descriptor for Modeling Multiple Features” proposes to aggregate local descriptors in the form of covariance descriptors into a rich descriptor by using sparse coding to learn second-order statistics of the covariance descriptors. “Action Recognition Using Form and Motion Modalities” uses hierarchal sparse coding to learn the underlying features from videos. The learned features characterize the form and motion simultaneously and therefore provide more accurate and complete feature representation. Beside sparse coding, six deep learning–based methods have also been proposed to address some issues of multimodal feature learning. “AMIL: Adversarial Multi-Instance Learning for Human Pose Estimation” proposes generative adversarial networks as the learning model, which has two residual multiple instance learning models with identical architecture. One is used as the generator, and the other is used as the discriminator. In addition to generative adversarial networks, “Multichannel Attention Refinement for Video Question Answering” proposes to tackle the Video Question Answering task—that is, the extension of image question answering in the video—from","",""
0,"Likita J. Raikar, Sayali V. Pardeshi, Pritam Sawale","Airplane Crash Analysis and Prediction using Machine Learning",2020,"","","","",96,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,3,2,"1,2,3 Department of Information Technology, Vidyalankar Institute of Technology, Mumbai, Maharashtra, India ---------------------------------------------------------------------***--------------------------------------------------------------------Abstract Airplanes are the most frequent mode of transportation in the present world. A single airplane crash leads to tremendous loss of human life. Safety is of prime importance since a huge number of people travel across the borders and within them. Abstracting data from a large database is always a difficult task. Data mining is a robust technology in order to extract the knowledge from raw data. Aviation systems take care of the minute precautions in order to prevent aircraft crashes. Factors causing and contributing to crashes needs to be understood studied and prevented in order to further minimize any kind of mishap. It is immensely difficult to find and extract the patterns of the factors due to very less amount of accident rates. In this research work, crash analysis and prediction is done. We have conducted the analysis of airplane crash data while, co-relating it with accidental information. To carry out this we have employed machine learning techniques. Machine learning helps in extracting the relationships between the various factors either affecting or non-affecting the crash to the general information of the airplane and as a result, patterns are formed. Many researchers, in recent times, have been using several machine learning techniques to help the aviation industry and the professionals in determining the hurdles. Supervised machine learning algorithms like SVM, K-NN, ADABoost and XGBoost are used for the purpose of prediction. The work has helped in improving the accuracy to a great extent.","",""
0,"Somayeh Shahrabadi, Y. Castilla, M. Guevara, L. Magalhães, Dibet Garcia Gonzalez, T. Adão","Defect detection in the textile industry using image-based machine learning methods: a brief review",2022,"","","","",97,"2022-07-13 09:23:39","","10.1088/1742-6596/2224/1/012010","","",,,,,0,0.00,0,6,1,"Traditionally, computer vision solutions for detecting elements of interest (e.g., defects) are based on strict context-sensitive implementations to address contained problems with a set of well-defined conditions. On the other hand, several machine learning approaches have proven their generalization capacity, not only to improve classification continuously, but also to learn from new examples, based on a fundamental aspect: the separation of data from the algorithmic setup. The findings regarding backward-propagation and the progresses built upon graphical cards technologies boost the advances in machine learning towards a subfield known as deep learning that is becoming very popular among many industrial areas, due to its even greater robustness and flexibility to map and deal knowledge that is typically handled by humans, with, also, incredible scalability proneness. Fabric defect detection is one of the manual processes that has been progressively automatized resorting to the aforementioned approaches, as it is an essential process for quality control. The goal is manifold: reduce human error, fatigue, ergonomic issues and associated costs, while simultaneously improving the expeditiousness and preciseness of the involved tasks, with a direct impact on profit. Following such research line with a specific focus in the textile industry, this work aims to constitute a brief review of both defect types and Automated Optical Inspection (AOI) mostly based on machine learning techniques, which have been proving their effectiveness in identifying anomalies within the context of textile material analysis. The inclusion of Convolutional Neural Network (CNN) based on known architectures such as AlexNet or Visual Geometry Group (VGG16) on computerized defect analysis allowed to reach accuracies over 98%. A short discussion is also provided along with an analysis of the current state characterizing this field of intervention, as well as some future challenges.","",""
2,"Robert Z. Zheng, Kevin Greenberg","Effective Design in Human and Machine Learning: A Cognitive Perspective",2018,"","","","",98,"2022-07-13 09:23:39","","10.1007/978-3-319-90403-0_4","","",,,,,2,0.50,1,2,4,"","",""
3,"Patrick C. Shih","Beyond Human-in-the-Loop: Empowering End-Users with Transparent Machine Learning",2018,"","","","",99,"2022-07-13 09:23:39","","10.1007/978-3-319-90403-0_3","","",,,,,3,0.75,3,1,4,"","",""
16,"Matthew E. Taylor","Assisting Transfer-Enabled Machine Learning Algorithms: Leveraging Human Knowledge for Curriculum Design",2009,"","","","",100,"2022-07-13 09:23:39","","","","",,,,,16,1.23,16,1,13,"Transfer learning is a successful technique that significantly improves machine learning algorithms by training on a sequence of tasks rather than a single task in isolation. However, there is currently no systematic method for deciding how to construct such a sequence of tasks. In this paper, I propose that while humans are well-suited for the task of curriculum development, significant research is still necessary to better understand how to create effective curricula for machine learning algorithms.","",""
1,"A. Mehta, Y. Jain, Anirudha Kemtur, Jugoslav Stojcheski, Saksham Consul, Mateo Tošić, Falk Lieder","Leveraging Machine Learning to Automatically Derive Robust Decision Strategies from Imperfect Knowledge of the Real World",2022,"","","","",101,"2022-07-13 09:23:39","","10.1007/s42113-022-00141-6","","",,,,,1,1.00,0,7,1,"","",""
3,"Wenxing Chen, Shuyang Dai, B. Zheng, Hao Lin","An Efficient Evaluation Method for Automobile Shells Design Based on Semi-supervised Machine Learning Strategy",2022,"","","","",102,"2022-07-13 09:23:39","","10.1088/1742-6596/2171/1/012026","","",,,,,3,3.00,1,4,1,"Automobile is one of the important modes of transportation for human travel in today’s society. Batch production in various countries in the world has also promoted the transformation of production concepts. At present, the development of the automobile industry is developing towards the trend of intelligence, personalizat-ion and sharing. Car appearance in a variety of ways, not every design is reasonable. Therefore, the main purpose of this article is to establish a scientific evaluation standard in order to large-scale test the quality of a variety of car shells design. The scientific nature is mainly reflected in combination the fluid-solid coupling knowledge and machine learning in this article, which can analyze the force of different shells in the flow field, and put out the cloud map information such as the stress, pressure and velocity of the shell. At last, analyze the best test samples and store them in the database, and then using semi-supervised heuristic algorithm to perform the sample training, the ultimate goal is to make the evaluation system more robust. The trained model can correctly evaluate each personalized car shape and give a reasonable score, which is convenient for car manufacturers to make best decision with personalized demand and scientific production.","",""
0,"Lihong Peng, Jialiang Yang, Minxian Wang, Liqian Zhou","Editorial: Machine Learning-Based Methods for RNA Data Analysis",2022,"","","","",103,"2022-07-13 09:23:39","","10.3389/fgene.2022.828575","","",,,,,0,0.00,0,4,1,"RNA is a type of extremely important biological macromolecules, which play key roles in all aspects of life activities and biological processes through its interactions with other biological entities Wang et al. (2021); Zhang et al. (2021). Thus, it is critical to identify complex biological associations between RNA and other biological entities Mu et al. (2020); Deng et al. (2018). Although experimental methods have been applied to analyze RNA data, especially identify various associations between RNA molecules and complex diseases, they are usually timeconsuming and resource demanding. Machine learning aims to simulate human learning ways in real time and divide the existing content into knowledge structures to advance learning efficiency. It can effectively use available electronic data to boost learning performance or implement accurate prediction Mohri et al. (2018). Furthermore, it still improves more evidence-based decision-making in the area of life science Jordan and Mitchell (2015). With the advancement of next generation sequencing techniques, machine learning-based methods discovered a large number of useful information from abundant RNA data and thus provide an effective way for the analysis of RNA data. Consequently, through machine learning techniques, we can design powerful models and algorithms to discovery diverse associations between RNA molecules themselves (such as microRNAs, mRNA, circular RNAs, and long noncoding RNAs) and between RNA molecules and complex diseases. We can further infer novel molecular markers for diagnosis and prognosis of corresponding diseases based on the identified associations. Based on the assumption of “guilt-by-association” and machine learning technologies, accumulated computational methods have been developed to analyze RNA data Liu et al. (2020); Chu et al. (2021). However, the performance of most methods remains unsatisfying due to data complexity and heterogeneity. Therefore, this research topic serves as a forum to develop new machine learning algorithms to improve RNA data analyses. MicroRNAs (miRNAs) are a class of short and endogenous noncoding RNAs Wang et al. (2020); Chen et al. (2019a). miRNAs can control gene expression based on translational repression or messenger RNA (mRNA) degradation and exhibit strong associations with a variety of disease including neurodegenerative diseases and cancers Saliminejad et al. (2019). Chen et al. designed a few representative machine learning-based algorithms to identify potential microRNA-disease associations Chen et al. (2018, 2019b). To find robust biomarkers associated with prostate cancer, Ning et al. designed amulti-omics data fusion method by integrating directed random walk and Support Vector Machine (SVM). They compared their proposed pathway-based method with five other methods including the Median method, Mean method, component analysis method, pathway activity inference method based on Edited by: William C. Cho, QEH, Hong Kong SAR, China","",""
0,"M. Barandas, Duarte Folgado, Ricardo Santos, Raquel Simão, Hugo Gamboa","Uncertainty-Based Rejection in Machine Learning: Implications for Model Development and Interpretability",2022,"","","","",104,"2022-07-13 09:23:39","","10.3390/electronics11030396","","",,,,,0,0.00,0,5,1,"Uncertainty is present in every single prediction of Machine Learning (ML) models. Uncertainty Quantification (UQ) is arguably relevant, in particular for safety-critical applications. Prior research focused on the development of methods to quantify uncertainty; however, less attention has been given to how to leverage the knowledge of uncertainty in the process of model development. This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline and giving insights into how UQ is used to improve model development and its interpretability. We identified three main research questions: (1) How can UQ contribute to choosing the most suitable model for a given classification task? (2) Can UQ be used to combine different models in a principled manner? (3) Can visualization techniques improve UQ’s interpretability? These questions are answered by applying several methods to quantify uncertainty in both a simulated dataset and a real-world dataset of Human Activity Recognition (HAR). Our results showed that uncertainty quantification can increase model robustness and interpretability.","",""
0,"Beilei Wang, Jie Jing, Xiaochun Huang, Cheng Hua, Qin Qin, Y. Jia, Zhiyong Wang, Lei Jiang, Bai Gao, Les J. Wu, Xianfei Zeng, Fubo Wang, Chuanbin Mao, Shanrong Liu","Establishment of a Knowledge‐and‐Data‐Driven Artificial Intelligence System with Robustness and Interpretability in Laboratory Medicine",2022,"","","","",105,"2022-07-13 09:23:39","","10.1002/aisy.202100204","","",,,,,0,0.00,0,14,1,"Laboratory medicine plays an important role in clinical diagnosis. However, no laboratory‐based artificial intelligence (AI) diagnostic system has been applied in current clinical practice due to the lack of robustness and interpretability. Although many attempts have been made, it is still difficult for doctors to adopt the existing machine learning (ML) patterns in interpreting laboratory (lab) big data. Here, a knowledge‐and‐data‐driven laboratory diagnostic system is developed, termed AI‐based Lab tEst tO diagNosis (AI LEON), by integrating an innovative knowledge graph analysis framework and “mixed XGboost and Genetic Algorithm (MiXG)” technique to simulate the doctor's laboratory‐based diagnosis. To establish AI LEON, we included 89 116 949 laboratory data and 10 423 581 diagnosis data points from 730 113 participants. Among them, 686 626 participants were recruited for training and validating purposes with the remaining for testing purposes. AI LEON automatically identified and analyzed 2071 lab indexes, resulting in multiple disease recommendations that involved 441 common diseases in ten organ systems. AI LEON exhibited outstanding transparency and interpretability in three universal clinical application scenarios and outperformed human physicians in interpreting lab reports. AI LEON is an advanced intelligent system that enables a comprehensive interpretation of lab big data, which substantially improves the clinical diagnosis.","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",106,"2022-07-13 09:23:39","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
0,"Majwega Jackson, Ggaliwango Marvin, A. Chakrabarty","Robust Ensemble Machine Learning for Precision Agriculture",2022,"","","","",107,"2022-07-13 09:23:39","","10.1109/iciset54810.2022.9775879","","",,,,,0,0.00,0,3,1,"In agriculture, various decisions largely depend on farmers’ previous experiences, however, using simple numerical values to enumerate these decisions is hard. To attain sustainable agriculture development, new technologies in farming are slowly replacing human labor in decision making. The new innovations in agriculture have been employed to increase crop planting scale and ensure quality. One of the biggest challenges faced by farmers who are operating on a small scale is soil exhaustion caused by poor farming practices for example mono-cropping which leads to loss of plant nutrients. And due to a lack of knowledge of existing soil nutrients and crop requirements, it’s hard for farmers to plant appropriately leading to low crop productivity and hence low production and huge losses. To address this challenge, precision agriculture, a modern farming technique has been proposed by many researchers to encompass research data of soil nutrients, soil types, etc., and recommend the most appropriate crop for planting. But since it’s too hard to build a single model that works best, it has been hard to attain precision agriculture goals with the previously proposed machine learning models. Therefore, in this paper, we propose a robust ensemble machine learning model which combines data from numerous modeling approaches to produce more robust models and more accurate predictions which Technology might work better especially in developing countries. And the results of the optimized crop recommendation indicate that the LightGBM classifier is the best with 99.39%, 100%, and 99.9% accuracy, Precision, and recall, making it the most reliable","",""
0,"Bukhoree Sahoh, Kanjana Haruehansapong, Mallika Kliangkhlao","Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model",2022,"","","","",108,"2022-07-13 09:23:39","","10.1109/access.2022.3155118","","",,,,,0,0.00,0,3,1,"A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.","",""
0,"Houpu Yao","Robust and Generalizable Machine Learning through Generative Models,Adversarial Training, and Physics Priors",2019,"","","","",109,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,3,"Machine learning has demonstrated great potential across a wide range of applications such as computer vision, robotics, speech recognition, drug discovery, material science, and physics simulation. Despite its current success, there are two major challenges for machine learning algorithms: limited robustness and generalizability. The robustness of a neural network is defined as the influence that input perturbations have on its final prediction. It has been shown that neural networks are very sensitive to input perturbations. For convolutional neural networks, its prediction can be totally different for input images that are visually indistinguishable to human eyes. Based on such property, hackers can reversely engineer the input to trick machine learning systems in targeted ways. These adversarial attacks have shown to be surprisingly effective, which has raised serious concerns over safety-critical applications like autonomous driving. In the meantime, how to improve the robustness of neural networks is still an open question. The generalizability of a neural network refers to its ability to be effective across a range of different inputs. On one hand, machine learning algorithms require a large number of samples from the data distribution in order to generalize well. It brings a big need for labeled data to perform supervised learning, and over-fitting on training data needs to be avoided for better generalization. On the other hand, machine learning models often fail to carry out reliable generalizations whenever there is a scarcity of supervised data. Many techniques have been proposed to improve the model generalizability; however, generalization with a few samples is still a challenging task. In this dissertation, we are thus motivated to improve the robustness and generalizability of neural networks. Firstly, unlike traditional bottom-up classifiers, we use a pre-trained generative model to perform top-down reasoning and infer the label information. The proposed generative classifier has shown to be promising in handling challenging classification tasks like adversarial attacks and input distribution shifts. Secondly, we focus on improving the network robustness and propose an extension to adversarial training by considering the transformation invariance. Proposed method improves the robustness over state-of-the-art methods by 2.5\% on MNIST, 3.7\% on CIFAR-10, and 1.1\% on restricted ImageNet. Thirdly, we focus on designing networks that generalize well at predicting physics response. Our physics prior knowledge is used to guide the designing of the network architecture, which enables efficient learning and inference. Proposed network is able to generalize well even when it is trained with a single image pair. Aerospace Engineering Doctoral Defense Robust and Generalizable Machine Learning through Generative Models, Adversarial Training, and Physics Prior Houpu Yao Advisor: Yi Ren July 12, 2019; 2:00 PM; ECG 237 School for Engineering of Matter, Transport and Energy","",""
2,"Gareth Simons","Prediction of 'artificial' urban archetypes at the pedestrian-scale through a synthesis of domain expertise with machine learning methods",2021,"","","","",110,"2022-07-13 09:23:39","","","","",,,,,2,2.00,2,1,1,"The vitality of urban spaces has been steadily undermined by the pervasive adoption of car-centric forms of urban development as characterised by lower densities, street networks offering poor connectivity for pedestrians, and a lack of accessible land-uses; yet, even if these issues have been clearly framed for some time, the problem persists in new forms of planning. It is here posited that a synthesis of domain knowledge and machine learning methods allows for the creation of robust toolsets against which newly proposed developments can be benchmarked in a more rigorous manner in the interest of greater accountability and better-evidenced decision-making. A worked example develops a sequence of machine learning models that distinguishing ‘artificial’ towns from their more walkable and mixed-use ‘historical’ equivalents. The dataset is developed from network centrality, mixed-use, land-use accessibility, and population density measures as proxies for spatial complexity, which are computed at the pedestrian-scale for 931 towns and cities in Great Britain. Using officially designated ‘New Towns’ as a departure point, a series of clues is then developed. First, using an iterative human-in-the-loop procedure, a supervised classifier (Extra-Trees) is cultivated from which 185 ‘artificial’ locations are identified based on data aggregated to respective town or city boundaries. This information is then used to train supervised and semi-supervised (M2) deep neural network classifiers against the higher resolution dataset. The models broadly align with intuitions expressed by urbanists and show potential for continued development to broach ensuing challenges pertaining to: selection of curated training exemplars; further development of techniques to accentuate localised scales of analysis; and methods for the calibration of model probabilities to align with the intuitions of domain experts.","",""
0,"Janghwan Lee, Shuhui Qu, Yan Kang, Wonhyouk Jang","Multimodal Machine Learning for Display Panel Defect Layer Identification",2021,"","","","",111,"2022-07-13 09:23:39","","10.1109/ASMC51741.2021.9435664","","",,,,,0,0.00,0,4,1,"Process control in display mass production needs defect layer identification to estimate the process that causes fault conditions, which is crucial for quality fault prediction and monitoring. Defect layer identification is a labor-intensive task that requires domain knowledge of experts to make consistent decisions over multiple datasets. Sometimes, it also requires examining multiple sources of inspection images to make the final identification. In this paper, we propose a multimodal machine learning model for defect layer identification as a classification problem from multiple sources of input images. After training two single modal models from each input source, we develop a final joint fusion model to achieve the best classification performance. This work also demonstrates how to estimate the final fusion model performance without exhaustively trying all possible combinations of single modal models. In order to integrate the approach into an industrial display manufacturing defect data analytic, we propose the data coverage model, which guarantees human-level classification performance within a certain portion of data. The data coverage model improves the robustness of the multimodal model, utilizing confident learning to make a high-confidence predictions for the particle defect layer identification and adding a filter to assess whether data samples are within the coverage based on the model’s latent space density estimation. This work uses particle defects data samples in 8 different layers as a combination of TEM and STEM images from display manufacturing fabrication lines. Our experimental results show that the classification accuracy improves substantially by deploying the proposed multimodal model. The results also show that it is possible to implement the data coverage model to achieve the human expert level of defect layer classification for a portion of data to automate the task.","",""
0,"C. Carpenter","Machine-Learning Approach Optimizes Well Spacing",2021,"","","","",112,"2022-07-13 09:23:39","","10.2118/0921-0044-jpt","","",,,,,0,0.00,0,1,1,"This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 201698, “Finding a Trend Out of Chaos: A Machine-Learning Approach for Well-Spacing Optimization,” by Zheren Ma, Ehsan Davani, SPE, and Xiaodan Ma, SPE, Quantum Reservoir Impact, et al., prepared for the 2020 SPE Annual Technical Conference and Exhibition, originally scheduled to be held in Denver, Colorado, 5–7 October. The paper has not been peer reviewed.  Data-driven decisions powered by machine-learning (ML) methods are increasing in popularity when optimizing field development in unconventional reservoirs. However, because well performance is affected by many factors, the challenge is to uncover trends within all the noise. By leveraging basin-level knowledge captured by big data sculpting, integrating private and public data with the use of uncertainty quantification, a process the authors describe as augmented artificial intelligence (AI) can provide quick, science-based answers for well spacing and fracturing optimization and can assess the full potential of an asset in unconventional reservoirs. A case study in the Midland Basin is detailed in the complete paper.      Augmented AI is a process wherein ML and human expertise are coupled to improve solutions. The augmented AI work flow (Fig. 1) starts with data sculpting, which includes information retrieval; data cleaning and standardization; and smart, deep, and systematic data quality control (QC). Feature engineering generates all relevant parameters entering the ML model. More than 50 features have been generated for this work and categorized. The final step is to perform model tuning and ensemble, evaluating model robustness and generating model explanation and uncertainty quantification.        The complete paper provides a detailed geological background of the Permian Basin and its Wolfcamp unconventional layer, an organic-rich shale formation with tight reservoir properties.  To find a solution for the multidimensional well-spacing problem in the Permian Basin, multiple sources and types of data were gathered using publicly available sources. The detailed geological attributes, including structure, petrophysics, geochemistry, basin-level features, and cultural information (such as counties or lease boundaries) have been combined in an integrated database to extract and generate features for the ML algorithm. Most attributes are available either in a limited number of wells, mostly vertical, or through the low number of available cored wells across the basin. Therefore, a significant amount of data imputation has been processed with mapping exercises using geostatistical modeling techniques.  The mapping process augmented the ML attribute-generation step because these features were distributed in both vertical and lateral dimensions. All horizontal wells within the area of interest across the Permian Basin have been resampled with the logged and mapped information.  The geological features also are reengineered into multiple indices to reduce the number of labeled features to include in the ML process. This feature-reduction process also has helped in ranking and selecting the most-important parameters relevant to the well-spacing problem. Here, a key attribute called the shale-oil index was introduced, which is generated for the ML-driven process and is used in understanding the level of contribution of geological sweet spots to well-spacing optimization. In addition, the initial well, reservoir, or laboratory data, including logs, have been normalized before mapping and modeling to eliminate potential bias. This study has focused on Wolfcamp layers; however, both geological and engineering attribute generation work flows used for this practical ML methodology to find optimization solutions for common problems are highly applicable to other unconventional layers, such as Bone Spring or Spraberry. ","",""
12,"Atik Mahabub","A robust voting approach for diabetes prediction using traditional machine learning techniques",2019,"","","","",113,"2022-07-13 09:23:39","","10.1007/s42452-019-1759-7","","",,,,,12,4.00,12,1,3,"","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",114,"2022-07-13 09:23:39","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
0,"G. Truda","Quantified Sleep: Machine learning techniques for observational n-of-1 studies",2021,"","","","",115,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,1,"This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features. The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. “Markov unfolding” is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal β-parameters, and using the SHAP framework, which can explain any “black box” model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.","",""
0,"Alireza Tamaddoni-Nezhad, D. Bohan, Ghazal Afroozi Milani, A. Raybould, S. Muggleton","Human–Machine Scientific Discovery",2021,"","","","",116,"2022-07-13 09:23:39","","10.1093/oso/9780198862536.003.0015","","",,,,,0,0.00,0,5,1,"Humanity is facing existential, societal challenges related to food security, ecosystem conservation, antimicrobial resistance, etc, and Artificial Intelligence (AI) is already playing an important role in tackling these new challenges. Most current AI approaches are limited when it comes to ‘knowledge transfer’ with humans, i.e. it is difficult to incorporate existing human knowledge and also the output knowledge is not human comprehensible. In this chapter we demonstrate how a combination of comprehensible machine learning, text-mining and domain knowledge could enhance human-machine collaboration for the purpose of automated scientific discovery where humans and computers jointly develop and evaluate scientific theories. As a case study, we describe a combination of logic-based machine learning (which included human-encoded ecological background knowledge) and text-mining from scientific publications (to verify machine-learned hypotheses) for the purpose of automated discovery of ecological interaction networks (food-webs) to detect change in agricultural ecosystems using the Farm Scale Evaluations (FSEs) of genetically modified herbicide-tolerant (GMHT) crops dataset. The results included novel food-web hypotheses, some confirmed by subsequent experimental studies (e.g. DNA analysis) and published in scientific journals. These machine-leaned food-webs were also used as the basis of a recent study revealing resilience of agro-ecosystems to changes in farming management using GMHT crops.","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",117,"2022-07-13 09:23:39","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
121,"Andreas Holzinger, Peter Kieseberg, E. Weippl, A. Tjoa","Current Advances, Trends and Challenges of Machine Learning and Knowledge Extraction: From Machine Learning to Explainable AI",2018,"","","","",118,"2022-07-13 09:23:39","","10.1007/978-3-319-99740-7_1","","",,,,,121,30.25,30,4,4,"","",""
114,"Andreas Holzinger, M. Plass, M. Kickmeier-Rust, K. Holzinger, G. Crişan, C. Pintea, V. Palade","Interactive machine learning: experimental evidence for the human in the algorithmic loop",2018,"","","","",119,"2022-07-13 09:23:39","","10.1007/s10489-018-1361-5","","",,,,,114,28.50,16,7,4,"","",""
3,"M. McMillan, J. Fohring, E. Haber, J. Granek","Orogenic gold prospectivity mapping using machine learning",2019,"","","","",120,"2022-07-13 09:23:39","","10.1080/22020586.2019.12073020","","",,,,,3,1.00,1,4,3,"Summary As major mineral discoveries have become rarer over the last two decades, the industry has begun to turn to new technologies to assist in the exploration process. One such advancement is the application of machine learning and artificial intelligence (AI) to geoscience data. Mineral prospectivity mapping has been around for decades but with the increase in computer power, recently it has gained traction again as a means for exploration teams to take full advantage of the numerous datasets at their disposal. Although having a team of human experts with a wealth of geoscience knowledge and experience is still fundamental to the exploration process, the ability to robustly integrate and analyse large geoscience datasets over vast spatial regions quickly becomes unwieldy if done manually. In this study, we developed a new algorithm for mineral prospectivity mapping using a VNet deep convolutional neural network and applied it to finding gold at the Committee Bay greenstone belt in the Canadian Arctic. The machine learning network took all the geoscience data available from the area and generated a prospectivity map for targeting economic orogenic gold mineralization. The results were subsequently validated on a separate nearby region where the machine predictions were compared to gold assay values from drilling. The gold assays from this region were not included in the training process, and the method demonstrated good success in predicting where the highest gold mineralization occurred. A subsequent gold prospectivity map was produced for the main area in question, and in addition to many new targets the VNet algorithm predicted many targets that the exploration team had previously generated. This suggests that this process assists the exploration team in vetting old targets while opening their eyes to new targets as well. In this way, the algorithm helps to vector in on prospective new and old areas while maximizing the value of all available geoscience data.","",""
4,"T. Schmid","Deconstructing the Final Frontier of Artificial Intelligence: Five Theses for a Constructivist Machine Learning",2019,"","","","",121,"2022-07-13 09:23:39","","","","",,,,,4,1.33,4,1,3,"Ambiguity and diversity in human cognition can be regarded a final frontier in developing equivalent systems of artificial intelligence. Despite astonishing accomplishments, modern machine learning algorithms are still hardly more than adaptive systems. Deep neural networks, for example, represent complexity through complex connectivity but are not able to allow for abstraction and differentiation of interpretable knowledge, i.e., for key mechanisms of human cognition. Like support vector machines, random forests and other statistically motivated algorithms, they do neither reflect nor yield structures and strategies of human thinking. Therefore, we suggest to realign the use of existing machine learning tools with respect to the philosophical paradigm of constructivism, which currently is the key concept in human learning and professional teaching. Based on the idea that learning units like classifiers can be considered models with limited validity, we formulate five principles to guide a constructivist machine learning. We describe how to define such models and model limitations, how to relate them and how relationships allow to abstract and differentiate models. To this end, we propose the use of meta data for classifiers and other models. Moreover, we argue that such meta data-based machine learning results in a knowledge base that is both created by the means of automation and interpretable for humans. Over the last decade, it has become widely accepted to address computational systems intelligent. Not only journalists, but also scientists have adapted this habit in their publications. In fact, many classical engineering tasks like monitoring or regulating have profited from the employment of machine learning (Abellan-Nebot and Romero Subirón 2010; Mohanraj, Jayaraj, and Muraleedharan 2012). The same holds true for pattern recognition, most prominently in automated image and video analysis (Zafeiriou, Zhang, and Zhang 2015; Yang et al. 2011). And even though ultimate challenges like the infamous Turing test are left unsatisfied (You 2015), some exceptional results in specialized tasks like playing the game of go (Silver et al. 2016) make current learning machines look intelligent on a human level. Copyright held by the author(s). In A. Martin, K. Hinkelmann, A. Gerber, D. Lenat, F. van Harmelen, P. Clark (Eds.), Proceedings of the AAAI 2019 Spring Symposium on Combining Machine Learning with Knowledge Engineering (AAAI-MAKE 2019). Stanford University, Palo Alto, California, USA, March 25-27, 2019. A final frontier for learning systems, however, is the variety of alternative cognitive functions observable in a diverse set of individuals or from ambiguous stimuli (Kornmeier and Bach 2012). While philosophy has acknowledged and embraced the subjectivity and limitations of human cognition during the last decades (Prawat and Floden 1994), current learning systems regard cognition a complex, yet technical task to be solved. In particular, established algorithms do neither provide convincing answers to the challenges provided by an ambiguous environment; nor do they offer concepts that explicitly allow for contradictory judgements comparable to differences in social perception. The main reason for this shortcoming is that so far both algorithms and researchers have failed to incorporate a constructivist point of view. Constructivism implies not only cognition to be a highly individual phenomenon, but also humans to take an active role in their perception of the world – and that there is no such thing as a human-independent reality (Reich 2009). Yet algorithms and applications aiming to predict things other than laws of nature are implicitly founded on exactly this outdated asumption. In the following, we introduce axioms that allow machine learning to follow constructivist principles. Key features of this approach are the use of modern tools from empirical sciences, model-oriented learning, the ability to handle ambiguity, the ability to integrate supervised and unsupervised learning into a unified framework, the ability to create an individual knowledge base and the ability to abstract, differentiate or discard learned knowledge automatically. 1. The key component of cognitive functionality is a model. Since the introduction of artificial neural networks as a theoretical concept (McCulloch and Pitts 1943), many mathematicians and computer scientists have considered neurons the key component of learning systems. In education and psychology, however, cognitive functions are often seen as certain skills or abilities acquired and exposed by an individual human and described in terms like the concept of competence, which, e.g., is widely used in the modern European education system (Méhaut and Winch 2012). Functionalistic psychology explains cognitive functions of humans by the concept of mental models (Rouse and Morris 1986). Initially, mental models have been used to understand motor control, e.g., of hand movements (Veldhuyzen and Stassen 1977). In a more general sense, however, mental models are described as “hypothetical constructs” (Wickens 2000) that can be ordered hierarchically (Rasmussen 1979) and allow a human to make predictions about his physical and social environment (Oatley 1985). It has also been postulated that such models cannot be of static nature but rather underlay continuous modifications (Oatley 1985). Philosophers, too, consider models an important tool in human knowledge acquisition (Klaus 1967, p. 412) or even the only tool, respectively (Stachowiak 1973, p. 56). While varying and concurring theoretical definitions exist, most model concepts assume an image, an origin of the image and a relationship between them. This definition is, e.g., matched by the idea of mathematical modeling as proposed by Heinrich Hertz and others (Hertz 1894; Hamilton 1982). With the rise of robotics and artificial intelligence, engineers have adapted and extended this idea by postulating the concept of a cybernetic model, which involves a generalized subject and an object of the model (Rose 2009). Cybernetics, however, did neither reflect time-related aspects nor issues involved with individual model subjects. This matter was adressed by Herbert Stachowiak, who was influenced by cybernetics when developing his General Model Theory (Hof 2018). He postulated any model to be limited to specific subjects, specific temporal ranges and specific purposes (Stachowiak 1973, p. 133). Limitations, to this end, are considered a matter of fact rather than a matter of definition. Thus, such models circumvent ambiguity by viewing an otherwise ambiguous model with unknown validity limits as a number of models of limited validity. 2. Learning constitutes from constructing, reconstructing or deconstructing models. Modern education is dominated by the ideas of constructivism and constructivist learning (Fox 2001). At its heart, this approach is based on the assumption that humans acquire knowledge and competences actively and individually through processes called construction, reconstruction and deconstruction (Duffy and Jonassen 1992). Construction is associated with creation, innovation and production and implies searching for variations, combinations or transfers of knowledge (Reich 2004, p. 145). Analogously, reconstruction is associated with application, repetition or imitation and implies searching for order, patterns or models (Reich 2004, p. 145). Deconstruction is in the context of constructivism associated with reconsideration, doubt and modification and implies searching for omissions, additions and defective parts of acquired knowledge (Reich 2004, p. 145). Learning algorithms have been used for half a century to transform sample data into models in a mathematical sense, that is: into generalized mathematical relationships between image and origin. The two major approaches or objectives, known as supervised and unsupervised learning, either do or do not require a given target parameter. Artificial neural networks and their relatives are among the most popular and prominent algorithms for learning with a given target parameter (Singh, Thakur, and Sharma 2016), but statistically motivated approaches like support vector machines (Cristianini and Shawe-Taylor 2000) or random forests (Breiman 2001) are also widely used for supervised learning; a specialized field of supervised learning is reinforcement learning, which is popular in robotics (Kober and Peters 2012) and adaptive control (Lewis, Vrabie, and Vamvoudakis 2012). For unsupervised learning, too, biologically inspired approaches like self-organizing maps (Kohonen 2001) as well as statistically motivated approaches like k-means (Jain 2010) are employed. To some extent, machine learning parallels modern education concepts. A construction process in the constructivist sense may be matched by an unsupervised learning, i.e., identifying clusterings or dimensionality reduction, and can, e.g., be implemented with self-organizing maps, kmeans, autoencoders or feature clustering (Schmid 2018). A reconstruction process in the constructivist sense may be matched by a supervised learning, i.e., classification or regression tasks, and can, e.g., be implemented with artificial neural networks or random forests (Schmid 2018). Few researchers, however, have discussed a constructivist approach to machine learning (Drescher 1989; Quartz 1993), and even less how to design a deconstruction process. While domainspecific applications with manual re-engineering options exist (Herbst and Karagiannis 2000), to the best of our knowledge, there is currently only one working implementation of an algorithmic deconstruction process (Schmid 2018). 3. Deconstructing models computationally requires model-based meta data. In order to automate and implement a deconstruction process, successfully learned models must be held available for comparison or re-training. More over, possible matchings with n","",""
0,"Zhirui Hu","Machine learning bias game",2019,"","","","",122,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,3,"Machine learning is the science that helps computers uncover data patterns and relationships. It is a powerful tool that studies how computers simulate or implement human learning behaviors to acquire new knowledge or skills and reorganize existing knowledge structures to continuously improve their performance. But as these systems become more complex and powerful, researchers have found that the widespread use of artificial intelligence systems can cause some erroneous decisions. However, it is not the use of these AI algorithms themselves that is an issue, but rather that human biases are incorporated into the resulting models, and into the systems that use these models. This paper focuses on the concept of how human bias effect on machine learning, analyzes the main reasons for its formation through two practical cases, and the impact of this bias on machine learning algorithms and the impact on practical engineering applications. Then we try to design a game in which we use regional crime rate prediction and the mathematical model of police deployment to combine the biased concepts we studied to show the impact of bias in the game and discuss how to eliminate this bias. Through the above work, we could get a better understanding of the concept of bias, and reflect on the incompleteness and defects of machine learning algorithms, thereby further improving the robustness, efficiency and reliability of machine learning algorithms.","",""
1,"Adyasha Rath, Debahuti Mishra, G. Panda, S. Satapathy","An exhaustive review of machine and deep learning based diagnosis of heart diseases",2021,"","","","",123,"2022-07-13 09:23:39","","10.1007/s11042-021-11259-3","","",,,,,1,1.00,0,4,1,"","",""
3,"K. M. Annervaz, J. George, Shubhashis Sengupta","A Generic Platform to Automate Legal Knowledge Work Process Using Machine Learning",2015,"","","","",124,"2022-07-13 09:23:39","","10.1109/ICMLA.2015.32","","",,,,,3,0.43,1,3,7,"Management of legal contracts in various business domains such as Real Estate are examples of typical business process outsourcing activity. One of such process is Lease Abstraction, where largely manual inspection and validation of large commercial lease documents made for real estate deals is done by offshore experts and relevant information from the documents is extracted into a structured form. This structured information is further used for aggregate analytics and decision making by large real estate firms. We propose a system based on machine learning techniques to semi automate this process, essentially leading to 50% human effort savings. Our approach weaves together state-of-the-art machine learning techniques like supervised classifier models, sequence modeling techniques and various semi-supervised approaches. We articulate the effectiveness of our solution using the results from the experiments. Our platform is being used in production environment by Accenture Operations and the initial results and user feedback are encouraging.","",""
1,"Anay Raj","Malaria Disease Diagnosis using Machine Learning Techniques",2020,"","","","",125,"2022-07-13 09:23:39","","","","",,,,,1,0.50,1,1,2,"Malaria is a major infectious disease of humans, with roughly 200 million cases worldwide and more than 400,000 deaths per year. Malaria could be prevented, controlled, and cured more effectively if a more accurate and efficient diagnostic method was available. The standard diagnostic method for malaria is the microscopic examination of blood smears for infected erythrocytes by qualified microscopists. However, this method is inefficient and the quality of the diagnosis depends on the experience and knowledge of the microscopists. This study proposes a new and robust machine learning model based on a Convolutional neural network (CNN) to automatically classify single cells in thin blood smears on standard microscope slides as either infected or uninfected. This will help in the faster diagnosis of malaria and save valuable time for beginning the treatment.","",""
1,"Maniesh Singh, G. Makarychev, H. Mustapha, D. Voleti, R. Akkurt, K. Daghar, A. Mawlod, Khalid Al Marzouqi, Sami Shehab, Alaa Maarouf, Obeida El Jundi, A. Razouki","Machine Learning Assisted Petrophysical Logs Quality Control, Editing and Reconstruction",2020,"","","","",126,"2022-07-13 09:23:39","","10.2118/202977-ms","","",,,,,1,0.50,0,12,2,"  Mature field operators collect log data for tens of years. Collection of log dataset include various generation and multiple vintages of logging tool from multiple vendors. Standard approach is to correct the logs for various artefacts and normalize the logs over a field scale. Manually conducting this routine is time consuming and subjective. The objective of the study was to create a machine learning (ML) assisted tool for logs in a giant Lower Cretaceous Carbonate Onshore field in Abu Dhabi, UAE to automatically perform data QC, bad data identification and log reconstruction (correcting for borehole effects, filling gaps, cleaning spikes, etc.) of Quad Combo well logs.  The study targets Quad Combo logs acquired since mid-60's. Machine learning algorithm was trained on 50 vertical wells, spread throughout the structure of the field.  The workflow solution consists of several advanced algorithms guided by domain knowledge and physics based well logs correlation, all embedded in an ML-data-driven environment. The methodology consists of the following steps: oOutliers detection and complete data clustering.oSupervised ML to map outliers to clusters.oRandom Forest based ML training by clusters, by logs combination on complete data.oSaved models are applied back to the whole data including outliers and sections with one or several logs missing.oValidation and Blind test of results.oModels can be stored and re-used for prediction on new data.  The ML tool demonstrated its effectiveness while correcting logs for outliers’ like Depth Offsets between logs, identifying Erroneous readings, logs prediction for absent data and Synthetic logs corrections. The tool has a tendency to harmonize logs. First test demonstrated robustness of the selected algorithm for outliers’ detection. It cleaned data from most of contamination, while keeping good but statistically underrepresented logs readings.  Clustering algorithm was enhanced to supplement cluster assignment by extraction of the corresponding probabilities that were used as a cut-off value and utilized for a mixture of different ML models results. This application made results more realistic in the intervals where clustering was problematic and at the transition between different clusters.  Several intervals of bad and depth shifted logs corrections were noticed. Outliers’ corrections for these logs was performed the way that at Neutron-Density or Neutron-Sonic cross-plots points were moved towards expected lithology lines. Algorithm could pick-up hidden outliers (such as synthetic logs) and edited the logs to make it look intuitively natural to a human analyst.  The work successfully demonstrated effectiveness of ML tool for log editing in a complex environment working on a big dataset that was subject of manual editing and has number of hidden outliers. This strong log quality assurance further assisted in building Rock Typing based Static Model in complex and diagenetically altered Carbonates.","",""
0,"Butch Quinto","Introduction to Machine Learning",2020,"","","","",127,"2022-07-13 09:23:39","","10.1007/978-1-4842-5669-5_1","","",,,,,0,0.00,0,1,2,"","",""
297,"Andrius Vabalas, E. Gowen, E. Poliakoff, A. Casson","Machine learning algorithm validation with a limited sample size",2019,"","","","",128,"2022-07-13 09:23:39","","10.1371/journal.pone.0224365","","",,,,,297,99.00,74,4,3,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.","",""
21,"James A. Brown, A. Cuzzocrea, Michael Kresta, Korbin D. L. Kristjanson, C. Leung, Timothy W. Tebinka","A Machine Learning Tool for Supporting Advanced Knowledge Discovery from Chess Game Data",2017,"","","","",129,"2022-07-13 09:23:39","","10.1109/ICMLA.2017.00-87","","",,,,,21,4.20,4,6,5,"In the current era of big data, high volumes of a wide variety of data of different veracity can be easily collected or generated at a high velocity. Embedded in these big data is valuable information or knowledge. This calls for machine learning techniques for supporting advanced knowledge discovery from these big data. A rich source of big heterogeneous data is game data--including sports games, online video games, and board games such as chess games. The deep interaction and simplicity of representation afforded by the game of chess have worked together to produce one of the most studied games in the world. It is a great intellectual challenge, and not only for humans. Chess engines can sometimes play chess better than grandmasters, and they can be used to assist the study of games and individual positions. However, this does not help a chess student choose which games to study. In this paper, we present a machine learning system--specifically, an unsupervised learning tool--to analyze big chess datasets. Evaluation results show that not only can machine learning help find interesting games, but also that chess can be a great testing ground for machine learning and data mining techniques for big data analytics.","",""
1,"Elizabeth Real de Oliveira, P. Rodrigues","A Review of Literature on Human Behaviour and Artificial Intelligence: Contributions Towards Knowledge Management",2021,"","","","",130,"2022-07-13 09:23:39","","10.34190/ejkm.19.2.2459","","",,,,,1,1.00,1,2,1,"The main purpose of this research paper is to understand how artificial intelligence and machine learning applied to human behaviour has been treated, both theoretically and empirically, over the last twenty years, regarding predictive analytics and human organizational behaviour analysis. To achieve this goal, the authors performed a systematic literature review, as proposed by Tranfield, Denyer and Smart (2003), on selected databases and followed the PRISMA framework (Preferred Reporting Items for Systematic reviews and Meta-Analyses). The method is particularly suited for assessing emerging trends within multiple disciplines and therefore deemed the most suitable method for the purposes of this paper, which intends to survey and select papers according to their contribute towards theory building. By mapping what is known, this review will lay the groundwork, providing a timely insight into the current state of research on human organisational behaviour and its applications. A total of 17795 papers resulted from the application of the search equations. The papers’ abstracts were screened according to the inclusion / exclusion criterions which resulted in 199 papers for analysis. The authors have analysed the papers through VOSviewer software and R programming statistical computing software. This review showed that 60% of the research undertaken in the field has been done in the last three and a half years and there is no prominent author or academic journal, showing the emergence and the novelty of this research. The other key finds of the research relate to the evolution of the concept, from data-driven (hard) towards emotions-driven (soft) organisations.","",""
0,"Dipanwita Thakur, A. Guzzo, G. Fortino","t-SNE and PCA in Ensemble Learning based Human Activity Recognition with Smartwatch*",2021,"","","","",131,"2022-07-13 09:23:39","","10.1109/ICHMS53169.2021.9582455","","",,,,,0,0.00,0,3,1,"Smartwatch based Human Activity Recognition (HAR) is gaining popularity due to habitual unhealthy behavior of the population and the rich in-built sensors of smartwatch. Raw sensor data is not well suited for the classifiers to identify similar activity patterns. According to the HAR literature handcrafted features are beneficial to properly identify the activities, which is time consuming and need expert domain knowledge. Automatic feature extraction libraries give high-dimensional feature sets that increase the computation and memory cost. In this work, we present an Ensemble Learning framework that exploit dimensional reduction and visualization to improve performance specification. Specifically, using Time Series Feature Extraction Library (TSFEL), the high dimensional features are extracted automatically. Then, to reduce the dimension of the feature set and proper visualization, Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) are used respectively. The relevant extracted features using PCA are fed to an ensemble of three different Machine Learning (ML) classifiers to identify six different human physical activities. We also compare the proposed method with three popularly used shallow ML methods. Self collected human activity smartwatch sensor signal is used to establish the feasibility of the proposed framework. We observe that the proposed framework outper-forms the existing state-of-the-art benchmark frameworks, with an accuracy of 96%.","",""
166,"M. Alber, A. Buganza Tepole, W. R. Cannon, S. De, S. Dura-Bernal, K. Garikipati, G. Karniadakis, W. Lytton, P. Perdikaris, L. Petzold, E. Kuhl","Integrating machine learning and multiscale modeling—perspectives, challenges, and opportunities in the biological, biomedical, and behavioral sciences",2019,"","","","",132,"2022-07-13 09:23:39","","10.1038/s41746-019-0193-y","","",,,,,166,55.33,17,11,3,"","",""
1,"Rui Li, Lulu Cui, Yilong Zhao, Wenhui Zhou, H. Fu","Long-term trends of ambient nitrate (NO3−) concentrations across China based on ensemble  machine-learning models",2020,"","","","",133,"2022-07-13 09:23:39","","10.5194/essd-2020-243","","",,,,,1,0.50,0,5,2,"High loadings of nitrate (NO−3 ) in the aerosol over China significantly exacerbate the air quality and pose a great threat to ecosystem safety through dry–wet deposition. Unfortunately, limited ground-level observation data make it challenging to fully reflect the spatial pattern of NO−3 levels across China. Until now, long-term monthly particulate NO−3 datasets at a high resolution were still missing, which restricted the assessment of human health and ecosystem safety. Therefore, a unique monthly NO−3 dataset at 0.25 ◦ resolution over China during 2005–2015 was developed by assimilating surface observations, satellite products, meteorological data, land use types and other covariates using an ensemble model combining random forest (RF), gradientboosting decision tree (GBDT), and extreme gradient-boosting (XGBoost) methods. The new developed product featured an excellent cross-validation R2 value (0.78) and relatively lower root-mean-square error (RMSE: 1.19 μgNm−3) and mean absolute error (MAE: 0.81 μgNm−3). Besides, the dataset also exhibited relatively robust performance at the spatial and temporal scales. Moreover, the dataset displayed good agreement with (R2 = 0.85, RMSE= 0.74 μgNm−3, and MAE= 0.55 μgNm−3) some unlearned data collected from previous studies. The spatiotemporal variations in the developed product were also shown. The estimated NO−3 concentration showed the highest value in the North China Plain (NCP) (3.55± 1.25 μgNm−3); followed by the Yangtze River Delta (YRD) (2.56±1.12 μgNm−3), Pearl River Delta (PRD) (1.68±0.81 μgNm−3), and Sichuan Basin (1.53± 0.63 μgNm−3), and the lowest one in the Tibetan Plateau (0.42± 0.25 μgNm−3). The higher ambient NO−3 concentrations in the NCP, YRD, and PRD were closely linked to the dense anthropogenic emissions. Apart from the intensive human activities, poor terrain condition might be a key factor for the serious NO−3 pollution in the Sichuan Basin. The lowest ambient NO−3 concentration in the Tibetan Plateau was contributed by the scarce anthropogenic emission and favourable meteorological factors (e.g. high wind speed). In addition, the ambient NO−3 concentration showed a marked increasing tendency of 0.10 μgNm −3 yr−1 during 2005–2014 (p < 0.05), while it decreased sharply from 2014 to 2015 at a rate of −0.40 μgNm−3 yr−1 (p < 0.05). The ambient NO−3 levels in Beijing–Tianjin–Hebei (BTH), YRD, and PRD displayed gradual increases at a rate of 0.20, 0.11, and 0.05 μgNm−3 yr−1 (p < 0.05) during 2005–2013, respectively. The gradual increases in NO−3 concentrations in these regions from 2005 to 2013 were due to the fact that the emission reduction measures during this period focused on the reduction of SO2 emission rather than NOx emission and the rapid increase in energy consumption. Afterwards, the government further strengthened these emission reduction measures and thus caused the dramatic decreases in NO−3 concentrations in these regions from 2013 to 2015 (p < 0.05). The long-term NO − 3 dataset over China could greatly deepen the knowledge about the impacts of emission reduction measures on Published by Copernicus Publications. 2148 R. Li et al.: Monthly NO 3 dataset across China air quality improvement. The monthly particulate NO−3 levels over China during 2005–2015 are open access at https://doi.org/10.5281/zenodo.3988307 (Li et al., 2020c).","",""
0,"Joshua Ho, Chien-Min Wang","Human-Centered AI using Ethical Causality and Learning Representation for Multi-Agent Deep Reinforcement Learning",2021,"","","","",134,"2022-07-13 09:23:39","","10.1109/ICHMS53169.2021.9582667","","",,,,,0,0.00,0,2,1,"Human-Centered Computing and AI are two fields devoted to several cross-intersecting interests in the modern AI design. They consider human factors and the machine learning algorithms to enhance compatibility and reliability for human-robot interaction and cooperation. In this work, we propose a novel design concept for the challenging issues that have raised ethical dilemmas; an augmented ethical causality with successor representation for policy gradient models Human-Centered AI with environments. The proposed system leverages Human-Centered AI for using explainable knowledge to construct the ethical causality, and shows it significantly outperformed the statistical approach and baselines alone by further considering meta parametric Human-Centered ethical priorities, when compared to other approaches in the simulated game theory Deep Reinforcement Learning environments. The experimental results aim to efficiently and effectively access the cause, effect and impact of causal inference and multi-agent heterogeneity in the DRL environments for natural, general and significant causal learning representations.","",""
1,"Andrew McCarthy, Essam Ghadafi, Panagiotis Andriotis, Phil Legg","Functionality-Preserving Adversarial Machine Learning for Robust Classification in Cybersecurity and Intrusion Detection Domains: A Survey",2022,"","","","",135,"2022-07-13 09:23:39","","10.3390/jcp2010010","","",,,,,1,1.00,0,4,1,"Machine learning has become widely adopted as a strategy for dealing with a variety of cybersecurity issues, ranging from insider threat detection to intrusion and malware detection. However, by their very nature, machine learning systems can introduce vulnerabilities to a security defence whereby a learnt model is unaware of so-called adversarial examples that may intentionally result in mis-classification and therefore bypass a system. Adversarial machine learning has been a research topic for over a decade and is now an accepted but open problem. Much of the early research on adversarial examples has addressed issues related to computer vision, yet as machine learning continues to be adopted in other domains, then likewise it is important to assess the potential vulnerabilities that may occur. A key part of transferring to new domains relates to functionality-preservation, such that any crafted attack can still execute the original intended functionality when inspected by a human and/or a machine. In this literature survey, our main objective is to address the domain of adversarial machine learning attacks and examine the robustness of machine learning models in the cybersecurity and intrusion detection domains. We identify the key trends in current work observed in the literature, and explore how these relate to the research challenges that remain open for future works. Inclusion criteria were: articles related to functionality-preservation in adversarial machine learning for cybersecurity or intrusion detection with insight into robust classification. Generally, we excluded works that are not yet peer-reviewed; however, we included some significant papers that make a clear contribution to the domain. There is a risk of subjective bias in the selection of non-peer reviewed articles; however, this was mitigated by co-author review. We selected the following databases with a sizeable computer science element to search and retrieve literature: IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus, SpringerLink, and Google Scholar. The literature search was conducted up to January 2022. We have striven to ensure a comprehensive coverage of the domain to the best of our knowledge. We have performed systematic searches of the literature, noting our search terms and results, and following up on all materials that appear relevant and fit within the topic domains of this review. This research was funded by the Partnership PhD scheme at the University of the West of England in collaboration with Techmodal Ltd.","",""
0,"Eike Petersen, Yannik Potdevin, Esfandiar Mohammadi, Stephan Zidowitz, Sabrina Breyer, Dirk Nowotka, Sandra Henn, Ludwig Pechmann, M. Leucker, P. Rostalski, Christian Herzog","Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Challenges and Solutions",2021,"","","","",136,"2022-07-13 09:23:39","","10.1109/ACCESS.2022.3178382","","",,,,,0,0.00,0,11,1,"Machine learning is expected to fuel significant improvements in medical care. To ensure that fundamental principles such as beneficence, respect for human autonomy, prevention of harm, justice, privacy, and transparency are respected, medical machine learning systems must be developed responsibly. Many high-level declarations of ethical principles have been put forth for this purpose, but there is a severe lack of technical guidelines explicating the practical consequences for medical machine learning. Similarly, there is currently considerable uncertainty regarding the exact regulatory requirements placed upon medical machine learning systems. This survey provides an overview of the technical and procedural challenges involved in creating medical machine learning systems responsibly and in conformity with existing regulations, as well as possible solutions to address these challenges. First, a brief review of existing regulations affecting medical machine learning is provided, showing that properties such as safety, robustness, reliability, privacy, security, transparency, explainability, and nondiscrimination are all demanded already by existing law and regulations—albeit, in many cases, to an uncertain degree. Next, the key technical obstacles to achieving these desirable properties are discussed, as well as important techniques to overcome these obstacles in the medical context. We notice that distribution shift, spurious correlations, model underspecification, uncertainty quantification, and data scarcity represent severe challenges in the medical context. Promising solution approaches include the use of large and representative datasets and federated learning as a means to that end, the careful exploitation of domain knowledge, the use of inherently transparent models, comprehensive out-of-distribution model testing and verification, as well as algorithmic impact assessments.","",""
23,"Muxin Gu, M. Buckley","Semi-supervised machine learning for automated species identification by collagen peptide mass fingerprinting",2018,"","","","",137,"2022-07-13 09:23:39","","10.1186/s12859-018-2221-3","","",,,,,23,5.75,12,2,4,"","",""
2,"Juan Gao, Chunfang Li, Zhen-Guo Liu, Lian-Zhong Liu","Elicitation of machine learning to human learning from iterative error correcting",2013,"","","","",138,"2022-07-13 09:23:39","","10.1109/ICMLC.2013.6890473","","",,,,,2,0.22,1,4,9,"Numerous high performance machine learning algorithms are designed based on human learning, while human learning can also acquire elicitation from machine learning to investigate highly efficient learning process. This paper presents two iteratively error correcting based probabilistic neural networks (PNN) for connecting human learning and machine learning. C-PNN, G-PNN and G-PNN have been used to delete redundancy samples in our learning software based on question bank. In detail, we propose a recommendation approach of learning samples which selects samples according to density of knowledge points through calculating data field of knowledge points covered by problems. The approach also deletes redundant problems in order to deal with the question-sea tactical and remedy the defects of random selecting usually used in human learning.","",""
3,"A. Tonda, N. Boukhelifa, T. Chabin, M. Barnabé, Benoît Génot, E. Lutton, N. Perrot","Interactive Machine Learning for Applications in Food Science",2018,"","","","",139,"2022-07-13 09:23:39","","10.1007/978-3-319-90403-0_22","","",,,,,3,0.75,0,7,4,"","",""
0,"S. Kavitha, Dr. R. Subramanian","KNOWLEDGE DISCOVERY CONDUCTED IN THE AREAS OF MACHINE LEARNING BY HIGH PERFORMANCE COMPUTING USING EVALUATION OF LEARNING ALGORITHMS",2017,"","","","",140,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,5,"The last decade has seen considerable growth in interest in Artificial Intelligence and Machine Learning. In the broadest sense, these fields aim to ‘learn something useful’ about the environment within which the organism operates. How gathered information is processed leads to the development of algorithms, how to process high dimensional data and deal with uncertainty. In the early stages of research in Machine Learning and related areas, similar techniques were discovered in relatively isolated research communities. Whilst not all techniques have a natural description in terms of probability theory, many do, and it is the framework of Graphical Models (a marriage between graph and probability theory) that has enabled the understanding and transference of ideas from statistical physics, statistics, machine learning and information theory. To this extent, it is now reasonable to expect that machine learning researchers are familiar with the basics of statistical modelling techniques. we apply different machine learning (ML) techniques for building objective models, that permit to automatically assess the image quality in agreement with human visual perception. The six ML methods proposed are discriminant analysis, k-nearest neighbors, artificial neural network, non-linear regression, decision tree and fuzzy logic. Both the stability and the robustness of designed models are evaluated by using Monte-Carlo cross-validation approach (MCCV). The simulation results demonstrate that fuzzy logic model provides the best prediction accuracy.","",""
16,"Phil Legg, Jim E. Smith, A. Downing","Visual analytics for collaborative human-machine confidence in human-centric active learning tasks",2019,"","","","",141,"2022-07-13 09:23:39","","10.1186/s13673-019-0167-8","","",,,,,16,5.33,5,3,3,"","",""
391,"Zhiyuan Chen, B. Liu","Lifelong Machine Learning",2016,"","","","",142,"2022-07-13 09:23:39","","10.2200/S00737ED1V01Y201610AIM033","","",,,,,391,65.17,196,2,6,"Lifelong Machine Learning (or Lifelong Learning) is an advanced machine learning paradigm that learns continuously, accumulates the knowledge learned in previous tasks, and uses it to help future learning. In the process, the learner becomes more and more knowledgeable and effective at learning. This learning ability is one of the hallmarks of human intelligence. However, the current dominant machine learning paradigm learns in isolation: given a training dataset, it runs a machine learning algorithm on the dataset to produce a model. It makes no attempt to retain the learned knowledge and use it in future learning. Although this isolated learning paradigm has been very successful, it requires a large number of training examples, and is only suitable for well-defined and narrow tasks. In comparison, we humans can learn effectively with a few examples because we have accumulated so much knowledge in the past which enables us to learn with little data or effort. Lifelong learning aims to achieve this capability. As statistical machine learning matures, it is time to make a major effort to break the isolated learning tradition and to study lifelong learning to bring machine learning to new heights. Applications such as intelligent assistants, chatbots, and physical robots that interact with humans and systems in real-life environments are also calling for such lifelong learning capabilities. Without the ability to accumulate the learned knowledge and use it to learn more knowledge incrementally, a system will probably never be truly intelligent. This book serves as an introductory text and survey to lifelong learning.","",""
1,"Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, M. Shafique","ISA4ML: Training Data-Unaware Imperceptible Security Attacks on Machine Learning Modules of Autonomous Vehicles",2018,"","","","",143,"2022-07-13 09:23:39","","","","",,,,,1,0.25,0,4,4,"Due to big data analysis ability, machine learning (ML) algorithms are becoming popular for several applications in autonomous vehicles. However, ML algorithms possessinherent security vulnerabilities which increase the demand for robust ML algorithms. Recently, various groups have demonstrated how vulnerabilities in ML can be exploited to perform several security attacks for confidence reduction and random/targeted misclassification, by using the data manipulation techniques. These traditional data manipulation techniques, especially during the training stage, introduce the random visual noise. However, such visual noise can be detected during the attack or testing through noise detection/filtering or human-in-the-loop. In this paper, we propose a novel methodology to automatically generate an ""imperceptible attack"" by exploiting the back-propagation property of trained deep neural networks (DNNs). Unlike state-of-the-art inference attacks, our methodology does not require any knowledge of the training data set during the attack image generation. To illustrate the effectiveness of the proposed methodology, we present a case study for traffic sign detection in an autonomous driving use case. We deploy the state-of-the-art VGGNet DNN trained for German Traffic Sign Recognition Benchmarks (GTSRB) datasets. Our experimental results show that the generated attacks are imperceptible in both subjective tests (i.e., visual perception) and objective tests (i.e., without any noticeable change in the correlation and structural similarity index) but still performs successful misclassification attacks.","",""
15742,"Thomas G. Dietterich","Machine learning",1996,"","","","",144,"2022-07-13 09:23:39","","10.1145/242224.242229","","",,,,,15742,605.46,15742,1,26,"Machine Learning is the study of methods for programming computers to learn. Computers are applied to a wide range of tasks, and for most of these it is relatively easy for programmers to design and implement the necessary software. However, there are many tasks for which this is difficult or impossible. These can be divided into four general categories. First, there are problems for which there exist no human experts. For example, in modern automated manufacturing facilities, there is a need to predict machine failures before they occur by analyzing sensor readings. Because the machines are new, there are no human experts who can be interviewed by a programmer to provide the knowledge necessary to build a computer system. A machine learning system can study recorded data and subsequent machine failures and learn prediction rules. Second, there are problems where human experts exist, but where they are unable to explain their expertise. This is the case in many perceptual tasks, such as speech recognition, hand-writing recognition, and natural language understanding. Virtually all humans exhibit expert-level abilities on these tasks, but none of them can describe the detailed steps that they follow as they perform them. Fortunately, humans can provide machines with examples of the inputs and correct outputs for these tasks, so machine learning algorithms can learn to map the inputs to the outputs. Third, there are problems where phenomena are changing rapidly. In finance, for example, people would like to predict the future behavior of the stock market, of consumer purchases, or of exchange rates. These behaviors change frequently, so that even if a programmer could construct a good predictive computer program, it would need to be rewritten frequently. A learning program can relieve the programmer of this burden by constantly modifying and tuning a set of learned prediction rules. Fourth, there are applications that need to be customized for each computer user separately. Consider, for example, a program to filter unwanted electronic mail messages. Different users will need different filters. It is unreasonable to expect each user to program his or her own rules, and it is infeasible to provide every user with a software engineer to keep the rules up-to-date. A machine learning system can learn which mail messages the user rejects and maintain the filtering rules automatically. Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis. Statistics focuses on understanding the phenomena that have generated the data, often with the goal of testing different hypotheses about those phenomena. Data mining seeks to find patterns in the data that are understandable by people. Psychological studies of human learning aspire to understand the mechanisms underlying the various learning behaviors exhibited by people (concept learning, skill acquisition, strategy change, etc.).","",""
3,"Finn Kuusisto, V. S. Costa, Zhonggang Hou, James A. Thomson, David Page, R. Stewart","Machine Learning to Predict Developmental Neurotoxicity with High-Throughput Data from 2D Bio-Engineered Tissues",2019,"","","","",145,"2022-07-13 09:23:39","","10.1109/ICMLA.2019.00055","","",,,,,3,1.00,1,6,3,"There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.","",""
0,"Jinyun Tang, W. Riley, Qing Zhu, T. Keenan","Using machine learning and artificial intelligence to improve model-data integrated earth system model predictions of water and carbon cycle extremes",2021,"","","","",146,"2022-07-13 09:23:39","","10.2172/1769794","","",,,,,0,0.00,0,4,1,"Jinyun Tang 1, William J Riley 1, Qing Zhu 1, Trevor Keenan 1, 2 1Lawrence Berkeley National Laboratory 2 University of California, Berkeley Focal Area(s) The research proposed here focuses on improving the predictive power of the land component of earth system models (ESMs) using (1) model-data fusion enabled by machine learning (ML) and artificial intelligence (AI), (2) predictive modeling through the combination of ML, AI, and big-data (comprising both model output and observations), and (3) insight of ESM structure and process mechanisms gleaned from complex data using ML and AI. Science Challenge Current efforts on water and carbon cycle benchmarking and improving ESM predictions focus on how well models capture (1) snapshots of climatology (e.g., the spatial pattern of land surface evapotranspiration), (2) time series of aggregated variables (e.g., interannual variability of net land carbon fluxes), and (3) one-vs-one variable correlations (e.g., the relationship between precipitation and evapotranspiration), all of which are less than three dimensional. However, ESM predictions are by nature of high dimension, beyond those spanned by space and time, when variables like vegetation diversity and human water use are considered. Moreover, in 10 years, with improved spatial-temporal resolution and the inclusion of more mechanistic processes, ESMs will very likely output more diverse data streams at much larger volume. Meanwhile, thanks to technological advancements, the amount of observations will also increase dramatically, in both type and spatial-temporal coverage. Current benchmark and model-data integration paradigms and methods are insufficient to address this big-data challenge. Further, current approaches are not of sufficient specificity or fidelity for evaluation at fine spatial resolutions (e.g., 1 km), nor do they provide comprehensive understanding of the casualty relationships that affect climate extremes. To address these challenges, research is proposed here to (1) make better uses of multiple scales of observations to concurrently analyze, evaluate, and reduce ESM uncertainty, and generate process knowledge of terrestrial processes, (2) achieve the ability to clearly integrate diverse observations, ML and AI, theory, and model predictive capabilities, (3) obtain robust quantification of multivariate functional relationships (e.g., net primary productivity to precipitation, temperature, and radiation) under a wide range of environmental conditions, and (4) provide high fidelity prediction and understanding of climate extreme events at fine spatial resolutions. Rationale ESM predictions are uncertain because (1) the earth system comprises many components, including atmosphere, land, ocean, biosphere, cryosphere, human activities, etc., each of which is insufficiently monitored and understood; (2) when the insufficient understanding of these earth system components are combined with the limited spatial-temporal resolution of ESMs,","",""
0,"Hadil Abukwaik, Mohammed Abufouda, Thejashree Nair, H. D. Rombach","How practical is it? Machine Learning for Identifying Conceptual Interoperability Constraints in API Documents",2018,"","","","",147,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,4,4,"Building meaningful interoperation with external software units requires performing the conceptual interoperability analysis that starts with identifying the conceptual interoperability constraints of each software unit, then it compares the systems' constraints to detect their conceptual mismatch. We call the conceptual interoperability constraints (the COINs) that can be of different types including structure, dynamic, and quality. Missing such constraints may lead to unexpected mismatches, expensive resolution, and running-late projects. However, it is a challenging task for software architects and analysts to manually analyze the unstructured text in API documents to identify the COINs. Not only it is a tedious and time-consuming task, but also it needs knowledge about the constraint types. In this article, we present and evaluate our idea of utilizing machine learning techniques in automating the COIN identification, which is the first step of conceptual interoperability analysis, from human text in API documents. Our empirical research started with a multiple-case study to build the ground truth dataset, on which we contributed our machine learning COIN-Classification Model. We show the model's robustness through experiments using different machine learning text-classification algorithms. The experiments' results revealed that our model can achieve up to 87% accuracy in automatically identifying the COINs in text. Thus, we implemented a tool that embeds our model to demonstrate its practical value in industrial context. Then, we evaluated the practitioners' acceptance for the tool and found that they significantly agreed on its usefulness and ease of use.","",""
1,"C. He, M. Mahfouf, Luis A. Torres-Salomao","An Adaptive General Type-2 Fuzzy Logic Approach for Psychophysiological State Modeling in Real-Time Human–Machine Interfaces",2021,"","","","",148,"2022-07-13 09:23:39","","10.1109/THMS.2020.3027531","","",,,,,1,1.00,0,3,1,"In this article, a new type-2 fuzzy-based modeling approach is proposed to assess human operators’ psychophysiological states for both safety and reliability of human–machine interface systems. Such a new modeling technique combines type-2 fuzzy sets with state tracking to update the rule base through a Bayesian process. These new configurations successfully lead to an adaptive, robust, and transparent computational framework that can be utilized to identify dynamic (i.e., real time) features without prior training. The proposed framework is validated on mental arithmetic cognitive real-time experiments with ten participants. It is found that the proposed framework outperforms other paradigms (i.e., an adaptive neuro-fuzzy inference system and an adaptive general type-2 fuzzy c-means modeling approach) in terms of disturbance rejection and learning capabilities. The proposed framework achieved the best performance compared to other models that have been presented in the related literature. Therefore, the new framework can be a promising development in human–machine interface systems. It can be further utilized to develop advanced control mechanisms, investigate the origins of human compromised task performance, and identify and remedy psychophysiological breakdown in the early stages.","",""
0,"Yangli-ao Geng, Ming Liu, Qingyong Li, Ruisi He","Introduction of machine learning",2019,"","","","",149,"2022-07-13 09:23:39","","10.1049/PBTE081E_CH1","","",,,,,0,0.00,0,4,3,"Machine learning, as a subfield of artificial intelligence, is a category of algorithms that allow computers to learn knowledge from examples and experience (data), without being explicitly programmed. Machine-learning algorithms can find natural patterns hidden in massive complex data, which humans can hardly deal with manually.In wireless communications, when you encounter a complex task or problem involving a large amount of data and lots of variables, but without existing formula or equation, machine learning can be a solution. Traditionally, machine-learning algorithms can be roughly divided into three categories: supervised learning, unsupervised learning and reinforcement learning (RL). In this chapter, we present an overview of machine-learning algorithms and list their applications, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of wireless communications practitioners.","",""
0,"T. Inamura, Hiroki Yokoyama, Emre Ugur, Xavier Hinaut, M. Beetz, T. Taniguchi","Section focused on machine learning methods for high-level cognitive capabilities in robotics",2019,"","","","",150,"2022-07-13 09:23:39","","10.1080/01691864.2019.1625183","","",,,,,0,0.00,0,6,3,"Integrating highand low-level cognitive capabilities is essential for developing robotic systems that can adaptively act in our daily environment in active collaboration with humans. Recent advances in machine learning techniques, including deep learning and hierarchical Bayesian modeling, are providing us with new possibilities to integrate highand low-level cognitive capabilities in robotics. It became clear that such learning methods are indispensable to create robots that can effectively address uncertaintieswhile acting smart in the realworld. We had organized workshops, named ‘Machine Learning Methods for High-Level Cognitive Capabilities in Robotics,’ in IROS 2016 and 2017. In the workshops, we solicited excellent papers related to the demand for accelerating the synergies of lowand high-level cognitive capabilities. It would enable us to develop methods that address real-world problems in a more robust manner. Hence, we aim to share knowledge regarding stateof-the-art machine learning methods that contribute to modeling sensory-motor and cognitive capabilities in robotics and to exchange views among cutting-edge robotics researchers with a special emphasis on adaptive high-level cognition. Through the workshops, researchers from cognitive robotics, speech processing, artificial intelligence, machine learning, computer vision, natural language processing, and so on were gathered to discuss the current challenges in machine learning methods for highlevel cognitive capabilities in robotics. Typical keywords discussed in the workshop were as follows: multimodal communication, learning motor skills and segmentation of time-series information, concept formation, probabilisticmodels, language acquisition, human–robot communication and collaboration, deep learning, the theory of mind and model of others, skill transfer, Bayesian modeling, application in communicable service robots, and so on. These keywords should be organized using Figure 1, which was used in the workshop discussion in 2017. Our daily environment is full of uncertainties, with complex objects and challenging tasks. A robot is not only required to deal with things appropriately in a physical manner, but also perform logical and linguistic tasks in the real world. Consider a scenario where a human user tells a robot, ‘pleasemove it into the blue box.’ In addition to solving a manipulation task, the robot must move the target object to a particular blue box and estimatewhat ‘it’ represents. In addition to solving the manipulation task, the robot should estimate the meaning of ‘into,’ representing the relationship between ‘it’ and ‘the blue box’ in a real-world environment. When a robot attempts to communicate and collaborate with human users in a realworld environment, bridging highand low-level cognitive capabilities is critical. Low-level cognitive capabilities include physical control, behavioral motion generation, and sensory perception (node (i) in Figure 1). In contrast, high-level cognitive capabilities include logical inference, planning, and language (node (ii) in Figure 1). Conventionally, symbol-based and/or rule-based approaches have been employed to model high-level cognitive capabilities in robotics. However, it has been reported that such conventional methods could not create a robot that could address inevitable uncertainties in the physical environment and natural human–robot communications. In other words, the difficulty of direct transformation between nodes (i) and (ii) was the major cause of the low performance of natural human–robot communications. However, recent advances in machine learning techniques have provided a bridge betweennode (i) and the top node, and between node (ii) and the top node, as shown in Figure 1. It has become increasingly clear that machine learning methods are indispensable for creating robots that address uncertainties. In addition to machine learning techniques, big data in human–robot interactions through a virtual reality environment can be applied to accelerate the learning process to connect the highand low-level cognitive capabilities. We organized a new type of submission strategy at the second workshop in 2017. Authors could choose from two submission categories:","",""
456,"Amir Mosavi, Pınar Öztürk, K. Chau","Flood Prediction Using Machine Learning Models: Literature Review",2018,"","","","",151,"2022-07-13 09:23:39","","10.3390/w10111536","","",,,,,456,114.00,152,3,4,"Floods are among the most destructive natural disasters, which are highly complex to model. The research on the advancement of flood prediction models contributed to risk reduction, policy suggestion, minimization of the loss of human life, and reduction of the property damage associated with floods. To mimic the complex mathematical expressions of physical processes of floods, during the past two decades, machine learning (ML) methods contributed highly in the advancement of prediction systems providing better performance and cost-effective solutions. Due to the vast benefits and potential of ML, its popularity dramatically increased among hydrologists. Researchers through introducing novel ML methods and hybridizing of the existing ones aim at discovering more accurate and efficient prediction models. The main contribution of this paper is to demonstrate the state of the art of ML models in flood prediction and to give insight into the most suitable models. In this paper, the literature where ML models were benchmarked through a qualitative analysis of robustness, accuracy, effectiveness, and speed are particularly investigated to provide an extensive overview on the various ML algorithms used in the field. The performance comparison of ML models presents an in-depth understanding of the different techniques within the framework of a comprehensive evaluation and discussion. As a result, this paper introduces the most promising prediction methods for both long-term and short-term floods. Furthermore, the major trends in improving the quality of the flood prediction models are investigated. Among them, hybridization, data decomposition, algorithm ensemble, and model optimization are reported as the most effective strategies for the improvement of ML methods. This survey can be used as a guideline for hydrologists as well as climate scientists in choosing the proper ML method according to the prediction task.","",""
1,"G. Mani, B. Bhargava, Pelin Angin, Miguel Villarreal-Vasquez, D. Ulybyshev, Jason Kobes","Machine Learning Models to Enhance the Science of Cognitive Autonomy",2018,"","","","",152,"2022-07-13 09:23:39","","10.1109/AIKE.2018.00015","","",,,,,1,0.25,0,6,4,"Intelligent Autonomous Systems (IAS) are highly cognitive, reflective, multitask-able, and effective in knowledge discovery. Examples of IAS include software systems that are capable of automatic reconfiguration, autonomous vehicles, network of sensors with reconfigurable sensory platforms, and an unmanned aerial vehicle (UAV) respecting privacy by deciding to turn off its camera when pointing inside a private residence. Research is needed to build systems that can monitor their environment and interactions, learn their capabilities and limitations, and adapt to meet the mission objectives with limited or no human intervention. The systems should be fail-safe and should allow for graceful degradations while continuing to meet the mission objectives. In this paper, we provide an overview of our proposed new methodologies and workflows, and survey the existing approaches and new ones that can advance the science of autonomy in smart systems through enhancements in real-time control, auto-reconfigurability, monitoring, adaptability, and trust. This paper also provides the theoretical framework behind IAS.","",""
0,"Byoung-Tak Zhang","AFRL-AFOSR-JP-TR-2016-0014 Bio-Inspired Human-Level Machine Learning",2016,"","","","",153,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,6,"How can brain computation be so fast, flexible, and robust? What kinds of representational and organizational principles facilitate the biological brain to learn so efficiently and flexibly on the sub-second time scale and so reliably on the continuous lifetime scale? To understand these principles, we aimed to develop human-level machine learning technology that is fast, flexible, and reliable to adapt to a continuously changing, dynamic environment. Based on dynamic “neural” populations (neural assemblies), we constructed a “human-like” machine learning model and implement this model in “molecular” populations (molecular assemblies) using in vitro DNA computing. In the first year, we developed the dynamic hypernetwork models of neural populations in the sequential Bayesian framework for lifelong learning. In the second year, we extended it to the molecular dynamic hypernetwork model, and designed in vitro experimental protocols to implement online language learning from a stream of text corpus. In the third year, we demonstrated the use of molecular dynamic hypernetworks for multimodal visuo-linguistic concept learning from a long stream of video data and their extensions to high-level cognitive functions such as anagram solving problem. We expect that the bio-inspired human-level machine learning combined with molecular-computing implementation can offer an interesting, novel paradigm to address for flexible and reliable computing. Introduction: One of the main challenges in artificial intelligence is to develop human-like machine learning technology that is fast, flexible, and reliable to adapt to a continuously changing, dynamic environment. Converging neuroanatomical and neurophysiological evidence shows that the brain uses distributed, overlapping representations based on sparse population codes that are coordinated dynamically (Averbeck et al., 2006; Pouget et al., 2000; von der Malsburg et al., 2010). We hypothesize that brain computation exploits the huge degrees of freedom generated by a large number of memory units, ranging from neurotransmitters and neurons to DISTRIBUTION A: Distribution approved for public release. cell-assembly, and organized into multiscale complex networks in space and coordinated dynamically in time (Caroni, 2012; Freeman, 2000). The objective of this project is to build a learning-friendly computational model based on dynamic neural populations and implementing this model in self-assembling molecular populations using DNA computing. A key idea underlying this approach is that the plasticity of neural populations in the brain is based on molecular interactions at the physico-chemical level and, thus, molecular computational processes can naturally simulate human-like learning and memory. The molecular self-assembly mechanisms in DNA chemistry provide us a natural, physical medium for modeling dynamic “neural” populations (neural assemblies). Massively parallel mechanisms of in vitro DNA computing provide us a convenient tool for dealing with large populations, 10 molecules in a nano-mole, which is bigger than the numbers of 10 neurons and 10 synaptic connections in the human brain. In previous work, we experimentally demonstrated the feasibility of cognitive memory with DNA self-assembly. We showed that wet DNA computing can implement weighted-sum operations which are fundamental to perform pattern classification (Lim et al., 2010). Since pattern classification underlies many cognitive tasks, this work opened a new way of creating flexible cognitive memories in vitro with molecules. We also demonstrated the potential of the molecular self-assembly model to build associative language models automatically from language data to generate sentences (Lee et al., 2011). On the mathematical and computational modeling side we developed a probabilistic graphical model of sparse, random population codes called hypernetworks (Zhang, 2008). The model also applied to a visually-grounded language learning (Zhang 35 al., 2012), where cognitive memory consists of multimodal compound concepts which are encoded as hyperedges (molecular memory particles) and then assembled, dissembled, and reassembled to be adapted incrementally as the video sequences are observed. However, there were several challenges to achieving human-level learning and memory. First, the concept of population coding needed to be extended to deal with online, predictive learning in a changing environment. Second, representational formalisms and their translations between neural populations and molecular populations needed to be investigated. Third, the DNA computing and molecular learning technology needed be scaled up to make molecular computational simulation of the whole-brain scale, to make cognitive learning possible and to achieve human-level machine learning. In the first year of the project, we focused on constructing mathematical theories of dynamic neural populations. Building upon our previous work on the hypernetwork models of cognitive learning and memory (Zhang, 2012), we developed population-coded dynamic hypernetwork models of lifelong learning in a non-stationary, changing environment [1, 2, 6, 8, 9, 17]. In [9], we discussed our model from the perspectives of embodied cognition, multisensory integration, cognitive dynamics, perception-action cycle, and lifelong learning. We developed a sequential Bayesian framework for lifelong learning, built a taxonomy of lifelong-learning paradigms, and examined information-theoretic objective functions for each paradigm, with an emphasis on active learning. Also, in [7], we presented that DNA hybridization can be modeled as computing the inner product between DISTRIBUTION A: Distribution approved for public release. embedded vectors in a corresponding vector space, and proposed the algorithm performing learning of a binary classifier in this vector space. In the second year, we extended this to the molecular dynamic hypernetwork model, and designed in vitro experimental protocols to implement online language learning from a stream of text corpus [3, 4, 10, 14, 19, 20, 23]. To measure the difference between different information-encoded sequences, we introduced the symmetric internal loops of double stranded DNA, and which were used to recognize similar or different patterns. Through a series of training processes which is simply storing the given training data in different microtubes in each class of hypernetwork, we observed that the accuracy of sentence classification tasks increased on the corpus of TV show dialogue and our molecular learning was able to generalize the training sentences. In the third year, we demonstrated the use of molecular dynamic hypernetworks for multimodal visuo-linguistic concept learning from a long stream of video data. Motivated by the cognitive developmental process of children constructing the visually grounded concepts from multimodal stimuli (Meltzoff, 1990), we proposed a hierarchical model of automatically constructing visual-linguistic knowledge by dynamically learning concepts represented with vision and language from videos [8, 12, 15, 16, 22]. We developed a stochastic method for graph construction, i.e. a graph Monte Carlo algorithm, and our model learns the concepts by the algorithm while observing new videos, thus robustly tracing concept drift and continuously accumulating new conceptual knowledge. Using a series of approximately 200 episodes of educational cartoon videos we examined the emergence and evolution of the concept hierarchies as the video stories unfold. Through the experiment, we observed that the number of visual and linguistic nodes tends to increase, because the concepts continuously develop while observing the videos. Also, we presented a molecular computational model for human anagram solving to show the potential of application to high-level cognitive functions [5, 11, 13, 18, 21]. Our major contribution is to propose the molecular assembly model of cognitive memory and learning which can be used as a tool for simulating cognitive dynamics involved with multisensory cue integration, grounded concept learning, and interaction of vision and language. We believe that the bio-inspired human-level machine learning combined with molecular-computing implementation can offer an interesting, novel paradigm to address for flexible and reliable computing. We also expect that the cognitive memory architectures and their learning algorithms contribute to revolutionize the AI technology to be used in lifelong learning, self-organizing, sensorimotor systems. DISTRIBUTION A: Distribution approved for public release. [1 Year] The Dynamic Hypernetwork Models of Neural Populations Experiments: In the first year, we constructed a dynamic Bayesian inference framework and examined information-theoretic objective functions for lifelong learning [9]. In lifelong learning, training data are observed sequentially as learning unfolds and not kept for iterative reuse. The learning is proceeded in an online and incremental manner over an extended period in a changing environment. This requires incremental transfer of knowledge acquired from previous learning to future learning, which can be formulated as a Bayesian inference. We applied a sequential Bayesian framework for lifelong learning to build taxonomy of lifelong-learning paradigms, and examine information-theoretic objective functions for each paradigm (Figure 1). Figure 1. Lifelong learning with action-perception-learning cycle [9] Results and Discussion: We distinguished three paradigms of lifelong-learning: learning with passive and continual observations, learning with actions (but without reward feedbacks), and active learning with explicit rewards. For each of the paradigm we examined the objective functions of the lifelong learning styles: prediction errors and predictive information, empowerment which measures how much influence an agent has on its environment, and the","",""
130,"Andreas Holzinger, I. Jurisica","Knowledge Discovery and Data Mining in Biomedical Informatics: The Future Is in Integrative, Interactive Machine Learning Solutions",2014,"","","","",154,"2022-07-13 09:23:39","","10.1007/978-3-662-43968-5_1","","",,,,,130,16.25,65,2,8,"","",""
0,"Jianfei Yang, Xinyan Chen, Han Zou, Dazhuo Wang, Lihua Xie","AutoFi: Towards Automatic WiFi Human Sensing via Geometric Self-Supervised Learning",2022,"","","","",155,"2022-07-13 09:23:39","","10.48550/arXiv.2205.01629","","",,,,,0,0.00,0,5,1,"—WiFi sensing technology has shown superiority in smart homes among various sensors for its cost-effective and privacy-preserving merits. It is empowered by Channel State Information (CSI) extracted from WiFi signals and advanced machine learning models to analyze motion patterns in CSI. Many learning-based models have been proposed for kinds of applications, but they severely suffer from environmental dependency. Though domain adaptation methods have been proposed to tackle this issue, it is not practical to collect high- quality, well-segmented and balanced CSI samples in a new environment for adaptation algorithms, but randomly-captured CSI samples can be easily collected. In this paper, we ﬁrstly explore how to learn a robust model from these low-quality CSI samples, and propose AutoFi, an automatic WiFi sensing model based on a novel geometric self-supervised learning algorithm. The AutoFi fully utilizes unlabeled low-quality CSI samples that are captured randomly, and then transfers the knowledge to speciﬁc tasks deﬁned by users, which is the ﬁrst work to achieve cross-task transfer in WiFi sensing. The AutoFi is implemented on a pair of Atheros WiFi APs for evaluation. The AutoFi transfers knowledge from randomly collected CSI samples into human gait recognition and achieves state-of-the-art performance. Furthermore, we simulate cross-task transfer using public datasets to further demonstrate its capacity for cross-task learning. For the UT-HAR and Widar datasets, the AutoFi achieves satisfactory results on activity recognition and gesture recognition without any prior training. We believe that the AutoFi takes a huge step toward automatic WiFi sensing without any developer engagement while overcoming the cross-site issue.","",""
29,"Violeta Mirchevska, M. Luštrek, M. Gams","Combining domain knowledge and machine learning for robust fall detection",2014,"","","","",156,"2022-07-13 09:23:39","","10.1111/exsy.12019","","",,,,,29,3.63,10,3,8,"This paper presents a method for combining domain knowledge and machine learning (CDKML) for classifier generation and online adaptation. The method exploits advantages in domain knowledge and machine learning as complementary information sources. Whereas machine learning may discover patterns in interest domains that are too subtle for humans to detect, domain knowledge may contain information on a domain not present in the available domain dataset. CDKML has three steps. First, prior domain knowledge is enriched with relevant patterns obtained by machine learning to create an initial classifier. Second, genetic algorithms refine the classifier. Third, the classifier is adapted online on the basis of user feedback using the Markov decision process. CDKML was applied in fall detection. Tests showed that the classifiers developed by CDKML have better performance than machine‐learning classifiers generated on a training dataset that does not adequately represent all real‐life cases of the learned concept. The accuracy of the initial classifier was 10 percentage points higher than the best machine‐learning classifier and the refinement added 3 percentage points. The online adaptation improved the accuracy of the refined classifier by an additional 15 percentage points.","",""
1,"Donggyu Lee, Hyeongmin Park, Taesup Moon, Youngwook Kim","Continual Learning of Micro-Doppler Signature-Based Human Activity Classification",2021,"","","","",157,"2022-07-13 09:23:39","","10.1109/LGRS.2020.3046015","","",,,,,1,1.00,0,4,1,"Human activity classification based on micro-Doppler signatures measured by radar recently has been successfully applied in diverse applications due to the improvement of machine learning methods, e.g., deep convolutional neural networks (DCNNs). Despite the success, those methods encounter a common practical problem when all the radar data are not readily available before training a model but sequentially arrive as the learning continues, e.g., during surveillance or search-and-rescue operations. That is, when DCNN is naively utilized in such settings, it is well-known that catastrophic forgetting of past learned tasks occurs; hence, more robust continual learning methods should be developed. To that end, we apply several state-of-the-art methods for two practical continual learning scenarios in activity classification, i.e., when the data for a subject and an activity class arrive incrementally, respectively, and compare the competitiveness of those methods. To the best of our knowledge, this is the first comparative study of continual learning methods for the classification based on micro-Doppler signatures—we find that exemplar memory-based methods particularly become very effective for both scenarios, not only for the performance but also for the memory usage.","",""
376,"Rui Zhao, Ruqiang Yan, Jinjiang Wang, K. Mao","Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks",2017,"","","","",158,"2022-07-13 09:23:39","","10.3390/s17020273","","",,,,,376,75.20,94,4,5,"In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","",""
2,"V. Broughton","The Respective Roles of Intellectual Creativity and Automation in Representing Diversity: Human and Machine Generated Bias",2019,"","","","",159,"2022-07-13 09:23:39","","10.5771/0943-7444-2019-8-596","","",,,,,2,0.67,2,1,3,"The paper traces the development of the discussion around ethical issues in artificial intelligence, and considers the way in which humans have affected the knowledge bases used in machine learning. The phenomenon of bias or discrimination in machine ethics is seen as inherited from humans, either through the use of biased data or through the semantics inherent in intellectually-built tools sourced by intelligent agents. The kind of biases observed in AI are compared with those identified in the field of knowledge organization, using religious adherents as an example of a community potentially marginalized by bias. A practical demonstration is given of apparent religious prejudice inherited from source material in a large database deployed widely in computational linguistics and automatic indexing. Methods to address the problem of bias are discussed, including the modelling of the moral process on neuroscientific understanding of brain function. The question is posed whether it is possible to model religious belief in a similar way, so that robots of the future may have both an ethical and a religious sense and themselves address the problem of prejudice.","",""
1,"I. Haq, Z. Khan, Arshad Ahmad, B. Hayat, Asif Khan, Yeeun Lee, Ki-Il Kim","Evaluating and Enhancing the Robustness of Sustainable Neural Relationship Classifiers Using Query-Efficient Black-Box Adversarial Attacks",2021,"","","","",160,"2022-07-13 09:23:39","","10.3390/SU13115892","","",,,,,1,1.00,0,7,1,"Neural relation extraction (NRE) models are the backbone of various machine learning tasks, including knowledge base enrichment, information extraction, and document summarization. Despite the vast popularity of these models, their vulnerabilities remain unknown; this is of high concern given their growing use in security-sensitive applications such as question answering and machine translation in the aspects of sustainability. In this study, we demonstrate that NRE models are inherently vulnerable to adversarially crafted text that contains imperceptible modifications of the original but can mislead the target NRE model. Specifically, we propose a novel sustainable term frequency-inverse document frequency (TFIDF) based black-box adversarial attack to evaluate the robustness of state-of-the-art CNN, CGN, LSTM, and BERT-based models on two benchmark RE datasets. Compared with white-box adversarial attacks, black-box attacks impose further constraints on the query budget; thus, efficient black-box attacks remain an open problem. By applying TFIDF to the correctly classified sentences of each class label in the test set, the proposed query-efficient method achieves a reduction of up to 70% in the number of queries to the target model for identifying important text items. Based on these items, we design both character- and word-level perturbations to generate adversarial examples. The proposed attack successfully reduces the accuracy of six representative models from an average F1 score of 80% to below 20%. The generated adversarial examples were evaluated by humans and are considered semantically similar. Moreover, we discuss defense strategies that mitigate such attacks, and the potential countermeasures that could be deployed in order to improve sustainability of the proposed scheme.","",""
0,"","Machine Learning From Archives Gauquelin",2020,"","","","",161,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,0,2,"We apply machine learning methods to the data from Archives Gauquelin in an attempt to build a binary classifier able to distinguish between outstanding scientists and sports champions using only astronomical factors derived from their natal data. We apply a special splitting into training, validation and testing sets, and a set of three combined features, each of which combines dozens of elementary astronomical features. Our null hypothesis is that accuracy on Testing sets must be 0.5 if the Training sets contain the same number of group A and group B representatives born on each year, that is, if yearly frequencies are equal. Our external Testing sets contain only persons born later than those in Archives Gauquelin. Logistic Regression is our primary method, and Random Forest an alternative. All data and implementations of our algorithms are available from a public repository on GitLab.com. Introduction Archives Gauquelin (AG) contain birth data of outstanding professionals, including Sports Champions (SC), Scientists And Medical Doctors (SMD), and other groups, for example, Mental Patients and The Hereditary Experiment Subjects. SMD is the biggest professional group. Data were collected by Françoise and Michel Gauquelin in 1949-1991, they used the data to investigate and report their findings, the most known of which is the so-called Mars Effect: a statistically significant number of sports champions were born just after planet Mars rises or culminates, relative to the horizon at time and place of birth. We use data from AG as published on the C.U.R.A. web site[1], but we do not use astronomical factors that depend upon the daily rotation of the Earth. Trying to build a classifier for professionals with only astronomical factors as features is certainly a questionable direction. First of all, the common knowledge is that all prior research “failed to find effects commensurate with astrological claims”[2]. If classifier could label better than a random number generator, that would support the main astrological claim. Also, why professionals? If there was any correlation between astronomical factors and something about behavior of humans who were not aware of those factors, then most likely the correlation would be stronger between astronomical factors and something psychological, like personality traits, or biological/physiological, like gene expression patterns or microbiota activity patterns. Furthermore, lets assume there may be correlations between astronomical factors at the time of birth, and something physiological/psychological, and then correlations between the latter and professions in which people succeed. In this case, correlations with professions would probably vary significantly over time: in the 19 century a noticeably different set of personality traits would work best for becoming a sports champion, or an outstanding scientist, than the set of traits that works best in the 21 century. We decided to try building a classifier using data from Archives Gauquelin because AG are easily available online, and have been available for many years, and because a number of relatively recent studies[4][5][6][7] suggest that there may be a lot more to learn about physical processes in the Solar System and their impact, especially about the imperceptible impact, on humans and other species. We understand that overall a genome that is able to utilize both A and B, two features of the environment, can become better adapted to environment than a genome able to utilize only A but not B, or vice versa, only B but not A. Fetching data and converting them to MLAG format Is all done completely automatically using the Python scripts we provide[8]. Plots are there as well. Features Our null hypothesis is as follows: classification accuracy on the Testing set must be close to 0.5 if the Training set contains the same number of group A and group B subjects born on each year. That is, if yearly frequencies are equal. We try to prevent classifier from learning the yearly frequencies using three different methods. First, with a special splitting into Training, Validation, and Testing sets. In every Training set the yearly frequencies are equal. Second, we were building a classifier able to distinguish between outstanding scientists and sports champions, but during the Parameter Optimization process we used seven other pairs of groups in addition to the target pair (Scientists And Medical Doctors, Sports Champions). Third, we avoid using astronomical features that (supposedly) help classifier to learn the yearly frequencies: features that last for months or even years. That is, features with only Jupiter and planets beyond it, with no faster moving bodies: Moon, Sun and planets closer to Sun than Jupiter. We also do not use astronomical factors that depend upon the daily rotation of the Earth (and thus depend on time of birth) including factors of the class “planets in twelve astrological houses”. This makes our research less dependent of the possible bias in AG, and this also makes our classifier more robust to unknown or imprecise time of birth. Our three combined features correspond to the three nearest cosmic neighbors of Earth, namely Moon, Venus, and Mars. These are also the first three columns in the summary table with findings of Gauquelins and the researchers who tried to replicate and further investigate their findings [3]. Each of the three features is a weighted sum of elementary features from two classes of factors being used in Western astrology since ancient times: astrological aspects, and planets in twelve Zodiac signs (our only truly innovative components are the secondary elements of celestial bodies, with aspect weights depending on both the primary and secondary elements). For example, the value of the “Mars” feature is a sum of a parameter corresponding to Mars’ position in one of the twelve 30-degree sectors (ecliptic longitude quantized to 12 values), and parameters originating from special angles, called astrological aspects, between Mars and the seven major celestial bodies. Sun, Moon, and planets up to Uranus, excluding Neptune, Pluto and dwarfs: Sun, Moon, Mercury, Venus, Jupiter, Saturn, Uranus The sets of bodies and aspects are the same for the other two features, “Venus” and “Moon” (with Mars in place of Venus or Moon in the set of bodies), but 28 other parameters are different. The total number of parameters is 122, with 28*3 of them impacting just one of the three features, and the remaining 38 parameters having an impact on all three features. 30 of the 38 are the weights of aspects and allowances of aspects, that is, half-widths of sectors, also known as orbs in Western astrology: for example, “body is in an opposition with Mars, with a 4 degree orb” means the angle is anywhere between 176 and 184 degrees between (the ecliptic longitudes of) the body and Mars. In this example, width of sector is 8 degrees, and orb is 4 degrees. Another example, the parameters corresponding to the Zodiac sign at which Moon was at the moment are as follows: [0, 3, 2, 1,-1, 0, 2, 2, 1,-1, 2,-8]. That is, +3*w if ecliptic longitude of Moon, expressed in degrees, was between 30 and 60, and -8*w if it was between 330 and 360, where w is the Moon’s Zodiac multiplier parameter, w=5.5. As can be seen from this example, some of the 122 parameters are redundant: here we could have 12 instead of 13 parameters. Training, Validation and Testing sets For each pair (group A, group B) we extract a Testing set using the following method. For every year Y, we look at the numbers of persons born on that year, NA[Y] and NB[Y]. If NA[Y]=0, then all of the persons from group B born in year Y are appended to the Testing set, and vice versa, if NB[Y]=0 then all NA[Y] persons from group A born in year Y are appended to the Testing set. The joint Training+Validation set is the other outcome of this procedure. Then during the Parameter Optimization (PO) process, as well as after it is complete, during the Testing set evaluation process, every trial is as follows. We repeat N times: split the Training+Validation set into a Training set and a Validation set, using a simple method described in details below, then train a classifier with the Training set, and evaluate it on the Validation set, and report the Training set accuracy and the Validation set accuracy. Note that PO process takes weeks on a modern laptop using the Logistic Regression implementation from the Scikit-learn machine learning library[12]. We use N=3000 in every trial for each pair (group A, group B), because splitting into Training and Validation sets is done with a pseudo-random data generator: for every year Y, if NA[Y] > NB[Y] then we select NA[Y]-NB[Y] persons from group A at random, and push them into Validation set. If NB[Y] > NA[Y] then we select NB[Y]-NA[Y] persons from group B at random, and these are appended to the Validation set. In either case, the remaining M*2 persons, where M = min(NA[Y], NB[Y]), are pushed into the Training set. Thus, the yearly frequencies in the Training set are equal. The outcome of every trial is a pair of numbers: the average Training set accuracy, ATraSA, and the average Validation set accuracy, AVaSA. The median Validation set accuracy is also reported, but it is not used in the Parameter Optimization process. The average Testing set accuracy ATeSA is also an arithmetic mean from 3000 iterations, calculated exactly like AVaSA: for each splitting into Training and Validation sets, evaluate on the Testing set, then take an arithmetic mean from 3000 iterations. Testing sets are ignored during the PO process. Pairs of groups and the parameter optimization target We built seven groups from AG data: SC: Sports Champions SMD: Scientists, Medical Doctors Military Men Merged 6: all actors, journalists, musicians, painters, politicians, writers from AG Heredity Vol. B Heredity Vol. E2 Mental Patients During the PO process each PO iter","",""
51,"Zhiyuan Chen, B. Liu","Lifelong Machine Learning, Second Edition",2018,"","","","",162,"2022-07-13 09:23:39","","10.2200/S00832ED1V01Y201802AIM037","","",,,,,51,12.75,26,2,4,"Lifelong Machine Learning, Second Edition is an introduction to an advanced machine learning paradigm that continuously learns by accumulating past knowledge that it then uses in future learning and problem solving. In contrast, the current dominant machine learning paradigm learns in isolation: given a training dataset, it runs a machine learning algorithm on the dataset to produce a model that is then used in its intended application. It makes no attempt to retain the learned knowledge and use it in subsequent learning. Unlike this isolated system, humans learn effectively with only a few examples precisely because our learning is very knowledge-driven: the knowledge learned in the past helps us learn new things with little data or effort. Lifelong learning aims to emulate this capability, because without it, an AI system cannot be considered truly intelligent. Research in lifelong learning has developed significantly in the relatively short time since the first edition of this book was published. The purpose of this second edition is to expand the definition of lifelong learning, update the content of several chapters, and add a new chapter about continual learning in deep neural networks—which has been actively researched over the past two or three years. A few chapters have also been reorganized to make each of them more coherent for the reader. Moreover, the authors want to propose a unified framework for the research area. Currently, there are several research topics in machine learning that are closely related to lifelong learning—most notably, multi-task learning, transfer learning, and meta-learning—because they also employ the idea of knowledge sharing and transfer. This book brings all these topics under one roof and discusses their similarities and differences. Its goal is to introduce this emerging machine learning paradigm and present a comprehensive survey and review of the important research results and latest ideas in the area. This book is thus suitable for students, researchers, and practitioners who are interested in machine learning, data mining, natural language processing, or pattern recognition. Lecturers can readily use the book for courses in any of these related fields.","",""
41,"Xiaoxiao Wang, X. Liang, Zhoufan Jiang, B. A. Nguchu, Yawen Zhou, Yanming Wang, Huijuan Wang, Yu Li, Yuying Zhu, Feng Wu, Jia-Hong Gao, B. Qiu","Decoding and mapping task states of the human brain via deep learning",2018,"","","","",163,"2022-07-13 09:23:39","","10.1002/hbm.24891","","",,,,,41,10.25,4,12,4,"Support vector machine (SVM)‐based multivariate pattern analysis (MVPA) has delivered promising performance in decoding specific task states based on functional magnetic resonance imaging (fMRI) of the human brain. Conventionally, the SVM‐MVPA requires careful feature selection/extraction according to expert knowledge. In this study, we propose a deep neural network (DNN) for directly decoding multiple brain task states from fMRI signals of the brain without any burden for feature handcrafts. We trained and tested the DNN classifier using task fMRI data from the Human Connectome Project's S1200 dataset (N = 1,034). In tests to verify its performance, the proposed classification method identified seven tasks with an average accuracy of 93.7%. We also showed the general applicability of the DNN for transfer learning to small datasets (N = 43), a situation encountered in typical neuroscience research. The proposed method achieved an average accuracy of 89.0 and 94.7% on a working memory task and a motor classification task, respectively, higher than the accuracy of 69.2 and 68.6% obtained by the SVM‐MVPA. A network visualization analysis showed that the DNN automatically detected features from areas of the brain related to each task. Without incurring the burden of handcrafting the features, the proposed deep decoding method can classify brain task states highly accurately, and is a powerful tool for fMRI researchers.","",""
0,"Mamta A. Rajnayak, Snigdha Moitra, Charu Nahata","Traditional vs. Machine Learning Techniques: Customer Propensity",2017,"","","","",164,"2022-07-13 09:23:39","","10.1007/978-3-319-54430-4_63","","",,,,,0,0.00,0,3,5,"","",""
0,"D. Ruta, Ling Cen, E. Damiani","Summarization-Guided Greedy Optimization of Machine Learning Model",2017,"","","","",165,"2022-07-13 09:23:39","","10.1007/978-3-319-62416-7_22","","",,,,,0,0.00,0,3,5,"","",""
44,"Keze Wang, Liang Lin, Chenhan Jiang, C. Qian, Pengxu Wei","3D Human Pose Machines with Self-Supervised Learning",2019,"","","","",166,"2022-07-13 09:23:39","","10.1109/TPAMI.2019.2892452","","",,,,,44,14.67,9,5,3,"Driven by recent computer vision and robotic applications, recovering 3D human poses has become increasingly important and attracted growing interests. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate priors /constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images. Specifically, the proposed mechanism involves two dual learning tasks, i.e., the 2D-to-3D pose transformation and 3D-to-2D pose projection, to serve as a bridge between 3D and 2D human poses in a type of “free” self-supervision for accurate 3D human pose estimation. The 2D-to-3D pose implies to sequentially regress intermediate 3D poses by transforming the pose representation from the 2D domain to the 3D domain under the sequence-dependent temporal context, while the 3D-to-2D pose projection contributes to refining the intermediate 3D poses by maintaining geometric consistency between the 2D projections of 3D poses and the estimated 2D poses. Therefore, these two dual learning tasks enable our model to adaptively learn from 3D human pose data and external large-scale 2D human pose data. We further apply our self-supervised correction mechanism to develop a 3D human pose machine, which jointly integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge. Extensive evaluations on the Human3.6M and HumanEva-I benchmarks demonstrate the superior performance and efficiency of our framework over all the compared competing methods.","",""
2,"Xipeng Chen, Pengxu Wei, Liang Lin","Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras",2021,"","","","",167,"2022-07-13 09:23:39","","","","",,,,,2,2.00,1,3,1,"Without prohibitive and laborious 3D annotations, weaklysupervised 3D human pose methods mainly employ the model regularization with geometric projection consistency or geometry estimation from multi-view images. Nevertheless, those approaches explicitly need known parameters of calibrated cameras, exhibiting a limited model generalization in various realistic scenarios. To mitigate this issue, in this paper, we propose a Deductive Weakly-Supervised Learning (DWSL) for 3D human pose machine. Our DWSL firstly learns latent representations on depth and camera pose for 3D pose reconstruction. Since weak supervision usually causes ill-conditioned learning or inferior estimation, our DWSL introduces deductive reasoning to make an inference for human pose from a view to another and develops a reconstruction loss to demonstrate what the model learns and infers is reliable. This learning by deduction strategy employs the view-transform demonstration and structural rules derived from depth, geometry and angle constraints, which improves the reliability of the model training with weak supervision. On three 3D human pose benchmarks, we conduct extensive experiments to evaluate our proposed method, which achieves superior performance in comparison with state-of-the-art weak-supervised methods. Particularly, our model shows an appealing potential for learning from 2D data captured in dynamic outdoor scenes, which demonstrates promising robustness and generalization in realistic scenarios. Our code is publicly available at https://github.com/XipengChen/DWSL-3D-pose. Introduction 3D human pose estimation is a fundamental problem in computer vision for many applications, such as human-robot interaction, virtual reality, and action recognition, etc. However, it is greatly bottlenecked by the availability of abundant 3D annotated data, since 3D images are usually subject to specific conditions with constrained laboratory environments and thus have limited pose variations and simple backgrounds, and particularly, accurate 3D annotation demands prohibitively expensive cost. Accordingly, they cause the poor generalization of 3D pose models to the cases in the wild. Without any 3D pose annotation, many researchers resort to Weakly-Supervised Learning (WSL) methods (Kocabas, *Pengxu Wei is the corresponding author. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Karagoz, and Akbas 2019; Rhodin et al. 2018; Rhodin, Salzmann, and Fua 2018; Chen et al. 2019a), which inherit the benefits of rich annotation and diversity of 2D pose datasets. They usually utilize annotated 2D pose images by lifting 2D poses to the 3D space together with geometric consistency constraints and train models without 3D pose labels for 3D human pose estimation. (Chen et al. 2019a) proposes a method to learn from single-view self-supervision, but requires a very large amount of diverse 2D human poses. (Kocabas, Karagoz, and Akbas 2019; Rhodin et al. 2018; Rhodin, Salzmann, and Fua 2018) propose a multi-view consistency from images which are taken for the same person from different viewpoints. Nevertheless, these methods have to obtain well-defined rigid transformation from annotations (Rhodin, Salzmann, and Fua 2018) or predictions from off-the-shelf methods (Kocabas, Karagoz, and Akbas 2019; Rhodin et al. 2018). Meanwhile, they employ the view synthesis strategy to produce 3D poses which supervise the training of 3D pose detectors. This casts the weakly-supervised learning problem of 3D pose estimation with only 2D annotation into a conventional fully-supervised learning task with synchronized information from multi-view images (Chen et al. 2019a). Essentially, fully supervised models are trained inductively in a data-driven manner, which greatly depends on abundant observations or samples with labels. Nevertheless, following the same spirit, with weak supervision or without annotation, the training of models suffers from a large knowledge of uncertainty or controversial ambiguity, which would cause ill-conditioned learning or inferior estimation. To mitigate this problem, we propose Deductive WeaklySupervised Learning (DWSL) for 3D human pose estimation. Rather than following the spirit of data-driven inductive learning in most existing methods, the proposed paradigm of learning by deduction utilizes deduction with view-transform demonstration and structural rules to infer the plausible 2D pose from another view and develop a reconstruction loss for training. This is regarded as a self-demonstration with deductive reasoning from one view to another view, namely, deduction with view-transform demonstration, and the derived reconstruction loss provides a checkpoint for the current weakly-supervised learning. At the same time, we also introduce structural rules to further promote the learning by deduction, which would ease the model training and reduce the searching space of parameters. We conduct experiments The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","",""
0,"N. Katanić, K. Fertalj","Towards Physical Intrusion Detection Method Based on Machine Learning and Context-Aware Activity Recognition in Real-Time",2017,"","","","",168,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,2,5,"Sensor-based human activity recognition is getting increasingly popular in various applications. Most of the related work within dense-sensing based approaches assume that large number of different multimodal sensors are placed on the objects in the environment (which is rarely the case in today’s real life home environments), that sensor data is not processed in real-time and that activity to be classified is always performed within the same context, thus perform poorly when tested in real life scenarios. In this paper we report on the current status and future steps towards a generic context-aware method for human activity recognition, based on a real-time raw sensor data stream coming from a minimum number of sensors placed in the environment. We propose a hybrid method based on state-of-the-art data-driven and knowledge-driven approaches. Proposed method is being developed and will be validated on the example of the application for robust physical intrusion detection on home doors in real life environment. Key-Words: activity recognition, machine learning, context-aware, real-time, dense-sensing, accelerometer,","",""
29,"T. Ishikawa, A. Hayashi, Shingo Nagamatsu, Y. Kyutoku, I. Dan, T. Wada, K. Oku, Y. Saeki, T. Uto, T. Tanabata, S. Isobe, N. Kochi","CLASSIFICATION OF STRAWBERRY FRUIT SHAPE BY MACHINE LEARNING",2018,"","","","",169,"2022-07-13 09:23:39","","10.5194/ISPRS-ARCHIVES-XLII-2-463-2018","","",,,,,29,7.25,3,12,4,"Abstract. Shape is one of the most important traits of agricultural products due to its relationships with the quality, quantity, and value of the products. For strawberries, the nine types of fruit shape were defined and classified by humans based on the sampler patterns of the nine types. In this study, we tested the classification of strawberry shapes by machine learning in order to increase the accuracy of the classification, and we introduce the concept of computerization into this field. Four types of descriptors were extracted from the digital images of strawberries: (1) the Measured Values (MVs) including the length of the contour line, the area, the fruit length and width, and the fruit width/length ratio; (2) the Ellipse Similarity Index (ESI); (3) Elliptic Fourier Descriptors (EFDs), and (4) Chain Code Subtraction (CCS). We used these descriptors for the classification test along with the random forest approach, and eight of the nine shape types were classified with combinations of MVs + CCS + EFDs. CCS is a descriptor that adds human knowledge to the chain codes, and it showed higher robustness in classification than the other descriptors. Our results suggest machine learning's high ability to classify fruit shapes accurately. We will attempt to increase the classification accuracy and apply the machine learning methods to other plant species. ","",""
19,"Chi Ian Tang, I. Perez-Pozuelo, Dimitris Spathis, S. Brage, N. Wareham, C. Mascolo","SelfHAR: Improving Human Activity Recognition through Self-training with Unlabeled Data",2021,"","","","",170,"2022-07-13 09:23:39","","10.1145/3448112","","",,,,,19,19.00,3,6,1,"Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models. In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input. We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.","",""
13,"Cong T. Nguyen, Nguyen Van Huynh, Nam H. Chu, Y. Saputra, D. Hoang, Diep N. Nguyen, Quoc-Viet Pham, D. Niyato, E. Dutkiewicz, W. Hwang","Transfer Learning for Future Wireless Networks: A Comprehensive Survey",2021,"","","","",171,"2022-07-13 09:23:39","","","","",,,,,13,13.00,1,10,1,"With outstanding features, Machine Learning (ML) has become the backbone of numerous applications in wireless networks. However, the conventional ML approaches face many challenges in practical implementation, such as the lack of labeled data, the constantly changing wireless environments, the long training process, and the limited capacity of wireless devices. These challenges, if not addressed, can impede the effectiveness and applicability of ML in wireless networks. To address these problems, Transfer Learning (TL) has recently emerged to be a promising solution. The core idea of TL is to leverage and synthesize distilled knowledge from similar tasks as well as from valuable experiences accumulated from the past to facilitate the learning of new problems. Doing so, TL techniques can reduce the dependence on labeled data, improve the learning speed, and enhance the ML methods’ robustness to different wireless environments. This article aims to provide a comprehensive survey on applications of TL in wireless networks. Particularly, we first provide an overview of TL including formal definitions, classification, and various types of TL techniques. We then discuss diverse TL approaches proposed to address emerging issues in wireless networks. The issues include spectrum management, localization, signal recognition, security, human activity recognition and caching, which are all important to nextgeneration networks such as 5G and beyond. Finally, we highlight important challenges, open issues, and future research directions of TL in future wireless networks.","",""
150,"H. Rahmani, A. Mian, M. Shah","Learning a Deep Model for Human Action Recognition from Novel Viewpoints",2016,"","","","",172,"2022-07-13 09:23:39","","10.1109/TPAMI.2017.2691768","","",,,,,150,25.00,50,3,6,"Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a set of non-linear transformations that connects the views. The R-NKTM is learned from 2D projections of dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.","",""
17,"Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, I. Kweon","Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications",2019,"","","","",173,"2022-07-13 09:23:39","","10.1109/TPAMI.2019.2952095","","",,,,,17,5.67,3,5,3,"Visual events are usually accompanied by sounds in our daily lives. However, can the machines learn to correlate the visual scene and sound, as well as localize the sound source only by observing them like humans? To investigate its empirical learnability, in this work we first present a novel unsupervised algorithm to address the problem of localizing sound sources in visual scenes. In order to achieve this goal, a two-stream network structure which handles each modality with attention mechanism is developed for sound source localization. The network naturally reveals the localized response in the scene without human annotation. In addition, a new sound source dataset is developed for performance evaluation. Nevertheless, our empirical evaluation shows that the unsupervised method generates false conclusions in some cases. Thereby, we show that this false conclusion cannot be fixed without human prior knowledge due to the well-known correlation and causality mismatch misconception. To fix this issue, we extend our network to the supervised and semi-supervised network settings via a simple modification due to the general architecture of our two-stream network. We show that the false conclusions can be effectively corrected even with a small amount of supervision, i.e., semi-supervised setup. Furthermore, we present the versatility of the learned audio and visual embeddings on the cross-modal content alignment and we extend this proposed algorithm to a new application, sound saliency based automatic camera view panning in 360 degree videos.","",""
9,"I. Nafea","Machine Learning in Educational Technology",2018,"","","","",174,"2022-07-13 09:23:39","","10.5772/INTECHOPEN.72906","","",,,,,9,2.25,9,1,4,"Machine learning is a subset of artificial intelligence (AI) that helps computers or teaching machines learn from all previous data and make intelligent decisions. The machine-learning framework entails capturing and maintaining a rich set of information and transforming it into a structured knowledge base for different uses in various fields. In the field of education, teachers can save time in their non-classroom activities by adopting machine learning. For example, teachers can use virtual assistants who work remotely from the home for their students. This kind of assistance helps to enhance students’ learning experience and can improve progression and student achievement. Machine learning fosters personalized learning in the context of disseminating education. Advances in AI are enabling teachers to gain a better understanding of how their students are progressing with learning. This enables teachers to create customized curriculum that suits the specific needs of the learners. When employed in the context of education, AI can foster intelligence moderation. It is through this platform that the analysis of data by human tutors and moderators is made possible.","",""
16,"W. MacInnes, Stephanie Santosa, William Wright","Visual Classification: Expert Knowledge Guides Machine Learning",2010,"","","","",175,"2022-07-13 09:23:39","","10.1109/MCG.2010.18","","",,,,,16,1.33,5,3,12,"Humans use intuition and experience to classify everything they perceive, but only if the distinguishing patterns are visible. Machine-learning algorithms can learn class information from data sets, but the created classes' meaning isn't always clear. A proposed mixed-initiative approach combines intuitive visualizations with machine learning to tap into the strengths of human and machine classification. The use of visualizations in an expert-guided clustering technique allows the display of complex data sets in a way that allows human input into machine clustering. Test participants successfully employed this technique to classify analytic activities using behavioral observations of a creative-analysis task. The results demonstrate how visualization of the machine-learned classification can help users create more robust and intuitive categories.","",""
11,"P. Mignone, Gianvito Pio, S. Džeroski, Michelangelo Ceci","Multi-task learning for the simultaneous reconstruction of the human and mouse gene regulatory networks",2020,"","","","",176,"2022-07-13 09:23:39","","10.1038/s41598-020-78033-7","","",,,,,11,5.50,3,4,2,"","",""
18,"Prachi Agrawal, T. Ganesh, A. W. Mohamed","A novel binary gaining-sharing knowledge-based optimization algorithm for feature selection",2020,"","","","",177,"2022-07-13 09:23:39","","10.1007/s00521-020-05375-8","","",,,,,18,9.00,6,3,2,"","",""
524,"S. Raschka","Python Machine Learning",2015,"","","","",178,"2022-07-13 09:23:39","","","","",,,,,524,74.86,524,1,7,"Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk and answer tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource.What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Keras and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success.Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization.Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.","",""
0,"Yen-Hsiang Wang, Chih-Yang Lin, Tipajin Thaipisutikul, T. Shih","Single-Head Lifelong Learning Based on Distilling Knowledge",2022,"","","","",179,"2022-07-13 09:23:39","","10.1109/access.2022.3155451","","",,,,,0,0.00,0,4,1,"Within the machine learning field, the main purpose of lifelong learning, also known as continuous learning, is to enable neural networks to learn continuously, as humans do. Lifelong learning accumulates the knowledge learned from previous tasks and transfers it to support the neural network in future tasks. This technique not only avoids the catastrophic forgetting problem with previous tasks when training new tasks, but also makes the model more robust with the temporal evolution. Motivated by the recent intervention of the lifelong learning technique, this paper presents a novel feature-based knowledge distillation method that differs from the existing methods of knowledge distillation in lifelong learning. Specifically, our proposed method utilizes the features from intermediate layers and compresses them in a unique way that involves global average pooling and fully connected layers. The authors then use the output of this branch network to deliver information from previous tasks to the model in the future. Extensive experiments show that our proposed model consistency outperforms the state-of-the-art baselines with the accuracy metric by at least two percent improvement under different experimental settings.","",""
1,"Gianni Barlacchi","Machine Learning Methods for Urban Computing",2019,"","","","",180,"2022-07-13 09:23:39","","","","",,,,,1,0.33,1,1,3,"Machine Learning Methods for Urban Computing World population is increasingly moving from rural areas to urban centers, making large cities densely populated. In urban areas, there is greater access to work, a wide variety of options for education and training, ease of transport and the abundance of attractive places within a few kilometers. Across huge cities, people tend to move more and have to do it faster than in the past. On the other hand, heavy traffic (e.g., traffic jams), overbuilding and changes in the urban lifestyle can cause several new problems such as noise, atmospheric pollution (i.e., smog) and severe traffic congestions. However, the rise of novel data sources and machine learning techniques can help to tackle such problems and improve the quality of life of citizens. Indeed, in a smart city environment, the huge amount of data generated daily can be captured by sensors, actuators, and mobile devices. It goes without saying that using such data opens the door to several applications, including forecasting of urban displacements, land use classification and event detection in an urban environment. Motived by these opportunities, Urban Computing (UC) leverages on heterogeneous data sources and applies machine learning techniques to tackle these big challenges that modern cities are facing. In this perspective, one of the core questions when designing UC systems is how to enable models to learn from different urban data sources and thus how to represent urban spaces. The mainstream approach is to represent input objects as feature vectors that encode several aspects of the urban environment such as the presence of people, density of urban activities, and mobility flows. However, this tedious approach of manually feature engineering can be extremely complex, time-consuming and domain-specific dependent. Additionally, it can become even more complex when aggregating multiple geographical data sources such as point-of- interests, administrative boundaries, and mobility data. A valid alternative to feature-based methods is using kernels, which are non-linear functions that map input examples into some high dimensional space allowing for learning more powerful discriminative decision functions. Given a representation of the input object, kernels map it into some high-dimensional space where implicitly a large number of features are generated, allowing for learning robust discriminative functions. In this way the effort for the feature engineering pro- cess can be greatly reduced. Machine Learning Methods for Urban Computing  Kernel methods have been widely applied in Natural Language Processing on tasks such as question answering, semantic role labeling and even for solving linguistic games. Taking inspiration from these successful cases, in this thesis we adapt kernel learning for solving novel tasks in UC. First, we focus on the problem of aggregating multiple urban data sources to provide datasets that fuse knowledge from a wide variety of data sources. Next, we focus on the problem of designing an input structure that is representative of urban space. In particular, we propose to model urban areas with tree structures that are fed to tree kernel functions for automatically generate expressive features. We propose several urban space representations that demonstrated to be very effecting in solving novel urban computing tasks such as land use classification and next location prediction in human mobility. Then, by applying a mining algorithm we enabled the interpretation of urban zones, providing help in the difficult problem of understanding the high-level urban characteristics of a city. In fact, our mined substructures provide help in identifying the different urban nature of cities. Finally, we explore the application of machine learning models to novel urban data sources by solving solve innovative tasks such as predicting the future presence of influenza-like symptoms looking at the people’s mobility behaviors.","",""
0,"Hiram Ponce","Artificial Hydrocarbon Networks: Chemical Nature Inspiration in Machine Learning",2019,"","","","",181,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,3,"Inspiration in nature has been widely explored, from macro to micro-scale. When looking into chemical phenomena, stability and organization are two properties that emerge. Recently, artificial hydrocarbon networks (AHN), a supervised learning method inspired in the inner structures and mechanisms of chemical compounds, have been proposed by as a data-driven approach in artificial intelligence. AHN have been successfully applied in data-driven approaches, such as: regression and classification models, control systems, signal processing, and robotics. To do so, molecules –the basic units of information in AHN– play an important role in the stability, organization and interpretability of this method. Interpretability, saving computing resources, and predictability have been handled by AHN, as any other machine learning model. This short paper aims to highlight the challenges, issues and trends of artificial hydrocarbon networks as a data-driven method. Throughout this document, it presents a description of the main insights of AHN and the efforts to tackle interpretability and training acceleration. Potential applications and future trends on AHN are also discussed. Keywords– machine learning, supervised learning, artificial organic networks, modeling, learning task Introduction Recently, artificial hydrocarbon networks (AHN), a supervised learning method inspired in the inner structures and mechanisms of chemical compounds, have been proposed as a data-driven approach in artificial intelligence [1]. This algorithm, inspired by nature, loosely mimics stability and organization of molecules in order to build organized structures made of packages of information. AHN have proved to be efficient in predictive power when modeling a data-based problem. However, the organizational property has not been strongly analyzed. If this organization capability is conducted in AHN, the output response in data-driven models will reveal, at least in a partial view, the inner structure and functionality of the systems model. So, new ways in building and training AHN are required. Thus, this paper aims to discuss challenges and trends of AHN as a data-driven method, with emphasis on interpretability and training acceleration. This document lays the foundations on AHN for implementing new training algorithms and the way to reveal the chemical nature of data-driven problems. Key Concepts of Artificial Hydrocarbon Networks AHN method was firstly proposed by Ponce and Ponce [2] as an implementation of their more general technique namely artificial organic networks (AON) [1]. In a nutshell, the purpose of the AHN method is to package information, from a set of instances, in basic units known as molecules. These molecules – composed of hydrogen and carbon atoms– are described by nonlinear functions, and they can be related among them using chemical heuristics resulting in complex units of information so-called compounds. Moreover, a set of compounds can be combined together, linearly, producing mixtures. To this end, the mixture constitutes a model [1]. Thus, the inspiration in organic compounds to develop a machine learning method considers three facts observed from nature [3]: (i) stability as the property of compounds to maintain their geometric configurations; (ii) organization based on the ground-state principle aiming to preserve energy minimization within the compounds; and (iii) multi-functionality for promoting transfer learning. For training purposes, the method considers the simple AHN training algorithm [1] which is based on the gradient descent and the numerical solution of least squares estimates via QR-factorization. This training algorithm has reported well performance in predictive power for low-dimensional input spaces, and large training time for computing suitable parameters in the model [4]. Currently, new training methods have been proposed based on hierarchical training [3] or using stochastic-parallel metaheuristic optimization [4]. The later, accelerating training in more than 3,500 times the simple AHN training algorithm. Applications of Artificial Hydrocarbon Networks Literature reports many different applications of AHN. Those can be classified as follows: function approximation and modeling [1]; robust human activity recognition systems [5]; signal processing in denoising audio and face recognition [1,6]; online advertising [6]; intelligent control systems for robotics [1,7,8,11] and mechatronics [1,9,10]; bio/medical applications [5,6,12]; and, theoretical approaches such as hybrid fuzzy-molecular inference systems [8], interpretability of the model [12] and training algorithms [3,4]. Highlights of Artificial Hydrocarbon Networks In these years of AHN, this method has reached notable contributions, as those highlighted following: • Type-II fuzzy inference like behavior – AHN have proved to be significantly similar to type-II fuzzy inference systems, handling noise and allowing experts to tune fuzzy partitions/rules [8]. • Competitive as deep learning – In [5], AHN reported to be significantly similar in performance as deep neural networks (DNN). This suggests that AHN can be trained with less data and obtaining comparable results as DNN. • Interpretability of the model – In contrast to neural networks, AHN can be partially interpreted and converted into decision trees or rules-based models. This interpretability was implemented for medical diagnosis systems [12]. • Reinforcement learning for continuous domains – AHN have been applied for continuous reinforcement learning approaches, in both states and actions, typically found in robotics [11,13]. This approach has also revealed insights on using it as a transfer learning method. Challenges and Trends of Artificial Hydrocarbon Networks Until now, AHN have been successfully applied to different problems and different learning tasks. However, there still are challenges and issues about AHN that have to be faced. Trends in the development and application of AHN can be listed as follows: (i) new training algorithms for AHN are required for better computational performance mainly in time; (ii) the next big step in AHN is parallel computing that opens the possibility for parallel processing and big data analysis; (iii) since the predictive power of AHN is well accurate, it is important to study other functions as kernels and relationships in molecules aiming to perform other approximations; (iv) hybrid approaches with AHN might improve solutions to very complex problems, such as robotics, business intelligence, healthcare, and others; (v) few efforts in dynamic modeling using AHN are reported in literature, so it is important to focus some research in this direction; (vi) transfer learning using pre-defined molecules can be done, but more studies are necessary; (vii) interpretability of machine learning models and specifically of AHN models, are of great importance for knowledge extraction, thus automatic procedures for this task are required; and (viii) open-source coding of AHN is specially required for fast adoption, as the first efforts reported in [14]. Conclusions In this short paper, we summarized the challenges, issues and trends of AHN as a data-driven method. Despite this method was proposed recently, it has been successfully applied to many different intelligent systems. However, there is a need to explore new ways on how this method can be useful. Important issues like interpretability, training acceleration and open-source efforts are also required. Finally, we believe that this method can be added as another powerful tool for practitioners, scientists and researchers in artificial intelligence community.","",""
270,"A. Vellido, J. Martín-Guerrero, P. Lisboa","Making machine learning models interpretable",2012,"","","","",182,"2022-07-13 09:23:39","","","","",,,,,270,27.00,90,3,10,"Data of different levels of complexity and of ever growing diversity of characteristics are the raw materials that machine learning practitioners try to model using their wide palette of methods and tools. The obtained models are meant to be a synthetic representation of the available, observed data that captures some of their intrinsic regularities or patterns. Therefore, the use of machine learning techniques for data analysis can be understood as a problem of pattern recognition or, more informally, of knowledge discovery and data mining. There exists a gap, though, between data modeling and knowledge extraction. Models, de- pending on the machine learning techniques employed, can be described in diverse ways but, in order to consider that some knowledge has been achieved from their description, we must take into account the human cog- nitive factor that any knowledge extraction process entails. These models as such can be rendered powerless unless they can be interpreted ,a nd the process of human interpretation follows rules that go well beyond techni- cal prowess. For this reason, interpretability is a paramount quality that machine learning methods should aim to achieve if they are to be applied in practice. This paper is a brief introduction to the special session on interpretable models in machine learning, organized as part of the 20 th European Symposium on Artificial Neural Networks, Computational In- telligence and Machine Learning. It includes a discussion on the several works accepted for the session, with an overview of the context of wider research on interpretability of machine learning models.","",""
1,"Ankit Kumar, K. Jani, Abhishek Kumar Jishu, Hrishitva Patel, Aditya Kumar Sharma, M. Khare","Evaluation of Deep Learning Based Human Expression Recognition on Noisy Images",2020,"","","","",183,"2022-07-13 09:23:39","","10.1109/ISCMI51676.2020.9311549","","",,,,,1,0.50,0,6,2,"Several engineers are currently attempting to recognize the emotions of an individual based on facial expressions. Previously, the images used for human expression recognition had a high resolution and were of good quality. In practice, due to factors such as the camera sensor being sensitive to temperature and illumination and noise added to the transmission of images from a camera to a computer system, noise is added to pictures. It changes the pixel values. Past research has not studied the impact of these factors in great detail. We have proposed a Convolutional Neural Network (CNN) based human expression recognition system and evaluated its performance in the presence of different types of noise. We have also compared the CNN-based model with the Support Vector machine algorithm that has been used in the past to explain why CNN-based human expression recognition is more robust than other face recognition methods. Based on the findings from the experiments, we offer suggestions for developers using human expression recognition technologies.","",""
10,"Yuanyuan Wei, Julian Jang-Jaccard, Fariza Sabrina, Amardeep Singh, Wen Xu, S. Çamtepe","AE-MLP: A Hybrid Deep Learning Approach for DDoS Detection and Classification",2021,"","","","",184,"2022-07-13 09:23:39","","10.1109/access.2021.3123791","","",,,,,10,10.00,2,6,1,"Distributed Denial-of-Service (DDoS) attacks are increasing as the demand for Internet connectivity massively grows in recent years. Conventional shallow machine learning-based techniques for DDoS attack classification tend to be ineffective when the volume and features of network traffic, potentially carry malicious DDoS payloads, increase exponentially as they cannot extract high importance features automatically. To address this concern, we propose a hybrid approach named AE-MLP that combines two deep learning-based models for effective DDoS attack detection and classification. The Autoencoder (AE) part of our proposed model provides an effective feature extraction that finds the most relevant feature sets automatically without human intervention (e.g., knowledge of cybersecurity professionals). The Multi-layer Perceptron Network (MLP) part of our proposed model uses the compressed and reduced feature sets produced by the AE as inputs and classifies the attacks into different DDoS attack types to overcome the performance overhead and bias associated with processing large feature sets with noise (i.e., unnecessary feature values). Our experimental results, obtained through comprehensive and extensive experiments on different aspects of performance on the CICDDoS2019 dataset, demonstrate both a very high and robust accuracy rate and F1-score that exceed 98% which also outperformed the performance of many similar methods. This shows that our proposed model can be used as an effective DDoS defense tool against the growing number of DDoS attacks.","",""
1,"Jemshit Iskanderov, M. A. Guvensan","Breaking the Limits of Transportation Mode Detection: Applying Deep Learning Approach With Knowledge-Based Features",2020,"","","","",185,"2022-07-13 09:23:39","","10.1109/JSEN.2020.3001803","","",,,,,1,0.50,1,2,2,"Activity recognition and transportation mode detection are the key research areas for context-aware systems. In smart environments such as cities, buildings, transportation systems etc., ambient intelligence applications watch on human activities in order to increase the quality of transportation, health, traffic and human-oriented services. Literature review shows that existing studies typically deal with recognition of motorized and non-motorized daily activities under the name of human activity recognition and transport mode detection. Only few studies worked on these problems with rich datasets in terms of the number of classes. To the best of our knowledge, for the first time, a study examines nearly the whole motorized/non-motorized transportation modes of people including still, walk, run, climbing upstairs, climbing downstairs, bicycle, motorbike, car, metro, train, high speed rail (HSR), tram and metrobus, excluding ferry and airplane. To outperform existing solutions on such a large dataset, an extended version of the well-known HTC dataset, especially consisting of similar classes, such as train, metro, tram and high speed rail, we propose a combined solution of an Long Short-Term Memory network and Healing algorithm. In our experiments, we first reveal the limits of traditional machine learning algorithms on such number of classes. In addition to that, apart from other studies exploiting deep learning approach, we then examine the potential input types for LSTM network, including raw sensor data, knowledge-based features and features obtained via Auto Encoder. Experimental results show that our proposed idea, feeding knowledge-based features into frames of LSTM network make a remarkable difference and bring out a robust, orientation-independent and generic solution for these well-known problems including activity recognition and transport mode detection. Besides, we examined the hyper-parameters of our deep learning approach and specified the effective parameter set including window size, number of frames, unit size, dropout rate and batch size. Our test results reveal that we could achieve a success rate of 95.5% and outperform the state-of-the art solutions for 12 different transportation modes with the help of our former algorithm, namely Healing, on a totally journey-independent dataset where instances for train, validation and test datasets are selected from different journeys.","",""
0,"Muhao Chen","Knowledge Acquisition with Transferable and Robust Representation Learning",2020,"","","","",186,"2022-07-13 09:23:39","","","","",,,,,0,0.00,0,1,2,"My research focuses on promoting the advancement of intelligent computational systems with better awareness of commonsense and expert knowledge, which leads to more efficient information exchange of the system with people and the world. My goal, in the long term, is to leverage unified methodologies to help machines understand the relations of lexemes, entities and concepts in human languages as well as the interactions of objects in nature (such as molecules and biomolecules). In the near term, I am motivated by the objective of developing new technologies in representation learning and information extraction, and extending their use in various tasks for knowledge base construction, natural language understanding, computational biology and medicine. The challenges span over a range of fields, from the fundamental questions in the acquisition, representation and inference of knowledge, to systematic paradigms for scalable data management, mining and retrieval. In this decade, AI systems in various application domains are empowered by representation learning technologies for automatically discovering and acquiring relations, patterns and properties of objects from large-scale data. In particular, such technologies involve relational embedding, language modeling and constrained learning. My work seeks to trigger the advancement of these technologies, with focus on knowledge acquisition from data in different modalities, and in scenarios with or without plausible supervision signals. My investigation in these research directions has led to over 30 published papers, and have benefited real-world applications in various computational and interdisciplinary areas. The following of this statement presents parts of my investigation into these directions, followed by some exciting future directions that I am planning to explore.","",""
7,"Ayon Sen, P. Patel, Martina A. Rau, Blake Mason, R. Nowak, T. Rogers, Xiaojin Zhu","Machine Beats Human at Sequencing Visuals for Perceptual-Fluency Practice",2018,"","","","",187,"2022-07-13 09:23:39","","","","",,,,,7,1.75,1,7,4,"In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency: the ability to intuitively and rapidly see which concepts visuals show and to translate among multiple visuals. Instructional problems that engage students in nonverbal, implicit learning processes enhance perceptual fluency. Such processes are highly influenced by sequence effects. Thus far, we lack a principled approach for identifying a sequence of perceptual-fluency problems that promote robust learning. Here, we describe a novel educational data mining approach that uses machine learning to generate an optimal sequence of visuals for perceptual-fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machinegenerated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that an educational data mining approach can induce desirable difficulties for perceptual learning.","",""
1,"Anoop Sathyan","Intelligent Machine Learning Approaches for Aerospace Applications",2017,"","","","",188,"2022-07-13 09:23:39","","","","",,,,,1,0.20,1,1,5,"Machine Learning is a type of artificial intelligence that provides machines or networks the ability to learn from data without the need to explicitly program them. There are different kinds of machine learning techniques. This thesis discusses the applications of two of these approaches: Genetic Fuzzy Logic and Convolutional Neural Networks (CNN). Fuzzy Logic System (FLS) is a powerful tool that can be used for a wide variety of applications. FLS is a universal approximator that reduces the need for complex mathematics and replaces it with expert knowledge of the system to produce an input-output mapping using If-Then rules. The expert knowledge of a system can help in obtaining the parameters for small-scale FLSs, but for larger networks we will need to use sophisticated approaches that can automatically train the network to meet the design requirements. This is where Genetic Algorithms (GA) and EVE come into the picture. Both GA and EVE can tune the FLS parameters to minimize a cost function that is designed to meet the requirements of the specific problem. EVE is an artificial intelligence developed by Psibernetix that is trained to tune large scale FLSs. The parameters of an FLS can include the membership functions and rulebase of the inherent Fuzzy Inference Systems (FISs). The main issue with using the GFS is that the number of parameters in a FIS increase exponentially with the number of inputs thus making it increasingly harder to tune them. To reduce this issue, the FLSs discussed in this thesis consist of 2-input-1-output FISs in cascade (Chapter 4) or as a layer of parallel FISs (Chapter 7). We have obtained extremely good results using GFS for different applications at a reduced computational cost compared to other algorithms that are commonly used to solve the corresponding problems. In this thesis, GFSs have been designed for controlling an inverted double pendulum, a task allocation problem of clustering targets amongst a set of UAVs, a fire detection problem and the aircraft conflict resolution problem. During the last decade, CNNs have become increasingly popular in the domain of image and speech processing. CNNs have a lot more parameters compared to GFSs that are tuned using the back-propagation algorithm. CNNs typically have hundreds of thousands or maybe millions of parameters that are tuned using common cost functions such as integral squared error, softmax loss etc. Chapter 5 discusses a classification problem to classify images as humans or not and Chapter 6 discusses a regression task using CNN for producing an approximate near-optimal route for the Traveling Salesman Problem (TSP) which is regarded as one of the most complicated decision making problem. Both the GFS and CNN are used to develop intelligent systems specific to the application providing them computational efficiency, robustness in the face of uncertainties and scalability.","",""
43,"Xiao-hui Li, Caleb Chen Cao, Yuhan Shi, Wei Bai, Han Gao, Luyu Qiu, Cong Wang, Yuanyuan Gao, Shenjia Zhang, Xun Xue, Lei Chen","A Survey of Data-Driven and Knowledge-Aware eXplainable AI",2020,"","","","",189,"2022-07-13 09:23:39","","10.1109/tkde.2020.2983930","","",,,,,43,21.50,4,11,2,"We are witnessing a fast development of Artificial Intelligence (AI), but it becomes dramatically challenging to explain AI models in the past decade. “Explanation” has a flexible philosophical concept of “satisfying the subjective curiosity for causal information”, driving a wide spectrum of methods being invented and/or adapted from many aspects and communities, including machine learning, visual analytics, human-computer interaction and so on. Nevertheless, from the view-point of data and knowledge engineering (DKE), a best explaining practice that is cost-effective in terms of extra intelligence acquisition should exploit the causal information and explaining scenarios which is hidden richly in the data itself. In the past several years, there are plenty of works contributing in this line but there is a lack of a clear taxonomy and systematic review of the current effort. To this end, we propose this survey, reviewing and taxonomizing existing efforts from the view-point of DKE, summarizing their contribution, technical essence and comparative characteristics. Specifically, we categorize methods into data-driven methods where explanation comes from the task-related data, and knowledge-aware methods where extraneous knowledge is incorporated. Furthermore, in the light of practice, we provide survey of state-of-art evaluation metrics and deployed explanation applications in industrial practice.","",""
51,"Wen Qi, Hang Su, A. Aliverti","A Smartphone-Based Adaptive Recognition and Real-Time Monitoring System for Human Activities",2020,"","","","",190,"2022-07-13 09:23:39","","10.1109/THMS.2020.2984181","","",,,,,51,25.50,17,3,2,"Human activity recognition (HAR) using smartphones provides significant healthcare guidance for telemedicine and long-term treatment. Machine learning and deep learning (DL) techniques are widely utilized for the scientific study of the statistical models of human behaviors. However, the performance of existing HAR platforms is limited by complex physical activity. In this article, we proposed an adaptive recognition and real-time monitoring system for human activities (Ada-HAR), which is expected to identify more human motions in dynamic situations. The Ada-HAR framework introduces an unsupervised online learning algorithm that is independent of the number of class constraints. Furthermore, the adopted hierarchical clustering and classification algorithms label and classify 12 activities (five dynamics, six statics, and a series of transitions) autonomously. Finally, practical experiments have been performed to validate the effectiveness and robustness of the proposed algorithms. Compared with the methods mentioned in the literature, the results show that the DL-based classifier obtains a higher recognition rate ($\text{95.15}\%$, waist, and $\text{92.20}\%$, pocket). The decision-tree-based classifier is the fastest method for modal evolution. Finally, the Ada-HAR system can monitor human activity in real time, regardless of the direction of the smartphone.","",""
2799,"R. Michalski, John R. Anderson","Machine learning - an artificial intelligence approach",1982,"","","","",191,"2022-07-13 09:23:39","","","","",,,,,2799,69.98,1400,2,40,"This book contains tutorial overviews and research papers on contemporary trends in the area of machine learning viewed from an AI perspective. Research directions covered include: learning from examples, modeling human learning strategies, knowledge acquisition for expert systems, learning heuristics, discovery systems, and conceptual data analysis.","",""
0,"Hsiao-Chi Li, Chang-Yu Cheng, Chia Chou, Chien-Chang Hsu, Meng-Lin Chang, Y. Chiu, J. Chai","Multi-Class Brain Age Discrimination Using Machine Learning Algorithm",2019,"","","","",192,"2022-07-13 09:23:39","","10.1109/ICMLC48188.2019.8949317","","",,,,,0,0.00,0,7,3,"Resting-state functional connectivity analyses have revealed a significant effect on the inter-regional interactions in brain. The brain age prediction based on resting-state functional magnetic resonance imaging has been proved as biomarkers to characterize the typical brain development and neuropsychiatric disorders. The brain age prediction model based on functional connectivity measurements derived from resting-state functional magnetic resonance imaging has received a lots of interest in recent years due to its great success in age prediction. However, some of the recent studies rely on experienced neuroscientist experts to select appropriate connectivity features in order to build a robust model for prediction while the others just selected the features based on trial-and-error test. Besides, the subjects used in this studies omitted some subjects that can be divided into two groups with less similarity which may confused the prediction model. In this study, we proposed a multi-class age categories discrimination method with the connectivity features selected via K-means clustering with no prior knowledge provided. The experimental results show that with K-means selected features the proposed model better discriminate multi-class age categories.","",""
9,"Syed Ashiqur Rahman, Peter Giacobbi, L. Pyles, C. Mullett, Gianfranco Doretto, D. Adjeroh","Deep learning for biological age estimation",2020,"","","","",193,"2022-07-13 09:23:39","","10.1093/bib/bbaa021","","",,,,,9,4.50,2,6,2,"Modern machine learning techniques (such as deep learning) offer immense opportunities in the field of human biological aging research. Aging is a complex process, experienced by all living organisms. While traditional machine learning and data mining approaches are still popular in aging research, they typically need feature engineering or feature extraction for robust performance. Explicit feature engineering represents a major challenge, as it requires significant domain knowledge. The latest advances in deep learning provide a paradigm shift in eliciting meaningful knowledge from complex data without performing explicit feature engineering. In this article, we review the recent literature on applying deep learning in biological age estimation. We consider the current data modalities that have been used to study aging and the deep learning architectures that have been applied. We identify four broad classes of measures to quantify the performance of algorithms for biological age estimation and based on these evaluate the current approaches. The paper concludes with a brief discussion on possible future directions in biological aging research using deep learning. This study has significant potentials for improving our understanding of the health status of individuals, for instance, based on their physical activities, blood samples and body shapes. Thus, the results of the study could have implications in different health care settings, from palliative care to public health.","",""
1896,"R. Schapire","The Boosting Approach to Machine Learning An Overview",2003,"","","","",194,"2022-07-13 09:23:39","","10.1007/978-0-387-21579-2_9","","",,,,,1896,99.79,1896,1,19,"","",""
1,"Nanyang Ye, Jingxuan Tang, Huayu Deng, Xiao-Yun Zhou, Qianxiao Li, Zhenguo Li, Guang-Zhong Yang, Zhanxing Zhu","Adversarial Invariant Learning",2021,"","","","",195,"2022-07-13 09:23:39","","10.1109/CVPR46437.2021.01226","","",,,,,1,1.00,0,8,1,"Though machine learning algorithms are able to achieve pattern recognition from the correlation between data and labels, the presence of spurious features in the data decreases the robustness of these learned relationships with respect to varied testing environments. This is known as out-of-distribution (OoD) generalization problem. Recently, invariant risk minimization (IRM) attempts to tackle this issue by penalizing predictions based on the unstable spurious features in the data collected from different environments. However, similar to domain adaptation or domain generalization, a prevalent non-trivial limitation in these works is that the environment information is assigned by human specialists, i.e. a priori, or determined heuristically. However, an inappropriate group partitioning can dramatically deteriorate the OoD generalization and this process is expensive and time-consuming. To deal with this issue, we propose a novel theoretically principled min-max framework to iteratively construct a worst-case splitting, i.e. creating the most challenging environment splittings for the backbone learning paradigm (e.g. IRM) to learn the robust feature representation. We also design a differentiable training strategy to facilitate the feasible gradient- based computation. Numerical experiments show that our algorithmic framework has achieved superior and stable performance in various datasets, such as Colored MNIST and Punctuated Stanford sentiment treebank (SST). Furthermore, we also find our algorithm to be robust even to a strong data poisoning attack. To the best of our knowledge, this is one of the first to adopt differentiable environment splitting method to enable stable predictions across environments without environment index information, which achieves the state-of-the-art performance on datasets with strong spurious correlation, such as Colored MNIST.","",""
16,"O. Daramola, T. Stålhane, Inah Omoronyia, G. Sindre","Using Ontologies and Machine Learning for Hazard Identification and Safety Analysis",2013,"","","","",196,"2022-07-13 09:23:39","","10.1007/978-3-642-34419-0_6","","",,,,,16,1.78,4,4,9,"","",""
1,"Karthik Raman","Research Statement : Machine Learning with Humans in the Loop",2014,"","","","",197,"2022-07-13 09:23:39","","","","",,,,,1,0.13,1,1,8,"Intelligent systems, ranging from internet search engines and online retailers to personal robots and MOOCs, live in a symbiotic relationship with their users or at least they should. On the one hand, users greatly benefit from the services provided by these systems. On the other hand, these systems can greatly benefit from the world knowledge that users communicate through their interactions with the system. These interactions – queries, clicks, votes, purchases, answers, demonstrations, etc. – are one of the key sources of “Big Data”, providing enormous potential for economically and autonomously optimizing these systems and for gaining unprecedented amounts of world knowledge required to solve some of the hardest AI problems. The key challenge in working with data that results from human behavior is that it typically does not fit standard machine learning models. In particular, interactions typically do not provide us with ground truth labels, but are simply the result of decisions made by humans. The core insight behind my research is that we need new machine learning models and algorithms that explicitly account for how humans make decisions, which is influenced by a variety of factors like decision context, expertise, skills, motivations and needs. Armed with this insight, I have developed new learning models and learning algorithms that provide provable performance guarantees for learning from human interaction data. I have also implemented and fielded human-interactive learning systems, such as the text search engine for arxiv.org, that autonomously, robustly, and cost-effectively improve their performance. In this vast research area of learning with humans in the loop, I have so far focused on problems motivated by search, recommendation, and education analytics. This work, and how it opens up new research directions, is discussed in the following. As will be evident from this work, my goal is to study machine learning problems with real-world impact from the combined lenses of machine learning, algorithmic theory, and human interaction. I strive to come up with algorithms, that have theoretical guarantees, which I then implement on real user-facing systems and evaluate via user studies. Going forward technological changes, such as smart homes, are only going to grow and enrich the modes for humans to interact with intelligent systems. By exploiting such advances, I hope to work on and create new disruptive technologies that can fundamentally alter our day-to-day life.","",""
0,"R. Marcacini","Machine learning with privileged information: approaches for hierarchical text clustering (Aprendizado de máquina com informação privilegiada: abordagens para agrupamento hierárquico de textos)",2014,"","","","",198,"2022-07-13 09:23:39","","10.11606/T.55.2014.TDE-05082015-094733","","",,,,,0,0.00,0,1,8,"Hierarchical text clustering methods are very useful to analyze the implicit knowledge in textual collections, enabling the organization of textual documents into clusters and subclusters to facilitate the knowledge browsing at various levels of granularity. Such methods are classified as unsupervised machine learning, since the clustering models are obtained only by observing regularities of textual data without human supervision. Traditional clustering methods assume that the text collection is represented only by the “technical information”, i.e., words and phrases extracted directly from the texts. On the other hand, in many text clustering tasks there is an additional and valuable knowledge about the problem domain, usually extracted by an advanced process with support of the domain experts. Due to the high cost of obtaining such expert knowledge, this additional information is defined as “privileged” and is usually available to represent only a subset of the textual documents. Recently, a new machine learning paradigm called LUPI (Learning Using Privileged Information) was proposed by Vapnik to incorporate privileged information into supervised learning methods. In this thesis, the LUPI paradigm was extended to unsupervised learning setting, in particular for hierarchical text clustering. We propose and evaluate approaches to deal with different challenges for clustering tasks, involving the extraction and structuring of privileged information and using this additional information to refine or correct clustering models. The proposed approaches were effective in (i) consensus clustering, allowing to combine different clustering solutions and textual representations; (ii) metric learning, in which more robust proximity measures are obtained from privileged information; and (iii) model selection, in which the privileged information is exploited to identify the relevant structures of hierarchical clustering. All the approaches presented in this thesis were investigated in an incremental clustering scenario, allowing its use in practical applications that require computational efficiency as well as deal with high frequency of publication of new textual knowledge.","",""
5,"R. Goebel, Sandra Zilles, Christoph Ringlstetter, A. Dengel, G. Grimnes","What Is the Role of the Semantic Layer Cake for Guiding the Use of Knowledge Representation and Machine Learning in the Development of the Semantic Web?",2008,"","","","",199,"2022-07-13 09:23:39","","","","",,,,,5,0.36,1,5,14,"The World Wide Web Consortium (W3C) has been the consolidator for many ideas regarding the evolution of the World Wide Web (WWW), including the promotion of the so-called “Semantic Layer Cake” model for the development of the semantic web. The semantic layer cake provides a framework to discuss a variety of approaches to an integrated view of the meta-data that will support a broad range of machine and human manipulation of digital information. Our goal is to develop a deeper understanding of the potential role of the semantic layer cake, by investigating some of the detailed relationships between the components. We also attempt to articulate some of the issues regarding the development of the semantic layer cake for real application. The path to this goal covers many fundamental issues underlying all of knowledge representation research. Paramount in this discussion is the goal of identifying the potential role of machine learning within the semantic layer cake, and finding the tradeoffs between the extremes of a completely automated construction of the semantic web via machine learning, versus one that is completely hand-engineered using the tools emerging from each layer of the semantic layer cake.","",""
0,"S. Muggleton, Wang-Zhou Dai","Human-like Computer Vision",2021,"","","","",200,"2022-07-13 09:23:39","","10.1093/oso/9780198862536.003.0010","","",,,,,0,0.00,0,2,1,"Statistical machine learning is widely used in image classification and typically 1) requires many images to achieve high accuracy and 2) does not provide support for reasoning below the level of classification.  By contrast this paper describes an approach called machine learning approach called Logical Vision (LV) which uses a) background knowledge such as light reflection that can itself be learned and used for resolving visual ambiguities, which cannot be easily modeled using statistical approaches, b) a wider class of background models representing classical 2D shapes such as circles and ellipses, c) primitive-level statistical estimators to handle noise in real images, Our results indicate that in real images the new noise-robust version of LV using a single example (ie one-shot LV) converges to an accuracy at least comparable to thirty-shot statistical machine learner on the prediction of hidden light sources.","",""
