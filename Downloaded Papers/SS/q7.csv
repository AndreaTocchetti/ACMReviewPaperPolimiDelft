Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",1,"2022-07-13 09:19:39","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
3,"A. Preece, Daniel Harborne, R. Raghavendra, Richard J. Tomsett, Dave Braines","Provisioning Robust and Interpretable AI/ML-Based Service Bundles",2018,"","","","",2,"2022-07-13 09:19:39","","10.1109/MILCOM.2018.8599838","","",,,,,3,0.75,1,5,4,"Coalition operations environments are characterised by the need to share intelligence, surveillance and reconnaissance services. Increasingly, such services are based on artificial intelligence (AI)and machine learning (ML)technologies. Two key issues in the exploitation of AI/ML services are robustness and interpretability. Employing a diverse portfolio of services can make a system robust to ‘unknown unknowns’. Interpretability - the need for services to offer explanation facilities to engender user trust - can be addressed by a variety of methods to generate either transparent or post hoc explanations according to users' requirements. This paper shows how a service-provisioning framework for coalition operations can be extended to address specific requirements for robustness and interpretability, allowing automatic selection of service bundles for intelligence, surveillance and reconnaissance tasks. The approach is demonstrated in a case study on traffic monitoring featuring a diverse set of AI/ML services based on deep neural networks and heuristic reasoning approaches.","",""
0,"Cheng-Lin Liu, A. Hussain, B. Luo, K. Tan, Yi Zeng, Zhaoxiang Zhang","Special Issue of BICS 2016",2018,"","","","",3,"2022-07-13 09:19:39","","10.1007/s12559-018-9551-3","","",,,,,0,0.00,0,6,4,"","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",4,"2022-07-13 09:19:39","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",5,"2022-07-13 09:19:39","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",6,"2022-07-13 09:19:39","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",7,"2022-07-13 09:19:39","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",8,"2022-07-13 09:19:39","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",9,"2022-07-13 09:19:39","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",10,"2022-07-13 09:19:39","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",11,"2022-07-13 09:19:39","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",12,"2022-07-13 09:19:39","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",13,"2022-07-13 09:19:39","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",14,"2022-07-13 09:19:39","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",15,"2022-07-13 09:19:39","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
2,"E. Papachristos, I. Stefanou","Controlling earthquake-like instabilities using artificial intelligence",2021,"","","","",16,"2022-07-13 09:19:39","","","","",,,,,2,2.00,1,2,1,"Earthquakes are lethal and costly. This study aims at avoiding these catastrophic events by the application of injection policies retrieved through reinforcement learning. With the rapid growth of artificial intelligence, prediction-control problems are all the more tackled by function approximation models that learn how to control a specific task, even for systems with unmodeled/unknown dynamics and important uncertainties. Here, we show for the first time the possibility of controlling earthquakelike instabilities using state-of-the-art deep reinforcement learning techniques. The controller is trained using a reduced model of the physical system, i.e, the spring-slider model, which embodies the main dynamics of the physical problem for a given earthquake magnitude. Its robustness to unmodeled dynamics is explored through a parametric study. Our study is a first step towards minimizing seismicity in industrial projects (geothermal energy, hydrocarbons production, CO2 sequestration) while, in a second step for inspiring techniques for natural earthquakes control and prevention.","",""
0,"Zhaiyi Wang","New Artificial Intelligence Technology Applied in Automobile Lithium Battery Manufacturing",2021,"","","","",17,"2022-07-13 09:19:39","","10.1088/1742-6596/1982/1/012026","","",,,,,0,0.00,0,1,1,"In order to improve the estimation accuracy of the state of charge (SOC) of electric vehicle power batteries, this paper is based on artificial intelligence technology for lithium-ion battery model and parameter identification algorithm, adaptive unscented Kalman filter algorithm and SOC estimation based on battery model fusion Algorithm for research. The simulation results show that the SOC error estimated by the artificial intelligence adaptive Kalman filter method is less than 2.4%, which effectively reduces the impact of unknown interference noise on the battery management system when the electric vehicle is driving. The SOC estimation accuracy is higher than that of the extended Kalman method, and has good robustness.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",18,"2022-07-13 09:19:39","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",19,"2022-07-13 09:19:39","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",20,"2022-07-13 09:19:39","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
0,"S. Farsoni, S. Simani","Validation of Fault Diagnosis Techniques Based on Artificial Intelligence Tools for a Wind Turbine Benchmark",2021,"","","","",21,"2022-07-13 09:19:39","","10.1109/SysTol52990.2021.9595291","","",,,,,0,0.00,0,2,1,"The fault diagnosis of wind turbines includes extremely challenging aspects that motivate the research issues considered in this paper. In particular, this work studies fault diagnosis solutions that are considered in a viable way and used as advanced techniques for condition monitoring of dynamic processes. To this end, the work proposes the design of fault diagnosis techniques that exploits the estimation of the fault by means of data–driven approaches. To this end, the fuzzy and neural network structures are integrated with auto–regressive with exogenous input regressors, thus making them able to approximate unknown nonlinear dynamic functions with arbitrary degree of accuracy. The capabilities of fault diagnosis schemes are validated by using a simulator of a wind turbine system. Moreover, at this stage the benchmark is also useful to analyse the robustness and the reliability characteristics of the developed tools in the presence of model–reality mismatch and modelling error effects featured by the wind turbine simulator. On the other hand, a hardware–in–the–loop tool is finally implemented for testing the performance of the developed fault diagnosis strategies in a more realistic environment.","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",22,"2022-07-13 09:19:39","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",23,"2022-07-13 09:19:39","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",24,"2022-07-13 09:19:39","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
5,"David Abele, Sara D’Onofrio","Artificial Intelligence – The Big Picture",2020,"","","","",25,"2022-07-13 09:19:39","","10.1007/978-3-658-27941-7_2","","",,,,,5,2.50,3,2,2,"","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",26,"2022-07-13 09:19:39","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
0,"José Lucas de Alencar Saraiva, O. M. Becker, Eliézer Silva, V. Kadirkamanathan, K. Kienitz","Sensitivity analysis–based sepsis prognosis using artificial intelligence",2020,"","","","",27,"2022-07-13 09:19:39","","10.1007/S42600-020-00083-7","","",,,,,0,0.00,0,5,2,"","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",28,"2022-07-13 09:19:39","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
56,"Konstantinos C. Siontis, P. Noseworthy, Z. Attia, P. Friedman","Artificial intelligence-enhanced electrocardiography in cardiovascular disease management",2021,"","","","",29,"2022-07-13 09:19:39","","10.1038/s41569-020-00503-2","","",,,,,56,56.00,14,4,1,"","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",30,"2022-07-13 09:19:39","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
47,"L. Faes, B. Geerts, Xiaoxuan Liu, L. Morgan, P. Watkinson, P. McCulloch","DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in clinical artificial intelligence.",2021,"","","","",31,"2022-07-13 09:19:39","","10.1038/s41591-021-01229-5","","",,,,,47,47.00,8,6,1,"","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",32,"2022-07-13 09:19:39","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",33,"2022-07-13 09:19:39","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",34,"2022-07-13 09:19:39","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",35,"2022-07-13 09:19:39","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",36,"2022-07-13 09:19:39","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
13,"A. Chehri, I. Fofana, Xiaoming Yang","Security Risk Modeling in Smart Grid Critical Infrastructures in the Era of Big Data and Artificial Intelligence",2021,"","","","",37,"2022-07-13 09:19:39","","10.3390/SU13063196","","",,,,,13,13.00,4,3,1,"Smart grids (SG) emerged as a response to the need to modernize the electricity grid. The current security tools are almost perfect when it comes to identifying and preventing known attacks in the smart grid. Still, unfortunately, they do not quite meet the requirements of advanced cybersecurity. Adequate protection against cyber threats requires a whole set of processes and tools. Therefore, a more flexible mechanism is needed to examine data sets holistically and detect otherwise unknown threats. This is possible with big modern data analyses based on deep learning, machine learning, and artificial intelligence. Machine learning, which can rely on adaptive baseline behavior models, effectively detects new, unknown attacks. Combined known and unknown data sets based on predictive analytics and machine intelligence will decisively change the security landscape. This paper identifies the trends, problems, and challenges of cybersecurity in smart grid critical infrastructures in big data and artificial intelligence. We present an overview of the SG with its architectures and functionalities and confirm how technology has configured the modern electricity grid. A qualitative risk assessment method is presented. The most significant contributions to the reliability, safety, and efficiency of the electrical network are described. We expose levels while proposing suitable security countermeasures. Finally, the smart grid’s cybersecurity risk assessment methods for supervisory control and data acquisition are presented.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",38,"2022-07-13 09:19:39","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",39,"2022-07-13 09:19:39","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",40,"2022-07-13 09:19:39","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
12,"M. Yoosefzadeh-Najafabadi, D. Tulpan, M. Eskandari","Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices",2021,"","","","",41,"2022-07-13 09:19:39","","10.3390/rs13132555","","",,,,,12,12.00,4,3,1,"Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",42,"2022-07-13 09:19:39","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",43,"2022-07-13 09:19:39","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",44,"2022-07-13 09:19:39","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",45,"2022-07-13 09:19:39","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",46,"2022-07-13 09:19:39","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
7,"F. Arama, Slimane Laribi, T. Ghaitaoui","A Control Method using Artificial Intelligence in Wind Energy Conversion System",2019,"","","","",47,"2022-07-13 09:19:39","","10.46657/ajresd.2019.1.1.6","","",,,,,7,2.33,2,3,3,"This work presents a field-oriented control (FOC) of active and reactive power applied on Doubly Fed Induction Machine (DFIM) integrated in wind energy conversion system (WECS). The main objective of this work is to compare the performances of energy produced by the use of two types of controllers ( PI regulator and the neural network regulator (NN)) in order to control the wind power conversion system to compare their precision & robustness against the wind fluctuation and the impact on the quality of produced energy. A field oriented control of DEFIG stator is also presented to control the active and reactive power. To show the efficiency of the performances and the robustness of the two control methods those were analyzed and compared by simulation using Matlab/Simulink software. The results described the favoured method.","",""
0,"Wei-Zhi Hu","Parameter identification based on artificial intelligence optimization and distributed tracking control of fractional-order multi-agent systems. (Identification de paramètre basée sur l'optimisation de l'intelligence artificielle et le contrôle de suivi distribué des systèmes multi-agents d'ordre fr",2019,"","","","",48,"2022-07-13 09:19:39","","","","",,,,,0,0.00,0,1,3,"This thesis deals with the parameter identification from the viewpoint of optimization and distributed tracking control of fractional-order multi-agent systems (FOMASs) considering time delays, external disturbances, inherent nonlinearity, parameters uncertainties, and heterogeneity under fixed undirected/directed communication topology. Several efficient controllers are designed to achieve the distributed tracking control of FOMASs successfully under different conditions. Several kinds of artificial intelligence optimization algorithms andtheir modified versions are applied to identify the unknown parameters of the FOMASs with high accuracy, fast convergence and strong robustness. It should be noted that this thesis provides a promising link between the artificial intelligence technique and distributed control.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",49,"2022-07-13 09:19:39","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
48,"Federico Cugurullo","Urban Artificial Intelligence: From Automation to Autonomy in the Smart City",2020,"","","","",50,"2022-07-13 09:19:39","","10.3389/frsc.2020.00038","","",,,,,48,24.00,48,1,2,"Technological innovation is constantly reshaping the materiality and mechanics of smart-city initiatives. Recently, innovation in artificial intelligence (AI) in the shape of self-driving cars, robots and city brains, has been pushing the so-called smart city to morph into an autonomous urban creature which is largely unknown. In this emerging strand of smart urbanism, artificially intelligent entities are taking the management of urban services as well as urban governance out of the hands of humans, operating the city in an autonomous manner. This paper explores, in theory and practice, how the development of AI intersects with the development of the city. The contribution of the paper is threefold. First, the paper advances a theoretical framework to understand AI specifically in urban contexts. It develops the concept of urban artificial intelligence, capturing the main manifestations of AI in cities. Second, the paper examines the case of Masdar City, an Emirati urban experiment, to show how the genesis of urban artificial intelligences is part of a long-standing process of technological development and a politico-economic agenda which together are enabling the transition from automation to autonomy. Third, it proposes a research agenda to investigate what the paper terms the autonomous city.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",51,"2022-07-13 09:19:39","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",52,"2022-07-13 09:19:39","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",53,"2022-07-13 09:19:39","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
6,"Z. Su, D. McDonnell, Barry L Bentley, Jiguang He, Feng Shi, Ali Cheshmehzangi, Junaid Ahmad, P. Jia","Addressing Biodisaster X Threats With Artificial Intelligence and 6G Technologies: Literature Review and Critical Insights",2021,"","","","",54,"2022-07-13 09:19:39","","10.2196/26109","","",,,,,6,6.00,1,8,1,"Background With advances in science and technology, biotechnology is becoming more accessible to people of all demographics. These advances inevitably hold the promise to improve personal and population well-being and welfare substantially. It is paradoxical that while greater access to biotechnology on a population level has many advantages, it may also increase the likelihood and frequency of biodisasters due to accidental or malicious use. Similar to “Disease X” (describing unknown naturally emerging pathogenic diseases with a pandemic potential), we term this unknown risk from biotechnologies “Biodisaster X.” To date, no studies have examined the potential role of information technologies in preventing and mitigating Biodisaster X. Objective This study aimed to explore (1) what Biodisaster X might entail and (2) solutions that use artificial intelligence (AI) and emerging 6G technologies to help monitor and manage Biodisaster X threats. Methods A review of the literature on applying AI and 6G technologies for monitoring and managing biodisasters was conducted on PubMed, using articles published from database inception through to November 16, 2020. Results Our findings show that Biodisaster X has the potential to upend lives and livelihoods and destroy economies, essentially posing a looming risk for civilizations worldwide. To shed light on Biodisaster X threats, we detailed effective AI and 6G-enabled strategies, ranging from natural language processing to deep learning–based image analysis to address issues ranging from early Biodisaster X detection (eg, identification of suspicious behaviors), remote design and development of pharmaceuticals (eg, treatment development), and public health interventions (eg, reactive shelter-at-home mandate enforcement), as well as disaster recovery (eg, sentiment analysis of social media posts to shed light on the public’s feelings and readiness for recovery building). Conclusions Biodisaster X is a looming but avoidable catastrophe. Considering the potential human and economic consequences Biodisaster X could cause, actions that can effectively monitor and manage Biodisaster X threats must be taken promptly and proactively. Rather than solely depending on overstretched professional attention of health experts and government officials, it is perhaps more cost-effective and practical to deploy technology-based solutions to prevent and control Biodisaster X threats. This study discusses what Biodisaster X could entail and emphasizes the importance of monitoring and managing Biodisaster X threats by AI techniques and 6G technologies. Future studies could explore how the convergence of AI and 6G systems may further advance the preparedness for high-impact, less likely events beyond Biodisaster X.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",55,"2022-07-13 09:19:39","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",56,"2022-07-13 09:19:39","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
103,"Onur Asan, A. E. Bayrak, Avishek Choudhury","Artificial Intelligence and Human Trust in Healthcare: Focus on Clinicians",2020,"","","","",57,"2022-07-13 09:19:39","","10.2196/15154","","",,,,,103,51.50,34,3,2,"Artificial intelligence (AI) can transform health care practices with its increasing ability to translate the uncertainty and complexity in data into actionable—though imperfect—clinical decisions or suggestions. In the evolving relationship between humans and AI, trust is the one mechanism that shapes clinicians’ use and adoption of AI. Trust is a psychological mechanism to deal with the uncertainty between what is known and unknown. Several research studies have highlighted the need for improving AI-based systems and enhancing their capabilities to help clinicians. However, assessing the magnitude and impact of human trust on AI technology demands substantial attention. Will a clinician trust an AI-based system? What are the factors that influence human trust in AI? Can trust in AI be optimized to improve decision-making processes? In this paper, we focus on clinicians as the primary users of AI systems in health care and present factors shaping trust between clinicians and AI. We highlight critical challenges related to trust that should be considered during the development of any AI system for clinical use.","",""
74,"E. Neri, F. Coppola, V. Miele, C. Bibbolino, R. Grassi","Artificial intelligence: Who is responsible for the diagnosis?",2020,"","","","",58,"2022-07-13 09:19:39","","10.1007/s11547-020-01135-9","","",,,,,74,37.00,15,5,2,"","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",59,"2022-07-13 09:19:39","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",60,"2022-07-13 09:19:39","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",61,"2022-07-13 09:19:39","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",62,"2022-07-13 09:19:39","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",63,"2022-07-13 09:19:39","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",64,"2022-07-13 09:19:39","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",65,"2022-07-13 09:19:39","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",66,"2022-07-13 09:19:39","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",67,"2022-07-13 09:19:39","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",68,"2022-07-13 09:19:39","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",69,"2022-07-13 09:19:39","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",70,"2022-07-13 09:19:39","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",71,"2022-07-13 09:19:39","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",72,"2022-07-13 09:19:39","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
0,"James M. White, R. Lidskog","Ignorance and the regulation of artificial intelligence",2021,"","","","",73,"2022-07-13 09:19:39","","10.1080/13669877.2021.1957985","","",,,,,0,0.00,0,2,1,"Abstract Much has been written about the risks posed by artificial intelligence (AI). This article is interested not only in what is known about these risks, but what remains unknown and how that unknowing is and should be approached. By reviewing and expanding on the scientific literature, it explores how social knowledge contributes to the understanding of AI and its regulatory challenges. The analysis is conducted in three steps. First, the article investigates risks associated with AI and shows how social scientists have challenged technically-oriented approaches that treat the social instrumentally. It then identifies the invisible and visible characteristics of AI, and argues that not only is it hard for outsiders to comprehend risks attached to the technology, but also for developers and researchers. Finally, it asserts the need to better recognise ignorance of AI, and explores what this means for how their risks are handled. The article concludes by stressing that proper regulation demands not only independent social knowledge about the pervasiveness, economic embeddedness and fragmented regulation of AI, but a social non-knowledge that is attuned to its complexity, and inhuman and incomprehensible behaviour. In properly allowing for ignorance of its social implications, the regulation of AI can proceed in a more modest, situated, plural and ultimately robust manner.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",74,"2022-07-13 09:19:39","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",75,"2022-07-13 09:19:39","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",76,"2022-07-13 09:19:39","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",77,"2022-07-13 09:19:39","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",78,"2022-07-13 09:19:39","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",79,"2022-07-13 09:19:39","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
6,"Arezoo Movaghar, David Page, D. Scholze, Jinkuk Hong, L. DaWalt, Finn Kuusisto, R. Stewart, M. Brilliant, M. Mailick","Artificial intelligence–assisted phenotype discovery of fragile X syndrome in a population-based sample",2021,"","","","",80,"2022-07-13 09:19:39","","10.1038/s41436-021-01144-7","","",,,,,6,6.00,1,9,1,"","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",81,"2022-07-13 09:19:39","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",82,"2022-07-13 09:19:39","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",83,"2022-07-13 09:19:39","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
19,"S. Michie, James Thomas, P. Mac Aonghusa, R. West, M. Johnston, M. Kelly, J. Shawe-Taylor, Janna Hastings, Francesca Bonin, A. O'Mara-Eves","The Human Behaviour-Change Project: An artificial intelligence system to answer questions about changing behaviour",2020,"","","","",84,"2022-07-13 09:19:39","","10.12688/wellcomeopenres.15900.1","","",,,,,19,9.50,2,10,2,"Changing behaviour is necessary to address many of the threats facing human populations. However, identifying behaviour change interventions likely to be effective in particular contexts as a basis for improving them presents a major challenge. The Human Behaviour-Change Project harnesses the power of artificial intelligence and behavioural science to organise global evidence about behaviour change to predict outcomes in common and unknown behaviour change scenarios.","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",85,"2022-07-13 09:19:39","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",86,"2022-07-13 09:19:39","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",87,"2022-07-13 09:19:39","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",88,"2022-07-13 09:19:39","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",89,"2022-07-13 09:19:39","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",90,"2022-07-13 09:19:39","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",91,"2022-07-13 09:19:39","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",92,"2022-07-13 09:19:39","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
14,"M. Yazdani-Asrami, Mehran Taghipour-Gorjikolaie, Wenjuan Song, Min Zhang, W. Yuan","Prediction of Nonsinusoidal AC Loss of Superconducting Tapes Using Artificial Intelligence-Based Models",2020,"","","","",93,"2022-07-13 09:19:39","","10.1109/ACCESS.2020.3037685","","",,,,,14,7.00,3,5,2,"Current is no longer sinusoidal in modern electric networks because of widespread use of power electronic-based equipments and nonlinear loads. Usually AC loss is calculated for pure sinusoidal current, while it is no longer accurate when current is nonsinusoidal. On the other hand, efficiency of cooling system in large scale power devices is dependent on accurate estimation and prediction of the heat load caused by AC loss in design stage. Therefore, estimation of nonsinusoidal AC loss of high temperature superconducting (HTS) material would be of great interest for designers of large-scale superconducting devices. In this paper, at first nonsinusoidal AC loss of a typical HTS tape was calculated under distorted currents using H-formulation finite element method. Then, a range of artificial intelligence (AI) models were implemented to predict AC loss of a typical HTS tape. In order to find the best and more adaptive AI model for nonsinusoidal AC loss prediction, different regression models are evaluated using Support Vector Machine regression model, Generalized Linear regression model, Decision Tree regression model, Feed Forward Neural Network based model, Adaptive Neuro Fuzzy Inference System based model, and Radial Basis Function Neural Network (RBFNN) based model. In order to evaluate robustness of developed models cross-validation technique is implemented on experimental data. To compare the performance of different AI models, four prediction measures were used: Theil’s U coefficients (U_Accuracy and U_Quality), Root Mean Square Error (RMSE) and Regression value (R-value). Obtained results show that best performance belongs to RBFNN based model and then ANFIS based model. U coefficients and RMSE values are obtained less than 0.005 and R-Value is become close to one by using RBFNN based model for testing data, which indicates high accuracy prediction performance.","",""
14,"Claudia Gonzalez Viejo, S. Fuentes","Beer Aroma and Quality Traits Assessment Using Artificial Intelligence",2020,"","","","",94,"2022-07-13 09:19:39","","10.3390/fermentation6020056","","",,,,,14,7.00,7,2,2,"Increasing beer quality demands from consumers have put pressure on brewers to target specific steps within the beer-making process to modify beer styles and quality traits. However, this demands more robust methodologies to assess the final aroma profiles and physicochemical characteristics of beers. This research shows the construction of artificial intelligence (AI) models based on aroma profiles, chemometrics, and chemical fingerprinting using near-infrared spectroscopy (NIR) obtained from 20 commercial beers used as targets. Results showed that machine learning models obtained using NIR from beers as inputs were accurate and robust in the prediction of six important aromas for beer (Model 1; R = 0.91; b = 0.87) and chemometrics (Model 2; R = 0.93; b = 0.90). Additionally, two more accurate models were obtained from robotics (RoboBEER) to obtain the same aroma profiles (Model 3; R = 0.99; b = 1.00) and chemometrics (Model 4; R = 0.98; b = 1.00). Low-cost robotics and sensors coupled with computer vision and machine learning modeling could help brewers in the decision-making process to target specific consumer preferences and to secure higher consumer demands.","",""
14,"E. Kotter, E. Ranschaert","Challenges and solutions for introducing artificial intelligence (AI) in daily clinical workflow",2020,"","","","",95,"2022-07-13 09:19:39","","10.1007/s00330-020-07148-2","","",,,,,14,7.00,7,2,2,"","",""
14,"I. Tyukin, D. Higham, A. Gorban","On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems",2020,"","","","",96,"2022-07-13 09:19:39","","10.1109/IJCNN48605.2020.9207472","","",,,,,14,7.00,5,3,2,"In this work we present a formal theoretical framework for assessing and analyzing two classes of malevolent action towards generic Artificial Intelligence (AI) systems. Our results apply to general multi-class classifiers that map from an input space into a decision space, including artificial neural networks used in deep learning applications. Two classes of attacks are considered. The first class involves adversarial examples and concerns the introduction of small perturbations of the input data that cause misclassification. The second class, introduced here for the first time and named stealth attacks, involves small perturbations to the AI system itself. Here the perturbed system produces whatever output is desired by the attacker on a specific small data set, perhaps even a single input, but performs as normal on a validation set (which is unknown to the attacker).We show that in both cases, i.e., in the case of an attack based on adversarial examples and in the case of a stealth attack, the dimensionality of the AI’s decision-making space is a major contributor to the AI’s susceptibility. For attacks based on adversarial examples, a second crucial parameter is the absence of local concentrations in the data probability distribution, a property known as Smeared Absolute Continuity. According to our findings, robustness to adversarial examples requires either (a) the data distributions in the AI’s feature space to have concentrated probability density functions or (b) the dimensionality of the AI’s decision variables to be sufficiently small. We also show how to construct stealth attacks on high-dimensional AI systems that are hard to spot unless the validation set is made exponentially large.","",""
23,"K. Mouridsen, P. Thurner, G. Zaharchuk","Artificial Intelligence Applications in Stroke.",2020,"","","","",97,"2022-07-13 09:19:39","","10.1161/STROKEAHA.119.027479","","",,,,,23,11.50,8,3,2,"Management of stroke highly depends on information from imaging studies. Noncontrast computed tomography (CT) and magnetic resonance imaging (MRI) can both be used to distinguish between ischemic and hemorrhagic stroke, which is difficult based on clinical features. Hypodensity on CT and DWI hyperintensity on MRI identifies irreversibly damaged tissue, although the sensitivity of MRI is higher in the acute setting. Angiographic and perfusion imaging sequences can identify a large vessel occlusion and, along with perfusion imaging, can select patients for endovascular therapy. The FLAIR-DWI mismatch yields information about patients with unknown time of onset (including wake-up strokes). Stroke imaging also gives insight into prognosis, with current methods aiming to give a picture of the short-term consequences of successful reperfusion or continued large vessel occlusion. One important caveat about stroke imaging is that it must be done quickly, as faster treatment leads to better outcomes.1 However, most steps in the stroke imaging triage pathway require the presence of human radiologists and neurologists, and this is often the time-limiting step. The expertise required for these tasks may not be available at all sites or at all times. Therefore, there is interest in automated methods for stroke imaging evaluation. Artificial intelligence (AI) is a broad term reflecting the use of computers to perform tasks that humans may find difficult, often in ways that are hard to pinpoint. For example, although humans find high-level computation difficult, calculator technology is not considered AI because we know how to break this down into discrete steps and feel we understand it. However, facial recognition is a task that humans perform well, but an algorithm to identify faces is usually considered AI since we cannot articulate precisely how this is done. Machine learning (ML) is a subset of AI in which algorithms learn from the data itself without explicit programming. ML methods reflect a broad range of statistical techniques ranging from linear regression to more complex methods such as support vector machines and decision trees. ML methods can be further broken into supervised and unsupervised learning, which differ from one another in that the former requires access to gold standard labels although the latter attempts to find the answers implicitly in the data itself. While ML methods have grown more popular over recent years, the advent of a specific supervised ML method based on architectures resembling human neural networks over the past decade has led to a quantum leap in performance.2 This method, called deep learning (DL) because of many multiple internal layers, can be considered a transformative technology. Compared with previous methods that required humans to identify image features, a deep neural network trained on a dataset with known outputs can learn the best features for organizing the data. In this review, we will discuss ML methods applied to stroke imaging with an emphasis on DL applications. We refer to Figure for a graphical overview of the applications discussed in this review.","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",98,"2022-07-13 09:19:39","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",99,"2022-07-13 09:19:39","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",100,"2022-07-13 09:19:39","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"S. Goto, K. Mahara, L. Beussink-Nelson, H. Ikura, Y. Katsumata, J. Endo, H. Gaggin, S. J. Shah, Y. Itabashi, C. Macrae, R. Deo","Artificial Intelligence-Enabled, Fully Automated Detection of Cardiac Amyloidosis Using Electrocardiograms and Echocardiograms.",2020,"","","","",101,"2022-07-13 09:19:39","","10.1101/2020.07.02.20141028","","",,,,,11,5.50,1,11,2,"Although individually uncommon, rare diseases collectively affect over 350 million patients worldwide and are increasingly the target of therapeutic development efforts. Unfortunately, the pursuit and use of such therapies have been hindered by a common challenge: patients with specific rare diseases are difficult to identify, especially if the conditions resemble more prevalent disorders. Cardiac amyloidosis is one such rare disease, which is characterized by deposition of misfolded proteins within the heart muscle resulting in heart failure and death. In recent years, specific therapies have emerged for cardiac amyloidosis and several more are under investigation, but because cardiac amyloidosis is mistaken for common forms of heart failure, it is typically diagnosed late in its course. As a possible solution, artificial intelligence methods could enable automated detection of rare diseases, but model performance must address low disease prevalence. Here we present an automated multi-modality pipeline for cardiac amyloidosis detection using two neural-network models; one using electrocardiograms (ECG) and the second using echocardiographic videos as input. These models were trained and validated on 3 and 5 academic medical centers (AMC), respectively, in the United States and Japan. Both models had excellent accuracy for detecting cardiac amyloidosis with C-statistics of 0.85-0.92 and 0.91-1.00 for the ECG and echocardiography models, respectively, with the latter outperforming expert diagnosis. Simulating deployment on 13,906 and 7775 patients with ECG-echocardiography paired data for AMC2 and AMC3 indicated a positive predictive value (PPV) for the ECG model of 4% and 3% at 61% and 54% recall, respectively. Pre-screening with ECG enhanced the echocardiography model performance from PPV 23% and 20% to PPV 58% and 53% at 64% recall, respectively for AMC2 and AMC3. In conclusion, we have developed a robust pipeline to augment detection of cardiac amyloidosis, which should serve as a generalizable strategy for other rare and intermediate frequency cardiac diseases with established or emerging therapies.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",102,"2022-07-13 09:19:39","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
9,"S. Elkatatny","Real-Time Prediction of Rate of Penetration in S-Shape Well Profile Using Artificial Intelligence Models",2020,"","","","",103,"2022-07-13 09:19:39","","10.3390/s20123506","","",,,,,9,4.50,9,1,2,"Rate of penetration (ROP) is defined as the amount of removed rock per unit area per unit time. It is affected by several factors which are inseparable. Current established models for determining the ROP include the basic mathematical and physics equations, as well as the use of empirical correlations. Given the complexity of the drilling process, the use of artificial intelligence (AI) has been a game changer because most of the unknown parameters can now be accounted for entirely at the modeling process. The objective of this paper is to evaluate the ability of the optimized adaptive neuro-fuzzy inference system (ANFIS), functional neural networks (FN), random forests (RF), and support vector machine (SVM) models to predict the ROP in real time from the drilling parameters in the S-shape well profile, for the first time, based on the drilling parameters of weight on bit (WOB), drillstring rotation (DSR), torque (T), pumping rate (GPM), and standpipe pressure (SPP). Data from two wells were used for training and testing (Well A and Well B with 4012 and 1717 data points, respectively), and one well for validation (Well C) with 2500 data points. Well A and Well B data were combined in the training-testing phase and were randomly divided into a 70:30 ratio for training/testing. The results showed that the ANFIS, FN, and RF models could effectively predict the ROP from the drilling parameters in the S-shape well profile, while the accuracy of the SVM model was very low. The ANFIS, FN, and RF models predicted the ROP for the training data with average absolute percentage errors (AAPEs) of 9.50%, 13.44%, and 3.25%, respectively. For the testing data, the ANFIS, FN, and RF models predicted the ROP with AAPEs of 9.57%, 11.20%, and 8.37%, respectively. The ANFIS, FN, and RF models overperformed the available empirical correlations for ROP prediction. The ANFIS model estimated the ROP for the validation data with an AAPE of 9.06%, whereas the FN model predicted the ROP with an AAPE of 10.48%, and the RF model predicted the ROP with an AAPE of 10.43%. The SVM model predicted the ROP for the validation data with a very high AAPE of 30.05% and all empirical correlations predicted the ROP with AAPEs greater than 25%.","",""
9,"R. Haneef, M. Delnord, M. Vernay, E. Bauchet, R. Gaidelytė, H. Van Oyen, Z. Or, B. Pérez-Gómez, L. Palmieri, P. Achterberg, M. Tijhuis, M. Zaletel, S. Mathis-Edenhofer, O. Májek, H. Haaheim, H. Tolonen, A. Gallay","Innovative use of data sources: a cross-sectional study of data linkage and artificial intelligence practices across European countries",2020,"","","","",104,"2022-07-13 09:19:39","","10.1186/s13690-020-00436-9","","",,,,,9,4.50,1,17,2,"","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",105,"2022-07-13 09:19:39","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"R. Deo, Z. Yaseen, N. Al‐Ansari, Thong Nguyen-Huy, Trevor Ashley Mcpherson Langlands, Linda Galligan","Modern Artificial Intelligence Model Development for Undergraduate Student Performance Prediction: An Investigation on Engineering Mathematics Courses",2020,"","","","",106,"2022-07-13 09:19:39","","10.1109/access.2020.3010938","","",,,,,8,4.00,1,6,2,"A computationally efficient artificial intelligence (AI) model called Extreme Learning Machines (ELM) is adopted to analyze patterns embedded in continuous assessment to model the weighted score (WS) and the examination (EX) score in engineering mathematics courses at an Australian regional university. The student performance data taken over a six-year period in multiple courses ranging from the mid- to the advanced level and a diverse course offering mode (i.e., on-campus, ONC, and online, ONL) are modelled by ELM and further benchmarked against competing models: random forest (RF) and Volterra. With the assessments and examination marks as key predictors of WS (leading to a grade in the mid-level course), ELM (with respect to RF and Volterra) outperformed its counterpart models both for the ONC and the ONL offer. This generated relative prediction error in the testing phase, of only 0.74%, compared to about 3.12% and 1.06%, respectively, while for the ONL offer, the prediction errors were only 0.51% compared to about 3.05% and 0.70%. In modelling the student performance in advanced engineering mathematics course, ELM registered slightly larger errors: 0.77% (vs. 22.23% and 1.87%) for ONC and 0.54% (vs. 4.08% and 1.31%) for the ONL offer. This study advocates a pioneer implementation of a robust AI methodology to uncover relationships among student learning variables, developing teaching and learning intervention and course health checks to address issues related to graduate outcomes, and student learning attributes in the higher education sector.","",""
7,"S. Harmon, Palak G Patel, T. Sanford, Isabelle Caven, Rachael Iseman, T. Vidotto, C. Picanço, J. Squire, Samira Masoudi, Sherif Mehralivand, P. Choyke, D. Berman, B. Turkbey, T. Jamaspishvili","High throughput assessment of biomarkers in tissue microarrays using artificial intelligence: PTEN loss as a proof-of-principle in multi-center prostate cancer cohorts",2020,"","","","",107,"2022-07-13 09:19:39","","10.1038/s41379-020-00674-w","","",,,,,7,3.50,1,14,2,"","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",108,"2022-07-13 09:19:39","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
8,"Dimitri Grün, F. Rudolph, Nils Gumpfer, J. Hannig, L. Elsner, B. Jeinsen, C. Hamm, A. Rieth, Michael Guckert, T. Keller","Identifying Heart Failure in ECG Data With Artificial Intelligence—A Meta-Analysis",2021,"","","","",109,"2022-07-13 09:19:39","","10.3389/fdgth.2020.584555","","",,,,,8,8.00,1,10,1,"Introduction: Electrocardiography (ECG) is a quick and easily accessible method for diagnosis and screening of cardiovascular diseases including heart failure (HF). Artificial intelligence (AI) can be used for semi-automated ECG analysis. The aim of this evaluation was to provide an overview of AI use in HF detection from ECG signals and to perform a meta-analysis of available studies. Methods and Results: An independent comprehensive search of the PubMed and Google Scholar database was conducted for articles dealing with the ability of AI to predict HF based on ECG signals. Only original articles published in peer-reviewed journals were considered. A total of five reports including 57,027 patients and 579,134 ECG datasets were identified including two sets of patient-level data and three with ECG-based datasets. The AI-processed ECG data yielded areas under the receiver operator characteristics curves between 0.92 and 0.99 to identify HF with higher values in ECG-based datasets. Applying a random-effects model, an sROC of 0.987 was calculated. Using the contingency tables led to diagnostic odds ratios ranging from 3.44 [95% confidence interval (CI) = 3.12–3.76] to 13.61 (95% CI = 13.14–14.08) also with lower values in patient-level datasets. The meta-analysis diagnostic odds ratio was 7.59 (95% CI = 5.85–9.34). Conclusions: The present meta-analysis confirms the ability of AI to predict HF from standard 12-lead ECG signals underlining the potential of such an approach. The observed overestimation of the diagnostic ability in artificial ECG databases compared to patient-level data stipulate the need for robust prospective studies.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",110,"2022-07-13 09:19:39","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
8,"J. Kwon, Kyung-Hee Kim, K. Jeon, Soo Youn Lee, Jinsik Park, B. Oh","Artificial intelligence algorithm for predicting cardiac arrest using electrocardiography",2020,"","","","",111,"2022-07-13 09:19:39","","10.1186/s13049-020-00791-0","","",,,,,8,4.00,1,6,2,"","",""
4,"S. Hoffman, Andy Podgurski","Artificial Intelligence and Discrimination in Health Care",2020,"","","","",112,"2022-07-13 09:19:39","","","","",,,,,4,2.00,2,2,2,"Artificial intelligence (AI) holds great promise for improved health-care outcomes. It has been used to analyze tumor images, to help doctors choose among different treatment options, and to combat the COVID-19 pandemic. But AI also poses new hazards. This Article focuses on a particular type of health-care harm that has thus far evaded significant legal scrutiny. The harm is algorithmic discrimination.    Algorithmic discrimination in healthcare occurs with surprising frequency. A well-known example is an algorithm used to identify candidates for “high risk care management” programs that routinely failed to refer racial minorities for these beneficial services. Some algorithms deliberately adjust for race in ways that hurt minority patients. For example, such algorithms have regularly underestimated African Americans’ risks of kidney stones, death from heart failure, and other medical problems.    The Article argues that algorithmic discrimination in medicine can violate civil rights laws such as Title VI and Section 1557 of the Affordable Care Act when it exacerbates health disparities or perpetuates inequities. It urges that algorithmic fairness constitute a key element in designing, validating, and implementing AI and that both legal and technical tools be deployed to promote fairness. To that end, we call for the reintroduction of the disparate impact theory as a robust litigation tool in the health-care arena and for the passage of an algorithmic accountability act. We also detail technical measures that AI developers and users should implement.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",113,"2022-07-13 09:19:39","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
2,"Sara Aqab, Muhammad Usman","Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing",2020,"","","","",114,"2022-07-13 09:19:39","","10.14569/ijacsa.2020.0110719","","",,,,,2,1.00,1,2,2,"Due to increased usage of digital technologies in all sectors and in almost all day to day activities to store and pass information, Handwriting character recognition has become a popular subject of research. Handwriting remains relevant, but people still want to have Handwriting copies converted into electronic copies that can be communicated and stored electronically. Handwriting character recognition refers to the computer's ability to detect and interpret intelligible Handwriting input from Handwriting sources such as touch screens, photographs, paper documents, and other sources. Handwriting characters remain complex since different individuals have different handwriting styles. This paper aims to report the development of a Handwriting character recognition system that will be used to read students and lectures Handwriting notes. The development is based on an artificial neural network, which is a field of study in artificial intelligence. Different techniques and methods are used to develop a Handwriting character recognition system. However, few of them focus on neural networks. The use of neural networks for recognizing Handwriting characters is more efficient and robust compared with other computing techniques. The paper also outlines the methodology, design, and architecture of the Handwriting character recognition system and testing and results of the system development. The aim is to demonstrate the effectiveness of neural networks for Handwriting character recognition.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",115,"2022-07-13 09:19:39","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",116,"2022-07-13 09:19:39","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
0,"Vinayak Majhi, S. Paul","Artificial Intelligence in Bioinformatics",2020,"","","","",117,"2022-07-13 09:19:39","","10.1007/978-981-15-2620-6_12","","",,,,,0,0.00,0,2,2,"","",""
6,"Tanya Tiwari, Tanuj Tiwari, Sanjay Tiwari","How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?",2018,"","","","",118,"2022-07-13 09:19:39","","10.23956/IJARCSSE.V8I2.569","","",,,,,6,1.50,2,3,4,"There is a lot of confusion these days about Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL). A computer system able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. Artificial Intelligence has made it possible. Deep learning is a subset of machine learning, and machine learning is a subset of AI, which is an umbrella term for any computer program that does something smart. In other words, all machine learning is AI, but not all AI is machine learning, and so forth. Machine Learning represents a key evolution in the fields of computer science, data analysis, software engineering, and artificial intelligence. Machine learning (ML)is a vibrant field of research, with a range of exciting areas for further development across different methods and applications. These areas include algorithmic interpretability, robustness, privacy, fairness, inference of causality, human-machine interaction, and security. The goal of ML is never to make “perfect” guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful. Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones. This paper gives an overview of artificial intelligence, machine learning & deep learning techniques and compare these techniques.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",119,"2022-07-13 09:19:39","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",120,"2022-07-13 09:19:39","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
2,"Nistha Tandiya, E. Colbert, V. Marojevic, Jeffrey H. Reed","Biologically Inspired Artificial Intelligence Techniques",2018,"","","","",121,"2022-07-13 09:19:39","","10.1007/978-3-319-77492-3_13","","",,,,,2,0.50,1,4,4,"","",""
66,"Keping Yu, Zhiwei Guo, Yulian Shen, Wei Wang, Jerry Chun‐wei Lin, Takuro Sato","Secure Artificial Intelligence of Things for Implicit Group Recommendations",2021,"","","","",122,"2022-07-13 09:19:39","","10.1109/JIOT.2021.3079574","","",,,,,66,66.00,11,6,1,"The emergence of Artificial Intelligence of Things (AIoT) has provided novel insights for many social computing applications, such as group recommender systems. As the distances between people have been greatly shortened, there has been more general demand for the provision of personalized services aimed at groups instead of individuals. The existing methods for capturing group-level preference features from individuals have mostly been established via aggregation and face two challenges: 1) secure data management workflows are absent and 2) implicit preference feedback is ignored. To tackle these current difficulties, this article proposes secure AIoT for implicit group recommendations (SAIoT-GRs). For the hardware module, a secure Internet of Things structure is developed as the bottom support platform. For the software module, a collaborative Bayesian network model and noncooperative game are introduced as algorithms. This secure AIoT architecture is able to maximize the advantages of the two modules. In addition, a large number of experiments are carried out to evaluate the performance of SAIoT-GR in terms of efficiency and robustness.","",""
199,"Dong Wook Kim, H. Jang, K. Kim, Youngbin Shin, S. Park","Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers",2019,"","","","",123,"2022-07-13 09:19:39","","10.3348/kjr.2019.0025","","",,,,,199,66.33,40,5,3,"Objective To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images. Materials and Methods PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals. Results Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals. Conclusion Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms.","",""
9,"E. Natsheh","Hybrid Power Systems Energy Management Based on Artificial Intelligence",2020,"","","","",124,"2022-07-13 09:19:39","","","","",,,,,9,4.50,9,1,2,"This thesis presents a novel adaptive scheme for energy management in stand-alone hybrid power systems. The proposed management system is designed to manage the power flow between the hybrid power system and energy storage elements in order to satisfy the load requirements based on artificial neural network (ANN) and fuzzy logic controllers.   The neural network controller is employed to achieve the maximum power point (MPP) for different types of photovoltaic (PV) panels, based on Levenberg Marquardt learning algorithm. The statistical analysis of the results indicates that the R2 value for the testing set was 0.99.   The advance fuzzy logic controller is developed to distribute the power among the hybrid system and to manage the charge and discharge current flow for performance optimization.  The developed management system performance was assessed using a hybrid system comprises PV panels, wind turbine, battery storage, and proton exchange membrane fuel cell (PEMFC). To improve the generating performance of the PEMFC and prolong its life, stack temperature is controlled by a fuzzy logic controller.  Moreover, perturb and observe (P&O) algorithm with two different controller techniques - the linear PI and the non-linear passivity-based controller (PBC) - are provided for a comparison with the proposed MPPT controller system. The comparison revealed the robustness of the proposed PV control system for solar irradiance and load resistance changes.  Real-time measured parameters and practical load profiles are used as inputs for the developed management system. The proposed model and its control strategy offer a proper tool for optimizing the hybrid power system performance, such as the one used in smart-house applications.  The research work also led to a new approach in monitoring PV power stations. The monitoring system enables system degradation early detection by calculating the residual difference between the model predicted and the actual measured power parameters. Measurements were taken over 21 month’s period; using hourly average irradiance and cell temperature. Good agreement was achieved between the theoretical simulation and the real time measurement taken the online grid connected solar power plant.","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",125,"2022-07-13 09:19:39","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",126,"2022-07-13 09:19:39","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",127,"2022-07-13 09:19:39","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
169,"Amisha, Paras Malik, Monika Pathania, V. Rathaur","Overview of artificial intelligence in medicine",2019,"","","","",128,"2022-07-13 09:19:39","","10.4103/jfmpc.jfmpc_440_19","","",,,,,169,56.33,42,4,3,"Background: Artificial intelligence (AI) is the term used to describe the use of computers and technology to simulate intelligent behavior and critical thinking comparable to a human being. John McCarthy first described the term AI in 1956 as the science and engineering of making intelligent machines. Objective: This descriptive article gives a broad overview of AI in medicine, dealing with the terms and concepts as well as the current and future applications of AI. It aims to develop knowledge and familiarity of AI among primary care physicians. Materials and Methods: PubMed and Google searches were performed using the key words 'artificial intelligence'. Further references were obtained by cross-referencing the key articles. Results: Recent advances in AI technology and its current applications in the field of medicine have been discussed in detail. Conclusions: AI promises to change the practice of medicine in hitherto unknown ways, but many of its practical applications are still in their infancy and need to be explored and developed better. Medical professionals also need to understand and acclimatize themselves with these advances for better healthcare delivery to the masses.","",""
132,"Y. Yang, C. S. Bang","Application of artificial intelligence in gastroenterology",2019,"","","","",129,"2022-07-13 09:19:39","","10.3748/wjg.v25.i14.1666","","",,,,,132,44.00,66,2,3,"Artificial intelligence (AI) using deep-learning (DL) has emerged as a breakthrough computer technology. By the era of big data, the accumulation of an enormous number of digital images and medical records drove the need for the utilization of AI to efficiently deal with these data, which have become fundamental resources for a machine to learn by itself. Among several DL models, the convolutional neural network showed outstanding performance in image analysis. In the field of gastroenterology, physicians handle large amounts of clinical data and various kinds of image devices such as endoscopy and ultrasound. AI has been applied in gastroenterology in terms of diagnosis, prognosis, and image analysis. However, potential inherent selection bias cannot be excluded in the form of retrospective study. Because overfitting and spectrum bias (class imbalance) have the possibility of overestimating the accuracy, external validation using unused datasets for model development, collected in a way that minimizes the spectrum bias, is mandatory. For robust verification, prospective studies with adequate inclusion/exclusion criteria, which represent the target populations, are needed. DL has its own lack of interpretability. Because interpretability is important in that it can provide safety measures, help to detect bias, and create social acceptance, further investigations should be performed.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",130,"2022-07-13 09:19:39","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",131,"2022-07-13 09:19:39","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
50,"F. Kunz, A. Stellzig-Eisenhauer, F. Zeman, J. Boldt","Artificial intelligence in orthodontics",2019,"","","","",132,"2022-07-13 09:19:39","","10.1007/s00056-019-00203-8","","",,,,,50,16.67,13,4,3,"","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",133,"2022-07-13 09:19:39","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",134,"2022-07-13 09:19:39","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",135,"2022-07-13 09:19:39","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
51,"Lu Minh Le, H. Ly, B. Pham, Vuong Minh Le, T. Pham, Duy-Hung Nguyen, Xuan-Tuan Tran, Tien-Thinh Le","Hybrid Artificial Intelligence Approaches for Predicting Buckling Damage of Steel Columns Under Axial Compression",2019,"","","","",136,"2022-07-13 09:19:39","","10.3390/ma12101670","","",,,,,51,17.00,6,8,3,"This study aims to investigate the prediction of critical buckling load of steel columns using two hybrid Artificial Intelligence (AI) models such as Adaptive Neuro-Fuzzy Inference System optimized by Genetic Algorithm (ANFIS-GA) and Adaptive Neuro-Fuzzy Inference System optimized by Particle Swarm Optimization (ANFIS-PSO). For this purpose, a total number of 57 experimental buckling tests of novel high strength steel Y-section columns were collected from the available literature to generate the dataset for training and validating the two proposed AI models. Quality assessment criteria such as coefficient of determination (R2), Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) were used to validate and evaluate the performance of the prediction models. Results showed that both ANFIS-GA and ANFIS-PSO had a strong ability in predicting the buckling load of steel columns, but ANFIS-PSO (R2 = 0.929, RMSE = 60.522 and MAE = 44.044) was slightly better than ANFIS-GA (R2 = 0.916, RMSE = 65.371 and MAE = 48.588). The two models were also robust even with the presence of input variability, as investigated via Monte Carlo simulations. This study showed that the hybrid AI techniques could help constructing an efficient numerical tool for buckling analysis.","",""
47,"Chengjie Zheng, T. V. Johnson, Aakriti Garg, Michael V. Boland","Artificial intelligence in glaucoma",2019,"","","","",137,"2022-07-13 09:19:39","","10.1097/ICU.0000000000000552","","",,,,,47,15.67,12,4,3,"Purpose of review The use of computers has become increasingly relevant to medical decision-making, and artificial intelligence methods have recently demonstrated significant advances in medicine. We therefore provide an overview of current artificial intelligence methods and their applications, to help the practicing ophthalmologist understand their potential impact on glaucoma care. Recent findings Techniques used in artificial intelligence can successfully analyze and categorize data from visual fields, optic nerve structure [e.g., optical coherence tomography (OCT) and fundus photography], ocular biomechanical properties, and a combination thereof to identify disease severity, determine disease progression, and/or recommend referral for specialized care. Algorithms have become increasingly complex in recent years, utilizing both supervised and unsupervised methods of artificial intelligence. Impressive performance of these algorithms on previously unseen data has been reported, often outperforming standard global indices and expert observers. However, there remains no clearly defined gold standard for determining the presence and severity of glaucoma, which undermines the training of these algorithms. To improve upon existing methodologies, future work must employ more robust definitions of disease, optimize data inputs for artificial intelligence analysis, and improve methods of extracting knowledge from learned results. Summary Artificial intelligence has the potential to revolutionize the screening, diagnosis, and classification of glaucoma, both through the automated processing of large data sets, and by earlier detection of new disease patterns. In addition, artificial intelligence holds promise for fundamentally changing research aimed at understanding the development, progression, and treatment of glaucoma, by identifying novel risk factors and by evaluating the importance of existing ones.","",""
41,"C. Macrae","Governing the safety of artificial intelligence in healthcare",2019,"","","","",138,"2022-07-13 09:19:39","","10.1136/bmjqs-2019-009484","","",,,,,41,13.67,41,1,3,"Artificial intelligence (AI) has enormous potential to improve the safety of healthcare, from increasing diagnostic accuracy,1 to optimising treatment planning,2 to forecasting outcomes of care.3 However, integrating AI technologies into the delivery of healthcare is likely to introduce a range of new risks and amplify existing ones. For instance, failures in widely used software have the potential to quickly affect large numbers of patients4; hidden assumptions in underlying data and models can lead to AI systems delivering dangerous recommendations that are insensitive to local care processes,5 6 and opaque AI techniques such as deep learning can make explaining and learning from failure extremely difficult.7 8 To maximise the benefits of AI in healthcare and to build trust among patients and practitioners, it will therefore be essential to robustly govern the risks that AI poses to patient safety.  In a recent review in this journal, Challen and colleagues present an important and timely analysis of some of the key technological risks associated with the application of machine learning in clinical settings.9 Machine learning is a subfield of AI that focuses on the development of algorithms that are automatically derived and optimised through exposure to large quantities of exemplar ‘training’ data.10 The outputs of machine learning algorithms are essentially classifications of patterns that provide some sort of prediction—for instance, predicting whether an image shows a malignant melanoma or a benign mole.11 Some of the basic techniques of machine learning have existed for half a century or more, but progress in the field has accelerated rapidly due to advances in the development of ‘deep’ artificial neural networks12 combined with huge increases in computational power and the availability of enormous quantities of data. These techniques have underpinned recent public demonstrations of AI systems …","",""
0,"Changyeob Shin","Vision-Guided Autonomous Surgical Subtasks via Surgical Robots with Artificial Intelligence",2020,"","","","",139,"2022-07-13 09:19:39","","","","",,,,,0,0.00,0,1,2,"Author(s): Shin, Changyeob | Advisor(s): Rosen, Jacob | Abstract: The introduction of automation into surgery may redefine the role of surgeons in operating rooms. While the majority of the manipulation will be performed autonomously by surgical robots, the surgeons may focus on decision-making procedures. This will drastically reduce the burden to surgeons by allowing them to instead interpret the abundant and intelligent information from the system, and will enhance the surgical outcome. To introduce the automation into surgery, the surgical robots are required to have: 1) high precision, 2) motion planning capabilities, and 3) scene understanding. Currently, surgical robots are commonly designed as cable-driven due to safety and several benefits such as low inertia. However, the cable-driven system has low precision because of cable stretch and long chains of cables. Therefore, a new control scheme of cable-driven surgical robots should be developed to overcome these limitations. Surgery is a complicated task consisting of multiple subtasks. To achieve the intermediate steps, motion planner should be developed. In surgery, the manipulation target objects are mostly soft tissue which introduces challenges in modeling the dynamics between the tool and the soft tissue. The motion planner should deal with the unknown dynamics while accomplishing each task. The surgical environment is further complicated by the many blood-covered anatomical structures. Surgeons use the visual feedback through an endoscope camera or other imaging devices, which provide rich information. Although the imaging devices are useful in understanding the surrounding anatomy, images from the devices are high-dimensional and it is difficult to process using algorithms to get high-level information. Therefore, vision-based perception algorithms to understand the relevant anatomy should be developed.This dissertation addresses the three problems above. In chapter two, a hybrid control scheme which utilizes both model-based and data-driven methods is introduced to improve the precision of the cable-driven surgical robots and robustness to hand-eye calibration errors. The convergence of the controller is shown theoretically and experimentally with the Raven IV. Additionally, the efficacy of the controller to clinical tasks is shown by demonstrating the autonomous operations of needle transfer and tissue debridement tasks. In chapter three, learning-based path planning algorithms are proposed for autonomous soft tissue manipulation. The planning algorithms learn the dynamics between the motion of a surgical tool and soft tissue, and the internal controller uses the learned dynamics to manipulate the soft tissue. The performance of developed algorithms is verified on a designed simulation and a robot experiment with the Raven IV. In chapter four, the semantic segmentation algorithm of the optical coherence tomography images for the automated lens extraction is presented. The algorithm uses the deep learning method and provides the capability of understanding the cross-sectional view of the eye anatomy. Furthermore, this segmentation algorithm is incorporated into the Intraocular Robotic Interventional and Surgical System (IRISS) to realize the semi-autonomous lens removal. The experimental results on 7 ex vivo pig eyes verified the efficacy of the developed framework.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",140,"2022-07-13 09:19:39","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
35,"J. Shapey, Guotai Wang, R. Dorent, A. Dimitriadis, Wenqi Li, I. Paddick, N. Kitchen, S. Bisdas, S. Saeed, S. Ourselin, R. Bradford, Tom Kamiel Magda Vercauteren","An artificial intelligence framework for automatic segmentation and volumetry of vestibular schwannomas from contrast-enhanced T1-weighted and high-resolution T2-weighted MRI.",2019,"","","","",141,"2022-07-13 09:19:39","","10.3171/2019.9.JNS191949","","",,,,,35,11.67,4,12,3,"OBJECTIVE Automatic segmentation of vestibular schwannomas (VSs) from MRI could significantly improve clinical workflow and assist in patient management. Accurate tumor segmentation and volumetric measurements provide the best indicators to detect subtle VS growth, but current techniques are labor intensive and dedicated software is not readily available within the clinical setting. The authors aim to develop a novel artificial intelligence (AI) framework to be embedded in the clinical routine for automatic delineation and volumetry of VS.   METHODS Imaging data (contrast-enhanced T1-weighted [ceT1] and high-resolution T2-weighted [hrT2] MR images) from all patients meeting the study's inclusion/exclusion criteria who had a single sporadic VS treated with Gamma Knife stereotactic radiosurgery were used to create a model. The authors developed a novel AI framework based on a 2.5D convolutional neural network (CNN) to exploit the different in-plane and through-plane resolutions encountered in standard clinical imaging protocols. They used a computational attention module to enable the CNN to focus on the small VS target and propose a supervision on the attention map for more accurate segmentation. The manually segmented target tumor volume (also tested for interobserver variability) was used as the ground truth for training and evaluation of the CNN. We quantitatively measured the Dice score, average symmetric surface distance (ASSD), and relative volume error (RVE) of the automatic segmentation results in comparison to manual segmentations to assess the model's accuracy.   RESULTS Imaging data from all eligible patients (n = 243) were randomly split into 3 nonoverlapping groups for training (n = 177), hyperparameter tuning (n = 20), and testing (n = 46). Dice, ASSD, and RVE scores were measured on the testing set for the respective input data types as follows: ceT1 93.43%, 0.203 mm, 6.96%; hrT2 88.25%, 0.416 mm, 9.77%; combined ceT1/hrT2 93.68%, 0.199 mm, 7.03%. Given a margin of 5% for the Dice score, the automated method was shown to achieve statistically equivalent performance in comparison to an annotator using ceT1 images alone (p = 4e-13) and combined ceT1/hrT2 images (p = 7e-18) as inputs.   CONCLUSIONS The authors developed a robust AI framework for automatically delineating and calculating VS tumor volume and have achieved excellent results, equivalent to those achieved by an independent human annotator. This promising AI technology has the potential to improve the management of patients with VS and potentially other brain tumors.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",142,"2022-07-13 09:19:39","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
29,"David Valle-Cruz, E. A. R. Gómez, Rodrigo Sandoval-Almazán, J. I. Criado","A Review of Artificial Intelligence in Government and its Potential from a Public Policy Perspective",2019,"","","","",143,"2022-07-13 09:19:39","","10.1145/3325112.3325242","","",,,,,29,9.67,7,4,3,"Artificial intelligence (AI) is the latest trend being implemented in the public sector. Recent advances in this field and the AI explosion in the private sector have served to promote a revolution for government, public service management, accountability, and public value. Incipient research to understand, conceptualize and express challenges and limitations is now ongoing. This paper is the first approach in such a direction; our research question is: What are the current AI trends in the public sector? In order to achieve that goal, we collected 78 papers related to this new field in recent years. We also used a public policy framework to identify future areas of implementation for this trend. We found that only normative and exploratory papers have been published so far and there are a lot of public policy challenges facing in this area, and that AI implementation results are unknown and unexpected; since there may be great benefits for governments and society, but, on the other hand, it may have negative results like the so-called ”algorithmic bias” of AI when making important decisions for social development. However, we consider that AI has potential benefits in the public health, public policies on climate change, public management, decision-making, disaster prevention and response, improving government-citizen interaction, personalization of services, interoperability, analyzing large amounts of data, detecting abnormalities and patterns, and discovering new solutions through dynamic models and simulation in real time.","",""
7,"Mir Riyanul Islam, Mobyen Uddin Ahmed, Shaibal Barua, S. Begum","A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks",2022,"","","","",144,"2022-07-13 09:19:39","","10.3390/app12031353","","",,,,,7,7.00,2,4,1,"Artificial intelligence (AI) and machine learning (ML) have recently been radically improved and are now being employed in almost every application domain to develop automated or semi-automated systems. To facilitate greater human acceptability of these systems, explainable artificial intelligence (XAI) has experienced significant growth over the last couple of years with the development of highly accurate models but with a paucity of explainability and interpretability. The literature shows evidence from numerous studies on the philosophy and methodologies of XAI. Nonetheless, there is an evident scarcity of secondary studies in connection with the application domains and tasks, let alone review studies following prescribed guidelines, that can enable researchers’ understanding of the current trends in XAI, which could lead to future research for domain- and application-specific method development. Therefore, this paper presents a systematic literature review (SLR) on the recent developments of XAI methods and evaluation metrics concerning different application domains and tasks. This study considers 137 articles published in recent years and identified through the prominent bibliographic databases. This systematic synthesis of research articles resulted in several analytical findings: XAI methods are mostly developed for safety-critical domains worldwide, deep learning and ensemble models are being exploited more than other types of AI/ML models, visual explanations are more acceptable to end-users and robust evaluation metrics are being developed to assess the quality of explanations. Research studies have been performed on the addition of explanations to widely used AI/ML models for expert users. However, more attention is required to generate explanations for general users from sensitive domains such as finance and the judicial system.","",""
27,"Jing Zhang, Chao-Kai Wen, Shi Jin, Geoffrey Y. Li","Artificial Intelligence-Aided Receiver for a CP-Free OFDM System: Design, Simulation, and Experimental Test",2019,"","","","",145,"2022-07-13 09:19:39","","10.1109/ACCESS.2019.2914928","","",,,,,27,9.00,7,4,3,"Orthogonal frequency division multiplexing (OFDM), usually with sufficient cyclic prefix (CP), has been widely applied in various communication systems. The CP in OFDM consumes additional resource and reduces spectrum and energy efficiency. However, channel estimation and signal detection are very challenging for CP-free OFDM systems. In this paper, we propose a novel artificial intelligence (AI)-aided receiver (AI receiver) for a CP-free OFDM system. The AI receiver includes a channel estimation neural network (CE-NET) and a signal detection neural network based on orthogonal approximate message passing (OAMP), called OAMP-NET. The CE-NET is initialized by the least-square channel estimation algorithm and refined by a linear minimum mean-squared error neural network. The OAMP-NET is established by unfolding the iterative OAMP algorithm and adding several trainable parameters to improve the detection performance. We first investigate their performance under different channel models through extensive simulation and then establish a real transmission system using a 5G rapid prototyping system for an over-the-air (OTA) test. Based on our study, the AI receiver can estimate time-varying channels with a single training phase. It also has great robustness to various imperfections and has better performance than those competitive algorithms, especially for high-order modulation. The OTA test further verifies its feasibility to real environments and indicates its potential for future communications systems.","",""
21,"D. Ting, M. Ang, J. Mehta, D. Ting","Artificial intelligence-assisted telemedicine platform for cataract screening and management: a potential model of care for global eye health",2019,"","","","",146,"2022-07-13 09:19:39","","10.1136/bjophthalmol-2019-315025","","",,,,,21,7.00,5,4,3,"Artificial intelligence (AI) is the fourth industrial revolution.1 Deep learning is a robust machine learning technique that uses convolutional neural network to perform multilevel data abstraction without the need for manual feature engineering.2 In ophthalmology, many studies showed comparable, if not better, diagnostic performance in using AI to screen, diagnose, predict and monitor various eye conditions on fundus photographs and optical coherence tomography,3 4 including diabetic retinopathy (DR),5 age-related macular degeneration,6 glaucoma,7 retinopathy of prematurity (ROP).8   To date, many countries have reported well-established telemedicine programme to screen for DR and ROP,9–12 but limited for cataracts. Cataract is the leading cause of reversible blindness, affecting approximately 12.6 million (3.4–28.7 million) worldwide.13 14 The prevalence of cataract-related visual impairment also varies between high-income and low-income countries, with the latter having poorer access to tertiary care.13 In this issue, Wu et al 15 reported an AI-integrated telemedicine platform to screen and refer patients with cataract. This article consists of two parts: (1) the first part focusing on the AI system in detection of three tasks (capture mode, cataract diagnosis and referable cataract) and (2) the second part describing how these AI algorithms could be integrated in the telemedicine platform for real-world operational use. In this study, the referable cases were defined as: (1) grade 3 and grade 4 nuclear sclerotic …","",""
22,"Rushikesh S. Joshi, Alexander F. Haddad, Darryl Lau, C. Ames","Artificial Intelligence for Adult Spinal Deformity",2019,"","","","",147,"2022-07-13 09:19:39","","10.14245/ns.1938414.207","","",,,,,22,7.33,6,4,3,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery.","",""
23,"B. Chin-Yee, Ross E. G. Upshur","Three Problems with Big Data and Artificial Intelligence in Medicine",2019,"","","","",148,"2022-07-13 09:19:39","","10.1353/pbm.2019.0012","","",,,,,23,7.67,12,2,3,"ABSTRACT:The rise of big data and artificial intelligence (AI) in health care has engendered considerable excitement, claiming to improve approaches to diagnosis, prognosis, and treatment. Amidst the enthusiasm, the philosophical assumptions that underlie the big data and AI movement in medicine are rarely examined. This essay outlines three philosophical challenges faced by this movement: (1) the epistemological-ontological problem arising from the theory-ladenness of big data and measurement; (2) the epistemological-logical problem resulting from the inherent limitations of algorithms and attendant issues of reliability and interpretability; and (3) the phenomenological problem concerning the irreducibility of human experience to quantitative data. These philosophical issues demonstrate several important challenges for these technologies that must be considered prior to their integration into clinical care. Our article aims to initiate a critical dialogue on the impact of big data and AI in health care in order to allow for more robust evaluation of these technologies and to aid in the development of approaches to clinical care that better serve clinicians and their patients.","",""
20,"I. Pavlenko, J. Trojanowska, V. Ivanov, O. Liaposhchenko","PARAMETER IDENTIFICATION OF HYDRO-MECHANICAL PROCESSES USING ARTIFICIAL INTELLIGENCE SYSTEMS",2019,"","","","",149,"2022-07-13 09:19:39","","10.17683/ijomam.issue5.3","","",,,,,20,6.67,5,4,3,"The article is aimed at developing the comprehensive approach of parameter identification of complicated hydro-mechanical system by means of artificial intelligence systems (AIS) using artificial neural networks (ANN) and genetic algorithms (GA). The scientific novelty of the proposed method is inconsequent implementation of numerical analysis approach (e. g., FEM and CFD simulations), mathematical modeling of hydro-mechanical processes using the quasilinear regression procedure (QLRP), and artificial intelligence systems. Algorithms and related design schemes for implementation of the abovementioned technique are proposed for solving the interdisciplinary problems of aero-elastic interaction of gas-dispersed flow with the previously deformed flexible plates in a separation channel, static calculations of fixtures for parts manufacturing, as well as dynamic analysis of centrifugal compressors’ rotors. All the presented has a significant advantage in comparison with the direct solving of the abovementioned problems. This advantage is in the ability of the comprehensive sequence “FEM / CFD – ANN / GA – QLRP” to predict the solutions of highly nonlinear mathematical models describing hydro-mechanical processes with uncertainties. As a result, unknown parameters of the mathematical models describing the complicated hydro-mechanical interactions are refined under an incompleteness of the initial data.","",""
16,"Wang Yiying, Zang Yeze","Cryptocurrency Price Analysis with Artificial Intelligence",2019,"","","","",150,"2022-07-13 09:19:39","","10.1109/INFOMAN.2019.8714700","","",,,,,16,5.33,8,2,3,"Cryptocurrency is playing an increasingly important role in reshaping the financial system due to its growing popular appeal and mechant acceptance. While many people are making investments in Cryptocurrency, the dynamical features, uncertainty, the predictability of Cryptocurrency are still mostly unknown, which dramatically risk the investments. It is a matter to try to understand the factors that infiuence the value formation. In this study, we use advanced artificial intelligence frameworks of fully connected Artificial Neural Network (ANN) and Long Short-Term Memory (LSTM) Recurrent Neural Network to analyse the price dynamics of Bitcoin, Etherum, and Ripple. We find that ANN tends to rely more on long-term history while LSTM tends to rely more on short-term dynamics, which indicate the efficiency of LSTM to utilise useful information hidden in historical memory is stronger than ANN. However, given enough historical information ANN can achieve a similar accuracy, compared with LSTM. This study provides a unique demonstration that Cryptocurrency market price is predictable. However, the explanation of the predictability could vary depending on the nature of the involved machine-learning model.","",""
16,"K. Denecke, E. Gabarron, R. Grainger, S. Konstantinidis, A. Lau, O. Rivera-Romero, T. Miron-Shatz, M. Merolli","Artificial Intelligence for Participatory Health: Applications, Impact, and Future Implications",2019,"","","","",151,"2022-07-13 09:19:39","","10.1055/s-0039-1677902","","",,,,,16,5.33,2,8,3,"Summary Objective : Artificial intelligence (AI) provides people and professionals working in the field of participatory health informatics an opportunity to derive robust insights from a variety of online sources. The objective of this paper is to identify current state of the art and application areas of AI in the context of participatory health. Methods : A search was conducted across seven databases (PubMed, Embase, CINAHL, PsychInfo, ACM Digital Library, IEEExplore, and SCOPUS), covering articles published since 2013. Additionally, clinical trials involving AI in participatory health contexts registered at clinicaltrials.gov were collected and analyzed. Results : Twenty-two articles and 12 trials were selected for review. The most common application of AI in participatory health was the secondary analysis of social media data: self-reported data including patient experiences with healthcare facilities, reports of adverse drug reactions, safety and efficacy concerns about over-the-counter medications, and other perspectives on medications. Other application areas included determining which online forum threads required moderator assistance, identifying users who were likely to drop out from a forum, extracting terms used in an online forum to learn its vocabulary, highlighting contextual information that is missing from online questions and answers, and paraphrasing technical medical terms for consumers. Conclusions : While AI for supporting participatory health is still in its infancy, there are a number of important research priorities that should be considered for the advancement of the field. Further research evaluating the impact of AI in participatory health informatics on the psychosocial wellbeing of individuals would help in facilitating the wider acceptance of AI into the healthcare ecosystem.","",""
0,"Nina de Lacy, Michael J. Ramshaw, J. Kutz","Integrated Evolutionary Learning: An Artificial Intelligence Approach to Joint Learning of Features and Hyperparameters for Optimized, Explainable Machine Learning",2022,"","","","",152,"2022-07-13 09:19:39","","10.3389/frai.2022.832530","","",,,,,0,0.00,0,3,1,"Artificial intelligence and machine learning techniques have proved fertile methods for attacking difficult problems in medicine and public health. These techniques have garnered strong interest for the analysis of the large, multi-domain open science datasets that are increasingly available in health research. Discovery science in large datasets is challenging given the unconstrained nature of the learning environment where there may be a large number of potential predictors and appropriate ranges for model hyperparameters are unknown. As well, it is likely that explainability is at a premium in order to engage in future hypothesis generation or analysis. Here, we present a novel method that addresses these challenges by exploiting evolutionary algorithms to optimize machine learning discovery science while exploring a large solution space and minimizing bias. We demonstrate that our approach, called integrated evolutionary learning (IEL), provides an automated, adaptive method for jointly learning features and hyperparameters while furnishing explainable models where the original features used to make predictions may be obtained even with artificial neural networks. In IEL the machine learning algorithm of choice is nested inside an evolutionary algorithm which selects features and hyperparameters over generations on the basis of an information function to converge on an optimal solution. We apply IEL to three gold standard machine learning algorithms in challenging, heterogenous biobehavioral data: deep learning with artificial neural networks, decision tree-based techniques and baseline linear models. Using our novel IEL approach, artificial neural networks achieved ≥ 95% accuracy, sensitivity and specificity and 45–73% R2 in classification and substantial gains over default settings. IEL may be applied to a wide range of less- or unconstrained discovery science problems where the practitioner wishes to jointly learn features and hyperparameters in an adaptive, principled manner within the same algorithmic process. This approach offers significant flexibility, enlarges the solution space and mitigates bias that may arise from manual or semi-manual hyperparameter tuning and feature selection and presents the opportunity to select the inner machine learning algorithm based on the results of optimized learning for the problem at hand.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",153,"2022-07-13 09:19:39","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
34,"Blen Keneni, D. Kaur, Ali Al Bataineh, V. Devabhaktuni, A. Javaid, Jack Zaientz, Robert P. Marinier","Evolving Rule-Based Explainable Artificial Intelligence for Unmanned Aerial Vehicles",2019,"","","","",154,"2022-07-13 09:19:39","","10.1109/ACCESS.2019.2893141","","",,,,,34,11.33,5,7,3,"In this paper, an explainable intelligence model that gives the logic behind the decisions unmanned aerial vehicle (UAV) makes when it is on a predefined mission and chooses to deviate from its designated path is developed. The explainable model is on a visual platform in the format of if-then rules derived from the Sugeno-type fuzzy inference model. The model is tested using the data recorded from three different missions. In each mission, adverse weather, conditions and enemy locations are introduced at random locations along the path of the mission. There are two phases to the model development. In the first phase, the Mamdani fuzzy model is used to create rules to steer the UAV along the designated mission and the rules of engagement when it encounters weather and enemy locations along and near its chosen mission. The data are gathered as UAV traverses on each mission. In the second phase, the data gathered from these missions are used to create a reverse model using a Sugeno-type fuzzy inference system based on the subtractive clustering in the data. The model has seven inputs (time, x-coordinate, y-coordinate, heading direction, engage in attack, continue mission, and steer UAV) and two outputs (weather conditions and distance from the enemy). This model predicts the outputs regarding the weather conditions and enemy positions whenever UAV deviates from the predefined path. The model is optimized with respect to the number of rules and prediction accuracy by adjusting subtractive clustering parameters. The model is then fine-tuned with ANFIS. The final model has six rules and root mean square error value that is less than 0.05. Furthermore, to check the robustness of the model, the Gaussian random noise is added to a UAV path, and the prediction accuracy is validated.","",""
43,"Peter Hahn","[Artificial intelligence and machine learning].",2019,"","","","",155,"2022-07-13 09:19:39","","10.1055/a-0826-4789","","",,,,,43,14.33,43,1,3,"Machine learning (ML) is the ability of computers to learn from data without being programmed explicitly for that purpose, and to apply the acquired knowledge to unknown cases. The application of ML in medicine will increase exponentially in the years to come. Doctors should have some basic knowledge of ML. Only then will they be able to use ML optimally and to recognise the limits and difficulties of ML.","",""
44,"A. Goli, H. Zare, R. Tavakkoli-Moghaddam, A. Sadeghieh","Hybrid artificial intelligence and robust optimization for a multi-objective product portfolio problem Case study: The dairy products industry",2019,"","","","",156,"2022-07-13 09:19:39","","10.1016/j.cie.2019.106090","","",,,,,44,14.67,11,4,3,"","",""
12,"A. Gholami, H. Bonakdari, A. Zaji, A. Akhtari","A comparison of artificial intelligence-based classification techniques in predicting flow variables in sharp curved channels",2019,"","","","",157,"2022-07-13 09:19:39","","10.1007/s00366-018-00697-7","","",,,,,12,4.00,3,4,3,"","",""
37,"R. Hamamoto, M. Komatsu, Ken Takasawa, Ken Asada, S. Kaneko","Epigenetics Analysis and Integrated Analysis of Multiomics Data, Including Epigenetic Data, Using Artificial Intelligence in the Era of Precision Medicine",2019,"","","","",158,"2022-07-13 09:19:39","","10.3390/biom10010062","","",,,,,37,12.33,7,5,3,"To clarify the mechanisms of diseases, such as cancer, studies analyzing genetic mutations have been actively conducted for a long time, and a large number of achievements have already been reported. Indeed, genomic medicine is considered the core discipline of precision medicine, and currently, the clinical application of cutting-edge genomic medicine aimed at improving the prevention, diagnosis and treatment of a wide range of diseases is promoted. However, although the Human Genome Project was completed in 2003 and large-scale genetic analyses have since been accomplished worldwide with the development of next-generation sequencing (NGS), explaining the mechanism of disease onset only using genetic variation has been recognized as difficult. Meanwhile, the importance of epigenetics, which describes inheritance by mechanisms other than the genomic DNA sequence, has recently attracted attention, and, in particular, many studies have reported the involvement of epigenetic deregulation in human cancer. So far, given that genetic and epigenetic studies tend to be accomplished independently, physiological relationships between genetics and epigenetics in diseases remain almost unknown. Since this situation may be a disadvantage to developing precision medicine, the integrated understanding of genetic variation and epigenetic deregulation appears to be now critical. Importantly, the current progress of artificial intelligence (AI) technologies, such as machine learning and deep learning, is remarkable and enables multimodal analyses of big omics data. In this regard, it is important to develop a platform that can conduct multimodal analysis of medical big data using AI as this may accelerate the realization of precision medicine. In this review, we discuss the importance of genome-wide epigenetic and multiomics analyses using AI in the era of precision medicine.","",""
0,"","ACTIVITY REPORT Project-Team Models and Algorithms for Artiﬁcial Intelligence",2022,"","","","",159,"2022-07-13 09:19:39","","","","",,,,,0,0.00,0,0,1,"The expectation-maximization (EM) algorithm is a powerful computational technique for maximum likelihood estimation in incomplete data models. When the expectation step cannot be performed in closed form, a stochastic approximation of EM (SAEM) can be used. The convergence of the SAEM toward critical points of the observed likelihood has been proved and its numerical efﬁciency has been demonstrated. However, sampling from the posterior distribution may be intractable or have a high computational cost. Moreover, despite appealing features, the limit position of this algorithm can strongly depend on its starting one. To cope with this two issues, we propose in [11] new stochastic approximation version of the EM in which we do not sample from the exact distribution in the expectation phase of the procedure. We ﬁrst prove the convergence of this algorithm toward critical points of the observed likelihood. Then, we propose an instantiation of this general procedure to favor convergence toward global maxima. Experiments on synthetic and real data highlight the performance of this algorithm in comparison to the SAEM and the EM when feasible. of subject-speciﬁc weights characterizing partial membership across clusters. With this ﬂexibility come challenges in uniquely identifying, estimating, and interpreting the parameters. In [40], we propose a new class of Dimension-Grouped MMMs (Gro-M 3 s) for multivariate categorical data, which improve parsimony and interpretability. In Gro-M 3 s, observed variables are partitioned into groups such that the latent membership is constant for variables within a group but can differ across groups. Traditional latent class models are obtained when all variables are in one group, while traditional MMMs are obtained when each variable is in its own group. The new model corresponds to a novel decomposition of probability tensors. Theoretically, we derive transparent identiﬁability conditions for both the unknown grouping structure and model parameters in general settings. Methodologically, we propose a Bayesian approach for Dirichlet Gro-M3 s to inferring the variable grouping structure and estimating model parameters. Simulation results demonstrate good computational performance and empirically conﬁrm the identiﬁability results. We illustrate the new methodology through an application to a functional disability dataset. from this natural partition. In a Bayesian context, this is achieved by considering the Dirichlet cluster proportion prior parameter α as a regularisation term controlling the granularity of the clustering. This second step allows the exploration of the clustering at coarser scales and the ordering of the clusters an important output for the visual representations of the clustering results. The clustering results obtained with the proposed approach, on simulated as well as real settings, are compared with existing strategies and are shown to be particularly relevant. This work is implemented in the R package greed and Figure 2 illustrates the main idea of the method. In this applied work [19], we use the Fisher-EM algorithm for clustering for the unsupervised classiﬁcation of 702, 248 spectra of galaxies and quasars with resdshifts smaller than 0.25 that were retrieved from the Sloan Digital Sky Survey (SDSS) database, release 7. The spectra were ﬁrst corrected for the redshift, then wavelet-ﬁltered to reduce the noise, and ﬁnally binned to obtain about 1437 wavelengths per spectrum. Fisher-EM, an unsupervised clustering discriminative latent mixture model algorithm, was applied on these corrected spectra, considering the full set as well as several subsets of 100,000 and 300,000 spectra. The optimum number of classes given by a penalized likelihood criterion is 86 classes, the 37 most populated ones gathering 99% of the sample. These classes are established from a subset of 302144 spectra. Using several cross-validation techniques we ﬁnd that this classiﬁcation is in agreement with the results obtained on the other subsets with an average misclassiﬁcation error of about 15%. The large number of very small classes tends to increase this error rate. This is the ﬁrst time that an automatic, objective and robust unsupervised classiﬁcation is established on such a large amount of spectra of galaxies. The mean spectra of the classes can be used as templates for a large majority of galaxies in our Universe. Figure 7 illustrates the obtained results. Recurrent Neural Networks, Deep linguistic patterns the of a of of to the is this linguistic that becomes valuable for our descriptive approach through deep as it allows us to observe complex lexico-grammatical structures, that potentially associate several levels of text representation in the same structure. The convolutional model used until now must therefore be adapted to integrate this additional information in order to obtain an even ﬁner description of the textual salience of a corpus. the relevant features used by the CNN to perform the classiﬁcation task. We empirically demonstrate the efﬁciency of our approach on corpora from two different languages: English and French. On all datasets, wTDS automatically encodes complex linguistic objects based on co-occurrences and possibly on grammatical and syntax analysis. relationships between the concepts in the metadata by analyzing the contrast between the concepts similarities in the Joconde’s semantic model and other vocabularies and we tried to improve the model prediction scores based on the semantic relations. Our results show that cross-fertilization between symbolic AI and machine learning can indeed provide the tools to address the challenges of the museum curators work describing the artwork pieces and searching for the relevant images. that combines a geometric approach for decision rules with existing post hoc solutions for machine learning models to generate an intuitive feature ranking tailored to the end user. We show that established model-agnostic approaches produce poor results in this framework. Figure 13 illustrates this work. Algorithms involving Gaussian processes or determinantal point processes typically require computing the determinant of a kernel matrix. Frequently, the latter is computed from the Cholesky decomposition, an algorithm of cubic complexity in the size of the matrix. We show that, under mild assumptions, it is possible to estimate the determinant from only a sub-matrix, with probabilistic guarantee on the relative error. In [37], we present an augmentation of the Cholesky decomposition that stops under certain conditions before processing the whole matrix. Experiments demonstrate that this can save a considerable amount of time while having an overhead of less than 5% when not stopping early. More generally, we present a probabilistic stopping strategy for the approximation of a sum of known length where addends are revealed sequentially. We do not assume independence between addends, only that they are bounded from below and decrease in conditional expectation. of there is a signiﬁcant from combining and audio data in detecting active speakers. either of the modalities can potentially mislead audiovisual fusion by inducing unreliable or deceptive information. outlines active speaker detection as a multi-objective learning problem to leverage best of each modalities using a novel self-attention, uncertainty-based multimodal fusion scheme. Results obtained show that the proposed multi-objective learning architecture outperforms traditional approaches in improving both mAP and AUC scores. We further demonstrate that our fusion strategy surpasses, in active speaker detection, other modality fusion methods reported in various disciplines. We ﬁnally show that the proposed method signiﬁcantly improves the state-of-the-art on the AVA-ActiveSpeaker dataset. This paper explores the problem of summarizing professional soccer matches as automatically as possible using both the event-stream data collected from the ﬁeld and the content broadcasted on TV. We have designed an architecture, introducing ﬁrst (1) a Multiple Instance Learning method that takes into account the sequential dependency among events and then (2) a hierarchical multimodal attention layer that grasps the importance of each event in an action [31]. We evaluate our approach on matches from two professional European soccer leagues, showing its capability to identify the best actions for automatic summarization by comparing with real summaries made by human operators. Figure 18 illustrates the general schema of the approach. We a coherent framework for studying longitudinal manifold-valued data. We introduce a Bayesian mixed-effects model which allows estimating both a group-representative piecewise-geodesic creating clusters of similar sentences. The ideal practice is to obtain a cluster with only positive blocks and another with only negative ones. Comparing to the supervised approach (Bag of words + Logistic Regression Classiﬁer) with its f1-score as 0.8234 and f2-score as 0.8316, we found that both S-Bert [58] (with a f1-score of 0.6250 and f2-score of 0.6192) and BioBert [57] (f1-score as 0.7004 and f2 as 0.6955) can achieves relatively good results and latter even outperformed the former due to its domain speciﬁc knowledge. around 13 billion euros per year to European citizens [52]. In the ﬁeld of healthcare insurance, in France the compulsory scheme detected over 261.2 million euros of fraudulent services in 2018, mainly due to healthcare professionals and healthcare establishments [50]. In the United States, according to the FBI, medicare fraud costs insurance companies between 21 billion and 71 billion US dollars per year [55]. In a context where reducing management costs is a real issue for healthcare insurers, the ﬁght against fraud is a real expectation of the customers of professionals in the sector so that everyone receives a fair return for their contributions. This stud","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",160,"2022-07-13 09:19:39","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
9,"Nawaf H. M. M. Shrifan, M. F. Akbar, N. Isa","Prospect of Using Artificial Intelligence for Microwave Nondestructive Testing Technique: A Review",2019,"","","","",161,"2022-07-13 09:19:39","","10.1109/ACCESS.2019.2934143","","",,,,,9,3.00,3,3,3,"The development in materials technology has produced stronger, lighter, stiffer, and more durable electrically insulating composites which are replacing metals in many applications. These composites require alternative inspection techniques because the conventional nondestructive testing (NDT) techniques such as thermography, eddy currents, ultrasonic, X-ray and magnetic particles have limitations of inspecting them. Microwave NDT technique employing open-ended rectangular waveguides (OERW) has emerged as a promising approach to detect the defects in both metal and composite materials. Despite its promising results over conventional NDT techniques, OERW microwave NDT technique has shown numerous limitations in terms of poor spatial resolution due to the stand-off distance variations, inspection area irregularities and quantitative estimation in imaging the size of defects. Microwave NDT employing OERW in conjunction with robust artificial intelligence approaches have tremendous potential and viability for evaluating composite structures for the purpose mentioned here. Artificial intelligence techniques with signal processing techniques are highly possible to enhance the efficiency and resolution of microwave NDT technique because the impact of artificial intelligence approaches is proven in various conventional NDT techniques. This paper provides a comprehensive review of NDT techniques as well as the prospect of using artificial intelligence approaches in microwave NDT technique with regards to other conventional NDT techniques.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",162,"2022-07-13 09:19:39","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
19,"E. O. Kontis, T. Papadopoulos, M. Syed, E. Guillo‐Sansano, G. Burt, G. Papagiannis","Artificial-Intelligence Method for the Derivation of Generic Aggregated Dynamic Equivalent Models",2019,"","","","",163,"2022-07-13 09:19:39","","10.1109/TPWRS.2019.2894185","","",,,,,19,6.33,3,6,3,"Aggregated equivalent models for the dynamic analysis of active distribution networks (ADNs) can be efficiently developed using dynamic responses recorded through field measurements. However, equivalent model parameters are highly affected from the time-varying composition of power system loads and the stochastic behavior of distributed generators. Thus, equivalent models, developed through in situ measurements, are valid only for the operating conditions from which they have been derived. To overcome this issue, in this paper, a new method is proposed for the derivation of generic aggregated dynamic equivalent models, i.e., for equivalent models that can be used for the dynamic analysis of a wide range of network conditions. The method incorporates clustering and artificial neural network techniques to derive robust sets of parameters for a variable-order dynamic equivalent model. The effectiveness of the proposed method is evaluated using measurements recorded on a laboratory-scale ADN, while its performance is compared with a conventional technique. The corresponding results reveal the applicability of the proposed approach for the analysis and simulation of a wide range of distinct network conditions.","",""
374,"S. Park, Kyunghwa Han","Methodologic Guide for Evaluating Clinical Performance and Effect of Artificial Intelligence Technology for Medical Diagnosis and Prediction.",2018,"","","","",164,"2022-07-13 09:19:39","","10.1148/radiol.2017171920","","",,,,,374,93.50,187,2,4,"The use of artificial intelligence in medicine is currently an issue of great interest, especially with regard to the diagnostic or predictive analysis of medical images. Adoption of an artificial intelligence tool in clinical practice requires careful confirmation of its clinical utility. Herein, the authors explain key methodology points involved in a clinical evaluation of artificial intelligence technology for use in medicine, especially high-dimensional or overparameterized diagnostic or predictive models in which artificial deep neural networks are used, mainly from the standpoints of clinical epidemiology and biostatistics. First, statistical methods for assessing the discrimination and calibration performances of a diagnostic or predictive model are summarized. Next, the effects of disease manifestation spectrum and disease prevalence on the performance results are explained, followed by a discussion of the difference between evaluating the performance with use of internal and external datasets, the importance of using an adequate external dataset obtained from a well-defined clinical cohort to avoid overestimating the clinical performance as a result of overfitting in high-dimensional or overparameterized classification model and spectrum bias, and the essentials for achieving a more robust clinical evaluation. Finally, the authors review the role of clinical trials and observational outcome studies for ultimate clinical verification of diagnostic or predictive artificial intelligence tools through patient outcomes, beyond performance metrics, and how to design such studies. © RSNA, 2018.","",""
27,"Óscar Álvarez-Machancoses, J. Fernández-Martínez","Using artificial intelligence methods to speed up drug discovery",2019,"","","","",165,"2022-07-13 09:19:39","","10.1080/17460441.2019.1621284","","",,,,,27,9.00,14,2,3,"ABSTRACT Introduction: Drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. Due to the high complexity of genomic data, AI techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. Phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. Phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). This imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. Areas covered: In this paper, the authors present AI methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. Expert opinion: AI is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. The use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","",""
8,"M. Cukurova, R. Luckin, C. Kent","Impact of an Artificial Intelligence Research Frame on the Perceived Credibility of Educational Research Evidence",2019,"","","","",166,"2022-07-13 09:19:39","","10.1007/s40593-019-00188-w","","",,,,,8,2.67,3,3,3,"","",""
8,"Eric M. S. P. Veith, Lars Fischer, Martin Tröschel, Astrid Nieße","Analyzing Cyber-Physical Systems from the Perspective of Artificial Intelligence",2019,"","","","",167,"2022-07-13 09:19:39","","10.1145/3388218.3388222","","",,,,,8,2.67,2,4,3,"Principles of modern cyber-physical system (CPS) analysis are based on analytical methods that depend on whether safety or liveness requirements are considered. Complexity is abstracted through different techniques, ranging from stochastic modelling to contracts. However, both distributed heuristics and Artificial Intelligence (AI)-based approaches as well as the user perspective or unpredictable effects, such as accidents or the weather, introduce enough uncertainty to warrant reinforcement-learning-based approaches. This paper compares traditional approaches in the domain of CPS modelling and analysis with the AI researcher perspective to exploring unknown complex systems.","",""
8,"Hong Chen","Success Factors Impacting Artificial Intelligence Adoption --- Perspective From the Telecom Industry in China",2019,"","","","",168,"2022-07-13 09:19:39","","10.25777/a8q8-gm13","","",,,,,8,2.67,8,1,3,"SUCCESS FACTORS IMPACTING ARTIFICIAL INTELLIGENCE ADOPTION--PERSPECTIVE FROM THE TELECOM INDUSTRY IN CHINA Hong Chen Old Dominion University, 2019 Director: Dr. Ling Li As the core driving force of the new round of informatization development and the industrial revolution, the disruptive achievements of artificial intelligence (AI) are rapidly and comprehensively infiltrating into various fields of human activities. Although technologies and applications of AI have been widely studied, and factors that affect AI adoption are identified in existing literature, the impact of success factors on AI adoption remains unknown. Accordingly, the main study of this paper proposes a framework to explore the effects of success factors on AI adoption by integrating the technology, organization, and environment (TOE) framework and diffusion of innovation (DOI) theory. Particularly, this framework consists of factors regarding the external environment, organizational capabilities, and innovation attributes of AI. The framework is empirically tested with data collected by surveying telecom companies in China. Structural equation modeling is applied to analyze the data. The results indicate that compatibility, relative advantage, complexity, managerial support, government involvement, and vendor partnership are significantly related to AI adoption. Managerial capability impacts other organizational capabilities and innovation attributes of AI, but it is indirectly related to AI adoption. Market uncertainty and competitive pressure are not significantly related to AI adoption, but all the external environment factors positively influence managerial capability. The study provides support for firms' decision-making and resource allocation regarding AI adoption. In addition, based on the resource-based view (RBV), this article conducts study 2 which explores the factors that influence the firm sustainable growth. Multiple regression model is applied to empirically test the hypotheses with longitudinal time-series panel data from telecom companies in China. The results indicate that at the firm level, the customer value and operational expenses are significantly related to sustainable growth. Also, at the industry level, industry investment significant impacts sustainable growth. Study 2 provides insights for practitioners the way to keep sustainable growth.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",169,"2022-07-13 09:19:39","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",170,"2022-07-13 09:19:39","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",171,"2022-07-13 09:19:39","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
0,"D. Gilboa, L. Bori, M. Shapiro, A. Pellicer, R. Maor, A. Delgado, D. Seidman, M. Meseguer","P-277 An artificial intelligence (AI) deselection model for top-quality blastocysts: algorithmic analysis of morphokinetic features for aneuploidy may increase implantation rates",2022,"","","","",172,"2022-07-13 09:19:39","","10.1093/humrep/deac107.266","","",,,,,0,0.00,0,8,1,"      Can an AI deselection model identify distinct morphokinetic patterns in top-quality blastocyst with unknown ploidy that fail to implant?        An AI based deselection model was able to predict implantation failure based on morphokinetic features previously found to associate with aneuploidy.        Aneuploidy is the most common explanation for implantation failure of high-quality blastocysts. Yet, high-quality blastocysts with unknown ploidy that fail to implant are often morphologically indistinguishable from blastocysts that succeed to implant. Our previously published results (ESHRE 2021) demonstrated that aneuploid blastocysts were more likely to reach development events (t2-t8) later, and that the timing between each event was statistically longer (p < 0.001), when compared to euploid embryos. Given that delayed morphokinetic rates are tightly linked to ploidy, we investigated whether similar known morphokinetic features were associated with implantation failure in top-graded embryos.        Time-lapse sequences of 3,259 top-quality blastocysts from fresh single embryo transfer cycles with known implantation outcomes were analyzed using an AI-based algorithm. The algorithm utilized convolutional neural network extracted temporal features based on multiple morphokinetic parameters known to associate with ploidy.        time-lapse sequences and morphokinetic events were algorithmically analyzed to measure the rate of mitotic division events and compare the number of embryos in each category (implanted/nonimplanted) that reached each developmental event at least one standard deviation (SD) later than the mean for implanted embryos.        Results showed statistical differences in the following morphokinetic features between the two categories: t2, t3, t4, and t3-t4 (p < 0.05). Implanted top-graded blastocysts were likely to reach t2, t3, and t4 after 25.23 ± 3.8 SD, 36.06 ± 3.4 SD, and 37.14 hours ±3.6 SD, respectively. The time gap between t3 and t4 was found to be 12.25 hours ± 5.31 SD. Given this, we followed the methodology described above to propose cutoff values (in hours) that differentiated between non-implanted and implanted top-graded blastocysts based on their morphokinetic profiles. Implantation failure was found to be associated with the likelihood of reaching t2 after 28.61 hours (OR = 2.36, CI 0.96-5.77), t3 after 39.46 (OR = 3.48, CI 1.62-7.47), and t4 after 40.79 hours (OR = 2.23, CI 1.09- 4.53). A time gap between t3 and t4 of more than 17.56 hours was also associated with implantation failure (OR = 2.48, CI 1.12-5.48), indicating perturbed mitotic activity. The cutoff values proposed here were incorporated into the algorithm for optimized deselection of morphologically similar top-quality blastocysts with delayed morphokinetic profiles.        This study needs to be validated on a larger, multi-centric dataset that takes into account more morphokinetic features associated with ploidy in order to increase the robustness of our algorithm.        For the first time, our algorithmic model proposed here demonstrates the utility of an AI tool to deselect top-graded blastocysts that would otherwise be selected for transfer based on conventional morphologic assessment alone.        Not Applicable ","",""
0,"Jie Hu","Research on Robot Fuzzy Neural Network Motion System Based on Artificial Intelligence",2022,"","","","",173,"2022-07-13 09:19:39","","10.1155/2022/4347772","","",,,,,0,0.00,0,1,1,"An intelligent controller based on a self-learning interval type-II fuzzy neural network is proposed to make the motion controller of the industrial intelligent robot with good adaptability. This controller has a parallel structure and contains an interval type-II fuzzy neural network and a conventional PD controller. For the design of the interval type-II fuzzy neural network, the interval type-II fuzzy set is established using the slave design method. In the design process of the interval type-II fuzzy set of the front piece, a dual sequence symmetric trapezoidal subordinate function arrangement method is proposed, which makes the self-learning law and stability analysis of the system in an analytic form and facilitates the implementation of the algorithm in hardware. In the design of the neural network self-learning law, a parametric self-learning algorithm based on sliding mode control theory is established to adjust the structural parameters of the interval type-II fuzzy neural network online, and the stability of the system is proved by using Lyapunov's stability theorem. Three sets of validation simulation experiments are given in conjunction with the trajectory tracking problem of the Delta parallel robot. The simulation results show that, in the presence of system uncertainty, the intelligent controller based on interval self-learning interval type-II fuzzy neural network can significantly improve the trajectory tracking accuracy and robustness of the system and make the control system highly adaptable to the environment. Experiments of intelligent control system based on self-learning interval type-II fuzzy neural network and experiments of reusable particle swarm optimal motion planning method are designed, and the effectiveness of the intelligent control system and motion planning method is verified on the experimental platform. The experimental results show that the intelligent control system based on the self-learning interval type-II fuzzy neural network can effectively improve the accuracy and stability of robot trajectory tracking control, and the reusable particle swarm optimal motion planning method can quickly solve the robot motion planning problem with complex constraints online.","",""
0,"Su Zhang","The Cognitive Transformation of Japanese Language Education by Artificial Intelligence Technology in the Wireless Network Environment",2022,"","","","",174,"2022-07-13 09:19:39","","10.1155/2022/7886369","","",,,,,0,0.00,0,1,1,"This study aims to solve the multiscale problems faced by the current classroom student behavior target detection based on the convolutional neural network (CNN) in the wireless network environment. Firstly, the recent reform of Japanese language education is introduced. Secondly, the multiscale problem research of classroom student behavior target detection is discussed. A CNN-based new extraction network is designed based on dilated convolution and pyramid features. An anchor reconstruction algorithm based on improved K-means clustering is presented for the self-made student behavior dataset. Finally, the performance of the designed algorithm is tested. The anchor reconstruction algorithm’s mean average precision is 83.2%, and the average intersection over union is 73.7%. The experimental results of this scheme outperform the original single-shot multibox detector and K-means algorithms. Compared with other algorithms, the designed multiscale detection algorithm of classroom student behavior has the best detection effect on Pascal visual object classes (VOC) dataset. The detection accuracy of the entire dataset is 79.8%. Overall, the multiscale detection algorithm for classroom student behavior has a better detection effect on the Pascal VOC dataset and has good generalization ability and robustness. This research can guide students to recognize their class status and make corresponding adjustments to improve their learning efficiency, which has essential research significance and application value.","",""
6,"Francisco Javier Abarca-Álvarez, F. S. Campos-Sánchez, Fernando Osuna-Pérez","Urban Shape and Built Density Metrics through the Analysis of European Urban Fabrics Using Artificial Intelligence",2019,"","","","",175,"2022-07-13 09:19:39","","10.3390/su11236622","","",,,,,6,2.00,2,3,3,"In recent decades, the concept of urban density has been considered key to the creation of sustainable urban fabrics. However, when it comes to measuring the built density, a difficulty has been observed in defining valid measurement indicators universally. With the intention of identifying the variables that allow the best characterization of the shape of urban fabrics and of obtaining the metrics of their density, a multi-variable analysis methodology from the field of artificial intelligence is proposed. The main objective of this paper was to evaluate the capacity and interest of such a methodology from standard indicators of the built density, measured at various urban scales, (i) to cluster differentiated urban profiles in a robust way by assessing the results statistically, and (ii) to obtain the metrics that characterize them with an identity. As a case study, this methodology was applied to the state of the art European urban fabrics (N = 117) by simultaneously integrating 13 regular parameters to qualify urban shape and density. It was verified that the profiles obtained were more robust than those based on a limited number of indicators, evidencing that the proposed methodology offers operational opportunities in urban management by allowing the comparison of a fabric with the identified profiles.","",""
4,"John K. Wulff","Artificial Intelligence and Law Enforcement",2019,"","","","",176,"2022-07-13 09:19:39","","","","",,,,,4,1.33,4,1,3,"After the 9/11 terrorist attacks against the United States, law enforcement, and intelligence communities began efforts to combine their talents and information gathering assets to create an efficient method for sharing data. The central focus of these cooperative efforts for information dissemination was State Fusion Centers, tasked with collecting data from several database sources and distributing that information to various agencies. This vast amount of intelligence data eventually overwhelmed the investigative organizations. The use of Artificial Intelligence (AI) is the preferred technology for analyzing data to recognize behavioral patterns and create a method for the sharing of data in the fight against crime and terrorism. AI can analyze threat data and historical information and then create attack hypotheses for predicting when and where crimes will be committed. The use of AI can directly affect the cost of operations. Criminal activity locations can be predicted by AI so equipment and personnel can be directed to those areas to prevent those events from occurring. Financial resources must be allocated to allow for the development and testing of these applications so that the options available to law enforcement and the intelligence communities can be increased. © 2 01 7 T he SA NS In sti tut e, Au tho r R eta ins Fu ll R igh ts © 2017 The SANS Institute Author retains full rights. AI and Law Enforcement 2 Introduction On the morning of September 11, 2001, at 8:46 an airliner carrying 10,000 gallons of fuel crashed into the north tower of the World Trade Center in lower Manhattan. A few minutes later, at 9:03 a second plane hit the south tower. Both structures collapsed in less than 90 minutes. On the same morning, at 9:37 a third airliner slammed into the Pentagon and at 10:03 a fourth plane crashed in a field in Pennsylvania, its target never reached due to the heroic actions of passengers with knowledge of the previous attacks. The human death toll from these events amounted to nearly 2700 (9/11 Commission, 2004). Nineteen young Arab men, implementing the plans of Islamic extremists in Afghanistan, committed these acts of terrorism. Some had been in the United States for over a year and blended into the population. While four had training as pilots, the rest were not well educated and spoke English poorly. In small groups, they were able to carry knives, box cutters, Mace, or pepper spray onto the hijacked jetliners and convert them into deadly weapons (9/11 Commission, 2004). How did this happen? How were they organized and financed? How did the authorities fail to anticipate and prevent this tragedy? 1.0. Fusion Centers & Information Sharing These events highlight the inability of law enforcement and the intelligence community to effectively share information. The 9/11 Commission Report found that the United States, while having access to vast amounts of data and information, is ill equipped to process the data that it has. The report suggested that the Intelligence community’s culture of “need to know” be replaced with “need to share”. Moreover, the report recommends that the President lead an effort to turn an outdated mainframe structure into a distributed network. In response to these recommendations, the law enforcement and intelligence groups began efforts to combine assets, knowledge, and skills in the pursuit of terrorists and to gather intelligence to prevent further attacks (9/11 Commission, 2004). The central focus of these cooperative efforts for sharing information was State Fusion Centers. A State Fusion Center is defined as “a collaborative effort of two or more agencies that provide resources, expertise, and information to the center with the goal of maximizing their John Wulff, john@jwcyberforensics.com © 2 01 7 T he SA NS In sti tut e, Au tho r R eta ins Fu ll R igh ts © 2017 The SANS Institute Author retains full rights. AI and Law Enforcement 3 ability to detect, prevent, investigate, and respond to criminal and terrorist activity” (Fusion Center Guidelines, n.d., p. 12). While the exact makeup of the centers varies from state to state, they are mostly comprised of state and local law enforcement agencies, public health and safety organizations, and federal agencies, most notably, the Federal Bureau of Investigation, U.S. Department of Homeland Security, and the Bureau of Alcohol, Tobacco, Firearms, and Explosives. The mission of fusion centers is to bridge the gap between these agencies, facilitating real-time information sharing. In addition to providing this intelligence, fusion centers provide agencies all-encompassing views of the threat environment (Grant & Terry, 2005). The end product of this mission is a tremendous amount of data that is generated and must be disseminated to the various law enforcement agencies that can best utilize these data. However, fusions centers have come under great scrutiny from Congress and the law enforcement community because of their perceived inability to digest the amount of data that they are collecting and distribute it in a meaningful way (Sypherlink, 2008). For example, terrorism often involves multiple suspects who are connected through various relationships. It is necessary to use research techniques such as link analysis to digest the information regarding these individuals and treat them like a network in which they interact and participate in differing roles. The adaptability and learning protocols inherent in Artificial Int lligence (AI) make it a solution that can constantly monitor the changing landscape of these criminal and terrorist networks. A study of this landscape often involves criminal network analysis by studying drug trafficking, fraud, gang related crimes, armed robbery, etc. An analysis of criminal network activity with AI can highlight previously unknown relationships between the actors in the criminal network and can identify and classify the individuals or groups into their appropriate network roles. This combination of network and behavior analysis can also be used to predict the commission of terrorist and criminal events, using the same AI techniques that retailers use in predicting the purchasing habits of consumers. The purpose of this research was to examine how law enforcement actors can better evaluate data distributed by fusion centers. What would Artificial Intelligence’s role be in the aggregation of critical threat data into actionable intelligence? How could Artificial Intelligence be used as an aid to intelligent policing? How could resource management leverage Artificial Intelligence for more effective deployment of resources? John Wulff, john@jwcyberforensics.com © 2 01 7 T he SA NS In sti tut e, Au tho r R eta ins Fu ll R igh ts © 2017 The SANS Institute Author retains full rights. AI and Law Enforcement 4 By looking beyond state and national borders, the fusion centers are intended to enhance the ability to predict crime and terrorism, rather than just react to events. Fusion centers analyze information from local criminal activity and can therefore determine whether a connection exists between that activity and terrorist threats. It is possible that the application of Artificial Intelligence to the processing of these data can help with these connections. 1.1. Advancing Law Enforcement The existence of fusion centers and their mandate to coordinate and disseminate these data has moved the technology of crime fighting into new territories of advanced law enforcement. The use of information technology gives these local agencies access to a vast amount of information and data, for better or worse that would previously be unavailable to them without this technology, and has coined the term, Intelligence-Led Policing (Grant & Terry, 2005). This information access is increasing exponentially and law enforcement must keep up with the amount of data collected. In order to create actionable intelligence necessary for successful Intelligence-Led Policing, crime analysis is completely dependent upon the quality of the data or information collected and the ability to collate and interpret its meaning. According to Canter (2000), the criteria for designing the data collection processes that will create the greatest possible relevance to the crime analysis are: 1. Timeliness: Does the pattern of the data or information relate to the current problem or are they indicative of a previous issue? 2. Relevancy: Is this information an accurate representation of that needed to carry out the intended task? 3. Reliability: Would different people come to the same conclusions after examining these data? In order to foster the technological and organizational capacities for information sharing, the National Institute of Justice made information sharing its top priority among state and local jurisdictions as well as internationally (Tomek, 2001). However, as the universe of collaborative participants expands, the difficulty in sharing information is John Wulff, john@jwcyberforensics.com © 2 01 7 T he SA NS In sti tut e, Au tho r R eta ins Fu ll R igh ts © 2017 The SANS Institute Author retains full rights. AI and Law Enforcement 5 related to different agency formats, protocols, standards, and even how extensively the data is collected (Tomek). Other overarching issues for the sharing of these intelligence data is the sheer amount of it as well as the expertise necessary for its proper distribution. “Sharing isn’t bad, it’s broken” (""Cyber intelligence tradecraft,"" 2013, p. 5). This was a point from the Carnegie Mellon Software Engineering Institute’s SEI Innovation Center Report: Cyber Intelligence Tradecraft Project Summary of Key Findings. The report, known as the CITP, examined the cyber intelligence, methodologies, best practices, technologies, processes, and training from six government agencies and 20 organizations from industry and academia. It concluded that while some organizations excel at gathering and a","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",177,"2022-07-13 09:19:39","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
6,"R. Sharma, Paul Kawachi, Aras Bozkurt","The Landscape of Artificial Intelligence in Open, Online and Distance Education: Promises and Concerns",2019,"","","","",178,"2022-07-13 09:19:39","","10.5281/ZENODO.3730631","","",,,,,6,2.00,2,3,3,"The Landscape of Artificial Intelligence in Open, Online and Distance Education: Promises and concerns  Editorial  “Only the unknown frightens men. But once a man has faced the unknown, that terror becomes the known.” Antoine de Saint-Exupery, 1939.","",""
0,"","Big Data and Artificial Intelligence Analytics in Geosciences : Promises and Potential Last Call for 2019 Annual Meeting Proposals",2019,"","","","",179,"2022-07-13 09:19:39","","","","",,,,,0,0.00,0,0,3,"Big data and machine learning are IT methodologies that are bringing substantial changes in the analysis and interpretation of scientific data. By adding GPU processing resources to the typical equipment of a server host, it is possible to speed up queries performed on large databases and reduce training time for deep learning architectures. A recent pairing of the big data technologies, applied to old and new data, and artificial intelligence techniques has enabled a team of scientists to create an interactive virtual globe that shows a color mosaic of the seabed geology. This interactive model allows us to obtain robust reconstructions and predictions of climate changes and their impacts on the ocean environment. We suggest a possible evolution of such a model by means of the expansion of functionalities and performance improvements. We refer respectively to the implementation of isochronic layers of seabed lithologies and the addition of GPU resources to speed up the learning phase of the support vector machine (SVM) model. These additional features would allow us to establish broader correlations and extract additional information on large-scale geological phenomena. INTRODUCTION The Earth system generates continuous data, and our acquisition capacity has significantly increased over time. The growing availability of acquired geological data and the methods developed in the field of information technology make it possible to identify associations and understand patterns and trends within data (Big Data), solve difficult decision problems (artificial intelligence), and provide acceleration to data processing (GPU computing). Big Data is a term that indicates very large databases (often by order of zettabytes, i.e., billions of terabytes) that can contain huge amounts of heterogeneous, structured and unstructured data (text, numerical values, images, e-mail, GPS data, and data acquired from social networks), which can be extrapolated, analyzed, and correlated with each other. Artificial Intelligence (AI) is a branch of computer science that studies the way in which the combination of hardware and software systems can simulate typical behaviors of the human brain. One of the most important applications consists of a complex algorithm, called machine learning, which is able to learn and make decisions. GPU Parallel Computing (GPGPU) involves the processing of data by the processors present in the graphics card (GPU) and has allowed the computation, in relatively short times, of huge amounts of data with an efficiency of at least two orders of magnitude greater compared to the past. There are several cases in which these technologies have been applied both in the field of potential earthquakes (RouetLeduc et al., 2017), volcanic eruptions (Ham et al., 2012), and to solve the problems of spatial modeling in the field of the assessment of landslide susceptibility (Korup and Stolle, 2014). The following describes a mixed approach (AI and Big Data) in the field of geosciences—analyzing potentials and possible future developments. CASE STUDY: BIG DATA AND AI MAP WORLD’S OCEAN FLOOR An example of an application combining Big Data and machine learning technologies was implemented by a team of Australian scientists who created the first digital map of seabed lithologies (Dutkiewicz et al., 2015) through the analysis and cataloging of ~15,000 samples of sediments found in marine basins. Before such a map, the most recent map of oceanic lithologies was hand drawn ~40 years ago, at the beginning of ocean exploration. Since then, the map has undergone few changes, with at most six types of sediment dominant in the ocean basins. The digital map was created using an AI method consisting of the support vector machine (SVM) model. Through a crossvalidation approach, the classifier was trained by adding new data gradually so as to allow its learning. Learning the parameter values, which optimize the classifier’s performance on withheld data, is an important step in the workflow. In this way, the vast set of point data has been transformed into a continuous digital map with very high accuracy (up to 80%). The new lithological map of the seabed is very important for the interpretation of global phenomena related to the evolution of ocean basins. An example of this is diatoms, siliceous phytoplankton that live in the oceans and that through chlorophyll photosynthesis produce about one-quarter of the oxygen present in the atmosphere, contributing to reduce global terrestrial warming. At their death, these organisms precipitate through the water column, accumulating on the underlying sea floor. Satellite surveys over the years have identified places where diatomaceous activity is more productive; that is, the marine areas in which there are the maximum concentrations of chlorophyll, considering that they should also correspond to the areas of maximum accumulation of these organisms in the sea floor. Surprisingly, the digital map of the seabed has revealed that there is a decoupling between the productivity of diatoms and the corresponding accumulation areas in the sea floor. The possibility of diatom ooze formation is however favored by the low surface temperature (0.9–5.7 °C), by salinity (33.8–34 PSS), and by the high concentration of nutrients, and therefore can represent an important indicator of the oceanographic variables of the surface of the sea (Cunningham and Big Data and Artificial Intelligence Analytics in Geosciences: Promises and Potential Roberto Spina, Geologist and DCompSci, CNG (National Council of Geologists), Rome, Italy, robertospina@geologi.it GSA Today, https://www.doi.org/10.1130/GSATG372GW.1. Copyright 2019, The Geological Society of America. CC-BY-NC. Leventer, 1998). For this reason, the map will help scientists better understand how our oceans have responded and will respond to environmental changes. POTENTIAL AND FUTURE PROSPECTS Big Data and AI are having an impact on every commercial and scientific domain, and their application in the field of geosciences is making a great impact in the analysis and understanding of natural phenomena. The intensive use of CPUs required by these two technologies has stimulated the search for alternative solutions to improve performance by using a mixed CPU-GPU approach. In this way it is possible to obtain rapid results from huge databases and the acceleration of the learning process for neural networks. These techniques are the basis of deep learning, an alternative model of machine learning, which achieves a very high degree of accuracy in recognizing objects and is able to learn features automatically from data without the need to extract them manually. The joint application of Big Data– machine learning, described as a case study, allowed researchers to demonstrate the absence of correlation between diatom productivity and the corresponding diatom oozes: The accumulation of these organisms in the seabed seems rather to be linked to specific variations in sea-surface parameters. This is one of many cases where the integrated analysis of various parameters allows a different interpretation from what could be assumed by their disjoint analysis. A possible evolution is to represent, on a similar map, in addition to the current surface lithologies, those present within the lithostratigraphic succession, making geochronological correlations between chronostratigraphic units. Using surveys carried out in various parts of the world, different layers could be defined, each corresponding to a specific age expressed in millions of years, representing the ocean lithologies existing in that particular geological period. Similarly to the previous case, the transition from a punctual to a continuous display could be obtained, for each layer, by applying the existing SVM model or an even more efficient version using GPU computing. Figure 1 shows a possible switching between current ocean Figure 1. Example of a layered implementation of seabed lithology maps (modified from https://portal.gplates.org). lithologies (https://portal.gplates.org) placed below and those existing respectively 500,000 and one million years ago (above). The oldest layers were made only for demonstration purposes and reproduce an artificial lithology of the seabed. A system of this kind allows the carrying out of various operations that can be summarized as follows: • display/hide isochronous levels obtaining different instantaneous representations of the ocean basins during the geological eras; • using Big Data analytics to pair data sets (oceanographic, stratigraphic, paleontological, and micropaleontological) with one or more isochronous layers to analyze geological phenomena on a global scale (eustatic oscillations, glacial and interglacial periods...) and perform stratigraphic correlations between oceanic crustal sectors to identify evolutionary patterns. The optimization introduced by IT methods lets us perform analyses on large heterogeneous data to discover hidden models and unknown correlations that allow for more solid reconstructions and forecasts on natural phenomena that have had and will have a major impact on the ecosystems of our planet. REFERENCES CITED Cunningham, W.L., and Leventer, A., 1998, Diatom assemblages in surface sediments of the Ross Sea: Relationship to present oceanographic conditions: Antarctic Science, v. 10, p. 134–146, https://doi.org/10.1017/S0954102098000182. Dutkiewicz, A., Müller, R.D., O’Callaghan, S., and Jónasson, H., 2015, Census of seafloor sediments in the world’s ocean: Geology, v. 43, no. 9, p. 795–798, https://doi.org/10.1130/G36883.1. Ham, M.F., Iyengar, I., Hambebo, B.M., Garces, M., Deaton, J., Perttu, A., and Williams, B., 2012, A neurocomputing approach for monitoring Plinian volcanic eruptions using infrasound: Procedia Computer Science, v. 13, p. 7–17, https://doi.org/10.1016/j.procs.2012.09.109. Korup, O., and Stolle, A., 2014, Landslide prediction from","",""
0,"Kaushik Madala","An Artificial Intelligence-Based Model-Driven Approach for Exposing Off-Nominal Behaviors",2019,"","","","",180,"2022-07-13 09:19:39","","10.1109/ICSE-Companion.2019.00085","","",,,,,0,0.00,0,1,3,"With an increase in the automation of cyber-physical systems (e.g., automated vehicles and robots), quality problems such as off-nominal behaviors (ONBs) have also increased. While there are techniques that can find ONBs at the requirements engineering stage as it reduces the cost of addressing defects early in development, they do not meet the current industrial needs and often ignore functional safety. These techniques suffer from limitations such as scalability, need for significant human effort and inability to detect overlooked or unknown ONBs. To address these limitations we need a technique that analyzes requirements with respect to functional safety, but with less human effort. To achieve this, we propose our artificial intelligence-based model-driven methodology that provides a means to find ONBs during requirements engineering with minimal human effort. Our methodology utilizes existing approaches such as causal component model (CCM) and systems theoretic process analysis (STPA). We describe the details of each step of our approach and how our approach would support finding ONBs. Using our research and the results of our studies, we intend to provide empirical evidence that considering ONBs during requirements engineering stage and analyzing requirements with respect to functional safety can help create more robust designs and higher-quality products.","",""
6,"A. Schuster","Robustness in Nature as a Design Principle for Artificial Intelligence",2008,"","","","",181,"2022-07-13 09:19:39","","10.1007/978-1-84800-261-6_8","","",,,,,6,0.43,6,1,14,"","",""
22,"L. Valiant","Knowledge Infusion: In Pursuit of Robustness in Artificial Intelligence",2008,"","","","",182,"2022-07-13 09:19:39","","10.4230/LIPIcs.FSTTCS.2008.1770","","",,,,,22,1.57,22,1,14,"Endowing computers with the ability to apply commonsense knowledge with human- level performance is a primary challenge for computer science, comparable in importance to past great challenges in other fields of science such as the sequencing of the human genome. The right approach to this problem is still under debate. Here we shall discuss and attempt to justify one ap- proach, that of knowledge infusion. This approach is based on the view that the fundamental objective that needs to be achieved is robustness in the following sense: a framework is needed in which a computer system can represent pieces of knowledge about the world, each piece having some un- certainty, and the interactions among the pieces having even more uncertainty, such that the system can nevertheless reason from these pieces so that the uncertainties in its conclusions are at least controlled. In knowledge infusion rules are learned from the world in a principled way so that sub- sequent reasoning using these rules will also be principled, and subject only to errors that can be bounded in terms of the inverse of the effort invested in the learning process.","",""
11,"Ruben E. Laukkonen, Hannah Biddell, Regan M. Gallagher","Preparing humanity for change and artificial intelligence",2019,"","","","",183,"2022-07-13 09:19:39","","10.31234/osf.io/g5qwc","","",,,,,11,3.67,4,3,3,"The world is changing at an increasingly rapid pace. In the span of only a few short years, we have witnessed technological progress, population growth, and globalization to a degree not seen in the lifetimes of our ancestors. Machines are also becoming smarter and more capable. As automation increases in domains where human labor and decision-making were once necessary, it will become increasingly difficult for individuals to create value and meaning through work. And, if one does find a niche, further changes may soon take place—new technology will acquire new skills, and people will continuously need to adapt. As a consequence of this growing dynamism, it is no longer sufficient to adapt to any one environment; humans and society must learn to adapt to change itself—they must increasingly learn to learn. In this paper, we begin with a brief account of how brains and minds work based on a theory broadly known as predictive processing (Friston, 2003; Clark, 2013). According to this view, humans come to understand and perceive the world by making predictions, a process that is therefore at the heart of understanding how humans deal with unpredictable circumstances. We then discuss research on how humans and machines respond in situations characterised by volatility, uncertainty, complexity, and ambiguity (VUCA), and the role of agency in social and moral situations. We conclude by arguing that learning-to-learn and meta- learning strategies are key capacities that currently distinguish humans from machines. For society to be generally adaptable to change, we propose that social structures and education systems will need to nurture skills that foster general and transferable learning capacities (rather than, or in addition to, specific skills). For humans to flourish in the future, governments are also encouraged to incentivize citizens who possess skills to become teachers and mentors. Society can be made robust when experts are inclined to teach those who are willing and able to learn.","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",184,"2022-07-13 09:19:39","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
82,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing and Collusion",2018,"","","","",185,"2022-07-13 09:19:39","","10.2139/ssrn.3304991","","",,,,,82,20.50,21,4,4,"Pricing algorithms are increasingly replacing human decision making in real marketplaces. To inform the competition policy debate on possible consequences, we run experiments with pricing algorithms powered by Artificial Intelligence in controlled environments (computer simulations).<br><br>In particular, we study the interaction among a number of Q-learning algorithms in the context of a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. We show that the algorithms consistently learn to charge supra-competitive prices, without communicating with each other. The high prices are sustained by classical collusive strategies with a finite punishment phase followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
6,"Herut Uzan, Shira Sardi, A. Goldental, R. Vardi, I. Kanter","Biological learning curves outperform existing ones in artificial intelligence algorithms",2019,"","","","",186,"2022-07-13 09:19:39","","10.1038/s41598-019-48016-4","","",,,,,6,2.00,1,5,3,"","",""
92,"A. Annoni, P. Benczúr, P. Bertoldi, Blagoj Delipetrev, Giuditta De Prato, C. Feijóo, Enrique Fernández-Macías, E. Gutiérrez, M. Portela, H. Junklewitz, M. L. Cobo, B. Martens, Susana Nascimento, S. Nativi, Alexandre Pólvora, Jose Ignacio Sanchez Martin, Songuel Tolan, I. Tuomi, Lucia Vesnić Alujević","Artificial Intelligence: A European Perspective",2018,"","","","",187,"2022-07-13 09:19:39","","10.2760/11251","","",,,,,92,23.00,9,19,4,"We are only at the beginning of a rapid period of transformation of our economy and society due to the convergence of many digital technologies. Artificial Intelligence (AI) is central to this change and offers major opportunities to improve our lives. The recent developments in AI are the result of increased processing power, improvements in algorithms and the exponential growth in the volume and variety of digital data. Many applications of AI have started entering into our every-day lives, from machine translations, to image recognition, and music generation, and are increasingly deployed in industry, government, and commerce. Connected and autonomous vehicles, and AI-supported medical diagnostics are areas of application that will soon be commonplace. There is strong global competition on AI among the US, China, and Europe. The US leads for now but China is catching up fast and aims to lead by 2030. For the EU, it is not so much a question of winning or losing a race but of finding the way of embracing the opportunities offered by AI in a way that is human-centred, ethical, secure, and true to our core values. The EU Member States and the European Commission are developing coordinated national and European strategies, recognising that only together we can succeed. We can build on our areas of strength including excellent research, leadership in some industrial sectors like automotive and robotics, a solid legal and regulatory framework, and very rich cultural diversity also at regional and sub-regional levels. It is generally recognised that AI can flourish only if supported by a robust computing infrastructure and good quality data: â€¢ With respect to computing, we identified a window of opportunity for Europe to invest in the emerging new paradigm of computing distributed towards the edges of the network, in addition to centralised facilities. This will support also the future deployment of 5G and the Internet of Things. â€¢ With respect to data, we argue in favour of learning from successful Internet companies, opening access to data and developing interactivity with the users rather than just broadcasting data. In this way, we can develop ecosystems of public administrations, firms, and civil society enriching the data to make it fit for AI applications responding to European needs. We should embrace the opportunities afforded by AI but not uncritically. The black box characteristics of most leading AI techniques make them opaque even to specialists. AI systems are currently limited to narrow and well-defined tasks, and their technologies inherit imperfections from their human creators, such as the well-recognised bias effect present in data. We should challenge the shortcomings of AI and work towards strong evaluation strategies, transparent and reliable systems, and good human-AI interactions. Ethical and secure-by-design algorithms are crucial to build trust in this disruptive technology, but we also need a broader engagement of civil society on the values to be embedded in AI and the directions for future development. This social engagement should be part of the effort to strengthen our resilience at all levels from local, to national and European, across institutions, industry and civil society. Developing local ecosystems of skills, computing, data, and applications can foster the engagement of local communities, respond to their needs, harness local creativity and knowledge, and build a human-centred, diverse, and socially driven AI. We still know very little about how AI will impact the way we think, make decisions, relate to each other, and how it will affect our jobs. This uncertainty can be a source of concern but is also a sign of opportunity. The future is not yet written. We can shape it based on our collective vision of what future we would like to have. But we need to act together and act fast.","",""
120,"Hoang Nguyen, X. Bui","Predicting Blast-Induced Air Overpressure: A Robust Artificial Intelligence System Based on Artificial Neural Networks and Random Forest",2018,"","","","",188,"2022-07-13 09:19:39","","10.1007/s11053-018-9424-1","","",,,,,120,30.00,60,2,4,"","",""
90,"M. Alsharqi, W. Woodward, J. Mumith, D. C. Markham, R. Upton, P. Leeson","Artificial intelligence and echocardiography",2018,"","","","",189,"2022-07-13 09:19:39","","10.1530/ERP-18-0056","","",,,,,90,22.50,15,6,4,"Echocardiography plays a crucial role in the diagnosis and management of cardiovascular disease. However, interpretation remains largely reliant on the subjective expertise of the operator. As a result inter-operator variability and experience can lead to incorrect diagnoses. Artificial intelligence (AI) technologies provide new possibilities for echocardiography to generate accurate, consistent and automated interpretation of echocardiograms, thus potentially reducing the risk of human error. In this review, we discuss a subfield of AI relevant to image interpretation, called machine learning, and its potential to enhance the diagnostic performance of echocardiography. We discuss recent applications of these methods and future directions for AI-assisted interpretation of echocardiograms. The research suggests it is feasible to apply machine learning models to provide rapid, highly accurate and consistent assessment of echocardiograms, comparable to clinicians. These algorithms are capable of accurately quantifying a wide range of features, such as the severity of valvular heart disease or the ischaemic burden in patients with coronary artery disease. However, the applications and their use are still in their infancy within the field of echocardiography. Research to refine methods and validate their use for automation, quantification and diagnosis are in progress. Widespread adoption of robust AI tools in clinical echocardiography practice should follow and have the potential to deliver significant benefits for patient outcome.","",""
100,"K. Yasaka, O. Abe","Deep learning and artificial intelligence in radiology: Current applications and future directions",2018,"","","","",190,"2022-07-13 09:19:39","","10.1371/journal.pmed.1002707","","",,,,,100,25.00,50,2,4,"Radiological imaging diagnosis plays important roles in clinical patient management. Deep learning with convolutional neural networks (CNNs) is recently gaining wide attention for its high performance in recognizing images. If CNNs realize their promise in the context of radiology, they are anticipated to help radiologists achieve diagnostic excellence and to enhance patient healthcare. Here, we discuss very recent developments in the field, including studies published in the current PLOS Medicine Special Issue on Machine Learning in Health and Biomedicine, with comment on expectations and planning for artificial intelligence (AI) in the radiology clinic. Chest radiographs are one of the most utilized radiological modalities in the world and have been collected into a number of large datasets currently available to machine learning researchers. In this Special Issue, three groups of researchers applied deep learning to radiological imaging diagnosis using this modality. In the first, Pranav Rajpurkar and colleagues found that deep learning models detected clinically important abnormalities (e.g., edema, fibrosis, mass, pneumonia, and pneumothorax) on chest radiography, at a performance level comparable to practicing radiologists [1]. In a similar study, Andrew Taylor and colleagues developed deep learning models that detected clinically significant pneumothoraces on chest radiography with excellent performance on data from the same site—with areas under the receiver operating characteristic curve (AUC) of 0.94–0.96 [2]. Meanwhile, Eric Oermann and colleagues investigated how well deep learning models that detected pneumonia on chest radiography generalized across different hospitals. They found that models trained on pooled data from sites with different pneumonia prevalence performed well on new pooled data from these same sites (AUC of 0.93–0.94) but significantly less well on external data (AUC 0.75–0.89); additional analyses supported the interpretation that deep learning models diagnosing pneumonia on chest radiography are able to exploit confounding information that is associated with pneumonia prevalence [3]. Also in this Special Issue, Nicholas Bien and colleagues applied deep learning techniques to detect knee abnormalities on magnetic resonance (MR) imaging and found that the trained model showed near-human-level performance [4]. Taking these four studies together, we can interpret that deep learning is currently able to diagnose a number of conditions using radiological data, but such diagnostic models may not be robust to a change in location. These Special Issue studies join a growing number of applications of deep learning to radiological images from various modalities that can aid with detection, diagnosis, staging, and subclassification of conditions. Cerebral aneurysms can be detected on MR angiography with","",""
71,"Vahid Nourani, Gozen Elkiran, S. Abba","Wastewater treatment plant performance analysis using artificial intelligence - an ensemble approach.",2018,"","","","",191,"2022-07-13 09:19:39","","10.2166/wst.2018.477","","",,,,,71,17.75,24,3,4,"In the present study, three different artificial intelligence based non-linear models, i.e. feed forward neural network (FFNN), adaptive neuro fuzzy inference system (ANFIS), support vector machine (SVM) approaches and a classical multi-linear regression (MLR) method were applied for predicting the performance of Nicosia wastewater treatment plant (NWWTP), in terms of effluent biological oxygen demand (BODeff), chemical oxygen demand (CODeff) and total nitrogen (TNeff). The daily data were used to develop single and ensemble models to improve the prediction ability of the methods. The obtained results of single models proved that, ANFIS model provides effective outcomes in comparison with single models. In the ensemble modeling, simple averaging ensemble, weighted averaging ensemble and neural network ensemble techniques were proposed subsequently to improve the performance of the single models. The results showed that in prediction of BODeff, the ensemble models of simple averaging ensemble (SAE), weighted averaging ensemble (WAE) and neural network ensemble (NNE), increased the performance efficiency of artificial intelligence (AI) modeling up to 14%, 20% and 24% at verification phase, respectively, and less than or equal to 5% for both CODeff and TNeff in calibration phase. This shows that NNE model is more robust and reliable ensemble method for predicting the NWWTP performance due to its non-linear averaging kernel.","",""
68,"Y. Mori, S. Kudo, Hussein E. N. Mohmed, M. Misawa, N. Ogata, H. Itoh, M. Oda, K. Mori","Artificial intelligence and upper gastrointestinal endoscopy: Current status and future perspective",2019,"","","","",192,"2022-07-13 09:19:39","","10.1111/den.13317","","",,,,,68,22.67,9,8,3,"With recent breakthroughs in artificial intelligence, computer‐aided diagnosis (CAD) for upper gastrointestinal endoscopy is gaining increasing attention. Main research focuses in this field include automated identification of dysplasia in Barrett's esophagus and detection of early gastric cancers. By helping endoscopists avoid missing and mischaracterizing neoplastic change in both the esophagus and the stomach, these technologies potentially contribute to solving current limitations of gastroscopy. Currently, optical diagnosis of early‐stage dysplasia related to Barrett's esophagus can be precisely achieved only by endoscopists proficient in advanced endoscopic imaging, and the false‐negative rate for detecting gastric cancer is approximately 10%. Ideally, these novel technologies should work during real‐time gastroscopy to provide on‐site decision support for endoscopists regardless of their skill; however, previous studies of these topics remain ex vivo and experimental in design. Therefore, the feasibility, effectiveness, and safety of CAD for upper gastrointestinal endoscopy in clinical practice remain unknown, although a considerable number of pilot studies have been conducted by both engineers and medical doctors with excellent results. This review summarizes current publications relating to CAD for upper gastrointestinal endoscopy from the perspective of endoscopists and aims to indicate what is required for future research and implementation in clinical practice.","",""
0,"Joseph Noussa-Yao, D. Heudes, P. Degoulet","Using Artificial Intelligence and Big Data-Based Documents to Optimize Medical Coding",2019,"","","","",193,"2022-07-13 09:19:39","","10.5772/INTECHOPEN.85749","","",,,,,0,0.00,0,3,3,"Clinical information systems (CISs) in some hospitals streamline the data management from data warehouses. These warehouses contain heterogeneous information from all medical specialties that offer patient care services. It is increasingly difficult to manage large volumes of data in a specific clinical context such as quality coding of medical services. The document-based not only SQL (NoSQL) model can provide an accessible, extensive, and robust coding data management framework while maintaining certain flexibility. This paper focuses on the design and implementation of a big data-coding warehouse, and it also defines the rules to convert a conceptual model of coding into a document-oriented logical model. Using that model, we implemented and analyzed a big data-coding warehouse via the MongoDB database and evaluated it using data research monoand multicriteria and then calculated the precision of our model.","",""
0,"A. Potapov, A. A. Pakhomov, V. I. Grachev","Development of Methods for Solving Ill-Posed Inverse Problems in Processing Multidimensional Signals in Problems of Artificial Intelligence, Radiolocation and Medical Diagnostics",2018,"","","","",194,"2022-07-13 09:19:39","","10.1007/978-3-030-12082-5_6","","",,,,,0,0.00,0,3,4,"","",""
44,"C. Krittanawong, A. Bomback, U. Baber, S. Bangalore, F. Messerli, W. Wilson Tang","Future Direction for Using Artificial Intelligence to Predict and Manage Hypertension",2018,"","","","",195,"2022-07-13 09:19:39","","10.1007/s11906-018-0875-x","","",,,,,44,11.00,7,6,4,"","",""
32,"Mohammed Falah Allawi, O. Jaafar, F. Mohamad Hamzah, S. M. S. Abdullah, A. El-Shafie","Review on applications of artificial intelligence methods for dam and reservoir-hydro-environment models",2018,"","","","",196,"2022-07-13 09:19:39","","10.1007/s11356-018-1867-8","","",,,,,32,8.00,6,5,4,"","",""
32,"S. Park, H. Kressel","Connecting Technological Innovation in Artificial Intelligence to Real-world Medical Practice through Rigorous Clinical Validation: What Peer-reviewed Medical Journals Could Do",2018,"","","","",197,"2022-07-13 09:19:39","","10.3346/jkms.2018.33.e152","","",,,,,32,8.00,16,2,4,"Artificial intelligence (AI) is projected to substantially influence clinical practice in the foreseeable future. However, despite the excitement around the technologies, it is yet rare to see examples of robust clinical validation of the technologies and, as a result, very few are currently in clinical use. A thorough, systematic validation of AI technologies using adequately designed clinical research studies before their integration into clinical practice is critical to ensure patient benefit and safety while avoiding any inadvertent harms. We would like to suggest several specific points regarding the role that peer-reviewed medical journals can play, in terms of study design, registration, and reporting, to help achieve proper and meaningful clinical validation of AI technologies designed to make medical diagnosis and prediction, focusing on the evaluation of diagnostic accuracy efficacy. Peer-reviewed medical journals can encourage investigators who wish to validate the performance of AI systems for medical diagnosis and prediction to pay closer attention to the factors listed in this article by emphasizing their importance. Thereby, peer-reviewed medical journals can ultimately facilitate translating the technological innovations into real-world practice while securing patient safety and benefit.","",""
0,"Svitlana Volkova, Dustin L. Arendt, Emily Saldanha, M. Glenski, Ellyn Ayton, Joseph A. Cottam, Sinan G. Aksoy, Brett Jefferson, Karthnik Shrivaram","Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",2021,"","","","",198,"2022-07-13 09:19:39","","10.1007/s10588-021-09351-y","","",,,,,0,0.00,0,9,1,"","",""
167,"Max Tegmark","Life 3.0: Being Human in the Age of Artificial Intelligence",2017,"","","","",199,"2022-07-13 09:19:39","","","","",,,,,167,33.40,167,1,5,"New York Times Best Seller How will Artificial Intelligence affect crime, war, justice, jobs, society and our very sense of being human? The rise of AI has the potential to transform our future more than any other technologyand theres nobody better qualified or situated to explore that future than Max Tegmark, an MIT professor whos helped mainstream research on how to keep AI beneficial. How can we grow our prosperity through automation without leaving people lacking income or purpose? What career advice should we give todays kids? How can we make future AI systems more robust, so that they do what we want without crashing, malfunctioning or getting hacked? Should we fear an arms race in lethal autonomous weapons? Will machines eventually outsmart us at all tasks, replacing humans on the job market and perhaps altogether? Will AI help life flourish like never before or give us more power than we can handle? What sort of future do you want? This book empowers you to join what may be the most important conversation of our time. It doesnt shy away from the full range of viewpoints or from the most controversial issuesfrom superintelligence to meaning, consciousness and the ultimate physical limits on life in the cosmos.","",""
36,"William R. Frey, D. Patton, M. Gaskell, K. McGregor","Artificial Intelligence and Inclusion: Formerly Gang-Involved Youth as Domain Experts for Analyzing Unstructured Twitter Data",2018,"","","","",200,"2022-07-13 09:19:39","","10.1177/0894439318788314","","",,,,,36,9.00,9,4,4,"Mining social media data for studying the human condition has created new and unique challenges. When analyzing social media data from marginalized communities, algorithms lack the ability to accurately interpret off-line context, which may lead to dangerous assumptions about and implications for marginalized communities. To combat this challenge, we hired formerly gang-involved young people as domain experts for contextualizing social media data in order to create inclusive, community-informed algorithms. Utilizing data from the Gang Intervention and Computer Science Project—a comprehensive analysis of Twitter data from gang-involved youth in Chicago—we describe the process of involving formerly gang-involved young people in developing a new part-of-speech tagger and content classifier for a prototype natural language processing system that detects aggression and loss in Twitter data. We argue that involving young people as domain experts leads to more robust understandings of context, including localized language, culture, and events. These insights could change how data scientists approach the development of corpora and algorithms that affect people in marginalized communities and who to involve in that process. We offer a contextually driven interdisciplinary approach between social work and data science that integrates domain insights into the training of qualitative annotators and the production of algorithms for positive social impact.","",""
