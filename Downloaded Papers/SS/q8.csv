Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
1,"Michael Tsang, James Enouen, Yan Liu","Interpretable Artificial Intelligence through the Lens of Feature Interaction",2021,"","","","",1,"2022-07-13 09:19:47","","","","",,,,,1,1.00,0,3,1,"Deep learning, alongside other modern machine learning techniques, has become the state of the art solution for a diverse range of real-world tasks. These include a variety of sensitive applications such as healthcare, finance, autonomous driving, criminal justice, and others which all pose significant concerns for fairness, robustness, safety, and trustworthiness. Despite these applications to critical tasks, deep networks are infamously referred to as black-box models because of their total lack of transparency in decision-making. If we are able to gain insight into how a model is coming to its conclusions, we are able to more clearly assess the trustworthiness and validity of its decisions. Consequently, an abundance of ongoing research is attempting to address model interpretability as the key problem to resolving these issues. There are many methods which are currently used to provide explanations of complex model predictions. LIME (Ribeiro et al., 2016) fits a local linear model around a data point, showing which features positively and negatively influence the prediction results. Despite the overall model being nonlinear, the local model gets an interpretable picture of how the model looks at small scales around the data point. Extensions of this method use other interpretable models like small decision tress. Shapley Values and SHAP follows a similar idea to assign a score to each feature, using a gametheoretic formulation which treats each feature as a player causing the final prediction (Lundberg and Lee, 2017). Its more rigorous formulation yields guarantees of its explanations summing up to the prediction score, but practically it usually must be estimated because of its high computational cost. Shuffle-based feature importance permutes the data of each feature to ascertain its importance in the final prediction in comparison to its normal prediction (Fisher et al., 2018). IG uses the fundamental theorem of calculus to provide additive explanations of a prediction (Sundararajan et al., 2017). This method is very popular in computer vision where its computational efficiency and saliency are prized, even though other work has exposed some of its shortcomings in providing an interpretation (Adebayo et al., 2018). Other methods are specifically designed for computer vision like TCAV (Kim et al., 2018) which finds a ‘concept direction’ corresponding to a large sample of concept images from the user. Surprisingly, all of these most popular interpretability methods share the same one limitation. None of these methods consider the shared importance of groups of two or more features; they only look at the effects had by each of the features individually. A feature interaction between two variables broadly describes a situation where both of the features/ variables are simultaneously important for a model’s prediction. In text applications for sentiment, ”not good” is a very simple example of two words strongly interacting with one another to create a negative sentiment. In modern-day applications, neural networks are usually hailed as amazing function approximators exactly because of their incredible ability to automatically uncover these kinds of complex relationships between the variables of the dataset. In many ways, however,","",""
6,"Kaveri A. Thakoor, Sharath C. Koorathota, D. Hood, P. Sajda","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images",2020,"","","","",2,"2022-07-13 09:19:47","","10.1109/tbme.2020.3043215","","",,,,,6,3.00,2,4,2,"Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","",""
0,"Yunzhe Li, Shiyi Cheng, Yujia Xue, L. Tian","Interpretable deep learning for imaging through scattering medium",2021,"","","","",3,"2022-07-13 09:19:47","","10.1117/12.2594043","","",,,,,0,0.00,0,4,1,"Imaging through scattering medium has wide applications across many areas. Here, we present a new deep learning framework for improving the robustness against physical perturbations of the scattering medium. The trained DNN can make high-quality predictions beyond the training range which is across 10X depth-of-field (DOF). We develop a new analysis framework based on dimensionality reduction for revealing the information contained in the speckle dataset, interpreting the mechanism of our DNN, and visualizing the generalizability of the DNN model. This allows us to further elucidate on the information encoded in both the raw speckle measurements and the working principle of our speckle-imaging deep learning model.","",""
3,"A. Preece, Daniel Harborne, R. Raghavendra, Richard J. Tomsett, Dave Braines","Provisioning Robust and Interpretable AI/ML-Based Service Bundles",2018,"","","","",4,"2022-07-13 09:19:47","","10.1109/MILCOM.2018.8599838","","",,,,,3,0.75,1,5,4,"Coalition operations environments are characterised by the need to share intelligence, surveillance and reconnaissance services. Increasingly, such services are based on artificial intelligence (AI)and machine learning (ML)technologies. Two key issues in the exploitation of AI/ML services are robustness and interpretability. Employing a diverse portfolio of services can make a system robust to ‘unknown unknowns’. Interpretability - the need for services to offer explanation facilities to engender user trust - can be addressed by a variety of methods to generate either transparent or post hoc explanations according to users' requirements. This paper shows how a service-provisioning framework for coalition operations can be extended to address specific requirements for robustness and interpretability, allowing automatic selection of service bundles for intelligence, surveillance and reconnaissance tasks. The approach is demonstrated in a case study on traffic monitoring featuring a diverse set of AI/ML services based on deep neural networks and heuristic reasoning approaches.","",""
52,"Mathias Lechner, Ramin M. Hasani, Alexander Amini, T. Henzinger, D. Rus, R. Grosu","Neural circuit policies enabling auditable autonomy",2020,"","","","",5,"2022-07-13 09:19:47","","10.1038/s42256-020-00237-3","","",,,,,52,26.00,9,6,2,"","",""
5,"Blake Ruprecht, Wenlong Wu, M. Islam, Derek T. Anderson, James M. Keller, G. Scott, Curt Davis, F. Petry, P. Elmore, Kristen Nock, Elizabeth Gilmour","Possibilistic Clustering Enabled Neuro Fuzzy Logic",2020,"","","","",6,"2022-07-13 09:19:47","","10.1109/FUZZ48607.2020.9177593","","",,,,,5,2.50,1,11,2,"Artificial neural networks are a dominant force in our modern era of data-driven artificial intelligence. The adaptive neuro fuzzy inference system (ANFIS) is a neural network based on fuzzy logic versus a more traditional premise like convolution. Advantages of ANFIS include the ability to encode and potentially understand machine learned neural information in the pursuit of explainable, interpretable, and ultimately trustworthy artificial intelligence. However, real-world data is almost always imperfect, e.g., incomplete or noisy, and ANFIS is not naturally robust. Specifically, ANFIS is susceptible to over inflated uncertainty, poor antecedent (fuzzy set) data alignment, degenerate optimization conditions, and hard to interpret logic, to name a few factors. Herein, we explore the use of possibilistic clustering to identify outliers, specifically typicality degrees, to increase the robustness of ANFIS; or any fuzzy logic neuron/network. Experiments are presented that demonstrate the need and quality of the proposed solutions in the pursuit of robust interpretable machine learned neuro fuzzy logic solutions.","",""
31,"D. Hong, W. He, N. Yokoya, Jing Yao, Lianru Gao, Liang-pei Zhang, J. Chanussot, Xiaoxiang Zhu","Interpretable Hyperspectral Artificial Intelligence: When nonconvex modeling meets hyperspectral remote sensing",2021,"","","","",7,"2022-07-13 09:19:47","","10.1109/MGRS.2021.3064051","","",,,,,31,31.00,4,8,1,"Hyperspectral (HS) imaging, also known as image spectrometry, is a landmark technique in geoscience and remote sensing (RS). In the past decade, enormous efforts have been made to process and analyze these HS products, mainly by seasoned experts. However, with an ever-growing volume of data, the bulk of costs in manpower and material resources poses new challenges for reducing the burden of manual labor and improving efficiency. For this reason, it is urgent that more intelligent and automatic approaches for various HS RS applications be developed. Machine learning (ML) tools with convex optimization have successfully undertaken the tasks of numerous artificial intelligence (AI)-related applications; however, their ability to handle complex practical problems remains limited, particularly for HS data, due to the effects of various spectral variabilities in the process of HS imaging and the complexity and redundancy of higher-dimensional HS signals. Compared to convex models, nonconvex modeling, which is capable of characterizing more complex real scenes and providing model interpretability technically and theoretically, has proven to be a feasible solution that reduces the gap between challenging HS vision tasks and currently advanced intelligent data processing models.","",""
58,"Nikos Tsiknakis, Eleftherios Trivizakis, Evangelia E Vassalou, G. Papadakis, D. Spandidos, A. Tsatsakis, J. Sánchez-García, R. López-González, N. Papanikolaou, A. Karantanas, K. Marias","Interpretable artificial intelligence framework for COVID-19 screening on chest X-rays",2020,"","","","",8,"2022-07-13 09:19:47","","10.3892/etm.2020.8797","","",,,,,58,29.00,6,11,2,"COVID-19 has led to an unprecedented healthcare crisis with millions of infected people across the globe often pushing infrastructures, healthcare workers and entire economies beyond their limits. The scarcity of testing kits, even in developed countries, has led to extensive research efforts towards alternative solutions with high sensitivity. Chest radiological imaging paired with artificial intelligence (AI) can offer significant advantages in diagnosis of novel coronavirus infected patients. To this end, transfer learning techniques are used for overcoming the limitations emanating from the lack of relevant big datasets, enabling specialized models to converge on limited data, as in the case of X-rays of COVID-19 patients. In this study, we present an interpretable AI framework assessed by expert radiologists on the basis on how well the attention maps focus on the diagnostically-relevant image regions. The proposed transfer learning methodology achieves an overall area under the curve of 1 for a binary classification problem across a 5-fold training/testing dataset.","",""
6,"M. Afnan, Yan-he Liu, Vincent Conitzer, C. Rudin, A. Mishra, J. Savulescu, M. Afnan","Interpretable, not black-box, artificial intelligence should be used for embryo selection",2021,"","","","",9,"2022-07-13 09:19:47","","10.1093/hropen/hoab040","","",,,,,6,6.00,1,7,1,"Abstract Artificial intelligence (AI) techniques are starting to be used in IVF, in particular for selecting which embryos to transfer to the woman. AI has the potential to process complex data sets, to be better at identifying subtle but important patterns, and to be more objective than humans when evaluating embryos. However, a current review of the literature shows much work is still needed before AI can be ethically implemented for this purpose. No randomized controlled trials (RCTs) have been published, and the efficacy studies which exist demonstrate that algorithms can broadly differentiate well between ‘good-’ and ‘poor-’ quality embryos but not necessarily between embryos of similar quality, which is the actual clinical need. Almost universally, the AI models were opaque (‘black-box’) in that at least some part of the process was uninterpretable. This gives rise to a number of epistemic and ethical concerns, including problems with trust, the possibility of using algorithms that generalize poorly to different populations, adverse economic implications for IVF clinics, potential misrepresentation of patient values, broader societal implications, a responsibility gap in the case of poor selection choices and introduction of a more paternalistic decision-making process. Use of interpretable models, which are constrained so that a human can easily understand and explain them, could overcome these concerns. The contribution of AI to IVF is potentially significant, but we recommend that AI models used in this field should be interpretable, and rigorously evaluated with RCTs before implementation. We also recommend long-term follow-up of children born after AI for embryo selection, regulatory oversight for implementation, and public availability of data and code to enable research teams to independently reproduce and validate existing models.","",""
77,"Fei Wang, R. Kaushal, D. Khullar","Should Health Care Demand Interpretable Artificial Intelligence or Accept “Black Box” Medicine?",2019,"","","","",10,"2022-07-13 09:19:47","","10.7326/M19-2548","","",,,,,77,25.67,26,3,3,"Health care applications of artificial intelligence (AI) have recently emerged. Artificial intelligence approaches, such as deep learning, rely on vast amounts of data and complex model structures ...","",""
4,"William Souillard-Mandar, D. Penney, B. Schaible, Á. Pascual-Leone, R. Au, Randall Davis","DCTclock: Clinically-Interpretable and Automated Artificial Intelligence Analysis of Drawing Behavior for Capturing Cognition",2021,"","","","",11,"2022-07-13 09:19:47","","10.3389/fdgth.2021.750661","","",,,,,4,4.00,1,6,1,"Developing tools for efficiently measuring cognitive change specifically and brain health generally—whether for clinical use or as endpoints in clinical trials—is a major challenge, particularly for conditions such as Alzheimer's disease. Technology such as connected devices and advances in artificial intelligence offer the possibility of creating and deploying clinical-grade tools with high sensitivity, rapidly, cheaply, and non-intrusively. Starting from a widely-used paper and pencil cognitive status test—The Clock Drawing Test—we combined a digital input device to capture time-stamped drawing coordinates with a machine learning analysis of drawing behavior to create DCTclock™, an automated analysis of nuances in cognitive performance beyond successful task completion. Development and validation was conducted on a dataset of 1,833 presumed cognitively unimpaired and clinically diagnosed cognitively impaired individuals with varied neurological conditions. We benchmarked DCTclock against existing clock scoring systems and the Mini-Mental Status Examination, a widely-used but lengthier cognitive test, and showed that DCTclock offered a significant improvement in the detection of early cognitive impairment and the ability to characterize individuals along the Alzheimer's disease trajectory. This offers an example of a robust framework for creating digital biomarkers that can be used clinically and in research for assessing neurological function.","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",12,"2022-07-13 09:19:47","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
14,"M. Zokaeinikoo, P. Kazemian, P. Mitra, S. Kumara","AIDCOV: An Interpretable Artificial Intelligence Model for Detection of COVID-19 from Chest Radiography Images",2020,"","","","",13,"2022-07-13 09:19:47","","10.1101/2020.05.24.20111922","","",,,,,14,7.00,4,4,2,"As the Coronavirus Disease 2019 (COVID-19) pandemic continues to grow globally, testing to detect COVID-19 and isolating individuals who test positive remains to be the primary strategy for preventing community spread of the disease. The current gold standard method of testing for COVID-19 is the reverse transcription polymerase chain reaction (RT-PCR) test. The RT-PCR test, however, has an imperfect sensitivity (around 70%), is time-consuming and labor-intensive, and is in short supply, particularly in resource-limited countries. Therefore, automatic and accurate detection of COVID-19 using medical imaging modalities such as chest X-ray and Computed Tomography, which are more widely available and accessible, can be beneficial. We develop a novel hierarchical attention neural network model to classify chest radiography images as belonging to a person with either COVID-19, other infections, or no pneumonia (i.e., normal). We refer to this model as Artificial Intelligence for Detection of COVID-19 (AIDCOV). The hierarchical structure in AIDCOV captures the dependency of features and improves model performance while the attention mechanism makes the model interpretable and transparent. Using a publicly available dataset of 5801 chest images, we demonstrate that our model achieves a mean cross-validation accuracy of 97.8%. AIDCOV has a sensitivity of 99.3%, a specificity of 99.98%, and a positive predictive value of 99.6% in detecting COVID-19 from chest radiography images. AIDCOV can be used in conjunction with or instead of RT-PCR testing (where RT-PCR testing is unavailable) to detect and isolate individuals with COVID-19 and prevent onward transmission to the general population and healthcare workers.","",""
19,"Adarsh Ghosh, D. Kandasamy","Interpretable Artificial Intelligence: Why and When.",2020,"","","","",14,"2022-07-13 09:19:47","","10.2214/ajr.19.22145","","",,,,,19,9.50,10,2,2,"OBJECTIVE. The purpose of this article is to discuss the problem of interpretability of artificial intelligence (AI) and highlight the need for continuing scientific discovery using AI algorithms to deal with medical big data. CONCLUSION. A plethora of AI algorithms are currently being used in medical research, but the opacity of these algorithms makes their clinical implementation a dilemma. Clinical decision making cannot be assigned to something that we do not understand. Therefore, AI research should not be limited to reporting accuracy and sensitivity but, rather, should try to explain the underlying reasons for the predictions, in an attempt to enrich biologic understanding and knowledge.","",""
2,"","Interpretable Artificial Intelligence: A Perspective of Granular Computing",2021,"","","","",15,"2022-07-13 09:19:47","","10.1007/978-3-030-64949-4","","",,,,,2,2.00,0,0,1,"","",""
15,"A. Warman, P. Warman, Ayushman Sharma, P. Parikh, Roshan Warman, Narayan A Viswanadhan, Lu Chen, S. Mohapatra, S. Mohapatra, G. Sapiro","Interpretable Artificial Intelligence for COVID-19 Diagnosis from Chest CT Reveals Specificity of Ground-Glass Opacities",2020,"","","","",16,"2022-07-13 09:19:47","","10.1101/2020.05.16.20103408","","",,,,,15,7.50,2,10,2,"Background The use of CT imaging enhanced by artificial intelligence to effectively diagnose COVID-19, instead of or in addition to reverse transcription-polymerase chain reaction (RT-PCR), can improve widespread COVID-19 detection and resource allocation. Methods 904 axial lung window CT slices from 338 patients in 17 countries were collected and labeled. The data included 606 images from COVID-19 positive patients (confirmed via RT-PCR), 224 images of a variety of other pulmonary diseases including viral pneumonias, and 74 images of normal patients. We developed, trained, validated, and tested an object detection model which detects features in three categories: ground-glass opacities (GGOs) for COVID-19, GGOs for non-COVID-19 diseases, and features that are inconsistent with a COVID-19 diagnosis. These collected features are passed into an interpretable decision tree model to make a suggested diagnosis. Results On an independent test of 219 images from COVID-19 positive, a variety of pneumonia, and healthy patients, the model predicted COVID-19 diagnoses with an accuracy of 96.80 % (95% confidence interval [CI], 96.75 to 96.86) , AUC-ROC of 0.9664 (95% CI, 0.9659 to 0.9671) , sensitivity of 98.33% (95% CI, 98.29 to 98.40) , precision of 95.93% (95% CI, 95.83 to 95.99), and specificity of 94.95% (95% CI, 94.84 to 95.05). On an independent test of 34 images from asymptomatic COVID-19 positive patients, our model achieved an accuracy of 97.06% (95% CI, 96.81 to 97.06) and a sensitivity of 96.97% (95% CI, 96.71 to 96.97). Similarly high performance was also obtained for out-of-sample countries, and no significant performance difference was obtained between genders. Conclusion We present an interpretable artificial intelligence CT analysis tool to diagnose COVID-19 in both symptomatic and asymptomatic patients. Further, our model is able to differentiate COVID-19 GGOs from similar pathologies suggesting that GGOs can be disease-specific.","",""
11,"I. Linkov, S. Galaitsi, Benjamin D. Trump, J. Keisler, A. Kott","Cybertrust: From Explainable to Actionable and Interpretable Artificial Intelligence",2020,"","","","",17,"2022-07-13 09:19:47","","10.1109/MC.2020.2993623","","",,,,,11,5.50,2,5,2,"We argue that artificial intelligence (AI) systems should be designed with features that build trust by bringing decision-analytic perspectives into AI. Actionable and interpretable AI will incorporate explicit quantifications and visualizations of user confidence in AI recommendations.","",""
353,"Erico Tjoa, Cuntai Guan","A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",2019,"","","","",18,"2022-07-13 09:19:47","","10.1109/TNNLS.2020.3027314","","",,,,,353,117.67,177,2,3,"Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",19,"2022-07-13 09:19:47","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",20,"2022-07-13 09:19:47","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",21,"2022-07-13 09:19:47","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
68,"Ilia Stepin, J. M. Alonso, Alejandro Catalá, Martin Pereira-Fariña","A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence",2021,"","","","",22,"2022-07-13 09:19:47","","10.1109/ACCESS.2021.3051315","","",,,,,68,68.00,17,4,1,"A number of algorithms in the field of artificial intelligence offer poorly interpretable decisions. To disclose the reasoning behind such algorithms, their output can be explained by means of so-called evidence-based (or factual) explanations. Alternatively, contrastive and counterfactual explanations justify why the output of the algorithms is not any different and how it could be changed, respectively. It is of crucial importance to bridge the gap between theoretical approaches to contrastive and counterfactual explanation and the corresponding computational frameworks. In this work we conduct a systematic literature review which provides readers with a thorough and reproducible analysis of the interdisciplinary research field under study. We first examine theoretical foundations of contrastive and counterfactual accounts of explanation. Then, we report the state-of-the-art computational frameworks for contrastive and counterfactual explanation generation. In addition, we analyze how grounded such frameworks are on the insights from the inspected theoretical approaches. As a result, we highlight a variety of properties of the approaches under study and reveal a number of shortcomings thereof. Moreover, we define a taxonomy regarding both theoretical and practical approaches to contrastive and counterfactual explanation.","",""
5,"Christopher J. Hazard, Christopher Fusting, Michael Resnick, Michael Auerbach, M. Meehan, Valeri Korobov","Natively Interpretable Machine Learning and Artificial Intelligence: Preliminary Results and Future Directions",2019,"","","","",23,"2022-07-13 09:19:47","","","","",,,,,5,1.67,1,6,3,"Machine learning models have become more and more complex in order to better approximate complex functions. Although fruitful in many domains, the added complexity has come at the cost of model interpretability. The once popular k-nearest neighbors (kNN) approach, which finds and uses the most similar data for reasoning, has received much less attention in recent decades due to numerous problems when compared to other techniques. We show that many of these historical problems with kNN can be overcome, and our contribution has applications not only in machine learning but also in online learning, data synthesis, anomaly detection, model compression, and reinforcement learning, without sacrificing interpretability. We introduce a synthesis between kNN and information theory that we hope will provide a clear path towards models that are innately interpretable and auditable. Through this work we hope to gather interest in combining kNN with information theory as a promising path to fully auditable machine learning and artificial intelligence.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",24,"2022-07-13 09:19:47","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
0,"Daniel Grahn, Melonie Richey","The prediction management framework: ethical, governable, and interpretable deployment of artificial intelligence/machine learning systems",2022,"","","","",25,"2022-07-13 09:19:47","","10.1117/12.2617772","","",,,,,0,0.00,0,2,1,"As defense organizations integrate artificial intelligence (AI) into evermore critical operations, especially those near the tactical edge with real-time decision making, the necessity of a standardized, robust framework for deployment and management of AI systems is increasing. In this paper, we propose a Prediction Management Framework (PMF) that aligns with the Department of Defense’s Ethical Principles for AI for ethical, governable, and interpretable deployments. We explore different requirements for the framework with inspiration drawn from various regulatory, safety, and communication standards. In support of these requirements, we offer recommendations and implementation guidance to provide comprehensive visibility into the system.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",26,"2022-07-13 09:19:47","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
0,"Beilei Wang, Jie Jing, Xiaochun Huang, Cheng Hua, Qin Qin, Y. Jia, Zhiyong Wang, Lei Jiang, Bai Gao, Les J. Wu, Xianfei Zeng, Fubo Wang, Chuanbin Mao, Shanrong Liu","Establishment of a Knowledge‐and‐Data‐Driven Artificial Intelligence System with Robustness and Interpretability in Laboratory Medicine",2022,"","","","",27,"2022-07-13 09:19:47","","10.1002/aisy.202100204","","",,,,,0,0.00,0,14,1,"Laboratory medicine plays an important role in clinical diagnosis. However, no laboratory‐based artificial intelligence (AI) diagnostic system has been applied in current clinical practice due to the lack of robustness and interpretability. Although many attempts have been made, it is still difficult for doctors to adopt the existing machine learning (ML) patterns in interpreting laboratory (lab) big data. Here, a knowledge‐and‐data‐driven laboratory diagnostic system is developed, termed AI‐based Lab tEst tO diagNosis (AI LEON), by integrating an innovative knowledge graph analysis framework and “mixed XGboost and Genetic Algorithm (MiXG)” technique to simulate the doctor's laboratory‐based diagnosis. To establish AI LEON, we included 89 116 949 laboratory data and 10 423 581 diagnosis data points from 730 113 participants. Among them, 686 626 participants were recruited for training and validating purposes with the remaining for testing purposes. AI LEON automatically identified and analyzed 2071 lab indexes, resulting in multiple disease recommendations that involved 441 common diseases in ten organ systems. AI LEON exhibited outstanding transparency and interpretability in three universal clinical application scenarios and outperformed human physicians in interpreting lab reports. AI LEON is an advanced intelligent system that enables a comprehensive interpretation of lab big data, which substantially improves the clinical diagnosis.","",""
0,"","Proceedings of the Symposium Interpretable AI for Well-being: Understanding Cognitive Bias and Social Embeddedness co-located with Association for the Advancement of Artificial Intelligence 2019 Spring Symposium (AAAI-Spring Symposium 2019), Stanford, CA, March 25-27, 2019",2019,"","","","",28,"2022-07-13 09:19:47","","","","",,,,,0,0.00,0,0,3,"","",""
1,"Kaustubh Supekar, S. Ryali, R. Yuan, Devinder Kumar, C. D. L. Angeles, V. Menon","Robust, Generalizable, and Interpretable Artificial Intelligence–Derived Brain Fingerprints of Autism and Social Communication Symptom Severity",2022,"","","","",29,"2022-07-13 09:19:47","","10.1016/j.biopsych.2022.02.005","","",,,,,1,1.00,0,6,1,"","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",30,"2022-07-13 09:19:47","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
29,"William Gale, L. Oakden-Rayner, G. Carneiro, A. Bradley, L. Palmer","Producing radiologist-quality reports for interpretable artificial intelligence",2018,"","","","",31,"2022-07-13 09:19:47","","","","",,,,,29,7.25,6,5,4,"Current approaches to explaining the decisions of deep learning systems for medical tasks have focused on visualising the elements that have contributed to each decision. We argue that such approaches are not enough to ""open the black box"" of medical decision making systems because they are missing a key component that has been used as a standard communication tool between doctors for centuries: language. We propose a model-agnostic interpretability method that involves training a simple recurrent neural network model to produce descriptive sentences to clarify the decision of deep learning classifiers.  We test our method on the task of detecting hip fractures from frontal pelvic x-rays. This process requires minimal additional labelling despite producing text containing elements that the original deep learning classification model was not specifically trained to detect.  The experimental results show that: 1) the sentences produced by our method consistently contain the desired information, 2) the generated sentences are preferred by doctors compared to current tools that create saliency maps, and 3) the combination of visualisations and generated text is better than either alone.","",""
129,"Arun Das, P. Rad","Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",2020,"","","","",32,"2022-07-13 09:19:47","","","","",,,,,129,64.50,65,2,2,"Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.","",""
105,"M. Reyes, R. Meier, Sérgio Pereira, Carlos A. Silva, F. Dahlweid, H. von Tengg-Kobligk, R. Summers, R. Wiest","On the Interpretability of Artificial Intelligence in Radiology: Challenges and Opportunities.",2020,"","","","",33,"2022-07-13 09:19:47","","10.1148/ryai.2020190043","","",,,,,105,52.50,13,8,2,"As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI ""interpretable"" have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists' opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice. Supplemental material is available for this article. © RSNA, 2020 See also the commentary by Gastounioti and Kontos in this issue.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",34,"2022-07-13 09:19:47","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",35,"2022-07-13 09:19:47","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
5,"N. Amoroso, Domenico Pomarico, A. Fanizzi, V. Didonna, F. Giotta, D. La Forgia, A. Latorre, A. Monaco, Ester Pantaleo, N. Petruzzellis, P. Tamborra, A. Zito, V. Lorusso, R. Bellotti, R. Massafra","A Roadmap towards Breast Cancer Therapies Supported by Explainable Artificial Intelligence",2021,"","","","",36,"2022-07-13 09:19:47","","10.3390/APP11114881","","",,,,,5,5.00,1,15,1,"In recent years personalized medicine reached an increasing importance, especially in the design of oncological therapies. In particular, the development of patients’ profiling strategies suggests the possibility of promising rewards. In this work, we present an explainable artificial intelligence (XAI) framework based on an adaptive dimensional reduction which (i) outlines the most important clinical features for oncological patients’ profiling and (ii), based on these features, determines the profile, i.e., the cluster a patient belongs to. For these purposes, we collected a cohort of 267 breast cancer patients. The adopted dimensional reduction method determines the relevant subspace where distances among patients are used by a hierarchical clustering procedure to identify the corresponding optimal categories. Our results demonstrate how the molecular subtype is the most important feature for clustering. Then, we assessed the robustness of current therapies and guidelines; our findings show a striking correspondence between available patients’ profiles determined in an unsupervised way and either molecular subtypes or therapies chosen according to guidelines, which guarantees the interpretability characterizing explainable approaches to machine learning techniques. Accordingly, our work suggests the possibility to design data-driven therapies to emphasize the differences observed among the patients.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",37,"2022-07-13 09:19:47","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
7,"J. McDermid, Yan Jia, Zoe Porter, I. Habli","Artificial intelligence explainability: the technical and ethical dimensions",2021,"","","","",38,"2022-07-13 09:19:47","","10.1098/rsta.2020.0363","","",,,,,7,7.00,2,4,1,"In recent years, several new technical methods have been developed to make AI-models more transparent and interpretable. These techniques are often referred to collectively as ‘AI explainability’ or ‘XAI’ methods. This paper presents an overview of XAI methods, and links them to stakeholder purposes for seeking an explanation. Because the underlying stakeholder purposes are broadly ethical in nature, we see this analysis as a contribution towards bringing together the technical and ethical dimensions of XAI. We emphasize that use of XAI methods must be linked to explanations of human decisions made during the development life cycle. Situated within that wider accountability framework, our analysis may offer a helpful starting point for designers, safety engineers, service providers and regulators who need to make practical judgements about which XAI methods to employ or to require. This article is part of the theme issue ‘Towards symbiotic autonomous systems’.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",39,"2022-07-13 09:19:47","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",40,"2022-07-13 09:19:47","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",41,"2022-07-13 09:19:47","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
1,"Andrea Torcianti, S. Matzka","Explainable Artificial Intelligence for Predictive Maintenance Applications using a Local Surrogate Model",2021,"","","","",42,"2022-07-13 09:19:47","","10.1109/AI4I51902.2021.00029","","",,,,,1,1.00,1,2,1,"This paper provides an explanatory interface using Local Interpretable Model-agnostic Explanations (LIME) for a predictive maintenance dataset. The explanations are evaluated and the explanatory quality of the model is compared to two previous explainable models for the same dataset.","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",43,"2022-07-13 09:19:47","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",44,"2022-07-13 09:19:47","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",45,"2022-07-13 09:19:47","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
1,"Ying L. Becker, Lingfeng Guo, Odilbek Nurmamatov","Assessing Asset Tail Risk with Artificial Intelligence: The Application of Artificial Neural Network",2020,"","","","",46,"2022-07-13 09:19:47","","10.1108/s2514-465020200000008002","","",,,,,1,0.50,0,3,2,"Value at risk (VaR) and expected shortfall (ES) are popular market risk measurements. The former is not coherent but robust, whereas the latter is coherent but less interpretable, only conditionally backtestable and less robust. In this chapter, we compare an innovative artificial neural network (ANN) model with a time series model in the context of forecasting VaR and ES of the univariate time series of four asset classes: US large capitalization equity index, European large cap equity index, US bond index, and US dollar versus euro exchange rate price index for the period of January 4, 1999, to December 31, 2018. In general, the ANN model has more favorable backtesting results as compared to the autoregressive moving average, generalized autoregressive conditional heteroscedasticity (ARMA-GARCH) time series model. In terms of forecasting accuracy, the ANN model has much fewer in-sample and out-of-sample exceptions than those of the ARMA-GARCH model.","",""
0,"Chao Fang, Zhengfeng Li, Ying Xue, Zheng You","Research on Innovation Path of Artificial Intelligence Technology Based on Comparative Analysis",2020,"","","","",47,"2022-07-13 09:19:47","","10.15302/j-sscae-2020.04.021","","",,,,,0,0.00,0,4,2,"Currently, artificial intelligence (AI) technology has been widely applied in socio-economic development and national defense construction; however, it still requires improvement in terms of flexibility, interpretability, robustness, and security. This study defines AI technology and AI industry and subsequently compares AI technology with nuclear and photovoltaic technologies from the aspects of basic theory, technology development, and market application, aiming to explore an effective path for AI development and innovation. The study reveals that the development of AI technology is bound to shift from an involution to evolution mode and integrated development is an optimized path for AI technology innovation in China. Specifically, a three-step development route should be adopted, including direct transfer of civilian achievements to military use, military–civilian coordinated innovation, and promoting civilian use based on military development. To promote deep integration of AI technology, new research institutions should be established, financial support be increased, talent training be promoted, and ethical research be conducted.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",48,"2022-07-13 09:19:47","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",49,"2022-07-13 09:19:47","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",50,"2022-07-13 09:19:47","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
23,"K. Bera, Nathaniel Braman, Amit Gupta, V. Velcheti, A. Madabhushi","Predicting cancer outcomes with radiomics and artificial intelligence in radiology",2021,"","","","",51,"2022-07-13 09:19:47","","10.1038/s41571-021-00560-7","","",,,,,23,23.00,5,5,1,"","",""
19,"Basim Mahbooba, Mohan Timilsina, R. Sahal, M. Serrano","Explainable Artificial Intelligence (XAI) to Enhance Trust Management in Intrusion Detection Systems Using Decision Tree Model",2021,"","","","",52,"2022-07-13 09:19:47","","10.1155/2021/6634811","","",,,,,19,19.00,5,4,1,"Despite the growing popularity of machine learning models in the cyber-security applications (e.g., an intrusion detection system (IDS)), most of these models are perceived as a black-box. The eXplainable Artificial Intelligence (XAI) has become increasingly important to interpret the machine learning models to enhance trust management by allowing human experts to understand the underlying data evidence and causal reasoning. According to IDS, the critical role of trust management is to understand the impact of the malicious data to detect any intrusion in the system. The previous studies focused more on the accuracy of the various classification algorithms for trust in IDS. They do not often provide insights into their behavior and reasoning provided by the sophisticated algorithm. Therefore, in this paper, we have addressed XAI concept to enhance trust management by exploring the decision tree model in the area of IDS. We use simple decision tree algorithms that can be easily read and even resemble a human approach to decision-making by splitting the choice into many small subchoices for IDS. We experimented with this approach by extracting rules in a widely used KDD benchmark dataset. We also compared the accuracy of the decision tree approach with the other state-of-the-art algorithms.","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",53,"2022-07-13 09:19:47","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
1,"W. Silva, João Ribeiro Pinto, Tiago Gonçalves, Ana F. Sequeira, Jaime S. Cardoso","Explainable Artificial Intelligence for Face Presentation Attack Detection",2020,"","","","",54,"2022-07-13 09:19:47","","","","",,,,,1,0.50,0,5,2,"The use of deep learning techniques for face presentation attack detection (PAD) is increasingly common due to their ability to reach strong accuracy performances. Nonetheless, the use of complex models such as the ones produced with deep learning techniques raises safety and trust concerns, as one is not able to understand the motifs behind model decisions. Furthermore, traditional metrics of evaluation fall short in terms of capturing the desirable working properties of models, which is particularly worrisome when working in high-regulated areas, such as biometrics. In this work, we propose the use of interpretability techniques to further assess the robustness of face PAD models. Moreover, we also define desirable properties for a face PAD model to have, which can be evaluated through interpretability. Experiments were performed using the ROSE Youtu video collection and showed the additional value of interpretability in the identification of model robustness.","",""
120,"R. Byrne","Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning",2019,"","","","",55,"2022-07-13 09:19:47","","10.24963/IJCAI.2019/876","","",,,,,120,40.00,120,1,3,"Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence (AI) applications, and especially in explainable AI (XAI). Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in AI.","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",56,"2022-07-13 09:19:47","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
24,"P. Papadimitroulas, L. Brocki, Neo Christopher Chung, Wistan Marchadour, F. Vermet, L. Gaubert, V. Eleftheriadis, Dimitris Plachouris, D. Visvikis, G. Kagadis, M. Hatt","Artificial intelligence: Deep learning in oncological radiomics and challenges of interpretability and data harmonization.",2021,"","","","",57,"2022-07-13 09:19:47","","10.1016/j.ejmp.2021.03.009","","",,,,,24,24.00,2,11,1,"","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",58,"2022-07-13 09:19:47","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
74,"Andrés Páez","The Pragmatic Turn in Explainable Artificial Intelligence (XAI)",2019,"","","","",59,"2022-07-13 09:19:47","","10.1007/s11023-019-09502-w","","",,,,,74,24.67,74,1,3,"","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",60,"2022-07-13 09:19:47","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",61,"2022-07-13 09:19:47","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",62,"2022-07-13 09:19:47","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
16,"D. Schlessinger, Guillaume Chhor, O. Gevaert, S. Swetter, J. Ko, R. Novoa","Artificial intelligence and dermatology: opportunities, challenges, and future directions.",2019,"","","","",63,"2022-07-13 09:19:47","","10.12788/j.sder.2019.007","","",,,,,16,5.33,3,6,3,"The application of artificial intelligence (AI) to medicine has considerable potential within dermatology, where the majority of diagnoses are based on visual pattern recognition. Opportunities for AI in dermatology include the potential to automate repetitive tasks; optimize time-consuming tasks; extend limited medical resources; improve interobserver reliability issues; and expand the diagnostic toolbox of dermatologists. To achieve the full potential of AI, however, developers must aim to create algorithms representing diverse patient populations; ensure algorithm output is ultimately interpretable; validate algorithm performance prospectively; preserve human-patient interaction when necessary; and demonstrate validity in the eyes of regulatory bodies.","",""
157,"S. C. Rivera, Xiaoxuan Liu, A. Chan, A. Denniston, M. Calvert, H. Ashrafian, A. Beam, G. Collins, A. Darzi, J. Deeks, M. Elzarrad, Cyrus Espinoza, Andre Esteva, L. Faes, L. Ferrante di Ruffano, J. Fletcher, R. Golub, H. Harvey, C. Haug, Christopher Holmes, Adrian Jonas, P. Keane, Christopher J. Kelly, Aaron Y. Lee, Cecilia S Lee, Elaine Manna, J. Matcham, Melissa D. McCradden, D. Moher, Joao Monteiro, C. Mulrow, L. Oakden-Rayner, D. Paltoo, M. Panico, G. Price, Samuel d. Rowley, Richard Savage, Rupa Sarkar, S. Vollmer, C. Yau","Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI Extension",2020,"","","","",64,"2022-07-13 09:19:47","","10.1136/bmj.m3210","","",,,,,157,78.50,16,40,2,"Abstract The SPIRIT 2013 (The Standard Protocol Items: Recommendations for Interventional Trials) statement aims to improve the completeness of clinical trial protocol reporting, by providing evidence-based recommendations for the minimum set of items to be addressed. This guidance has been instrumental in promoting transparent evaluation of new interventions. More recently, there is a growing recognition that interventions involving artificial intelligence need to undergo rigorous, prospective evaluation to demonstrate their impact on health outcomes. The SPIRIT-AI extension is a new reporting guideline for clinical trials protocols evaluating interventions with an AI component. It was developed in parallel with its companion statement for trial reports: CONSORT-AI. Both guidelines were developed using a staged consensus process, involving a literature review and expert consultation to generate 26 candidate items, which were consulted on by an international multi-stakeholder group in a 2-stage Delphi survey (103 stakeholders), agreed on in a consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The SPIRIT-AI extension includes 15 new items, which were considered sufficiently important for clinical trial protocols of AI interventions. These new items should be routinely reported in addition to the core SPIRIT 2013 items. SPIRIT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention will be integrated, considerations around the handling of input and output data, the human-AI interaction and analysis of error cases. SPIRIT-AI will help promote transparency and completeness for clinical trial protocols for AI interventions. Its use will assist editors and peer-reviewers, as well as the general readership, to understand, interpret and critically appraise the design and risk of bias for a planned clinical trial.","",""
159,"Xiaoxuan Liu, S. C. Rivera, D. Moher, M. Calvert, A. Denniston, H. Ashrafian, A. Beam, A. Chan, G. Collins, A. Darzi, J. Deeks, M. Elzarrad, Cyrus Espinoza, Andre Esteva, L. Faes, L. Ferrante di Ruffano, J. Fletcher, R. Golub, H. Harvey, C. Haug, Christopher Holmes, Adrian Jonas, P. Keane, Christopher J. Kelly, Aaron Y. Lee, Cecilia S Lee, Elaine Manna, J. Matcham, Melissa D. McCradden, Joao Monteiro, C. Mulrow, L. Oakden-Rayner, D. Paltoo, M. Panico, G. Price, Samuel d. Rowley, Richard Savage, Rupa Sarkar, S. Vollmer, C. Yau","Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI Extension",2020,"","","","",65,"2022-07-13 09:19:47","","10.1136/bmj.m3164","","",,,,,159,79.50,16,40,2,"Abstract The CONSORT 2010 (Consolidated Standards of Reporting Trials) statement provides minimum guidelines for reporting randomised trials. Its widespread use has been instrumental in ensuring transparency when evaluating new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI. Both guidelines were developed through a staged consensus process, involving a literature review and expert consultation to generate 29 candidate items, which were assessed by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed on in a two-day consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The CONSORT-AI extension includes 14 new items, which were considered sufficiently important for AI interventions, that they should be routinely reported in addition to the core CONSORT 2010 items. CONSORT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention is integrated, the handling of inputs and outputs of the AI intervention, the human-AI interaction and providing analysis of error cases. CONSORT-AI will help promote transparency and completeness in reporting clinical trials for AI interventions. It will assist editors and peer-reviewers, as well as the general readership, to understand, interpret and critically appraise the quality of clinical trial design and risk of bias in the reported outcomes.","",""
0,"Bukhoree Sahoh, Kanjana Haruehansapong, Mallika Kliangkhlao","Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model",2022,"","","","",66,"2022-07-13 09:19:47","","10.1109/access.2022.3155118","","",,,,,0,0.00,0,3,1,"A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.","",""
0,"Younghoon Lee","Identifying Competitive Attributes Based on an Ensemble of Explainable Artificial Intelligence",2022,"","","","",67,"2022-07-13 09:19:47","","10.1007/s12599-021-00737-5","","",,,,,0,0.00,0,1,1,"","",""
0,"Minh-Hoang Tran, Ngoc Quy Nguyen, H. Pham","A New Hope in the Fight Against Antimicrobial Resistance with Artificial Intelligence",2022,"","","","",68,"2022-07-13 09:19:47","","10.2147/IDR.S362356","","",,,,,0,0.00,0,3,1,"Abstract Recent years have witnessed the rise of artificial intelligence (AI) in antimicrobial resistance (AMR) management, implying a positive signal in the fight against antibiotic-resistant microbes. The impact of AI starts with data collection and preparation for deploying AI-driven systems, which can lay the foundation for some effective infection control strategies. Primary applications of AI include identifying potential antimicrobial molecules, rapidly testing antimicrobial susceptibility, and optimizing antibiotic combinations. Aside from their outstanding effectiveness, these applications also express high potential in narrowing the burden gap of AMR among different settings around the world. Despite these benefits, the interpretability of AI-based systems or models remains vague. Attempts to address this issue had led to two novel explanation techniques, but none have shown enough robustness or comprehensiveness to be widely applied in AI and AMR control. A multidisciplinary collaboration between the medical field and advanced technology is therefore needed to partially manage this situation and improve the AI systems’ performance and their effectiveness against drug-resistant pathogens, in addition to multiple equity actions for mitigating the failure risks of AI due to a global-scale equity gap.","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",69,"2022-07-13 09:19:47","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
0,"O. Rouvière, R. Souchon, C. Lartizien, Adeline Mansuy, L. Magaud, Matthieu Colom, Marine Dubreuil-Chambardel, Sabine Debeer, Tristan Jaouen, Audrey Duran, P. Rippert, B. Riche, C. Monini, V. Vlaeminck-Guillem, J. Haesebaert, M. Rabilloud, S. Crouzet","Detection of ISUP ≥2 prostate cancers using multiparametric MRI: prospective multicentre assessment of the non-inferiority of an artificial intelligence system as compared to the PI-RADS V.2.1 score (CHANGE study)",2022,"","","","",70,"2022-07-13 09:19:47","","10.1136/bmjopen-2021-051274","","",,,,,0,0.00,0,17,1,"Introduction Prostate multiparametric MRI (mpMRI) has shown good sensitivity in detecting cancers with an International Society of Urological Pathology (ISUP) grade of ≥2. However, it lacks specificity, and its inter-reader reproducibility remains moderate. Biomarkers, such as the Prostate Health Index (PHI), may help select patients for prostate biopsy. Computer-aided diagnosis/detection (CAD) systems may also improve mpMRI interpretation. Different prototypes of CAD systems are currently developed under the Recherche Hospitalo-Universitaire en Santé / Personalized Focused Ultrasound Surgery of Localized Prostate Cancer (RHU PERFUSE) research programme, tackling challenging issues such as robustness across imaging protocols and magnetic resonance (MR) vendors, and ability to characterise cancer aggressiveness. The study primary objective is to evaluate the non-inferiority of the area under the receiver operating characteristic curve of the final CAD system as compared with the Prostate Imaging-Reporting and Data System V.2.1 (PI-RADS V.2.1) in predicting the presence of ISUP ≥2 prostate cancer in patients undergoing prostate biopsy. Methods This prospective, multicentre, non-inferiority trial will include 420 men with suspected prostate cancer, a prostate-specific antigen level of ≤30 ng/mL and a clinical stage ≤T2 c. Included men will undergo prostate mpMRI that will be interpreted using the PI-RADS V.2.1 score. Then, they will undergo systematic and targeted biopsy. PHI will be assessed before biopsy. At the end of patient inclusion, MR images will be assessed by the final version of the CAD system developed under the RHU PERFUSE programme. Key secondary outcomes include the prediction of ISUP grade ≥2 prostate cancer during a 3-year follow-up, and the number of biopsy procedures saved and ISUP grade ≥2 cancers missed by several diagnostic pathways combining PHI and MRI findings. Ethics and dissemination Ethical approval was obtained from the Comité de Protection des Personnes Nord Ouest III (ID-RCB: 2020-A02785-34). After publication of the results, access to MR images will be possible for testing other CAD systems. Trial registration number NCT04732156.","",""
0,"S. Sarkar","47 Plant Phenomics and Artificial Intelligence to Glean Information from Plant Sensing Technologies",2022,"","","","",71,"2022-07-13 09:19:47","","10.1093/jas/skac064.022","","",,,,,0,0.00,0,1,1,"  One of the grand challenges of our generation is to get ready to feed 9 billion people by 2050 with sustainable use of environmental resources. However, our current agricultural system is not prepared for it. We are facing unprecedented challenges in adopting sustainable management practices, increasing production, and coping with pest and climate stressors that threaten yield; while running a profitable farm operation. In this talk, I will discuss our vision of a new cyber-plant-agricultural system that leads to an ultra-precision technology to monitor and manage plants or small plots at an individual level. To realize this grand vision, machine learning (ML) will play a large role. However, several key aspects of ML such as robustness, interpretability and data requirement need to be studied in the context of agriculture for successful deployment. In addition, high-throughput and effective plant phenotyping systems need to assimilate heterogeneous, multi-modal data for decision-making and should be suitable for distributed implementation for enhanced scalability. I will discuss a few success stories from our recent work to discuss these aspects of ML in plant agriculture that is relevant and potentially beneficial for the animal agriculture community.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",72,"2022-07-13 09:19:47","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",73,"2022-07-13 09:19:47","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
85,"Giulia Vilone, L. Longo","Explainable Artificial Intelligence: a Systematic Review",2020,"","","","",74,"2022-07-13 09:19:47","","","","",,,,,85,42.50,43,2,2,"Explainable Artificial Intelligence (XAI) has experienced a significant growth over the last few years. This is due to the widespread application of machine learning, particularly deep learning, that has led to the development of highly accurate models but lack explainability and interpretability. A plethora of methods to tackle this problem have been proposed, developed and tested. This systematic review contributes to the body of knowledge by clustering these methods with a hierarchical classification system with four main clusters: review articles, theories and notions, methods and their evaluation. It also summarises the state-of-the-art in XAI and recommends future research directions.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",75,"2022-07-13 09:19:47","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
4,"T. Schmid","Deconstructing the Final Frontier of Artificial Intelligence: Five Theses for a Constructivist Machine Learning",2019,"","","","",76,"2022-07-13 09:19:47","","","","",,,,,4,1.33,4,1,3,"Ambiguity and diversity in human cognition can be regarded a final frontier in developing equivalent systems of artificial intelligence. Despite astonishing accomplishments, modern machine learning algorithms are still hardly more than adaptive systems. Deep neural networks, for example, represent complexity through complex connectivity but are not able to allow for abstraction and differentiation of interpretable knowledge, i.e., for key mechanisms of human cognition. Like support vector machines, random forests and other statistically motivated algorithms, they do neither reflect nor yield structures and strategies of human thinking. Therefore, we suggest to realign the use of existing machine learning tools with respect to the philosophical paradigm of constructivism, which currently is the key concept in human learning and professional teaching. Based on the idea that learning units like classifiers can be considered models with limited validity, we formulate five principles to guide a constructivist machine learning. We describe how to define such models and model limitations, how to relate them and how relationships allow to abstract and differentiate models. To this end, we propose the use of meta data for classifiers and other models. Moreover, we argue that such meta data-based machine learning results in a knowledge base that is both created by the means of automation and interpretable for humans. Over the last decade, it has become widely accepted to address computational systems intelligent. Not only journalists, but also scientists have adapted this habit in their publications. In fact, many classical engineering tasks like monitoring or regulating have profited from the employment of machine learning (Abellan-Nebot and Romero Subirón 2010; Mohanraj, Jayaraj, and Muraleedharan 2012). The same holds true for pattern recognition, most prominently in automated image and video analysis (Zafeiriou, Zhang, and Zhang 2015; Yang et al. 2011). And even though ultimate challenges like the infamous Turing test are left unsatisfied (You 2015), some exceptional results in specialized tasks like playing the game of go (Silver et al. 2016) make current learning machines look intelligent on a human level. Copyright held by the author(s). In A. Martin, K. Hinkelmann, A. Gerber, D. Lenat, F. van Harmelen, P. Clark (Eds.), Proceedings of the AAAI 2019 Spring Symposium on Combining Machine Learning with Knowledge Engineering (AAAI-MAKE 2019). Stanford University, Palo Alto, California, USA, March 25-27, 2019. A final frontier for learning systems, however, is the variety of alternative cognitive functions observable in a diverse set of individuals or from ambiguous stimuli (Kornmeier and Bach 2012). While philosophy has acknowledged and embraced the subjectivity and limitations of human cognition during the last decades (Prawat and Floden 1994), current learning systems regard cognition a complex, yet technical task to be solved. In particular, established algorithms do neither provide convincing answers to the challenges provided by an ambiguous environment; nor do they offer concepts that explicitly allow for contradictory judgements comparable to differences in social perception. The main reason for this shortcoming is that so far both algorithms and researchers have failed to incorporate a constructivist point of view. Constructivism implies not only cognition to be a highly individual phenomenon, but also humans to take an active role in their perception of the world – and that there is no such thing as a human-independent reality (Reich 2009). Yet algorithms and applications aiming to predict things other than laws of nature are implicitly founded on exactly this outdated asumption. In the following, we introduce axioms that allow machine learning to follow constructivist principles. Key features of this approach are the use of modern tools from empirical sciences, model-oriented learning, the ability to handle ambiguity, the ability to integrate supervised and unsupervised learning into a unified framework, the ability to create an individual knowledge base and the ability to abstract, differentiate or discard learned knowledge automatically. 1. The key component of cognitive functionality is a model. Since the introduction of artificial neural networks as a theoretical concept (McCulloch and Pitts 1943), many mathematicians and computer scientists have considered neurons the key component of learning systems. In education and psychology, however, cognitive functions are often seen as certain skills or abilities acquired and exposed by an individual human and described in terms like the concept of competence, which, e.g., is widely used in the modern European education system (Méhaut and Winch 2012). Functionalistic psychology explains cognitive functions of humans by the concept of mental models (Rouse and Morris 1986). Initially, mental models have been used to understand motor control, e.g., of hand movements (Veldhuyzen and Stassen 1977). In a more general sense, however, mental models are described as “hypothetical constructs” (Wickens 2000) that can be ordered hierarchically (Rasmussen 1979) and allow a human to make predictions about his physical and social environment (Oatley 1985). It has also been postulated that such models cannot be of static nature but rather underlay continuous modifications (Oatley 1985). Philosophers, too, consider models an important tool in human knowledge acquisition (Klaus 1967, p. 412) or even the only tool, respectively (Stachowiak 1973, p. 56). While varying and concurring theoretical definitions exist, most model concepts assume an image, an origin of the image and a relationship between them. This definition is, e.g., matched by the idea of mathematical modeling as proposed by Heinrich Hertz and others (Hertz 1894; Hamilton 1982). With the rise of robotics and artificial intelligence, engineers have adapted and extended this idea by postulating the concept of a cybernetic model, which involves a generalized subject and an object of the model (Rose 2009). Cybernetics, however, did neither reflect time-related aspects nor issues involved with individual model subjects. This matter was adressed by Herbert Stachowiak, who was influenced by cybernetics when developing his General Model Theory (Hof 2018). He postulated any model to be limited to specific subjects, specific temporal ranges and specific purposes (Stachowiak 1973, p. 133). Limitations, to this end, are considered a matter of fact rather than a matter of definition. Thus, such models circumvent ambiguity by viewing an otherwise ambiguous model with unknown validity limits as a number of models of limited validity. 2. Learning constitutes from constructing, reconstructing or deconstructing models. Modern education is dominated by the ideas of constructivism and constructivist learning (Fox 2001). At its heart, this approach is based on the assumption that humans acquire knowledge and competences actively and individually through processes called construction, reconstruction and deconstruction (Duffy and Jonassen 1992). Construction is associated with creation, innovation and production and implies searching for variations, combinations or transfers of knowledge (Reich 2004, p. 145). Analogously, reconstruction is associated with application, repetition or imitation and implies searching for order, patterns or models (Reich 2004, p. 145). Deconstruction is in the context of constructivism associated with reconsideration, doubt and modification and implies searching for omissions, additions and defective parts of acquired knowledge (Reich 2004, p. 145). Learning algorithms have been used for half a century to transform sample data into models in a mathematical sense, that is: into generalized mathematical relationships between image and origin. The two major approaches or objectives, known as supervised and unsupervised learning, either do or do not require a given target parameter. Artificial neural networks and their relatives are among the most popular and prominent algorithms for learning with a given target parameter (Singh, Thakur, and Sharma 2016), but statistically motivated approaches like support vector machines (Cristianini and Shawe-Taylor 2000) or random forests (Breiman 2001) are also widely used for supervised learning; a specialized field of supervised learning is reinforcement learning, which is popular in robotics (Kober and Peters 2012) and adaptive control (Lewis, Vrabie, and Vamvoudakis 2012). For unsupervised learning, too, biologically inspired approaches like self-organizing maps (Kohonen 2001) as well as statistically motivated approaches like k-means (Jain 2010) are employed. To some extent, machine learning parallels modern education concepts. A construction process in the constructivist sense may be matched by an unsupervised learning, i.e., identifying clusterings or dimensionality reduction, and can, e.g., be implemented with self-organizing maps, kmeans, autoencoders or feature clustering (Schmid 2018). A reconstruction process in the constructivist sense may be matched by a supervised learning, i.e., classification or regression tasks, and can, e.g., be implemented with artificial neural networks or random forests (Schmid 2018). Few researchers, however, have discussed a constructivist approach to machine learning (Drescher 1989; Quartz 1993), and even less how to design a deconstruction process. While domainspecific applications with manual re-engineering options exist (Herbst and Karagiannis 2000), to the best of our knowledge, there is currently only one working implementation of an algorithmic deconstruction process (Schmid 2018). 3. Deconstructing models computationally requires model-based meta data. In order to automate and implement a deconstruction process, successfully learned models must be held available for comparison or re-training. More over, possible matchings with n","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",77,"2022-07-13 09:19:47","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
9,"Junfeng Peng, Kaiqiang Zou, Mi Zhou, Yi Teng, Xiongyong Zhu, Feifei Zhang, Jun Xu","An Explainable Artificial Intelligence Framework for the Deterioration Risk Prediction of Hepatitis Patients",2021,"","","","",78,"2022-07-13 09:19:47","","10.1007/s10916-021-01736-5","","",,,,,9,9.00,1,7,1,"","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",79,"2022-07-13 09:19:47","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
32,"Rohan Pothumsetty","Implementation of Artificial Intelligence and Machine learning in Financial services",2020,"","","","",80,"2022-07-13 09:19:47","","","","",,,,,32,16.00,32,1,2,"The recent innovations in technology is never ending and have drastically impacted everyone in every single aspect of life over the previous decades. One such innovation which is capable of changing the world is AI technology. Artificial intelligence is a computer software which can mimic and think like a human being. AI in the present day and age is being implemented in most of the business functions. One business function where AI integration is taking place at a rapid pace is the financial services industry. AI is taking over most of the core functions in finance such as risk assessment, stock trading and credit lending process to loan seekers. Implementation of AI doesn’t mean that AI technology will totally take over the jobs of finance professionals but AI will help the finance managers to focus on the core and strategic aspects of the company and spend less time on monotonous and repetitive tasks. This research paper focuses on qualitative research and mainly aims to interpret how AI has been implemented in various finance functions and its influence towards employees, finance professionals and business","",""
132,"Xiaoxuan Liu, Samantha Cruz Rivera, D. Moher, M. Calvert, A. Denniston","Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension",2020,"","","","",81,"2022-07-13 09:19:47","","10.1038/s41591-020-1034-x","","",,,,,132,66.00,26,5,2,"","",""
7,"L. Foppa, L. Ghiringhelli, F. Girgsdies, M. Hashagen, P. Kube, M. Hävecker, S. Carey, A. Tarasov, P. Kraus, F. Rosowski, R. Schlögl, A. Trunschke, M. Scheffler","Materials genes of heterogeneous catalysis from clean experiments and artificial intelligence",2021,"","","","",82,"2022-07-13 09:19:47","","10.1557/s43577-021-00165-6","","",,,,,7,7.00,1,13,1,"Abstract The performance in heterogeneous catalysis is an example of a complex materials function, governed by an intricate interplay of several processes (e.g., the different surface chemical reactions, and the dynamic restructuring of the catalyst material at reaction conditions). Modeling the full catalytic progression via first-principles statistical mechanics is impractical, if not impossible. Instead, we show here how a tailored artificial-intelligence approach can be applied, even to a small number of materials, to model catalysis and determine the key descriptive parameters (“materials genes”) reflecting the processes that trigger, facilitate, or hinder catalyst performance. We start from a consistent experimental set of “clean data,” containing nine vanadium-based oxidation catalysts. These materials were synthesized, fully characterized, and tested according to standardized protocols. By applying the symbolic-regression SISSO approach, we identify correlations between the few most relevant materials properties and their reactivity. This approach highlights the underlying physicochemical processes, and accelerates catalyst design. Impact statement Artificial intelligence (AI) accepts that there are relationships or correlations that cannot be expressed in terms of a closed mathematical form or an easy-to-do numerical simulation. For the function of materials, for example, catalysis, AI may well capture the behavior better than the theory of the past. However, currently the flexibility of AI comes together with a lack of interpretability, and AI can only predict aspects that were included in the training. The approach proposed and demonstrated in this IMPACT article is interpretable. It combines detailed experimental data (called ""clean data"") and symbolic regression for the identification of the key descriptive parameters (called ""materials genes"") that are correlated with the materials function. The approach demonstrated here for the catalytic oxidation of propane will accelerate the discovery of improved or novel materials while also enhancing physical understanding. Supplementary Information The online version contains supplementary material available at 10.1557/s43577-021-00165-6.","",""
6,"Jordan J. Bird, Anik'o Ek'art, D. Faria","Chatbot Interaction with Artificial Intelligence: Human Data Augmentation with T5 and Language Transformer Ensemble for Text Classification",2020,"","","","",83,"2022-07-13 09:19:47","","10.1007/s12652-021-03439-8","","",,,,,6,3.00,2,3,2,"","",""
121,"T. Schaffter, D. Buist, Christoph I. Lee, Yaroslav Nikulin, D. Ribli, Y. Guan, William Lotter, Zequn Jie, Hao Du, Sijia Wang, Jiashi Feng, Mengling Feng, Hyo-Eun Kim, F. Albiol, A. Albiol, Stephen Morrell, Z. Wojna, M. Ahsen, U. Asif, Antonio José Jimeno Yepes, Shivanthan A. C. Yohanandan, S. Rabinovici-Cohen, Darvin Yi, B. Hoff, Thomas Yu, E. Chaibub Neto, D. Rubin, Peter Lindholm, L. Margolies, R. McBride, J. Rothstein, W. Sieh, Rami Ben-Ari, S. Harrer, A. Trister, S. Friend, Thea C. Norman, B. Sahiner, Fredrik Strand, J. Guinney, G. Stolovitzky, Lester W. Mackey, Joyce Cahoon, Li Shen, J. H. Sohn, H. Trivedi, Yiqiu Shen, L. Buturovic, J. C. Pereira, Jaime S. Cardoso","Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms",2020,"","","","",84,"2022-07-13 09:19:47","","10.1001/jamanetworkopen.2020.0265","","",,,,,121,60.50,12,50,2,"This diagnostic accuracy study evaluates whether artificial intelligence can overcome human mammography interpretation limits with a rigorous, unbiased evaluation of machine learning algorithms.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",85,"2022-07-13 09:19:47","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
101,"Samantha Cruz Rivera, Xiaoxuan Liu, A. Chan, A. Denniston, M. Calvert","Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI extension",2020,"","","","",86,"2022-07-13 09:19:47","","10.1038/s41591-020-1037-7","","",,,,,101,50.50,20,5,2,"","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",87,"2022-07-13 09:19:47","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"Ali M’Rabeth","Model Risk in the age of Artificial Intelligence and Machine Learning What are the impacts on Model Risk?",2019,"","","","",88,"2022-07-13 09:19:47","","","","",,,,,0,0.00,0,1,3,"An increasing reliance on Artificial Intelligence for decision making is driving financial institutions, regulators, and supervisors towards a clarification of sources and control of risks. These risks were either already present (but marginal) or even non-existent in the usual model risk management framework. In a context where the use of machine learning is becoming massive and industrialized across banks and insurance companies, problematics such as interpretability and dynamic monitoring, robustness, ethics, bias and fairness require a specific attention.","",""
10,"David A. Broniatowski","Psychological Foundations of Explainability and Interpretability in Artificial Intelligence",2021,"","","","",89,"2022-07-13 09:19:47","","10.6028/NIST.IR.8367","","",,,,,10,10.00,10,1,1,"In this paper, we make the case that interpretability and explainability are distinct requirements for machine learning systems. To make this case, we provide an overview of the literature in experimental psychology pertaining to interpretation (especially of numerical stimuli) and comprehension. We find that interpretation refers to the ability to contextualize a model’s output in a manner that relates it to the system’s designed functional purpose, and the goals, values, and preferences of end users. In contrast, explanation refers to the ability to accurately describe the mechanism, or implementation, that led to an algorithm’s output, often so that the algorithm can be improved in some way. Beyond these definitions, our review shows that humans differ from one another in systematic ways, that affect the extent to which they prefer to make decisions based on detailed explanations versus less precise interpretations. These individual differences, such as personality traits and skills, are associated with their abilities to derive meaningful interpretations from precise explanations of model output. This implies that system output should be tailored to different types of users.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",90,"2022-07-13 09:19:47","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
61,"S. N. Payrovnaziri, Zhaoyi Chen, Pablo A Rengifo-Moreno, Tim Miller, J. Bian, Jonathan H. Chen, Xiuwen Liu, Zhe He","Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review",2020,"","","","",91,"2022-07-13 09:19:47","","10.1093/jamia/ocaa053","","",,,,,61,30.50,8,8,2,"OBJECTIVE To conduct a systematic scoping review of explainable artificial intelligence (XAI) models that use real-world electronic health record data, categorize these techniques according to different biomedical applications, identify gaps of current studies, and suggest future research directions.   MATERIALS AND METHODS We searched MEDLINE, IEEE Xplore, and the Association for Computing Machinery (ACM) Digital Library to identify relevant papers published between January 1, 2009 and May 1, 2019. We summarized these studies based on the year of publication, prediction tasks, machine learning algorithm, dataset(s) used to build the models, the scope, category, and evaluation of the XAI methods. We further assessed the reproducibility of the studies in terms of the availability of data and code and discussed open issues and challenges.   RESULTS Forty-two articles were included in this review. We reported the research trend and most-studied diseases. We grouped XAI methods into 5 categories: knowledge distillation and rule extraction (N = 13), intrinsically interpretable models (N = 9), data dimensionality reduction (N = 8), attention mechanism (N = 7), and feature interaction and importance (N = 5).   DISCUSSION XAI evaluation is an open issue that requires a deeper focus in the case of medical applications. We also discuss the importance of reproducibility of research work in this field, as well as the challenges and opportunities of XAI from 2 medical professionals' point of view.   CONCLUSION Based on our review, we found that XAI evaluation in medicine has not been adequately and formally practiced. Reproducibility remains a critical concern. Ample opportunities exist to advance XAI research in medicine.","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",92,"2022-07-13 09:19:47","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
38,"Z. Khan, Sultan R. Alotaibi","Applications of Artificial Intelligence and Big Data Analytics in m-Health: A Healthcare System Perspective",2020,"","","","",93,"2022-07-13 09:19:47","","10.1155/2020/8894694","","",,,,,38,19.00,19,2,2,"Mobile health (m-health) is the term of monitoring the health using mobile phones and patient monitoring devices etc. It has been often deemed as the substantial breakthrough in technology in this modern era. Recently, artificial intelligence (AI) and big data analytics have been applied within the m-health for providing an effective healthcare system. Various types of data such as electronic health records (EHRs), medical images, and complicated text which are diversified, poorly interpreted, and extensively unorganized have been used in the modern medical research. This is an important reason for the cause of various unorganized and unstructured datasets due to emergence of mobile applications along with the healthcare systems. In this paper, a systematic review is carried out on application of AI and the big data analytics to improve the m-health system. Various AI-based algorithms and frameworks of big data with respect to the source of data, techniques used, and the area of application are also discussed. This paper explores the applications of AI and big data analytics for providing insights to the users and enabling them to plan, using the resources especially for the specific challenges in m-health, and proposes a model based on the AI and big data analytics for m-health. Findings of this paper will guide the development of techniques using the combination of AI and the big data as source for handling m-health data more effectively.","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",94,"2022-07-13 09:19:47","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",95,"2022-07-13 09:19:47","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",96,"2022-07-13 09:19:47","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
35,"Arieh Gomolin, E. Netchiporouk, R. Gniadecki, I. Litvinov","Artificial Intelligence Applications in Dermatology: Where Do We Stand?",2020,"","","","",97,"2022-07-13 09:19:47","","10.3389/fmed.2020.00100","","",,,,,35,17.50,9,4,2,"Artificial intelligence (AI) has become a progressively prevalent Research Topic in medicine and is increasingly being applied to dermatology. There is a need to understand this technology's progress to help guide and shape the future for medical care providers and recipients. We reviewed the literature to evaluate the types of publications on the subject, the specific dermatological topics addressed by AI, and the most challenging barriers to its implementation. A substantial number of original articles and commentaries have been published to date and only few detailed reviews exist. Most AI applications focus on differentiating between benign and malignant skin lesions, however; others exist pertaining to ulcers, inflammatory skin diseases, allergen exposure, dermatopathology, and gene expression profiling. Applications commonly analyze and classify images, however, other tools such as risk assessment calculators are becoming increasingly available. Although many applications are technologically feasible, important implementation barriers have been identified including systematic biases, difficulty of standardization, interpretability, and acceptance by physicians and patients alike. This review provides insight into future research needs and possibilities. There is a strong need for clinical investigation in dermatology providing evidence of success overcoming the identified barriers. With these research goals in mind, an appropriate role for AI in dermatology may be achieved in not so distant future.","",""
36,"P. Mascagni, Armine Vardazaryan, Deepak Alapatt, T. Urade, T. Emre, C. Fiorillo, P. Pessaux, D. Mutter, J. Marescaux, G. Costamagna, B. Dallemagne, N. Padoy","Artificial Intelligence for Surgical Safety",2020,"","","","",98,"2022-07-13 09:19:47","","10.1097/SLA.0000000000004351","","",,,,,36,18.00,4,12,2,"Objective: To develop a deep learning model to automatically segment hepatocystic anatomy and assess the criteria defining the critical view of safety (CVS) in laparoscopic cholecystectomy (LC). Background: Poor implementation and subjective interpretation of CVS contributes to the stable rates of bile duct injuries in LC. As CVS is assessed visually, this task can be automated by using computer vision, an area of artificial intelligence aimed at interpreting images. Methods: Still images from LC videos were annotated with CVS criteria and hepatocystic anatomy segmentation. A deep neural network comprising a segmentation model to highlight hepatocystic anatomy and a classification model to predict CVS criteria achievement was trained and tested using 5-fold cross validation. Intersection over union, average precision, and balanced accuracy were computed to evaluate the model performance versus the annotated ground truth. Results: A total of 2854 images from 201 LC videos were annotated and 402 images were further segmented. Mean intersection over union for segmentation was 66.6%. The model assessed the achievement of CVS criteria with a mean average precision and balanced accuracy of 71.9% and 71.4%, respectively. Conclusions: Deep learning algorithms can be trained to reliably segment hepatocystic anatomy and assess CVS criteria in still laparoscopic images. Surgical-technical partnerships should be encouraged to develop and evaluate deep learning models to improve surgical safety.","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",99,"2022-07-13 09:19:47","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",100,"2022-07-13 09:19:47","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",101,"2022-07-13 09:19:47","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
4,"C. Mallio, C. Quattrocchi, B. Beomonte Zobel, P. Parizel","Artificial intelligence, chest radiographs, and radiology trainees: a powerful combination to enhance the future of radiologists?",2021,"","","","",102,"2022-07-13 09:19:47","","10.21037/qims-20-1306","","",,,,,4,4.00,1,4,1,"Quant Imaging Med Surg 2021;11(5):2204-2207 | http://dx.doi.org/10.21037/qims-20-1306 Work overload has become a major challenge for radiologists. The increasing demands upon radiologists’ time, expertise and energy depend not only on the absolute number of imaging examinations to be performed and reported (i.e., number of patients), but also on the progressively growing complexity of imaging datasets, in terms of the number of images to be analyzed, as well as the quality of information to be processed, especially in the case of advanced imaging examinations that require post-processing and detailed interpretation (1-3). Artificial intelligence (AI) is a breakthrough innovation involving computer-based algorithms tailored to analyze complex datasets (4,5). Moreover, AI is emerging as a potential game changer in many fields. In medical imaging for instance, AI showed promising results for lesion detection and quantification over a wide spectrum of clinical conditions, as well as speeding up workflows, improving accuracy, addressing resource scarcity, and reducing the costs of care (4-7). The most promising subset of AI is the so-called deep learning algorithm, in which the term “deep” is due to the artificial neural network architecture composed by multiple layers (8,9). To be effective as representative learning applications, deep learning algorithms require large amounts of imaging data for training. These models, that are able to automatically learn, and then label, features on archetypal images, have been shown to robustly mirror or even outperform humans in task-specific applications in some cases? (8-10). AI and deep learning are currently being tested for imaging processing in several anatomical regions and various clinical scenarios, including disorders of the chest (7,8). In this context, we read with great interest the recently published paper by Wu et al. (7), investigating the performance of AI model and human third-year radiology residents in interpreting chest radiographs. The novel deep learning AI algorithm that they tested was extensively trained with a large image database (i.e., 342,126 frontal chest radiographs), acquired at the emergency departments (ED) and urgent care settings in multiple hospitals. Anteroposterior (AP) and postero-anterior (PA) images were used to train the model, despite the comparison AI vs. human radiology residents was based on AP images only. Interestingly, the major results of the study showed no significant difference between the performance of the AI algorithm and human radiology residents in terms of sensitivity (P=0.66); however, specificity [reported for AI 0.980 (95% CI, 0.980–0.981)] and positive predictive value [reported for AI 0.730 (95% CI, 0.718–0.742)] showed statistically significant greater results for the AI algorithm (both with P<0.001). This work, based on the “humble” but impactful chest radiograph, which represents the most commonly performed imaging examination, is of seminal importance at least for three good reasons (7). Firstly, the authors demonstrated Editorial Commentary","",""
1,"Enhua Shao, Congxin Liu, Lei Wang, Dandan Song, Libin Guo, Xuan-Liang Yao, J. Xiong, Bin Wang, Yuntao Hu","Artificial intelligence-based detection of epimacular membrane from color fundus photographs",2021,"","","","",103,"2022-07-13 09:19:47","","10.1038/s41598-021-98510-x","","",,,,,1,1.00,0,9,1,"","",""
30,"S. L. Piano","Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward",2020,"","","","",104,"2022-07-13 09:19:47","","10.1057/S41599-020-0501-9","","",,,,,30,15.00,30,1,2,"","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",105,"2022-07-13 09:19:47","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",106,"2022-07-13 09:19:47","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"A. Auerbach, S. Fihn","Discovery, Learning, and Experimentation With Artificial Intelligence-Based Tools at the Point of Care-Perils and Opportunity.",2021,"","","","",107,"2022-07-13 09:19:47","","10.1001/jamanetworkopen.2021.1474","","",,,,,0,0.00,0,2,1,"Our ability to gain insights about diseases, treatments, and how we practice (or how we should practice) medicine using data is growing at an accelerating rate and is a key precondition for health systems and the accurate delivery of precision medicine.1-3 The use of real-world data to direct decisions during the conduct of clinical care is viewed as a critical advance. However, it is unclear whether or how new approaches using advanced analytics, such as machine learning or artificial intelligence (AI), are exempt from well-known and long-standing challenges affecting clinical decision support systems (CDSSs) more generally. Vasey and colleagues4 conducted a systematic review of studies that compared clinicians’ diagnostic performance in interpreting imaging with and without the assistance of CDSS interventions based on machine learning.5 Of the 37 studies evaluated, most pertained to diagnosis of cancer or lung pathology and more than half assessed commercial CDSS technology. The authors found no robust evidence that clinicians made better diagnostic decisions when provided with support from machine-learning algorithms, suggesting that AI-based CDSSs are far from achieving their potential. This finding is similar for essentially all forms of AI-based decision support systems that have been evaluated to date. One explanation is that data amassed as part of providing usual care are, by their nature, messy and complex.1 Observational data are invariably deeply confounded in ways that will produce misleading associations because of selection bias, confounding by indication, immortal time bias, and observation-time bias. Additionally, data in electronic health records are entered by busy people with varying priorities on the information that they enter into the records and where, when, and how they enter that information. In clinical care, lack of documentation of a diagnosis, problem, finding, communication, or even an action does not constitute evidence that it did not exist or occur. The computer only knows what it is told—missing data and the meaning of gaps are informative but often are unknowable and may lead to further imprecision in AI-based CDSSs. A CDSS based on algorithms that are based on confounded or incomplete data will be confounded and provide inaccurate guidance. Even with big numbers and advanced modeling algorithms, predicting rare events is a fundamentally tough business, particularly when trying to predict a patient’s outcome or risks. All too often, investigators and those building AI-based CDSSs tout use of data from massive numbers of patients even as the actual event rate is low (eg, only 1 or 2%), which means that even when the area under the curve is as high as 0.9, the positive predictive value may not exceed 0.1, and the resulting false alarms will greatly outnumber true signals.6 Moreover, there is no agreement on the best metrics to categorize the performance of predictive algorithms. Metrics have included area under the receiver operating curve, confusion matrix, accuracy, positive predictive value/precision, recall/ sensitivity, precision-recall curve, specificity, negative predictive value, F1 score, number needed to screen, likelihood ratio, net reclassification index, stratification tables, and calibration curves. In addition, model performance inevitably degrades over time (because of population drift or more commonly, alterations in the underlying data structure) and when applied to data emanating from a different system or setting. Many experts now advocate not only that models be tested on multiple independent data sets, but that testing be conducted by independent investigators.6 + Related article","",""
0,"Mir Riyanul Islam, Mobyen Uddin Ahmed, S. Begum","Local and Global Interpretability Using Mutual Information in Explainable Artificial Intelligence",2021,"","","","",108,"2022-07-13 09:19:47","","10.1109/ISCMI53840.2021.9654898","","",,,,,0,0.00,0,3,1,"Numerous studies have exploited the potential of Artificial Intelligence (AI) and Machine Learning (ML) models to develop intelligent systems in diverse domains for complex tasks, such as analysing data, extracting features, prediction, recommendation etc. However, presently these systems embrace acceptability issues from the end-users. The models deployed at the back of the systems mostly analyse the correlations or dependencies between the input and output to uncover the important characteristics of the input features, but they lack explainability and interpretability that causing the acceptability issues of intelligent systems and raising the research domain of eXplainable Artificial Intelligence (XAI). In this study, to overcome these shortcomings, a hybrid XAI approach is developed to explain an AI/ML model’s inference mechanism as well as the final outcome. The overall approach comprises of 1) a convolutional encoder that extracts deep features from the data and computes their relevancy with features extracted using domain knowledge, 2) a model for classifying data points using the features from autoencoder, and 3) a process of explaining the model’s working procedure and decisions using mutual information to provide global and local interpretability. To demonstrate and validate the proposed approach, experimentation was performed using an electroencephalography dataset from road safety to classify drivers’ in-vehicle mental workload. The outcome of the experiment was found to be promising that produced a Support Vector Machine classifier for mental workload with approximately 89% performance accuracy. Moreover, the proposed approach can also provide an explanation for the classifier model’s behaviour and decisions with the combined illustration of Shapely values and mutual information.","",""
0,"Julio Torres-Tello, Seok-Bum Ko","Interpretability of artificial intelligence models that use data fusion to predict yield in aeroponics",2021,"","","","",109,"2022-07-13 09:19:47","","10.1007/s12652-021-03470-9","","",,,,,0,0.00,0,2,1,"","",""
0,"M. Safa, A. Pandian, T. Kartick, K. ChakraPani, G. Geetha, G. Saranya","Hybrid Artificial Intelligence and IoT in Health care for Cardiovascular Patient in Decision-Making System",2021,"","","","",110,"2022-07-13 09:19:47","","10.1007/978-981-16-2972-3_7","","",,,,,0,0.00,0,6,1,"","",""
0,"Victoria Tucci, J. Saary, Thomas E. Doyle","Factors influencing trust in medical artificial intelligence for healthcare professionals: a narrative review",2021,"","","","",111,"2022-07-13 09:19:47","","10.21037/jmai-21-25","","",,,,,0,0.00,0,3,1,"Objective: We performed a comprehensive review of the literature to better understand the trust dynamics between medical artificial intelligence (AI) and healthcare expert end-users. We explored the factors that influence trust in these technologies and how they compare to established concepts of trust in the engineering discipline. By identifying the qualitatively and quantitatively assessed factors that influence trust in medical AI, we gain insight into understanding how autonomous systems can be optimized during the development phase to improve decision-making support and clinician-machine teaming. This facilitates an enhanced understanding of the qualities that healthcare professional users seek in AI to consider it trustworthy. We also highlight key considerations for promoting on-going improvement of trust in autonomous medical systems to support the adoption of medical technologies into practice. Background: decision support systems introduces challenges and barriers to adoption and implementation into clinical practice. Methods: We searched databases including, Ovid MEDLINE, Ovid EMBASE, Clarivate Web of Science, and Google Scholar, as well as gray literature, for publications from 2000 to July 15, 2021, that reported features of AI-based diagnostic and clinical decision support systems that contribute to enhanced end-user trust. Papers discussing implications and applications of medical AI in clinical practice were also recorded. Results were based on the quantity of papers that discussed each trust concept, either quantitatively or qualitatively, using frequency of concept commentary as a proxy for importance of a respective concept. Conclusions: Explainability, transparency, interpretability, usability, and education are among the key identified factors thought to influence a healthcare professionals’ trust in medical AI and enhance clinician-machine teaming in critical decision-making healthcare environments. We also identified the need to better evaluate and incorporate other critical factors to promote trust by consulting medical professionals when developing AI systems for clinical decision-making and diagnostic support.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",112,"2022-07-13 09:19:47","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",113,"2022-07-13 09:19:47","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",114,"2022-07-13 09:19:47","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
26,"Zhongheng Zhang, E. Navarese, Bin Zheng, Q. Meng, Nan Liu, H. Ge, Qing Pan, Yuetian Yu, Xuelei Ma","Analytics with artificial intelligence to advance the treatment of acute respiratory distress syndrome",2020,"","","","",115,"2022-07-13 09:19:47","","10.1111/jebm.12418","","",,,,,26,13.00,3,9,2,"Artificial intelligence (AI) has found its way into clinical studies in the era of big data. Acute respiratory distress syndrome (ARDS) or acute lung injury (ALI) is a clinical syndrome that encompasses a heterogeneous population. Management of such heterogeneous patient population is a big challenge for clinicians. With accumulating ALI datasets being publicly available, more knowledge could be discovered with sophisticated analytics. We reviewed literatures with big data analytics to understand the role of AI for improving the caring of patients with ALI/ARDS. Many studies have utilized the electronic medical records (EMR) data for the identification and prognostication of ARDS patients. As increasing number of ARDS clinical trials data is open to public, secondary analysis on these combined datasets provide a powerful way of finding solution to clinical questions with a new perspective. AI techniques such as Classification and Regression Tree (CART) and artificial neural networks (ANN) have also been successfully used in the investigation of ARDS problems. Individualized treatment of ARDS could be implemented with a support from AI as we are now able to classify ARDS into many subphenotypes by unsupervised machine learning algorithms. Interestingly, these subphenotypes show different responses to a certain intervention. However, current analytics involving ARDS have not fully incorporated information from omics such as transcriptome, proteomics, daily activities and environmental conditions. AI technology is assisting us to interpret complex data of ARDS patients and enable us to further improve the management of ARDS patients in future with individual treatment plans.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",116,"2022-07-13 09:19:47","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
27,"Sergii Bogachov, A. Kwiliński, Boris Miethlich, V. Bartosova, A. Gurnak","Artificial intelligence components and fuzzy regulators in entrepreneurship development",2020,"","","","",117,"2022-07-13 09:19:47","","10.9770/jesi.2020.8.2(29)","","",,,,,27,13.50,5,5,2,"The article provides a comparative study of the possibility of entrepreneurship development based on fuzzy signals of business activity and applied elements of artificial intelligence. The principal research methods that determine the logic and practical basis of the application of fuzzy logic in entrepreneurship are highlighted. It has been determined that fuzzy modeling is effective when technological processes are too complex for analysis using generally accepted quantitative methods, or when available sources of information in the business environment are interpreted poorly, inaccurately, and indefinitely. It has been shown experimentally that fuzzy logic gives better results compared to those obtained with generally accepted algorithms for analyzing the quality of doing business. A model of a neuro-fuzzy regulator has been developed and measures for its implementation in the business environment have been proposed. A neural network model in entrepreneurial development has been formed. Studies have shown the possibility of effective use of the principles of artificial intelligence and modeling in solving problems of developing entrepreneurial potential and making business decisions under conditions of uncertainty. This ensures objective and well-grounded decision-making in solving various applied problems of business development and taking into account environmental factors. The applied tasks of supporting the adoption of entrepreneurial decisions in the conditions are formulated; uncertainty; indicating that approaches to decision-making under conditions of uncertainty based on artificial intelligence and fuzzy logic tools are universal and require appropriate careful study and adaptation to a specific applied problem in the business environment.","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",118,"2022-07-13 09:19:47","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
25,"R. Shouval, J. Fein, B. Savani, M. Mohty, A. Nagler","Machine learning and artificial intelligence in haematology",2020,"","","","",119,"2022-07-13 09:19:47","","10.1111/bjh.16915","","",,,,,25,12.50,5,5,2,"Digitalization of the medical record and integration of genomic methods into clinical practice have resulted in an unprecedented wealth of data. Machine learning is a subdomain of artificial intelligence that attempts to computationally extract meaningful insights from complex data structures. Applications of machine learning in haematological scenarios are steadily increasing. However, basic concepts are often unfamiliar to clinicians and investigators. The purpose of this review is to provide readers with tools to interpret and critically appraise machine learning literature. We begin with the elucidation of standard terminology and then review examples in haematology. Guidelines for designing and evaluating machine‐learning studies are provided. Finally, we discuss limitations of the machine‐learning approach.","",""
26,"T. Shan, F. R. Tay, L. Gu","Application of Artificial Intelligence in Dentistry",2020,"","","","",120,"2022-07-13 09:19:47","","10.1177/0022034520969115","","",,,,,26,13.00,9,3,2,"Artificial intelligence (AI) is a technology that utilizes machines to mimic intelligent human behavior. To appreciate human-technology interaction in the clinical setting, augmented intelligence has been proposed as a cognitive extension of AI in health care, emphasizing its assistive and supplementary role to medical professionals. While truly autonomous medical robotic systems are still beyond reach, the virtual component of AI, known as software-type algorithms, is the main component used in dentistry. Because of their powerful capabilities in data analysis, these virtual algorithms are expected to improve the accuracy and efficacy of dental diagnosis, provide visualized anatomic guidance for treatment, simulate and evaluate prospective results, and project the occurrence and prognosis of oral diseases. Potential obstacles in contemporary algorithms that prevent routine implementation of AI include the lack of data curation, sharing, and readability; the inability to illustrate the inner decision-making process; the insufficient power of classical computing; and the neglect of ethical principles in the design of AI frameworks. It is necessary to maintain a proactive attitude toward AI to ensure its affirmative development and promote human-technology rapport to revolutionize dental practice. The present review outlines the progress and potential dental applications of AI in medical-aided diagnosis, treatment, and disease prediction and discusses their data limitations, interpretability, computing power, and ethical considerations, as well as their impact on dentists, with the objective of creating a backdrop for future research in this rapidly expanding arena.","",""
76,"L. Floridi","What the Near Future of Artificial Intelligence Could Be",2019,"","","","",121,"2022-07-13 09:19:47","","10.1007/S13347-019-00345-Y","","",,,,,76,25.33,76,1,3,"","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",122,"2022-07-13 09:19:47","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
22,"Yulei Jiang, A. Edwards, G. Newstead","Artificial Intelligence Applied to Breast MRI for Improved Diagnosis.",2020,"","","","",123,"2022-07-13 09:19:47","","10.1148/radiol.2020200292","","",,,,,22,11.00,7,3,2,"Background Recognition of salient MRI morphologic and kinetic features of various malignant tumor subtypes and benign diseases, either visually or with artificial intelligence (AI), allows radiologists to improve diagnoses that may improve patient treatment. Purpose To evaluate whether the diagnostic performance of radiologists in the differentiation of cancer from noncancer at dynamic contrast material-enhanced (DCE) breast MRI is improved when using an AI system compared with conventionally available software. Materials and Methods In a retrospective clinical reader study, images from breast DCE MRI examinations were interpreted by 19 breast imaging radiologists from eight academic and 11 private practices. Readers interpreted each examination twice. In the ""first read,"" they were provided with conventionally available computer-aided evaluation software, including kinetic maps. In the ""second read,"" they were also provided with AI analytics through computer-aided diagnosis software. Reader diagnostic performance was evaluated with receiver operating characteristic (ROC) analysis, with the area under the ROC curve (AUC) as a figure of merit in the task of distinguishing between malignant and benign lesions. The primary study end point was the difference in AUC between the first-read and the second-read conditions. Results One hundred eleven women (mean age, 52 years ± 13 [standard deviation]) were evaluated with a total of 111 breast DCE MRI examinations (54 malignant and 57 nonmalignant lesions). The average AUC of all readers improved from 0.71 to 0.76 (P = .04) when using the AI system. The average sensitivity improved when Breast Imaging Reporting and Data System (BI-RADS) category 3 was used as the cut point (from 90% to 94%; 95% confidence interval [CI] for the change: 0.8%, 7.4%) but not when using BI-RADS category 4a (from 80% to 85%; 95% CI: -0.9%, 11%). The average specificity showed no difference when using either BI-RADS category 4a or category 3 as the cut point (52% and 52% [95% CI: -7.3%, 6.0%], and from 29% to 28% [95% CI: -6.4%, 4.3%], respectively). Conclusion Use of an artificial intelligence system improves radiologists' performance in the task of differentiating benign and malignant MRI breast lesions. © RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Krupinski in this issue.","",""
20,"Esra Zihni, V. Madai, Michelle Livne, I. Galinovic, A. Khalil, J. Fiebach, D. Frey","Opening the black box of artificial intelligence for clinical decision support: A study predicting stroke outcome",2019,"","","","",124,"2022-07-13 09:19:47","","10.1371/journal.pone.0231166","","",,,,,20,6.67,3,7,3,"State-of-the-art machine learning (ML) artificial intelligence methods are increasingly leveraged in clinical predictive modeling to provide clinical decision support systems to physicians. Modern ML approaches such as artificial neural networks (ANNs) and tree boosting often perform better than more traditional methods like logistic regression. On the other hand, these modern methods yield a limited understanding of the resulting predictions. However, in the medical domain, understanding of applied models is essential, in particular, when informing clinical decision support. Thus, in recent years, interpretability methods for modern ML methods have emerged to potentially allow explainable predictions paired with high performance. To our knowledge, we present in this work the first explainability comparison of two modern ML methods, tree boosting and multilayer perceptrons (MLPs), to traditional logistic regression methods using a stroke outcome prediction paradigm. Here, we used clinical features to predict a dichotomized 90 days post-stroke modified Rankin Scale (mRS) score. For interpretability, we evaluated clinical features’ importance with regard to predictions using deep Taylor decomposition for MLP, Shapley values for tree boosting and model coefficients for logistic regression. With regard to performance as measured by Area under the Curve (AUC) values on the test dataset, all models performed comparably: Logistic regression AUCs were 0.83, 0.83, 0.81 for three different regularization schemes; tree boosting AUC was 0.81; MLP AUC was 0.83. Importantly, the interpretability analysis demonstrated consistent results across models by rating age and stroke severity consecutively amongst the most important predictive features. For less important features, some differences were observed between the methods. Our analysis suggests that modern machine learning methods can provide explainability which is compatible with domain knowledge interpretation and traditional method rankings. Future work should focus on replication of these findings in other datasets and further testing of different explainability methods.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",125,"2022-07-13 09:19:47","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",126,"2022-07-13 09:19:47","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",127,"2022-07-13 09:19:47","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",128,"2022-07-13 09:19:47","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
4,"S. O'Connor, M. Bhalla","Should Artificial Intelligence Tell Radiologists Which Study to Read Next?",2021,"","","","",129,"2022-07-13 09:19:47","","10.1148/ryai.2021210009","","",,,,,4,4.00,2,2,1,"T reading worklist, which displays studies to be interpreted, is often organized to help radiologists read the most urgent study next. However, there are few variables available to determine the urgency of any given examination. Many lists simply use imaging location (eg, emergency, inpatient, outpatient) and the priority assigned by the ordering provider based on a clinical assessment of the patient’s symptoms. Ordering providers also may apply a high priority to an examination that does not require immediate interpretation but must be acquired quickly to accommodate a patient’s other appointments. Although this sort of prioritization serves as a guide to technologists to determine the order in which to perform the examinations, its application as a reading priority indicator has limitations and is fraught with errors. At some practices, an experienced imaging technologist may alert radiologists about imaging findings noticed while scanning that may need immediate if not urgent attention. Alternatively, the technologist may edit the priority level of the examination while sending it to the radiologists’ reading worklist. This practice, however, is not standard across the country. In this age of quality improvement, it may be prudent to augment these current practices with additional more sophisticated tools such as artificial intelligence (AI). A trained AI algorithm can be applied to everyday practice in critical time-dependent scenarios such as stroke and other acute intracranial findings such as intracranial hemorrhage (ICH) from nonstroke causes. A leading cause of death and disability worldwide, stroke kills approximately 140 000 Americans each year and is responsible for almost one death every 4 minutes (1). The use of CT to distinguish ischemic from hemorrhagic stroke is critical to establish early treatment options and to triage patients to appropriate management. The speed at which this determination is made greatly affects the success of treatment, such that door-to-diagnosis time and radiologist turnaround time (TAT) are included in national benchmarks and performance metrics of evolving reimbursement models. The rapidity of CT acquisition could be negated by the absence of appropriate prioritization, especially if stroke or ICH is unexpected or examinations are ordered from less urgent locations, as these studies could have a longer “shelf life” or wait time on a radiologist reading list. Examinations can be prioritized appropriately based on specific tags or labels placed at the time of ordering or by request after images have been obtained (2). This in turn expedites the interpretation by minimizing the wait time of an examination in the reading worklist. Osborne et al evaluated the impact of tagging studies as “stroke protocol,” which would prioritize them above emergent CT examinations. The average TAT for stroke protocol CT was 6.5 minutes compared with 17.3 minutes for emergent CT examinations. The improvement was the result of decreased “available-to-picked time,” which is combined with “radiologist reading time” to calculate TAT. Reading priorities can be set manually by technologists at end examination using a schema, which relies on many different variables. When these priorities are assigned numerical values, radiologists can easily identify the next most urgent study to read. Using this method, Gaskin et al reported significant improvement in the median TAT for the most urgent studies (critical, emergency department/ urgent, and inpatient/urgent), but the change was less (5%) in emergency department studies, presumably because examinations tagged with the emergency department location are by default interpreted first by radiologists (3). AI tools have the potential to go beyond variables known prior to an examination and incorporate information gleaned from the images themselves to impact radiologists and their workflow. Arbabshirani et al first evaluated Should Artificial Intelligence Tell Radiologists Which Study to Read Next?","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",130,"2022-07-13 09:19:47","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
3,"Y. Afridi, Kashif Ahmad, Laiq Hassan","Artificial Intelligence Based Prognostic Maintenance of Renewable Energy Systems: A Review of Techniques, Challenges, and Future Research Directions",2021,"","","","",131,"2022-07-13 09:19:47","","10.1002/er.7100","","",,,,,3,3.00,1,3,1,"Since the depletion of fossil fuels, the world has started to rely heavily on renewable sources of energy. With every passing year, our dependency on the renewable sources of energy is increasing exponentially. As a result, complex and hybrid generation systems are being designed and developed to meet the energy demands and ensure energy security in a country. The continual improvement in the technology and an effort towards the provision of uninterrupted power to the end-users is strongly dependent on an effective and fault resilient Operation & Maintenance (O&M) system. Ingenious algorithms and techniques are hence been introduced aiming to minimize equipment and plant downtime. Efforts are being made to develop robust Prognostic Maintenance systems that can identify the faults before they occur. To this aim, complex Data Analytics and Machine Learning (ML) techniques are being used to increase the overall efficiency of these prognostic maintenance systems. This paper provides an overview of the predictive/prognostic maintenance frameworks reported in the literature. We pay a particular focus to the approaches, challenges including datarelated issues, such as the availability and quality of the data and data auditing, feature engineering, interpretability, and security issues. Being a key aspect of ML-based solutions, we also discuss some of the commonly used publicly available datasets in the domain. The paper also identifies key future research directions. We believe such detailed analysis will provide a baseline for future research in the domain.","",""
16,"Weina Jin, M. Fatehi, Kumar Abhishek, Mayur Mallya, B. Toyota, G. Hamarneh","Artificial intelligence in glioma imaging: Challenges and advances.",2019,"","","","",132,"2022-07-13 09:19:47","","10.1088/1741-2552/ab8131","","",,,,,16,5.33,3,6,3,"Primary brain tumors including gliomas continue to pose significant management challenges to clinicians. While the presentation, the pathology, and the clinical course of these lesions are variable, the initial investigations are usually similar. Patients who are suspected to have a brain tumor will be assessed with computed tomography (CT) and magnetic resonance imaging (MRI). The imaging findings are used by neurosurgeons to determine the feasibility of surgical resection and plan such an undertaking. Imaging studies are also an indispensable tool in tracking tumor progression or its response to treatment. As these imaging studies are non-invasive, relatively cheap and accessible to patients, there have been many efforts over the past two decades to increase the amount of clinically-relevant information that can be extracted from brain imaging. Most recently, artificial intelligence (AI) techniques have been employed to segment and characterize brain tumors, as well as to detect progression or treatment-response. However, the clinical utility of such endeavours remains limited due to challenges in data collection and annotation, model training, and the reliability of AI-generated information. We provide a review of recent advances in addressing the above challenges. First, to overcome the challenge of data paucity, different image imputation and synthesis techniques along with annotation collection efforts are summarized. Next, various training strategies are presented to meet multiple desiderata, such as model performance, generalization ability, data privacy protection, and learning with sparse annotations. Finally, standardized performance evaluation and model interpretability methods have been reviewed. We believe that these technical approaches will facilitate the development of a fully-functional AI tool in the clinical care of patients with gliomas.","",""
17,"F. Fitzpatrick, A. Doherty, G. Lacey","Using Artificial Intelligence in Infection Prevention",2020,"","","","",133,"2022-07-13 09:19:47","","10.1007/s40506-020-00216-7","","",,,,,17,8.50,6,3,2,"","",""
16,"P. Xue, Chao Tang, Qing Li, Yuexiang Li, Yulian Shen, Yuqian Zhao, Jiawei Chen, Jianrong Wu, Longyu Li, Wei Wang, Yucong Li, Xiaoli Cui, Shaokai Zhang, Wenhua Zhang, Xun Zhang, Kai Ma, Yefeng Zheng, Tianyi Qian, Man Tat Alexander Ng, Zhihua Liu, Y. Qiao, Yu Jiang, F. Zhao","Development and validation of an artificial intelligence system for grading colposcopic impressions and guiding biopsies",2020,"","","","",134,"2022-07-13 09:19:47","","10.1186/s12916-020-01860-y","","",,,,,16,8.00,2,23,2,"","",""
16,"Laith T. Khrais","Role of Artificial Intelligence in Shaping Consumer Demand in E-Commerce",2020,"","","","",135,"2022-07-13 09:19:47","","10.3390/fi12120226","","",,,,,16,8.00,16,1,2,"The advent and incorporation of technology in businesses have reformed operations across industries. Notably, major technical shifts in e-commerce aim to influence customer behavior in favor of some products and brands. Artificial intelligence (AI) comes on board as an essential innovative tool for personalization and customizing products to meet specific demands. This research finds that, despite the contribution of AI systems in e-commerce, its ethical soundness is a contentious issue, especially regarding the concept of explainability. The study adopted the use of word cloud analysis, voyance analysis, and concordance analysis to gain a detailed understanding of the idea of explainability as has been utilized by researchers in the context of AI. Motivated by a corpus analysis, this research lays the groundwork for a uniform front, thus contributing to a scientific breakthrough that seeks to formulate Explainable Artificial Intelligence (XAI) models. XAI is a machine learning field that inspects and tries to understand the models and steps involved in how the black box decisions of AI systems are made; it provides insights into the decision points, variables, and data used to make a recommendation. This study suggested that, to deploy explainable XAI systems, ML models should be improved, making them interpretable and comprehensible.","",""
1,"R. Pettit, Robert Fullem, Chao Cheng, Chris Amos","Artificial intelligence, machine learning, and deep learning for clinical outcome prediction",2021,"","","","",136,"2022-07-13 09:19:47","","10.1042/ETLS20210246","","",,,,,1,1.00,0,4,1,"AI is a broad concept, grouping initiatives that use a computer to perform tasks that would usually require a human to complete. AI methods are well suited to predict clinical outcomes. In practice, AI methods can be thought of as functions that learn the outcomes accompanying standardized input data to produce accurate outcome predictions when trialed with new data. Current methods for cleaning, creating, accessing, extracting, augmenting, and representing data for training AI clinical prediction models are well defined. The use of AI to predict clinical outcomes is a dynamic and rapidly evolving arena, with new methods and applications emerging. Extraction or accession of electronic health care records and combining these with patient genetic data is an area of present attention, with tremendous potential for future growth. Machine learning approaches, including decision tree methods of Random Forest and XGBoost, and deep learning techniques including deep multi-layer and recurrent neural networks, afford unique capabilities to accurately create predictions from high dimensional, multimodal data. Furthermore, AI methods are increasing our ability to accurately predict clinical outcomes that previously were difficult to model, including time-dependent and multi-class outcomes. Barriers to robust AI-based clinical outcome model deployment include changing AI product development interfaces, the specificity of regulation requirements, and limitations in ensuring model interpretability, generalizability, and adaptability over time.","",""
1,"W. Monroe, F. Skidmore, David G. Odaibo, M. Tanik","HihO: accelerating artificial intelligence interpretability for medical imaging in IoT applications using hierarchical occlusion",2020,"","","","",137,"2022-07-13 09:19:47","","10.1007/S00521-020-05379-4","","",,,,,1,0.50,0,4,2,"","",""
26,"Daniel S. Weld, Gagan Bansal","Intelligible Artificial Intelligence",2018,"","","","",138,"2022-07-13 09:19:47","","","","",,,,,26,6.50,13,2,4,"Since Artificial Intelligence (AI) software uses techniques like deep lookahead search and stochastic optimization of huge neural networks to fit mammoth datasets, it often results in complex behavior that is difficult for people to understand. Yet organizations are deploying AI algorithms in many mission-critical settings. In order to trust their behavior, we must make it intelligible --- either by using inherently interpretable models or by developing methods for explaining otherwise overwhelmingly complex decisions by local approximation, vocabulary alignment, and interactive dialog.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",139,"2022-07-13 09:19:47","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",140,"2022-07-13 09:19:47","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",141,"2022-07-13 09:19:47","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",142,"2022-07-13 09:19:47","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
13,"Meicheng Yang, Chengyu Liu, Xingyao Wang, Yuwen Li, Hongxiang Gao, Xing Liu, Jianqing Li","An Explainable Artificial Intelligence Predictor for Early Detection of Sepsis",2020,"","","","",143,"2022-07-13 09:19:47","","10.1097/CCM.0000000000004550","","",,,,,13,6.50,2,7,2,"Supplemental Digital Content is available in the text. Objectives: Early detection of sepsis is critical in clinical practice since each hour of delayed treatment has been associated with an increase in mortality due to irreversible organ damage. This study aimed to develop an explainable artificial intelligence model for early predicting sepsis by analyzing the electronic health record data from ICU provided by the PhysioNet/Computing in Cardiology Challenge 2019. Design: Retrospective observational study. Setting: We developed our model on the shared ICUs publicly data and verified on the full hidden populations for challenge scoring. Patients: Public database included 40,336 patients’ electronic health records sourced from Beth Israel Deaconess Medical Center (hospital system A) and Emory University Hospital (hospital system B). A total of 24,819 patients from hospital systems A, B, and C (an unidentified hospital system) were sequestered as full hidden test sets. Interventions: None. Measurements and Main Results: A total of 168 features were extracted on hourly basis. Explainable artificial intelligence sepsis predictor model was trained to predict sepsis in real time. Impact of each feature on hourly sepsis prediction was explored in-depth to show the interpretability. The algorithm demonstrated the final clinical utility score of 0.364 in this challenge when tested on the full hidden test sets, and the scores on three separate test sets were 0.430, 0.422, and –0.048, respectively. Conclusions: Explainable artificial intelligence sepsis predictor model achieves superior performance for predicting sepsis risk in a real-time way and provides interpretable information for understanding sepsis risk in ICU.","",""
353,"M. Haenlein, A. Kaplan","A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence",2019,"","","","",144,"2022-07-13 09:19:47","","10.1177/0008125619864925","","",,,,,353,117.67,177,2,3,"This introduction to this special issue discusses artificial intelligence (AI), commonly defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.” It summarizes seven articles published in this special issue that present a wide variety of perspectives on AI, authored by several of the world’s leading experts and specialists in AI. It concludes by offering a comprehensive outlook on the future of AI, drawing on micro-, meso-, and macro-perspectives.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",145,"2022-07-13 09:19:47","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
10,"Sushant Kafle, Abraham Glasser, Sedeeq Al-khazraji, Larwan Berke, Matthew Seita, Matt Huenerfauth","Artificial intelligence fairness in the context of accessibility research on intelligent systems for people who are deaf or hard of hearing",2019,"","","","",146,"2022-07-13 09:19:47","","10.1145/3386296.3386300","","",,,,,10,3.33,2,6,3,"We discuss issues of Artificial Intelligence (AI) fairness for people with disabilities, with examples drawn from our research on HCI for AI-based systems for people who are Deaf or Hard of Hearing (DHH). In particular, we discuss the need for inclusion of data from people with disabilities in training sets, the lack of interpretability of AI systems, ethical responsibilities of access technology researchers and companies, the need for appropriate evaluation metrics for AI-based access technologies (to determine if they are ready to be deployed and if they can be trusted by users), and the ways in which AI systems influence human behavior and influence the set of abilities needed by users to successfully interact with computing systems.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",147,"2022-07-13 09:19:47","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
7,"O. Q. Groot, M. Bongers, Paul T. Ogink, J. Senders, Aditya V. Karhade, J. Bramer, J. Verlaan, J. Schwab","Does Artificial Intelligence Outperform Natural Intelligence in Interpreting Musculoskeletal Radiological Studies? A Systematic Review.",2020,"","","","",148,"2022-07-13 09:19:47","","10.1097/CORR.0000000000001360","","",,,,,7,3.50,1,8,2,"BACKGROUND Machine learning (ML) is a subdomain of artificial intelligence that enables computers to abstract patterns from data without explicit programming. A myriad of impactful ML applications already exists in orthopaedics ranging from predicting infections after surgery to diagnostic imaging. However, no systematic reviews that we know of have compared, in particular, the performance of ML models with that of clinicians in musculoskeletal imaging to provide an up-to-date summary regarding the extent of applying ML to imaging diagnoses. By doing so, this review delves into where current ML developments stand in aiding orthopaedists in assessing musculoskeletal images.   QUESTIONS/PURPOSES This systematic review aimed (1) to compare performance of ML models versus clinicians in detecting, differentiating, or classifying orthopaedic abnormalities on imaging by (A) accuracy, sensitivity, and specificity, (B) input features (for example, plain radiographs, MRI scans, ultrasound), (C) clinician specialties, and (2) to compare the performance of clinician-aided versus unaided ML models.   METHODS A systematic review was performed in PubMed, Embase, and the Cochrane Library for studies published up to October 1, 2019, using synonyms for machine learning and all potential orthopaedic specialties. We included all studies that compared ML models head-to-head against clinicians in the binary detection of abnormalities in musculoskeletal images. After screening 6531 studies, we ultimately included 12 studies. We conducted quality assessment using the Methodological Index for Non-randomized Studies (MINORS) checklist. All 12 studies were of comparable quality, and they all clearly included six of the eight critical appraisal items (study aim, input feature, ground truth, ML versus human comparison, performance metric, and ML model description). This justified summarizing the findings in a quantitative form by calculating the median absolute improvement of the ML models compared with clinicians for the following metrics of performance: accuracy, sensitivity, and specificity.   RESULTS ML models provided, in aggregate, only very slight improvements in diagnostic accuracy and sensitivity compared with clinicians working alone and were on par in specificity (3% (interquartile range [IQR] -2.0% to 7.5%), 0.06% (IQR -0.03 to 0.14), and 0.00 (IQR -0.048 to 0.048), respectively). Inputs used by the ML models were plain radiographs (n = 8), MRI scans (n = 3), and ultrasound examinations (n = 1). Overall, ML models outperformed clinicians more when interpreting plain radiographs than when interpreting MRIs (17 of 34 and 3 of 16 performance comparisons, respectively). Orthopaedists and radiologists performed similarly to ML models, while ML models mostly outperformed other clinicians (outperformance in 7 of 19, 7 of 23, and 6 of 10 performance comparisons, respectively). Two studies evaluated the performance of clinicians aided and unaided by ML models; both demonstrated considerable improvements in ML-aided clinician performance by reporting a 47% decrease of misinterpretation rate (95% confidence interval [CI] 37 to 54; p < 0.001) and a mean increase in specificity of 0.048 (95% CI 0.029 to 0.068; p < 0.001) in detecting abnormalities on musculoskeletal images.   CONCLUSIONS At present, ML models have comparable performance to clinicians in assessing musculoskeletal images. ML models may enhance the performance of clinicians as a technical supplement rather than as a replacement for clinical intelligence. Future ML-related studies should emphasize how ML models can complement clinicians, instead of determining the overall superiority of one versus the other. This can be accomplished by improving transparent reporting, diminishing bias, determining the feasibility of implantation in the clinical setting, and appropriately tempering conclusions.   LEVEL OF EVIDENCE Level III, diagnostic study.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",149,"2022-07-13 09:19:47","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"J. Jill Hopkins, P. Keane, K. Balaskas","Delivering personalized medicine in retinal care: from artificial intelligence algorithms to clinical application.",2020,"","","","",150,"2022-07-13 09:19:47","","10.1097/ICU.0000000000000677","","",,,,,8,4.00,3,3,2,"PURPOSE OF REVIEW To review the current status of artificial intelligence systems in ophthalmology and highlight the steps required for clinical translation of artificial intelligence into personalized health care (PHC) in retinal disease.   RECENT FINDINGS Artificial intelligence systems for ophthalmological application have made rapid advances, but are yet to attain a state of technical maturity that allows their adoption into real-world settings. There remains an 'artificial intelligence chasm' in the spheres of validation, regulation, safe implementation, and demonstration of clinical impact that needs to be bridged before the full potential of artificial intelligence to deliver PHC can be realized.   SUMMARY Ophthalmology is currently in a stage between the demonstration of the potential of artificial intelligence and widespread deployment. Next stages include aggregating and curating datasets, training and validating artificial intelligence systems, establishing the regulatory framework, implementation and adoption with ongoing evaluation and model adjustment, and finally, meaningful human-artificial intelligence interaction with clinically validated tools that have demonstrated measurable impact on patient and healthcare system outcomes. Ophthalmologists should leverage the ability of artificial intelligence systems to glean insights from large volumes of multivariate data, and to interpret artificial intelligence recommendations in a clinical context. In doing so, the field will be well positioned to lead the transformation of health care in a personalized direction. VIDEO ABSTRACT: http://links.lww.com/COOP/A35.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",151,"2022-07-13 09:19:47","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
6,"Oscar Serradilla, E. Zugasti, C. Cernuda, Andoitz Aranburu, Julian Ramirez de Okariz, Urko Zurutuza","Interpreting Remaining Useful Life estimations combining Explainable Artificial Intelligence and domain knowledge in industrial machinery",2020,"","","","",152,"2022-07-13 09:19:47","","10.1109/FUZZ48607.2020.9177537","","",,,,,6,3.00,1,6,2,"This paper presents the implementation and explanations of a remaining life estimator model based on machine learning, applied to industrial data. Concretely, the model has been applied to a bushings testbed, where fatigue life tests are performed to find more suitable bushing characteristics. Different regressors have been compared Environmental and Operational Condition and setting variables as input data to prognosticate the remaining life on each observation during fatigue tests, where final model is a Random Forest was chosen given its accuracy and explainability potential. The model creation, optimisation and interpretation has been guided combining eXplainable Artificial Intelligence with domain knowledge.Precisely, ELI5 and LIME explainable techniques have been used to perform local and global explanations. These were used to understand the relevance of predictor variables in individual and overall remaining life estimations. The achieved results have been process knowledge gain and expert knowledge validation, assertion of huge potential of data-driven models in industrial processes and highlight the need of collaboration between expert knowledge technicians and eXplainable Artificial Intelligence techniques to understand advanced machine learning models.","",""
6,"T. York, Heloise Jenney, G. Jones","Clinician and computer: a study on patient perceptions of artificial intelligence in skeletal radiography",2020,"","","","",153,"2022-07-13 09:19:47","","10.1136/bmjhci-2020-100233","","",,,,,6,3.00,2,3,2,"Background Up to half of all musculoskeletal injuries are investigated with plain radiographs. However, high rates of image interpretation error mean that novel solutions such as artificial intelligence (AI) are being explored. Objectives To determine patient confidence in clinician-led radiograph interpretation, the perception of AI-assisted interpretation and management, and to identify factors which might influence these views. Methods A novel questionnaire was distributed to patients attending fracture clinic in a large inner-city teaching hospital. Categorical and Likert scale questions were used to assess participant demographics, daily electronics use, pain score and perceptions towards AI used to assist in interpretation of their radiographs, and guide management. Results 216 questionnaires were included (M=126, F=90). Significantly higher confidence in clinician rather than AI-assisted interpretation was observed (clinician=9.20, SD=1.27 vs AI=7.06, SD=2.13), 95.4% reported favouring clinician over AI-performed interpretation in the event of disagreement. Small positive correlations were observed between younger age/educational achievement and confidence in AI-assistance. Students demonstrated similarly increased confidence (8.43, SD 1.80), and were over-represented in the minority who indicated a preference for AI-assessment over their clinicians (50%). Conclusions Participant’s held the clinician’s assessment in the highest regard and expressed a clear preference for it over the hypothetical AI assessment. However, robust confidence scores for the role of AI-assistance in interpreting skeletal imaging suggest patients view the technology favourably. Findings indicate that younger, more educated patients are potentially more comfortable with a role for AI-assistance however further research is needed to overcome the small number of responses on which these observations are based.","",""
6,"A. Elkins, F. F. Freitas, V. Sanz","Developing an App to interpret Chest X-rays to support the diagnosis of respiratory pathology with Artificial Intelligence",2019,"","","","",154,"2022-07-13 09:19:47","","10.21037/JMAI.2019.12.01","","",,,,,6,2.00,2,3,3,"In this paper we present our work to improve access to diagnosis in remote areas where good quality medical services may be lacking. We develop new Machine Learning methodologies for deployment onto mobile devices to help the early diagnosis of a number of life-threatening conditions using X-ray images. By using the latest developments in fast and portable Artificial Intelligence environments, we develop a smartphone app using an Artificial Neural Network to assist physicians in their diagnostic.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",155,"2022-07-13 09:19:47","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",156,"2022-07-13 09:19:47","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
2,"Sara Aqab, Muhammad Usman","Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing",2020,"","","","",157,"2022-07-13 09:19:47","","10.14569/ijacsa.2020.0110719","","",,,,,2,1.00,1,2,2,"Due to increased usage of digital technologies in all sectors and in almost all day to day activities to store and pass information, Handwriting character recognition has become a popular subject of research. Handwriting remains relevant, but people still want to have Handwriting copies converted into electronic copies that can be communicated and stored electronically. Handwriting character recognition refers to the computer's ability to detect and interpret intelligible Handwriting input from Handwriting sources such as touch screens, photographs, paper documents, and other sources. Handwriting characters remain complex since different individuals have different handwriting styles. This paper aims to report the development of a Handwriting character recognition system that will be used to read students and lectures Handwriting notes. The development is based on an artificial neural network, which is a field of study in artificial intelligence. Different techniques and methods are used to develop a Handwriting character recognition system. However, few of them focus on neural networks. The use of neural networks for recognizing Handwriting characters is more efficient and robust compared with other computing techniques. The paper also outlines the methodology, design, and architecture of the Handwriting character recognition system and testing and results of the system development. The aim is to demonstrate the effectiveness of neural networks for Handwriting character recognition.","",""
0,"R. Brachman, David Gunning, Murray Burke","Integrated Artificial Intelligence Systems",2020,"","","","",158,"2022-07-13 09:19:47","","","","",,,,,0,0.00,0,3,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 66 AI MAGAZINE When one thinks about what it might take to build an intelligent system, it is evident that multiple capabilities will be required. Intelligence is generally considered to be reflected in the ability of a system to learn and understand the world around it, and to deal successfully with new or challenging situations. A closer look at what it might take to accomplish this reveals a surprisingly complex set of abilities that must work together. There are many variations on these themes, but roughly speaking, a robustly intelligent, autonomous agent embedded in the real world will need perceptual capabilities to sense and help interpret external signals and phenomena; a set of beliefs about the world, including itself and other agents, cause and effect, and a host of other things relevant to its survival and success in achieving its goals; a variety of reasoning capabilities to determine implications of its beliefs, understand its environment, plan ahead, solve problems, and so forth; a wide array of learning and adaptation capabilities; the ability to affect the world through action; and, some kind of rich communication mechanism along the lines of natural human language generation and understanding.  From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richlyintegrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI. Integrated Artificial Intelligence Systems","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",159,"2022-07-13 09:19:47","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
0,"B. Zaman, M. McKee","Smart Tools for Wetland Management: UAV Data and Artificial Intelligence Technique for Change Detection of Phragmites Australis in the Bear River Migratory Bird Refuge",2020,"","","","",160,"2022-07-13 09:19:47","","10.12691/AEES-8-6-9","","",,,,,0,0.00,0,2,2,"Unmanned Aerial Vehicle (UAV) data and artificial intelligence (AI) techniques have often been separately used for wetland management applications. Existence of native or invasive weed species which are a threat to the biodiversity of the wetland ecosystem is a common problem. High resolution multispectral image data from UAV and AI analysis together may prove to be a very robust combination for solving some of the wetland management problems. AggieAir, a UAV platform developed at Utah State University (USU), was used to acquire very high-resolution, multispectral aerial images of the study area in the summers of 2010 and 2011. The AggieAir data and an AI model have been used to classify and detect the weed P. australis in the Bear River Migratory Bird Refuge (BRMBR) wetland ecology. The images were classified based on the reflectance values in red, green and NIR bands using the multiclass relevance vector machine (MCRVM). The total P. australis cover was calculated and results indicated a decrease of 6.6% in total P. australis cover between June and September 2010 but an increase of 43.85% between June 2010 to July 2011. This study provided useful information about the extent and spread of P. australis P. australis which is a priority as regards to invasive plant treatment and control in the BRMBR. The results are easy to interpret and can contribute to management advising. Given the high spatial and temporal resolution of the UAV and excellent performance of the MCRVM model, we propose their further use for wetland management applications.","",""
0,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dental Diagnostics: Chances and challenges",2020,"","","","",161,"2022-07-13 09:19:47","","","","",,,,,0,0.00,0,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. is a using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning and conduct, e.g. image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, a, predictive, preventive and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to (1) limited data availability, accessibility, structure and comprehensiveness, (2) lacking methodological rigor and standards in their development, (3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, e.g. by improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Last, trustworthiness into and generalizability of dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"J. Wallace, Angelica Valdivia","A Hybrid Artificial Intelligence, Machine Learning, and Control Algorithm Integration Framework for Embedded Systems using Semantic Web Technology",2020,"","","","",162,"2022-07-13 09:19:47","","10.1109/CSCI51800.2020.00089","","",,,,,0,0.00,0,2,2,"A framework to integrate structurally different artificial intelligence, machine learning, and control algorithms is combined with an execution framework to create a powerful embedded system development platform. Control, decision, or algorithms providing an emulation of intelligent behavior in both declarative (interpreted) and imperative (compiled) paradigms can now be combined, for example Prolog and neural networks, respectively. This hybridization of algorithms provides more efficient overall control of systems in terms of resources such as compute cycles, network bandwidth and throughput, and memory speed and capacity. By providing an execution framework and control software that is native to embedded system and cloud architectures, and supports interactivity and time synchronization, the true utility of cloud computing and ""big data systems"" can be increased.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",163,"2022-07-13 09:19:47","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
66,"Keping Yu, Zhiwei Guo, Yulian Shen, Wei Wang, Jerry Chun‐wei Lin, Takuro Sato","Secure Artificial Intelligence of Things for Implicit Group Recommendations",2021,"","","","",164,"2022-07-13 09:19:47","","10.1109/JIOT.2021.3079574","","",,,,,66,66.00,11,6,1,"The emergence of Artificial Intelligence of Things (AIoT) has provided novel insights for many social computing applications, such as group recommender systems. As the distances between people have been greatly shortened, there has been more general demand for the provision of personalized services aimed at groups instead of individuals. The existing methods for capturing group-level preference features from individuals have mostly been established via aggregation and face two challenges: 1) secure data management workflows are absent and 2) implicit preference feedback is ignored. To tackle these current difficulties, this article proposes secure AIoT for implicit group recommendations (SAIoT-GRs). For the hardware module, a secure Internet of Things structure is developed as the bottom support platform. For the software module, a collaborative Bayesian network model and noncooperative game are introduced as algorithms. This secure AIoT architecture is able to maximize the advantages of the two modules. In addition, a large number of experiments are carried out to evaluate the performance of SAIoT-GR in terms of efficiency and robustness.","",""
199,"Dong Wook Kim, H. Jang, K. Kim, Youngbin Shin, S. Park","Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers",2019,"","","","",165,"2022-07-13 09:19:47","","10.3348/kjr.2019.0025","","",,,,,199,66.33,40,5,3,"Objective To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images. Materials and Methods PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals. Results Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals. Conclusion Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms.","",""
195,"A. Rodríguez-Ruiz, E. Krupinski, J. Mordang, K. Schilling, S. Heywang-Köbrunner, I. Sechopoulos, R. Mann","Detection of Breast Cancer with Mammography: Effect of an Artificial Intelligence Support System.",2019,"","","","",166,"2022-07-13 09:19:47","","10.1148/radiol.2018181371","","",,,,,195,65.00,28,7,3,"Purpose To compare breast cancer detection performance of radiologists reading mammographic examinations unaided versus supported by an artificial intelligence (AI) system. Materials and Methods An enriched retrospective, fully crossed, multireader, multicase, HIPAA-compliant study was performed. Screening digital mammographic examinations from 240 women (median age, 62 years; range, 39-89 years) performed between 2013 and 2017 were included. The 240 examinations (100 showing cancers, 40 leading to false-positive recalls, 100 normal) were interpreted by 14 Mammography Quality Standards Act-qualified radiologists, once with and once without AI support. The readers provided a Breast Imaging Reporting and Data System score and probability of malignancy. AI support provided radiologists with interactive decision support (clicking on a breast region yields a local cancer likelihood score), traditional lesion markers for computer-detected abnormalities, and an examination-based cancer likelihood score. The area under the receiver operating characteristic curve (AUC), specificity and sensitivity, and reading time were compared between conditions by using mixed-models analysis dof variance and generalized linear models for multiple repeated measurements. Results On average, the AUC was higher with AI support than with unaided reading (0.89 vs 0.87, respectively; P = .002). Sensitivity increased with AI support (86% [86 of 100] vs 83% [83 of 100]; P = .046), whereas specificity trended toward improvement (79% [111 of 140]) vs 77% [108 of 140]; P = .06). Reading time per case was similar (unaided, 146 seconds; supported by AI, 149 seconds; P = .15). The AUC with the AI system alone was similar to the average AUC of the radiologists (0.89 vs 0.87). Conclusion Radiologists improved their cancer detection at mammography when using an artificial intelligence system for support, without requiring additional reading time. Published under a CC BY 4.0 license. See also the editorial by Bahl in this issue.","",""
6,"Tanya Tiwari, Tanuj Tiwari, Sanjay Tiwari","How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?",2018,"","","","",167,"2022-07-13 09:19:47","","10.23956/IJARCSSE.V8I2.569","","",,,,,6,1.50,2,3,4,"There is a lot of confusion these days about Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL). A computer system able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. Artificial Intelligence has made it possible. Deep learning is a subset of machine learning, and machine learning is a subset of AI, which is an umbrella term for any computer program that does something smart. In other words, all machine learning is AI, but not all AI is machine learning, and so forth. Machine Learning represents a key evolution in the fields of computer science, data analysis, software engineering, and artificial intelligence. Machine learning (ML)is a vibrant field of research, with a range of exciting areas for further development across different methods and applications. These areas include algorithmic interpretability, robustness, privacy, fairness, inference of causality, human-machine interaction, and security. The goal of ML is never to make “perfect” guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful. Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones. This paper gives an overview of artificial intelligence, machine learning & deep learning techniques and compare these techniques.","",""
286,"Anna Jobin, M. Ienca, E. Vayena","Artificial Intelligence: the global landscape of ethics guidelines",2019,"","","","",168,"2022-07-13 09:19:47","","10.1038/s42256-019-0088-2","","",,,,,286,95.33,95,3,3,"","",""
225,"Kai-Cheng Yang, Onur Varol, Clayton A. Davis, Emilio Ferrara, A. Flammini, F. Menczer","Arming the public with artificial intelligence to counter social bots",2019,"","","","",169,"2022-07-13 09:19:47","","10.1002/hbe2.115","","",,,,,225,75.00,38,6,3,"The increased relevance of social media in our daily life has been accompanied by efforts to manipulate online conversations and opinions. Deceptive social bots -- automated or semi-automated accounts designed to impersonate humans -- have been successfully exploited for these kinds of abuse. Researchers have responded by developing AI tools to arm the public in the fight against social bots. Here we review the literature on different types of bots, their impact, and detection methods. We use the case study of Botometer, a popular bot detection tool developed at Indiana University, to illustrate how people interact with AI countermeasures. A user experience survey suggests that bot detection has become an integral part of the social media experience for many users. However, barriers in interpreting the output of AI tools can lead to fundamental misunderstandings. The arms race between machine learning methods to develop sophisticated bots and effective countermeasures makes it necessary to update the training data and features of detection tools. We again use the Botometer case to illustrate both algorithmic and interpretability improvements of bot scores, designed to meet user expectations. We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",170,"2022-07-13 09:19:47","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
11,"Xin Yi, S. Adams, Robert D. E. Henderson, P. Babyn","Computer-Aided Assessment of Catheters and Tubes on Radiographs: How Good is Artificial Intelligence for Assessment?",2020,"","","","",171,"2022-07-13 09:19:47","","10.1148/ryai.2020190082","","",,,,,11,5.50,3,4,2,"Catheters are the second most common abnormal finding on radiographs. The position of catheters must be assessed on all radiographs because serious complications can arise if catheters are malpositioned. However, due to the large number of radiographs obtained each day, there can be substantial delays between the time a radiograph is obtained and when it is interpreted by a radiologist. Computer-aided approaches hold the potential to assist in prioritizing radiographs with potentially malpositioned catheters for interpretation and automatically insert text indicating the placement of catheters in radiology reports, thereby improving radiologists' efficiency. After 50 years of research in computer-aided diagnosis, there is still a paucity of study in this area. With the development of deep learning approaches, the problem of catheter assessment is far more solvable. This review provides an overview of current algorithms and identifies key challenges in building a reliable computer-aided diagnosis system for assessment of catheters on radiographs. This review may serve to further the development of machine learning approaches for this important use case. Supplemental material is available for this article. © RSNA, 2020.","",""
3,"E. Sala, Stephan Ursprung","Artificial Intelligence in Radiology: The Computer's Helping Hand Needs Guidance.",2020,"","","","",172,"2022-07-13 09:19:47","","10.1148/ryai.2020200207","","",,,,,3,1.50,2,2,2,"A intelligence (AI) is not entirely new to the medical field. We are accustomed to applying tools that have been developed with a varying degree of human and computer input in our clinical practice. Representative examples include handcrafted diagnostic algorithms to triage patients presenting with acute illness (1), statistically derived scores for osteoporotic fracture risk assessment (2), and decision trees for the differentiation of benign and malignant ovarian masses (3). Common to all these tools is that changes to input parameters lead to predictable changes in model output, making them easy to interrogate and understand. More sophisticated, deep learning (DL)–based models employed in decision support systems have been implemented in clinical practice for the automated interpretation of electrocardiograms (4) and detection and classification of lesions on mammography (5). Although DL-based models have exciting potential to solve complex problems, their black box approach faces skepticism despite advances in interpretability and explainability (6). The recent, widespread availability of hardware and software for the development of AI solutions for medicine has inspired an exponential increase in publications. Data-rich medical specialties such as radiology have become a particular focus of rapid development. However, there are ample scope and encouraging initiatives for AI to support the delivery of care from general practice, primary care, the emergency department, and specialist diagnostics to patient self-care (7). This study by Tadavarthi and colleagues (8) has examined the market of AI-enabled image analysis solutions for radiology and provides recommendations for the evaluation of AI tools before purchase. In their market study, the authors illustrate how most solutions are focused on highvolume conditions. Unsurprisingly, many solutions focus on support for lesion detection and quantification rather than decision support for diagnosis and recommendations for management where regulatory stakes and hurdles are higher. Yet only a minority of solutions advertised at the Radiological Society of North America and Society of Imaging Informatics in Medicine annual meetings between November 2016 and June 2019 have received approval for the American or European market. This finding is indicative of a rapidly developing field where, after years of purely scientific development, the first tools start undergoing consolidation, approval, and marketing. The sole focus on solutions advertised at North American conferences risks missing tools by smaller companies with lower marketing budgets and introducing a geographic bias. Indeed, several other solutions have achieved Conformité Européenne marking or U.S. Food and Drug Administration (FDA) approval. Such approval or their equivalent in other territories is a precondition for the implementation of products, but it is by no means sufficient to identify clinically beneficial and financially viable tools. Overall, the adoption of these algorithms into clinical practice is emerging, and further work is needed to transform the scientific enthusiasm for developing advanced AI tools with a broader scope into clinically workable solutions. For tracking the ongoing market, surveys like this study (dating from November 2019) date quickly, leaving a gap for a living review and other market watchers. Tadavarthi et al contribute to a growing number of recommendations for the acquisition and adoption of AI solutions in medicine with a particular focus on radiology (9). They raise important considerations to determine whether an AI tool is a viable solution for an individual service. In addition, one might want to consider the following criteria: Artificial Intelligence in Radiology: The Computer’s Helping Hand Needs Guidance","",""
99,"Y. Shrestha, Shiko M. Ben-Menahem, G. von Krogh","Organizational Decision-Making Structures in the Age of Artificial Intelligence",2019,"","","","",173,"2022-07-13 09:19:47","","10.1177/0008125619862257","","",,,,,99,33.00,33,3,3,"How does organizational decision-making change with the advent of artificial intelligence (AI)-based decision-making algorithms? This article identifies the idiosyncrasies of human and AI-based decision making along five key contingency factors: specificity of the decision search space, interpretability of the decision-making process and outcome, size of the alternative set, decision-making speed, and replicability. Based on a comparison of human and AI-based decision making along these dimensions, the article builds a novel framework outlining how both modes of decision making may be combined to optimally benefit the quality of organizational decision making. The framework presents three structural categories in which decisions of organizational members can be combined with AI-based decisions: full human to AI delegation; hybrid—human-to-AI and AI-to-human—sequential decision making; and aggregated human–AI decision making.","",""
132,"Y. Yang, C. S. Bang","Application of artificial intelligence in gastroenterology",2019,"","","","",174,"2022-07-13 09:19:47","","10.3748/wjg.v25.i14.1666","","",,,,,132,44.00,66,2,3,"Artificial intelligence (AI) using deep-learning (DL) has emerged as a breakthrough computer technology. By the era of big data, the accumulation of an enormous number of digital images and medical records drove the need for the utilization of AI to efficiently deal with these data, which have become fundamental resources for a machine to learn by itself. Among several DL models, the convolutional neural network showed outstanding performance in image analysis. In the field of gastroenterology, physicians handle large amounts of clinical data and various kinds of image devices such as endoscopy and ultrasound. AI has been applied in gastroenterology in terms of diagnosis, prognosis, and image analysis. However, potential inherent selection bias cannot be excluded in the form of retrospective study. Because overfitting and spectrum bias (class imbalance) have the possibility of overestimating the accuracy, external validation using unused datasets for model development, collected in a way that minimizes the spectrum bias, is mandatory. For robust verification, prospective studies with adequate inclusion/exclusion criteria, which represent the target populations, are needed. DL has its own lack of interpretability. Because interpretability is important in that it can provide safety measures, help to detect bias, and create social acceptance, further investigations should be performed.","",""
85,"T. Loftus, P. Tighe, A. Filiberto, P. Efron, S. Brakenridge, A. Mohr, Parisa Rashidi, G. Upchurch, A. Bihorac","Artificial Intelligence and Surgical Decision-Making.",2019,"","","","",175,"2022-07-13 09:19:47","","10.1001/jamasurg.2019.4917","","",,,,,85,28.33,9,9,3,"Importance Surgeons make complex, high-stakes decisions under time constraints and uncertainty, with significant effect on patient outcomes. This review describes the weaknesses of traditional clinical decision-support systems and proposes that artificial intelligence should be used to augment surgical decision-making.   Observations Surgical decision-making is dominated by hypothetical-deductive reasoning, individual judgment, and heuristics. These factors can lead to bias, error, and preventable harm. Traditional predictive analytics and clinical decision-support systems are intended to augment surgical decision-making, but their clinical utility is compromised by time-consuming manual data management and suboptimal accuracy. These challenges can be overcome by automated artificial intelligence models fed by livestreaming electronic health record data with mobile device outputs. This approach would require data standardization, advances in model interpretability, careful implementation and monitoring, attention to ethical challenges involving algorithm bias and accountability for errors, and preservation of bedside assessment and human intuition in the decision-making process.   Conclusions and Relevance Integration of artificial intelligence with surgical decision-making has the potential to transform care by augmenting the decision to operate, informed consent process, identification and mitigation of modifiable risk factors, decisions regarding postoperative management, and shared decisions regarding resource use.","",""
106,"S. Graham, C. Depp, Ellen E. Lee, C. Nebeker, X. Tu, Ho-Cheol Kim, D. Jeste","Artificial Intelligence for Mental Health and Mental Illnesses: an Overview",2019,"","","","",176,"2022-07-13 09:19:47","","10.1007/s11920-019-1094-0","","",,,,,106,35.33,15,7,3,"","",""
126,"Ali Hassan Sodhro, Sandeep Pirbhulal, V. H. C. de Albuquerque","Artificial Intelligence-Driven Mechanism for Edge Computing-Based Industrial Applications",2019,"","","","",177,"2022-07-13 09:19:47","","10.1109/TII.2019.2902878","","",,,,,126,42.00,42,3,3,"Due to various challenging issues such as, computational complexity and more delay in cloud computing, edge computing has overtaken the conventional process by efficiently and fairly allocating the resources i.e., power and battery lifetime in Internet of things (IoT)-based industrial applications. In the meantime, intelligent and accurate resource management by artificial intelligence (AI) has become the center of attention especially in industrial applications. With the coordination of AI at the edge will remarkably enhance the range and computational speed of IoT-based devices in industries. But the challenging issue in these power hungry, short battery lifetime, and delay-intolerant portable devices is inappropriate and inefficient classical trends of fair resource allotment. Also, it is interpreted through extensive industrial datasets that dynamic wireless channel could not be supported by the typical power saving and battery lifetime techniques, for example, predictive transmission power control (TPC) and baseline. Thus, this paper proposes 1) a forward central dynamic and available approach (FCDAA) by adapting the running time of sensing and transmission processes in IoT-based portable devices; 2) a system-level battery model by evaluating the energy dissipation in IoT devices; and 3) a data reliability model for edge AI-based IoT devices over hybrid TPC and duty-cycle network. Two important cases, for instance, static (i.e., product processing) and dynamic (i.e., vibration and fault diagnosis) are introduced for proper monitoring of industrial platform. Experimental testbed reveals that the proposed FCDAA enhances energy efficiency and battery lifetime at acceptable reliability (∼0.95) by appropriately tuning duty cycle and TPC unlike conventional methods.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",178,"2022-07-13 09:19:47","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",179,"2022-07-13 09:19:47","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
59,"David Gunning, D. Aha","DARPA’s Explainable Artificial Intelligence Program",2019,"","","","",180,"2022-07-13 09:19:47","","","","",,,,,59,19.67,30,2,3,"n Dramatic success in machine learning has led toanewwaveofAIapplications (for example, transportation, security,medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA’s explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. TheXAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems’ explanations improve user understanding, user trust, and user task performance. Advances inmachine learning (ML) techniques promise to produce AI systems that perceive, learn, decide, and act on their own. However, they will be unable to explain their decisions and actions to human users. This lack is especially important for the Department of Defense, whose challenges require developingmore intelligent, autonomous, and symbiotic systems. Explainable AI will be essential if users are to understand, appropriately trust, and effectively manage these artificially intelligent partners. To address this, DARPA launched its explainable artificial intelligence (XAI) program in May 2017. DARPA defines explainable AI as AI systems that can explain their rationale to a human user, characterize their strengths and weaknesses, and convey an understanding of how theywill behave in the future. Naming this program explainable AI (rather than interpretable, comprehensible, or transparent AI, for example) reflects DARPA’s objective to create more human-understandable AI systems through the use of effective explanations. It also reflects the XAI team’s interest in the human psychology of explanation, which draws on the vast body of research and expertise in the social sciences.","",""
95,"G. Handelman, H. Kok, R. Chandra, A. H. Razavi, Shiwei Huang, M. Brooks, Michael J. Lee, H. Asadi","Peering Into the Black Box of Artificial Intelligence: Evaluation Metrics of Machine Learning Methods.",2019,"","","","",181,"2022-07-13 09:19:47","","10.2214/AJR.18.20224","","",,,,,95,31.67,12,8,3,"OBJECTIVE Machine learning (ML) and artificial intelligence (AI) are rapidly becoming the most talked about and controversial topics in radiology and medicine. Over the past few years, the numbers of ML- or AI-focused studies in the literature have increased almost exponentially, and ML has become a hot topic at academic and industry conferences. However, despite the increased awareness of ML as a tool, many medical professionals have a poor understanding of how ML works and how to critically appraise studies and tools that are presented to us. Thus, we present a brief overview of ML, explain the metrics used in ML and how to interpret them, and explain some of the technical jargon associated with the field so that readers with a medical background and basic knowledge of statistics can feel more comfortable when examining ML applications.   CONCLUSION Attention to sample size, overfitting, underfitting, cross validation, as well as a broad knowledge of the metrics of machine learning, can help those with little or no technical knowledge begin to assess machine learning studies. However, transparency in methods and sharing of algorithms is vital to allow clinicians to assess these tools themselves.","",""
93,"Mark O. Riedl","Human-Centered Artificial Intelligence and Machine Learning",2019,"","","","",182,"2022-07-13 09:19:47","","10.1002/HBE2.117","","",,,,,93,31.00,93,1,3,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",183,"2022-07-13 09:19:47","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
76,"Yung-Yao Chen, Yu‐Hsiu Lin, Chia-Ching Kung, Ming-Han Chung, I-Hsuan Yen","Design and Implementation of Cloud Analytics-Assisted Smart Power Meters Considering Advanced Artificial Intelligence as Edge Analytics in Demand-Side Management for Smart Homes",2019,"","","","",184,"2022-07-13 09:19:47","","10.3390/s19092047","","",,,,,76,25.33,15,5,3,"In a smart home linked to a smart grid (SG), demand-side management (DSM) has the potential to reduce electricity costs and carbon/chlorofluorocarbon emissions, which are associated with electricity used in today’s modern society. To meet continuously increasing electrical energy demands requested from downstream sectors in an SG, energy management systems (EMS), developed with paradigms of artificial intelligence (AI) across Internet of things (IoT) and conducted in fields of interest, monitor, manage, and analyze industrial, commercial, and residential electrical appliances efficiently in response to demand response (DR) signals as DSM. Usually, a DSM service provided by utilities for consumers in an SG is based on cloud-centered data science analytics. However, such cloud-centered data science analytics service involved for DSM is mostly far away from on-site IoT end devices, such as DR switches/power meters/smart meters, which is usually unacceptable for latency-sensitive user-centric IoT applications in DSM. This implies that, for instance, IoT end devices deployed on-site for latency-sensitive user-centric IoT applications in DSM should be aware of immediately analytical, interpretable, and real-time actionable data insights processed on and identified by IoT end devices at IoT sources. Therefore, this work designs and implements a smart edge analytics-empowered power meter prototype considering advanced AI in DSM for smart homes. The prototype in this work works in a cloud analytics-assisted electrical EMS architecture, which is designed and implemented as edge analytics in the architecture described and developed toward a next-generation smart sensing infrastructure for smart homes. Two different types of AI deployed on-site on the prototype are conducted for DSM and compared in this work. The experimentation reported in this work shows the architecture described with the prototype in this work is feasible and workable.","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",185,"2022-07-13 09:19:47","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
60,"N. Schork","Artificial Intelligence and Personalized Medicine.",2019,"","","","",186,"2022-07-13 09:19:47","","10.1007/978-3-030-16391-4_11","","",,,,,60,20.00,60,1,3,"","",""
63,"M. Topalovic, N. Das, P. Burgel, M. Daenen, E. Derom, Christel Haenebalcke, R. Janssen, H. Kerstjens, G. Liistro, R. Louis, V. Ninane, C. Pison, M. Schlesser, P. Vercauter, C. Vogelmeier, E. Wouters, J. Wynants, W. Janssens","Artificial intelligence outperforms pulmonologists in the interpretation of pulmonary function tests",2019,"","","","",187,"2022-07-13 09:19:47","","10.1183/13993003.01660-2018","","",,,,,63,21.00,6,18,3,"The interpretation of pulmonary function tests (PFTs) to diagnose respiratory diseases is built on expert opinion that relies on the recognition of patterns and the clinical context for detection of specific diseases. In this study, we aimed to explore the accuracy and interrater variability of pulmonologists when interpreting PFTs compared with artificial intelligence (AI)-based software that was developed and validated in more than 1500 historical patient cases. 120 pulmonologists from 16 European hospitals evaluated 50 cases with PFT and clinical information, resulting in 6000 independent interpretations. The AI software examined the same data. American Thoracic Society/European Respiratory Society guidelines were used as the gold standard for PFT pattern interpretation. The gold standard for diagnosis was derived from clinical history, PFT and all additional tests. The pattern recognition of PFTs by pulmonologists (senior 73%, junior 27%) matched the guidelines in 74.4±5.9% of the cases (range 56–88%). The interrater variability of κ=0.67 pointed to a common agreement. Pulmonologists made correct diagnoses in 44.6±8.7% of the cases (range 24–62%) with a large interrater variability (κ=0.35). The AI-based software perfectly matched the PFT pattern interpretations (100%) and assigned a correct diagnosis in 82% of all cases (p<0.0001 for both measures). The interpretation of PFTs by pulmonologists leads to marked variations and errors. AI-based software provides more accurate interpretations and may serve as a powerful decision support tool to improve clinical practice. There is poor accuracy and substantial disagreement between pulmonologists when interpreting complex pulmonary function data. Automating interpretation with artificial intelligence provides a powerful decision support tool in clinical practice. http://ow.ly/Tj9h30nxw4U","",""
51,"Lu Minh Le, H. Ly, B. Pham, Vuong Minh Le, T. Pham, Duy-Hung Nguyen, Xuan-Tuan Tran, Tien-Thinh Le","Hybrid Artificial Intelligence Approaches for Predicting Buckling Damage of Steel Columns Under Axial Compression",2019,"","","","",188,"2022-07-13 09:19:47","","10.3390/ma12101670","","",,,,,51,17.00,6,8,3,"This study aims to investigate the prediction of critical buckling load of steel columns using two hybrid Artificial Intelligence (AI) models such as Adaptive Neuro-Fuzzy Inference System optimized by Genetic Algorithm (ANFIS-GA) and Adaptive Neuro-Fuzzy Inference System optimized by Particle Swarm Optimization (ANFIS-PSO). For this purpose, a total number of 57 experimental buckling tests of novel high strength steel Y-section columns were collected from the available literature to generate the dataset for training and validating the two proposed AI models. Quality assessment criteria such as coefficient of determination (R2), Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) were used to validate and evaluate the performance of the prediction models. Results showed that both ANFIS-GA and ANFIS-PSO had a strong ability in predicting the buckling load of steel columns, but ANFIS-PSO (R2 = 0.929, RMSE = 60.522 and MAE = 44.044) was slightly better than ANFIS-GA (R2 = 0.916, RMSE = 65.371 and MAE = 48.588). The two models were also robust even with the presence of input variability, as investigated via Monte Carlo simulations. This study showed that the hybrid AI techniques could help constructing an efficient numerical tool for buckling analysis.","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",189,"2022-07-13 09:19:47","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
47,"Chengjie Zheng, T. V. Johnson, Aakriti Garg, Michael V. Boland","Artificial intelligence in glaucoma",2019,"","","","",190,"2022-07-13 09:19:47","","10.1097/ICU.0000000000000552","","",,,,,47,15.67,12,4,3,"Purpose of review The use of computers has become increasingly relevant to medical decision-making, and artificial intelligence methods have recently demonstrated significant advances in medicine. We therefore provide an overview of current artificial intelligence methods and their applications, to help the practicing ophthalmologist understand their potential impact on glaucoma care. Recent findings Techniques used in artificial intelligence can successfully analyze and categorize data from visual fields, optic nerve structure [e.g., optical coherence tomography (OCT) and fundus photography], ocular biomechanical properties, and a combination thereof to identify disease severity, determine disease progression, and/or recommend referral for specialized care. Algorithms have become increasingly complex in recent years, utilizing both supervised and unsupervised methods of artificial intelligence. Impressive performance of these algorithms on previously unseen data has been reported, often outperforming standard global indices and expert observers. However, there remains no clearly defined gold standard for determining the presence and severity of glaucoma, which undermines the training of these algorithms. To improve upon existing methodologies, future work must employ more robust definitions of disease, optimize data inputs for artificial intelligence analysis, and improve methods of extracting knowledge from learned results. Summary Artificial intelligence has the potential to revolutionize the screening, diagnosis, and classification of glaucoma, both through the automated processing of large data sets, and by earlier detection of new disease patterns. In addition, artificial intelligence holds promise for fundamentally changing research aimed at understanding the development, progression, and treatment of glaucoma, by identifying novel risk factors and by evaluating the importance of existing ones.","",""
47,"U. Raghavendra, U. Acharya, H. Adeli","Artificial Intelligence Techniques for Automated Diagnosis of Neurological Disorders",2019,"","","","",191,"2022-07-13 09:19:47","","10.1159/000504292","","",,,,,47,15.67,16,3,3,"Background: Authors have been advocating the research ideology that a computer-aided diagnosis (CAD) system trained using lots of patient data and physiological signals and images based on adroit integration of advanced signal processing and artificial intelligence (AI)/machine learning techniques in an automated fashion can assist neurologists, neurosurgeons, radiologists, and other medical providers to make better clinical decisions. Summary: This paper presents a state-of-the-art review of research on automated diagnosis of 5 neurological disorders in the past 2 decades using AI techniques: epilepsy, Parkinson’s disease, Alzheimer’s disease, multiple sclerosis, and ischemic brain stroke using physiological signals and images. Recent research articles on different feature extraction methods, dimensionality reduction techniques, feature selection, and classification techniques are reviewed. Key Message: CAD systems using AI and advanced signal processing techniques can assist clinicians in analyzing and interpreting physiological signals and images more effectively.","",""
49,"T. Panch, H. Mattie, R. Atun","Artificial intelligence and algorithmic bias: implications for health systems",2019,"","","","",192,"2022-07-13 09:19:47","","10.7189/jogh.09.020318","","",,,,,49,16.33,16,3,3,"www.jogh.org • doi: 10.7189/jogh.09.020318 1 December 2019 • Vol. 9 No. 2 • 020318 Artificial intelligence (AI) is a family of techniques where algorithms uncover or learn associations of predictive power from data. An algorithm is a step-by-step procedure for solving a problem. The most tangible form of AI is machine learning, which includes a family of techniques called deep learning that rely on multiple layers of representation of data and are thus able to represent complex relationships between inputs and outputs. However, learned representations are difficult for humans to interpret [1].","",""
44,"F. Nensa, A. Demircioğlu, C. Rischpler","Artificial Intelligence in Nuclear Medicine",2019,"","","","",193,"2022-07-13 09:19:47","","10.2967/jnumed.118.220590","","",,,,,44,14.67,15,3,3,"Despite the great media attention for artificial intelligence (AI), for many health care professionals the term and the functioning of AI remain a “black box,” leading to exaggerated expectations on the one hand and unfounded fears on the other. In this review, we provide a conceptual classification and a brief summary of the technical fundamentals of AI. Possible applications are discussed on the basis of a typical work flow in medical imaging, grouped by planning, scanning, interpretation, and reporting. The main limitations of current AI techniques, such as issues with interpretability or the need for large amounts of annotated data, are briefly addressed. Finally, we highlight the possible impact of AI on the nuclear medicine profession, the associated challenges and, last but not least, the opportunities.","",""
41,"C. Macrae","Governing the safety of artificial intelligence in healthcare",2019,"","","","",194,"2022-07-13 09:19:47","","10.1136/bmjqs-2019-009484","","",,,,,41,13.67,41,1,3,"Artificial intelligence (AI) has enormous potential to improve the safety of healthcare, from increasing diagnostic accuracy,1 to optimising treatment planning,2 to forecasting outcomes of care.3 However, integrating AI technologies into the delivery of healthcare is likely to introduce a range of new risks and amplify existing ones. For instance, failures in widely used software have the potential to quickly affect large numbers of patients4; hidden assumptions in underlying data and models can lead to AI systems delivering dangerous recommendations that are insensitive to local care processes,5 6 and opaque AI techniques such as deep learning can make explaining and learning from failure extremely difficult.7 8 To maximise the benefits of AI in healthcare and to build trust among patients and practitioners, it will therefore be essential to robustly govern the risks that AI poses to patient safety.  In a recent review in this journal, Challen and colleagues present an important and timely analysis of some of the key technological risks associated with the application of machine learning in clinical settings.9 Machine learning is a subfield of AI that focuses on the development of algorithms that are automatically derived and optimised through exposure to large quantities of exemplar ‘training’ data.10 The outputs of machine learning algorithms are essentially classifications of patterns that provide some sort of prediction—for instance, predicting whether an image shows a malignant melanoma or a benign mole.11 Some of the basic techniques of machine learning have existed for half a century or more, but progress in the field has accelerated rapidly due to advances in the development of ‘deep’ artificial neural networks12 combined with huge increases in computational power and the availability of enormous quantities of data. These techniques have underpinned recent public demonstrations of AI systems …","",""
44,"N. Kagiyama, S. Shrestha, P. Farjo, P. Sengupta","Artificial Intelligence: Practical Primer for Clinical Research in Cardiovascular Disease",2019,"","","","",195,"2022-07-13 09:19:47","","10.1161/JAHA.119.012788","","",,,,,44,14.67,11,4,3,"Artificial intelligence (AI) has begun to permeate and reform the field of medicine and cardiovascular medicine. Impacting about 100 million patients in the United States, the burden of cardiovascular disease is felt in a diverse array of demographics.1, 2 Meanwhile, routine mediums such as multimodality images, electronic health records (EHR), and mobile health devices store troves of underutilized data for each patient. AI has the potential to improve and influence the status quo, with capacity to learn from these massive data and apply knowledge from them to distinct circumstances.3, 4 With considerable information in each heart beat, cardiovascular medicine will definitely be one of the fields that embrace AI to move toward personalized and precise care.5    AI has already been woven into the fabric of everyday life. From an internet search engine, email spam and malware filtering, to uncovering fraudulent credit card purchases, AI addresses an individual's needs in the realms of business, entertainment, and technology. Unfortunately, medicine, including cardiology, has not fully embraced this revolution, with only a limited number of AI‐based clinical applications being available. Nevertheless, there is promise towards routine implementation; machine learning and deep learning have seen an exponential surge of cardiovascular publications in the past decade.6, 7 These methods have proven beneficial in a variety of complex areas including echocardiogram interpretation and diastolic dysfunction grade stratification.8, 9 The US Food and Drug Administration has already approved several devices that utilize AI features.10 Imagine coming to work finding that your system has analyzed all your patients while you were sleeping: their laboratory data, imaging results, symptoms, and mobile device data to calculate their risk of cardiovascular events, death, hospitalization, whether medications should be adjusted/added/removed, or whether they should be referred for an examination. The system presents you with the reasons for its recommendations, and you are confident that they are as good as those given by the most experienced physicians. This may allow you to spend time in shared decision making with your patients, both objectively and compassionately. Although there are currently several barriers/challenges to adoption of AI in clinical practice, undoubtedly, AI will drive current healthcare practice towards a more individualized and precision‐based approach over the next several years. Therefore, general understanding of AI techniques by clinicians and researchers in cardiovascular medicine is paramount. In this review article, we describe the fundamentals of AI that clinicians and researchers should understand, its definition and principles, how to interpret and apply AI in cardiovascular research, limitations, and future perspectives.","",""
1,"A. Le Vourch, Poncelet Edouard, Nicolas Laurent","Breast screening and artificial intelligence: an independent evaluation of two different software carried out at Valenciennes hospital",2020,"","","","",196,"2022-07-13 09:19:47","","10.1117/12.2564129","","",,,,,1,0.50,0,3,2,"We aimed to test two different software based on the deep learning technology versus two senior and one junior radiologist on a recall-based model for mammography. We performed a retrospective, monocentric, multi-reader study in the Centre Hospitalier de Valenciennes in the north of France. A set of examinations from a daily practice, with both screening and diagnostic studies, has been interpreted by 3 radiologists and the two AI based algorithms. The dataset has been enriched with BIRADS 4 and 5 cases in order to have a number of cancer cases sufficient to have statistically significant results. In total, 140 examinations have been included in the final dataset. Sensitivity (true positive rate - TPR), False positive rate (FPR), and recall rate per BI-RADS category were considered as endpoints for each of the radiologists. To compute these metrics all the included cases were considered as positive if the initial BI-RADS was equal or higher than 3 and as negative if the initial BI-RADS was 1 or 2. Additional analysis have been carried out taking into account the biopsy report (if any) as ground truth. While both the algorithms and radiologist have a good and comparative rate of sensitivity and FPR, the test based on BI-RADS categories (i.e. the number of cancer per BI-RADS category), showed heterogeneous results, with bad performances for one of the tested software on the extremes score of BI-RADS. We concluded that one of the analysed software cannot be used in the current clinical practice without further improvements, the second one shows promising results, but other studies are needed to have a robust external validation before being used in a daily practice.","",""
196,"W. Samek, K. Müller","Towards Explainable Artificial Intelligence",2019,"","","","",197,"2022-07-13 09:19:47","","10.1007/978-3-030-28954-6_1","","",,,,,196,65.33,98,2,3,"","",""
0,"Changyeob Shin","Vision-Guided Autonomous Surgical Subtasks via Surgical Robots with Artificial Intelligence",2020,"","","","",198,"2022-07-13 09:19:47","","","","",,,,,0,0.00,0,1,2,"Author(s): Shin, Changyeob | Advisor(s): Rosen, Jacob | Abstract: The introduction of automation into surgery may redefine the role of surgeons in operating rooms. While the majority of the manipulation will be performed autonomously by surgical robots, the surgeons may focus on decision-making procedures. This will drastically reduce the burden to surgeons by allowing them to instead interpret the abundant and intelligent information from the system, and will enhance the surgical outcome. To introduce the automation into surgery, the surgical robots are required to have: 1) high precision, 2) motion planning capabilities, and 3) scene understanding. Currently, surgical robots are commonly designed as cable-driven due to safety and several benefits such as low inertia. However, the cable-driven system has low precision because of cable stretch and long chains of cables. Therefore, a new control scheme of cable-driven surgical robots should be developed to overcome these limitations. Surgery is a complicated task consisting of multiple subtasks. To achieve the intermediate steps, motion planner should be developed. In surgery, the manipulation target objects are mostly soft tissue which introduces challenges in modeling the dynamics between the tool and the soft tissue. The motion planner should deal with the unknown dynamics while accomplishing each task. The surgical environment is further complicated by the many blood-covered anatomical structures. Surgeons use the visual feedback through an endoscope camera or other imaging devices, which provide rich information. Although the imaging devices are useful in understanding the surrounding anatomy, images from the devices are high-dimensional and it is difficult to process using algorithms to get high-level information. Therefore, vision-based perception algorithms to understand the relevant anatomy should be developed.This dissertation addresses the three problems above. In chapter two, a hybrid control scheme which utilizes both model-based and data-driven methods is introduced to improve the precision of the cable-driven surgical robots and robustness to hand-eye calibration errors. The convergence of the controller is shown theoretically and experimentally with the Raven IV. Additionally, the efficacy of the controller to clinical tasks is shown by demonstrating the autonomous operations of needle transfer and tissue debridement tasks. In chapter three, learning-based path planning algorithms are proposed for autonomous soft tissue manipulation. The planning algorithms learn the dynamics between the motion of a surgical tool and soft tissue, and the internal controller uses the learned dynamics to manipulate the soft tissue. The performance of developed algorithms is verified on a designed simulation and a robot experiment with the Raven IV. In chapter four, the semantic segmentation algorithm of the optical coherence tomography images for the automated lens extraction is presented. The algorithm uses the deep learning method and provides the capability of understanding the cross-sectional view of the eye anatomy. Furthermore, this segmentation algorithm is incorporated into the Intraocular Robotic Interventional and Surgical System (IRISS) to realize the semi-autonomous lens removal. The experimental results on 7 ex vivo pig eyes verified the efficacy of the developed framework.","",""
0,"M. Ebadi, Yashar Bezyan, S. Zabihifar, D. Koroteev","An Artificial Intelligence-Based Nonlinear Solver for Hydrocarbon Reservoir Simulations",2020,"","","","",199,"2022-07-13 09:19:47","","10.2118/200601-ms","","",,,,,0,0.00,0,4,2,"  The reservoir simulation is based on the solving of second-order nonlinear Partial Differential Equations (PDEs). Following the high-level of nonlinearity or irregular boundaries, analytical solutions are not applicable to solve the supposed PDEs. To numerically solve the PDEs, applying nonlinear solvers are recommended. Dependencies on derivatives and proper initial guesses are the main disadvantages of classic solvers. To overcome the mentioned obstacles, solving supposed equations based on Adaptive Neural Network (ANN) has been introduced.  The algorithm starts by introducing an initial set into the Nonlinear Simultaneous Algebraic Equations (NSAE). The outputs are compared with the desired matrix of zeros to generate the required error. The calculated vectors of errors and its derivation are firstly employed to update the ANN weights through applying the adaption laws, and secondly, create the input vector to run the ANN. The outputs of the ANN are considered as corrections to be made to the initial set. Then, the corrected initial set is reintroduced into equations. The procedure continues iteratively until the outputs of equations meet the required level of accuracy.  By taking advantages of the adaptive laws, the outputs of the presented algorithm have successfully been matched with answers of the classic solvers, but with less computational costs. The convergence of the shown algorithm has practically been examined by assuming various mathematical types of initial sets. The implemented algorithm has been robust enough to converge for different forms of the initial sets, even for invalid values like minus numbers. However, records indicate that the convergence rates are strongly dependent on the values of initial sets. Following the sensitivity analysis over the primary model of ANN lead to the optimized network, which could solve the supposed NSAE three times faster. It has been interpreted that the number of neurons (NN), the diagonal coefficient matrix of error (λ), and the adaptive coefficient (Fw) have the most significant impacts on the performance of the algorithm.  In contrast to Newton's method as the most well-known nonlinear solver, the launched algorithm does not require any proper initial guesses. Moreover, the absolute independence of computing the partial derivatives of the Jacobian matrix and its inversion, which causes a notable reduction of computational costs, is the other remarkable advantage of the proposed approach. The represented algorithm can be taken as the platform to develop the next generation of simulators working based on machine learning.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",200,"2022-07-13 09:19:47","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
