Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
30,"Mohsen Ahmadi, Abbas Sharifi, Mahta Jafarian Fard, Nastaran Soleimani","Detection of Brain Lesion Location in MRI Images Using Convolutional Neural Network and Robust PCA.",2021,"","","","",1,"2022-07-13 10:09:41","","10.1080/00207454.2021.1883602","","",,,,,30,30.00,8,4,1,"Detection of brain tumors plays a critical role in the treatment of patients. Before any treatment, tumor segmentation is crucial to protect healthy tissues during treatment and to destroy tumor cells. Tumor segmentation involves the detection, precise identification, and separation of tumor tissues. In this paper, we used a convolutional neural network to segment tumors in seven types of brain disease consisting of Glioma, Meningioma, Alzheimer's, Alzheimer's plus, Pick, Sarcoma, and Huntington. Firstly, we used feature-reduction-based method robust PCA to find tumor location and spot in a dataset of Harvard Medical School. Then we present an architecture of the CNN method to detect brain tumors. Results are depicted based on the probability of tumor location in MRI images. Results show that the presented method provides high accuracy (96%), sensitivity (99.9%), and dice index (91%) regarding other investigations. Highlights: Robust PCA is used for the clustering of brain MRI images as an automated approach. A Convolutional Neural Network architecture is presented for detection. The segmentation is performed for seven types of brain lesions. The results declare the efficiency of the presented method.","",""
30,"Wei Zhao, Wenbing Zhao, Wenfeng Wang, Xiaolu Jiang, Xiaodong Zhang, Yonghong Peng, Baocan Zhang, Guokai Zhang","A Novel Deep Neural Network for Robust Detection of Seizures Using EEG Signals",2020,"","","","",2,"2022-07-13 10:09:41","","10.1155/2020/9689821","","",,,,,30,15.00,4,8,2,"The detection of recorded epileptic seizure activity in electroencephalogram (EEG) segments is crucial for the classification of seizures. Manual recognition is a time-consuming and laborious process that places a heavy burden on neurologists, and hence, the automatic identification of epilepsy has become an important issue. Traditional EEG recognition models largely depend on artificial experience and are of weak generalization ability. To break these limitations, we propose a novel one-dimensional deep neural network for robust detection of seizures, which composes of three convolutional blocks and three fully connected layers. Thereinto, each convolutional block consists of five types of layers: convolutional layer, batch normalization layer, nonlinear activation layer, dropout layer, and max-pooling layer. Model performance is evaluated on the University of Bonn dataset, which achieves the accuracy of 97.63%∼99.52% in the two-class classification problem, 96.73%∼98.06% in the three-class EEG classification problem, and 93.55% in classifying the complicated five-class problem.","",""
19,"Klas Leino, Zifan Wang, Matt Fredrikson","Globally-Robust Neural Networks",2021,"","","","",3,"2022-07-13 10:09:41","","","","",,,,,19,19.00,6,3,1,"The threat of adversarial examples has motivated work on training certifiably robust neural networks to facilitate efficient verification of local robustness at inference time. We formalize a notion of global robustness, which captures the operational properties of on-line local robustness certification while yielding a natural learning objective for robust training. We show that widely-used architectures can be easily adapted to this objective by incorporating efficient global Lipschitz bounds into the network, yielding certifiably-robust models by construction that achieve state-of-theart verifiable accuracy. Notably, this approach requires significantly less time and memory than recent certifiable training methods, and leads to negligible costs when certifying points on-line; for example, our evaluation shows that it is possible to train a large robust Tiny-Imagenet model in a matter of hours. Our models effectively leverage inexpensive global Lipschitz bounds for real-time certification, despite prior suggestions that tighter local bounds are needed for good performance; we posit this is possible because our models are specifically trained to achieve tighter global bounds. Namely, we prove that the maximum achievable verifiable accuracy for a given dataset is not improved by using a local bound.","",""
93,"Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh","Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network",2018,"","","","",4,"2022-07-13 10:09:41","","","","",,,,,93,23.25,23,4,4,"We present a new algorithm to train a robust neural network against adversarial attacks. Our algorithm is motivated by the following two ideas. First, although recent work has demonstrated that fusing randomness can improve the robustness of neural networks (Liu 2017), we noticed that adding noise blindly to all the layers is not the optimal way to incorporate randomness. Instead, we model randomness under the framework of Bayesian Neural Network (BNN) to formally learn the posterior distribution of models in a scalable way. Second, we formulate the mini-max problem in BNN to learn the best model distribution under adversarial attacks, leading to an adversarial-trained Bayesian neural net. Experiment results demonstrate that the proposed algorithm achieves state-of-the-art performance under strong attacks. On CIFAR-10 with VGG network, our model leads to 14\% accuracy improvement compared with adversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD attack with $0.035$ distortion, and the gap becomes even larger on a subset of ImageNet.","",""
346,"A. Tran, Tal Hassner, I. Masi, G. Medioni","Regressing Robust and Discriminative 3D Morphable Models with a Very Deep Neural Network",2016,"","","","",5,"2022-07-13 10:09:41","","10.1109/CVPR.2017.163","","",,,,,346,57.67,87,4,6,"The 3D shapes of faces are well known to be discriminative. Yet despite this, they are rarely used for face recognition and always under controlled viewing conditions. We claim that this is a symptom of a serious but often overlooked problem with existing methods for single view 3D face reconstruction: when applied in the wild, their 3D estimates are either unstable and change for different photos of the same subject or they are over-regularized and generic. In response, we describe a robust method for regressing discriminative 3D morphable face models (3DMM). We use a convolutional neural network (CNN) to regress 3DMM shape and texture parameters directly from an input photo. We overcome the shortage of training data required for this purpose by offering a method for generating huge numbers of labeled examples. The 3D estimates produced by our CNN surpass state of the art accuracy on the MICC data set. Coupled with a 3D-3D face matching pipeline, we show the first competitive face recognition results on the LFW, YTF and IJB-A benchmarks using 3D face shapes as representations, rather than the opaque deep feature vectors used by other modern systems.","",""
57,"Yuanlin Zhang, Yuan Yuan, Y. Feng, Xiaoqiang Lu","Hierarchical and Robust Convolutional Neural Network for Very High-Resolution Remote Sensing Object Detection",2019,"","","","",6,"2022-07-13 10:09:41","","10.1109/TGRS.2019.2900302","","",,,,,57,19.00,14,4,3,"Object detection is a basic issue of very high-resolution remote sensing images (RSIs) for automatically labeling objects. At present, deep learning has gradually gained the competitive advantage for remote sensing object detection, especially based on convolutional neural networks (CNNs). Most of the existing methods use the global information in the fully connected feature vector and ignore the local information in the convolutional feature cubes. However, the local information can provide spatial information, which is helpful for accurate localization. In addition, there are variable factors, such as rotation and scaling, which affect the object detection accuracy in RSIs. In order to solve these problems, this paper presents a hierarchical robust CNN. First, multiscale convolutional features are extracted to represent the hierarchical spatial semantic information. Second, multiple fully connected layer features are stacked together so as to improve the rotation and scaling robustness. Experiments on two data sets have shown the effectiveness of our method. In addition, a large-scale high-resolution remote sensing object detection data set is established to make up for the current situation that the existing data set is insufficient or too small. The data set is available at https://github.com/CrazyStoneonRoad/TGRS-HRRSD-Dataset.","",""
203,"Tian Wang, Yang Chen, Meina Qiao, H. Snoussi","A fast and robust convolutional neural network-based defect detection model in product quality control",2018,"","","","",7,"2022-07-13 10:09:41","","10.1007/S00170-017-0882-0","","",,,,,203,50.75,51,4,4,"","",""
55,"R. Kamaleswaran, Ruhi Mahajan, O. Akbilgic","A robust deep convolutional neural network for the classification of abnormal cardiac rhythm using single lead electrocardiograms of variable length.",2018,"","","","",8,"2022-07-13 10:09:41","","10.1088/1361-6579/aaaa9d","","",,,,,55,13.75,18,3,4,"OBJECTIVE Atrial fibrillation (AF) is a major cause of hospitalization and death in the United States. Moreover, as the average age of individuals increases around the world, early detection and diagnosis of AF become even more pressing. In this paper, we introduce a novel deep learning architecture for the detection of normal sinus rhythm, AF, other abnormal rhythms, and noise.   APPROACH We have demonstrated through a systematic approach many hyperparameters, input sets, and optimization methods that yielded influence in both training time and performance accuracy. We have focused on these properties to identify an optimal 13-layer convolutional neural network (CNN) model which was trained on 8528 short single-lead ECG recordings and evaluated on a test dataset of 3658 recordings.   MAIN RESULTS The proposed CNN architecture achieved a state-of-the-art performance in identifying normal, AF and other rhythms with an average F 1-score of 0.83.   SIGNIFICANCE We have presented a robust deep learning-based architecture that can identify abnormal cardiac rhythms using short single-lead ECG recordings. The proposed architecture is computationally fast and can also be used in real-time cardiac arrhythmia detection applications.","",""
62,"Shunping Ji, Shiqing Wei, Meng Lu","A scale robust convolutional neural network for automatic building extraction from aerial and satellite imagery",2018,"","","","",9,"2022-07-13 10:09:41","","10.1080/01431161.2018.1528024","","",,,,,62,15.50,21,3,4,"ABSTRACT Identifying buildings from remote sensing imagery has been a challenge due to uncertainties from remote sensing imagery and variations in building structure and texture. In this study, we develop a scale robust CNN structure to improve the segmentation accuracy of building data from high-resolution aerial and satellite images. Based on a fully convolutional network, we introduce two Atrous convolutions on the first two lowest-scale layers, respectively, in the decoding step, aiming at enlarging the sight-of-view and integrate semantic information of large buildings. Then, a multi-scale aggregation strategy is applied. The last feature maps of each scale are used to predict the corresponding building labels, and further up-sampled to the original scale and concatenated for the final prediction. In addition, we introduce a combined data augmentation and relative radiometric calibration method for multi-source building extraction. The method enlarges sample spaces and hence the generalization ability of the deep learning models. We validate our developed methods with an aerial dataset of more than 180, 000 buildings with various architectural types, and a satellite image dataset consists of more than 29,000 buildings. The results are compared with several most recent studies. The comparison result shows our neural network outperformed other studies, especially in segmenting scenes of large buildings. The test on transfer learning from aerial dataset to satellite dataset showed our augmentation strategy significantly improved the prediction accuracy; however, further studies are needed to improve the generalization ability of the CNN model.","",""
25,"Yipeng Ning, Jian Wang, Houzeng Han, Xinglong Tan, Tian-xing Liu","An Optimal Radial Basis Function Neural Network Enhanced Adaptive Robust Kalman Filter for GNSS/INS Integrated Systems in Complex Urban Areas",2018,"","","","",10,"2022-07-13 10:09:41","","10.3390/s18093091","","",,,,,25,6.25,5,5,4,"Inertial Navigation System (INS) is often combined with Global Navigation Satellite System (GNSS) to increase the positioning accuracy and continuity. In complex urban environments, GNSS/INS integrated systems suffer not only from dynamical model errors but also GNSS observation gross errors. However, it is hard to distinguish dynamical model errors from observation gross errors because the observation residuals are affected by both of them in a loosely-coupled integrated navigation system. In this research, an optimal Radial Basis Function (RBF) neural network-enhanced adaptive robust Kalman filter (KF) method is proposed to isolate and mitigate the influence of the two types of errors. In the proposed method, firstly a test statistic based on Mahalanobis distance is treated as judging index to achieve fault detection. Then, an optimal RBF neural network strategy is trained on-line by the optimality principle. The network’s output will bring benefits in recognizing the above two kinds of filtering fault and the system is able to choose a robust or adaptive Kalman filtering method autonomously. A field vehicle test in urban areas with a low-cost GNSS/INS integrated system indicates that two types of errors simulated in complex urban areas have been detected, distinguished and eliminated with the proposed scheme, success rate reached up to 92%. In particular, we also find that the novel neural network strategy can improve the overall position accuracy during GNSS signal short-term outages.","",""
79,"Ze Wang, Chuxiong Hu, Yu Zhu, Suqin He, K. Yang, Ming Zhang","Neural Network Learning Adaptive Robust Control of an Industrial Linear Motor-Driven Stage With Disturbance Rejection Ability",2017,"","","","",11,"2022-07-13 10:09:41","","10.1109/TII.2017.2684820","","",,,,,79,15.80,13,6,5,"In this paper, a neural network learning adaptive robust controller (NNLARC) is synthesized for an industrial linear motor stage to achieve good tracking performance and excellent disturbance rejection ability. The NNLARC scheme contains parametric adaption part, robust feedback part, and radial basis function (RBF) neural network (NN) part in a parallel structure. The adaptive part and the robust part are designed based on the system dynamics to meet the challenge of parametric variations and uncertain random disturbances. It must be noted that in actual industrial machining situations, precision motion equipment is always disturbed by unknown factors, which usually cannot be described by mathematical models but affect the tracking accuracy significantly. Therefore, the RBF NN part is employed to further approximate and compensate the complicated disturbances with high reconstructing accuracy and fast training rate. The stability of the proposed NNLARC strategy is analyzed and proved through the Lyapunov theorem. Comparative experiments under various external disturbances such as completely unknown disturbance added by polyfoam are conducted on an industrial linear motor stage. The experimental results consistently validate that the proposed NNLARC control strategy can excellently meet the challenge of complicated disturbance in practical applications. The proposed scheme also provides a guidance for control strategy synthesis with both good tracking performance and disturbance rejection.","",""
18,"Vikash Sehwag, Shiqi Wang, Prateek Mittal, S. Jana","On Pruning Adversarially Robust Neural Networks",2020,"","","","",12,"2022-07-13 10:09:41","","","","",,,,,18,9.00,5,4,2,"In safety-critical but computationally resourceconstrained applications, deep learning faces two key challenges: lack of robustness against adversarial attacks and large neural network size (often millions of parameters). While the research community has extensively explored the use of robust training and network pruning independently to address one of these challenges, we show that integrating existing pruning techniques with multiple types of robust training techniques, including verifiably robust training, leads to poor robust accuracy even though such techniques can preserve high regular accuracy. We further demonstrate that making pruning techniques aware of the robust learning objective can lead to a large improvement in performance. We realize this insight by formulating the pruning objective as an empirical risk minimization problem which is then solved using SGD. We demonstrate the success of the proposed pruning technique across CIFAR-10, SVHN, and ImageNet dataset with four different robust training techniques: iterative adversarial training, randomized smoothing, MixTrain, and CROWN-IBP. Specifically, at 99% connection pruning ratio, we achieve gains up to 3.2, 10.0, and 17.8 percentage points in robust accuracy under state-of-the-art adversarial attacks for ImageNet, CIFAR-10, and SVHN dataset, respectively. Our code and compressed networks are publicly available1.","",""
40,"Sulabh Kumra, Shirin Joshi, F. Sahin","Antipodal Robotic Grasping using Generative Residual Convolutional Neural Network",2019,"","","","",13,"2022-07-13 10:09:41","","10.1109/IROS45743.2020.9340777","","",,,,,40,13.33,13,3,3,"In this paper, we present a modular robotic system to tackle the problem of generating and performing antipodal robotic grasps for unknown objects from the n-channel image of the scene. We propose a novel Generative Residual Convolutional Neural Network (GR-ConvNet) model that can generate robust antipodal grasps from n-channel input at real-time speeds (∼20ms). We evaluate the proposed model architecture on standard datasets and a diverse set of household objects. We achieved state-of-the-art accuracy of 97.7% and 94.6% on Cornell and Jacquard grasping datasets, respectively. We also demonstrate a grasp success rate of 95.4% and 93% on household and adversarial objects, respectively, using a 7 DoF robotic arm.","",""
106,"Xiaopeng Chen, W. Shen, Mingxiang Dai, Z. Cao, Jiong Jin, A. Kapoor","Robust Adaptive Sliding-Mode Observer Using RBF Neural Network for Lithium-Ion Battery State of Charge Estimation in Electric Vehicles",2016,"","","","",14,"2022-07-13 10:09:41","","10.1109/TVT.2015.2427659","","",,,,,106,17.67,18,6,6,"This paper presents a robust sliding-mode observer (RSMO) for state-of-charge (SOC) estimation of a lithium-polymer battery (LiPB) in electric vehicles (EVs). A radial basis function (RBF) neural network (NN) is employed to adaptively learn an upper bound of system uncertainty. The switching gain of the RSMO is adjusted based on the learned upper bound to achieve asymptotic error convergence of the SOC estimation. A battery equivalent circuit model (BECM) is constructed for battery modeling, and its BECM is identified in real time by using a forgetting-factor recursive least squares (FFRLS) algorithm. The experiments under the discharge current profiles based on EV driving cycles are conducted on the LiPB to validate the effectiveness and accuracy of the proposed framework for the SOC estimation.","",""
72,"Rongqiang Qian, Bailing Zhang, Yong Yue, Zhaojing Wang, Frans Coenen","Robust chinese traffic sign detection and recognition with deep convolutional neural network",2015,"","","","",15,"2022-07-13 10:09:41","","10.1109/ICNC.2015.7378092","","",,,,,72,10.29,14,5,7,"Detection and recognition of traffic sign, including various road signs and text, play an important role in autonomous driving, mapping/navigation and traffic safety. In this paper, we proposed a traffic sign detection and recognition system by applying deep convolutional neural network (CNN), which demonstrates high performance with regard to detection rate and recognition accuracy. Compared with other published methods which are usually limited to a predefined set of traffic signs, our proposed system is more comprehensive as our target includes traffic signs, digits, English letters and Chinese characters. The system is based on a multi-task CNN trained to acquire effective features for the localization and classification of different traffic signs and texts. In addition to the public benchmarking datasets, the proposed approach has also been successfully evaluated on a field-captured Chinese traffic sign dataset, with performance confirming its robustness and suitability to real-world applications.","",""
25,"Guoyang Liu, Weidong Zhou, Minxing Geng","Automatic Seizure Detection Based on S-Transform and Deep Convolutional Neural Network",2020,"","","","",16,"2022-07-13 10:09:41","","10.1142/S0129065719500242","","",,,,,25,12.50,8,3,2,"Automatic seizure detection is significant for the diagnosis of epilepsy and reducing the massive workload of reviewing continuous EEGs. In this work, a novel approach, combining Stockwell transform (S-transform) with deep Convolutional Neural Networks (CNN), is proposed to detect seizure onsets in long-term intracranial EEG recordings. Primarily, raw EEG data is filtered with wavelet decomposition. Then, S-transform is used to obtain a proper time-frequency representation of each EEG segment. After that, a 15-layer deep CNN using dropout and batch normalization serves as a robust feature extractor and classifier. Finally, smoothing and collar technique are applied to the outputs of CNN to improve the detection accuracy and reduce the false detection rate (FDR). The segment-based and event-based evaluation assessments and receiver operating characteristic (ROC) curves are employed for the performance evaluation on a public EEG database containing 21 patients. A segment-based sensitivity of 97.01% and a specificity of 98.12% are yielded. For the event-based assessment, this method achieves a sensitivity of 95.45% with an FDR of 0.36/h.","",""
276,"Timothy Niven, Hung-Yu Kao","Probing Neural Network Comprehension of Natural Language Arguments",2019,"","","","",17,"2022-07-13 10:09:41","","10.18653/v1/P19-1459","","",,,,,276,92.00,138,2,3,"We are surprised to find that BERT’s peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.","",""
10,"Justin Cosentino, Federico Zaiter, Dan Pei, Jun Zhu","The Search for Sparse, Robust Neural Networks",2019,"","","","",18,"2022-07-13 10:09:41","","","","",,,,,10,3.33,3,4,3,"Recent work on deep neural network pruning has shown there exist sparse subnetworks that achieve equal or improved accuracy, training time, and loss using fewer network parameters when compared to their dense counterparts. Orthogonal to pruning literature, deep neural networks are known to be susceptible to adversarial examples, which may pose risks in security- or safety-critical applications. Intuition suggests that there is an inherent trade-off between sparsity and robustness such that these characteristics could not co-exist. We perform an extensive empirical evaluation and analysis testing the Lottery Ticket Hypothesis with adversarial training and show this approach enables us to find sparse, robust neural networks. Code for reproducing experiments is available here: this https URL.","",""
26,"James Diffenderfer, B. Kailkhura","Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network",2021,"","","","",19,"2022-07-13 10:09:41","","","","",,,,,26,26.00,13,2,1,"Recently, Frankle & Carbin (2019) demonstrated that randomly-initialized dense networks contain subnetworks that once found can be trained to reach test accuracy comparable to the trained dense network. However, finding these high performing trainable subnetworks is expensive, requiring iterative process of training and pruning weights. In this paper, we propose (and prove) a stronger Multi-Prize Lottery Ticket Hypothesis: A sufficiently over-parameterized neural network with random weights contains several subnetworks (winning tickets) that (a) have comparable accuracy to a dense target network with learned weights (prize 1), (b) do not require any further training to achieve prize 1 (prize 2), and (c) is robust to extreme forms of quantization (i.e., binary weights and/or activation) (prize 3). This provides a new paradigm for learning compact yet highly accurate binary neural networks simply by pruning and quantizing randomly weighted full precision neural networks. We also propose an algorithm for finding multi-prize tickets (MPTs) and test it by performing a series of experiments on CIFAR-10 and ImageNet datasets. Empirical results indicate that as models grow deeper and wider, multi-prize tickets start to reach similar (and sometimes even higher) test accuracy compared to their significantly larger and full-precision counterparts that have been weight-trained. Without ever updating the weight values, our MPTs-1/32 not only set new binary weight network state-of-the-art (SOTA) Top-1 accuracy – 94.8% on CIFAR-10 and 74.03% on ImageNet – but also outperform their full-precision counterparts by 1.78% and 0.76%, respectively. Further, our MPT-1/1 achieves SOTA Top-1 accuracy (91.9%) for binary neural networks on CIFAR-10. Code and pre-trained models are available at: https: //github.com/chrundle/biprop.","",""
25,"Ji Ma, Yue Zhang, Jingbo Zhu","Tagging The Web: Building A Robust Web Tagger with Neural Network",2014,"","","","",20,"2022-07-13 10:09:41","","10.3115/v1/P14-1014","","",,,,,25,3.13,8,3,8,"In this paper, we address the problem of web-domain POS tagging using a twophase approach. The first phase learns representations that capture regularities underlying web text. The representation is integrated as features into a neural network that serves as a scorer for an easy-first POS tagger. Parameters of the neural network are trained using guided learning in the second phase. Experiment on the SANCL 2012 shared task show that our approach achieves 93.15% average tagging accuracy, which is the best accuracy reported so far on this data set, higher than those given by ensembled syntactic parsers.","",""
30,"Yanhui Tu, Jun Du, Yong Xu, Lirong Dai, Chin-Hui Lee","Deep neural network based speech separation for robust speech recognition",2014,"","","","",21,"2022-07-13 10:09:41","","10.1109/ICOSP.2014.7015061","","",,,,,30,3.75,6,5,8,"In this paper, a novel deep neural network (DNN) architecture is proposed to generate the speech features of both the target speaker and interferer for speech separation without using any prior information about the interfering speaker. DNN is adopted here to directly model the highly nonlinear relationship between speech features of the mixed signals and the two competing speakers. Experimental results on a monaural speech separation and recognition challenge task show that the proposed DNN framework enhances the separation performance in terms of different objective measures under the semi-supervised mode where the training data of the target speaker is provided while the unseen interferer in the separation stage is predicted by using multiple interfering speakers mixed with the target speaker in the training stage. Furthermore, as a preprocessing step in the testing stage for robust speech recognition, our speech separation approach can achieve significant improvements of the recognition accuracy over the baseline system with no source separation.","",""
87,"M. Hammad, Yashu Liu, Kuanquan Wang","Multimodal Biometric Authentication Systems Using Convolution Neural Network Based on Different Level Fusion of ECG and Fingerprint",2019,"","","","",22,"2022-07-13 10:09:41","","10.1109/ACCESS.2018.2886573","","",,,,,87,29.00,29,3,3,"A multimodal biometric system integrates information from more than one biometric modality to improve the performance of each individual biometric system and make the system robust to spoof attacks. In this paper, we propose a secure multimodal biometric system that uses convolution neural network (CNN) and Q-Gaussian multi support vector machine (QG-MSVM) based on a different level fusion. We developed two authentication systems with two different level fusion algorithms: a feature level fusion and a decision level fusion. The feature extraction for individual modalities is performed using CNN. In this step, we selected two layers from CNN that achieved the highest accuracy, in which each layer is regarded as separated feature descriptors. After that, we combined them using the proposed internal fusion to generate the biometric templates. In the next step, we applied one of the cancelable biometric techniques to protect these templates and increase the security of the proposed system. In the authentication stage, we applied QG-MSVM as a classifier for authentication to improve the performance. Our systems were tested on several publicly available databases for ECG and fingerprint. The experimental results show that the proposed multimodal systems are efficient, robust, and reliable than existing multimodal authentication systems.","",""
119,"Mahdi Khodayar, Jianhui Wang","Spatio-Temporal Graph Deep Neural Network for Short-Term Wind Speed Forecasting",2019,"","","","",23,"2022-07-13 10:09:41","","10.1109/TSTE.2018.2844102","","",,,,,119,39.67,60,2,3,"Wind speed forecasting is still a challenge due to the stochastic and highly varying characteristics of wind. In this paper, a graph deep learning model is proposed to learn the powerful spatio-temporal features from the wind speed and wind direction data in neighboring wind farms. The underlying wind farms are modeled by an undirected graph, where each node corresponds to a wind site. For each node, temporal features are extracted using a long short-term memory Network. A scalable graph convolutional deep learning architecture (GCDLA), motivated by the localized first-order approximation of spectral graph convolutions, leverages the extracted temporal features to forecast the wind-speed time series of the whole graph nodes. The proposed GCDLA captures spatial wind features as well as deep temporal features of the wind data at each wind site. To further improve the prediction accuracy and capture robust latent representations, the rough set theory is incorporated with the proposed graph deep network by introducing upper and lower bound parameter approximations in the model. Simulation results show the advantages of capturing deep spatial and temporal interval features in the proposed framework compared to the state-of-the-art deep learning models as well as shallow architectures in the recent literature.","",""
50,"Joseph Aylett-Bullock, C. Cuesta-Lázaro, A. Quera-Bofarull","XNet: a convolutional neural network (CNN) implementation for medical x-ray image segmentation suitable for small datasets",2018,"","","","",24,"2022-07-13 10:09:41","","10.1117/12.2512451","","",,,,,50,12.50,17,3,4,"X-Ray image enhancement, along with many other medical image processing applications, requires the segmentation of images into bone, soft tissue, and open beam regions. We apply a machine learning approach to this problem, presenting an end-to-end solution which results in robust and efficient inference. Since medical institutions often do not have the resources to process and label the large quantity of X-Ray images usually needed for neural network training, we design an end-to-end solution for small datasets, while achieving state-of-the-art results. Our implementation produces an overall accuracy of 92%, F1 score of 0.92, and an AUC of 0.98, surpassing classical image processing techniques, such as clustering and entropy based methods, while improving upon the output of existing neural networks used for segmentation in non-medical contexts. The code used for this project is available online.1","",""
2090,"Daniel Maturana, S. Scherer","VoxNet: A 3D Convolutional Neural Network for real-time object recognition",2015,"","","","",25,"2022-07-13 10:09:41","","10.1109/IROS.2015.7353481","","",,,,,2090,298.57,1045,2,7,"Robust object recognition is a crucial skill for robots operating autonomously in real world environments. Range sensors such as LiDAR and RGBD cameras are increasingly found in modern robotic systems, providing a rich source of 3D information that can aid in this task. However, many current systems do not fully utilize this information and have trouble efficiently dealing with large amounts of point cloud data. In this paper, we propose VoxNet, an architecture to tackle this problem by integrating a volumetric Occupancy Grid representation with a supervised 3D Convolutional Neural Network (3D CNN). We evaluate our approach on publicly available benchmarks using LiDAR, RGBD, and CAD data. VoxNet achieves accuracy beyond the state of the art while labeling hundreds of instances per second.","",""
25,"J. X. Chen, Z. Mao, W. Yao, Y. Huang","EEG-based biometric identification with convolutional neural network",2019,"","","","",26,"2022-07-13 10:09:41","","10.1007/s11042-019-7258-4","","",,,,,25,8.33,6,4,3,"","",""
22,"Walt Woods, Jack H Chen, C. Teuscher","Adversarial explanations for understanding image classification decisions and improved neural network robustness",2019,"","","","",27,"2022-07-13 10:09:41","","10.1038/s42256-019-0104-6","","",,,,,22,7.33,7,3,3,"","",""
24,"Ç. Aladag, E. Egrioglu, U. Yolcu","Robust multilayer neural network based on median neuron model",2014,"","","","",28,"2022-07-13 10:09:41","","10.1007/s00521-012-1315-5","","",,,,,24,3.00,8,3,8,"","",""
205,"Kun Yao, John E. Herr, David W Toth, Ryker Mckintyre, John A Parkhill","The TensorMol-0.1 model chemistry: a neural network augmented with long-range physics† †Electronic supplementary information (ESI) available. See DOI: 10.1039/c7sc04934j",2017,"","","","",29,"2022-07-13 10:09:41","","10.1039/c7sc04934j","","",,,,,205,41.00,41,5,5,"We construct a robust chemistry consisting of a nearsighted neural network potential, TensorMol-0.1, with screened long-range electrostatic and van der Waals physics. It is offered in an open-source Python package and achieves millihartree accuracy and a scalability to tens-of-thousands of atoms on ordinary laptops.","",""
78,"Christine Lee, I. Hofer, Eilon Gabel, P. Baldi, M. Cannesson","Development and Validation of a Deep Neural Network Model for Prediction of Postoperative In-hospital Mortality",2018,"","","","",30,"2022-07-13 10:09:41","","10.1097/ALN.0000000000002186","","",,,,,78,19.50,16,5,4,"What We Already Know about This Topic Robust predictions are required to compare perioperative mortality among hospitals Deep neural network systems, a type of machine learning, can be used to develop highly nonlinear prediction models What This Article Tells Us That Is New The authors’ neural network model was comparable in accuracy to, but potentially more efficient at feature selection than logistic regression models Deep neural network–based machine learning provides an alternative to conventional multivariate regression Background: The authors tested the hypothesis that deep neural networks trained on intraoperative features can predict postoperative in-hospital mortality. Methods: The data used to train and validate the algorithm consists of 59,985 patients with 87 features extracted at the end of surgery. Feed-forward networks with a logistic output were trained using stochastic gradient descent with momentum. The deep neural networks were trained on 80% of the data, with 20% reserved for testing. The authors assessed improvement of the deep neural network by adding American Society of Anesthesiologists (ASA) Physical Status Classification and robustness of the deep neural network to a reduced feature set. The networks were then compared to ASA Physical Status, logistic regression, and other published clinical scores including the Surgical Apgar, Preoperative Score to Predict Postoperative Mortality, Risk Quantification Index, and the Risk Stratification Index. Results: In-hospital mortality in the training and test sets were 0.81% and 0.73%. The deep neural network with a reduced feature set and ASA Physical Status classification had the highest area under the receiver operating characteristics curve, 0.91 (95% CI, 0.88 to 0.93). The highest logistic regression area under the curve was found with a reduced feature set and ASA Physical Status (0.90, 95% CI, 0.87 to 0.93). The Risk Stratification Index had the highest area under the receiver operating characteristics curve, at 0.97 (95% CI, 0.94 to 0.99). Conclusions: Deep neural networks can predict in-hospital mortality based on automatically extractable intraoperative data, but are not (yet) superior to existing methods.","",""
69,"M. Lipu, M. Hannan, A. Hussain, M. Saad, A. Ayob, F. Blaabjerg","State of Charge Estimation for Lithium-Ion Battery Using Recurrent NARX Neural Network Model Based Lighting Search Algorithm",2018,"","","","",31,"2022-07-13 10:09:41","","10.1109/ACCESS.2018.2837156","","",,,,,69,17.25,12,6,4,"State of charge (SOC) is one of the crucial parameters in a lithium-ion battery. The accurate estimation of SOC guarantees the safe and efficient operation of a specific application. However, SOC estimation with high accuracy is a serious concern to the automobile engineer due to the battery nonlinear characteristics and complex electrochemical reactions. This paper presents an improved nonlinear autoregressive with exogenous input (NARX)-based neural network (NARXNN) algorithm for an accurate and robust SOC estimation of lithium-ion battery which is effective and computationally rich for controlling dynamic system and predicting time series. However, the accuracy of recurrent NARXNN depends on the amount of input order, output order, and hidden layer neurons. The unique contribution of the improved recurrent NARXNN-based SOC estimation is developed using lighting search algorithm (LSA) for finding the best value of input delays, feedback delays, and hidden layer neurons. The contributions are summarized as: 1) the computational capability of NARXNN model which does not require battery model and parameters rather only needs current, voltage, and temperature sensors; 2) the effectiveness of LSA which is verified with particle swarm optimization; 3) the adaptability, efficiency, and robustness of the model which are evaluated using FUDS and US06 drive cycles at varying temperatures conditions; and 4) the performance of the proposed model which is compared with back propagation neural network and radial basis function neural network optimized by LSA using different error statistical terms and computational time. Furthermore, a comparative analysis of SOC estimation in proposed method and existing techniques is presented for validation of NARXNN performance. The results prove that the proposed NARXNN model achieves higher accuracy with less computational time than other existing SOC algorithms under different temperature conditions and electric vehicle drive cycles.","",""
67,"Chuangjian Cai, Kexin Deng, Cheng Ma, Jianwen Luo","End-to-end deep neural network for optical inversion in quantitative photoacoustic imaging.",2018,"","","","",32,"2022-07-13 10:09:41","","10.1364/OL.43.002752","","",,,,,67,16.75,17,4,4,"An end-to-end deep neural network, ResU-net, is developed for quantitative photoacoustic imaging. A residual learning framework is used to facilitate optimization and to gain better accuracy from considerably increased network depth. The contracting and expanding paths enable ResU-net to extract comprehensive context information from multispectral initial pressure images and, subsequently, to infer a quantitative image of chromophore concentration or oxygen saturation (sO2). According to our numerical experiments, the estimations of sO2 and indocyanine green concentration are accurate and robust against variations in both optical property and object geometry. An extremely short reconstruction time of 22 ms is achieved.","",""
69,"M. Rashid, Muhammad Attique Khan, M. Sharif, M. Raza, M. Sarfraz, Farhat Afza","Object detection and classification: a joint selection and fusion strategy of deep convolutional neural network and SIFT point features",2018,"","","","",33,"2022-07-13 10:09:41","","10.1007/s11042-018-7031-0","","",,,,,69,17.25,12,6,4,"","",""
354,"O. Inan, L. Giovangrandi, G. Kovacs","Robust Neural-Network-Based Classification of Premature Ventricular Contractions Using Wavelet Transform and Timing Interval Features",2006,"","","","",34,"2022-07-13 10:09:41","","10.1109/TBME.2006.880879","","",,,,,354,22.13,118,3,16,"Automatic electrocardiogram (ECG) beat classification is essential to timely diagnosis of dangerous heart conditions. Specifically, accurate detection of premature ventricular contractions (PVCs) is imperative to prepare for the possible onset of life-threatening arrhythmias. Although many groups have developed highly accurate algorithms for detecting PVC beats, results have generally been limited to relatively small data sets. Additionally, many of the highest classification accuracies (>90%) have been achieved in experiments where training and testing sets overlapped significantly. Expanding the overall data set greatly reduces overall accuracy due to significant variation in ECG morphology among different patients. As a result, we believe that morphological information must be coupled with timing information, which is more constant among patients, in order to achieve high classification accuracy for larger data sets. With this approach, we combined wavelet-transformed ECG waves with timing information as our feature set for classification. We used select waveforms of 18 files of the MIT/BIH arrhythmia database, which provides an annotated collection of normal and arrhythmic beats, for training our neural-network classifier. We then tested the classifier on these 18 training files as well as 22 other files from the database. The accuracy was 95.16% over 93,281 beats from all 40 files, and 96.82% over the 22 files outside the training set in differentiating normal, PVC, and other beats","",""
23,"Brian Q Geuther, S. Deats, Kai J Fox, S. Murray, R. Braun, Jacqueline K. White, E. Chesler, C. Lutz, Vivek Kumar","Robust mouse tracking in complex environments using neural networks",2019,"","","","",35,"2022-07-13 10:09:41","","10.1038/s42003-019-0362-1","","",,,,,23,7.67,3,9,3,"","",""
49,"Shiba Kuanar, V. Athitsos, N. Pradhan, A. Mishra, K. Rao","Cognitive Analysis of Working Memory Load from Eeg, by a Deep Recurrent Neural Network",2018,"","","","",36,"2022-07-13 10:09:41","","10.1109/ICASSP.2018.8462243","","",,,,,49,12.25,10,5,4,"One of the common modalities for observing mental activity is electroencephalogram (EEG) signals. However, EEG recording is highly susceptible to various sources of noise and to inter subject differences. In order to solve these problems we present a deep recurrent neural network (RNN) architecture to learn robust features and predict the levels of cognitive load from EEG recordings. Using a deep learning approach, we first transform the EEG time series into a sequence of multispectral images which carries spatial information. Next, we train our recurrent hybrid network to learn robust representations from the sequence of frames. The proposed approach preserves spectral, spatial and temporal structures and extracts features which are less sensitive to variations along each dimension. Our results demonstrate cognitive memory load prediction across four different levels with an overall accuracy of 92.5% during the memory task execution and reduce classification error to 7.61% in comparison to other state-of-art techniques.","",""
41,"Andrew J. Dunnings, T. Breckon","Experimentally Defined Convolutional Neural Network Architecture Variants for Non-Temporal Real-Time Fire Detection",2018,"","","","",37,"2022-07-13 10:09:41","","10.1109/ICIP.2018.8451657","","",,,,,41,10.25,21,2,4,"In this work we investigate the automatic detection of fire pixel regions in video (or still) imagery within real-time bounds without reliance on temporal scene information. As an extension to prior work in the field, we consider the performance of experimentally defined, reduced complexity deep convolutional neural network architectures for this task. Contrary to contemporary trends in the field, our work illustrates maximal accuracy of 0.93 for whole image binary fire detection, with 0.89 accuracy within our superpixel localization framework can be achieved, via a network architecture of signficantly reduced complexity. These reduced architectures additionally offer a 3–4 fold increase in computational performance offering up to 17 fps processing on contemporary hardware independent of temporal information. We show the relative performance achieved against prior work using benchmark datasets to illustrate maximally robust real-time fire region detection.","",""
21,"Vikash Sehwag, Shiqi Wang, Prateek Mittal, S. Jana","Towards Compact and Robust Deep Neural Networks",2019,"","","","",38,"2022-07-13 10:09:41","","","","",,,,,21,7.00,5,4,3,"Deep neural networks have achieved impressive performance in many applications but their large number of parameters lead to significant computational and storage overheads. Several recent works attempt to mitigate these overheads by designing compact networks using pruning of connections. However, we observe that most of the existing strategies to design compact networks fail to preserve network robustness against adversarial examples. In this work, we rigorously study the extension of network pruning strategies to preserve both benign accuracy and robustness of a network. Starting with a formal definition of the pruning procedure, including pre-training, weights pruning, and fine-tuning, we propose a new pruning method that can create compact networks while preserving both benign accuracy and robustness. Our method is based on two main insights: (1) we ensure that the training objectives of the pre-training and fine-tuning steps match the training objective of the desired robust model (e.g., adversarial robustness/verifiable robustness), and (2) we keep the pruning strategy agnostic to pre-training and fine-tuning objectives. We evaluate our method on four different networks on the CIFAR-10 dataset and measure benign accuracy, empirical robust accuracy, and verifiable robust accuracy. We demonstrate that our pruning method can preserve on average 93\% benign accuracy, 92.5\% empirical robust accuracy, and 85.0\% verifiable robust accuracy while compressing the tested network by 10$\times$.","",""
57,"B. Baheti, S. Gajre, S. Talbar","Detection of Distracted Driver Using Convolutional Neural Network",2018,"","","","",39,"2022-07-13 10:09:41","","10.1109/CVPRW.2018.00150","","",,,,,57,14.25,19,3,4,"Number of road accidents is continuously increasing in last few years worldwide. As per the survey of National Highway Traffic Safety Administrator, nearly one in five motor vehicle crashes are caused by distracted driver. We attempt to develop an accurate and robust system for detecting distracted driver and warn him against it. Motivated by the performance of Convolutional Neural Networks in computer vision, we present a CNN based system that not only detects the distracted driver but also identifies the cause of distraction. VGG-16 architecture is modified for this particular task and various regularization techniques are implied in order to improve the performance. Experimental results show that our system outperforms earlier methods in literature achieving an accuracy of 96.31% and processes 42 images per second on GPU. We also study the effect of dropout, L2 regularization and batch normalisation on the performance of the system. Next, we present a modified version of our architecture that achieves 95.54% classification accuracy with the number of parameters reduced from 140M in original VGG-16 to 15M only.","",""
35,"Jianwei Chen, Kezhi Li, P. Herrero, Taiyu Zhu, P. Georgiou","Dilated Recurrent Neural Network for Short-time Prediction of Glucose Concentration",2018,"","","","",40,"2022-07-13 10:09:41","","","","",,,,,35,8.75,7,5,4,"Diabetes is one of the diseases affecting 415 million people in the world. Developing a robust blood glucose (BG) prediction model has a profound influence especially important for the diabetes management. Subjects with diabetes need to adjust insulin doses according to the blood glucose levels to maintain blood glucose in a target range. An accurate glucose level prediction is able to provide subjects with diabetes with the future glucose levels, so that proper actions could be taken to avoid shortterm dangerous consequences or long-term complications. With the developing of continuous glucose monitoring (CGM) systems, the accuracy of predicting the glucose levels can be improved using the machine learning techniques. In this paper, a new deep learning technique, which is based on the Dilated Recurrent Neural Network (DRNN) model, is proposed to predict the future glucose levels for prediction horizon (PH) of 30 minutes. And the method also can be implemented in real-time prediction as well. The result reveals that using the dilated connection in the RNN network, it can improve the accuracy of short-time glucose predictions significantly (RMSE = 19.04 in the blood glucose level prediction (BGLP) on and only on all data points provided).","",""
94,"H. Hong, Min Beom Lee, K. Park","Convolutional Neural Network-Based Finger-Vein Recognition Using NIR Image Sensors",2017,"","","","",41,"2022-07-13 10:09:41","","10.3390/s17061297","","",,,,,94,18.80,31,3,5,"Conventional finger-vein recognition systems perform recognition based on the finger-vein lines extracted from the input images or image enhancement, and texture feature extraction from the finger-vein images. In these cases, however, the inaccurate detection of finger-vein lines lowers the recognition accuracy. In the case of texture feature extraction, the developer must experimentally decide on a form of the optimal filter for extraction considering the characteristics of the image database. To address this problem, this research proposes a finger-vein recognition method that is robust to various database types and environmental changes based on the convolutional neural network (CNN). In the experiments using the two finger-vein databases constructed in this research and the SDUMLA-HMT finger-vein database, which is an open database, the method proposed in this research showed a better performance compared to the conventional methods.","",""
30,"Nauman Munir, H. Kim, Sung-Jin Song, Sung-Sik Kang","Investigation of deep neural network with drop out for ultrasonic flaw classification in weldments",2018,"","","","",42,"2022-07-13 10:09:41","","10.1007/S12206-018-0610-1","","",,,,,30,7.50,8,4,4,"","",""
112,"P. Asteris, P. Roussis, M. Douvika","Feed-Forward Neural Network Prediction of the Mechanical Properties of Sandcrete Materials",2017,"","","","",43,"2022-07-13 10:09:41","","10.3390/s17061344","","",,,,,112,22.40,37,3,5,"This work presents a soft-sensor approach for estimating critical mechanical properties of sandcrete materials. Feed-forward (FF) artificial neural network (ANN) models are employed for building soft-sensors able to predict the 28-day compressive strength and the modulus of elasticity of sandcrete materials. To this end, a new normalization technique for the pre-processing of data is proposed. The comparison of the derived results with the available experimental data demonstrates the capability of FF ANNs to predict with pinpoint accuracy the mechanical properties of sandcrete materials. Furthermore, the proposed normalization technique has been proven effective and robust compared to other normalization techniques available in the literature.","",""
17,"R. Bettocchi, M. Pinelli, P. R. Spina, M. Venturini, M. Burgio","Set Up of a Robust Neural Network for Gas Turbine Simulation",2004,"","","","",44,"2022-07-13 10:09:41","","10.1115/GT2004-53421","","",,,,,17,0.94,3,5,18,"In this paper, Neural Network (NN) models for the real-time simulation of gas turbines are studied and developed. The analyses carried out are aimed at the selection of the most appropriate NN structure for gas turbine simulation, in terms of both computational time of the NN training phase and accuracy and robustness with respect to measurement uncertainty. In particular, feed-forward NNs, with a single hidden layer and different numbers of neurons, trained by using a back-propagation learning algorithm are considered and tested. Finally, a general procedure for the validation of computational codes is adapted and applied to the validation of the developed NN models.© 2004 ASME","",""
50,"S. Ben Driss, M. Soua, R. Kachouri, M. Akil","A comparison study between MLP and convolutional neural network models for character recognition",2017,"","","","",45,"2022-07-13 10:09:41","","10.1117/12.2262589","","",,,,,50,10.00,13,4,5,"Optical Character Recognition (OCR) systems have been designed to operate on text contained in scanned documents and images. They include text detection and character recognition in which characters are described then classified. In the classification step, characters are identified according to their features or template descriptions. Then, a given classifier is employed to identify characters. In this context, we have proposed the unified character descriptor (UCD) to represent characters based on their features. Then, matching was employed to ensure the classification. This recognition scheme performs a good OCR Accuracy on homogeneous scanned documents, however it cannot discriminate characters with high font variation and distortion.3 To improve recognition, classifiers based on neural networks can be used. The multilayer perceptron (MLP) ensures high recognition accuracy when performing a robust training. Moreover, the convolutional neural network (CNN), is gaining nowadays a lot of popularity for its high performance. Furthermore, both CNN and MLP may suffer from the large amount of computation in the training phase. In this paper, we establish a comparison between MLP and CNN. We provide MLP with the UCD descriptor and the appropriate network configuration. For CNN, we employ the convolutional network designed for handwritten and machine-printed character recognition (Lenet-5) and we adapt it to support 62 classes, including both digits and characters. In addition, GPU parallelization is studied to speed up both of MLP and CNN classifiers. Based on our experimentations, we demonstrate that the used real-time CNN is 2x more relevant than MLP when classifying characters.","",""
10,"P. Marino, M. Milano, F. Vasca","Robust neural network observer for induction motor control",1997,"","","","",46,"2022-07-13 10:09:41","","10.1109/PESC.1997.616797","","",,,,,10,0.40,3,3,25,"A neural network observer for induction motor state estimation, which is robust with respect to parameter variations is presented. Robustness is obtained using a suitable training set based on a stochastic model of the motor obtained by the Price algorithm. This algorithm is used to obtain the confidence ellipsoid for the model parameters, which are then modeled as Gaussian random variables strictly contained in the ellipsoid. Simulation results show that the resulting neural observer provides a good trade off between estimates accuracy and robustness.","",""
55,"O. Meneghini, Sterling P. Smith, P. Snyder, G. Staebler, J. Candy, E. Belli, L. Lao, M. Kostuk, T. Luce, T. Luda, J. M. Park, F. Poli","Self-consistent core-pedestal transport simulations with neural network accelerated models",2017,"","","","",47,"2022-07-13 10:09:41","","10.1088/1741-4326/AA7776","","",,,,,55,11.00,6,12,5,"Fusion whole device modeling simulations require comprehensive models that are simultaneously physically accurate, fast, robust, and predictive. In this paper we describe the development of two neural-network (NN) based models as a means to perform a snon-linear multivariate regression of theory-based models for the core turbulent transport fluxes, and the pedestal structure. Specifically, we find that a NN-based approach can be used to consistently reproduce the results of the TGLF and EPED1 theory-based models over a broad range of plasma regimes, and with a computational speedup of several orders of magnitudes. These models are then integrated into a predictive workflow that allows prediction with self-consistent core-pedestal coupling of the kinetic profiles within the last closed flux surface of the plasma. The NN paradigm is capable of breaking the speed-accuracy trade-off that is expected of traditional numerical physics models, and can provide the missing link towards self-consistent coupled core-pedestal whole device modeling simulations that are physically accurate and yet take only seconds to run.","",""
37,"Rundong Li, Lizhong Li, Shuyuan Yang, Shaoqian Li","Robust Automated VHF Modulation Recognition Based on Deep Convolutional Neural Networks",2018,"","","","",48,"2022-07-13 10:09:41","","10.1109/LCOMM.2018.2809732","","",,,,,37,9.25,9,4,4,"This letter proposes a novel modulation recognition algorithm for very high frequency (VHF) radio signals, which is based on antinoise processing and deep sparse-filtering convolutional neural network (AN-SF-CNN). First, the cyclic spectra of modulated signals are calculated, and then, low-rank representation is performed on cyclic spectra to reduce disturbances existed in VHF radio signals. After that, before fine tuning the CNN, we propose a sparse-filtering criterion to unsupervised pretrain the network layer-by-layer, which improves generalization effectively. Several experiments are taken on seven kinds of modulated signals, and the simulation results show that, compared with the traditional methods and some renowned deep learning methods, the proposed method can achieve higher or equivalent classification accuracy, and presents robustness against noises.","",""
37,"Pyong-Kun Kim, Kil-Taek Lim","Vehicle Type Classification Using Bagging and Convolutional Neural Network on Multi View Surveillance Image",2017,"","","","",49,"2022-07-13 10:09:41","","10.1109/CVPRW.2017.126","","",,,,,37,7.40,19,2,5,"This paper aims to introduce a new vehicle type classification scheme on the images from multi-view surveillance camera. We propose four concepts to increase the performance on the images which have various resolutions from multi-view point. The Deep Learning method is essential to multi-view point image, bagging method makes system robust, data augmentation help to grow the classification capability, and post-processing compensate for imbalanced data. We combine these schemes and build a novel vehicle type classification system. Our system shows 97.84% classification accuracy on the 103,833 images in classification challenge dataset.","",""
15,"Tianyu Guo, Chang Xu, Shiyi He, Boxin Shi, Chao Xu, D. Tao","Robust Student Network Learning",2018,"","","","",50,"2022-07-13 10:09:41","","10.1109/TNNLS.2019.2929114","","",,,,,15,3.75,3,6,4,"Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher–student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.","",""
71,"Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew M. Dai, Dustin Tran","Training independent subnetworks for robust prediction",2020,"","","","",51,"2022-07-13 10:09:41","","","","",,,,,71,35.50,9,8,2,"Recent approaches to efficiently ensemble neural networks have shown that strong robustness and uncertainty performance can be achieved with a negligible gain in parameters over the original network. However, these methods still require multiple forward passes for prediction, leading to a significant computational cost. In this work, we show a surprising result: the benefits of using multiple predictions can be achieved `for free' under a single model's forward pass. In particular, we show that, using a multi-input multi-output (MIMO) configuration, one can utilize a single model's capacity to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the subnetworks, we improve model robustness without increasing compute. We observe a significant improvement in negative log-likelihood, accuracy, and calibration error on CIFAR10, CIFAR100, ImageNet, and their out-of-distribution variants compared to previous methods.","",""
31,"H. F. Zhang, Li Hao Wang, Jingyi Yin, Peng-Hui Chen, Hong-Fei Zhang","Performance of the Levenberg–Marquardt neural network approach in nuclear mass prediction",2017,"","","","",52,"2022-07-13 10:09:41","","10.1088/1361-6471/AA5D78","","",,,,,31,6.20,6,5,5,"Resorting to a neural network approach we refined several representative and sophisticated global nuclear mass models within the latest atomic mass evaluation (AME2012). In the training process, a quite robust algorithm named the Levenberg–Marquardt (LM) method is employed to determine the weights and biases of the neural network. As a result, this LM neural network approach demonstrates a very useful tool for further improving the accuracy of mass models. For a simple liquid drop formula the root mean square (rms) deviation between the predictions and the 2353 experimental known masses are sharply reduced from 2.455 MeV to 0.235 MeV, and for the other revisited mass models, the rms is remarkably improved by about 30%.","",""
25,"K. Islam, R. G. Raj, G. Mujtaba","Recognition of Traffic Sign Based on Bag-of-Words and Artificial Neural Network",2017,"","","","",53,"2022-07-13 10:09:41","","10.3390/SYM9080138","","",,,,,25,5.00,8,3,5,"The traffic sign recognition system is a support system that can be useful to give notification and warning to drivers. It may be effective for traffic conditions on the current road traffic system. A robust artificial intelligence based traffic sign recognition system can support the driver and significantly reduce driving risk and injury. It performs by recognizing and interpreting various traffic sign using vision-based information. This study aims to recognize the well-maintained, un-maintained, standard, and non-standard traffic signs using the Bag-of-Words and the Artificial Neural Network techniques. This research work employs a Bag-of-Words model on the Speeded Up Robust Features descriptors of the road traffic signs. A robust classifier Artificial Neural Network has been employed to recognize the traffic sign in its respective class. The proposed system has been trained and tested to determine the suitable neural network architecture. The experimental results showed high accuracy of classification of traffic signs including complex background images. The proposed traffic sign detection and recognition system obtained 99.00% classification accuracy with a 1.00% false positive rate. For real-time implementation and deployment, this marginal false positive rate may increase reliability and stability of the proposed system.","",""
84,"S. Radzi, M. Khalil-Hani, R. Bakhteri","Finger-vein biometric identification using convolutional neural network",2016,"","","","",54,"2022-07-13 10:09:41","","10.3906/ELK-1311-43","","",,,,,84,14.00,28,3,6,"A novel approach using a convolutional neural network (CNN) for finger-vein biometric identification is presented in this paper. Unlike existing biometric techniques such as fingerprint and face, vein patterns are inside the body, making them virtually impossible to replicate. This also makes finger-vein biometrics a more secure alternative without being susceptible to forgery, damage, or change with time. In conventional finger-vein recognition methods, complex image processing is required to remove noise and extract and enhance the features before the image classification can be performed in order to achieve high performance accuracy. In this regard, a significant advantage of the CNN over conventional approaches is its ability to simultaneously extract features, reduce data dimensionality, and classify in one network structure. In addition, the method requires only minimal image preprocessing since the CNN is robust to noise and small misalignments of the acquired images. In this paper, a reduced-complexity four-layer CNN with fused convolutional-subsampling architecture is proposed for finger-vein recognition. For network training, we have modified and applied the stochastic diagonal Levenberg{Marquardt algorithm, which results in a faster convergence time. The proposed CNN is tested on a finger-vein database developed in-house that contains 50 subjects with 10 samples from each finger. An identification rate of 100.00% is achieved, with an 80/20 percent ratio for separation of training and test samples, respectively. An additional number of subjects have also been tested, in which for 81 subjects an accuracy of 99.38% is achieved.","",""
37,"Paul-Edouard Sarlin, Ajaykumar Unagar, Maans Larsson, Hugo Germain, Carl Toft, Viktor Larsson, M. Pollefeys, V. Lepetit, L. Hammarstrand, F. Kahl, Torsten Sattler","Back to the Feature: Learning Robust Camera Localization from Pixels to Pose",2021,"","","","",55,"2022-07-13 10:09:41","","10.1109/CVPR46437.2021.00326","","",,,,,37,37.00,4,11,1,"Camera pose estimation in known scenes is a 3D geometry task recently tackled by multiple learning algorithms. Many regress precise geometric quantities, like poses or 3D points, from an input image. This either fails to generalize to new viewpoints or ties the model parameters to a specific scene. In this paper, we go Back to the Feature: we argue that deep networks should focus on learning robust and invariant visual features, while the geometric estimation should be left to principled algorithms. We introduce PixLoc, a scene-agnostic neural network that estimates an accurate 6-DoF pose from an image and a 3D model. Our approach is based on the direct alignment of multiscale deep features, casting camera localization as metric learning. PixLoc learns strong data priors by end-to-end training from pixels to pose and exhibits exceptional generalization to new scenes by separating model parameters and scene geometry. The system can localize in large environments given coarse pose priors but also improve the accuracy of sparse feature matching by jointly refining keypoints and poses with little overhead. The code will be publicly available at github.com/cvg/pixloc.","",""
21,"N. E. Khalifa, Mohamed Hamed Taha, A. Hassanien, I. Selim","Deep Galaxy V2: Robust Deep Convolutional Neural Networks for Galaxy Morphology Classifications",2018,"","","","",56,"2022-07-13 10:09:41","","10.1109/ICCSE1.2018.8374210","","",,,,,21,5.25,5,4,4,"This paper is an extended version of ""Deep Galaxy: Classification of Galaxies based on Deep Convolutional Neural Networks"". In this paper, a robust deep convolutional neural network architecture for galaxy morphology classification is presented. A galaxy can be classified based on its features into one of three categories (Elliptical, Spiral, or Irregular) according to the Hubble galaxy morphology classification from 1926. The proposed convolutional neural network architecture consists of 8 layers, including one main convolutional layer for feature ex-traction with 96 filters and two principle fully connected layers for classification. The architecture is trained over 4238 images and achieved a 97.772% testing accuracy. In this version, ""Deep Galaxy V2"", an augmentation process is applied to the training data to overcome the overfitting problem and make the proposed architecture more robust and immune to memorizing the training data. A comparative result is present, and the testing accuracy was compared with those of other related works. The proposed architecture outperformed the other related works in terms of its testing accuracy.","",""
15,"B. Sengupta, Karl J. Friston","How Robust are Deep Neural Networks?",2018,"","","","",57,"2022-07-13 10:09:41","","","","",,,,,15,3.75,8,2,4,"Convolutional and Recurrent, deep neural networks have been successful in machine learning systems for computer vision, reinforcement learning, and other allied fields. However, the robustness of such neural networks is seldom apprised, especially after high classification accuracy has been attained. In this paper, we evaluate the robustness of three recurrent neural networks to tiny perturbations, on three widely used datasets, to argue that high accuracy does not always mean a stable and a robust (to bounded perturbations, adversarial attacks, etc.) system. Especially, normalizing the spectrum of the discrete recurrent network to bound the spectrum (using power method, Rayleigh quotient, etc.) on a unit disk produces stable, albeit highly non-robust neural networks. Furthermore, using the $\epsilon$-pseudo-spectrum, we show that training of recurrent networks, say using gradient-based methods, often result in non-normal matrices that may or may not be diagonalizable. Therefore, the open problem lies in constructing methods that optimize not only for accuracy but also for the stability and the robustness of the underlying neural network, a criterion that is distinct from the other.","",""
53,"Saeid Shakeri, A. Ghassemi, M. Hassani, A. Hajian","Investigation of material removal rate and surface roughness in wire electrical discharge machining process for cementation alloy steel using artificial neural network",2016,"","","","",58,"2022-07-13 10:09:41","","10.1007/S00170-015-7349-Y","","",,,,,53,8.83,13,4,6,"","",""
55,"Jiandan Zhong, Tao Lei, Guangle Yao","Robust Vehicle Detection in Aerial Images Based on Cascaded Convolutional Neural Networks",2017,"","","","",59,"2022-07-13 10:09:41","","10.3390/s17122720","","",,,,,55,11.00,18,3,5,"Vehicle detection in aerial images is an important and challenging task. Traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. Recently, with the great success of convolutional neural networks (CNNs) in computer vision, many state-of-the-art detectors have been designed based on deep CNNs. However, these CNN-based detectors are inefficient when applied in aerial image data due to the fact that the existing CNN-based models struggle with small-size object detection and precise localization. To improve the detection accuracy without decreasing speed, we propose a CNN-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. Because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. Then, the generated candidate regions are fed into the second network for feature extraction and decision making. Comprehensive experiments are conducted on the Vehicle Detection in Aerial Imagery (VEDAI) dataset and Munich vehicle dataset. The proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.","",""
35,"Guiguang Ding, Yuchen Guo, Kai Chen, Chaoqun Chu, J. Han, Qionghai Dai","DECODE: Deep Confidence Network for Robust Image Classification",2019,"","","","",60,"2022-07-13 10:09:41","","10.1109/TIP.2019.2902115","","",,,,,35,11.67,6,6,3,"Recent years have witnessed the success of deep convolutional neural networks for image classification and many related tasks. It should be pointed out that the existing training strategies assume that there is a clean dataset for model learning. In elaborately constructed benchmark datasets, deep network has yielded promising performance under the assumption. However, in real-world applications, it is burdensome and expensive to collect sufficient clean training samples. On the other hand, collecting noisy labeled samples is very economical and practical, especially with the rapidly increasing amount of visual data in the web. Unfortunately, the accuracy of current deep models may drop dramatically even with 5%–10% label noise. Therefore, enabling label noise resistant classification has become a crucial issue in the data driven deep learning approaches. In this paper, we propose a DEep COnfiDEnce network (DECODE) to address this issue. In particular, based on the distribution of mislabeled data, we adopt a confidence evaluation module that is able to determine the confidence that a sample is mislabeled. With the confidence, we further use a weighting strategy to assign different weights to different samples so that the model pays less attention to low confidence data, which is more likely to be noise. In this way, the deep model is more robust to label noise. DECODE is designed to be general, such that it can be easily combined with existing studies. We conduct extensive experiments on several datasets, and the results validate that DECODE can improve the accuracy of deep models trained with noisy data.","",""
63,"F. Chapotot, G. Becq","Automated sleep–wake staging combining robust feature extraction, artificial neural network classification, and flexible decision rules",2009,"","","","",61,"2022-07-13 10:09:41","","10.1002/ACS.1147","","",,,,,63,4.85,32,2,13,"The classification of sleep–wake stages suffers from poor standardization in scoring criteria and heterogeneous conditioning of polysomnographic signals. To improve applicability of fully automated sleep staging, we have designed a formal classification framework to rigorously (1) select robust candidate features, (2) emulate artificial neural network classifiers, and (3) assign sleep–wake stages using flexible decision rules. An extensive database of 48 PSG records scored in 20 s epochs by two independent clinicians was used. A small subset of 2 s elementary epochs representative of each stages with unequivocal expert scores was selected to form a limited set of learning exemplars. From 16 statistical, spectral and non‐linear candidate features extracted in 2 s epochs from EEG and EMG signals, a sequential forward search selected an optimal set of five features with a 22% error rate. Multiple layer perceptrons were trained from this optimal feature set while classification accuracy was assessed using the unequivocal instance subset. A simple majority vote among 10 consecutive classifier outputs ensured a final scoring resolution comparable to that of the experts. Poor classification performance was obtained for movement time, wakefulness, and intermediate sleep stages with a 36±15% error rate (Cohen's kappa 0.48±0.18). In contrast, deep and paradoxical sleep was classified with an 82% accuracy not far from inter‐expert expert agreement (83±3%). Significant improvements should be expected using a larger learning set compensating for a high inter‐individual variability, and decision rules incorporating more domain‐knowledge. Copyright © 2009 John Wiley & Sons, Ltd.","",""
58,"S. Naz, A. I. Umar, Riaz Ahmad, S. Ahmed, S. H. Shirazi, M. I. Razzak","Urdu Nasta’liq text recognition system based on multi-dimensional recurrent neural network and statistical features",2017,"","","","",62,"2022-07-13 10:09:41","","10.1007/s00521-015-2051-4","","",,,,,58,11.60,10,6,5,"","",""
96,"Huy Phan, L. Hertel, M. Maass, A. Mertins","Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks",2016,"","","","",63,"2022-07-13 10:09:41","","10.21437/Interspeech.2016-123","","",,,,,96,16.00,24,4,6,"We present in this paper a simple, yet efficient convolutional neural network (CNN) architecture for robust audio event recognition. Opposing to deep CNN architectures with multiple convolutional and pooling layers topped up with multiple fully connected layers, the proposed network consists of only three layers: convolutional, pooling, and softmax layer. Two further features distinguish it from the deep architectures that have been proposed for the task: varying-size convolutional filters at the convolutional layer and 1-max pooling scheme at the pooling layer. In intuition, the network tends to select the most discriminative features from the whole audio signals for recognition. Our proposed CNN not only shows state-of-the-art performance on the standard task of robust audio event recognition but also outperforms other deep architectures up to 4.5% in terms of recognition accuracy, which is equivalent to 76.3% relative error reduction.","",""
59,"Vijay John, Keisuke Yoneda, Zheng Liu, S. Mita","Saliency Map Generation by the Convolutional Neural Network for Real-Time Traffic Light Detection Using Template Matching",2015,"","","","",64,"2022-07-13 10:09:41","","10.1109/TCI.2015.2480006","","",,,,,59,8.43,15,4,7,"A critical issue in autonomous vehicle navigation and advanced driver assistance systems (ADAS) is the accurate real-time detection of traffic lights. Typically, vision-based sensors are used to detect the traffic light. However, the detection of traffic lights using computer vision, image processing, and learning algorithms is not trivial. The challenges include appearance variations, illumination variations, and reduced appearance information in low illumination conditions. To address these challenges, we present a visual camera-based real-time traffic light detection algorithm, where we identify the spatially constrained region-of-interest in the image containing the traffic light. Given, the identified region-of-interest, we achieve high traffic light detection accuracy with few false positives, even in adverse environments. To perform robust traffic light detection in varying conditions with few false positives, the proposed algorithm consists of two steps, an offline saliency map generation and a real-time traffic light detection. In the offline step, a convolutional neural network, i.e., a deep learning framework, detects and recognizes the traffic lights in the image using region-of-interest information provided by an onboard GPS sensor. The detected traffic light information is then used to generate the saliency maps with a modified multidimensional density-based spatial clustering of applications with noise (M-DBSCAN) algorithm. The generated saliency maps are indexed using the vehicle GPS information. In the real-time step, traffic lights are detected by retrieving relevant saliency maps and performing template matching by using colour information. The proposed algorithm is validated with the datasets acquired in varying conditions and different countries, e.g., USA, Japan, and France. The experimental results report a high detection accuracy with negligible false positives under varied illumination conditions. More importantly, an average computational time of 10 ms/frame is achieved. A detailed parameter analysis is conducted and the observations are summarized and reported in this paper.","",""
194,"Bo-Kyeong Kim, Jihyeon Roh, Suh-Yeon Dong, Soo-Young Lee","Hierarchical committee of deep convolutional neural networks for robust facial expression recognition",2016,"","","","",65,"2022-07-13 10:09:41","","10.1007/s12193-015-0209-0","","",,,,,194,32.33,49,4,6,"","",""
447,"S. Ghosh-Dastidar, H. Adeli, N. Dadmehr","Principal Component Analysis-Enhanced Cosine Radial Basis Function Neural Network for Robust Epilepsy and Seizure Detection",2008,"","","","",66,"2022-07-13 10:09:41","","10.1109/TBME.2007.905490","","",,,,,447,31.93,149,3,14,"A novel principal component analysis (PCA)-enhanced cosine radial basis function neural network classifier is presented. The two-stage classifier is integrated with the mixed-band wavelet-chaos methodology, developed earlier by the authors, for accurate and robust classification of electroencephalogram (EEGs) into healthy, ictal, and interictal EEGs. A nine-parameter mixed-band feature space discovered in previous research for effective EEG representation is used as input to the two-stage classifier. In the first stage, PCA is employed for feature enhancement. The rearrangement of the input space along the principal components of the data improves the classification accuracy of the cosine radial basis function neural network (RBFNN) employed in the second stage significantly. The classification accuracy and robustness of the classifier are validated by extensive parametric and sensitivity analysis. The new wavelet-chaos-neural network methodology yields high EEG classification accuracy (96.6%) and is quite robust to changes in training data with a low standard deviation of 1.4%. For epilepsy diagnosis, when only normal and interictal EEGs are considered, the classification accuracy of the proposed model is 99.3%. This statistic is especially remarkable because even the most highly trained neurologists do not appear to be able to detect interictal EEGs more than 80% of the times.","",""
118,"S. Anbazhagan, N. Kumarappan","Day-Ahead Deregulated Electricity Market Price Forecasting Using Recurrent Neural Network",2013,"","","","",67,"2022-07-13 10:09:41","","10.1109/JSYST.2012.2225733","","",,,,,118,13.11,59,2,9,"This paper proposes a recurrent neural network model for the day ahead deregulated electricity market price forecasting that could be realized using the Elman network. In a deregulated market, electricity price is influenced by many factors and exhibits a very complicated and irregular fluctuation. Both power producers and consumers need a single compact and robust price forecasting tool for maximizing their profits and utilities. In order to validate the chaotic characteristic of electricity price, an Elman network is modeled. The proposed Elman network is a single compact and robust architecture (without hybridizing the various hard and soft computing models). It has been observed that a nearly state of the art Elman network forecasting accuracy can be achieved with less computation time. The proposed Elman network approach is compared with autoregressive integrated moving average (ARIMA), mixed model, neural network, wavelet ARIMA, weighted nearest neighbors, fuzzy neural network, hybrid intelligent system, adaptive wavelet neural network, neural networks with wavelet transform, wavelet transform and a hybrid of neural networks and fuzzy logic, wavelet-ARIMA radial basis function neural networks, cascaded neuro-evolutionary algorithm, and wavelet transform, particle swarm optimization, and adaptive-network-based fuzzy inference system approaches to forecast the electricity market of mainland Spain. Finally, the accuracy of the price forecasting is also applied to the electricity market of New York in 2010, which shows the effectiveness of the proposed approach.","",""
30,"Junjie Chen, Songling Huang, Wei Zhao","Three-dimensional defect inversion from magnetic flux leakage signals using iterative neural network",2015,"","","","",68,"2022-07-13 10:09:41","","10.1049/IET-SMT.2014.0173","","",,,,,30,4.29,10,3,7,"Defect inversion is of special interest to magnetic flux leakage (MFL) inspection in industry. This study proposes an iterative neural network to reconstruct three-dimensional defect profiles from three-axial MFL signals in pipeline inspection. A radial basis function neural network is utilised as the forward model to predict the MFL signals given a defect profile, and the defect profile gets updated based on a combination of gradient descent and simulated annealing in the iterative inversion procedure. Accuracy of the proposed inversion procedure is demonstrated in estimating the profile of different defects in steel pipes. Experimental result based on three-axial simulated MFL data also shows that the proposed inversion approach is robust even in presence of reasonable noise.","",""
29,"A. Rebhi, Issam Benmhammed, S. Abid, F. Fnaiech","Fabric Defect Detection Using Local Homogeneity Analysis and Neural Network",2015,"","","","",69,"2022-07-13 10:09:41","","10.1155/2015/376163","","",,,,,29,4.14,7,4,7,"In the textile manufacturing industry, fabric defect detection becomes a necessary and essential step in quality control. The investment in this field is more than economical when reduction in labor cost and associated benefits are considered. Moreover, the development of a wholly automated inspection system requires efficient and robust algorithms. To overcome this problem, in this paper, we present a new fabric defect detection scheme which uses the local homogeneity and neural network. Its first step consists in computing a new homogeneity image denoted as -image. The second step is devoted to the application of the discrete cosine transform (DCT) to the -image and the extraction of different representative energy features of each DCT block. These energy features are used by the back-propagation neural network to judge the existence of fabric defect. Simulations on different fabric images and different defect aspects show that the proposed method achieves an average accuracy of 97.35%.","",""
40,"Qiang Cheng, Zhuo Qi, Guojun Zhang, Yongsheng Zhao, Bingwei Sun, P. Gu","Robust modelling and prediction of thermally induced positional error based on grey rough set theory and neural networks",2016,"","","","",70,"2022-07-13 10:09:41","","10.1007/S00170-015-7556-6","","",,,,,40,6.67,7,6,6,"","",""
40,"A. R. Syafeeza, M. Khalil-Hani, Shan Sung Liew, R. Bakhteri","Convolutional Neural Network for Face Recognition with Pose and Illumination Variation",2014,"","","","",71,"2022-07-13 10:09:41","","","","",,,,,40,5.00,10,4,8,"Face recognition remains a challenging problem till today. The main challenge is how to improve the recognition performance when affected by the variability of non-linear effects that include illumination variances, poses, facial expressions, occlusions, etc. In this paper, a robust 4-layer Convolutional Neural Network (CNN) architecture is proposed for the face recognition problem, with a solution that is capable of handling facial images that contain occlusions, poses, facial expressions and varying illumination. Experimental results show that the proposed CNN solution outperforms existing works, achieving 99.5% recognition accuracy on AR database. The test on the 35-subjects of FERET database achieves an accuracy of 85.13%, which is in the similar range of performance as the best result of previous works. More significantly, our proposed system completes the facial recognition process in less than 0.01 seconds. Keyword- Convolutional Neural Network, face recognition, biometric identification, Stochastic Diagonal Levenberg-Marquardt","",""
26,"Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, Quanquan Gu","Do Wider Neural Networks Really Help Adversarial Robustness?",2020,"","","","",72,"2022-07-13 10:09:41","","","","",,,,,26,13.00,5,5,2,"Adversarial training is a powerful type of defense against adversarial examples. Previous empirical results suggest that adversarial training requires wider networks for better performances. However, it remains elusive how does neural network width affect model robustness. In this paper, we carefully examine the relationship between network width and model robustness. Specifically, we show that the model robustness is closely related to the tradeoff between natural accuracy and perturbation stability, which is controlled by the robust regularization parameter λ. With the same λ, wider networks can achieve better natural accuracy but worse perturbation stability, leading to a potentially worse overall model robustness. To understand the origin of this phenomenon, we further relate the perturbation stability with the network’s local Lipschitzness. By leveraging recent results on neural tangent kernels, we theoretically show that wider networks tend to have worse perturbation stability. Our analyses suggest that: 1) the common strategy of first fine-tuning λ on small networks and then directly use it for wide model training could lead to deteriorated model robustness; 2) one needs to properly enlarge λ to unleash the robustness potential of wider models fully. Finally, we propose a new Width Adjusted Regularization (WAR) method that adaptively enlarges λ on wide models and significantly saves the tuning time.","",""
55,"A. Shafahi, Parsa Saadatpanah, Chen Zhu, Amin Ghiasi, C. Studer, D. Jacobs, T. Goldstein","Adversarially robust transfer learning",2019,"","","","",73,"2022-07-13 10:09:41","","","","",,,,,55,18.33,8,7,3,"Transfer learning, in which a network is trained on one task and re-purposed on another, is often used to produce neural network classifiers when data is scarce or full-scale training is too costly. When the goal is to produce a model that is not only accurate but also adversarially robust, data scarcity and computational limitations become even more cumbersome. We consider robust transfer learning, in which we transfer not only performance but also robustness from a source model to a target domain. We start by observing that robust networks contain robust feature extractors. By training classifiers on top of these feature extractors, we produce new models that inherit the robustness of their parent networks. We then consider the case of fine tuning a network by re-training end-to-end in the target domain. When using lifelong learning strategies, this process preserves the robustness of the source network while achieving high accuracy. By using such strategies, it is possible to produce accurate and robust models with little data, and without the cost of adversarial training. Additionally, we can improve the generalization of adversarially trained models, while maintaining their robustness.","",""
28,"Tian-Rui Liu, T. Stathaki","Faster R-CNN for Robust Pedestrian Detection Using Semantic Segmentation Network",2018,"","","","",74,"2022-07-13 10:09:41","","10.3389/fnbot.2018.00064","","",,,,,28,7.00,14,2,4,"Convolutional neural networks (CNN) have enabled significant improvements in pedestrian detection owing to the strong representation ability of the CNN features. However, it is generally difficult to reduce false positives on hard negative samples such as tree leaves, traffic lights, poles, etc. Some of these hard negatives can be removed by making use of high level semantic vision cues. In this paper, we propose a region-based CNN method which makes use of semantic cues for better pedestrian detection. Our method extends the Faster R-CNN detection framework by adding a branch of network for semantic image segmentation. The semantic network aims to compute complementary higher level semantic features to be integrated with the convolutional features. We make use of multi-resolution feature maps extracted from different network layers in order to ensure good detection accuracy for pedestrians at different scales. Boosted forest is used for training the integrated features in a cascaded manner for hard negatives mining. Experiments on the Caltech pedestrian dataset show improvements on detection accuracy with the semantic network. With the deep VGG16 model, our pedestrian detection method achieves robust detection performance on the Caltech dataset.","",""
312,"Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Uesato, R. Arandjelović, Timothy A. Mann, Pushmeet Kohli","On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models",2018,"","","","",75,"2022-07-13 10:09:41","","","","",,,,,312,78.00,35,9,4,"Recent work has shown that it is possible to train deep neural networks that are provably robust to norm-bounded adversarial perturbations. Most of these methods are based on minimizing an upper bound on the worst-case loss over all possible adversarial perturbations. While these techniques show promise, they often result in difficult optimization procedures that remain hard to scale to larger networks. Through a comprehensive analysis, we show how a simple bounding technique, interval bound propagation (IBP), can be exploited to train large provably robust neural networks that beat the state-of-the-art in verified accuracy. While the upper bound computed by IBP can be quite weak for general networks, we demonstrate that an appropriate loss and clever hyper-parameter schedule allow the network to adapt such that the IBP bound is tight. This results in a fast and stable learning algorithm that outperforms more sophisticated methods and achieves state-of-the-art results on MNIST, CIFAR-10 and SVHN. It also allows us to train the largest model to be verified beyond vacuous bounds on a downscaled version of ImageNet.","",""
20,"Qingdong Wu, Bo Yan, Chao Zhang, Lu Wang, Guobao Ning, Bin Yu","Displacement Prediction of Tunnel Surrounding Rock: A Comparison of Support Vector Machine and Artificial Neural Network",2014,"","","","",76,"2022-07-13 10:09:41","","10.1155/2014/351496","","",,,,,20,2.50,3,6,8,"Displacement prediction of tunnel surrounding rock plays an important role in safety monitoring and quality control tunnel construction. In this paper, two methodologies, support vector machines (SVM) and artificial neural network (ANN), are introduced to predict tunnel surrounding rock displacement. Then the two modes are texted with the data of Fangtianchong tunnel, respectively. The comparative results show that solutions gained by SVM seem to be more robust with a smaller standard error compared to ANN. Generally, the comparison between artificial neural network (ANN) and SVM shows that SVM has a higher accuracy prediction than ANN. Results also show that SVM seems to be a powerful tool for tunnel surrounding rock displacement prediction.","",""
44,"V. Mitra, Weiqi Wang, H. Franco, Yun Lei, C. Bartels, M. Graciarena","Evaluating robust features on deep neural networks for speech recognition in noisy and channel mismatched conditions",2014,"","","","",77,"2022-07-13 10:09:41","","","","",,,,,44,5.50,7,6,8,"Deep Neural Network (DNN) based acoustic models have shown significant improvement over their Gaussian Mixture Model (GMM) counterparts in the last few years. While several studies exist that evaluate the performance of GMM systems under noisy and channel degraded conditions, noise robustness studies on DNN systems have been far fewer. In this work we present a study exploring both conventional DNNs and deep Convolutional Neural Networks (CNN) for noiseand channel-degraded speech recognition tasks using the Aurora4 dataset. We compare the baseline mel-filterbank energies with noise-robust features that we have proposed earlier and show that the use of robust features helps to improve the performance of DNNs or CNNs compared to melfilterbank energies. We also show that vocal tract length normalization has a positive role in improving the performance of the robust acoustic features. Finally, we show that by combining multiple systems together we can achieve even further improvement in recognition accuracy.","",""
31,"H. Nemmour, Y. Chibani","Neural Network Combination by Fuzzy Integral for Robust Change Detection in Remotely Sensed Imagery",2005,"","","","",78,"2022-07-13 10:09:41","","10.1155/ASP.2005.2187","","",,,,,31,1.82,16,2,17,"Combining multiple neural networks has been used to improve the decision accuracy in many application fields including pattern recognition and classification. In this paper, we investigate the potential of this approach for land cover change detection. In a first step, we perform many experiments in order to find the optimal individual networks in terms of architecture and training rule. In the second step, different neural network change detectors are combined using a method based on the notion of fuzzy integral. This method combines objective evidences in the form of network outputs, with subjective measures of their performances. Various forms of the fuzzy integral, which are, namely, Choquet integral, Sugeno integral, and two extensions of Sugeno integral with ordered weighted averaging operators, are implemented. Experimental analysis using error matrices and Kappa analysis showed that the fuzzy integral outperforms individual networks and constitutes an appropriate strategy to increase the accuracy of change detection.","",""
137,"J. Gong, B. Yao","Neural network adaptive robust control of nonlinear systems in semi-strict feedback form",2001,"","","","",79,"2022-07-13 10:09:41","","10.1109/ACC.2001.946180","","",,,,,137,6.52,69,2,21,"In this paper, the recently proposed neural network adaptive robust control (NNARC) design axe generalized to synthesize performance oriented control laws for a class of nonlinear systems transformable to the semi-strict feedback forms through the incorporation of backstepping design techniques. All unknown but repeatable nonlinearities in system are approximated by outputs of multi-layer neural networks to achieve a better model compensation and an improved performance. Through the use of discontinuous projections with fictitious bounds, a controlled on-line training of all NN weights is achieved. Robust control terms can then be constructed to attenuate various model uncertainties effectively for a guaranteed output tracking transient performance and a guaranteed final tracking accuracy.","",""
46,"Yuanda Wang, Jia Sun, Haibo He, Changyin Sun","Deterministic Policy Gradient With Integral Compensator for Robust Quadrotor Control",2020,"","","","",80,"2022-07-13 10:09:41","","10.1109/TSMC.2018.2884725","","",,,,,46,23.00,12,4,2,"In this paper, a deep reinforcement learning-based robust control strategy for quadrotor helicopters is proposed. The quadrotor is controlled by a learned neural network which directly maps the system states to control commands in an end-to-end style. The learning algorithm is developed based on the deterministic policy gradient algorithm. By introducing an integral compensator to the actor-critic structure, the tracking accuracy and robustness have been greatly enhanced. Moreover, a two-phase learning protocol which includes both offline and online learning phase is proposed for practical implementation. An offline policy is first learned based on a simplified quadrotor model. Then, the policy is online optimized in actual flight. The proposed approach is evaluated in the flight simulator. The results demonstrate that the offline learned policy is highly robust to model errors and external disturbances. It also shows that the online learning could significantly improve the control performance.","",""
18,"Bu Dexu, Sun Wei, Yu Hongshan, Wang Cong, Zhang Hui","Adaptive robust control based on RBF neural networks for duct cleaning robot",2015,"","","","",81,"2022-07-13 10:09:41","","10.1007/S12555-012-0447-9","","",,,,,18,2.57,4,5,7,"","",""
25,"G. Kasieczka, D. Shih","DisCo Fever: Robust Networks Through Distance Correlation",2020,"","","","",82,"2022-07-13 10:09:41","","","","",,,,,25,12.50,13,2,2,"While deep learning has proven to be extremely successful at supervised classification tasks at the LHC and beyond, for practical applications, raw classification accuracy is often not the only consideration. One crucial issue is the stability of network predictions, either versus changes of individual features of the input data, or against systematic perturbations. We present a new method based on a novel application of “distance correlation” (DisCo), a measure quantifying non-linear correlations, that achieves equal performance to state-of-the-art adversarial decorrelation networks but is much simpler to train and has better convergence properties. To demonstrate the effectiveness of our method, we carefully recast a recent ATLAS study of decorrelation methods as applied to boosted, hadronic W -tagging. We also show the feasibility of DisCo regularization for more powerful convolutional neural networks, as well as for the problem of hadronic top tagging.","",""
535,"Alvaro Fuentes, Sook Yoon, Sang Cheol Kim, D. Park","A Robust Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition",2017,"","","","",83,"2022-07-13 10:09:41","","10.3390/s17092022","","",,,,,535,107.00,134,4,5,"Plant Diseases and Pests are a major challenge in the agriculture sector. An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses. Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems. In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions. Our goal is to find the more suitable deep-learning architecture for our task. Therefore, we consider three main families of detectors: Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called “deep learning meta-architectures”. We combine each of these meta-architectures with “deep feature extractors” such as VGG net and Residual Network (ResNet). We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training. We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant. Experimental results show that our proposed system can effectively recognize nine different types of diseases and pests, with the ability to deal with complex scenarios from a plant’s surrounding area.","",""
90,"Jianming Zhang, Juan Sun, Jin Wang, Xiao-Guang Yue","Visual object tracking based on residual network and cascaded correlation filters",2020,"","","","",84,"2022-07-13 10:09:41","","10.1007/S12652-020-02572-0","","",,,,,90,45.00,23,4,2,"","",""
18,"M. El-Melegy","Random Sampler M-Estimator Algorithm With Sequential Probability Ratio Test for Robust Function Approximation Via Feed-Forward Neural Networks",2013,"","","","",85,"2022-07-13 10:09:41","","10.1109/TNNLS.2013.2251001","","",,,,,18,2.00,18,1,9,"This paper addresses the problem of fitting a functional model to data corrupted with outliers using a multilayered feed-forward neural network. Although it is of high importance in practical applications, this problem has not received careful attention from the neural network research community. One recent approach to solving this problem is to use a neural network training algorithm based on the random sample consensus (RANSAC) framework. This paper proposes a new algorithm that offers two enhancements over the original RANSAC algorithm. The first one improves the algorithm accuracy and robustness by employing an M-estimator cost function to decide on the best estimated model from the randomly selected samples. The other one improves the time performance of the algorithm by utilizing a statistical pretest based on Wald's sequential probability ratio test. The proposed algorithm is successfully evaluated on synthetic and real data, contaminated with varying degrees of outliers, and compared with existing neural network training algorithms.","",""
2679,"George E. Dahl, Dong Yu, L. Deng, A. Acero","Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition",2012,"","","","",86,"2022-07-13 10:09:41","","10.1109/TASL.2011.2134090","","",,,,,2679,267.90,670,4,10,"We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.","",""
89,"Runtian Zhai, Tianle Cai, Di He, Chen Dan, Kun He, J. Hopcroft, Liwei Wang","Adversarially Robust Generalization Just Requires More Unlabeled Data",2019,"","","","",87,"2022-07-13 10:09:41","","","","",,,,,89,29.67,13,7,3,"Neural network robustness has recently been highlighted by the existence of adversarial examples. Many previous works show that the learned networks do not perform well on perturbed test data, and significantly more labeled data is required to achieve adversarially robust generalization. In this paper, we theoretically and empirically show that with just more unlabeled data, we can learn a model with better adversarially robust generalization. The key insight of our results is based on a risk decomposition theorem, in which the expected robust risk is separated into two parts: the stability part which measures the prediction stability in the presence of perturbations, and the accuracy part which evaluates the standard classification accuracy. As the stability part does not depend on any label information, we can optimize this part using unlabeled data. We further prove that for a specific Gaussian mixture problem illustrated by [35], adversarially robust generalization can be almost as easy as the standard generalization in supervised learning if a sufficiently large amount of unlabeled data is provided. Inspired by the theoretical findings, we propose a new algorithm called PASS by leveraging unlabeled data during adversarial training. We show that in the transductive and semi-supervised settings, PASS achieves higher robust accuracy and defense success rate on the Cifar-10 task.","",""
69,"Sven Gowal, Robert Stanforth","Scalable Verified Training for Provably Robust Image Classification",2019,"","","","",88,"2022-07-13 10:09:41","","10.1109/ICCV.2019.00494","","",,,,,69,23.00,35,2,3,"Recent work has shown that it is possible to train deep neural networks that are provably robust to norm-bounded adversarial perturbations. Most of these methods are based on minimizing an upper bound on the worst-case loss over all possible adversarial perturbations. While these techniques show promise, they often result in difficult optimization procedures that remain hard to scale to larger networks. Through a comprehensive analysis, we show how a simple bounding technique, interval bound propagation (IBP), can be exploited to train large provably robust neural networks that beat the state-of-the-art in verified accuracy. While the upper bound computed by IBP can be quite weak for general networks, we demonstrate that an appropriate loss and clever hyper-parameter schedule allow the network to adapt such that the IBP bound is tight. This results in a fast and stable learning algorithm that outperforms more sophisticated methods and achieves state-of-the-art results on MNIST, CIFAR-10 and SVHN. It also allows us to train the largest model to be verified beyond vacuous bounds on a downscaled version of IMAGENET.","",""
794,"Yi Sun, Xiaogang Wang, Xiaoou Tang","Deeply learned face representations are sparse, selective, and robust",2014,"","","","",89,"2022-07-13 10:09:41","","10.1109/CVPR.2015.7298907","","",,,,,794,99.25,265,3,8,"This paper designs a high-performance deep convolutional network (DeepID2+) for face recognition. It is learned with the identification-verification supervisory signal. By increasing the dimension of hidden representations and adding supervision to early convolutional layers, DeepID2+ achieves new state-of-the-art on LFW and YouTube Faces benchmarks. Through empirical studies, we have discovered three properties of its deep neural activations critical for the high performance: sparsity, selectiveness and robustness. (1) It is observed that neural activations are moderately sparse. Moderate sparsity maximizes the discriminative power of the deep net as well as the distance between images. It is surprising that DeepID2+ still can achieve high recognition accuracy even after the neural responses are binarized. (2) Its neurons in higher layers are highly selective to identities and identity-related attributes. We can identify different subsets of neurons which are either constantly excited or inhibited when different identities or attributes are present. Although DeepID2+ is not taught to distinguish attributes during training, it has implicitly learned such high-level concepts. (3) It is much more robust to occlusions, although occlusion patterns are not included in the training set.","",""
277,"Min Xia, Teng Li, Lin Xu, Lizhi Liu, C. D. de Silva","Fault Diagnosis for Rotating Machinery Using Multiple Sensors and Convolutional Neural Networks",2018,"","","","",90,"2022-07-13 10:09:41","","10.1109/TMECH.2017.2728371","","",,,,,277,69.25,55,5,4,"This paper presents a convolutional neural network (CNN) based approach for fault diagnosis of rotating machinery. The proposed approach incorporates sensor fusion by taking advantage of the CNN structure to achieve higher and more robust diagnosis accuracy. Both temporal and spatial information of the raw data from multiple sensors is considered during the training process of the CNN. Representative features can be extracted automatically from the raw signals. It avoids manual feature extraction or selection, which relies heavily on prior knowledge of specific machinery and fault types. The effectiveness of the developed method is evaluated by using datasets from two types of typical rotating machinery, roller bearings, and gearboxes. Compared with traditional approaches using manual feature extraction, the results show the superior diagnosis performance of the proposed method. The present approach can be extended to fault diagnosis of other machinery with various types of sensors due to its end to end feature learning capability.","",""
49,"Ning Chen, Tie Qiu, Xiaobo Zhou, Keqiu Li, Mohammed Atiquzzaman","An Intelligent Robust Networking Mechanism for the Internet of Things",2019,"","","","",91,"2022-07-13 10:09:41","","10.1109/MCOM.001.1900094","","",,,,,49,16.33,10,5,3,"In smart cities, the Internet of Things (IoT) consists of many low-power smart nodes. Its robustness is essential for protection of communication in data science against node failures caused by energy shortage or cyber-attacks. Scale-free networking topology, widely applied in IoT, is effectively resilient to random attacks but is vulnerable to malicious ones in which high-degree nodes are made to fail. The prohibitively high computational cost of existing robustness optimization algorithms is an obstacle to efficient topology self-optimization. To solve this problem, a novel robust networking model based on artificial intelligence is proposed to improve IoT topology robustness to protect its communication. Using the Back-Propagation neural network learning algorithm, the model extracts topology features from a dataset by supervised training. The experimental results show that the model achieves better prediction accuracy, thereby optimizing the topology with minimal computation overhead.","",""
18,"Saima Sharmin, Nitin Rathi, P. Panda, K. Roy","Inherent Adversarial Robustness of Deep Spiking Neural Networks: Effects of Discrete Input Encoding and Non-Linear Activations",2020,"","","","",92,"2022-07-13 10:09:41","","10.1007/978-3-030-58526-6_24","","",,,,,18,9.00,5,4,2,"","",""
466,"Namhoon Lee, Thalaiyasingam Ajanthan, Philip H. S. Torr","SNIP: Single-shot Network Pruning based on Connection Sensitivity",2018,"","","","",93,"2022-07-13 10:09:41","","","","",,,,,466,116.50,155,3,4,"Pruning large neural networks while maintaining their performance is often desirable due to the reduced space and time complexity. In existing methods, pruning is done within an iterative optimization procedure with either heuristically designed pruning schedules or additional hyperparameters, undermining their utility. In this work, we present a new approach that prunes a given network once at initialization prior to training. To achieve this, we introduce a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task. This eliminates the need for both pretraining and the complex pruning schedule while making it robust to architecture variations. After pruning, the sparse network is trained in the standard way. Our method obtains extremely sparse networks with virtually the same accuracy as the reference network on the MNIST, CIFAR-10, and Tiny-ImageNet classification tasks and is broadly applicable to various architectures including convolutional, residual and recurrent networks. Unlike existing methods, our approach enables us to demonstrate that the retained connections are indeed relevant to the given task.","",""
67,"N. Amjady, F. Keynia","A New Neural Network Approach to Short Term Load Forecasting of Electrical Power Systems",2011,"","","","",94,"2022-07-13 10:09:41","","10.3390/EN4030488","","",,,,,67,6.09,34,2,11,"Short-term load forecast (STLF) is an important operational function in both regulated power systems and deregulated open electricity markets. However, STLF is not easy to handle due to the nonlinear and random-like behaviors of system loads, weather conditions, and social and economic environment variations. Despite the research work performed in the area, more accurate and robust STLF methods are still needed due to the importance and complexity of STLF. In this paper, a new neural network approach for STLF is proposed. The proposed neural network has a novel learning algorithm based on a new modified harmony search technique. This learning algorithm can widely search the solution space in various directions, and it can also avoid the overfitting problem, trapping in local minima and dead bands. Based on this learning algorithm, the suggested neural network can efficiently extract the input/output mapping function of the forecast process leading to high STLF accuracy. The proposed approach is tested on two practical power systems and the results obtained are compared with the results of several other recently published STLF methods. These comparisons confirm the validity of the developed approach.","",""
114,"Ty Nguyen, Steven W. Chen, Shreyas S. Shivakumar, C. J. Taylor, Vijay Kumar","Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model",2017,"","","","",95,"2022-07-13 10:09:41","","10.1109/LRA.2018.2809549","","",,,,,114,22.80,23,5,5,"Homography estimation between multiple aerial images can provide relative pose estimation for collaborative autonomous exploration and monitoring. The usage on a robotic system requires a fast and robust homography estimation algorithm. In this letter, we propose an unsupervised learning algorithm that trains a deep convolutional neural network to estimate planar homographies. We compare the proposed algorithm to traditional-feature-based and direct methods, as well as a corresponding supervised learning algorithm. Our empirical results demonstrate that compared to traditional approaches, the unsupervised algorithm achieves faster inference speed, while maintaining comparable or better accuracy and robustness to illumination variation. In addition, our unsupervised method has superior adaptability and performance compared to the corresponding supervised deep learning method. Our image dataset and a Tensorflow implementation of our work are available at  https://github.com/tynguyen/unsupervisedDeepHomographyRAL2018.","",""
32,"Lingjun Zhao, Huakun Huang, Xiang Li, Shuxue Ding, Haoli Zhao, Zhaoyang Han","An Accurate and Robust Approach of Device-Free Localization With Convolutional Autoencoder",2019,"","","","",96,"2022-07-13 10:09:41","","10.1109/JIOT.2019.2907580","","",,,,,32,10.67,5,6,3,"Device-free localization (DFL), as an emerging technology that locates targets without any attached devices via wireless sensor networks, has spawned extensive applications in the Internet of Things (IoT) field. For DFL, a key problem is how to extract significant features to characterize raw signals with different patterns associated with different locations. To address this problem, in this paper, the DFL problem is formulated as an image classification problem. Moreover, we design a three-layer convolutional autoencoder (CAE) neural network to perform unsupervised feature extraction from raw signals followed by supervised fine-tuning for classification. The CAE combines the advantages of a convolutional neural network (CNN) and a deep autoencoder (AE) in the feature learning and signals reconstruction, which is expected to achieve good performance for DFL. The experimental results show that the proposed approach can achieve a high localization accuracy rate of 100% for a reasonable grid size on the raw real-world data, i.e., the collected raw data without added Gaussian noise, and is robust to noisy data with a signal-to-noise ratio greater than −5 dB. Additionally, its time cost for the classification of a single activity is 4 ms, which is fast enough for the IoT applications. The proposed approach outperforms the deep CNN and AE in terms of localization accuracy and robust ability against noise.","",""
53,"B. A. Garro, Juan Humberto Sossa Azuela, R. Vázquez","Artificial neural network synthesis by means of artificial bee colony (ABC) algorithm",2011,"","","","",97,"2022-07-13 10:09:41","","10.1109/CEC.2011.5949637","","",,,,,53,4.82,18,3,11,"Artificial bee colony (ABC) algorithm has been used in several optimization problems, including the optimization of synaptic weights from an Artificial Neural Network (ANN). However, this is not enough to generate a robust ANN. For that reason, some authors have proposed methodologies based on so-called metaheuristics that automatically allow designing an ANN, taking into account not only the optimization of the synaptic weights as well as the ANN's architecture, and the transfer function of each neuron. However, those methodologies do not generate a reduced design (synthesis) of the ANN. In this paper, we present an ABC based methodology, that maximizes its accuracy and minimizes the number of connections of an ANN by evolving at the same time the synaptic weights, the ANN's architecture and the transfer functions of each neuron. The methodology is tested with several pattern recognition problems.","",""
39,"Sunok Kim, Dongbo Min, Seungryong Kim, K. Sohn","Unified Confidence Estimation Networks for Robust Stereo Matching",2019,"","","","",98,"2022-07-13 10:09:41","","10.1109/TIP.2018.2878325","","",,,,,39,13.00,10,4,3,"We present a deep architecture that estimates a stereo confidence, which is essential for improving the accuracy of stereo matching algorithms. In contrast to existing methods based on deep convolutional neural networks (CNNs) that rely on only one of the matching cost volume or estimated disparity map, our network estimates the stereo confidence by using the two heterogeneous inputs simultaneously. Specifically, the matching probability volume is first computed from the matching cost volume with residual networks and a pooling module in a manner that yields greater robustness. The confidence is then estimated through a unified deep network that combines confidence features extracted both from the matching probability volume and its corresponding disparity. In addition, our method extracts the confidence features of the disparity map by applying multiple convolutional filters with varying sizes to an input disparity map. To learn our networks in a semi-supervised manner, we propose a novel loss function that use confident points to compute the image reconstruction loss. To validate the effectiveness of our method in a disparity post-processing step, we employ three post-processing approaches; cost modulation, ground control points-based propagation, and aggregated ground control points-based propagation. Experimental results demonstrate that our method outperforms state-of-the-art confidence estimation methods on various benchmarks.","",""
32,"Xiang He, Sibei Yang, Guanbin Li, Haofeng Li, Huiyou Chang, Yizhou Yu","Non-Local Context Encoder: Robust Biomedical Image Segmentation against Adversarial Attacks",2019,"","","","",99,"2022-07-13 10:09:41","","10.1609/AAAI.V33I01.33018417","","",,,,,32,10.67,5,6,3,"Recent progress in biomedical image segmentation based on deep convolutional neural networks (CNNs) has drawn much attention. However, its vulnerability towards adversarial samples cannot be overlooked. This paper is the first one that discovers that all the CNN-based state-of-the-art biomedical image segmentation models are sensitive to adversarial perturbations. This limits the deployment of these methods in safety-critical biomedical fields. In this paper, we discover that global spatial dependencies and global contextual information in a biomedical image can be exploited to defend against adversarial attacks. To this end, non-local context encoder (NLCE) is proposed to model short- and long-range spatial dependencies and encode global contexts for strengthening feature activations by channel-wise attention. The NLCE modules enhance the robustness and accuracy of the non-local context encoding network (NLCEN), which learns robust enhanced pyramid feature representations with NLCE modules, and then integrates the information across different levels. Experiments on both lung and skin lesion segmentation datasets have demonstrated that NLCEN outperforms any other state-of-the-art biomedical image segmentation methods against adversarial attacks. In addition, NLCE modules can be applied to improve the robustness of other CNN-based biomedical image segmentation methods.","",""
38,"Vincent Lostanlen, J. Salamon, A. Farnsworth, S. Kelling, J. Bello","Robust sound event detection in bioacoustic sensor networks",2019,"","","","",100,"2022-07-13 10:09:41","","10.1371/journal.pone.0214168","","",,,,,38,12.67,8,5,3,"Bioacoustic sensors, sometimes known as autonomous recording units (ARUs), can record sounds of wildlife over long periods of time in scalable and minimally invasive ways. Deriving per-species abundance estimates from these sensors requires detection, classification, and quantification of animal vocalizations as individual acoustic events. Yet, variability in ambient noise, both over time and across sensors, hinders the reliability of current automated systems for sound event detection (SED), such as convolutional neural networks (CNN) in the time-frequency domain. In this article, we develop, benchmark, and combine several machine listening techniques to improve the generalizability of SED models across heterogeneous acoustic environments. As a case study, we consider the problem of detecting avian flight calls from a ten-hour recording of nocturnal bird migration, recorded by a network of six ARUs in the presence of heterogeneous background noise. Starting from a CNN yielding state-of-the-art accuracy on this task, we introduce two noise adaptation techniques, respectively integrating short-term (60 ms) and long-term (30 min) context. First, we apply per-channel energy normalization (PCEN) in the time-frequency domain, which applies short-term automatic gain control to every subband in the mel-frequency spectrogram. Secondly, we replace the last dense layer in the network by a context-adaptive neural network (CA-NN) layer, i.e. an affine layer whose weights are dynamically adapted at prediction time by an auxiliary network taking long-term summary statistics of spectrotemporal features as input. We show that PCEN reduces temporal overfitting across dawn vs. dusk audio clips whereas context adaptation on PCEN-based summary statistics reduces spatial overfitting across sensor locations. Moreover, combining them yields state-of-the-art results that are unmatched by artificial data augmentation alone. We release a pre-trained version of our best performing system under the name of BirdVoxDetect, a ready-to-use detector of avian flight calls in field recordings.","",""
38,"Vincent Lostanlen, J. Salamon, A. Farnsworth, S. Kelling, J. Bello","Robust sound event detection in bioacoustic sensor networks",2019,"","","","",101,"2022-07-13 10:09:41","","10.1371/journal.pone.0214168","","",,,,,38,12.67,8,5,3,"Bioacoustic sensors, sometimes known as autonomous recording units (ARUs), can record sounds of wildlife over long periods of time in scalable and minimally invasive ways. Deriving per-species abundance estimates from these sensors requires detection, classification, and quantification of animal vocalizations as individual acoustic events. Yet, variability in ambient noise, both over time and across sensors, hinders the reliability of current automated systems for sound event detection (SED), such as convolutional neural networks (CNN) in the time-frequency domain. In this article, we develop, benchmark, and combine several machine listening techniques to improve the generalizability of SED models across heterogeneous acoustic environments. As a case study, we consider the problem of detecting avian flight calls from a ten-hour recording of nocturnal bird migration, recorded by a network of six ARUs in the presence of heterogeneous background noise. Starting from a CNN yielding state-of-the-art accuracy on this task, we introduce two noise adaptation techniques, respectively integrating short-term (60 ms) and long-term (30 min) context. First, we apply per-channel energy normalization (PCEN) in the time-frequency domain, which applies short-term automatic gain control to every subband in the mel-frequency spectrogram. Secondly, we replace the last dense layer in the network by a context-adaptive neural network (CA-NN) layer, i.e. an affine layer whose weights are dynamically adapted at prediction time by an auxiliary network taking long-term summary statistics of spectrotemporal features as input. We show that PCEN reduces temporal overfitting across dawn vs. dusk audio clips whereas context adaptation on PCEN-based summary statistics reduces spatial overfitting across sensor locations. Moreover, combining them yields state-of-the-art results that are unmatched by artificial data augmentation alone. We release a pre-trained version of our best performing system under the name of BirdVoxDetect, a ready-to-use detector of avian flight calls in field recordings.","",""
19,"Nour Eldeen M. Khalifa, M. Taha, A. Hassanien, A. A. Hemedan","Deep bacteria: robust deep learning data augmentation design for limited bacterial colony dataset",2019,"","","","",102,"2022-07-13 10:09:41","","10.1504/IJRIS.2019.10023444","","",,,,,19,6.33,5,4,3,"Bacterial colony classification is an important problem in microbiology. With the advances in computer-aided software's, similar problems have been solved in a speedy and accurate manner during the last decade. In this paper, deep neural network architecture will be presented to solve the bacterial colony classification problem. In addition, the training and testing strategy that relies on the strong use of data augmentation will be introduced. The used dataset was limited as it contains 660 images for 33 classes of a bacterial colony. Any neural network cannot learn from this data directly and in case of learning the neural network will overfit. The adopted training and testing strategy lead to a significant improvement in the training and testing phases. It raised the dataset images to 6,600 images for the training phase and 5,940 images for verification phase. The proposed neural network with the adopted augmentation techniques achieved 98.22% in testing accuracy. A comparative result is presented, and the testing accuracy was compared with those of other related works. The proposed architecture outperformed the other related works in terms of its testing accuracy.","",""
56,"Liuhao Ge, Hui Liang, Junsong Yuan, D. Thalmann","Real-Time 3D Hand Pose Estimation with 3D Convolutional Neural Networks",2019,"","","","",103,"2022-07-13 10:09:41","","10.1109/TPAMI.2018.2827052","","",,,,,56,18.67,14,4,3,"In this paper, we present a novel method for real-time 3D hand pose estimation from single depth images using 3D Convolutional Neural Networks (CNNs). Image-based features extracted by 2D CNNs are not directly suitable for 3D hand pose estimation due to the lack of 3D spatial information. Our proposed 3D CNN-based method, taking a 3D volumetric representation of the hand depth image as input and extracting 3D features from the volumetric input, can capture the 3D spatial structure of the hand and accurately regress full 3D hand pose in a single pass. In order to make the 3D CNN robust to variations in hand sizes and global orientations, we perform 3D data augmentation on the training data. To further improve the estimation accuracy, we propose applying the 3D deep network architectures and leveraging the complete hand surface as intermediate supervision for learning 3D hand pose from depth images. Extensive experiments on three challenging datasets demonstrate that our proposed approach outperforms baselines and state-of-the-art methods. A cross-dataset experiment also shows that our method has good generalization ability. Furthermore, our method is fast as our implementation runs at over 91 frames per second on a standard computer with a single GPU.","",""
1327,"Alex Kendall, M. Grimes, R. Cipolla","PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization",2015,"","","","",104,"2022-07-13 10:09:41","","10.1109/ICCV.2015.336","","",,,,,1327,189.57,442,3,7,"We present a robust and real-time monocular six degree of freedom relocalization system. Our system trains a convolutional neural network to regress the 6-DOF camera pose from a single RGB image in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking 5ms per frame to compute. It obtains approximately 2m and 3 degrees accuracy for large scale outdoor scenes and 0.5m and 5 degrees accuracy indoors. This is achieved using an efficient 23 layer deep convnet, demonstrating that convnets can be used to solve complicated out of image plane regression problems. This was made possible by leveraging transfer learning from large scale classification data. We show that the PoseNet localizes from high level features and is robust to difficult lighting, motion blur and different camera intrinsics where point based SIFT registration fails. Furthermore we show how the pose feature that is produced generalizes to other scenes allowing us to regress pose with only a few dozen training examples.","",""
56,"Brandon Wagstaff, Jonathan Kelly","LSTM-Based Zero-Velocity Detection for Robust Inertial Navigation",2018,"","","","",105,"2022-07-13 10:09:41","","10.1109/IPIN.2018.8533770","","",,,,,56,14.00,28,2,4,"We present a method to improve the accuracy of a zero-velocity-aided inertial navigation system (INS) by replacing the standard zero-velocity detector with a long short-term memory (LSTM) neural network. While existing threshold-based zero-velocity detectors are not robust to varying motion types, our learned model accurately detects stationary periods of the inertial measurement unit (IMU) despite changes in the motion of the user. Upon detection, zero-velocity pseudo-measurements are fused with a dead reckoning motion model in an extended Kalman filter (EKF). We demonstrate that our LSTM-based zero-velocity detector, used within a zero-velocity-aided INS, improves zero-velocity detection during human localization tasks. Consequently, localization accuracy is also improved. Our system is evaluated on more than 7.5 km of indoor pedestrian locomotion data, acquired from five different subjects. We show that 3D positioning error is reduced by over 34% compared to existing fixed-threshold zero-velocity detectors for walking, running, and stair climbing motions. Additionally, we demonstrate how our learned zero-velocity detector operates effectively during crawling and ladder climbing. Our system is calibration-free (no careful threshold-tuning is required) and operates consistently with differing users, IMU placements, and shoe types, while being compatible with any generic zero-velocity-aided INS.","",""
51,"E. Vamsidhar, K. Varma, P. Sankara","Prediction of Rainfall Using Backpropagation Neural Network Model",2010,"","","","",106,"2022-07-13 10:09:41","","","","",,,,,51,4.25,17,3,12,"Agriculture is the predominant occupation in India, accounting for about 52% of employment. The Irrigation facilities are inadequate, as revealed by the fact that only 52.6% of the land was irrigated in 2009–10 which result in farmers still being dependent on rainfall, specifically the Monsoon season. A good monsoon results in a robust growth for the economy as a whole, while a poor monsoon leads to a sluggish growth. . Artificial neural network is one of the most widely used supervised techniques of data mining. In this paper we used the back propagation neural network model for predicting the rainfall based on humidity, dew point and pressure in the country INDIA. Two-Third of the data was used for training and One-third for testing .The number of training and testing patterns are 250 training and 120 testing .In the training we obtained 99.79% of accuracy and in Testing we obtained 94.28% of accuracy. From these results we can predict the rainfall for the future.","",""
42,"M. Hariharan, L. Chee, S. Yaacob","Analysis of Infant Cry Through Weighted Linear Prediction Cepstral Coefficients and Probabilistic Neural Network",2012,"","","","",107,"2022-07-13 10:09:41","","10.1007/s10916-010-9591-z","","",,,,,42,4.20,14,3,10,"","",""
22,"M. Klachko, M. Mahmoodi, D. Strukov","Improving Noise Tolerance of Mixed-Signal Neural Networks",2019,"","","","",108,"2022-07-13 10:09:41","","10.1109/IJCNN.2019.8851966","","",,,,,22,7.33,7,3,3,"Mixed-signal hardware accelerators for deep learning achieve orders of magnitude better power efficiency than their digital counterparts. In the ultra-low power consumption regime, limited signal precision inherent to analog computation becomes a challenge. We perform a case study of a 6-layer convolutional neural network running on a mixed-signal accelerator and evaluate its sensitivity to hardware specific noise. We apply various methods to improve noise robustness of the network and demonstrate an effective way to optimize useful signal ranges through adaptive signal clipping. The resulting model is robust enough to achieve 80.2% classification accuracy on CIFAR-10 dataset with just 1.4 mW power budget, while 6 mW budget allows us to achieve 87.1% accuracy, which is within 1% of the software baseline. For comparison, the unoptimized version of the same model achieves only 67.7% accuracy at 1.4 mW and 78.6% at 6 mW.","",""
70,"Nicholas R. Waytowich, V. Lawhern, Javier O. Garcia, J. Cummings, J. Faller, P. Sajda, J. Vettel","Compact Convolutional Neural Networks for Classification of Asynchronous Steady-state Visual Evoked Potentials",2018,"","","","",109,"2022-07-13 10:09:41","","10.1088/1741-2552/aae5d8","","",,,,,70,17.50,10,7,4,"OBJECTIVE Steady-state visual evoked potentials (SSVEPs) are neural oscillations from the parietal and occipital regions of the brain that are evoked from flickering visual stimuli. SSVEPs are robust signals measurable in the electroencephalogram (EEG) and are commonly used in brain-computer interfaces (BCIs). However, methods for high-accuracy decoding of SSVEPs usually require hand-crafted approaches that leverage domain-specific knowledge of the stimulus signals, such as specific temporal frequencies in the visual stimuli and their relative spatial arrangement. When this knowledge is unavailable, such as when SSVEP signals are acquired asynchronously, such approaches tend to fail.   APPROACH In this paper, we show how a compact convolutional neural network (Compact-CNN), which only requires raw EEG signals for automatic feature extraction, can be used to decode signals from a 12-class SSVEP dataset without the need for user-specific calibration.   MAIN RESULTS The Compact-CNN demonstrates across subject mean accuracy of approximately 80%, out-performing current state-of-the-art, hand-crafted approaches using canonical correlation analysis (CCA) and Combined-CCA. Furthermore, the Compact-CNN approach can reveal the underlying feature representation, revealing that the deep learner extracts additional phase- and amplitude-related features associated with the structure of the dataset.   SIGNIFICANCE We discuss how our Compact-CNN shows promise for BCI applications that allow users to freely gaze/attend to any stimulus at any time (e.g. asynchronous BCI) as well as provides a method for analyzing SSVEP signals in a way that might augment our understanding about the basic processing in the visual cortex.","",""
46,"Chi-Chung Chen, Chia-Lin Yang, Hsiang-Yun Cheng","Efficient and Robust Parallel DNN Training through Model Parallelism on Multi-GPU Platform",2018,"","","","",110,"2022-07-13 10:09:41","","","","",,,,,46,11.50,15,3,4,"The training process of Deep Neural Network (DNN) is compute-intensive, often taking days to weeks to train a DNN model. Therefore, parallel execution of DNN training on GPUs is a widely adopted approach to speed up the process nowadays. Due to the implementation simplicity, data parallelism is currently the most commonly used parallelization method. Nonetheless, data parallelism suffers from excessive inter-GPU communication overhead due to frequent weight synchronization among GPUs. Another approach is pipelined model parallelism, which partitions a DNN model among GPUs, and processes multiple mini-batches concurrently. This approach can significantly reduce inter-GPU communication cost compared to data parallelism. However, pipelined model parallelism faces the weight staleness issue; that is, gradients are computed with stale weights, leading to training instability and accuracy loss. In this paper, we present a pipelined model parallel execution method that enables high GPU utilization while maintaining robust training accuracy via a novel weight prediction technique, SpecTrain. Experimental results show that our proposal achieves up to 8.91x speedup compared to data parallelism on a 4-GPU platform while maintaining comparable model accuracy.","",""
79,"M. Wood, A. Thompson","Extending the accuracy of the SNAP interatomic potential form.",2017,"","","","",111,"2022-07-13 10:09:41","","10.1063/1.5017641","","",,,,,79,15.80,40,2,5,"The Spectral Neighbor Analysis Potential (SNAP) is a classical interatomic potential that expresses the energy of each atom as a linear function of selected bispectrum components of the neighbor atoms. An extension of the SNAP form is proposed that includes quadratic terms in the bispectrum components. The extension is shown to provide a large increase in accuracy relative to the linear form, while incurring only a modest increase in computational cost. The mathematical structure of the quadratic SNAP form is similar to the embedded atom method (EAM), with the SNAP bispectrum components serving as counterparts to the two-body density functions in EAM. The effectiveness of the new form is demonstrated using an extensive set of training data for tantalum structures. Similar to artificial neural network potentials, the quadratic SNAP form requires substantially more training data in order to prevent overfitting. The quality of this new potential form is measured through a robust cross-validation analysis.","",""
17,"Saima Sharmin, P. Panda, Syed Shakib Sarwar, Chankyu Lee, Wachirawit Ponghiran, K. Roy","A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks",2019,"","","","",112,"2022-07-13 10:09:41","","10.1109/IJCNN.2019.8851732","","",,,,,17,5.67,3,6,3,"In this era of machine learning models, their functionality is being threatened by adversarial attacks. In the face of this struggle for making artificial neural networks robust, finding a model, resilient to these attacks, is very important. In this work, we present, for the first time, a comprehensive analysis of the behavior of more bio-plausible networks, namely Spiking Neural Network (SNN) under state-of-the-art adversarial tests. We perform a comparative study of the accuracy degradation between conventional VGG-9 Artificial Neural Network (ANN) and equivalent spiking network with CIFAR-10 dataset in both whitebox and blackbox setting for different types of single-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We demonstrate that SNNs tend to show more resiliency compared to ANN under blackbox attack scenario. Additionally, we find that SNN robustness is largely dependent on the corresponding training mechanism. We observe that SNNs trained by spike-based backpropagation are more adversarially robust than the ones obtained by ANN-to-SNN conversion rules in several whitebox and blackbox scenarios. Finally, we also propose a simple, yet, effective framework for crafting adversarial attacks from SNNs. Our results suggest that attacks crafted from SNNs following our proposed method are much stronger than those crafted from ANNs.","",""
38,"Danqing Luo, Yuexian Zou, Dongyan Huang","Investigation on Joint Representation Learning for Robust Feature Extraction in Speech Emotion Recognition",2018,"","","","",113,"2022-07-13 10:09:41","","10.21437/Interspeech.2018-1832","","",,,,,38,9.50,13,3,4,"Speech emotion recognition (SER) is a challenging task due to its difficulty in finding proper representations for emotion embedding in speech. Recently, Convolutional Recurrent Neural Network (CRNN), which is combined by convolution neural network and recurrent neural network, is popular in this field and achieves state-of-art on related corpus. However, most of work on CRNN only utilizes simple spectral information, which is not capable to capture enough emotion characteristics for the SER task. In this work, we investigate two joint representation learning structures based on CRNN aiming at capturing richer emotional information from speech. Cooperating the handcrafted high-level statistic features with CRNN, a two-channel SER system (HSF-CRNN) is developed to jointly learn the emotion-related features with better discriminative property. Furthermore, considering that the time duration of speech segment significantly affects the accuracy of emotion recognition, another two-channel SER system is proposed where CRNN features extracted from different time scale of spectrogram segment are used for joint representation learning. The systems are evaluated over Atypical Affect Challenge of ComParE2018 and IEMOCAP corpus. Experimental results show that our proposed systems outperform the plain CRNN.","",""
29,"R. Ravikanth","Prediction of Rainfall Using Backpropagation Neural Network Model",2010,"","","","",114,"2022-07-13 10:09:41","","","","",,,,,29,2.42,29,1,12,"Agriculture is the predominant occupation in India, accounting for about 52% of employment. The Irrigation facilities are inadequate, as revealed by the fact that only 52.6% of the land was irrigated in 2009–10 which result in farmers still being dependent on rainfall, specifically the Monsoon season. A good monsoon results in a robust growth for the economy as a whole, while a poor monsoon leads to a sluggish growth. . Artificial neural network is one of the most widely used supervised techniques of data mining. In this paper we used the back propagation neural network model for predicting the rainfall based on humidity, dew point and pressure in the country INDIA. Two-Third of the data was used for training and One-third for testing .The number of training and testing patterns are 250 training and 120 testing .In the training we obtained 99.79% of accuracy and in Testing we obtained 94.28% of accuracy. From these results we can predict the rainfall for the future.","",""
80,"H. Khodabandehlou, G. Pekcan, M. Fadali","Vibration‐based structural condition assessment using convolution neural networks",2018,"","","","",115,"2022-07-13 10:09:41","","10.1002/stc.2308","","",,,,,80,20.00,27,3,4,"A novel vibration‐based structural health monitoring (SHM) approach that uses two‐dimensional deep convolution neural networks (CNN) is introduced. The CNN extracts the features from acceleration response histories and drastically reduces the dimension of response history to make damage state classification possible with limited number of acceleration measurements. The proposed method was validated, and its applicability and efficiency were demonstrated using vibration response data recorded during the shake‐table testing of a one‐fourth–scale model of a reinforced concrete highway bridge. The proposed method predicted predefined damage states with 100% accuracy using recorded (acceleration) vibration response data. The method was shown to be robust and sensitive to very small changes in structural condition. It is also noted that the CNN‐based SHM method is scalable to any large number of damage states (including extent and location) with suitable network training. The required training data may be generated analytically using a nonlinear finite element model.","",""
75,"Guotai Wang, Wenqi Li, S. Ourselin, Tom Kamiel Magda Vercauteren","Automatic Brain Tumor Segmentation using Convolutional Neural Networks with Test-Time Augmentation",2018,"","","","",116,"2022-07-13 10:09:41","","10.1007/978-3-030-11726-9_6","","",,,,,75,18.75,19,4,4,"","",""
48,"Suwon Shon, Ahmed Ali, James R. Glass","Convolutional Neural Networks and Language Embeddings for End-to-End Dialect Recognition",2018,"","","","",117,"2022-07-13 10:09:41","","10.21437/Odyssey.2018-14","","",,,,,48,12.00,16,3,4,"Dialect identification (DID) is a special case of general language identification (LID), but a more challenging problem due to the linguistic similarity between dialects. In this paper, we propose an end-to-end DID system and a Siamese neural network to extract language embeddings. We use both acoustic and linguistic features for the DID task on the Arabic dialectal speech dataset: Multi-Genre Broadcast 3 (MGB-3). The end-to-end DID system was trained using three kinds of acoustic features: Mel-Frequency Cepstral Coefficients (MFCCs), log Mel-scale Filter Bank energies (FBANK) and spectrogram energies. We also investigated a dataset augmentation approach to achieve robust performance with limited data resources. Our linguistic feature research focused on learning similarities and dissimilarities between dialects using the Siamese network, so that we can reduce feature dimensionality as well as improve DID performance. The best system using a single feature set achieves 73% accuracy, while a fusion system using multiple features yields 78% on the MGB-3 dialect test set consisting of 5 dialects. The experimental results indicate that FBANK features achieve slightly better results than MFCCs. Dataset augmentation via speed perturbation appears to add significant robustness to the system. Although the Siamese network with language embeddings did not achieve as good a result as the end-to-end DID system, the two approaches had good synergy when combined together in a fused system.","",""
143,"Vasileios Belagiannis, C. Rupprecht, G. Carneiro, Nassir Navab","Robust Optimization for Deep Regression",2015,"","","","",118,"2022-07-13 10:09:41","","10.1109/ICCV.2015.324","","",,,,,143,20.43,36,4,7,"Convolutional Neural Networks (ConvNets) have successfully contributed to improve the accuracy of regression-based methods for computer vision tasks such as human pose estimation, landmark localization, and object detection. The network optimization has been usually performed with L2 loss and without considering the impact of outliers on the training process, where an outlier in this context is defined by a sample estimation that lies at an abnormal distance from the other training sample estimations in the objective space. In this work, we propose a regression model with ConvNets that achieves robustness to such outliers by minimizing Tukey's biweight function, an M-estimator robust to outliers, as the loss function for the ConvNet. In addition to the robust loss, we introduce a coarse-to-fine model, which processes input images of progressively higher resolutions for improving the accuracy of the regressed values. In our experiments, we demonstrate faster convergence and better generalization of our robust loss function for the tasks of human pose estimation and age estimation from face images. We also show that the combination of the robust loss function with the coarse-to-fine model produces comparable or better results than current state-of-the-art approaches in four publicly available human pose estimation datasets.","",""
88,"Ulysse Côté Allard, C. Fall, A. Campeau-Lecours, C. Gosselin, François Laviolette, B. Gosselin","Transfer learning for sEMG hand gestures recognition using convolutional neural networks",2017,"","","","",119,"2022-07-13 10:09:41","","10.1109/SMC.2017.8122854","","",,,,,88,17.60,15,6,5,"In the realm of surface electromyography (sEMG) gesture recognition, deep learning algorithms are seldom employed. This is due in part to the large quantity of data required for them to train on. Consequently, it would be prohibitively time consuming for a single user to generate a sufficient amount of data for training such algorithms. In this paper, two datasets of 18 and 17 able-bodied participants respectively are recorded using a low-cost, low-sampling rate (200Hz), 8-channel, consumer-grade, dry electrode sEMG device named Myo armband (Thalmic Labs). A convolutional neural network (CNN) is augmented using transfer learning techniques to leverage inter-user data from the first dataset and alleviate the data generation burden imposed on a single individual. The results show that the proposed classifier is robust and precise enough to guide a 6DoF robotic arm (in conjunction with orientation data) with the same speed and precision as with a joystick. Furthermore, the proposed CNN achieves an average accuracy of 97.81% on seven hand/wrist gestures on the 17 participants of the second dataset.","",""
39,"G. Carneiro, J. Nascimento, A. Freitas","Robust left ventricle segmentation from ultrasound data using deep neural networks and efficient search methods",2010,"","","","",120,"2022-07-13 10:09:41","","10.1109/ISBI.2010.5490181","","",,,,,39,3.25,13,3,12,"The automatic segmentation of the left ventricle of the heart in ultrasound images has been a core research topic in medical image analysis. Most of the solutions are based on low-level segmentation methods, which uses a prior model of the appearance of the left ventricle, but imaging conditions violating the assumptions present in the prior can damage their performance. Recently, pattern recognition methods have become more robust to imaging conditions by automatically building an appearance model from training images, but they present a few challenges, such as: the need of a large set of training images, robustness to imaging conditions not present in the training data, and complex search process. In this paper we handle the second problem using the recently proposed deep neural network and the third problem with efficient searching algorithms. Quantitative comparisons show that the accuracy of our approach is higher than state-of-the-art methods. The results also show that efficient search strategies reduce ten times the run-time complexity.","",""
16,"J. P. Pandey, Devender Singh","Application of radial basis neural network for state estimation of power system networks",2010,"","","","",121,"2022-07-13 10:09:41","","10.4314/IJEST.V2I3.59169","","",,,,,16,1.33,8,2,12,"An original application of radial basis function (RBF) neural network for power system state estimation is proposed in this paper. The property of massive parallelism of neural networks is employed for this. The application of RBF neural network for state estimation is investigated by testing its applicability on a IEEE 14 bus system. The proposed estimator is compared with conventional Weighted Least Squares (WLS) State Estimator on basis of time, accuracy and robustness. It is observed that the time taken by the proposed estimator is quite low. The proposed estimator is more accurate and robust in case of gross errors and topological errors present in the measurement data.     Keywords: Radial Basis Function Neural Networks, State Estimation.","",""
45,"Siyue Wang, Xiao Wang, Pu Zhao, Wujie Wen, D. Kaeli, S. Chin, X. Lin","Defensive dropout for hardening deep neural networks under adversarial attacks",2018,"","","","",122,"2022-07-13 10:09:41","","10.1145/3240765.3264699","","",,,,,45,11.25,6,7,4,"Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That is, adversarial examples, obtained by adding delicately crafted distortions onto original legal inputs, can mislead a DNN to classify them as any target labels. This work provides a solution to hardening DNNs under adversarial attacks through defensive dropout. Besides using dropout during training for the best test accuracy, we propose to use dropout also at test time to achieve strong defense effects. We consider the problem of building robust DNNs as an attacker-defender two-player game, where the attacker and the defender know each others' strategies and try to optimize their own strategies towards an equilibrium. Based on the observations of the effect of test dropout rate on test accuracy and attack success rate, we propose a defensive dropout algorithm to determine an optimal test dropout rate given the neural network model and the attacker's strategy for generating adversarial examples. We also investigate the mechanism behind the outstanding defense effects achieved by the proposed defensive dropout. Comparing with stochastic activation pruning (SAP), another defense method through introducing randomness into the DNN model, we find that our defensive dropout achieves much larger variances of the gradients, which is the key for the improved defense effects (much lower attack success rate). For example, our defensive dropout can reduce the attack success rate from 100% to 13.89% under the currently strongest attack i.e., C&W attack on MNIST dataset.","",""
115,"V. B. Semwal, K. Mondal, G. Nandi","Robust and accurate feature selection for humanoid push recovery and classification: deep learning approach",2017,"","","","",123,"2022-07-13 10:09:41","","10.1007/s00521-015-2089-3","","",,,,,115,23.00,38,3,5,"","",""
45,"K. Grill-Spector, K. Weiner, Jesse Gomez, Anthony Stigliani, Vaidehi S. Natu","The functional neuroanatomy of face perception: from brain measurements to deep neural networks",2018,"","","","",124,"2022-07-13 10:09:41","","10.1098/rsfs.2018.0013","","",,,,,45,11.25,9,5,4,"A central goal in neuroscience is to understand how processing within the ventral visual stream enables rapid and robust perception and recognition. Recent neuroscientific discoveries have significantly advanced understanding of the function, structure and computations along the ventral visual stream that serve as the infrastructure supporting this behaviour. In parallel, significant advances in computational models, such as hierarchical deep neural networks (DNNs), have brought machine performance to a level that is commensurate with human performance. Here, we propose a new framework using the ventral face network as a model system to illustrate how increasing the neural accuracy of present DNNs may allow researchers to test the computational benefits of the functional architecture of the human brain. Thus, the review (i) considers specific neural implementational features of the ventral face network, (ii) describes similarities and differences between the functional architecture of the brain and DNNs, and (iii) provides a hypothesis for the computational value of implementational features within the brain that may improve DNN performance. Importantly, this new framework promotes the incorporation of neuroscientific findings into DNNs in order to test the computational benefits of fundamental organizational features of the visual system.","",""
81,"Michele Mancini, G. Costante, P. Valigi, T. A. Ciarfuglia","Fast robust monocular depth estimation for Obstacle Detection with fully convolutional networks",2016,"","","","",125,"2022-07-13 10:09:41","","10.1109/IROS.2016.7759632","","",,,,,81,13.50,20,4,6,"Obstacle Detection is a central problem for any robotic system, and critical for autonomous systems that travel at high speeds in unpredictable environment. This is often achieved through scene depth estimation, by various means. When fast motion is considered, the detection range must be longer enough to allow for safe avoidance and path planning. Current solutions often make assumption on the motion of the vehicle that limit their applicability, or work at very limited ranges due to intrinsic constraints. We propose a novel appearance-based Object Detection system that is able to detect obstacles at very long range and at a very high speed (~ 300Hz), without making assumptions on the type of motion. We achieve these results using a Deep Neural Network approach trained on real and synthetic images and trading some depth accuracy for fast, robust and consistent operation. We show how photo-realistic synthetic images are able to solve the problem of training set dimension and variety typical of machine learning approaches, and how our system is robust to massive blurring of test images.","",""
39,"Hythem Sidky, J. Whitmer","Learning free energy landscapes using artificial neural networks.",2017,"","","","",126,"2022-07-13 10:09:41","","10.1063/1.5018708","","",,,,,39,7.80,20,2,5,"Existing adaptive bias techniques, which seek to estimate free energies and physical properties from molecular simulations, are limited by their reliance on fixed kernels or basis sets which hinder their ability to efficiently conform to varied free energy landscapes. Further, user-specified parameters are in general non-intuitive yet significantly affect the convergence rate and accuracy of the free energy estimate. Here we propose a novel method, wherein artificial neural networks (ANNs) are used to develop an adaptive biasing potential which learns free energy landscapes. We demonstrate that this method is capable of rapidly adapting to complex free energy landscapes and is not prone to boundary or oscillation problems. The method is made robust to hyperparameters and overfitting through Bayesian regularization which penalizes network weights and auto-regulates the number of effective parameters in the network. ANN sampling represents a promising innovative approach which can resolve complex free energy landscapes in less time than conventional approaches while requiring minimal user input.","",""
89,"F. Feng, Chao Zhang, Jianguo Ma, Qi-jun Zhang","Parametric Modeling of EM Behavior of Microwave Components Using Combined Neural Networks and Pole-Residue-Based Transfer Functions",2016,"","","","",127,"2022-07-13 10:09:41","","10.1109/TMTT.2015.2504099","","",,,,,89,14.83,22,4,6,"This paper proposes an advanced technique to develop combined neural network and pole-residue-based transfer function models for parametric modeling of electromagnetic (EM) behavior of microwave components. In this technique, neural networks are trained to learn the relationship between pole/residues of the transfer functions and geometrical parameters. The order of the pole-residue transfer function may vary over different regions of geometrical parameters. We develop a pole-residue tracking technique to solve this order-changing problem. After the proposed modeling process, the trained model can be used to provide accurate and fast prediction of the EM behavior of microwave components with geometrical parameters as variables. The proposed method can obtain better accuracy in challenging applications involving high dimension of geometrical parameter space and large geometrical variations, compared with conventional modeling methods. The proposed technique is effective and robust especially in solving high-order problems. This technique is illustrated by three examples of EM parametric modeling.","",""
35,"A. Vo, Hee-Jun Kang","An Adaptive Neural Non-Singular Fast-Terminal Sliding-Mode Control for Industrial Robotic Manipulators",2018,"","","","",128,"2022-07-13 10:09:41","","10.3390/APP8122562","","",,,,,35,8.75,18,2,4,"In this study, a robust control strategy is suggested for industrial robotic manipulators. First, to minimize the effects of disturbances and dynamic uncertainties, while achieving faster response times and removing the singularity problem, a nonsingular fast terminal sliding function is proposed. Second, to achieve the proposed tracking trajectory and chattering phenomenon elimination, a robust control strategy is designed for the robotic manipulator based on the proposed sliding function and a continuous adaptive control law. Furthermore, the dynamical model of the robotic system is estimated by applying a radial basis function neural network. Thanks to those techniques, the proposed system can operate free of an exact robotic model. The suggested system provides high tracking accuracy, robustness, and fast response with minimal positional errors compared to other control strategies. Proof of the robustness and stability of the suggested system has been verified by the Lyapunov theory. In simulation analyses, the simulated results present the effectiveness of the suggested strategy for the joint position tracking control of a 3-degree of freedom (3-DOF) PUMA560 robot.","",""
30,"B. Jia, K. Pham, Erik Blasch, Zhonghai Wang, Dan Shen, Genshe Chen","Space object classification using deep neural networks",2018,"","","","",129,"2022-07-13 10:09:41","","10.1109/AERO.2018.8396567","","",,,,,30,7.50,5,6,4,"Space object classification is desired for space situational awareness to be able to discern resident space object (RSO) characteristics, behaviors, and perspective changes. Due to the limited sensing resources and observations, it is challenging for space object classification to be responsive to unfolding and unexpected events. Many machine learning algorithms are already used to classify space objects based on various sensor observations from radar and telescope. In this paper, the use of deep neural networks (DNN) is proposed to classify space objects due to DNN robust performance in many classification tasks, such as face recognition and object recognition. This paper explores DNN using light curve data. Conventional classification algorithms, such as k nearest neighbor (k-NN), are implemented and compared to the proposed DNN based classification algorithms, including the popular convolutional neural network (CNN) and the recurrent neural network (RNN), in terms of accuracy. Inherent advantages and disadvantages of the deep neural network based classification algorithms are summarized and the potential for future space object classification tasks is analyzed and postulated.","",""
74,"Anbang Yao, Dongqi Cai, Ping Hu, Shandong Wang, Liang Sha, Yurong Chen","HoloNet: towards robust emotion recognition in the wild",2016,"","","","",130,"2022-07-13 10:09:41","","10.1145/2993148.2997639","","",,,,,74,12.33,12,6,6,"In this paper, we present HoloNet, a well-designed Convolutional Neural Network (CNN) architecture regarding our submissions to the video based sub-challenge of the Emotion Recognition in the Wild (EmotiW) 2016 challenge. In contrast to previous related methods that usually adopt relatively simple and shallow neural network architectures to address emotion recognition task, our HoloNet has three critical considerations in network design. (1) To reduce redundant filters and enhance the non-saturated non-linearity in the lower convolutional layers, we use a modified Concatenated Rectified Linear Unit (CReLU) instead of ReLU. (2) To enjoy the accuracy gain from considerably increased network depth and maintain efficiency, we combine residual structure and CReLU to construct the middle layers. (3) To broaden network width and introduce multi-scale feature extraction property, the topper layers are designed as a variant of inception-residual structure. The main benefit of grouping these modules into the HoloNet is that both negative and positive phase information implicitly contained in the input data can flow over it in multiple paths, thus deep multi-scale features explicitly capturing emotion variation can be well extracted from multi-path sibling layers, and then can be further concatenated for robust recognition. We obtain competitive results in this year’s video based emotion recognition sub-challenge using an ensemble of two HoloNet models trained with given data only. Specifically, we obtain a mean recognition rate of 57.84%, outperforming the baseline accuracy with an absolute margin of 17.37%, and yielding 4.04% absolute accuracy gain compared to the result of last year’s winner team. Meanwhile, our method runs with a speed of several thousands of frames per second on a GPU, thus it is well applicable to real-time scenarios.","",""
226,"Dong Yu, M. Seltzer, Jinyu Li, J. Huang, F. Seide","Feature Learning in Deep Neural Networks - Studies on Speech Recognition Tasks.",2013,"","","","",131,"2022-07-13 10:09:41","","","","",,,,,226,25.11,45,5,9,"Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper, we argue that the improved accuracy achieved by the DNNs is the result of their ability to extract discriminative internal representations that are robust to the many sources of variability in speech signals. We show that these representations become increasingly insensitive to small perturbations in the input with increasing network depth, which leads to better speech recognition performance with deeper networks. We also show that DNNs cannot extrapolate to test samples that are substantially different from the training examples. If the training data are sufficiently representative, however, internal features learned by the DNN are relatively stable with respect to speaker differences, bandwidth differences, and environment distortion. This enables DNN-based recognizers to perform as well or better than state-of-the-art systems based on GMMs or shallow networks without the need for explicit model adaptation or feature normalization.","",""
34,"René Schuster, Oliver Wasenmüller, C. Unger, D. Stricker","SDC – Stacked Dilated Convolution: A Unified Descriptor Network for Dense Matching Tasks",2019,"","","","",132,"2022-07-13 10:09:41","","10.1109/CVPR.2019.00266","","",,,,,34,11.33,9,4,3,"Dense pixel matching is important for many computer vision tasks such as disparity and flow estimation. We present a robust, unified descriptor network that considers a large context region with high spatial variance. Our network has a very large receptive field and avoids striding layers to maintain spatial resolution. These properties are achieved by creating a novel neural network layer that consists of multiple, parallel, stacked dilated convolutions (SDC). Several of these layers are combined to form our SDC descriptor network. In our experiments, we show that our SDC features outperform state-of-the-art feature descriptors in terms of accuracy and robustness. In addition, we demonstrate the superior performance of SDC in state-of-the-art stereo matching, optical flow and scene flow algorithms on several famous public benchmarks.","",""
62,"Yuan Yao, Zhi-guo Jiang, Haopeng Zhang, Danpei Zhao, Bowen Cai","Ship detection in optical remote sensing images based on deep convolutional neural networks",2017,"","","","",133,"2022-07-13 10:09:41","","10.1117/1.JRS.11.042611","","",,,,,62,12.40,12,5,5,"Abstract. Automatic ship detection in optical remote sensing images has attracted wide attention for its broad applications. Major challenges for this task include the interference of cloud, wave, wake, and the high computational expenses. We propose a fast and robust ship detection algorithm to solve these issues. The framework for ship detection is designed based on deep convolutional neural networks (CNNs), which provide the accurate locations of ship targets in an efficient way. First, the deep CNN is designed to extract features. Then, a region proposal network (RPN) is applied to discriminate ship targets and regress the detection bounding boxes, in which the anchors are designed by intrinsic shape of ship targets. Experimental results on numerous panchromatic images demonstrate that, in comparison with other state-of-the-art ship detection methods, our method is more efficient and achieves higher detection accuracy and more precise bounding boxes in different complex backgrounds.","",""
57,"Inam Shamsher, Zaheer Ahmad, Jehanzeb Khan Orakzai, A. Adnan","OCR For Printed Urdu Script Using Feed Forward Neural Network",2007,"","","","",134,"2022-07-13 10:09:41","","","","",,,,,57,3.80,14,4,15,"This paper deals with an Optical Character Recognition system for printed Urdu, a popular Pakistani/Indian script and is the third largest understandable language in the world, especially in the subcontinent but fewer efforts are made to make it understandable to computers. Lot of work has been done in the field of literature and Islamic studies in Urdu, which has to be computerized. In the proposed system individual characters are recognized using our own proposed method/ algorithms. The feature detection methods are simple and robust. Supervised learning is used to train the feed forward neural network. A prototype of the system has been tested on printed Urdu characters and currently achieves 98.3% character level accuracy on average .Although the system is script/ language independent but we have designed it for Urdu characters only.","",""
490,"Evgeny Byvatov, U. Fechner, J. Sadowski, G. Schneider","Comparison of Support Vector Machine and Artificial Neural Network Systems for Drug/Nondrug Classification",2003,"","","","",135,"2022-07-13 10:09:41","","10.1021/ci0341161","","",,,,,490,25.79,123,4,19,"Support vector machine (SVM) and artificial neural network (ANN) systems were applied to a drug/nondrug classification problem as an example of binary decision problems in early-phase virtual compound filtering and screening. The results indicate that solutions obtained by SVM training seem to be more robust with a smaller standard error compared to ANN training. Generally, the SVM classifier yielded slightly higher prediction accuracy than ANN, irrespective of the type of descriptors used for molecule encoding, the size of the training data sets, and the algorithm employed for neural network training. The performance was compared using various different descriptor sets and descriptor combinations based on the 120 standard Ghose-Crippen fragment descriptors, a wide range of 180 different properties and physicochemical descriptors from the Molecular Operating Environment (MOE) package, and 225 topological pharmacophore (CATS) descriptors. For the complete set of 525 descriptors cross-validated classification by SVM yielded 82% correct predictions (Matthews cc = 0.63), whereas ANN reached 80% correct predictions (Matthews cc = 0.58). Although SVM outperformed the ANN classifiers with regard to overall prediction accuracy, both methods were shown to complement each other, as the sets of true positives, false positives (overprediction), true negatives, and false negatives (underprediction) produced by the two classifiers were not identical. The theory of SVM and ANN training is briefly reviewed.","",""
51,"R. Bettocchi, M. Pinelli, P. R. Spina, M. Venturini","Artificial Intelligence for the Diagnostics of Gas Turbines—Part I: Neural Network Approach",2007,"","","","",136,"2022-07-13 10:09:41","","10.1115/1.2431391","","",,,,,51,3.40,13,4,15,"In the paper, neural network (NN) models for gas turbine diagnostics are studied and developed. The analyses carried out are aimed at the selection of the most appropriate NN structure for gas turbine diagnostics, in terms of computational time of the NN training phase, accuracy, and robustness with respect to measurement uncertainty. In particular, feed-forward NNs with a single hidden layer trained by using a back-propagation learning algorithm are considered and tested. Moreover, multi-input/ multioutput NN architectures (i.e., NNs calculating all the system outputs) are compared to multi-input/single-output NNs, each of them calculating a single output of the system. The results obtained show that NNs are sufficiently robust with respect to measurement uncertainty, if a sufficient number of training patterns are used. Moreover, multi-input/ multioutput NNs trained with data corrupted with measurement errors seem to be the best compromise between the computational time required for NN training phase and the NN accuracy in performing gas turbine diagnostics.","",""
19,"Jegor Uglov, L. Jakaite, V. Schetinin, C. Maple","Comparing Robustness of Pairwise and Multiclass Neural-Network Systems for Face Recognition",2007,"","","","",137,"2022-07-13 10:09:41","","10.1155/2008/468693","","",,,,,19,1.27,5,4,15,"Noise, corruptions, and variations in face images can seriously hurt the performance of face-recognition systems. To make these systems robust to noise and corruptions in image data, multiclass neural networks capable of learning from noisy data have been suggested. However on large face datasets such systems cannot provide the robustness at a high level. In this paper, we explore a pairwise neural-network system as an alternative approach to improve the robustness of face recognition. In our experiments, the pairwise recognition system is shown to outperform the multiclass-recognition system in terms of the predictive accuracy on the test face images.","",""
45,"S. Barai, A. Dikshit, Sameer Sharma","Neural Network Models for Air Quality Prediction: A Comparative Study",2007,"","","","",138,"2022-07-13 10:09:41","","10.1007/978-3-540-70706-6_27","","",,,,,45,3.00,15,3,15,"","",""
49,"Takaaki Hori, Zhuo Chen, Hakan Erdogan, J. Hershey, Jonathan Le Roux, V. Mitra, Shinji Watanabe","The MERL/SRI system for the 3RD CHiME challenge using beamforming, robust feature extraction, and advanced speech recognition",2015,"","","","",139,"2022-07-13 10:09:41","","10.1109/ASRU.2015.7404833","","",,,,,49,7.00,7,7,7,"This paper introduces the MERL/SRI system designed for the 3rd CHiME speech separation and recognition challenge (CHiME-3). Our proposed system takes advantage of recurrent neural networks (RNNs) throughout the model from the front speech enhancement to the language modeling. Two different types of beamforming are used to combine multi-microphone signals to obtain a single higher quality signal. Beamformed signal is further processed by a single-channel bi-directional long short-term memory (LSTM) enhancement network which is used to extract stacked mel-frequency cepstral coefficients (MFCC) features. In addition, two proposed noise-robust feature extraction methods are used with the beamformed signal. The features are used for decoding in speech recognition systems with deep neural network (DNN) based acoustic models and large-scale RNN language models to achieve high recognition accuracy in noisy environments. Our training methodology includes data augmentation and speaker adaptive training, whereas at test time model combination is used to improve generalization. Results on the CHiME-3 benchmark show that the full cadre of techniques substantially reduced the word error rate (WER). Combining hypotheses from different robust-feature systems ultimately achieved 9.10% WER for the real test data, a 72.4% reduction relative to the baseline of 32.99% WER.","",""
34,"T. Le, Chenchen Zhu, Yutong Zheng, Khoa Luu, M. Savvides","Robust hand detection in Vehicles",2016,"","","","",140,"2022-07-13 10:09:41","","10.1109/ICPR.2016.7899695","","",,,,,34,5.67,7,5,6,"The problems of hand detection have been widely addressed in many areas, e.g. human computer interaction environment, driver behaviors monitoring, etc. However, the detection accuracy in recent hand detection systems are still far away from the demands in practice due to a number of challenges, e.g. hand variations, highly occlusions, low-resolution and strong lighting conditions. This paper presents the Multiple Scale Faster Region-based Convolutional Neural Network (MS-FRCNN) to handle the problems of hand detection in given digital images collected under challenging conditions. Our proposed method introduces a multiple scale deep feature extraction approach in order to handle the challenging factors to provide a robust hand detection algorithm. The method is evaluated on the challenging hand database, i.e. the Vision for Intelligent Vehicles and Applications (VIVA) Challenge, and compared against various recent hand detection methods. Our proposed method achieves the state-of-the-art results with 20% of the detection accuracy higher than the second best one in the VIVA challenge.","",""
120,"Hui Hu, P. Woo","Fuzzy supervisory sliding-mode and neural-network control for robotic manipulators",2006,"","","","",141,"2022-07-13 10:09:41","","10.1109/TIE.2006.874261","","",,,,,120,7.50,60,2,16,"Highly nonlinear, highly coupled, and time-varying robotic manipulators suffer from structured and unstructured uncertainties. Sliding-mode control (SMC) is effective in overcoming uncertainties and has a fast transient response, while the control effort is discontinuous and creates chattering. The neural network has an inherent ability to learn and approximate a nonlinear function to arbitrary accuracy, which is used in the controllers to model complex processes and compensate for unstructured uncertainties. However, the unavoidable learning procedure degrades its transient performance in the presence of disturbance. A novel approach is presented to overcome their demerits and take advantage of their attractive features of robust and intelligent control. The proposed control scheme combines the SMC and the neural-network control (NNC) with different weights, which are determined by a fuzzy supervisory controller. This novel scheme is named fuzzy supervisory sliding-mode and neural-network control (FSSNC). The convergence and stability of the proposed control system are proved by using Lyapunov's direct method. Simulations for different situations demonstrate its robustness with satisfactory performance.","",""
315,"A. Tatem, H. Lewis, P. Atkinson, M. Nixon","Super-resolution target identification from remotely sensed images using a Hopfield neural network",2001,"","","","",142,"2022-07-13 10:09:41","","10.1109/36.917895","","",,,,,315,15.00,79,4,21,"Fuzzy classification techniques have been developed recently to estimate the class composition of image pixels, but their output provides no indication of how these classes are distributed spatially within the instantaneous field of view represented by the pixel. As such, while the accuracy of land cover target identification has been improved using fuzzy classification, it remains for robust techniques that provide better spatial representation of land cover to be developed. Such techniques could provide more accurate land cover metrics for determining social or environmental policy, for example. The use of a Hopfield neural network to map the spatial distribution of classes more reliably using prior information of pixel composition determined from fuzzy classification was investigated. An approach was adopted that used the output from a fuzzy classification to constrain a Hopfield neural network formulated as an energy minimization tool. The network converges to a minimum of an energy function, defined as a goal and several constraints. Extracting the spatial distribution of target class components within each pixel was, therefore, formulated as a constraint satisfaction problem with an optimal solution determined by the minimum of the energy function. This energy minimum represents a ""best guess"" map of the spatial distribution of class components in each pixel. The technique was applied to both synthetic and simulated Landsat TM imagery, and the resultant maps provided an accurate and improved representation of the land covers studied, with root mean square errors (RMSEs) for Landsat imagery of the order of 0.09 pixels in the new fine resolution image recorded.","",""
31,"Egor Lakomkin, C. Weber, S. Magg, S. Wermter","Reusing Neural Speech Representations for Auditory Emotion Recognition",2017,"","","","",143,"2022-07-13 10:09:41","","","","",,,,,31,6.20,8,4,5,"Acoustic emotion recognition aims to categorize the affective state of the speaker and is still a difficult task for machine learning models. The difficulties come from the scarcity of training data, general subjectivity in emotion perception resulting in low annotator agreement, and the uncertainty about which features are the most relevant and robust ones for classification. In this paper, we will tackle the latter problem. Inspired by the recent success of transfer learning methods we propose a set of architectures which utilize neural representations inferred by training on large speech databases for the acoustic emotion recognition task. Our experiments on the IEMOCAP dataset show ~10% relative improvements in the accuracy and F1-score over the baseline recurrent neural network which is trained end-to-end for emotion recognition.","",""
48,"Yi Cao, R. Ding, Qi-jun Zhang","State-space dynamic neural network technique for high-speed IC applications: modeling and stability analysis",2006,"","","","",144,"2022-07-13 10:09:41","","10.1109/TMTT.2006.875297","","",,,,,48,3.00,16,3,16,"We present a state-space dynamic neural network (SSDNN) method for modeling the transient behaviors of high-speed nonlinear circuits. The SSDNN technique extends the existing dynamic neural network (DNN) approaches into a more generalized and robust formulation. For the first time, stability analysis methods are presented for neural modeling of nonlinear microwave circuits. We derive the stability criteria for both the local stability and global stability of SSDNN models. Stability test matrices are formulated from SSDNN internal weight parameters. The proposed criteria can be conveniently applied to the stability verification of a trained SSDNN model using the eigenvalues of the test matrices. In addition, a new constrained training algorithm is introduced by formulating the proposed stability criteria as training constraints such that the resulting SSDNN models satisfy both the accuracy and stability requirements. The validity of the proposed technique is demonstrated through the transient modeling of high-speed interconnect driver and receiver circuits and the stability verifications of the obtained SSDNN models","",""
62,"Shuo-yiin Chang, N. Morgan","Robust CNN-based speech recognition with Gabor filter kernels",2014,"","","","",145,"2022-07-13 10:09:41","","","","",,,,,62,7.75,31,2,8,"As has been extensively shown, acoustic features for speech recognition can be learned from neural networks with multiple hidden layers. However, the learned transformations may not sufficiently generalize to test sets that have a significant mismatch to the training data. Gabor features, on the other hand, are generated from spectro-temporal filters designed to model human auditory processing. In previous work, these features are used as inputs to neural networks, which improved word accuracy for speech recognition in the presence of noise. Here we propose a neural network architecture called a Gabor Convolutional Neural Network (GCNN) that incorporates Gabor functions into convolutional filter kernels. In this architecture, a variety of Gabor features served as the multiple feature maps of the convolutional layer. The filter coefficients are further tuned by back-propagation training. Experiments used two noisy versions of the WSJ corpus: Aurora 4, and RATS re-noised WSJ. In both cases, the proposed architecture performs better than other noise-robust features that we have tried, namely, ETSI-AFE, PNCC, Gabor features without the CNN-based approach, and our best neural network features that don’t incorporate Gabor functions.","",""
26,"Suyoun Kim, B. Raj, I. Lane","Environmental Noise Embeddings for Robust Speech Recognition",2016,"","","","",146,"2022-07-13 10:09:41","","","","",,,,,26,4.33,9,3,6,"We propose a novel deep neural network architecture for speech recognition that explicitly employs knowledge of the background environmental noise within a deep neural network acoustic model. A deep neural network is used to predict the acoustic environment in which the system in being used. The discriminative embedding generated at the bottleneck layer of this network is then concatenated with traditional acoustic features as input to a deep neural network acoustic model. Through a series of experiments on Resource Management, CHiME-3 task, and Aurora4, we show that the proposed approach significantly improves speech recognition accuracy in noisy and highly reverberant environments, outperforming multi-condition training, noise-aware training, i-vector framework, and multi-task learning on both in-domain noise and unseen noise.","",""
213,"R. Setiono, L. Hui","Use of a quasi-Newton method in a feedforward neural network construction algorithm",1995,"","","","",147,"2022-07-13 10:09:41","","10.1109/72.363426","","",,,,,213,7.89,107,2,27,"This paper describes an algorithm for constructing a single hidden layer feedforward neural network. A distinguishing feature of this algorithm is that it uses the quasi-Newton method to minimize the sequence of error functions associated with the growing network. Experimental results indicate that the algorithm is very efficient and robust. The algorithm was tested on two test problems. The first was the n-bit parity problem and the second was the breast cancer diagnosis problem from the University of Wisconsin Hospitals. For the n-bit parity problem, the algorithm was able to construct neural network having less than n hidden units that solved the problem for n=4,...,7. For the cancer diagnosis problem, the neural networks constructed by the algorithm had small number of hidden units and high accuracy rates on both the training data and the testing data.","",""
32,"Jianming Lian, Yonggon Lee, S. Żak","Variable Neural Direct Adaptive Robust Control of Uncertain Systems",2008,"","","","",148,"2022-07-13 10:09:41","","10.1109/TAC.2008.2007149","","",,,,,32,2.29,11,3,14,"Direct adaptive robust state and output feedback controllers are proposed for the output tracking control of a class of uncertain systems. The proposed controllers incorporate a variable structure radial basis function (RBF) network to approximate unknown system dynamics, where the RBF network can determine its structure online dynamically. Radial basis functions can be added or removed to ensure the desired tracking accuracy and to prevent the network redundancy simultaneously. The closed-loop systems driven by the direct adaptive robust controllers are characterized by the guaranteed transient and steady-state tracking performance. The performance of the proposed output feedback controller is illustrated with numerical simulations.","",""
95,"Muzammal Naseer, Kanchana Ranasinghe, S. Khan, Munawar Hayat, F. Khan, Ming-Hsuan Yang","Intriguing Properties of Vision Transformers",2021,"","","","",149,"2022-07-13 10:09:41","","","","",,,,,95,95.00,16,6,1,"Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can flexibly attend to a sequence of image patches to encode contextual cues. An important question is how such flexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a) Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1 accuracy on ImageNet even after randomly occluding 80% of the image content. (b) The robustness towards occlusions is not due to texture bias, instead we show that ViTs are significantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c) Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d) Off-the-shelf features from a single ViT model can be combined to create a feature ensemble, leading to high accuracy rates across a range of classification datasets in both traditional and few-shot learning paradigms. We show effective features of ViTs are due to flexible and dynamic receptive fields possible via self-attention mechanisms. Code: https://git.io/Js15X","",""
46,"N. Iannella, A. Back","A spiking neural network architecture for nonlinear function approximation",1999,"","","","",150,"2022-07-13 10:09:41","","10.1109/NNSP.1999.788132","","",,,,,46,2.00,23,2,23,"Multilayer perceptrons have received much attention due to their universal approximation capabilities. Normally such models use real valued signals, although they are loosely based on biological neuronal networks which encode signals using spike trains. Spiking neural networks are of interest from both a biological point of view, but also from a method of robust signalling in particularly noisy or difficult environments. From a signal processing perspective, it is important to consider networks based on spike trains. A basic question that needs to be considered, is what type of architecture can be used to provide universal function approximation capabilities in spiking networks? We propose a spiking neural network architecture using both integrate and fire units as well as delays which is capable of approximating a real valued function mapping to within a finite degree of accuracy.","",""
17,"H. Sarnel, Y. Senol","Accurate and robust image registration based on radial basis neural networks",2008,"","","","",151,"2022-07-13 10:09:41","","10.1007/s00521-011-0564-z","","",,,,,17,1.21,9,2,14,"","",""
43,"D. Akhmetov, Y. Dote, S. Ovaska","Fuzzy neural network with general parameter adaptation for modeling of nonlinear time-series",2001,"","","","",152,"2022-07-13 10:09:41","","10.1109/72.896803","","",,,,,43,2.05,14,3,21,"By taking advantage of fuzzy systems and neural networks, a fuzzy-neural network with a general parameter (GP) learning algorithm and heuristic model structure determination is proposed in this paper. Our network model is based on the Gaussian radial basis function network (RBFN). We use the flexible GP approach both for initializing the off-line training algorithm and fine-tuning the nonlinear model efficiently in online operation. A modification of the robust unbiasedness criterion using distorter (UCD) is utilized for selecting the structural parameters of this adaptive model. The UCD approach provides the desired modeling accuracy and avoids the risk of over-fitting. In order to illustrate the operation of the proposed modeling scheme, it is experimentally applied to a fault detection application.","",""
20,"Chin-Teng Lin, S.F. Liang, Chang-Moun Yeh, K. Fan","Fuzzy neural network design using support vector regression for function approximation with outliers",2005,"","","","",153,"2022-07-13 10:09:41","","10.1109/ICSMC.2005.1571568","","",,,,,20,1.18,5,4,17,"A fuzzy neural network based on support vector learning mechanism for function approximation is proposed in this paper. Support vector regression (SVR) is a novel method for tackling the problems of function approximation and regression estimation based on the statistical learning theory. SVR has been shown to have robust properties against noise. A novel support-vector-regression based fuzzy neural network (SVRFNN) by integrating SVR technology into FNN is developed. The SVRFNN combines the high accuracy and robustness of support vector regression (SVR) and the efficient human-like reasoning of FNN for function approximation. Experimental results show that the proposed SVFNN for function approximation can achieve good approximation performance with drastically reduced number of fuzzy kernel functions.","",""
70,"A. Kamari, Abbas Khaksar-Manshad, F. Gharagheizi, A. Mohammadi, S. Ashoori","Robust Model for the Determination of Wax Deposition in Oil Systems",2013,"","","","",154,"2022-07-13 10:09:41","","10.1021/IE402462Q","","",,,,,70,7.78,14,5,9,"Wax deposition is a serious problem during oil production in the petroleum industry. Therefore, accurate prediction of this solid deposition problem can result in increasing the efficiency of oil/gas production. In this article, a novel approach is proposed to develop a predictive model for the estimation of wax deposition. An intelligent reliable model is proposed using a robust soft computing approach, namely, least-squares support vector machine (LSSVM) modeling optimized with the coupled simulated annealing (CSA) optimization approach. Our results demonstrate that there is good agreement between predictions based on the CSA-LSSVM model and experimental data on wax deposition. Furthermore, the performance of the newly developed model is compared with the performance of neural network and multisolid models for predicting wax deposition. The results of this comparison indicate that the proposed method is superior, in terms of both accuracy and generality, to the neural network and multisolid models. Fina...","",""
54,"Alexander Grushin, Derek Monner, J. Reggia, A. Mishra","Robust human action recognition via long short-term memory",2013,"","","","",155,"2022-07-13 10:09:41","","10.1109/IJCNN.2013.6706797","","",,,,,54,6.00,14,4,9,"The long short-term memory (LSTM) neural network utilizes specialized modulation mechanisms to store information for extended periods of time. It is thus potentially well-suited for complex visual processing, where the current video frame must be considered in the context of past frames. Recent studies have indeed shown that LSTM can effectively recognize and classify human actions (e.g., running, hand waving) in video data; however, these results were achieved under somewhat restricted settings. In this effort, we seek to demonstrate that LSTM's performance remains robust even as experimental conditions deteriorate. Specifically, we show that classification accuracy exhibits graceful degradation when the LSTM network is faced with (a) lower quantities of available training data, (b) tighter deadlines for decision making (i.e., shorter available input data sequences) and (c) poorer video quality (resulting from noise, dropped frames or reduced resolution). We also clearly demonstrate the benefits of memory for video processing, particularly, under high noise or frame drop rates. Our study is thus an initial step towards demonstrating LSTM's potential for robust action recognition in real-world scenarios.","",""
18,"Xin Ma, Wei Liu, Yibin Li, R. Song","LVQ neural network based target differentiation method for mobile robot",2005,"","","","",156,"2022-07-13 10:09:41","","10.1109/ICAR.2005.1507482","","",,,,,18,1.06,5,4,17,"This paper presents a LVQ (learning vector quantization) neural network based target differentiation method for mobile robots. The typical targets can be differentiated efficiently in indoor environments with LVQ neural network by fusing the time-of-flight data and amplitude data of sonar system. The algorithm is simple and real-time and has high accuracy and robustness. The uncertainty of sonar data can be effectively dealt with the method and mobile robots can classify the targets quickly and reliably in indoor environments. In simulation experiments, a hierarchical configuration is adopted and the sonar data is preprocessed before inputted to neural network to improve the differentiation performance of LVQ network farther. The simulation experiments prove that the algorithm is effective and robust","",""
28,"Weihua Song, V. Phoha","Neural network-based reputation model in a distributed system",2004,"","","","",157,"2022-07-13 10:09:41","","10.1109/ICECT.2004.1319751","","",,,,,28,1.56,14,2,18,"Current centralized trust models are inappropriate to apply in a large distributed multi-agent system, due to various evaluation models and partial observations in local level reputation management. This paper proposes a distributed reputation management structure, and develops a global reputation model. The global reputation model is a novel application of neural network techniques in distributed reputation evaluations. The experimental results showed that the model has robust performance under various estimation accuracy requirements. More important, the model is adaptive to changes in distributed system structures and in local reputation evaluations.","",""
41,"D.C. Park, Yan-Hai Zhu","Bilinear recurrent neural network",1994,"","","","",158,"2022-07-13 10:09:41","","10.1109/ICNN.1994.374501","","",,,,,41,1.46,21,2,28,"A recurrent neural network and its training algorithm are proposed in this paper. Since the proposed algorithm is based on the bilinear polynomial, it can model many nonlinear systems with much more parsimony than the higher order neural networks based on Volterra series. The proposed bilinear recurrent neural network (BLRNN) is compared with multilayer perceptron neural networks (MLPNN) for time series prediction problems. The results show that the BLRNN is robust and outperforms the MLPNN in terms of prediction accuracy.<<ETX>>","",""
35,"B. Barshan, B. Ayrulu, S. Utete","Neural network-based target differentiation using sonar for robotics applications",2000,"","","","",159,"2022-07-13 10:09:41","","10.1109/70.864239","","",,,,,35,1.59,12,3,22,"This study investigates the processing of sonar signals using neural networks for robust differentiation of commonly encountered features in indoor environments. The neural network can differentiate more targets, and achieves high differentiation and localization accuracy, improving on previously reported methods. It achieves this by exploiting the identifying features in the differential amplitude and time-of-flight characteristics of these targets. An important observation follows from the robustness tests, which indicate that the amplitude information is more crucial than time-of-flight for reliable operation. The study suggests wider use of neural networks and amplitude information in sonar-based mobile robotics.","",""
26,"Lina Wang, Ge Yu, Guoren Wang, Dong Wang","Method of evolutionary neural network-based intrusion detection",2001,"","","","",160,"2022-07-13 10:09:41","","10.1109/ICII.2001.983487","","",,,,,26,1.24,7,4,21,"Intrusion detection is an important defence to protect the security of computer network systems. With an integrated technique of genetic algorithm and neural network, a method of evolutionary neural networks is proposed to perform intrusion detection in this paper. It is a robust enough, parallel and nonlinear dynamic processing system to satisfy requirements of real-time processing and prediction with high accuracy. With the new method, the structure of the neural network is optimized using a genetic algorithm. The obtained neural network model is thus used for intrusion detection and prealarm with high accuracy.","",""
40,"N. Wilson, Kwee S. Chong, M. Peel, A. N. Kolmogorov","Neural Network Simulation and the Prediction of Corporate Outcomes: Some Empirical Findings",1995,"","","","",161,"2022-07-13 10:09:41","","10.1080/758521095","","",,,,,40,1.48,10,4,27,"Neural Networks (NN's) involve an innovative method of simulating and analysing complex and constantly changing systems of relationships. Originally developed to mimic the neural architecture and functioning of the human brain, NN techniques have recently been applied to many different business fields and have demonstrated a capability to solve complex problems. This paper investigates the use of NN techniques as a tool for the modelling and prediction of corporate bankruptcy and other corporate outcomes. The within and out-of-sample accuracy of trained NNs are compared with those of standard logit and multilogit techniques. The results of the study suggest that, from a pure predictive point of view, NN simulation produces a higher predictive accuracy and is more robust than conventional logit and multilogit models.","",""
4860,"Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun","Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition",2014,"","","","",162,"2022-07-13 10:09:41","","10.1007/978-3-319-10578-9_23","","",,,,,4860,607.50,1215,4,8,"","",""
45,"Gary B. Huang, Viren Jain","Deep and Wide Multiscale Recursive Networks for Robust Image Labeling",2013,"","","","",163,"2022-07-13 10:09:41","","","","",,,,,45,5.00,23,2,9,"Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these ""Deep And Wide Multiscale Recursive"" (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.","",""
17,"B. Barshan, B. Ayrulu, S. Utete","Neural network based target differentiation using sonar for robotics applications",2000,"","","","",164,"2022-07-13 10:09:41","","10.1109/ROBOT.2000.845315","","",,,,,17,0.77,6,3,22,"This study investigates the processing of sonar signals using neural networks for robust differentiation of commonly encountered features in indoor environments. The neural network can differentiate more targets, and achieves high differentiation and localization accuracy, improving on previously reported methods. It achieves this by exploiting the identifying features in the differential amplitude and time-of-flight characteristics of these targets. An important observation follows from the robustness tests, which indicate that the amplitude information is more crucial than time-of-flight for reliable operation. The study suggests wider use of neural networks and amplitude information in sonar-based mobile robotics.","",""
44,"Mien Van, Hee-Jun Kang, Y. Suh, K. Shin","A robust fault diagnosis and accommodation scheme for robot manipulators",2013,"","","","",165,"2022-07-13 10:09:41","","10.1007/S12555-012-0022-4","","",,,,,44,4.89,11,4,9,"","",""
19,"J. Veezhinathan, Don Wagner","A neural network approach to first break picking",1990,"","","","",166,"2022-07-13 10:09:41","","10.1109/IJCNN.1990.137575","","",,,,,19,0.59,10,2,32,"First-break picking is an extremely time-consuming task for manual operation since seismic data are so voluminous (e.g. a typical 3-D survey consists of more than half a million traces to be picked). Previous attempts to automate first-arrival picking have achieved only limited success. The authors describe a neural network (NN) solution to this problem using a back-propagation network. The NN-based application system achieved above 95% accuracy on picking several seismic lines based on a single training using only a few seismic records. The level of performance exceeded that achieved by an existing automatic picking program. Job turnaround time (compared to manual picking) improved by 88%. The approach appears robust and shows promise for automating other event-picking tasks in seismic velocity analysis and seismic tomography","",""
26,"J. Ortiz-Rodríguez, M. Martinez-Blanco, H. Vega-Carrillo","Robust Design of Artificial Neural Networks Applying the Taguchi methodology and DoE",2006,"","","","",167,"2022-07-13 10:09:41","","10.1109/CERMA.2006.83","","",,,,,26,1.63,9,3,16,"The integration of artificial neural networks and optimization provides a tool for designing robust network parameters and improving their performance. The Taguchi method offers considerable benefits in time and accuracy when is compared with the conventional trial and error neural network design approach. This work is concerned with the robust design of multilayer feedforward neural networks trained by backpropagation algorithm and develops a systematic and experimental strategy which emphasizes simultaneous optimization artificial neural network's parameters optimization under various noise conditions. We make a comparison among this method and conventional training methods. The attention is drawing on the advantages on Taguchi methods which offer potential benefits in evaluating the network behavior","",""
394,"T. Ince, S. Kiranyaz, M. Gabbouj","A Generic and Robust System for Automated Patient-Specific Classification of ECG Signals",2009,"","","","",168,"2022-07-13 10:09:41","","10.1109/TBME.2009.2013934","","",,,,,394,30.31,131,3,13,"This paper presents a generic and patient-specific classification system designed for robust and accurate detection of ECG heartbeat patterns. The proposed feature extraction process utilizes morphological wavelet transform features, which are projected onto a lower dimensional feature space using principal component analysis, and temporal features from the ECG data. For the pattern recognition unit, feedforward and fully connected artificial neural networks, which are optimally designed for each patient by the proposed multidimensional particle swarm optimization technique, are employed. By using relatively small common and patient-specific training data, the proposed classification system can adapt to significant interpatient variations in ECG patterns by training the optimal network structure, and thus, achieves higher accuracy over larger datasets. The classification experiments over a benchmark database demonstrate that the proposed system achieves such average accuracies and sensitivities better than most of the current state-of-the-art algorithms for detection of ventricular ectopic beats (VEBs) and supra-VEBs (SVEBs). Over the entire database, the average accuracy-sensitivity performances of the proposed system for VEB and SVEB detections are 98.3%-84.6% and 97.4%-63.5%, respectively. Finally, due to its parameter-invariant nature, the proposed system is highly generic, and thus, applicable to any ECG dataset.","",""
91,"S. L. Phung, D. Chai, A. Bouzerdoum","A universal and robust human skin color model using neural networks",2001,"","","","",169,"2022-07-13 10:09:41","","10.1109/IJCNN.2001.938827","","",,,,,91,4.33,30,3,21,"We propose a new image classification technique that utilizes neural networks to classify skin and non-skin pixels in color images. The aim is to develop a universal and robust model of the human skin color that caters for all human races. The ability to detecting solid skin regions in color images by the model is extremely useful in applications such as face detection and recognition, and human gesture analysis. Experimental results show that the neural network classifiers can consistently achieve up to 90% accuracy in skin color detection.","",""
36,"Eric Brachmann, C. Rother","Visual Camera Re-Localization from RGB and RGB-D Images Using DSAC",2020,"","","","",170,"2022-07-13 10:09:41","","10.1109/TPAMI.2021.3070754","","",,,,,36,18.00,18,2,2,"We describe a learning-based system that estimates the camera position and orientation from a single input image relative to a known environment. The system is flexible w.r.t. the amount of information available at test and at training time, catering to different applications. Input images can be RGB-D or RGB, and a 3D model of the environment can be utilized for training but is not necessary. In the minimal case, our system requires only RGB images and ground truth poses at training time, and it requires only a single RGB image at test time. The framework consists of a deep neural network and fully differentiable pose optimization. The neural network predicts so called scene coordinates, i.e. dense correspondences between the input image and 3D scene space of the environment. The pose optimization implements robust fitting of pose parameters using differentiable RANSAC (DSAC) to facilitate end-to-end training. The system, an extension of DSAC++ and referred to as DSAC*, achieves state-of-the-art accuracy on various public datasets for RGB-based re-localization, and competitive accuracy for RGB-D based re-localization.","",""
22,"D. Gavrilis, I. Tsoulos, E. Dermatas","Neural Recognition and Genetic Features Selection for Robust Detection of E-Mail Spam",2006,"","","","",171,"2022-07-13 10:09:41","","10.1007/11752912_54","","",,,,,22,1.38,7,3,16,"","",""
84,"Wenwen Wang, Budhitama Subagdja, A. Tan, J. Starzyk","Neural Modeling of Episodic Memory: Encoding, Retrieval, and Forgetting",2012,"","","","",172,"2022-07-13 10:09:41","","10.1109/TNNLS.2012.2208477","","",,,,,84,8.40,21,4,10,"This paper presents a neural model that learns episodic traces in response to a continuous stream of sensory input and feedback received from the environment. The proposed model, based on fusion adaptive resonance theory (ART) network, extracts key events and encodes spatio-temporal relations between events by creating cognitive nodes dynamically. The model further incorporates a novel memory search procedure, which performs a continuous parallel search of stored episodic traces. Combined with a mechanism of gradual forgetting, the model is able to achieve a high level of memory performance and robustness, while controlling memory consumption over time. We present experimental studies, where the proposed episodic memory model is evaluated based on the memory consumption for encoding events and episodes as well as recall accuracy using partial and erroneous cues. Our experimental results show that: 1) the model produces highly robust performance in encoding and recalling events and episodes even with incomplete and noisy cues; 2) the model provides enhanced performance in a noisy environment due to the process of forgetting; and 3) compared with prior models of spatio-temporal memory, our model shows a higher tolerance toward noise and errors in the retrieval cues.","",""
25,"Mohamed H. Abdelpakey, M. Shehata, Mostafa M. Mohamed","DensSiam: End-to-End Densely-Siamese Network with Self-Attention Model for Object Tracking",2018,"","","","",173,"2022-07-13 10:09:41","","10.1007/978-3-030-03801-4_41","","",,,,,25,6.25,8,3,4,"","",""
39,"Bowen Yang, Jian Zhang, Jonathan Li, Christopher Ré, Christopher R. Aberger, Christopher De Sa","PipeMare: Asynchronous Pipeline Parallel DNN Training",2019,"","","","",174,"2022-07-13 10:09:41","","","","",,,,,39,13.00,7,6,3,"Recently there has been a flurry of interest around using pipeline parallelism while training neural networks. Pipeline parallelism enables larger models to be partitioned spatially across chips and within a chip, leading to both lower network communication and overall higher hardware utilization. Unfortunately, to preserve statistical efficiency, existing pipeline-parallelism techniques sacrifice hardware efficiency by introducing bubbles into the pipeline and/or incurring extra memory costs. In this paper, we investigate to what extent these sacrifices are necessary. Theoretically, we derive a simple but robust training method, called PipeMare, that tolerates asynchronous updates during pipeline-parallel execution. Using this, we show empirically, on a ResNet network and a Transformer network, that PipeMare can achieve final model qualities that match those of synchronous training techniques (at most 0.9% worse test accuracy and 0.3 better test BLEU score) while either using up to 2.0X less weight and optimizer memory or being up to 3.3X faster than other pipeline parallel training techniques. To the best of our knowledge we are the first to explore these techniques and fine-grained pipeline parallelism (e.g. the number of pipeline stages equals to the number of layers) during neural network training.","",""
39,"Hadi Harb, Liming Chen","Robust speech music discrimination using spectrum's first order statistics and neural networks",2003,"","","","",175,"2022-07-13 10:09:41","","10.1109/ISSPA.2003.1224831","","",,,,,39,2.05,20,2,19,"Most of speech/music discrimination techniques proposed in the literature need a great amount of training data in order to provide acceptable results. Besides, they are usually context-dependent. In this paper, we propose a novel technique for speech/music discrimination which relies on first order sound spectrum's statistics as feature vector and a neural network for classification. Experiments driven on 20000 seconds of various audio data show that the proposed technique has a great ability of generalization since a classification accuracy of 96% has been achieved only after a training phase on 80 seconds audio data. Furthermore, the proposed technique is context-independent as it can be applied to various audio sources.","",""
45,"F. Weninger, M. Wöllmer, Jürgen T. Geiger, Björn Schuller, J. Gemmeke, Antti Hurmalainen, T. Virtanen, G. Rigoll","Non-negative matrix factorization for highly noise-robust ASR: To enhance or to recognize?",2012,"","","","",176,"2022-07-13 10:09:41","","10.1109/ICASSP.2012.6288963","","",,,,,45,4.50,6,8,10,"This paper proposes a multi-stream speech recognition system that combines information from three complementary analysis methods in order to improve automatic speech recognition in highly noisy and reverberant environments, as featured in the 2011 PASCAL CHiME Challenge. We integrate word predictions by a bidirectional Long Short-Term Memory recurrent neural network and non-negative sparse classification (NSC) into a multi-stream Hidden Markov Model using convolutive non-negative matrix factorization (NMF) for speech enhancement. Our results suggest that NMF-based enhancement and NSC are complementary despite their overlap in methodology, reaching up to 91.9% average keyword accuracy on the Challenge test set at signal-to-noise ratios from -6 to 9 dB-the best result reported so far on these data.","",""
357,"Yanzhang He, T. Sainath, Rohit Prabhavalkar, Ian McGraw, R. Álvarez, Ding Zhao, David Rybach, Anjuli Kannan, Yonghui Wu, Ruoming Pang, Qiao Liang, Deepti Bhatia, Yuan Shangguan, Bo Li, G. Pundak, K. Sim, Tom Bagby, Shuo-yiin Chang, Kanishka Rao, Alexander Gruenstein","Streaming End-to-end Speech Recognition for Mobile Devices",2018,"","","","",177,"2022-07-13 10:09:41","","10.1109/ICASSP.2019.8682336","","",,,,,357,89.25,36,20,4,"End-to-end (E2E) models, which directly predict output character sequences given input speech, are good candidates for on-device speech recognition. E2E models, however, present numerous challenges: In order to be truly useful, such models must decode speech utterances in a streaming fashion, in real time; they must be robust to the long tail of use cases; they must be able to leverage user-specific context (e.g., contact lists); and above all, they must be extremely accurate. In this work, we describe our efforts at building an E2E speech recog-nizer using a recurrent neural network transducer. In experimental evaluations, we find that the proposed approach can outperform a conventional CTC-based model in terms of both latency and accuracy in a number of evaluation categories.","",""
38,"C. Che, Q. Lin, J. Pearson, B. D. Vries, J. Flanagan","Microphone Arrays and Neural Networks for Robust Speech Recognition",1994,"","","","",178,"2022-07-13 10:09:41","","10.3115/1075812.1075891","","",,,,,38,1.36,8,5,28,"This paper explores use of synergistically-integrated systems of microphone arrays and neural networks for robust speech recognition in variable acoustic environments, where the user must not be encumbered by microphone equipment. Existing speech recognizers work best for ""high-quality close-talking speech."" Performance of these recognizers is typically degraded by environmental interference and mismatch in training conditions and testing conditions. It is found that use of microphone arrays and neural network processors can elevate the recognition performance of existing speech recognizers in an adverse acoustic environment, thus avoiding the need to retrain the recognizer, a complex and tedious task. We also present results showing that a system of microphone arrays and neural networks can achieve a higher word recognition accuracy in an unmatched training/testing condition than that obtained with a retrained speech recognizer using array speech for both training and testing, i.e., a matched training/testing condition.","",""
365,"Wei-Sheng Lai, Jia-Bin Huang, N. Ahuja, Ming-Hsuan Yang","Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks",2017,"","","","",179,"2022-07-13 10:09:41","","10.1109/TPAMI.2018.2865304","","",,,,,365,73.00,91,4,5,"Convolutional neural networks have recently demonstrated high-quality reconstruction for single image super-resolution. However, existing methods often require a large number of network parameters and entail heavy computational loads at runtime for generating high-accuracy super-resolution results. In this paper, we propose the deep Laplacian Pyramid Super-Resolution Network for fast and accurate image super-resolution. The proposed network progressively reconstructs the sub-band residuals of high-resolution images at multiple pyramid levels. In contrast to existing methods that involve the bicubic interpolation for pre-processing (which results in large feature maps), the proposed method directly extracts features from the low-resolution input space and thereby entails low computational loads. We train the proposed network with deep supervision using the robust Charbonnier loss functions and achieve high-quality image reconstruction. Furthermore, we utilize the recursive layers to share parameters across as well as within pyramid levels, and thus drastically reduce the number of parameters. Extensive quantitative and qualitative evaluations on benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of run-time and image quality.","",""
96,"Jiaming Qian, Shijie Feng, Yixuan Li, Tianyang Tao, Jing Han, Qian Chen, Chao Zuo","Single-shot absolute 3D shape measurement with deep-learning-based color fringe projection profilometry.",2020,"","","","",180,"2022-07-13 10:09:41","","10.1364/ol.388994","","",,,,,96,48.00,14,7,2,"Recovering the high-resolution three-dimensional (3D) surface of an object from a single frame image has been the ultimate goal long pursued in fringe projection profilometry (FPP). The color fringe projection method is one of the technologies with the most potential towards such a goal due to its three-channel multiplexing properties. However, the associated color imbalance, crosstalk problems, and compromised coding strategy remain major obstacles to overcome. Inspired by recent successes of deep learning for FPP, we propose a single-shot absolute 3D shape measurement with deep-learning-based color FPP. Through ""learning"" on extensive data sets, the properly trained neural network can ""predict"" the high-resolution, motion-artifact-free, crosstalk-free absolute phase directly from one single color fringe image. Compared with the traditional approach, our method allows for more accurate phase retrieval and more robust phase unwrapping. Experimental results demonstrate that the proposed approach can provide high-accuracy single-frame absolute 3D shape measurement for complicated objects.","",""
38,"Gheith A. Abandah, Fuad Jamour, E. Qaralleh","Recognizing handwritten Arabic words using grapheme segmentation and recurrent neural networks",2014,"","","","",181,"2022-07-13 10:09:41","","10.1007/s10032-014-0218-7","","",,,,,38,4.75,13,3,8,"","",""
82,"Chen Song, Jiaru Song, Qi-Xing Huang","HybridPose: 6D Object Pose Estimation Under Hybrid Representations",2020,"","","","",182,"2022-07-13 10:09:41","","10.1109/cvpr42600.2020.00051","","",,,,,82,41.00,27,3,2,"We introduce HybridPose, a novel 6D object pose estimation approach. HybridPose utilizes a hybrid intermediate representation to express different geometric information in the input image, including keypoints, edge vectors, and symmetry correspondences. Compared to a unitary representation, our hybrid representation allows pose regression to exploit more and diverse features when one type of predicted representation is inaccurate (e.g., because of occlusion). Different intermediate representations used by HybridPose can all be predicted by the same simple neural network, and outliers in predicted intermediate representations are filtered by a robust regression module. Compared to state-of-the-art pose estimation approaches, HybridPose is comparable in running time and is significantly more accurate. For example, on Occlusion Linemod dataset, our method achieves a prediction speed of 30 fps with a mean ADD(-S) accuracy of 79.2%, representing a 67.4% improvement from the current state-of-the-art approach.","",""
72,"Zizhao Zhang, Han Zhang, Sercan Ö. Arik, Honglak Lee, Tomas Pfister","Distilling Effective Supervision From Severe Label Noise",2019,"","","","",183,"2022-07-13 10:09:41","","10.1109/CVPR42600.2020.00931","","",,,,,72,24.00,14,5,3,"Collecting large-scale data with clean labels for supervised training of neural networks is practically challenging. Although noisy labels are usually cheap to acquire, existing methods suffer a lot from label noise. This paper targets at the challenge of robust training at high label noise regimes. The key insight to achieve this goal is to wisely leverage a small trusted set to estimate exemplar weights and pseudo labels for noisy data in order to reuse them for supervised training. We present a holistic framework to train deep neural networks in a way that is highly invulnerable to label noise. Our method sets the new state of the art on various types of label noise and achieves excellent performance on large-scale datasets with real-world label noise. For instance, on CIFAR100 with a 40% uniform noise ratio and only 10 trusted labeled data per class, our method achieves 80.2% classification accuracy, where the error rate is only 1.4% higher than a neural network trained without label noise. Moreover, increasing the noise ratio to 80%, our method still maintains a high accuracy of 75.5%, compared to the previous best accuracy 48.2%.","",""
26,"C. Alippi","Selecting accurate, robust, and minimal feedforward neural networks",2002,"","","","",184,"2022-07-13 10:09:41","","10.1109/TCSI.2002.805710","","",,,,,26,1.30,26,1,20,"Accuracy, robustness, and minimality are fundamental issues in system-level design. Such properties are generally associated with constraints limiting the feasible model space. The paper focuses on the optimal selection of feedforward neural networks under the accuracy, robustness, and minimality constraints. Model selection, with respect to accuracy, can be carried out within the theoretical framework delineated by the final prediction error (FPE), generalization error estimate (GEN), general prediction error (GPE) and network information criterion (NIC) or cross-validation-based techniques. Robustness is an appealing feature since a robust application provides a graceful degradation in performance once affected by perturbations in its structural parameters (e.g., associated with faults or finite precision representations). Minimality is related to model selection and attempts to reduce the computational load of the solution (with also silicon area and power consumption reduction in a digital implementation). A novel sensitivity analysis derived by the FPE selection criterion is suggested in the paper to quantify the relationship between performance loss and robustness; based on the definition of weak and acute perturbations, we introduce two criteria for estimating the robustness degree of a neural network. Finally, by ranking the features of the obtained models we identify the best constrained neural network.","",""
67,"Minseong Kim, Jihoon Tack, Sung Ju Hwang","Adversarial Self-Supervised Contrastive Learning",2020,"","","","",185,"2022-07-13 10:09:41","","","","",,,,,67,33.50,22,3,2,"Existing adversarial learning approaches mostly use class labels to generate adversarial samples that lead to incorrect predictions, which are then used to augment the training of the model for improved robustness. While some recent works propose semi-supervised adversarial learning methods that utilize unlabeled data, they still require class labels. However, do we really need class labels at all, for adversarially robust training of deep neural networks? In this paper, we propose a novel adversarial attack for unlabeled data, which makes the model confuse the instance-level identities of the perturbed data samples. Further, we present a self-supervised contrastive learning framework to adversarially train a robust neural network without labeled data, which aims to maximize the similarity between a random augmentation of a data sample and its instance-wise adversarial perturbation. We validate our method, Robust Contrastive Learning (RoCL), on multiple benchmark datasets, on which it obtains comparable robust accuracy over state-of-the-art supervised adversarial learning methods, and significantly improved robustness against the black box and unseen types of attacks. Moreover, with further joint fine-tuning with supervised adversarial loss, RoCL obtains even higher robust accuracy over using self-supervised learning alone. Notably, RoCL also demonstrate impressive results in robust transfer learning.","",""
65,"Jing wei Tan, Siow-Wee Chang, S. Abdul-Kareem, H. J. Yap, K. Yong","Deep Learning for Plant Species Classification Using Leaf Vein Morphometric",2020,"","","","",186,"2022-07-13 10:09:41","","10.1109/TCBB.2018.2848653","","",,,,,65,32.50,13,5,2,"An automated plant species identification system could help botanists and layman in identifying plant species rapidly. Deep learning is robust for feature extraction as it is superior in providing deeper information of images. In this research, a new CNN-based method named D-Leaf was proposed. The leaf images were pre-processed and the features were extracted by using three different Convolutional Neural Network (CNN) models namely pre-trained AlexNet, fine-tuned AlexNet, and D-Leaf. These features were then classified by using five machine learning techniques, namely, Support Vector Machine (SVM), Artificial Neural Network (ANN), k-Nearest-Neighbor (k-NN), Naïve-Bayes (NB), and CNN. A conventional morphometric method computed the morphological measurements based on the Sobel segmented veins was employed for benchmarking purposes. The D-Leaf model achieved a comparable testing accuracy of 94.88 percent as compared to AlexNet (93.26 percent) and fine-tuned AlexNet (95.54 percent) models. In addition, CNN models performed better than the traditional morphometric measurements (66.55 percent). The features extracted from the CNN are found to be fitted well with the ANN classifier. D-Leaf can be an effective automated system for plant species identification as shown by the experimental results.","",""
85,"Xinyu Zhang, Q. Wang, Jian Zhang, Zhaobai Zhong","Adversarial AutoAugment",2019,"","","","",187,"2022-07-13 10:09:41","","","","",,,,,85,28.33,21,4,3,"Data augmentation (DA) has been widely utilized to improve generalization in training deep neural networks. Recently, human-designed data augmentation has been gradually replaced by automatically learned augmentation policy. Through finding the best policy in well-designed search space of data augmentation, AutoAugment can significantly improve validation accuracy on image classification tasks. However, this approach is not computationally practical for large-scale problems. In this paper, we develop an adversarial method to arrive at a computationally-affordable solution called Adversarial AutoAugment, which can simultaneously optimize target related object and augmentation policy search loss. The augmentation policy network attempts to increase the training loss of a target network through generating adversarial augmentation policies, while the target network can learn more robust features from harder examples to improve the generalization. In contrast to prior work, we reuse the computation in target network training for policy evaluation, and dispense with the retraining of the target network. Compared to AutoAugment, this leads to about 12x reduction in computing cost and 11x shortening in time overhead on ImageNet. We show experimental results of our approach on CIFAR-10/CIFAR-100, ImageNet, and demonstrate significant performance improvements over state-of-the-art. On CIFAR-10, we achieve a top-1 test error of 1.36%, which is the currently best performing single model. On ImageNet, we achieve a leading performance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D without extra data.","",""
16,"Wang Song, X. Shaowei","Robust PCA based on neural networks",1997,"","","","",188,"2022-07-13 10:09:41","","10.1109/CDC.1997.650676","","",,,,,16,0.64,8,2,25,"One way to improve the robustness of principal component analysis (PCA) is studied. The typical two kinds of aspects to analyze the robustness of PCA algorithm are proposed and compared: one is based on the independent among the acquired principal components and the other is based on reducing the effects of the outliers in the training sample set. A new self-organizing algorithm of robust PCA is presented based on the structure of a single-layer neural network (NN) with the modification of the cost function which stands for the reconstruction error of the input signal. The new nonlinear robust PCA algorithm can recognize the outliers in the training sample set automatically and exterminate their effects to the accuracy and convergence of the PCA algorithm through proper processing to the recognized outliers. The comparison simulation experiments are designed to show that robust PCA algorithms developed in this paper are better than the statistical PCA algorithm based on eigenvalue decomposition and the linear self-organizing PCA algorithms based on single-layer NN.","",""
390,"Alex Kendall, R. Cipolla","Modelling uncertainty in deep learning for camera relocalization",2015,"","","","",189,"2022-07-13 10:09:41","","10.1109/ICRA.2016.7487679","","",,,,,390,55.71,195,2,7,"We present a robust and real-time monocular six degree of freedom visual relocalization system. We use a Bayesian convolutional neural network to regress the 6-DOF camera pose from a single RGB image. It is trained in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking under 6ms to compute. It obtains approximately 2m and 6° accuracy for very large scale outdoor scenes and 0.5m and 10° accuracy indoors. Using a Bayesian convolutional neural network implementation we obtain an estimate of the model's relocalization uncertainty and improve state of the art localization accuracy on a large scale outdoor dataset. We leverage the uncertainty measure to estimate metric relocalization error and to detect the presence or absence of the scene in the input image. We show that the model's uncertainty is caused by images being dissimilar to the training dataset in either pose or appearance.","",""
55,"Dushyant Mehta, Oleksandr Sotnychenko, Franziska Mueller, Weipeng Xu, Mohamed A. Elgharib, P. Fua, H. Seidel, Helge Rhodin, Gerard Pons-Moll, C. Theobalt","XNect: Real-time Multi-person 3D Human Pose Estimation with a Single RGB Camera",2019,"","","","",190,"2022-07-13 10:09:41","","10.1145/3386569.3392410","","",,,,,55,18.33,6,10,3,"We present a real-time approach for multi-person 3D motion capture at over 30 fps using a single RGB camera. It operates in generic scenes and is robust to difficult occlusions both by other people and objects. Our method operates in subsequent stages. The first stage is a convolutional neural network (CNN) that estimates 2D and 3D pose features along with identity assignments for all visible joints of all individuals. We contribute a new architecture for this CNN, called SelecSLS Net, that uses novel selective long and short range skip connections to improve the information flow allowing for a drastically faster network without compromising accuracy. In the second stage, a fully-connected neural network turns the possibly partial (on account of occlusion) 2D pose and 3D pose features for each subject into a complete 3D pose estimate per individual. The third stage applies space-time skeletal model fitting to the predicted 2D and 3D pose per subject to further reconcile the 2D and 3D pose, and enforce temporal coherence. Our method returns the full skeletal pose in joint angles for each subject. This is a further key distinction from previous work that neither extracted global body positions nor joint angle results of a coherent skeleton in real time for multi-person scenes. The proposed system runs on consumer hardware at a previously unseen speed of more than 30 fps given 512x320 images as input while achieving state-of-the-art accuracy, which we will demonstrate on a range of challenging real-world scenes.","",""
64,"Mark D. Skowronski, J. Harris","Noise-Robust Automatic Speech Recognition Using a Predictive Echo State Network",2007,"","","","",191,"2022-07-13 10:09:41","","10.1109/TASL.2007.896669","","",,,,,64,4.27,32,2,15,"Artificial neural networks have been shown to perform well in automatic speech recognition (ASR) tasks, although their complexity and excessive computational costs have limited their use. Recently, a recurrent neural network with simplified training, the echo state network (ESN), was introduced by Jaeger and shown to outperform conventional methods in time series prediction experiments. We created the predictive ESN classifier by combining the ESN with a state machine framework. In small-vocabulary ASR experiments, we compared the noise-robust performance of the predictive ESN classifier with a hidden Markov model (HMM) as a function of model size and signal-to-noise ratio (SNR). The predictive ESN classifier outperformed an HMM by 8-dB SNR, and both models achieved maximum noise-robust accuracy for architectures with more states and fewer kernels per state. Using ten trials of random sets of training/validation/test speakers, accuracy for the predictive ESN classifier, averaged between 0 and 20 dB SNR, was 81plusmn3%, compared to 61plusmn2% for an HMM. The closed-form regression training for the ESN significantly reduced the computational cost of the network, and the reservoir of the ESN created a high-dimensional representation of the input with memory which led to increased noise-robust classification.","",""
29,"Jerome Paul N. Cruz, Ma Lourdes Dimaala, L. Francisco, E. J. Franco, A. Bandala, E. Dadios","Object recognition and detection by shape and color pattern recognition utilizing Artificial Neural Networks",2013,"","","","",192,"2022-07-13 10:09:41","","10.1109/ICOICT.2013.6574562","","",,,,,29,3.22,5,6,9,"A robust and accurate object recognition tool is presented in this paper. The paper introduced the use of Artificial Neural Networks in evaluating a frame shot of the target image. The system utilizes three major steps in object recognition, namely image processing, ANN processing and interpretation. In image processing stage a frame shot or an image go through a process of extracting numerical values of object's shape and object's color. These values are then fed to the Artificial Neural Network stage, wherein the recognition of the object is done. Since the output of the ANN stage is in numerical form the third process is indispensable for human understanding. This stage simply converts a given value to its equivalent linguistic term. All three components are integrated in an interface for ease of use. Upon the conclusion of the system's development, experimentation and testing procedures are initiated. The study proved that the optimum lighting condition opted for the system is at 674 lumens with an accuracy of 99.99996072%. Another finding that the paper presented is that the optimum distance for recognition is at 40cm with an accuracy of 99.99996072%. Lastly the system contains a very high tolerance in the variations in the objects position or orientation, with the optimum accuracy at upward position with 99.99940181% accuracy rate.","",""
44,"S. Udrescu, A. Tan, Jiahai Feng, Orisvaldo Neto, Tailin Wu, Max Tegmark","AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",2020,"","","","",193,"2022-07-13 10:09:41","","","","",,,,,44,22.00,7,6,2,"We present an improved method for symbolic regression that seeks to fit data to formulas that are Pareto-optimal, in the sense of having the best accuracy for a given complexity. It improves on the previous state-of-the-art by typically being orders of magnitude more robust toward noise and bad data, and also by discovering many formulas that stumped previous methods. We develop a method for discovering generalized symmetries (arbitrary modularity in the computational graph of a formula) from gradient properties of a neural network fit. We use normalizing flows to generalize our symbolic regression method to probability distributions from which we only have samples, and employ statistical hypothesis testing to accelerate robust brute-force search.","",""
42,"Bing Liu","Text sentiment analysis based on CBOW model and deep learning in big data environment",2018,"","","","",194,"2022-07-13 10:09:41","","10.1007/S12652-018-1095-6","","",,,,,42,10.50,42,1,4,"","",""
294,"Yi-Zhou Lin, Z. Nie, Hongwei Ma","Structural Damage Detection with Automatic Feature‐Extraction through Deep Learning",2017,"","","","",195,"2022-07-13 10:09:41","","10.1111/mice.12313","","",,,,,294,58.80,98,3,5,"Structural damage detection is still a challenging problem owing to the difficulty of extracting damage‐sensitive and noise‐robust features from structure response. This article presents a novel damage detection approach to automatically extract features from low‐level sensor data through deep learning. A deep convolutional neural network is designed to learn features and identify damage locations, leading to an excellent localization accuracy on both noise‐free and noisy data set, in contrast to another detector using wavelet packet component energy as the input feature. Visualization of the features learned by hidden layers in the network is implemented to get a physical insight into how the network works. It is found the learned features evolve with the depth from rough filters to the concept of vibration mode, implying the good performance results from its ability to learn essential characteristics behind the data.","",""
53,"Pu Zhao, Pin-Yu Chen, Payel Das, K. Ramamurthy, Xue Lin","Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness",2020,"","","","",196,"2022-07-13 10:09:41","","","","",,,,,53,26.50,11,5,2,"Mode connectivity provides novel geometric insights on analyzing loss landscapes and enables building high-accuracy pathways between well-trained neural networks. In this work, we propose to employ mode connectivity in loss landscapes to study the adversarial robustness of deep neural networks, and provide novel methods for improving this robustness. Our experiments cover various types of adversarial attacks applied to different network architectures and datasets. When network models are tampered with backdoor or error-injection attacks, our results demonstrate that the path connection learned using limited amount of bonafide data can effectively mitigate adversarial effects while maintaining the original accuracy on clean data. Therefore, mode connectivity provides users with the power to repair backdoored or error-injected models. We also use mode connectivity to investigate the loss landscapes of regular and robust models against evasion attacks. Experiments show that there exists a barrier in adversarial robustness loss on the path connecting regular and adversarially-trained models. A high correlation is observed between the adversarial robustness loss and the largest eigenvalue of the input Hessian matrix, for which theoretical justifications are provided. Our results suggest that mode connectivity offers a holistic tool and practical means for evaluating and improving adversarial robustness.","",""
331,"J. Mairal, Piotr Koniusz, Z. Harchaoui, C. Schmid","Convolutional Kernel Networks",2014,"","","","",197,"2022-07-13 10:09:41","","","","",,,,,331,41.38,83,4,8,"An important goal in visual recognition is to devise image representations that are invariant to particular transformations. In this paper, we address this goal with a new type of convolutional neural network (CNN) whose invariance is encoded by a reproducing kernel. Unlike traditional approaches where neural networks are learned either to represent data or for solving a classification task, our network learns to approximate the kernel feature map on training data.    Such an approach enjoys several benefits over classical ones. First, by teaching CNNs to be invariant, we obtain simple network architectures that achieve a similar accuracy to more complex ones, while being easy to train and robust to overfitting. Second, we bridge a gap between the neural network literature and kernels, which are natural tools to model invariance. We evaluate our methodology on visual recognition tasks where CNNs have proven to perform well, e.g., digit recognition with the MNIST dataset, and the more challenging CIFAR-10 and STL-10 datasets, where our accuracy is competitive with the state of the art.","",""
116,"Ruimin Ke, Zhibin Li, Jinjun Tang, Zewen Pan, Yinhai Wang","Real-Time Traffic Flow Parameter Estimation From UAV Video Based on Ensemble Classifier and Optical Flow",2019,"","","","",198,"2022-07-13 10:09:41","","10.1109/TITS.2018.2797697","","",,,,,116,38.67,23,5,3,"Recently, the availability of unmanned aerial vehicle (UAV) opens up new opportunities for smart transportation applications, such as automatic traffic data collection. In such a trend, detecting vehicles and extracting traffic parameters from UAV video in a fast and accurate manner is becoming crucial in many prospective applications. However, from the methodological perspective, several limitations have to be addressed before the actual implementation of UAV. This paper proposes a new and complete analysis framework for traffic flow parameter estimation from UAV video. This framework addresses the well-concerned issues on UAV’s irregular ego-motion, low estimation accuracy in dense traffic situation, and high computational complexity by designing and integrating four stages. In the first two stages an ensemble classifier (Haar cascade + convolutional neural network) is developed for vehicle detection, and in the last two stages a robust traffic flow parameter estimation method is developed based on optical flow and traffic flow theory. The proposed ensemble classifier is demonstrated to outperform the state-of-the-art vehicle detectors that designed for UAV-based vehicle detection. Traffic flow parameter estimations in both free flow and congested traffic conditions are evaluated, and the results turn out to be very encouraging. The dataset with 20,000 image samples used in this study is publicly accessible for benchmarking at http://www.uwstarlab.org/research.html.","",""
356,"Chi Su, Shiliang Zhang, Junliang Xing, Wen Gao, Q. Tian","Deep Attributes Driven Multi-Camera Person Re-identification",2016,"","","","",199,"2022-07-13 10:09:41","","10.1007/978-3-319-46475-6_30","","",,,,,356,59.33,71,5,6,"","",""
160,"Guotai Wang, Maria A. Zuluaga, Wenqi Li, R. Pratt, P. Patel, M. Aertsen, Tom Doel, A. David, J. Deprest, S. Ourselin, Tom Kamiel Magda Vercauteren","DeepIGeoS: A Deep Interactive Geodesic Framework for Medical Image Segmentation",2017,"","","","",200,"2022-07-13 10:09:41","","10.1109/TPAMI.2018.2840695","","",,,,,160,32.00,16,11,5,"Accurate medical image segmentation is essential for diagnosis, surgical planning and many other applications. Convolutional Neural Networks (CNNs) have become the state-of-the-art automatic segmentation methods. However, fully automatic results may still need to be refined to become accurate and robust enough for clinical use. We propose a deep learning-based interactive segmentation method to improve the results obtained by an automatic CNN and to reduce user interactions during refinement for higher accuracy. We use one CNN to obtain an initial automatic segmentation, on which user interactions are added to indicate mis-segmentations. Another CNN takes as input the user interactions with the initial segmentation and gives a refined result. We propose to combine user interactions with CNNs through geodesic distance transforms, and propose a resolution-preserving network that gives a better dense prediction. In addition, we integrate user interactions as hard constraints into a back-propagatable Conditional Random Field. We validated the proposed framework in the context of 2D placenta segmentation from fetal MRI and 3D brain tumor segmentation from FLAIR images. Experimental results show our method achieves a large improvement from automatic CNNs, and obtains comparable and even higher accuracy with fewer user interventions and less time compared with traditional interactive methods.","",""
