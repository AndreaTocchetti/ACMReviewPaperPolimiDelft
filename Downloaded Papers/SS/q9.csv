Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
1,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis (Preprint)",2020,"","","","",1,"2022-07-13 09:19:55","","10.2196/preprints.19428","","",,,,,1,0.50,0,3,2,"  BACKGROUND  During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles.      OBJECTIVE  This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system.      METHODS  The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning.      RESULTS  The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods.      CONCLUSIONS  A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field. ","",""
0,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis",2020,"","","","",2,"2022-07-13 09:19:55","","10.2196/19428","","",,,,,0,0.00,0,3,2,"Background During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles. Objective This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system. Methods The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning. Results The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods. Conclusions A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field.","",""
1,"T. Sethi, R. Awasthi","Use of artificial intelligence based models for learning better policy for maternal and child health",2020,"","","","",3,"2022-07-13 09:19:55","","10.1093/eurpub/ckaa165.291","","",,,,,1,0.50,1,2,2,"  More than 640,000 babies died of sepsis before they reach the age of one month in India in 2016. Despite a large number of government schemes aimed at reducing this rate, this number still remains high because of the complexity and interplay of factors involved. Finding an optimum policy and solutions to this problem needs learning from data. We integrated diverse sources of data and applied Bayesian Artificial Intelligence methods for learning to mitigate sepsis and adverse pregnancy outcomes in India. In this project, we created models that combine the robustness of ensemble averaged Baeysian Networks with decision learning and impact evaluation by using simulations and counterfactual reasoning respectively. We will demonstrate the process of learning these models and how these led us to infer the pivotal role of Water, Sanitation and Hygiene for reducing Adverse Pregnancy Outcome and neonatal sepsis in the population studied. We will also demonstrate the creation of explainable AI models for complex public health challenges and their deployment with wiseR, our in-house, open source platform for doing end-to-end Bayesian Decision Network learning.","",""
22,"L. Valiant","Knowledge Infusion: In Pursuit of Robustness in Artificial Intelligence",2008,"","","","",4,"2022-07-13 09:19:55","","10.4230/LIPIcs.FSTTCS.2008.1770","","",,,,,22,1.57,22,1,14,"Endowing computers with the ability to apply commonsense knowledge with human- level performance is a primary challenge for computer science, comparable in importance to past great challenges in other fields of science such as the sequencing of the human genome. The right approach to this problem is still under debate. Here we shall discuss and attempt to justify one ap- proach, that of knowledge infusion. This approach is based on the view that the fundamental objective that needs to be achieved is robustness in the following sense: a framework is needed in which a computer system can represent pieces of knowledge about the world, each piece having some un- certainty, and the interactions among the pieces having even more uncertainty, such that the system can nevertheless reason from these pieces so that the uncertainties in its conclusions are at least controlled. In knowledge infusion rules are learned from the world in a principled way so that sub- sequent reasoning using these rules will also be principled, and subject only to errors that can be bounded in terms of the inverse of the effort invested in the learning process.","",""
3,"Zhengxiang Shi, Qiang Zhang, Aldo Lipani","StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts",2022,"","","","",5,"2022-07-13 09:19:55","","10.48550/arXiv.2204.08292","","",,,,,3,3.00,1,3,1,"Inferring spatial relations in natural language is a crucial ability an intelligent system should possess. The bAbI dataset tries to capture tasks relevant to this domain (task 17 and 19). However, these tasks have several limitations. Most importantly, they are limited to fixed expressions, they are limited in the number of reasoning steps required to solve them, and they fail to test the robustness of models to input that contains irrelevant or redundant information. In this paper, we present a new Question-Answering dataset called StepGame for robust multi-step spatial reasoning in texts. Our experiments demonstrate that state-of-the-art models on the bAbI dataset struggle on the StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental results on both datasets show that our model outperforms all the baselines with superior generalization and robustness performance.","",""
3,"Yongyue Wang, Chunhe Xia, Chengxiang Si, Beitong Yao, Tianbo Wang","Robust Reasoning Over Heterogeneous Textual Information for Fact Verification",2020,"","","","",6,"2022-07-13 09:19:55","","10.1109/ACCESS.2020.3019586","","",,,,,3,1.50,1,5,2,"Automatic fact verification (FV) based on artificial intelligence is considered as a promising approach which can be used to identify misinformation distributed on the web. Even though previous FV using deep learning have made great achievements in single dataset (e.g., FEVER), the trained systems are unlikely to be capable of extracting evidence from heterogeneous web-sources and validating claims in accordance with evidence found on the Internet. Nevertheless, the heterogeneity covers abundant semantic information, which will help FV system identify misinformation in a more accurate way. The current work is the first attempt to make the combination of knowledge graph (KG) and graph neural network (GNN) to enhance the robustness of FV systems for heterogeneous information. As a result, it can be generalized to multi-domain datasets after training on a sufficient single one. To make information update and aggregate well on the collaborative graph, the present study proposes a double graph attention network (DGAT) framework which recursively propagates the embeddings from a node’s neighbors to refine the node’s embedding as well as applies an attention mechanism to classify the importance of the neighbors. We train and evaluate our system on FEVER, a single and benchmark dataset for FV, and then re-evaluate our system on UKP Snopes Corpus, a new richly annotated corpus for FV tasks on the basis of heterogeneous web sources. According to experimental results, although DGAT has no excellent advantages in a single dataset, it shows outstanding performance in more realistic and multi-domain datasets. Moreover, the current study also provides a feasible method for deep learning to have the ability to infer heterogeneous information robustly.","",""
1,"Nikhil Naik, P. Nuzzo","Robustness Contracts for Scalable Verification of Neural Network-Enabled Cyber-Physical Systems",2020,"","","","",7,"2022-07-13 09:19:55","","10.1109/MEMOCODE51338.2020.9315118","","",,,,,1,0.50,1,2,2,"The proliferation of artificial intelligence based systems in all walks of life raises concerns about their safety and robustness, especially for cyber-physical systems including multiple machine learning components. In this paper, we introduce robustness contracts as a framework for compositional specification and reasoning about the robustness of cyber-physical systems based on neural network (NN) components. Robustness contracts can encompass and generalize a variety of notions of robustness which were previously proposed in the literature. They can seamlessly apply to NN-based perception as well as deep reinforcement learning (RL)-enabled control applications. We present a sound and complete algorithm that can efficiently verify the satisfaction of a class of robustness contracts on NNs by leveraging notions from Lagrangian duality to identify system configurations that violate the contracts. We illustrate the effectiveness of our approach on the verification of NN-based perception systems and deep RL-based control systems.","",""
0,"Suleyman Emre Isik, Ali Eren Aytekin, Halil Vurus","A machine learning approach for abstraction and reasoning problems without large amounts of data",2022,"","","","",8,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,3,1,"Journal of Emerging Investigators • www.emerginginvestigators.org level abstraction-reasoning ability which makes it difficult for algorithms to handle volatile and hard-to-predict real-life problems. The problems caused by this task-based nature necessitated flexibility and robustness for certain broader subfields of AI, such as L5 self-driving, domestic robotics, or personal assistants; there is even increasing interest in generality itself (e.g., developmental robotics, artificial general intelligence) (2, 3). The first and most important step to take in order to offer an approach that is closer to human intelligence is to examine the concept of intelligence and to define it in the most useful way. Various definitions have been made for intelligence in the past. Legg and Hutter summarized the definitions made in the context of artificial intelligence research as follows: ""Intelligence measures a person's ability to achieve goals in a wide and varied environment (4)."" Two main characteristics are emphasized here: a task-goal focus and generalizability to a wide range of environments. Accordingly, while human intelligence can perform tasks with its high ability, these abilities can also be generalized for new tasks in new environments (skill acquisition). This feature is a mechanism that human nature has developed in line with evolutionary psychology to solve new unknown tasks and problems (5, 6). In the direction of the development of AI, many approaches have emerged to develop and evaluate AI models. One of them is the human observational approach that examines, judges, and scores the system’s inputs and outputs. This is a highly subjective, difficult, and expensive method to automate. White-box analysis, on the other hand, is inspecting the implementation of the system to determine its input-output response and score it (e.g., an algorithm that plays “Connect Four”) (7). Peer confrontation, for example, is having the system compete against either other AIs or humans. This is the preferred mode of evaluation for player-versus-player games, such as chess. The benchmarking approach, which is based on enabling the system through algorithms to produce outputs for a ""test set"" of inputs (or environments) for which the desired outcome is known (solvable by humans), is another of the most valuable approaches for the evaluation of artificial intelligence. In particular, it is reproducible (test set fixed), scalable (cheap to run the evaluation multiple times), easy to set up, and flexible enough to be applied to a wide variety of possible tasks (8). For this reason, benchmarking has been an important part of progress in artificial intelligence A machine learning approach for abstraction and reasoning problems without large amounts of data","",""
1,"Mama Chouitek, N. Benouzza, Benaissa Bekouche","Control of variable reluctance machine (8/6) by artificiel intelligence techniques",2020,"","","","",9,"2022-07-13 09:19:55","","10.11591/ijece.v10i2.pp1893-1904","","",,,,,1,0.50,0,3,2,"The non-linearity of variable-Reluctance Machine (8/6) and the dependence of machine inductance on rotor position and applied current complicate the development of the control strategies of drives using variable-Reluctance Machine variable-Reluctance Machine (VRM). The classical-control algorithms for example of derived full proportional action may prove sufficient if the requirements on the accuracy and performance of systems are not too strict. In the opposite case and particularly when the controlled part is submitted to strong nonlinearity and to temporal variations, control techniques must be designed which ensure the robustness of the process with respect to the uncertainties on the parameters and their variations. These techniques include artificial-intelligence-based techniques constituted of neural networks and fuzzy logic. This technique has the ability to replace PID regulators by nonlinear ones using the human brain’s reasoning and functioning and is simulated by using MATLAB/Simulink software. Finally, by using obtained waveforms, these results will be compared.","",""
31,"Associazione italiana per l'intelligenza artificiale. Congress, S. Bandini, S. Manzoni","AI*IA 2005: Advances in Artificial Intelligence, 9th Congress of the Italian Association for Artificial Intelligence, Milan, Italy, September 21-23, 2005, Proceedings",2005,"","","","",10,"2022-07-13 09:19:55","","10.1007/11558590","","",,,,,31,1.82,10,3,17,"","",""
110,"C. Kulikowski","Artificial intelligence methods and systems for medical consultation",1980,"","","","",11,"2022-07-13 09:19:55","","10.1109/TPAMI.1980.6592368","","",,,,,110,2.62,110,1,42,"The major AI problems that arise in designing a consultation program involve choices of knowledge representations, diagnostic interpretation strategies, and treatment planning strategies. The need to justify decisions and update the knowledge base in the light of new research findings places a premium on the modularity of a representation and the ease with which its reasoning procedures can be explained. In both diagnosis and treatment decisions, the relative advantages and disadvantages of different schemes for quantifying the uncertainty of inferences raises difficult issues of a formal logical nature, as well as many specific practical problems of system design. An important insight that has resulted from the design of several artificial intelligence systems is that robustness of performance in the presence of many uncertainty relationships can be achieved by eliciting from the expert a segmentation of knowledge that will also provide a rich network of deterministic relationships to interweave the space of hypotheses.","",""
5,"M. Selfridge, D. J. Dickerson, S. F. Biggs","Cognitive Expert Systems and Machine Learning: Artificial Intelligence Research at the University of Connecticut",1987,"","","","",12,"2022-07-13 09:19:55","","10.1609/AIMAG.V8I1.577","","",,,,,5,0.14,2,3,35,"In order for next-generation expert systems to demonstrate the performance, robustness, flexibility, and learning ability of human experts, they will have to be based on cognitive models of expert human reasoning and learning. We call such next-generation systems cognitive expert systems. Research at the Artificial Intelligence Laboratory at the University of Connecticut is directed toward understanding the principles underlying cognitive expert systems and developing computer programs embodying those principles. The Causal Model Acquisition System (CMACS) learns causal models of physical mechanisms by understanding real-world natural language explanations of those mechanisms. The going Concern Expert ( GCX) uses business and environmental knowledge to assess whether a company will remain in business for at least the following year. The Business Information System (BIS) acquires business and environmental knowledge from in-depth reading of real-world news stories. These systems are based on theories of expert human reasoning and learning, and thus represent steps toward next-generation cognitive expert systems.","",""
21,"Claudia d’Amato, N. Fanizzi, B. Fazzinga, G. Gottlob, Thomas Lukasiewicz","Ontology-based semantic search on the Web and its combination with the power of inductive reasoning",2012,"","","","",13,"2022-07-13 09:19:55","","10.1007/s10472-012-9309-7","","",,,,,21,2.10,4,5,10,"","",""
29,"A. Umbrico, A. Cesta, Gabriella Cortellessa, Andrea Orlandini","A Holistic Approach to Behavior Adaptation for Socially Assistive Robots",2020,"","","","",14,"2022-07-13 09:19:55","","10.1007/s12369-019-00617-9","","",,,,,29,14.50,7,4,2,"","",""
3,"Javier Viaña, Kelly Cohen","Extension to Multidimensional Problems of a Fuzzy- based Explainable & Noise-Resilient Algorithm",2021,"","","","",15,"2022-07-13 09:19:55","","","","",,,,,3,3.00,2,2,1,"While Deep Neural Networks (DNNs) have shown incredible performance in a variety of data, they are brittle and opaque: easily fooled by the presence of noise, and difficult to understand the underlying reasoning for their predictions or choices. This focus on accuracy at the expense of interpretability and robustness caused little concern since, until recently, DNNs were employed primarily for scientific and limited commercial work. An increasing, widespread use of artificial intelligence and growing emphasis on user data protections, however, motivates the need for robust solutions with explainable methods and results. In this work, we extend a novel fuzzy based algorithm for regression to multidimensional problems. Previous research demonstrated that this approach outperforms neural network benchmarks while using only 5% of the number of the parameters.","",""
1,"Fernando Martínez-Plumed, David Castellano Falcón, Carlos Monserrat Aranda, J. Hernández-Orallo","When AI Difficulty Is Easy: The Explanatory Power of Predicting IRT Difficulty",2022,"","","","",16,"2022-07-13 09:19:55","","10.1609/aaai.v36i7.20739","","",,,,,1,1.00,0,4,1,"One of challenges of artificial intelligence as a whole is robustness. Many issues such as adversarial examples, out of distribution performance, Clever Hans phenomena, and the wider areas of AI evaluation and explainable AI, have to do with the following question: Did the system fail because it is a hard instance or because something else? In this paper we address this question with a generic method for estimating IRT-based instance difficulty for a wide range of AI domains covering several areas, from supervised feature-based classification to automated reasoning. We show how to estimate difficulty systematically using off-the-shelf machine learning regression models. We illustrate the usefulness of this estimation for a range of applications.","",""
0,"Qilin Xiong, Chun Liao, Zhenhong Yang, W. Gao","A Method for Accelerating YOLO by Hybrid Computing Based on ARM and FPGA",2021,"","","","",17,"2022-07-13 09:19:55","","10.1145/3508546.3508576","","",,,,,0,0.00,0,4,1,"CNN has promoted the rapid development of target recognition and detection technology. By comparison with machine learning, it has faster detection speed and higher robustness. However, the deployment of the CNN network model often needs more computing resources, which hinders the application of artificial intelligence technology. In this paper, the authors use the hybrid architecture of ARM and FPGA to deploy a You Only Look Once (YOLO) model on the FPGA to improve the efficiency of target recognition and detection under condition of low resources consumption and low power consumption. YOLO is a one-stage real-time detection model and it has high detection speed and remarkable accuracy. High-level Synthesis (HLS) is a fast development and verification technology of FPGA based on C/C++. We use HLS to implement the pipeline mechanism and complete the parallel calculation of convolution, thereby constructing a forward reasoning model of YOLOv3-tiny. In order to accelerate the forward inference process of YOLO, we combine convolution with batch normalization. The FPGA we use in the paper is Xilinx Zynq-7035 containing system on chip (SoC). We build the software and hardware co-architecture of ARM and FPGA on Zynq-7035, which makes full use of the logic control advantages of ARM and the logic computing advantages of FPGA. In the end, we achieve 28.99 GOP/S speed with only 3.715W power consumption. Finally, compared with the Ryzen 5 3600, we achieve 41.3inference speed at a lower clock rate.","",""
26,"Kushal Kafle, Robik Shrestha, Christopher Kanan","Challenges and Prospects in Vision and Language Research",2019,"","","","",18,"2022-07-13 09:19:55","","10.3389/frai.2019.00028","","",,,,,26,8.67,9,3,3,"Language grounded image understanding tasks have often been proposed as a method for evaluating progress in artificial intelligence. Ideally, these tasks should test a plethora of capabilities that integrate computer vision, reasoning, and natural language understanding. However, the datasets and evaluation procedures used in these tasks are replete with flaws which allows the vision and language (V&L) algorithms to achieve a good performance without a robust understanding of vision and language. We argue for this position based on several recent studies in V&L literature and our own observations of dataset bias, robustness, and spurious correlations. Finally, we propose that several of these challenges can be mitigated by creation of carefully designed benchmarks.","",""
311,"R. Cucchiara, M. Piccardi, P. Mello","Image analysis and rule-based reasoning for a traffic monitoring system",1999,"","","","",19,"2022-07-13 09:19:55","","10.1109/ITSC.1999.821156","","",,,,,311,13.52,104,3,23,"The paper describes a system for detecting vehicles in urban traffic scenes in daytime and at night by means of image analysis and rule-based reasoning. The strength of the proposed approach is its formal separation between the low-level image processing modules (detecting moving vehicles under day and night light) and the high-level module, which provides a single framework for tracking vehicles in the scene. The image processing modules perform spatio-temporal analysis on moving templates in daytime images, and morphological analysis of headlight pairs in night images. The high-level module is designed as a forward chained production rule system, working on symbolic data, i.e. vehicles and their attributes, and exploiting a set of heuristic roles tuned to urban traffic conditions. The synergy between the artificial intelligence techniques of the high level and low-level image analysis techniques provides the system with flexibility and robustness.","",""
0,"Nhan Dam","Modelling Data with Stochastic Generative Processes",2020,"","","","",20,"2022-07-13 09:19:55","","10.26180/5E9FA403084CC","","",,,,,0,0.00,0,1,2,"Learning and modelling complex data with generative models is a prominent research topic in modern artificial intelligence since generative models empower us to answer fundamental and important research questions into the generative processes of algorithmic intelligence. They also enable practical applications such as recognising patterns and anomaly, constructing high-level abstractions utilised in reasoning and decision making, and drawing deep insights from the data to facilitate data compression and augmentation. This dissertation aims to advance research in generative models by enriching their modelling capacity and enhancing their robustness to work more efficiently on a wider range of problems and data types.","",""
8,"Szymon Bobek, G. J. Nalepa, M. Slazynski","HEARTDROID—Rule engine for mobile and context‐aware expert systems",2018,"","","","",21,"2022-07-13 09:19:55","","10.1111/exsy.12328","","",,,,,8,2.00,3,3,4,"Building mobile context‐aware systems is inherently complex and non‐trivial task. It consists of several phases starting from acquisition of context, through modeling to execution of contextual models. Today, such systems are mostly implemented on mobile platforms, that introduce specific requirements, such as intelligibility, robustness, privacy, and efficiency. Over the last decade, along with the rapid development of mobile industry, many approaches were developed that unevenly support these requirements. This is mainly caused by the fact that current modelling and reasoning methods are not crafted to operate in mobile environments. We argue that the use of rule‐based reasoning tailored to mobile environments is an optimal solution. Rules are based on symbolic knowledge representation, as such they meet the general tendency to enforce understandability, intelligibility, and controllability of artificial intelligence software, as stated in the recent European Union General Data Protection Regulation. To this goal, we introduce a lightweight rule engine dedicated for Android platform called HEARTDROID. It executes models in the HMR+ rule language that are capable of expressing uncertainty of knowledge, capturing dynamics of mobile environment and provide high level of intelligibility. We present a qualitative and quantitative comparison of HEARTDROID with the most popular rule engines available.","",""
64,"Emmanuel Kounalis, M. Rusinowitch","Mechanizing inductive reasoning",1990,"","","","",22,"2022-07-13 09:19:55","","","","",,,,,64,2.00,32,2,32,"Automating proofs by induction is important in many computer science and artificial intelligence applications, in particular in program verification and specification systems. We present a new method to prove (and disprove) automatically inductive properties. Given a set of axioms, a well-suited induction scheme is constructed automatically. We call such a scheme a test-set. Then, for proving a property, we just instanciate it with terms from the test-set and apply pure algebraic simplification to the result. This method avoids completion and explicit induction. However it retains their positive features, namely the completeness of the former and the robustness of the latter.","",""
0,"Li Wei-hua","Automated Reasoning Algorithm in Extended Second Order Logic",2010,"","","","",23,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,1,12,"This proposed automatic reasoning algorithm that has been used in artificial intelligence decision making system can effectively extract knowledge and complete the unsupervised classification with the uncertain data sets.The purpose of the new method based on extended second-order logic(SOLe) is to improve the accuracy and robustness of decision-making system.By analyzing of unstructured knowledge,this paper built the automatic reasoning framework through adopting second-order logic that has these variables as well as additional variables that range over sets of individuals,and combining interval parameter estimation based on exponential distribution-cluster can effectively avoid paradox.Simulations show that the new algorithm can improve the accuracy by about 7% and the robustness by about 6.5% on UCI datasets in decision making system and expert system.","",""
2,"E. Blasch, Zheng Liu, Yufeng Zheng, U. Majumder, A. Aved, P. Zulch","Multisource deep learning for situation awareness",2019,"","","","",24,"2022-07-13 09:19:55","","10.1117/12.2519236","","",,,,,2,0.67,0,6,3,"The resurgence of interest in artificial intelligence (AI) stems from impressive deep learning (DL) performance such as hierarchical supervised training using a Convolutional Neural Network (CNN). Current DL methods should provide contextual reasoning, explainable results, and repeatable understanding that require evaluation methods. This paper discusses DL techniques using multimodal (or multisource) information that extend measures of performance (MOP). Examples of joint multi-modal learning include imagery and text, video and radar, and other common sensor types. Issues with joint multimodal learning challenge many current methods and care is needed to apply machine learning methods. Results from Deep Multimodal Image Fusion (DMIF) using Electro-optical and infrared data demonstrate performance modeling based on distance to better understand DL robustness and quality to provide situation awareness.","",""
1,"Christophe Guéret","Linked Data Meets Computational Intelligence - Position paper",2010,"","","","",25,"2022-07-13 09:19:55","","","","",,,,,1,0.08,1,1,12,"The Web of Data (WoD) is growing at an amazing rate and it will no longer be feasible to deal with it in a global way, by centralising the data or reasoning processes making use of that data. We believe that Computational Intelligence tech- niques provides the adaptiveness, robustness and scalability that will be required to exploit the full value of ever growing amounts of dynamic SemanticWeb data.","",""
1,"Shehab Abdulhabib Alzaeemi, M. Mansor, M. Kasihmuddin, S. Sathasivam","Comparing the logic programming between Hopfield neural network and radial basis function neural network",2019,"","","","",26,"2022-07-13 09:19:55","","10.1063/1.5136476","","",,,,,1,0.33,0,4,3,"Logic programming is a superior language because it operates on a higher level of mathematical or logical reasoning. Logic programming is well-suited in building the artificial intelligence systems. In this paper, we reviewed the performance of the logic programming in Hopfield Neural Network (HNN) and Radial Basis Function Neural Network (RBFNN). Logic programming by using the Embedding method will improve the performance of RBFNN. In HNN, the logic programming can be implemented by finding the optimal synaptic weight via Wan Abdullah method. RBFNN is expected to do logic programming optimally compared to HNN. This study gives an overview of HNN and RBFNN regarding architectures, learning processing, and their application in 2 Satisfiability (2SAT) logic programming. Both networks will be assessed based on accuracy, sensitivity, and robustness. Pursuing that, RBFNN is expected to outperform HNN in doing 2 Satisfiability logic programming.Logic programming is a superior language because it operates on a higher level of mathematical or logical reasoning. Logic programming is well-suited in building the artificial intelligence systems. In this paper, we reviewed the performance of the logic programming in Hopfield Neural Network (HNN) and Radial Basis Function Neural Network (RBFNN). Logic programming by using the Embedding method will improve the performance of RBFNN. In HNN, the logic programming can be implemented by finding the optimal synaptic weight via Wan Abdullah method. RBFNN is expected to do logic programming optimally compared to HNN. This study gives an overview of HNN and RBFNN regarding architectures, learning processing, and their application in 2 Satisfiability (2SAT) logic programming. Both networks will be assessed based on accuracy, sensitivity, and robustness. Pursuing that, RBFNN is expected to outperform HNN in doing 2 Satisfiability logic programming.","",""
13,"Erik Blasch, Shuo Liu, Zheng Liu, Yufeng Zheng","Deep Learning Measures of Effectiveness",2018,"","","","",27,"2022-07-13 09:19:55","","10.1109/NAECON.2018.8556808","","",,,,,13,3.25,3,4,4,"The resurgence of interest in artificial intelligence (AI) stem from impressive deep learning (DL) performance such as hierarchical supervised training using a Convolutional Neural Network (CNN). Current DL needs to focus on contextual reasoning, explainable results, and repeatable understanding that require evaluation methods. This paper presents measures of effectiveness (MOE) for DL techniques that extend measures of performance (MOP). MOPs include: Timeliness: computational efficiency, Accuracy: operational robustness, and Confidence: semi-supervised representation. MOE concerns include Throughput: data efficiency, Security: adversarial robustness, and Completeness: problem representation. DL evaluation requires verification and validation testing in realistic environments. An example is shown for Deep Multimodal Image Fusion (DMIF) that evaluates MOEs of information gain, robustness, and quality.","",""
166,"H. Hoos, T. Stützle","Local Search Algorithms for SAT: An Empirical Evaluation",2000,"","","","",28,"2022-07-13 09:19:55","","10.1023/A:1006350622830","","",,,,,166,7.55,83,2,22,"","",""
9,"E. Bradley, A. O'Gallagher, J. Rogers","Global solutions for nonlinear systems using qualitative reasoning",1998,"","","","",29,"2022-07-13 09:19:55","","10.1023/A:1018972409754","","",,,,,9,0.38,3,3,24,"","",""
6,"D. Patterson, M. Galushka, N. Rooney","Characterisation of a Novel Indexing Technique for Case-Based Reasoning",2005,"","","","",30,"2022-07-13 09:19:55","","10.1007/s10462-004-7188-y","","",,,,,6,0.35,2,3,17,"","",""
15,"H. Andersen, D. Dieks, Wenceslao J. Gonzalez, T. Uebel, G. Wheeler","New Challenges to Philosophy of Science",2013,"","","","",31,"2022-07-13 09:19:55","","10.1007/978-94-007-5845-2","","",,,,,15,1.67,3,5,9,"","",""
6,"H. Kitano, M. Yasunaga","Wafer Scale Integration for Massively Parallel Memory-Based Reasoning",1992,"","","","",32,"2022-07-13 09:19:55","","","","",,,,,6,0.20,3,2,30,"In this paper, we describe a design of wafer-scale integration for massively parallel memory-based reasoning (WSI-MBR). WSI-MBR attains about 2 million parallelism on a single 8 inch wafer using the state-of-the-art fabrication technologies. While WSI-MBR is specialized to memory-based reasoning, which is one of the mainstream approachs in massively parallel artificial intelligence research, the level of parallelism attained far surpasses any existing massively parallel hardware. Combination of memory array and analog weight computing circuits enable us to attain super high-density implementation with nanoseconds order inference time. Simulation results indicates that inherent robustness of the memory-based reasoning paradigm overcomes the possible precision degradation and fabrication defects in the wafer-scale integration. Also, the WSI-MBR provides a compact (desk-top size) massively parallel computing environment.","",""
0,"Pan Quan, Zhang Shan-ying, Wang Gang, Z. Hongcai","Some Research on Conflict and Robustness of Evidence Theory",2001,"","","","",33,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,4,21,"Evidence reasoning has good performance in dealing with uncertain information. But in general, Dempster’ s rule is suitable to solve the problem with high belief and low conflict. In this paper, the drawbacks of Dempster’ s rule mentioned above are analyzed firstly. According to the different resource of conflict, two methods are proposed to solve the problem of high conflict. Furthermore, a new concept “conflict rate” is defined and its formula is given out. The robust range of Dempster’ s rule and these two new methods are easily analyzed with the sectional conflict rate and then extended to general discernment frame. As a conclusion, the two methods have better performance in treating with conflict and robustness than Dempster’ s rule and other rules. Key word: Evidence reasoning, conflict rate, artificial intelligence, robustness.","",""
1,"R. Cucchiara, M. Gavanelli, A. Prati, M. Piccardi","Rule-based Reasoning on Visual Data for Urban Traffic Monitoring",2002,"","","","",34,"2022-07-13 09:19:55","","","","",,,,,1,0.05,0,4,20,"The paper describes a system for detecting vehicles in urban traffic scenes by means of rule-based reasoning on visual data. The strength of the proposed approach is its formal separation between low-level image processing modules (able for extracting visual data under various illumination conditions) and the high-level module, which provides a single framework for tracking vehicles in the scene. The image processing modules extract visual data from the scene, by spatio-temporal analysis during day-time, and by morphological analysis of headlights at night. The high-level module is designed as a forward chaining production rule system, working on symbolic data, i.e. vehicles and their attributes (area, pattern, direction...) and exploiting a set of heuristic rules tuned to urban traffic conditions. The synergy between the artificial intelligence techniques of the high level and the lowlevel image analysis techniques provides the system with flexibility and robustness.","",""
7,"K. Zeb, Komal Saleem, C. A. Mehmood, Waqar Uddin, Muhammad Zia ur Rehman, A. Haider, M. A. Javed","Performance of adaptive PI based on fuzzy logic for Indirect Vector Control Induction Motor drive",2016,"","","","",35,"2022-07-13 09:19:55","","10.1109/ICRAI.2016.7791235","","",,,,,7,1.17,1,7,6,"A Novel Adaptive PI based on Fuzzy Logic Reasoning (FLR) is presented in this paper for Indirect Vector Control (IVC) three phase Induction Motor (IM). The main objective is to achieve fast dynamic response and robustness for speed variation, parameter uncertainties, load disturbances, electrical faults perturbations, and to acquire maximum torque and efficiency. The d-q modeling of the IM in synchronously rotating reference frame and Space Vector Pulse Width Modulation (SVPWM) employed in power inverter are carried out in Matlab/Simulink. Both PI and Adaptive PI based on FLR are analyzed, designed, and simulated for IVC IM drive system. Furthermore, the critical and analytical assessment of the aforesaid designed control methodology provides robust and faster response with low overshoot, rise, and settling time for the load disturbances, parameter uncertainties, speed variation, and electrical faults perturbation of IVC IM drive system, compared to prior works.","",""
5,"N. Alaya, S. Yahia, M. Lamolle","RakSOR: Ranking of Ontology Reasoners Based on Predicted Performances",2016,"","","","",36,"2022-07-13 09:19:55","","10.1109/ICTAI.2016.0165","","",,,,,5,0.83,2,3,6,"Over the last decade, several ontology reasoners have been proposed to overcome the computational complexity of inference tasks on expressive ontology languages. Nevertheless, it is well-accepted that there is no outstanding reasoner that can outperform in all input ontologies. Thus, an algorithm selection problem have emerged in this field of study. In this paper, we describe first steps to develop a new system to provide user support when looking for guidance over ontology reasoners. Our main goal is to be able to automatically rank a set of candidate reasoners for any given ontology. Robustness standing for the ability of reasoner to correctly achieve a reasoning task within a fixed time limit is our primary ranking criterion. Our ranking method follows a meta-learning approach and applies bucket order rules. An extensive experiments covering over 2500 well selected real-world ontologies and six state-of-the-art of the most performing reasoners was carried out to provide enough data for the study. Our prediction and ranking results are encouraging, witnessing the potential benefits of the proposed approach.","",""
0,"Stefan Zwicklbauer","Robust Entity Linking in Heterogeneous Domains",2017,"","","","",37,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,1,5,"Entity Linking is the task of mapping terms in arbitrary documents to entities in a knowledge base by identifying the correct semantic meaning. It is applied in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question and Answering. Most existing Entity Linking systems were optimized for specific domains (e.g., general domain, biomedical domain), knowledge base types (e.g., DBpedia, Wikipedia), or document structures (e.g., tables) and types (e.g., news articles, tweets). This led to very specialized systems that lack robustness and are only applicable for very specific tasks. In this regard, this work focuses on the research and development of a robust Entity Linking system in terms of domains, knowledge base types, and document structures and types.    To create a robust Entity Linking system, we first analyze the following three crucial components of an Entity Linking algorithm in terms of robustness criteria: (i) the underlying knowledge base, (ii) the entity relatedness measure, and (iii) the textual context matching technique. Based on the analyzed components, our scientific contributions are three-fold. First, we show that a federated approach leveraging knowledge from various knowledge base types can significantly improve robustness in Entity Linking systems. Second, we propose a new state-of-the-art, robust entity relatedness measure for topical coherence computation based on semantic entity embeddings. Third, we present the neural-network-based approach Doc2Vec as a textual context matching technique for robust Entity Linking.    Based on our previous findings and outcomes, our main contribution in this work is DoSeR (Disambiguation of Semantic Resources). DoSeR is a robust, knowledge-base-agnostic Entity Linking framework that extracts relevant entity information from multiple knowledge bases in a fully automatic way. The integrated algorithm represents a collective, graph-based approach that utilizes semantic entity and document embeddings for entity relatedness and textual context matching computation. Our evaluation shows, that DoSeR achieves state-of-the-art results over a wide range of different document structures (e.g., tables), document types (e.g., news documents) and domains (e.g., general domain, biomedical domain). In this context, DoSeR outperforms all other (publicly available) Entity Linking algorithms on most data sets.","",""
0,"Dr. Roberto Passailaigue Baquerizo, Vivian Estrada Sentí, Dr. Juan P. Febles Rodríguez","Evaluation of the socialization of knowledge and collaboration in educational management",2017,"","","","",38,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,3,5,"1Ph.D, Canciller Universidad Tecnológica ECOTEC, Ecuador 2 Ph.D, Universidad de las Ciencias Informáticas, Metodóloga de posgrado, La Habana, Cuba 3 Ph.D, Universidad de las Ciencias Informáticas, Metodólogo de posgrado, La Habana, Cuba ---------------------------------------------------------------------***--------------------------------------------------------------------Abstract The authors, using qualitative research methods, the Case-Based Reasoning as a paradigm of Artificial Intelligence and based on various data and opinions obtained from research on educational networks developed previously achieved knowledge representation for the status of socialization and collaboration in the process of educational management of selected educational institutions. The base case was tested with various situations and the results were 100% correct (in the test cases were used whose answers were known). The result intersects technological aspects associated with conclusions and recommendations to educational management, which were timely validated in previous processes and ensures the robustness of the proposal that article is performed.","",""
2,"J. Olszewska","Tracking The Invisible Man - Hidden-object Detection for Complex Visual Scene Understanding",2016,"","","","",39,"2022-07-13 09:19:55","","10.5220/0005852302230229","","",,,,,2,0.33,2,1,6,"Reliable detection of objects of interest in complex visual scenes is of prime importance for video-surveillance applications. While most vision approaches deal with tracking visible or partially visible objects in single or multiple video streams, we propose a new approach to automatically detect all objects of interest being part of an analyzed scene, even those entirely hidden in a camera view whereas being present in the scene. For that, we have developed an innovative artificial-intelligence framework embedding a computer vision process fully integrating symbolic knowledge-based reasoning. Our system has been evaluated on standard datasets consisting of video streams with real-world objects evolving in cluttered, outdoor environment under difficult lighting conditions. Our proposed approach shows excellent performance both in detection accuracy and robustness, and outperforms state-of-the-art methods.","",""
3,"M. Geetha, J. Jerome","Fuzzy expert system based sensor and actuator fault diagnosis for continuous stirred tank reactor",2013,"","","","",40,"2022-07-13 09:19:55","","10.1109/IFUZZY.2013.6825445","","",,,,,3,0.33,2,2,9,"An approach on the degree in artificial intelligence applications to model-based diagnosis for dynamic nonlinear CSTR processes is proposed. Stress is placed on residual generation and residual evaluation employing fuzzy logic. Especially for residual generation, a novel Extended Kalman Filter concept, on knowledge Estimator, is introduced. An intelligent fuzzy approach for residual generation and evaluation is also defined. A fuzzy-reasoning approach is proposed to guarantee robustness to the inherent doubtfulness in the identified trends and to provide compact mapping. A two-staged strategy is employed: (i) identifying the most likely fault candidates based on a resemblance measure between the observed trends and the event-signatures in the cognition-base and, (ii) estimation of the fault magnitude. The fuzzy-cognition-base consists of a set of physically explainable if/then rules providing physical insight into the process. This technique provides multivariate differencing and is transparent for fault detection.","",""
11,"Kenneth D. Forbus, E. Tomai","A pragmatic approach to computational narrative understanding",2009,"","","","",41,"2022-07-13 09:19:55","","","","",,,,,11,0.85,6,2,13,"Narrative understanding is a hard problem for artificial intelligence that requires deep semantic understanding of natural language and broad world knowledge. Early research in this area stalled due to the difficulty of knowledge engineering and a trend in the field towards robustness at the expense of depth. This work explores how a practical integration of more recent resources and theories for natural language understanding can perform deep semantic interpretation of narratives when guided by specific pragmatic constraints. It shows how cognitive models can provide pragmatic context for narrative understanding in terms of well-defined reasoning tasks, and how those tasks can be used to guide interpretation and evaluate understanding.  This work presents an implemented system, EA NLU, which has been used to interpret narrative text input to cognitive modeling simulations. EA NLU integrates existing large-scale knowledge resources with a controlled grammar and a compositional semantic interpretation process to generate highly expressive logical representations of sentences. Delayed disambiguation and representations from dynamic logic are used to separate this compositional process from a querydriven discourse interpretation process that is guided by pragmatic concerns and uses world knowledge. By isolating explicit points of ambiguity and using limited evidential abduction, this query-driven process can automatically identify the disambiguation choices that entail relevant interpretations. This work shows how this approach maintains computational tractability without sacrificing expressive power. EA NLU is evaluated through a series of experiments with two cognitive models, showing that it is capable of meeting the deep reasoning requirements those models pose, and that the constraints provided by the models can effectively guide the interpretation process. By enforcing consistent interpretation principles, EA NLU benefits the cognitive modeling experiments by reducing the opportunities for tailoring the input.  This work also explores the use of a theory of narrative functions as a heuristic guide to interpretation in EA NLU. In contrast to potentially global task-specific queries, these narrative functions can be inferred on a sentence-by-sentence basis, providing incremental disambiguation. This method is evaluated by interpreting a set of Aesop's fables, and showing that the interpretations are sufficient to capture the intended lesson of each fable.","",""
3,"Xu Yun","Design of Hybrid Cognitive Engine in Cognitive Radios",2010,"","","","",42,"2022-07-13 09:19:55","","","","",,,,,3,0.25,3,1,12,"To enhance the performance of cognitive engine(CE) and to better realize the intelligent parameters adjusting in cognitive radio(CR) system,a hybrid cognitive engine(HCE) is designed by using multiple artificial intelligent methods synthetically for reasoning,learning,optimization,decision,and so on.Classical CE models and artificial intelligence for CE are analysed.The HCE function architecture block diagram is created,and the working mechanism and technology characteristics of HCE are discussed.The analysis shows that HCE has strong agility and robustness.","",""
0,"Peer-Olaf Siebers","Hongmei He (intelligent System Lab, University of Bristol): Soft Computing Approaches under the Framework of Hierarchical Decision Making or Classification System",2010,"","","","",43,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,1,12,"Hongmei He (Intelligent System Lab, University of Bristol): Soft Computing Approaches Under the Framework of Hierarchical Decision Making or Classification System With the development of AI, we can see there are a surprising number of the brain functions of the human Intelligent System (IS) are quite similar to those of an artificial IS, since most artificial ISs are modelled through naturally emulating human intelligence. A wide variety of approaches have been utilised in the functional design of artificial ISs. For example, fuzzy logic for robustness, decision trees for the transparency of reasoning, machine learning for knowledge learning, semantics for understandability, probabilistic reasoning, and neural computing, etc.","",""
4,"Xiaoyang Tong, Xiaoru Wang","Agent-oriented Petri Net based Modeling of Dynamic Behavior for Wide-area Backup Protection",2007,"","","","",44,"2022-07-13 09:19:55","","10.1109/SNPD.2007.95","","",,,,,4,0.27,2,2,15,"The study of agent-based wide-area backup protection (WABP) in power system has become a hot. An improved agent-oriented Petri net (AOPN) is proposed to simulate dynamic behaviors of multi-agent system. The general architecture of improved AOPN is set up, as well as formalized definitions, structural properties and theorems to describe Petri net. Agent-oriented Petri net for WABP is constructed; autonomy, corporation, concurrency and robustness characters of WABP agent are designed. The analysis of L3-liveness and consistency of Petri net are given. The reasoning results of three samples illustrate the accurateness of Petri net for WABP and effectiveness of capturing dynamic behaviors. Design errors can be found to make the system being robust and reliable.","",""
3,"Burkhard Schafer","Can you have too much of a good thing? A comment on Bart Verheij's legal argumentation support software",2007,"","","","",45,"2022-07-13 09:19:55","","10.1093/LPR/MGM038","","",,,,,3,0.20,3,1,15,"Bart Verheij’s paper (this volume, p. 187) on argumentation support software (ASS) gives an excellent account of the past and present of ASS for legal reasoning, and offers some tantalizing glimpses of what the future may have to offer. In my reply, I want to focus on one particular aspect of his presentation, the use of ASS as a teaching tool and in particular a tool for the teaching of reasoning with facts and evidence. Generally speaking, there are good reasons to be sceptical when artificial intelligence (AI) systems are presented as teaching aids. The search for commercial strength legal expert systems that perform autonomously the tasks of human experts has so far proved largely elusive. Two related issues in particular have been identified as recurrent problems. The first is robustness, i.e. the ability to deal with new scenarios not anticipated by the developers. Systems are said to be robust if they remain operational in circumstances for which they were not designed. In the context of criminal evidence, for instance, robustness would require adaptability to unforeseen crime scenarios. This objective is difficult to achieve because low-volume major crimes tend to be virtually unique. Each major crime scenario potentially consists of a unique set of circumstances, while many conventional AI techniques have difficulties in handling previously unseen problem settings. This then results in the second problem, the knowledge acquisition bottleneck. Reasoning about evidence in legal settings is knowledge intensive, requiring input from a broad range of scientific disciplines and also formal representations of large chunks of everyday knowledge. In teaching environments by contrast, the educator has control over the type of problems they choose, their complexity and relevant parameters and features. This brings teaching applications seemingly closer to the ‘worked examples’ or prototypes that are so often the result of the research programs by small teams of academics that dominate the AI and law field—including projects by the author of this reply. Verheij deserves considerable credit for resisting the temptation to see teaching applications just as a simpler task for AI research. Of particular value is his emphasis on rigorous empirical evaluation of the effectiveness of his systems in a teaching environment, and the systematic way in which evaluations that he has carried out in the past influence his theoretical analysis of the problem. This type of evidence-based approach to software-supported teaching in law has so far been missing. Indeed, with few exceptions such as Hall and Zeleznikow (2001), there has been little research into the empirical valuation of legal AI in general. His conclusions are refreshingly honest too, identifying some potential problems in his own approach and indicating a whole range of possible extensions and even wholesale revisions. My observations and comments will elaborate on these findings. In","",""
1,"Safety for Technical Processes, Hongyue Zhang","Fault detection, supervision and safety of technical processes 2006 : a proceedings volume from the 6th IFAC symposium, SAFEPROCESS 2006, Beijing, P.R., China, August 30-September 1, 2006",2007,"","","","",46,"2022-07-13 09:19:55","","","","",,,,,1,0.07,1,2,15,"Fault Detection, Isolation and Identification Model-based methods: observers, parity relations and identification Statistical approaches Fault modelling Signal analysis Design measures for robustness Pattern recognition Computational Intelligence in Fault Diagnosis Expert systems Fuzzy logic and rough sets Artificial neural networks Neuro-fuzzy approaches Qualitative reasoning Design for Reliability and Safety Reliability and safety analysis Probabilistic safety assessment Testing and evaluation of safety systems Safety standards and qualification Safety evaluation tools Fault Tolerant Systems Design Fault prediction Fault tolerant and fail-safe control Design measures for fault tolerance Reconfigurable and scalable control systems Maintenance and Repair Maintenance and repair strategies Predictive maintenance Operator support information systems Life-cycle considerations Human Factors Human factors in automation Human reliability analysis Support for systems operation and decision making Industrial safety management and safety culture Economic, environmental and ecological aspects of fault diagnosis Industrial Applications and Case Studies Electrical, mechanical and electronic systems Chemical and biomedical processes Transportation, traffic and automotive systems Power systems Marine systems Aeronautics and aerospace Evaluation of benchmark problems","",""
1,"M. Hagiwara, Y. Anzai","Connectionist Model Data Base System with a Template for Association",1992,"","","","",47,"2022-07-13 09:19:55","","10.1541/IEEJEISS1987.112.3_165","","",,,,,1,0.03,1,2,30,"Combination of Artificial Intelligence (AI) and Connectionist model is very effective to construct an intelligent information processing system. There are several studies based on such a concept. An example, a knowledge base system based on connectionist model has the following features. (1) Robustness : even when there are some errors in a user's question or in a knowledge base, a near right answer can be obtained. (2) Context dependency : retrieval with prediction is possible. (3) Easy parallel retrieval for multiple concepts. (4) Easy maintenance of knowledge base : facts are expressed by symbols. In spite of the above advantages, the conventional system has a great shortcoming : it can only make inference of facts. This paper proposes a connectionist model data base system with a template for association. The proposed system has two features : inference is possible when data is insufficient, and new knowl edge can be generated by inference. The proposed system uses a template to create a network for associative reasoning, and it can be done by interactive activation and competition process. Computer simulation result indicates the effectiveness of the proposed system.","",""
0,"A. Abraham, C. Grosan","ON SOFT COMPUTING FOR MODELING AND SIMULATION",1998,"","","","",48,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,2,24,"It is well known that the intelligent systems, which can provide human like expertise such as domain knowledge, uncertain reasoning, and adaptation to a noisy and time varying environment, are important in tackling practical computing problems. In contrast with conventional artificial intelligence techniques which only deal with precision, certainty and rigor the guiding principle of soft computing is to exploit the tolerance for imprecision, uncertainty, low solution cost, robustness, partial truth to achieve tractability, and better rapport with reality [Zadeh, 1998]. Soft computing is a consortium of technologies involving approximate reasoning, function approximation, learning capabilities, and a methodology for systematic random search and optimization. These capabilities are combined in a complementary and synergetic fashion. Soft computing has evolved not only from a theoretical point of view but also with a large variety of realistic applications to consumer products and industrial systems. Applications of soft computing have provided the opportunity to integrate humanlike vagueness and real-life uncertainty into an otherwise hard computer programs.","",""
2,"M. Bringmann","Knowledge acquisition through the use of combined repertory grids",1990,"","","","",49,"2022-07-13 09:19:55","","","","",,,,,2,0.06,2,1,32,"Artificial intelligence is the study of the simulation of human cognitive faculties. Applications of various aspects of AI are important to the development of expert or knowledge-based systems. An individual expert system can be characterized by the methods selected for representing expertise, transfer of expertise and user interaction. Various aspects of a domain can be represented by separate knowledge sources acquired from different experts or through different models of reasoning. Combination of these knowledge sources can improve the capability or robustness of a model of a domain. The literature of clinical and experimental psychology contains much research relevant to the problem of improving the communication between knowledge engineers and domain experts. Specifically, the Personal Construct Theory of George A. Kelly (1955) has served as the basis for several recent experimental approaches to the design and construction of automated (i.e., computer-based) knowledge acquisition tools. A measure of the shared aspects of domain knowledge common to multiple experts is developed and illustrated with this model using knowledge gathered about two different domains. A model of the shared aspects of personal construct systems of a domain is developed and a system to draw conclusions based upon this information is also proposed.","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",50,"2022-07-13 09:19:55","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
2,"Qiwei-Kong, Jing He, Peizhuang Wang","Factor space:a new idea for artificial intelligence based on causal reasoning",2020,"","","","",51,"2022-07-13 09:19:55","","10.1109/WIIAT50758.2020.00089","","",,,,,2,1.00,1,3,2,"In the rapid development of artificial intelligence in the last several years, machine learning is the mainstream method to realize artificial intelligence. What people usually call machine learning can be equivalent to statistical learning, which requires big data and powerful computing power; This is a machine learning trend driven by data, using algorithms to get a model with clear parameters, ignoring causal reasoning and focusing on statistical data; The machine learning method lacking logical causal reasoning will greatly hinder the advancement of artificial intelligence; How knowledge-driven causal reasoning provides new ideas for artificial intelligence is a question worth thinking about for scholars of artificial intelligence. Factor space theory that emphasizes causal reasoning will provide a new perspective and thinking for the development of artificial intelligence.","",""
120,"R. Byrne","Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning",2019,"","","","",52,"2022-07-13 09:19:55","","10.24963/IJCAI.2019/876","","",,,,,120,40.00,120,1,3,"Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence (AI) applications, and especially in explainable AI (XAI). Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in AI.","",""
0,"M. Manna, Andreas Pieris","Reasoning Web. Declarative Artificial Intelligence: 16th International Summer School 2020, Oslo, Norway, June 24–26, 2020, Tutorial Lectures",2020,"","","","",53,"2022-07-13 09:19:55","","10.1007/978-3-030-60067-9","","",,,,,0,0.00,0,2,2,"","",""
134,"J. Lamy, B. Sekar, Gilles Guézennec, J. Bouaud, B. Séroussi","Explainable artificial intelligence for breast cancer: A visual case-based reasoning approach",2019,"","","","",54,"2022-07-13 09:19:55","","10.1016/J.ARTMED.2019.01.001","","",,,,,134,44.67,27,5,3,"","",""
2,"Frank Guerin","Projection: A Mechanism for Human-like Reasoning in Artificial Intelligence",2021,"","","","",55,"2022-07-13 09:19:55","","10.1080/0952813x.2022.2078889","","",,,,,2,2.00,2,1,1,"Artiﬁcial Intelligence systems cannot yet match human abilities to apply knowledge to situations that vary from what they have been programmed for, or trained for. In visual object recognition, methods of inference exploiting top-down information (from a model) have been shown to be eﬀective for recognising entities in diﬃcult conditions. Here a component of this type of inference, called ‘projection’, is shown to be a key mechanism to solve the problem of applying knowledge to varied or challenging situations, across a range of AI domains, such as vision, robotics, or language. Finally the relevance of projection to tackling the commonsense knowledge problem is discussed.","",""
0,"Janmanchi Harika, Palavadi Baleeshwar, Kummari Navya, Hariharan Shanmugasundaram","A Review on Artificial Intelligence with Deep Human Reasoning",2022,"","","","",56,"2022-07-13 09:19:55","","10.1109/icaaic53929.2022.9793310","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) is a broad term that can be construed to mean a focusing computer programming and development that is designed to train machines and to perform task. Artificial intelligence can be used to test theories of reasoning like cognitive reasoning and consciousness. Research has been conducted on the development of machines with human behavior and cognitive characteristics that are related to consciousness. Artificial Intelligence and Reasoning that are dealt with, can necessarily solve problems related to mental health issues that humans find complex, but research on new interaction techniques and human for cooperation theories, technologies limited the issues and challenges facing the application of artificial reasoning. Here in this paper, the relation between artificial intelligence human reasoning that is also called as AI reasoning or artificial reasoning has been studied. Artificial intelligence impacts reasoning and how artificial reasoning can be used in day-to-day activities to regain our mental health. Moreover, this work focuses on problems that can be solved with AI Reasoning in trying to find the possible solutions.","",""
0,"","Reasoning Web. Declarative Artificial Intelligence: 17th International Summer School 2021, Leuven, Belgium, September 8–15, 2021, Tutorial Lectures",2022,"","","","",57,"2022-07-13 09:19:55","","10.1007/978-3-030-95481-9","","",,,,,0,0.00,0,0,1,"","",""
0,"M. Krötzsch, D. Stepanova","Reasoning Web. Explainable Artificial Intelligence: 15th International Summer School 2019, Bolzano, Italy, September 20–24, 2019, Tutorial Lectures",2019,"","","","",58,"2022-07-13 09:19:55","","10.1007/978-3-030-31423-1","","",,,,,0,0.00,0,2,3,"","",""
3,"A. Sans, D. Casacuberta","Remarks on the Possibility of Ethical Reasoning in an Artificial Intelligence System by Means of Abductive Models",2018,"","","","",59,"2022-07-13 09:19:55","","10.1007/978-3-030-32722-4_19","","",,,,,3,0.75,2,2,4,"","",""
0,"德钧 邱","Automatic Logic Reasoning in Artificial Intelligence",2019,"","","","",60,"2022-07-13 09:19:55","","10.12677/airr.2019.81002","","",,,,,0,0.00,0,1,3,"","",""
12,"S. Craw, A. Aamodt","Case Based Reasoning as a Model for Cognitive Artificial Intelligence",2018,"","","","",61,"2022-07-13 09:19:55","","10.1007/978-3-030-01081-2_5","","",,,,,12,3.00,6,2,4,"","",""
15,"M. Bonacina","Automated Reasoning for Explainable Artificial Intelligence",2017,"","","","",62,"2022-07-13 09:19:55","","10.29007/4B7H","","",,,,,15,3.00,15,1,5,"Reasoning and learning have been considered fundamental features of intelligence ever since the dawn of the field of artificial intelligence, leading to the development of the research areas of automated reasoning and machine learning. This paper discusses the relationship between automated reasoning and machine learning, and more generally between automated reasoning and artificial intelligence. We suggest that the emergence of the new paradigm of XAI, that stands for eXplainable Artificial Intelligence, is an opportunity for rethinking these relationships, and that XAI may offer a grand challenge for future research on automated reasoning. 1 Artificial Intelligence, Automated Reasoning, and Ma-","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",63,"2022-07-13 09:19:55","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
50,"L. D. Raedt, Sebastijan Dumancic, Robin Manhaeve, G. Marra","From Statistical Relational to Neuro-Symbolic Artificial Intelligence",2020,"","","","",64,"2022-07-13 09:19:55","","10.24963/ijcai.2020/677","","",,,,,50,25.00,13,4,2,"Neuro-symbolic and statistical relational artificial intelligence both integrate frameworks for learning with logical reasoning. This survey identifies several parallels across seven different dimensions between these two fields. These cannot only be used to characterize and position neuro-symbolic artificial intelligence approaches but also to identify a number of directions for further research.","",""
1,"Y. Sheng, Jiahan Zhang, Y. Ge, Xinyi Li, Wentao Wang, H. Stephens, F. Yin, Qiuwen Wu, Q. Wu","Artificial intelligence applications in intensity modulated radiation treatment planning: an overview.",2021,"","","","",65,"2022-07-13 09:19:55","","10.21037/qims-21-208","","",,,,,1,1.00,0,9,1,"Artificial intelligence (AI) refers to methods that improve and automate challenging human tasks by systematically capturing and applying relevant knowledge in these tasks. Over the past decades, a number of approaches have been developed to address different types and needs of system intelligence ranging from search strategies to knowledge representation and inference to robotic planning. In the context of radiation treatment planning, multiple AI approaches may be adopted to improve the planning quality and efficiency. For example, knowledge representation and inference methods may improve dose prescription by integrating and reasoning about the domain knowledge described in many clinical guidelines and clinical trials reports. In this review, we will focus on the most studied AI approach in intensity modulated radiation therapy (IMRT)/volumetric modulated arc therapy (VMAT)-machine learning (ML) and describe our recent efforts in applying ML to improve the quality, consistency, and efficiency of IMRT/VMAT planning. With the available high-quality data, we can build models to accurately predict critical variables for each step of the planning process and thus automate and improve its outcomes. Specific to the IMRT/VMAT planning process, we can build models for each of the four critical components in the process: dose-volume histogram (DVH), Dose, Fluence, and Human Planner. These models can be divided into two general groups. The first group focuses on encoding prior experience and knowledge through ML and more recently deep learning (DL) from prior clinical plans and using these models to predict the optimal DVH (DVH prediction model), or 3D dose distribution (dose prediction model), or fluence map (fluence map model). The goal of these models is to reduce or remove the trial-and-error process and guarantee consistently high-quality plans. The second group of models focuses on mimicking human planners' decision-making process (planning strategy model) during the iterative adjustments/guidance of the optimization engine. Each critical step of the IMRT/VMAT treatment planning process can be improved and automated by AI methods. As more training data becomes available and more sophisticated models are developed, we can expect that the AI methods in treatment planning will continue to improve accuracy, efficiency, and robustness.","",""
1,"R. Joshi, Neeraj Kumar","Artificial Intelligence for Autonomous Molecular Design: A Perspective",2021,"","","","",66,"2022-07-13 09:19:55","","10.3390/molecules26226761","","",,,,,1,1.00,1,2,1,"Domain-aware artificial intelligence has been increasingly adopted in recent years to expedite molecular design in various applications, including drug design and discovery. Recent advances in areas such as physics-informed machine learning and reasoning, software engineering, high-end hardware development, and computing infrastructures are providing opportunities to build scalable and explainable AI molecular discovery systems. This could improve a design hypothesis through feedback analysis, data integration that can provide a basis for the introduction of end-to-end automation for compound discovery and optimization, and enable more intelligent searches of chemical space. Several state-of-the-art ML architectures are predominantly and independently used for predicting the properties of small molecules, their high throughput synthesis, and screening, iteratively identifying and optimizing lead therapeutic candidates. However, such deep learning and ML approaches also raise considerable conceptual, technical, scalability, and end-to-end error quantification challenges, as well as skepticism about the current AI hype to build automated tools. To this end, synergistically and intelligently using these individual components along with robust quantum physics-based molecular representation and data generation tools in a closed-loop holds enormous promise for accelerated therapeutic design to critically analyze the opportunities and challenges for their more widespread application. This article aims to identify the most recent technology and breakthrough achieved by each of the components and discusses how such autonomous AI and ML workflows can be integrated to radically accelerate the protein target or disease model-based probe design that can be iteratively validated experimentally. Taken together, this could significantly reduce the timeline for end-to-end therapeutic discovery and optimization upon the arrival of any novel zoonotic transmission event. Our article serves as a guide for medicinal, computational chemistry and biology, analytical chemistry, and the ML community to practice autonomous molecular design in precision medicine and drug discovery.","",""
139,"D. Parkes, Michael P. Wellman","Economic reasoning and artificial intelligence",2015,"","","","",67,"2022-07-13 09:19:55","","10.1126/science.aaa8403","","",,,,,139,19.86,70,2,7,"The field of artificial intelligence (AI) strives to build rational agents capable of perceiving the world around them and taking actions to advance specified goals. Put another way, AI researchers aim to construct a synthetic homo economicus, the mythical perfectly rational agent of neoclassical economics. We review progress toward creating this new species of machine, machina economicus, and discuss some challenges in designing AIs that can reason effectively in economic contexts. Supposing that AI succeeds in this quest, or at least comes close enough that it is useful to think about AIs in rationalistic terms, we ask how to design the rules of interaction in multi-agent systems that come to represent an economy of AIs. Theories of normative design from economics may prove more relevant for artificial agents than human agents, with AIs that better respect idealized assumptions of rationality than people, interacting through novel rules and incentive systems quite distinct from those tailored for people.","",""
0,"Ranjith Raveendran, Suresh Perumbure, Sameera G Nath","Artificial intelligence: A newer vista in dentistry.",2021,"","","","",68,"2022-07-13 09:19:55","","10.1111/aor.14128","","",,,,,0,0.00,0,3,1,"BACKGROUND Artificial intelligence (AI) is one of the newest fields in science and engineering. It refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. Artificial intelligence as a science is very broad and encompasses various fields, including reasoning, natural language processing, planning, and machine learning. In modern times the real-world current applications of AI include health care, automotive, finance and economics, playing video games, solving mathematical theorems, writing poetry, driving a car on a crowded street, and many more all of which aim to improve human life.   METHODS The aim of this article is to review the current application of AI in the field of dentistry based on electronic search in various data bases like Google scholar, PubMed, and Scopus.   RESULTS The present review outlines the potential applications of AI in the field of Dentistry in diagnosis, treatment planning, and disease prediction and discusses its impact on dentists, with the objective of creating a support for future research in this rapidly expanding arena.   CONCLUSIONS Artificial intelligence systems can simplify the tasks, give a standardization to the procedures and provide results in quick time which can save the dentist time and help the dentist to perform his duties more efficiently.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",69,"2022-07-13 09:19:55","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
38,"H. Jaeger","Artificial intelligence: Deep neural reasoning",2016,"","","","",70,"2022-07-13 09:19:55","","10.1038/nature19477","","",,,,,38,6.33,38,1,6,"","",""
26,"T. Denœux, D. Dubois, H. Prade","Representations of Uncertainty in Artificial Intelligence: Probability and Possibility",2020,"","","","",71,"2022-07-13 09:19:55","","10.1007/978-3-030-06164-7_3","","",,,,,26,13.00,9,3,2,"","",""
301,"E. Davis, G. Marcus","Commonsense reasoning and commonsense knowledge in artificial intelligence",2015,"","","","",72,"2022-07-13 09:19:55","","10.1145/2701413","","",,,,,301,43.00,151,2,7,"AI has seen great advances of many kinds recently, but there is one critical area where progress has been extremely slow: ordinary commonsense.","",""
47,"T. Frei","An Artificial Intelligence Approach To Legal Reasoning",2016,"","","","",73,"2022-07-13 09:19:55","","","","",,,,,47,7.83,47,1,6,"ed to be an introduction to computational jurisprudence for both groups. It identifies issues critical to the purpose , behavior, knowledge sources, knowledge structures, and reasoning processes of expert legal systems. The second part implements a simple prototype system for a well-defined area of contract law and is more appropriate for experienced developers of knowledge-based systems. Law is a domain in which the experts are supposed to disagree, and lawyers must be able to argue either side of a case. A judge or juror must decide which argument is "" best. "" A knowledge based legal reasoning program can only guide analysis and identification of technically defensi-ble positions in a case. However, it should also be able to distinguish between questions that are "" easy "" to decide, and those demanding human analysis. These two ideas form the basis of the prototype's behavior, making it somewhat different from knowledge based systems in most other expert domains. According to Gardner, legal reasoning systems are further distinguished by their knowledge sources and knowledge structures. She reviews the evolution of legal thought in the context of knowledge engineering, raises several critical issues, and draws conclusions about how legal knowledge must be used and represented in programs. In the human world, legal knowledge is represented in cases, and statutes. Although not all areas of law use both sources, she concludes that expert legal systems need both types of knowledge, plus some additional "" common sense knowledge "" to guide analysis effectively. Gardner views statutes as rules defining legal states and their consequences. Although they are convenient starting points for legal analysis , they are usually insufficient for making wise legal decisions. Most litigation involves questions about whether the rules have been followed, what the rules actually mean, and sometimes, which set of rules should be used. Cases contain written arguments about how to answer these questions under specific circumstances, along with their final interpretation by the juror. Lawyers can use similar cases as examples to guide their formulation of arguments in future disputes. Cases are used as precedents for deciding which rules to use in a given situation, and how to apply them. They can be used to annotate and clarify rules that conflict in some context, or whose relevance might be disputed. They can even change the way rules are applied to similar factual situations in the future. In these respects, cases embody …","",""
0,"A. Raglin, Henry Hoffman, Mark R. Mittrick, Haitao Zheng, Justine P. Caylor","Artificial Reasoning Toward Goal-Oriented Adaptive Arrays of Sensors",2021,"","","","",74,"2022-07-13 09:19:55","","10.1109/CogMI52975.2021.00034","","",,,,,0,0.00,0,5,1,"Army future modernization will require an increased focus on data analytics, autonomous systems, cyber security, and automated decision-making, all influenced by emerging capabilities from artificial intelligence research. A critical area of importance is autonomous sensing on the battlefield, such as the ability to detect and reason about people, equipment, and obstacles within the Army's operational environment. The operational environment is extremely complex, dynamic, and fast-paced with highly cluttered data from multiple information sources and heterogeneous systems. The creation and deployment of goal-oriented adaptive arrays of sensors, with various levels of reasoning, could potentially provide capabilities to address these challenges. This paper will present research ideas for incorporating artificial reasoning within a goal-oriented adaptive array of sensors, granting them the ability to reason about methods to improve their performance, use context to interpret multisource data, detect outliers that impact decision-making, and leverage inferencing techniques to support mission goals.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",75,"2022-07-13 09:19:55","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",76,"2022-07-13 09:19:55","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
77,"Alon Jacovi, Ana Marasović, Tim Miller, Yoav Goldberg","Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",2020,"","","","",77,"2022-07-13 09:19:55","","10.1145/3442188.3445923","","",,,,,77,38.50,19,4,2,"Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.","",""
260,"Huiying Liang, B. Tsui, H. Ni, C. Valentim, Sally L. Baxter, Guangjian Liu, Wenjia Cai, Daniel S. Kermany, Xin Sun, Jiancong Chen, Liya He, Jie Zhu, Pin Tian, Hua Shao, Lianghong Zheng, Rui Hou, Sierra Hewett, Gen Li, P. Liang, Xuan Zang, Zhiqi Zhang, Liyan Pan, Huimin Cai, Rujuan Ling, Shuhua Li, Yongwang Cui, Shusheng Tang, Hong Ye, Xiaoyan Huang, Waner He, W. Liang, Qing Zhang, Jianmin Jiang, Wei Yu, Jianqun Gao, Wanxing Ou, Ying Deng, Qiaozhen Hou, Bei Wang, Cuichan Yao, Yan Liang, Shu Zhang, Yaou Duan, Runze Zhang, Sarah Gibson, Charlotte L. Zhang, Oulan Li, Edward D. Zhang, Gabriel Karin, N. Nguyen","Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence",2019,"","","","",78,"2022-07-13 09:19:55","","10.1038/s41591-018-0335-9","","",,,,,260,86.67,26,50,3,"","",""
1,"D. Dubois, H. Prade","A Glance at Causality Theories for Artificial Intelligence",2020,"","","","",79,"2022-07-13 09:19:55","","10.1007/978-3-030-06164-7_9","","",,,,,1,0.50,1,2,2,"","",""
0,"Wei Yan","IEEE Transactions on Artificial Intelligence",2020,"","","","",80,"2022-07-13 09:19:55","","10.1109/tfuzz.2020.2987029","","",,,,,0,0.00,0,1,2,"The IEEE Transactions on Artificial Intelligence (TAI) is a multidisciplinary journal publishing papers on theories and methodologies of Artificial Intelligence. Applications of Artificial Intelligence are also considered. Topics covered by IEEE TAI include, but not limited to, Agent-based Systems, Augmented Intelligence, Autonomic Computing, Constraint Systems, Explainable AI, Knowledge-Based Systems, Learning Theories, Planning, Reasoning, Search, Natural Language Processing, and Applications. Technical papers addressing contemporary topics in AI such as Ethics and Social Implications are welcomed.","",""
0,"R. Brachman, David Gunning, Murray Burke","Integrated Artificial Intelligence Systems",2020,"","","","",81,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,3,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 66 AI MAGAZINE When one thinks about what it might take to build an intelligent system, it is evident that multiple capabilities will be required. Intelligence is generally considered to be reflected in the ability of a system to learn and understand the world around it, and to deal successfully with new or challenging situations. A closer look at what it might take to accomplish this reveals a surprisingly complex set of abilities that must work together. There are many variations on these themes, but roughly speaking, a robustly intelligent, autonomous agent embedded in the real world will need perceptual capabilities to sense and help interpret external signals and phenomena; a set of beliefs about the world, including itself and other agents, cause and effect, and a host of other things relevant to its survival and success in achieving its goals; a variety of reasoning capabilities to determine implications of its beliefs, understand its environment, plan ahead, solve problems, and so forth; a wide array of learning and adaptation capabilities; the ability to affect the world through action; and, some kind of rich communication mechanism along the lines of natural human language generation and understanding.  From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richlyintegrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI. Integrated Artificial Intelligence Systems","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",82,"2022-07-13 09:19:55","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
39,"Ashley S. Deeks","The Judicial Demand for Explainable Artificial Intelligence",2019,"","","","",83,"2022-07-13 09:19:55","","","","",,,,,39,13.00,39,1,3,"A recurrent concern about machine learning algorithms is that they operate as “black boxes,” making it difficult to identify how and why the algorithms reach particular decisions, recommendations, or predictions. Yet judges will confront machine learning algorithms with increasing frequency, including in criminal, administrative, and tort cases. This Essay argues that judges should demand explanations for these algorithmic outcomes. One way to address the “black box” problem is to design systems that explain how the algorithms reach their conclusions or predictions. If and as judges demand these explanations, they will play a seminal role in shaping the nature and form of “explainable artificial intelligence” (or “xAI”). Using the tools of the common law, courts can develop what xAI should mean in different legal contexts.    There are advantages to having courts to play this role: Judicial reasoning that builds from the bottom up, using case-by-case consideration of the facts to produce nuanced decisions, is a pragmatic way to develop rules for xAI. Further, courts are likely to stimulate the production of different forms of xAI that are responsive to distinct legal settings and audiences. More generally, we should favor the greater involvement of public actors in shaping xAI, which to date has largely been left in private hands.","",""
27,"N. S. Saravana Kumar","IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN IMPARTING EDUCATION AND EVALUATING STUDENT PERFORMANCE",2019,"","","","",84,"2022-07-13 09:19:55","","10.36548/jaicn.2019.1.001","","",,,,,27,9.00,27,1,3,"Simulation of human intelligence process is made possible with the help of artificial intelligence. The learning, reasoning and self-correction properties are made possible in computer systems. Along with AI, other technologies are combined effectively in order to create remarkable applications. We apply the changing role of AI and its techniques in new educational paradigms to create a personalised teaching-learning environment. Features like recognition, pattern matching, decision making, reasoning, problem solving and so on are applied along with knowledge based system and supervised machine learning for a complete learning and assessment process.","",""
0,"Ekaterina Jussupow, Kai Spohrer, A. Heinzl","Identity Threats as a Reason for Resistance to Artificial Intelligence: Survey Study With Medical Students and Professionals",2022,"","","","",85,"2022-07-13 09:19:55","","10.2196/28750","","",,,,,0,0.00,0,3,1,"Background Information systems based on artificial intelligence (AI) have increasingly spurred controversies among medical professionals as they start to outperform medical experts in tasks that previously required complex human reasoning. Prior research in other contexts has shown that such a technological disruption can result in professional identity threats and provoke negative attitudes and resistance to using technology. However, little is known about how AI systems evoke professional identity threats in medical professionals and under which conditions they actually provoke negative attitudes and resistance. Objective The aim of this study is to investigate how medical professionals’ resistance to AI can be understood because of professional identity threats and temporal perceptions of AI systems. It examines the following two dimensions of medical professional identity threat: threats to physicians’ expert status (professional recognition) and threats to physicians’ role as an autonomous care provider (professional capabilities). This paper assesses whether these professional identity threats predict resistance to AI systems and change in importance under the conditions of varying professional experience and varying perceived temporal relevance of AI systems. Methods We conducted 2 web-based surveys with 164 medical students and 42 experienced physicians across different specialties. The participants were provided with a vignette of a general medical AI system. We measured the experienced identity threats, resistance attitudes, and perceived temporal distance of AI. In a subsample, we collected additional data on the perceived identity enhancement to gain a better understanding of how the participants perceived the upcoming technological change as beyond a mere threat. Qualitative data were coded in a content analysis. Quantitative data were analyzed in regression analyses. Results Both threats to professional recognition and threats to professional capabilities contributed to perceived self-threat and resistance to AI. Self-threat was negatively associated with resistance. Threats to professional capabilities directly affected resistance to AI, whereas the effect of threats to professional recognition was fully mediated through self-threat. Medical students experienced stronger identity threats and resistance to AI than medical professionals. The temporal distance of AI changed the importance of professional identity threats. If AI systems were perceived as relevant only in the distant future, the effect of threats to professional capabilities was weaker, whereas the effect of threats to professional recognition was stronger. The effect of threats remained robust after including perceived identity enhancement. The results show that the distinct dimensions of medical professional identity are affected by the upcoming technological change through AI. Conclusions Our findings demonstrate that AI systems can be perceived as a threat to medical professional identity. Both threats to professional recognition and threats to professional capabilities contribute to resistance attitudes toward AI and need to be considered in the implementation of AI systems in clinical practice.","",""
0,"Alexander Williams, C. S. Bangun","Artificial Intelligence System Framework in Improving The Competence of Indonesian Human Resources",2022,"","","","",86,"2022-07-13 09:19:55","","10.34306/ijcitsm.v2i1.91","","",,,,,0,0.00,0,2,1,"In this rapidly evolving period, notably the digital era, technology is critical. The globe is presently living in the technological era, sometimes known as the ""Industrial Revolution 4.0."" This state is characterized by the widespread use of digital machines and the internet, which has resulted in quick and substantial changes in many aspects of human existence, making it simpler for humans to perform numerous tasks. The digital transformation age is part of a more robust technology, which is a shift in how digital technology is applied to many elements of life in society. Artificial intelligence is a field of study that looks at ways to make computers behave like humans. In order to advance science, technology, and art in Indonesia, an artificial intelligence system framework is required. The goal of this research is to explain the Case-Based Reasoning (CBR) paradigm in the context of artificial intelligence development. This framework is intended to serve as a model for implementing intelligence systems in Indonesia.","",""
4,"Stuart J. Russell","Artificial Intelligence and the Problem of Control",2021,"","","","",87,"2022-07-13 09:19:55","","10.1007/978-3-030-86144-5_3","","",,,,,4,4.00,4,1,1,"","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",88,"2022-07-13 09:19:55","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
0,"Jianru Fu, Xuezhi Zhou, Guoping Mei","Internet Digital Economy Development Forecast Based on Artificial Intelligence and SVM-KNN Network Detection",2022,"","","","",89,"2022-07-13 09:19:55","","10.1155/2022/5792694","","",,,,,0,0.00,0,3,1,"The development and spread of Internet technology have made it easier to find web servers. People can browse various websites to shop or pay for living expenses, which brings great convenience to life, but as a result, Internet security problems continue to appear. This article is based on a detailed theoretical analysis of mainstream algorithms, making an analysis of web logs which is of great significance and practical value. In addition, through reasoning analysis, technical support is provided for improving the weight factor of the KNN (K-nearest neighbor) algorithm, and the literature research method of the SVM-KNN hybrid algorithm and the KNN classifier is proposed. This paper conducts a detailed theoretical analysis based on the mainstream algorithms that are widely used in the current classification technology and integrates the mainstream classification algorithms in real-life applications and popularization, selecting the support vector machine and KNN calculation method. In the digital economy development model, although China has a large number of netizens, obvious late-comer advantages and institutional advantages as a guarantee, due to the constraints of two key factors, capital and technology, a series of social problems have also arisen. During the transformation of the digital economy, prominent digital security issues, high-risk vulnerabilities, and increasing number of cyber-attacks, along with uneven data quality levels and lagging laws and regulations, have brought many challenges and obstacles.","",""
12,"L. Robaldo, S. Villata, A. Wyner, Matthias Grabmair","Introduction for artificial intelligence and law: special issue “natural language processing for legal texts”",2019,"","","","",90,"2022-07-13 09:19:55","","10.1007/s10506-019-09251-2","","",,,,,12,4.00,3,4,3,"","",""
11,"C. E. Kahn","Artificial Intelligence, Real Radiology.",2019,"","","","",91,"2022-07-13 09:19:55","","10.1148/RYAI.2019184001","","",,,,,11,3.67,11,1,3,"Welcome to this inaugural issue of Radiology: Artificial Intelligence. Our journal’s mission is to publish highquality scientific work that advances our understanding of artificial intelligence (AI) in radiology. AI has become a topic of great interest—especially the application of machine learning techniques to medical images—but AI itself is not new. The term artificial intelligence was proposed in 1956 to describe efforts to understand, simulate, and improve upon human qualities such as reasoning, learning, solving problems, understanding verbal and written language, processing visual information, and playing games like chess and poker. What is new is a resurgence of interest in AI, particularly in the use of machine learning to recognize patterns in images. And, curiously, it is game playing that has opened this new frontier—but not the games of chess, checkers, or Go. Rather, think Xbox and PlayStation. Video games require a rapidly changing three-dimensional scene to be transformed into two-dimensional images shown in real time. The need to compute images efficiently spurred the development of highly parallelized graphics processing units. These specialized processors, in turn, have powered software for increasingly complex and sophisticated “deep” artificial neural network models. Whereas neural networks developed 10 years ago typically had three or four layers, today’s deep networks comprise hundreds of layers (1). Deep learning models have engendered both great excitement and a great deal of hyperbole. After all, if AI systems can pick out pictures of cats on the web, then surely such systems are ready to replace radiologists, right? Well, perhaps not, at least not right now. There is much work to be done to build and validate systems that can detect and characterize the thousands of imaging findings and their associated diseases that can be seen across a panoply of radiology studies. And that brings us to the quote from Shakespeare. Anyone can claim to build an AI system, but that doesn’t mean that the system will do their bidding as imagined. Our journal is here to assure that the science and applications of AI in radiology are built on thoughtful, innovative, and well-validated research. What sorts of topics will this journal publish? We will bring you the same high caliber of research that is found in RSNA’s flagship scientific journal, Radiology, but focused here on AI, machine learning, and data science in radiology. In particular, we seek to publish first-rate work that provides rigorous evaluation of AI’s applications to clinical problems in radiology. We invite manuscripts that show the impact of AI to extract information, diagnose and manage disease in patients, streamline radiology workflow, or improve health care outcomes. We’re interested in image segmentation, image reconstruction, automated detection of abnormalities, diagnostic reasoning, natural language processing, clinical workflow analysis, radiomics, and radiogenomics. We also invite manuscripts that demonstrate novel applications of AI in radiology or highlight innovative AI methodologies. Developers of publicly available sets of radiologic images, image annotations, radiology reports, or algorithms can present their work as a Data Resources report. AI and radiology do not exist in isolation: they are part of broad endeavors to advance knowledge and improve health. As such, this journal will feature articles on the ethical, legal, social, and economic implications of AI in radiology. AI is and must be a human—and humane—activity (2). We must engage in this work with an eye to how these technologies will help us care for our patients more effectively and humanely. Our goal is not to replace, but rather to extend our human abilities to provide medical care— and to improve the lives of those we are privileged to serve. All RSNA members receive access to this online bimonthly journal. We invite all readers (RSNA members or not) to sign up for our Editor’s Blog, The Vasty Deep (https://pubs.rsna.org/page/ai/blog) and to follow us on Twitter (@Radiology_AI). These social media platforms will augment the journal and offer innovative online features. Again, welcome!","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",92,"2022-07-13 09:19:55","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
7,"D. G. Harkut, K. Kasat","Introductory Chapter: Artificial Intelligence - Challenges and Applications",2019,"","","","",93,"2022-07-13 09:19:55","","10.5772/INTECHOPEN.84624","","",,,,,7,2.33,4,2,3,"Artificial intelligence (AI) is any task performed by program or machine, which otherwise human needs to apply intelligence to accomplish it. It is the science and engineering of making machines to demonstrate intelligence especially visual perception, speech recognition, decision-making, and translation between languages like human beings. AI is the simulation of human intelligence processes by machines, especially computer systems. This includes learning, reasoning, planning, self-correction, problem solving, knowledge representation, perception, motion, manipulation, and creativity. It is a science and a set of computational techniques that are inspired by the way in which human beings use their nervous system and their body to feel, learn, reason, and act. AI is related to machine learning and deep learning wherein machine learning makes use of algorithms to discover patterns and generate insights from the data they are working on. Deep learning is a subset of machine learning, one that brings AI closer to the goal of enabling machines to think and work as human as possible. AI is a debatable topic and is often represented in a negative way; some would call it a blessing in disguise for businesses, while for some it is a technology that endangers the mere existence of humankind as it is potentially capable of taking over and dominating human being, but in reality artificial intelligence has affected our lifestyle either directly or indirectly and shaping the future of tomorrow. AI has already become an intrinsic part of our daily life and has greatly impacted our lifestyle despite the imperative uses of digital assistants of mobile phones, driverassistance systems, the bots, texts and speech translators, and systems that assist in recommending products and services and customized learning. Every emerging technology is a source of both enthusiasm and skepticism. AI is a source of both advantages and disadvantages in different perspectives. However, we need to overcome certain challenges before we can realize the true potential and immense transformational capabilities of this emerging technology. Some of the challenges related to artificial intelligence are:","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",94,"2022-07-13 09:19:55","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
3,"James A. Crowder, John Carbone, Shelli Friess","Abductive Artificial Intelligence Learning Models",2019,"","","","",95,"2022-07-13 09:19:55","","10.1007/978-3-030-17081-3_5","","",,,,,3,1.00,1,3,3,"","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",96,"2022-07-13 09:19:55","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",97,"2022-07-13 09:19:55","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
0,"M. Aluaș, S. Bolboacă","Is the biggest problem of health-related artificial intelligence an ethical one?",2019,"","","","",98,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,2,3,"Artificial intelligence (AI) is define by MeSH (Medical Subject Headings) as “theory and development of computer systems which perform tasks that normally require human intelligence. Such tasks may include speech recognition, learning; visual perception; mathematical computing; reasoning, problem solving, decision-making, and translation of language”. The keyword has been introduced in 1986 but received lately special attention due to the access to a considerable amount of organized/structured data. The AI technology in health care has raw medical data as input on which apply machine learning algorithms and provide as a specific output. The main feature of the AI is represented by the creation of its own logic by recognizing patterns in the input data but are “black boxes” that predict well without explaining why and are case-specific, the received goal is not self-adjusted. The healthrelated AI applications are developed to assist the diagnosis, development of the treatment protocol, drug development, personalized medicine, and healthcare monitoring. High-Level Expert Group on Artificial Intelligence (AI HLEG, https://ec.europa.eu/digital-singlemarket/en/high-level-expert-group-artificial-intelligence) published the Ethics Guidelines for Trustworthy AI that listed “seven key requirements for Trustworthy AI: (1) human agency and oversight, (2) technical robustness and safety, (3) privacy and data governance, (4) transparency, (5) diversity, non-discrimination and fairness, (6) environmental and societal well-being and (7) accountability.” The use of AI technology in health care and medical education arise several ethical issues regarding patient autonomy, privacy, and confidentiality, informed consent, discrimination, quantification of AI risks and benefits, responsibility, misuses, responsible conduct of AI research and testing, etc. Several AI ethical issues in health-care are introduced and discussed.","",""
0,"A. AdekunleY.","Holistic Exploration of Gaps vis-à-vis Artificial Intelligence in Automated Teller Machine and Internet Banking",2019,"","","","",99,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,1,3,"Artificial Intelligence (AI) is a computer science discipline that seeks to create intelligent software and hardware that can replicate our critical mental faculties in order to work and react like humans. Key applications of AI include speech recognition, language translation, visual perception, learning, reasoning, inference, strategizing, planning, decision making, and intuition. Automated Teller Machine (ATM) is a system that is in place to provide the users with instant cash; this system rides on the technology of AI. But the system functions with a single tier of security called the Personal Identification Number (PIN). The ATM is an electronic telecommunication device that allows the financial institutions customers to directly use a secure method of communication to access their bank accounts. It is a self-service banking terminal that accepts deposits and dispenses cash at a lightning speed. Any ATM installed operates while the card is inserted into the machine. However, as man begins to realize the gains brought about by this machine to supplement human tellers, little did one know that the joy shall be short lived by the various sharp practices leading to financial losses. As banks are losing, so are the customers. News Media are filled with various forms of complaints on how users are losing money to fraudsters. Some have vowed never to come near usage of various cards – debit, credit or prepaid – local or international. The problem may even go as deep as engaging in legal battle between banks and their customers. This paper presents various gaps in authentication methods used in ATM transaction and their vulnerabilities and proffer robust authentication method to curb fraudulent activities in ATM. Hence, the need to find a lasting solution to ATM fraud is the main thrust of this paper.","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",100,"2022-07-13 09:19:55","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"J. Dipnall, R. Page, Lan Du, M. Costa, R. Lyons, Peter Cameron, R. D. de Steiger, R. Hau, A. Bucknill, A. Oppy, E. Edwards, D. Varma, M. C. Jung, B. Gabbe","Predicting fracture outcomes from clinical registry data using artificial intelligence supplemented models for evidence-informed treatment (PRAISE) study protocol",2021,"","","","",101,"2022-07-13 09:19:55","","10.1371/journal.pone.0257361","","",,,,,0,0.00,0,14,1,"Background Distal radius (wrist) fractures are the second most common fracture admitted to hospital. The anatomical pattern of these types of injuries is diverse, with variation in clinical management, guidelines for management remain inconclusive, and the uptake of findings from clinical trials into routine practice limited. Robust predictive modelling, which considers both the characteristics of the fracture and patient, provides the best opportunity to reduce variation in care and improve patient outcomes. This type of data is housed in unstructured data sources with no particular format or schema. The “Predicting fracture outcomes from clinical Registry data using Artificial Intelligence (AI) Supplemented models for Evidence-informed treatment (PRAISE)” study aims to use AI methods on unstructured data to describe the fracture characteristics and test if using this information improves identification of key fracture characteristics and prediction of patient-reported outcome measures and clinical outcomes following wrist fractures compared to prediction models based on standard registry data. Methods and design Adult (16+ years) patients presenting to the emergency department, treated in a short stay unit, or admitted to hospital for >24h for management of a wrist fracture in four Victorian hospitals will be included in this study. The study will use routine registry data from the Victorian Orthopaedic Trauma Outcomes Registry (VOTOR), and electronic medical record (EMR) information (e.g. X-rays, surgical reports, radiology reports, images). A multimodal deep learning fracture reasoning system (DLFRS) will be developed that reasons on EMR information. Machine learning prediction models will test the performance with/without output from the DLFRS. Discussion The PRAISE study will establish the use of AI techniques to provide enhanced information about fracture characteristics in people with wrist fractures. Prediction models using AI derived characteristics are expected to provide better prediction of clinical and patient-reported outcomes following distal radius fracture.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",102,"2022-07-13 09:19:55","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
84,"Lars Kunze, Nick Hawes, T. Duckett, M. Hanheide, T. Krajník","Artificial Intelligence for Long-Term Robot Autonomy: A Survey",2018,"","","","",103,"2022-07-13 09:19:55","","10.1109/LRA.2018.2860628","","",,,,,84,21.00,17,5,4,"Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty, and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e., weeks, months, or years) poses many challenges. Some of these have been investigated by subdisciplines of Artificial Intelligence (AI) including navigation and mapping, perception, knowledge representation and reasoning, planning, interaction, and learning. The different subdisciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this letter, we survey and discuss AI techniques as “enablers” for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",104,"2022-07-13 09:19:55","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",105,"2022-07-13 09:19:55","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
198,"Matej Moravcík, Martin Schmid, Neil Burch, V. Lisý, Dustin Morrill, Nolan Bard, Trevor Davis, K. Waugh, Michael Bradley Johanson, Michael Bowling","DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker",2017,"","","","",106,"2022-07-13 09:19:55","","","","",,,,,198,39.60,20,10,5,"Artificial intelligence has seen a number of breakthroughs in recent years, with games often serving as significant milestones. A common feature of games with these successes is that they involve information symmetry among the players, where all players have identical information. This property of perfect information, though, is far more common in games than in real-world problems. Poker is the quintessential game of imperfect information, and it has been a longstanding challenge problem in artificial intelligence. In this paper we introduce DeepStack, a new algorithm for imperfect information settings such as poker. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition about arbitrary poker situations that is automatically learned from selfplay games using deep learning. In a study involving dozens of participants and 44,000 hands of poker, DeepStack becomes the first computer program to beat professional poker players in heads-up no-limit Texas hold’em. Furthermore, we show this approach dramatically reduces worst-case exploitability compared to the abstraction paradigm that has been favored for over a decade.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",107,"2022-07-13 09:19:55","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",108,"2022-07-13 09:19:55","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
6,"","Dutch Artificial Intelligence Manifesto",2018,"","","","",109,"2022-07-13 09:19:55","","","","",,,,,6,1.50,0,0,4,"Artificial Intelligence (AI), the science and engineering that studies and creates intelligent systems, has become a disruptive force revolutionizing fields as diverse as health care, finance, law, insurance, HR, communication, education, energy, transportation, manufacturing, agriculture, and defense.2 Driven by the increased availability of compute power, access to massive amounts of data3, and advanced sensor technology, AI techniques such as reasoning, imaging processing and machine learning algorithms have become powerful enablers of automation, predictive analytics, and human-machine interaction. AI has already changed online interactions in the retail sector (e.g., recommender systems and chatbots) but also enable sophisticated AI-enabled user experiences (e.g., AI assistants) that profoundly affect how people live, work, and play.4 To ensure these developments are beneficial for all, we should invest in making AI highly robust, and include all stakeholders in their development.5 The Netherlands is well positioned to benefit from these developments as strong enablers are in place including strong digital absorption and economic innovation. AI research and education is also strong, but to avoid a brain drain, investments are needed in human talent.6 In the meantime, a technology race has started with the US taking a leading role, China closely following and heavily investing in AI7, and Europe still in the process of formulating its AI strategy at EU as well as national levels.8 We urgently need a national agenda for AI that provides a national strategy that is supported by academy, industry, and government. The Netherlands must make substantial investments in high-quality Dutch AI research and innovation if it is to compete at all.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",110,"2022-07-13 09:19:55","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",111,"2022-07-13 09:19:55","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",112,"2022-07-13 09:19:55","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
59,"Chunhao Wang, Xiaofeng Zhu, Julian C. Hong, D. Zheng","Artificial Intelligence in Radiotherapy Treatment Planning: Present and Future",2019,"","","","",113,"2022-07-13 09:19:55","","10.1177/1533033819873922","","",,,,,59,19.67,15,4,3,"Treatment planning is an essential step of the radiotherapy workflow. It has become more sophisticated over the past couple of decades with the help of computer science, enabling planners to design highly complex radiotherapy plans to minimize the normal tissue damage while persevering sufficient tumor control. As a result, treatment planning has become more labor intensive, requiring hours or even days of planner effort to optimize an individual patient case in a trial-and-error fashion. More recently, artificial intelligence has been utilized to automate and improve various aspects of medical science. For radiotherapy treatment planning, many algorithms have been developed to better support planners. These algorithms focus on automating the planning process and/or optimizing dosimetric trade-offs, and they have already made great impact on improving treatment planning efficiency and plan quality consistency. In this review, the smart planning tools in current clinical use are summarized in 3 main categories: automated rule implementation and reasoning, modeling of prior knowledge in clinical practice, and multicriteria optimization. Novel artificial intelligence–based treatment planning applications, such as deep learning–based algorithms and emerging research directions, are also reviewed. Finally, the challenges of artificial intelligence–based treatment planning are discussed for future works.","",""
1,"A. Palin, I. Jacob","Review on Fog Based Spectrum Sensing for Artificial Intelligence",2018,"","","","",114,"2022-07-13 09:19:55","","10.32628/CSEIT183816","","",,,,,1,0.25,1,2,4,"Wireless Mesh Network (MWN) could be divided into proactive routing, reactive routing and hybrid routing, which must satisfy the requirements related to scalability, reliability, flexibility, throughput, load balancing, congestion control and efficiency. DMN (Directional Mesh Network) become more adaptive to the local environments and robust to spectrum changes. The existing computing units in the mesh network systems are Fog nodes, the DMN architecture is more economic and efficient since it doesn’t require architecture- level changes from existing systems. The cluster head (CH) manages a group of nodes such that the network has the hierarchical structure for the channel access, routing and bandwidth allocation. The feature extraction and situational awareness is conducted, each Fog node sends the information regarding the current situation to the cluster head in the contextual format. A Markov logic network (MLN) based reasoning engine is utilized for the final routing table updating regarding the system uncertainty and complexity.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",115,"2022-07-13 09:19:55","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
0,"Juveriya Afreen","A Survey on Artificial Intelligence Techniques to Prevent Cyber Crime",2018,"","","","",116,"2022-07-13 09:19:55","","10.23956/IJARCSSE.V8I5.669","","",,,,,0,0.00,0,1,4,"Abstract-- With increase in complexity of data, security, it is difficult for the individuals to prevent the offence. Thus, by using any automation or software it’s not possible by only using huge fixed algorithms to overcome this. Thus, we need to look for something which is robust and feasible enough. Hence AI plays an epitome role to defense such violations. In this paper we basically look how human reasoning along with AI can be applied to uplift cyber security.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",117,"2022-07-13 09:19:55","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
26779,"Stuart J. Russell, Peter Norvig","Artificial Intelligence: A Modern Approach",1995,"","","","",118,"2022-07-13 09:19:55","","10.5860/choice.33-1577","","",,,,,26779,991.81,13390,2,27,"The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",119,"2022-07-13 09:19:55","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",120,"2022-07-13 09:19:55","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
374,"S. Park, Kyunghwa Han","Methodologic Guide for Evaluating Clinical Performance and Effect of Artificial Intelligence Technology for Medical Diagnosis and Prediction.",2018,"","","","",121,"2022-07-13 09:19:55","","10.1148/radiol.2017171920","","",,,,,374,93.50,187,2,4,"The use of artificial intelligence in medicine is currently an issue of great interest, especially with regard to the diagnostic or predictive analysis of medical images. Adoption of an artificial intelligence tool in clinical practice requires careful confirmation of its clinical utility. Herein, the authors explain key methodology points involved in a clinical evaluation of artificial intelligence technology for use in medicine, especially high-dimensional or overparameterized diagnostic or predictive models in which artificial deep neural networks are used, mainly from the standpoints of clinical epidemiology and biostatistics. First, statistical methods for assessing the discrimination and calibration performances of a diagnostic or predictive model are summarized. Next, the effects of disease manifestation spectrum and disease prevalence on the performance results are explained, followed by a discussion of the difference between evaluating the performance with use of internal and external datasets, the importance of using an adequate external dataset obtained from a well-defined clinical cohort to avoid overestimating the clinical performance as a result of overfitting in high-dimensional or overparameterized classification model and spectrum bias, and the essentials for achieving a more robust clinical evaluation. Finally, the authors review the role of clinical trials and observational outcome studies for ultimate clinical verification of diagnostic or predictive artificial intelligence tools through patient outcomes, beyond performance metrics, and how to design such studies. © RSNA, 2018.","",""
6,"John Licato, Zhitian Zhang","Evaluating representational systems in artificial intelligence",2019,"","","","",122,"2022-07-13 09:19:55","","10.1007/s10462-017-9598-7","","",,,,,6,2.00,3,2,3,"","",""
8,"M. Cukurova, R. Luckin, C. Kent","Impact of an Artificial Intelligence Research Frame on the Perceived Credibility of Educational Research Evidence",2019,"","","","",123,"2022-07-13 09:19:55","","10.1007/s40593-019-00188-w","","",,,,,8,2.67,3,3,3,"","",""
0,"Jie Hu","Research on Robot Fuzzy Neural Network Motion System Based on Artificial Intelligence",2022,"","","","",124,"2022-07-13 09:19:55","","10.1155/2022/4347772","","",,,,,0,0.00,0,1,1,"An intelligent controller based on a self-learning interval type-II fuzzy neural network is proposed to make the motion controller of the industrial intelligent robot with good adaptability. This controller has a parallel structure and contains an interval type-II fuzzy neural network and a conventional PD controller. For the design of the interval type-II fuzzy neural network, the interval type-II fuzzy set is established using the slave design method. In the design process of the interval type-II fuzzy set of the front piece, a dual sequence symmetric trapezoidal subordinate function arrangement method is proposed, which makes the self-learning law and stability analysis of the system in an analytic form and facilitates the implementation of the algorithm in hardware. In the design of the neural network self-learning law, a parametric self-learning algorithm based on sliding mode control theory is established to adjust the structural parameters of the interval type-II fuzzy neural network online, and the stability of the system is proved by using Lyapunov's stability theorem. Three sets of validation simulation experiments are given in conjunction with the trajectory tracking problem of the Delta parallel robot. The simulation results show that, in the presence of system uncertainty, the intelligent controller based on interval self-learning interval type-II fuzzy neural network can significantly improve the trajectory tracking accuracy and robustness of the system and make the control system highly adaptable to the environment. Experiments of intelligent control system based on self-learning interval type-II fuzzy neural network and experiments of reusable particle swarm optimal motion planning method are designed, and the effectiveness of the intelligent control system and motion planning method is verified on the experimental platform. The experimental results show that the intelligent control system based on the self-learning interval type-II fuzzy neural network can effectively improve the accuracy and stability of robot trajectory tracking control, and the reusable particle swarm optimal motion planning method can quickly solve the robot motion planning problem with complex constraints online.","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",125,"2022-07-13 09:19:55","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
0,"Su Zhang","The Cognitive Transformation of Japanese Language Education by Artificial Intelligence Technology in the Wireless Network Environment",2022,"","","","",126,"2022-07-13 09:19:55","","10.1155/2022/7886369","","",,,,,0,0.00,0,1,1,"This study aims to solve the multiscale problems faced by the current classroom student behavior target detection based on the convolutional neural network (CNN) in the wireless network environment. Firstly, the recent reform of Japanese language education is introduced. Secondly, the multiscale problem research of classroom student behavior target detection is discussed. A CNN-based new extraction network is designed based on dilated convolution and pyramid features. An anchor reconstruction algorithm based on improved K-means clustering is presented for the self-made student behavior dataset. Finally, the performance of the designed algorithm is tested. The anchor reconstruction algorithm’s mean average precision is 83.2%, and the average intersection over union is 73.7%. The experimental results of this scheme outperform the original single-shot multibox detector and K-means algorithms. Compared with other algorithms, the designed multiscale detection algorithm of classroom student behavior has the best detection effect on Pascal visual object classes (VOC) dataset. The detection accuracy of the entire dataset is 79.8%. Overall, the multiscale detection algorithm for classroom student behavior has a better detection effect on the Pascal VOC dataset and has good generalization ability and robustness. This research can guide students to recognize their class status and make corresponding adjustments to improve their learning efficiency, which has essential research significance and application value.","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",127,"2022-07-13 09:19:55","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",128,"2022-07-13 09:19:55","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
0,"Shashank Agnihotri, Anshul Agarwal","Ambient Artificial Intelligence",2017,"","","","",129,"2022-07-13 09:19:55","","10.5120/IJCA2017914886","","",,,,,0,0.00,0,2,5,"The paper presents an integrated, automated and wireless system concept for the human intelligence environment domain based on the technique called ambient artificial intelligence (AAI). Ambient Intelligence system is that which is embedded in an environment, enhancing complex and manual life to simple and automatic life. This technology in an environment is challenging to various algorithm that are being used with respect to human behavior and human life. Development of such intelligent and smart environment is dependent on the adaptive nature, flexibility, robust parameters of such intelligent system which are mainly forecasted on certain factors like reasoning, decision making and acting. The details of new emerging technology, ambient artificial intelligence, its working, architecture and various technologies used to build such efficient system.[1]","",""
0,"J. Joseph, C. Edward","Artificial Intelligence Literaturised in Jose Saramango’s Novels: An Endorsement of Creativity, Rationality and Magic Realism",2019,"","","","",130,"2022-07-13 09:19:55","","10.26643/think-india.v22i2.8734","","",,,,,0,0.00,0,2,3,"Apparently, there is no connection between artificial intelligence and literature, but at closer scrutiny, it is discernibly clear that a link-up is quite possible in a harmonious manner because both the subjects do have commonalities dotting them one end to the next. Literature is a journey through the trajectories or pathways of imagination, illusion, fantasy, and dreamlike situations. The world of artificial intelligence does have virtual realities taking place in an imaginative plain. Artificial intelligence is a repetitive, perennial and a crucial current topic in science fiction, whether unworldly, stressing the capacity advantages, or dystopian, emphasizing the possible risks and insecurities. The belief of machines with human-like intelligence dates lower back to the talented writer Samuel Butler's 1872 novel Erewhon. Buoyant or positive perceptions of the destiny of artificial intelligence are feasible in science fiction. The artificial intelligence facilitates the quick and robust operational efficiency of the world and literature fulfills this role through its crucial ingredient imagination running riot to beautify the world. The literary works of Jose Saramago do sublimate in their scope the role of artificial intelligence fair and square. John McCarthy, the founder of the idea of Artificial Intelligence, conveys the idea that ‘Artificial Intelligence is the technology and designing of making sensible and brilliant machines, particularly intelligent packages’. For me, Jose Saramago acts as an intelligent machine to check and reformulate the fundamental ethical values which are considered as universal, secular and scientific. His Scepticism goes beyond all pessimistic worldviews and his humanistic ideology surpasses all notions of illogical and unreasonable thought patterns.  Through this paper, I intend to present his literary contributions packed with ecstasy, prophetic pronouncements and visionary ability. I call his intelligence as artificial intelligence that represents his ideology, prophetic activity, and reasoning power.","",""
83,"G. Pigozzi, A. Tsoukiàs, P. Viappiani","Preferences in artificial intelligence",2016,"","","","",131,"2022-07-13 09:19:55","","10.1007/s10472-015-9475-5","","",,,,,83,13.83,28,3,6,"","",""
587,"Matej Moravcík, Martin Schmid, Neil Burch, V. Lisý, Dustin Morrill, Nolan Bard, Trevor Davis, K. Waugh, Michael Bradley Johanson, Michael H. Bowling","DeepStack: Expert-level artificial intelligence in heads-up no-limit poker",2017,"","","","",132,"2022-07-13 09:19:55","","10.1126/science.aam6960","","",,,,,587,117.40,59,10,5,"Computer code based on continual problem re-solving beats human professional poker players at a two-player variant of poker. Artificial intelligence masters poker Computers can beat humans at games as complex as chess or go. In these and similar games, both players have access to the same information, as displayed on the board. Although computers have the ultimate poker face, it has been tricky to teach them to be good at poker, where players cannot see their opponents' cards. Moravčík et al. built a code dubbed DeepStack that managed to beat professional poker players at a two-player poker variant called heads-up no-limit Texas hold'em. Instead of devising its strategy beforehand, DeepStack recalculated it at each step, taking into account the current state of the game. The principles behind DeepStack may enable advances in solving real-world problems that involve information asymmetry. Science, this issue p. 508 Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold’em. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.","",""
15,"M. Klincewicz","Artificial Intelligence as a Means to Moral Enhancement",2016,"","","","",133,"2022-07-13 09:19:55","","10.1515/SLGR-2016-0061","","",,,,,15,2.50,15,1,6,"Abstract This paper critically assesses the possibility of moral enhancement with ambient intelligence technologies and artificial intelligence presented in Savulescu and Maslen (2015). The main problem with their proposal is that it is not robust enough to play a normative role in users’ behavior. A more promising approach, and the one presented in the paper, relies on an artificial moral reasoning engine, which is designed to present its users with moral arguments grounded in first-order normative theories, such as Kantianism or utilitarianism, that reason-responsive people can be persuaded by. This proposal can play a normative role and it is also a more promising avenue towards moral enhancement. It is more promising because such a system can be designed to take advantage of the sometimes undue trust that people put in automated technologies. We could therefore expect a well-designed moral reasoner system to be able to persuade people that may not be persuaded by similar arguments from other people. So, all things considered, there is hope in artificial intelligence for moral enhancement, but not in artificial intelligence that relies solely on ambient intelligence technologies.","",""
92,"A. Annoni, P. Benczúr, P. Bertoldi, Blagoj Delipetrev, Giuditta De Prato, C. Feijóo, Enrique Fernández-Macías, E. Gutiérrez, M. Portela, H. Junklewitz, M. L. Cobo, B. Martens, Susana Nascimento, S. Nativi, Alexandre Pólvora, Jose Ignacio Sanchez Martin, Songuel Tolan, I. Tuomi, Lucia Vesnić Alujević","Artificial Intelligence: A European Perspective",2018,"","","","",134,"2022-07-13 09:19:55","","10.2760/11251","","",,,,,92,23.00,9,19,4,"We are only at the beginning of a rapid period of transformation of our economy and society due to the convergence of many digital technologies. Artificial Intelligence (AI) is central to this change and offers major opportunities to improve our lives. The recent developments in AI are the result of increased processing power, improvements in algorithms and the exponential growth in the volume and variety of digital data. Many applications of AI have started entering into our every-day lives, from machine translations, to image recognition, and music generation, and are increasingly deployed in industry, government, and commerce. Connected and autonomous vehicles, and AI-supported medical diagnostics are areas of application that will soon be commonplace. There is strong global competition on AI among the US, China, and Europe. The US leads for now but China is catching up fast and aims to lead by 2030. For the EU, it is not so much a question of winning or losing a race but of finding the way of embracing the opportunities offered by AI in a way that is human-centred, ethical, secure, and true to our core values. The EU Member States and the European Commission are developing coordinated national and European strategies, recognising that only together we can succeed. We can build on our areas of strength including excellent research, leadership in some industrial sectors like automotive and robotics, a solid legal and regulatory framework, and very rich cultural diversity also at regional and sub-regional levels. It is generally recognised that AI can flourish only if supported by a robust computing infrastructure and good quality data: â€¢ With respect to computing, we identified a window of opportunity for Europe to invest in the emerging new paradigm of computing distributed towards the edges of the network, in addition to centralised facilities. This will support also the future deployment of 5G and the Internet of Things. â€¢ With respect to data, we argue in favour of learning from successful Internet companies, opening access to data and developing interactivity with the users rather than just broadcasting data. In this way, we can develop ecosystems of public administrations, firms, and civil society enriching the data to make it fit for AI applications responding to European needs. We should embrace the opportunities afforded by AI but not uncritically. The black box characteristics of most leading AI techniques make them opaque even to specialists. AI systems are currently limited to narrow and well-defined tasks, and their technologies inherit imperfections from their human creators, such as the well-recognised bias effect present in data. We should challenge the shortcomings of AI and work towards strong evaluation strategies, transparent and reliable systems, and good human-AI interactions. Ethical and secure-by-design algorithms are crucial to build trust in this disruptive technology, but we also need a broader engagement of civil society on the values to be embedded in AI and the directions for future development. This social engagement should be part of the effort to strengthen our resilience at all levels from local, to national and European, across institutions, industry and civil society. Developing local ecosystems of skills, computing, data, and applications can foster the engagement of local communities, respond to their needs, harness local creativity and knowledge, and build a human-centred, diverse, and socially driven AI. We still know very little about how AI will impact the way we think, make decisions, relate to each other, and how it will affect our jobs. This uncertainty can be a source of concern but is also a sign of opportunity. The future is not yet written. We can shape it based on our collective vision of what future we would like to have. But we need to act together and act fast.","",""
53,"Pasquale Minervini, Matko Bovsnjak, Tim Rocktäschel, Sebastian Riedel, Edward Grefenstette","Differentiable Reasoning on Large Knowledge Bases and Natural Language",2019,"","","","",135,"2022-07-13 09:19:55","","10.1609/AAAI.V34I04.5962","","",,,,,53,17.67,11,5,3,"Reasoning with knowledge expressed in natural language and Knowledge Bases (KBs) is a major challenge for Artificial Intelligence, with applications in machine reading, dialogue, and question answering. General neural architectures that jointly learn representations and transformations of text are very data-inefficient, and it is hard to analyse their reasoning process. These issues are addressed by end-to-end differentiable reasoning systems such as Neural Theorem Provers (NTPs), although they can only be used with small-scale symbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension to NTPs addressing their complexity and scalability limitations, thus making them applicable to real-world datasets. This result is achieved by dynamically constructing the computation graph of NTPs and including only the most promising proof paths during inference, thus obtaining orders of magnitude more efficient models. Then, we propose a novel approach for jointly reasoning over KBs and textual mentions, by embedding logic facts and natural language sentences in a shared embedding space. We show that GNTPs perform on par with NTPs at a fraction of their cost while achieving competitive link prediction results on large datasets, providing explanations for predictions, and inducing interpretable models. Source code, datasets, and supplementary material are available online at this https URL.","",""
0,"Joseph Noussa-Yao, D. Heudes, P. Degoulet","Using Artificial Intelligence and Big Data-Based Documents to Optimize Medical Coding",2019,"","","","",136,"2022-07-13 09:19:55","","10.5772/INTECHOPEN.85749","","",,,,,0,0.00,0,3,3,"Clinical information systems (CISs) in some hospitals streamline the data management from data warehouses. These warehouses contain heterogeneous information from all medical specialties that offer patient care services. It is increasingly difficult to manage large volumes of data in a specific clinical context such as quality coding of medical services. The document-based not only SQL (NoSQL) model can provide an accessible, extensive, and robust coding data management framework while maintaining certain flexibility. This paper focuses on the design and implementation of a big data-coding warehouse, and it also defines the rules to convert a conceptual model of coding into a document-oriented logical model. Using that model, we implemented and analyzed a big data-coding warehouse via the MongoDB database and evaluated it using data research monoand multicriteria and then calculated the precision of our model.","",""
9,"Ruben Branco, A. Branco, J. Rodrigues, J. Silva","Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning",2021,"","","","",137,"2022-07-13 09:19:55","","10.18653/v1/2021.emnlp-main.113","","",,,,,9,9.00,2,4,1,"Commonsense is a quintessential human capacity that has been a core challenge to Artificial Intelligence since its inception. Impressive results in Natural Language Processing tasks, including in commonsense reasoning, have consistently been achieved with Transformer neural language models, even matching or surpassing human performance in some benchmarks. Recently, some of these advances have been called into question: so called data artifacts in the training data have been made evident as spurious correlations and shallow shortcuts that in some cases are leveraging these outstanding results. In this paper we seek to further pursue this analysis into the realm of commonsense related language processing tasks. We undertake a study on different prominent benchmarks that involve commonsense reasoning, along a number of key stress experiments, thus seeking to gain insight on whether the models are learning transferable generalizations intrinsic to the problem at stake or just taking advantage of incidental shortcuts in the data items. The results obtained indicate that most datasets experimented with are problematic, with models resorting to non-robust features and appearing not to be learning and generalizing towards the overall tasks intended to be conveyed or exemplified by the datasets.","",""
8,"Alvin Chan, Lei Ma, Felix Juefei-Xu, Y. Ong, Xiaofei Xie, Minhui Xue, Yang Liu","Breaking Neural Reasoning Architectures With Metamorphic Relation-Based Adversarial Examples.",2021,"","","","",138,"2022-07-13 09:19:55","","10.1109/TNNLS.2021.3072166","","",,,,,8,8.00,1,7,1,"The ability to read, reason, and infer lies at the heart of neural reasoning architectures. After all, the ability to perform logical reasoning over language remains a coveted goal of Artificial Intelligence. To this end, models such as the Turing-complete differentiable neural computer (DNC) boast of real logical reasoning capabilities, along with the ability to reason beyond simple surface-level matching. In this brief, we propose the first probe into DNC's logical reasoning capabilities with a focus on text-based question answering (QA). More concretely, we propose a conceptually simple but effective adversarial attack based on metamorphic relations. Our proposed adversarial attack reduces DNCs' state-of-the-art accuracy from 100% to 1.5% in the worst case, exposing weaknesses and susceptibilities in modern neural reasoning architectures. We further empirically explore possibilities to defend against such attacks and demonstrate the utility of our adversarial framework as a simple scalable method to improve model adversarial robustness.","",""
3,"Kwwabena Nuamah","Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",2021,"","","","",139,"2022-07-13 09:19:55","","","","",,,,,3,3.00,3,1,1,"An important aspect of artificial intelligence (AI) is the ability to reason in a step-by-step “algorithmic” manner that can be inspected and verified for its correctness. This is especially important in the domain of question answering (QA). We argue that the challenge of algorithmic reasoning in QA can be effectively tackled with a “systems” approach to AI which features a hybrid use of symbolic and sub-symbolic methods including deep neural networks. Additionally, we argue that while neural network models with end-to-end training pipelines perform well in narrow applications such as image classification and language modelling, they cannot, on their own, successfully perform algorithmic reasoning, especially if the task spans multiple domains. We discuss a few notable exceptions and point out how they are still limited when the QA problem is widened to include other intelligence-requiring tasks. However, deep learning, and machine learning in general, do play important roles as components in the reasoning process. In this position paper, we propose an approach to algorithm reasoning for QA, Deep Algorithmic Question Answering (DAQA), based on three desirable properties: interpretability, generalizability, and robustness which such an AI system should posses, and conclude that they are best achieved with a combination of hybrid and compositional AI.","",""
611,"Y. Shoham","Reasoning About Change: Time and Causation from the Standpoint of Artificial Intelligence",1987,"","","","",140,"2022-07-13 09:19:55","","","","",,,,,611,17.46,611,1,35,"Reasoning About Change presents a comprehensive approach to temporal reasoning in artificial intelligence.","",""
170,"Michael Fisher, D. Gabbay, Lluís Vila","Handbook of Temporal Reasoning in Artificial Intelligence",2005,"","","","",141,"2022-07-13 09:19:55","","","","",,,,,170,10.00,57,3,17,"This collection represents the primary reference work for researchers and students in the area of Temporal Reasoning in Artificial Intelligence. Temporal reasoning has a vital role to play in many areas, particularly Artificial Intelligence. Yet, until now, there has been no single volume collecting together the breadth of work in this area. This collection brings together the leading researchers in a range of relevant areas and provides an coherent description of the breadth of activity concerning temporal reasoning in the filed of Artificial Intelligence.    Key Features:    - Broad range: foundations; techniques and applications  - Leading researchers around the world have written the chapters  - Covers many vital applications  - Source book for Artificial Intelligence, temporal reasoning  - Approaches provide foundation for many future software systems    ·Broad range: foundations; techniques and applications  ·Leading researchers around the world have written the chapters  ·Covers many vital applications  ·Source book for Artificial Intelligence, temporal reasoning  ·Approaches provide foundation for many future software systems    Table of Contents    ""Formal Theories of Time and Temproal Incidence"", Lluis Vila.    ""Eventualities"", Antony Galton.    ""Time Granularity"", Jerome Euzenat and Angelo Montanari.    ""Modal Varieties of Temporal Logic"", Howard Barringer and Dov Gabbay.    ""Temporal Qualification in Artificial Intelligence"", Han Reichgelt and Lluis Vila.    ""Computational Complexity of Temporal Constraint Problems"", Thomas Drakengren and Peter Jonsson.    ""Indefinite Constraint Databases with Temporal Information: Representational Power and Computational Complexity"", Manolis Koubarakis.    ""Processing Qualitative Temporal Constraints"", Alfonso Gerevini.    ""Theorem-Proving for Discrete Temporal Logic"", Mark Reynolds/Clare Dixon.    ""Probabilistic Temporal Reasoning"", Steve Hanks/David Madigan.    ""Temporal Reasoning with iff-Abduction"", Marc Denecker/Kristof Van Belleghem.    ""Temporal Description Logics"", Alessandro Artale/Enrico Franconi.    ""Logic Programming and Reasoning about Actions"", Chitta Baral/Michael Gelfond.    ""Temporal Databases"" Jan Chomicki/David Toman.    ""Temporal Reasoning in Agent-Based Systems"" Michael Fisher/Michael Wooldridge.    ""Time in Planning"" Maris Fox/Derek Long.    ""Time in Automated Legal Reasoning"" Lluis Vila/Hajime Yoshino.    ""Temporal Reasoning in Natural Language"" Alice ter Meulen.    ""Temporal Reasoning in Medicine"" Elpida Keravnou/Yuval Shahar.    ""Time in Qualitative Simulation"" Dan Clancy/Benjamin Kuipers.","",""
193,"A. Gardner","An artificial intelligence approach to legal reasoning",1985,"","","","",142,"2022-07-13 09:19:55","","","","",,,,,193,5.22,193,1,37,"For artificial intelligence, understanding the forms of human reasoning is a central goal. Legal reasoning is a form that makes a new set of demands on artificial intelligence methods. Most importantly, a computer program that reasons about legal problems must be able to distinguish between questions it is competent to answer and questions that human lawyers could seriously argue either way. In addition, a program for analyzing legal problems should be able to use both general legal rules and decisions in past cases; and it should be able to work with technical concepts that are only partly defined and subject to shifts of meaning. Each of these requirements has wider applications in artificial intelligence, beyond the legal domain.  This dissertation presents a computational framework for legal reasoning, within which such requirements can be accommodated. The development of the framework draws significantly on the philosophy of law, in which the elucidation of legal reasoning is an important topic. A key element of the framework is the legal distinction between hard cases and clear cases. In legal writing, this distinction has been taken for granted more often than it has been explored. Here, some initial heuristics are proposed by which a program might make the distinction.  The dissertation also describes an implemented program based on the framework. For definiteness, the program is given the task of analyzing law examination problems concerning the formation of contracts by offer and acceptance. The program performs adequately on a narrow class of such problems and appears to be extensible to other areas. Thus, the research opens up a line of investigation that may prove fruitful for both artifical intelligence and legal philosophy.","",""
86,"B. Buchanan, Thomas E. Headrick","Some Speculation about Artificial Intelligence and Legal Reasoning",1970,"","","","",143,"2022-07-13 09:19:55","","10.2307/1227753","","",,,,,86,1.65,43,2,52,"Abstract : Legal reasoning is viewed here as a complex problem-solving task to which the techniques of artificial intelligence programming may be applied. Some existing programs are discussed which successfully attack various aspects of the problem, in this and other task domains. It remains an open question, to be answered by intensive research, whether computers can be programmed to do creative legal reasoning. Regardless of the answer, it is argued that much will be gained by the research. (Author)","",""
98,"P. Boddington","Towards a Code of Ethics for Artificial Intelligence",2017,"","","","",144,"2022-07-13 09:19:55","","10.1007/978-3-319-60648-4","","",,,,,98,19.60,98,1,5,"","",""
26,"K. Sim","Bilattices and Reasoning in Artificial Intelligence: Concepts and Foundations",2001,"","","","",145,"2022-07-13 09:19:55","","10.1023/A:1011049617655","","",,,,,26,1.24,26,1,21,"","",""
88,"Edwina L. Rissland","Artificial Intelligence and Law: Stepping Stones to a Model of Legal Reasoning",1990,"","","","",146,"2022-07-13 09:19:55","","10.2307/796679","","",,,,,88,2.75,88,1,32,"This Comment discusses developments in the twenty-year-old interdisciplinary field of Artificial Intelligence (AI) and law. This field is important for both AI and law because it is directed at improving our understanding and modeling of legal reasoning. The AI and law projects discussed here are landmarks in this field., A unifying theme of the projects is the goal to understand and model legal argument, a keystone of an overarching goal to understand and model legal reasoning. These goals require that we know first how to represent several types of knowledge, such as cases, rules, and arguments; second, how to reason with them, such as to manipulate precedents, to apply and make inferences with rules, and to tailor arguments to facts; and third, how to use them ultimately in a computer program that can perform tasks in legal reasoning and argumentation, such as analogizing favorable cases and distinguishing contrary ones, anticipating parries in adversarial argument, and creating artful hypothetical. The projects constitute a coherent set of studies about key topics in AI and law: (1) reasoning with rules; (2) handling open-textured legal concepts; (3) reasoning with cases and hypotheticals; (4) integrating reasoning with rules and reasoning with cases; and (5) representing legal knowledge. The limitations of techniques for handling the first topic are addressed by the second, and the third topic addresses critical issues not covered at all by work on the first. The fourth integrates work on the first three, and the fifth provides underpinnings needed for all of them. The projects are some of the major accomplishments in AI and law, especially","",""
23,"C. Sunstein","Of Artificial Intelligence and Legal Reasoning",2001,"","","","",147,"2022-07-13 09:19:55","","10.2139/SSRN.289789","","",,,,,23,1.10,23,1,21,"Can computers, or artificial intelligence, reason by analogy? This essay urges that they cannot, because they are unable to engage in the crucial task of identifying the normative principle that links or separates cases. Current claims, about the ability of artificial intelligence to reason analogically, rest on an inadequate picture of what legal reasoning actually is. For the most part, artificial intelligence now operates as a kind of advanced version of LEXIS, offering research assistance rather than analogical reasoning. But this is a claim about current technology, not about inevitable limitations of artificial intelligence; things might change in the future.","",""
543,"M. Ginsberg","Multivalued logics: a uniform approach to reasoning in artificial intelligence",1988,"","","","",148,"2022-07-13 09:19:55","","10.1111/j.1467-8640.1988.tb00280.x","","",,,,,543,15.97,543,1,34,"This paper describes a uniform formalization of much of the current work in artificial intelligence on inference systems. We show that many of these systems, including first‐order theorem provers, assumption‐based truth maintenance systems (atmss), and unimplemented formal systems such as default logic or circumscription, can be subsumed under a single general framework.","",""
43,"J. Calmet, B. Benhamou, O. Caprotti, Laurent Henocque, V. Sorge","Artificial Intelligence, Automated Reasoning, and Symbolic Computation",2002,"","","","",149,"2022-07-13 09:19:55","","10.1007/3-540-45470-5","","",,,,,43,2.15,9,5,20,"","",""
24,"Sebastian Bader, P. Hitzler, Steffen Hölldobler","The Integration of Connectionism and First-Order Knowledge Representation and Reasoning as a Challenge for Artificial Intelligence",2004,"","","","",150,"2022-07-13 09:19:55","","","","",,,,,24,1.33,8,3,18,"Intelligent systems based on first-order logic on the one hand, and on artificial neural networks (also called connectionist systems) on the other, differ substantially. It would be very desirable to combine the robust neural networking machinery with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. Current state-of-the-art research, however, fails by far to achieve this ultimate goal. As one of the main obstacles to be overcome we perceive the question how symbolic knowledge can be encoded by means of connectionist systems: Satisfactory answers to this will naturally lead the way to knowledge extraction algorithms and to integrated neural-symbolic systems.","",""
54,"Fausto Giunchiglia, P. Bouquet","Introduction to Contextual Reasoning. An Artificial Intelligence Perspective",1997,"","","","",151,"2022-07-13 09:19:55","","","","",,,,,54,2.16,27,2,25,"The notion of context is called to account for a multifarious variety of phenomena. Since Frege's proposal of a principle of contextuality [8], context has had its place in philosophy of language (e.g. [2,15,19]). In Artificial intelligence (AI), McCarthy was the first to argue that formalizing context was a necessary step toward the designing of more general computer programs ([23], but see also [14,28,11,24]). Other work comes from cognitive science (e.g. [7,29,6,16]), where context is viewed as a way of structuring knowledge and modeling its usage in problem solving tasks. The motivations and the approaches to the problem of context are very different, and one might even wonder whether there is something as the problem of context, or rather a multiplicity of different problems very loosely related by the word ""context"". We will argue that most of the proposed notions of context can be looked at from a unifying perspective. However, before we are ready to defend this claim, a lot of preliminary work is needed.","",""
103,"L. Chittaro, A. Montanari","Temporal representation and reasoning in artificial intelligence: Issues and approaches",2000,"","","","",152,"2022-07-13 09:19:55","","10.1023/A:1018900105153","","",,,,,103,4.68,52,2,22,"","",""
115,"VilaLluís","A survey on temporal reasoning in artificial intelligence",1994,"","","","",153,"2022-07-13 09:19:55","","","","",,,,,115,4.11,115,1,28,"The notion of time is ubiquitous in any activity that requires intelligence. In particular , several important notions like change, causality, action are described in terms of time. Therefore, the representation of time and reasoning about time is of crucial importance for many Artiicial Intelligence systems. Speciically during the last 10 years, it has been attracting the attention of many AI researchers. In this survey, the results of this work are analysed. Firstly, Temporal Reasoning is deened. Then, the most important repre-sentational issues which determine a Temporal Reasoning approach are introduced: the logical form on which the approach is based, the ontology (the units taken as primitives, the temporal relations, the algorithms that have been developed,.. .) and the concepts related with reasoning about action (the representation of change, causality, action,.. .). For each issue the diierent choices in the literature are discussed.","",""
198,"A. Sloman","Interactions Between Philosophy and Artificial Intelligence: The Role of Intuition and Non-Logical Reasoning in Intelligence",1971,"","","","",154,"2022-07-13 09:19:55","","10.1016/0004-3702(71)90011-7","","",,,,,198,3.88,198,1,51,"","",""
203,"L. T. McCarty","Reflections on ""Taxman"": An Experiment in Artificial Intelligence and Legal Reasoning",1977,"","","","",155,"2022-07-13 09:19:55","","10.2307/1340132","","",,,,,203,4.51,203,1,45,"","",""
37,"Marco Cadoli","Tractable Reasoning in Artificial Intelligence",1995,"","","","",156,"2022-07-13 09:19:55","","10.1007/3-540-60058-2","","",,,,,37,1.37,37,1,27,"","",""
94,"L. Vieu","Spatial Representation and Reasoning in Artificial Intelligence",1997,"","","","",157,"2022-07-13 09:19:55","","10.1007/978-0-585-28322-7_1","","",,,,,94,3.76,94,1,25,"","",""
225,"J. Baldwin, T. Martin, B. Pilsworth","Fril- Fuzzy and Evidential Reasoning in Artificial Intelligence",1995,"","","","",158,"2022-07-13 09:19:55","","","","",,,,,225,8.33,75,3,27,"From the Publisher:  Presents a theory of uncertainty, consistent with and combining the theories of probability and fuzzy sets. Extends the logic programming form of knowledge representation and method of inference to permit the inclusion of uncertainties such as probabilistic knowledge and fuzzy incompleteness. Describes the application to general areas of knowledge engineering including expert and decision-support systems, evidential and case-based reasoning, fuzzy control and databases. An accompanying disk for Macintosh and one for the IBM PC enables readers to implement the examples while following the text.","",""
573,"D. Gabbay, C. Hogger, J. Robinson","Handbook of Logic in Artificial Intelligence and Logic Programming: Volume 3: Nonmonotonic Reasoning and Uncertain Reasoning",1994,"","","","",159,"2022-07-13 09:19:55","","","","",,,,,573,20.46,191,3,28,"","",""
16,"P. Olivier","Diagrammatic Reasoning: An Artificial Intelligence Perspective",2001,"","","","",160,"2022-07-13 09:19:55","","10.1023/A:1006669526043","","",,,,,16,0.76,16,1,21,"","",""
300,"P. Cohen","Heuristic reasoning about uncertainty: an artificial intelligence approach",1984,"","","","",161,"2022-07-13 09:19:55","","","","",,,,,300,7.89,300,1,38,"","",""
0,"Ruben Branco, A. Branco, João Silva, J. Rodrigues","Commonsense Reasoning: How do Neuro-Symbolic and Neuro-only Approaches Compare?",2021,"","","","",162,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
0,"Maria Dolors Martinez Cazalla, Tania Menendez Martin, Shahid Rahman","Parallel Reasoning by Ratio Legis in Contemporary Jurisprudence. Elements for a Dialogical Approach",2019,"","","","",163,"2022-07-13 09:19:55","","10.1007/978-3-030-61438-6_9","","",,,,,0,0.00,0,3,3,"","",""
0,"L. Valiant","How to Augment Learning with Reasoning?",2021,"","","","",164,"2022-07-13 09:19:55","","10.1145/3486622.0000001","","",,,,,0,0.00,0,1,1,"Learning is a cognitive phenomenon that has proved amenable both to theoretical analysis and exploitation as a technology. However, not all of cognition can be accounted for directly by learning. The question we ask here is whether one can build on the success of machine learning to address the broader goals of artificial intelligence. We regard reasoning as the major component of cognition that needs to be added. We suggest that the central challenge therefore is to unify the formulation of these two phenomena, learning and reasoning, into a single framework with a common semantics. In such a framework one would aim to learn rules with the same success that predicates can be learned by means of machine learning, and, at the same time, to reason with the rules with guarantees analogous to those of standard logic. We discuss how Robust Logic fulfils the role of such a theoretical framework. We also discuss the challenges of testing this experimentally on a significant scale, for tasks where one hopes to exceed the performance offered by learning alone.","",""
0,"Kaiyu Yang","1 Machine Learning for Reasoning",2021,"","","","",165,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,1,1,"Reasoning is a core component of human intelligence that machines still struggle with. I do research in the field of artificial intelligence, with the long-term goal of building machines that reason precisely, systematically, in ways that are interpretable and robust to ambiguity in real-world environments. My research advances towards this goal by attempting to combine the complementary strengths of machine learning and symbolic reasoning. My graduate research has focused on developing machine learning models that represent reasoning via symbolic proofs. They show the promise of new learning paradigms that I envision to be more robust, interpretable, and trustworthy for deployment in real-world high-stake applications. Symbolic reasoning is precise and generalizes systematically to unseen scenarios. But it has been restricted to domains amenable to rigid formalization. In contrast, machine learning has the flexibility to handle noisy and ambiguous domains that are hard to formalize. But predominant machine learning models, such as deep neural networks, are notoriously uninterpretable, data-hungry, and incapable of generalizing outside the training data distribution. Integrating the strengths of both approaches is essential for building flexible reasoning machines with precise and systematic generalization. However, due to the discrete nature of symbolic reasoning, such integration may require a radical departure from the predominant paradigm of gradient-based learning. And my research tries to answer what that alternative form of learning might look like.","",""
0,"Philipp Tueschen, Vítor M. Santos","Cased Based Reasoning in Business Process Management Design",2021,"","","","",166,"2022-07-13 09:19:55","","10.1007/978-3-030-77445-5_65","","",,,,,0,0.00,0,2,1,"","",""
0,"Ruben Branco, A. Branco, J. Silva, J. Rodrigues","Commonsense Reasoning: \protect \@normalcr how do Neuro-Symbolic and Neuro-only approaches compare?",2021,"","","","",167,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
3309,"P. Brézillon, P. Bouquet","Lecture Notes in Artificial Intelligence",1999,"","","","",168,"2022-07-13 09:19:55","","","","",,,,,3309,143.87,1655,2,23,"LNAI was established in the mid-1980s as a topical subseries of LNCS focusing on artificial intelligence. This subseries is devoted to the publication of state-of-the-art research results in artificial intelligence, at a high level and in both printed and electronic versions making use of the well-established LNCS publication machinery. As with the LNCS mother series, proceedings and postproceedings are at the core of LNAI; however, all other sublines are available for LNAI as well. The topics in LNAI include automated reasoning, automated programming, algorithms, knowledge representation, agent-based systems, intelligent systems, expert systems, machine learning, natural-language processing, machine vision, robotics, search systems, knowledge discovery, data mining, and related programming languages.","",""
534,"A. Aamodt, E. Plaza","CASE-BASED REASONING: FOUNDATIONAL ISSUES, METHODOLOGICAL VARIATIONS, AND SYSTEM APPROACHES AICOM - ARTIFICIAL INTELLIGENCE COMMUNICATIONS",1994,"","","","",169,"2022-07-13 09:19:55","","","","",,,,,534,19.07,267,2,28,"","",""
0,"Zhaohan Xi, Ren Pang, Changjiang Li, S. Ji, Xiapu Luo, Xusheng Xiao, Ting Wang","Towards Robust Reasoning over Knowledge Graphs",2021,"","","","",170,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,7,1,"Answering complex logical queries over large-scale knowledge graphs (KGs) represents an important artificial intelligence task, entailing a range of applications. Recently, knowledge representation learning (KRL) has emerged as the stateof-the-art approach, wherein KG entities and the query are embedded into a latent space such that entities that answer the query are embedded close to the query. Yet, despite its surging popularity, the potential security risks of KRL are largely unexplored, which is concerning, given the increasing use of such capabilities in security-critical domains (e.g., cyber-security and healthcare). This work represents a solid initial step towards bridging this gap. We systematize the potential security threats to KRL according to the underlying attack vectors (e.g., knowledge poisoning and query perturbation) and the adversary’s background knowledge. More importantly, we present ROAR1, a new class of attacks that instantiate a variety of such threats. We demonstrate the practicality of ROAR in two representative use cases (i.e., cyber-threat hunting and drug repurposing). For instance, ROAR attains over 99% attack success rate in misleading the threat intelligence engine to give pre-defined answers for target queries, yet without any impact on nontarget ones. Further, we discuss potential countermeasures against ROAR, including filtering of poisoning facts and robust training with adversarial queries, which leads to several promising research directions.","",""
165,"Lluís Vila","A Survey on Temporal Reasoning in Artificial Intelligence",1994,"","","","",171,"2022-07-13 09:19:55","","10.3233/AIC-1994-7102","","",,,,,165,5.89,165,1,28,"","",""
64,"A. Pani, G. Bhattacharjee","Temporal representation and reasoning in artificial intelligence: A review",2001,"","","","",172,"2022-07-13 09:19:55","","10.1016/S0895-7177(01)00049-8","","",,,,,64,3.05,32,2,21,"","",""
54,"Y. Shoham, N. Goyal","Temporal reasoning in artificial intelligence",1988,"","","","",173,"2022-07-13 09:19:55","","10.1016/B978-0-934613-67-5.50015-0","","",,,,,54,1.59,27,2,34,"","",""
3,"Tao Fu","Forecasting Second-hand Housing Price using Artificial Intelligence and Machine Learning Techniques",2018,"","","","",174,"2022-07-13 09:19:55","","10.2991/mcei-18.2018.54","","",,,,,3,0.75,3,1,4,"In this era of information explosion, the development of science and technology changes with each passing day. Therefore, the automatic analysis of scientific and technological trends aims to help scientists extract useful information from a large number of academic conferences and scientific and technological documents, which is of great practical significance. Artificial Intelligence give us an useful techniques, this paper we use using artificial intelligence and machine learning techniques to fit and forecast house price, From the point of view of model, the prediction effect of support vector machine is the best, with strong stability, while neural network is the worst. As a contrast, linear regression and random forest have little difference between them. Introduction Artificial Intelligence is a new science of technology to study, develop and extend human intelligence theory, method, technology and application system. Artificial intelligence is the study of computer to simulate certain thinking processes and intelligent behaviors (such as learning, reasoning, thinking, planning, etc.). Enable the computer to achieve a higher level of application. Artificial intelligence will involve computer science, psychology, philosophy and linguistics. Corinna Cortes and Vapnik (1995) proposed support Vector Machine, which can improve the generalization ability of learning machine and minimize the empirical risk and confidence range by seeking the minimum structural risk[1].It can also be extended to other machine learning problems such as function fitting. Nello Cristianini and John Shawe-Taylor can be applied to support vector machine[2].A random forest is a classifier containing multiple decision trees, and the output categories are determined by the modes of the classes outputted by individual trees.Leo Breiman and Adele Cutler(1995) developed an algorithm to infer random forests[3], which was derived from random decision proposed by Tin Kam Ho of Bell Labs in 1995[4]. It improves the prediction accuracy of the model by summing up a large number of classification trees[5].Instead of traditional machine learning such as neural networks A new model of the. Artificial Neural Network (Ann), a hot research hot spot in artificial intelligence field since 1980s, Rumelhart, Hinton, William's(1986) developed BP algorithm has developed the radial basis function (RBF) basis function neural network for the first time[6].It has strong nonlinear fitting ability, can map any complex nonlinear relation, and the learning rules are simple, easy to realize by computer, and have strong robustness and memory ability. Nonlinear mapping ability and powerful self-learning ability. Methodologies Support Vector Machine. Support Vector Machine is based on the development of statistical learning theory. It systematically studies some fundamental problems in pattern recognition in the case of limited samples. The support Vector Machine regression (SVR) algorithm needs to define a loss function, which can ignore the errors in a range of real values, just like the SVM classification algorithm. This kind of function is insensitive loss. Figure 1shows the one-dimensional linear regression function with insensitive region. Copyright © 2018, the Authors. Published by Atlantis Press. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by-nc/4.0/). 269 8th International Conference on Mechatronics, Computer and Education Informationization (MCEI 2018) Advances in Computer Science Research (ACSR), volume 83","",""
12,"T. T. Dhivyaprabha, P. Subashini, M. Krishnaveni","Computational intelligence based machine learning methods for rule-based reasoning in computer vision applications",2016,"","","","",175,"2022-07-13 09:19:55","","10.1109/SSCI.2016.7850050","","",,,,,12,2.00,4,3,6,"In robot control, rule discovery for understanding of data is of critical importance. Basically, understanding of data depends upon logical rules, similarity evaluation and graphical methods. The expert system collects training examples separately by exploring an anonymous environment by using machine learning techniques. In dynamic environments, future actions are determined by sequences of perceptions thus encoded as rule base. This paper is focused on demonstrating the extraction and application of logical rules for image understanding, using newly developed Synergistic Fibroblast Optimization (SFO) algorithm with well-known existing artificial learning methods. The SFO algorithm is tested in two modes: Michigan and Pittsburgh approach. Optimal rule discovery is evaluated by describing continuous data and verifying accuracy and error level at optimization phase. In this work, Monk's problem is solved by discovering optimal rules that enhance the generalization and comprehensibility of a robot classification system in classifying the objects from extracted attributes to effectively categorize its domain.","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",176,"2022-07-13 09:19:55","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
0,"S. Lucek, S. Collander-Brown","Using artificial intelligence algorithms for high level tactical wargames and new approaches to wargame simulation",2018,"","","","",177,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,2,4,"Received 06 October 2016 Accepted 22 August 2017 Abstract—The Mission Planner is a decision-making toolset developed by NSC, a UK based provider of cutting‐edge training, modelling and simulation and consultancy services, for Dstl (Defence Science and Technology Laboratory, an executive agency, sponsored by the UK Ministry of Defence) currently applied at the tactical level of combat. It aims to support Dstl high intensity warfighting simulations by reducing or eliminating the need for complex pre-scripting of simulated combat units or human-in-the-loop interactors. This has a big impact in reducing the burden of supporting simulations needed for Dstl studies. Two stochastic optimisation Artificial Intelligence (AI) techniques have been used (Genetic Programming and a novel implementation of Simulated Annealing). The algorithms have been employed in a generic architecture that allows simple application to different problems. This is central to the approach taken. The problem considered is the Dstl level land engagement simulation, SimBrig. This is a highly detailed and complex simulation, with execution times that prohibits the many runs required for the AI to consider a wide range of possible solutions (in this case orders for the military units under AI control). Also, application of stochastic optimisation AI directly on this model would result in solutions that exploited the detailed complexities of the engagement simulation, rather than were based on sound tactical reasoning. However, being able to switch the AI between problems means that a solution can be quickly generated against a simplified wargame (a meta model) which represents only the essential elements of the full wargame problem, whilst still referencing the full simulation (SimBrig) to evaluate the quality of the solution as necessary. The meta model is designed to be quick and robust, without the complexities that would be exploited by the AI. However all essential elements of the tactical problem are modelled (albeit as simply as possible) so that the solutions considered by the AI are properly evaluated. A novel approach has been taken in the way the problem is formulated for the AI. Presenting the problem to the AI using military-like syntax results in the AI algorithms efficiently generating plans for tactical problems which resemble human decision making. This paper presents the approach and techniques used in both the AI algorithms and the meta wargame simulation.","",""
21,"Tiago Oliveira, P. Novais, J. Neves","Development and implementation of clinical guidelines: An artificial intelligence perspective",2014,"","","","",178,"2022-07-13 09:19:55","","10.1007/s10462-013-9402-2","","",,,,,21,2.63,7,3,8,"","",""
118,"Pengzhen Lu, Shengyong Chen, Yujun Zheng","Artificial Intelligence in Civil Engineering",2012,"","","","",179,"2022-07-13 09:19:55","","10.1155/2012/145974","","",,,,,118,11.80,39,3,10,"Artificial intelligence is a branch of computer science, involved in the research, design, and application of intelligent computer. Traditional methods for modeling and optimizing complex structure systems require huge amounts of computing resources, and artificial-intelligence-based solutions can often provide valuable alternatives for efficiently solving problems in the civil engineering. This paper summarizes recently developed methods and theories in the developing direction for applications of artificial intelligence in civil engineering, including evolutionary computation, neural networks, fuzzy systems, expert system, reasoning, classification, and learning, as well as others like chaos theory, cuckoo search, firefly algorithm, knowledge-based engineering, and simulated annealing. The main research trends are also pointed out in the end. The paper provides an overview of the advances of artificial intelligence applied in civil engineering.","",""
107,"Nicholas Ernest, David Carroll, C. Schumacher, M. Clark, Kelly Cohen, Gene Lee","Genetic Fuzzy based Artificial Intelligence for Unmanned Combat Aerial Vehicle Control in Simulated Air Combat Missions",2016,"","","","",180,"2022-07-13 09:19:55","","10.4172/2167-0374.1000144","","",,,,,107,17.83,18,6,6,"Breakthroughs in genetic fuzzy systems, most notably the development of the Genetic Fuzzy Tree methodology, have allowed fuzzy logic based Artificial Intelligences to be developed that can be applied to incredibly complex problems. The ability to have extreme performance and computational efficiency as well as to be robust to uncertainties and randomness, adaptable to changing scenarios, verified and validated to follow safety specifications and operating doctrines via formal methods, and easily designed and implemented are just some of the strengths that this type of control brings. Within this white paper, the authors introduce ALPHA, an Artificial Intelligence that controls flights of Unmanned Combat Aerial Vehicles in aerial combat missions within an extreme-fidelity simulation environment. To this day, this represents the most complex application of a fuzzy-logic based Artificial Intelligence to an Unmanned Combat Aerial Vehicle control problem. While development is on-going, the version of ALPHA presented withinwas assessed by Colonel (retired)Gene Lee who described ALPHA as “the most aggressive, responsive, dynamic and credible AI (he’s) seen-to-date.” The quality of these preliminary results in a problem that is not only complex and rife with uncertainties but also contains an intelligent and unrestricted hostile force has significant implications for this type of Artificial Intelligence. This work adds immensely to the body of evidence that this methodology is an ideal solution to a very wide array of problems.","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",181,"2022-07-13 09:19:55","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
0,"K. Manikandan, K. Yogeswari, M. Vishnupriya, S. Priya","A Milestone in Artificial Intelligence & Neural Science Cyborg",2015,"","","","",182,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,4,7,"Neural interfacing is a powerful means, which can develop a robust bridge between humans and machines. In this paper we emphasize on neural interfacing as an evolving trend in wireless communications by taking into account one of its important application i.e. cyborgs. In the next half of the paper we discuss the operational features of cyborgs. In an attempt to promote greater interaction between humans and computers, companies that develop cybernetic technologies participate in a variety of seductive strategies that embody the cyborg discourse. Some of these strategies persuade individuals to concede to particular philosophies, such as the argument that technical artifacts and instrumental reasoning are necessary for effective social development. With the experiments conducted and proposed to be conducted in future, and in the process given a brief description of the advantages and disadvantages of this technology.","",""
4,"Ao Luo, F. Yang, Kunming Luo, Xin Li, Haoqiang Fan, Shuaicheng Liu","Learning Optical Flow with Adaptive Graph Reasoning",2022,"","","","",183,"2022-07-13 09:19:55","","10.1609/aaai.v36i2.20083","","",,,,,4,4.00,1,6,1,"Estimating per-pixel motion between video frames, known as optical flow, is a long-standing problem in video understanding and analysis. Most contemporary optical flow techniques largely focus on addressing the cross-image matching with feature similarity, with few methods considering how to explicitly reason over the given scene for achieving a holistic motion understanding. In this work, taking a fresh perspective, we introduce a novel graph-based approach, called adaptive graph reasoning for optical flow (AGFlow), to emphasize the value of scene/context information in optical flow. Our key idea is to decouple the context reasoning from the matching procedure, and exploit scene information to effectively assist motion estimation by learning to reason over the adaptive graph. The proposed AGFlow can effectively exploit the context information and incorporate it within the matching procedure, producing more robust and accurate results. On both Sintel clean and final passes, our AGFlow achieves the best accuracy with EPE of 1.43 and 2.47 pixels, outperforming state-of-the-art approaches by 11.2% and 13.6%, respectively. Code is publicly available at https://github.com/megvii-research/AGFlow.","",""
18,"John K. C. Kingston","Using artificial intelligence to support compliance with the general data protection regulation",2017,"","","","",184,"2022-07-13 09:19:55","","10.1007/s10506-017-9206-9","","",,,,,18,3.60,18,1,5,"","",""
15,"Yun-he Pan","Special issue on artificial intelligence 2.0",2017,"","","","",185,"2022-07-13 09:19:55","","10.1631/FITEE.1710000","","",,,,,15,3.00,15,1,5,"With the ever-growing popularization of the Internet, universal existence of sensors, emergence of big data, development of e-commerce, rise of the information community, and interconnection and fusion of data and knowledge in human society, physical space, and cyberspace, the information environment surrounding artificial intelligence (AI) development has changed profoundly, leading to a new evolutionary stage: AI 2.0. The emergence of new technologies also promotes AI to a new stage (Pan, 2016). The next-generation AI, namely AI 2.0, is a more explainable, robust, open, and general AI with the following attractive merits: It effectively integrates data-driven machine learning approaches (bottom-up) with knowledge-guided methods (top-down). In addition, it can employ data with different modalities (e.g., visual, auditory, and natural language processing) to perform cross-media learning and inference. Furthermore, there will be a step from the pursuit of an intelligent machine to the hybridaugmented intelligence (i.e., high-level man-machine collaboration and fusion). AI 2.0 will also promote crowd-based intelligence and autonomous-intelligent systems. In the next decades, AI2.0 will probably achieve remarkable progress in aforementioned trends, and therefore significantly change our cities, products, services, economics, environments, even how we advance our society. This special issue aims at reporting recent re-thinking of AI 2.0 from aforementioned aspects as well as practical methodologies, efficient implementations, and applications of AI 2.0. The papers in this special issue can be categorized into two groups. The first group consists of six review papers and the second group five research papers. In the first group, Zhuang et al. (2017) reviewed recent emerging theoretical and technological advances of AI in big data settings. The authors concluded that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI. Li W et al. (2017) described the concepts of crowd intelligence, and explained its relationship to the existing related concepts, e.g., crowdsourcing and human computation. In addition, the authors introduced four categories of representative crowd intelligence platforms. Peng et al. (2017) presented approaches, advances, and future directions in cross-media analysis and reasoning. This paper covers cross-media representation, mining, reasoning, and cross-media knowledge evolution. Tian et al. (2017) reviewed the state-of-the-art research of the perception in terms of visual perception, auditory perception, and speech perception. It also covered perceptual information processing and learning engines. Zhang et al. (2017) introduced the trends in the development of intelligent unmanned autonomous systems. It covered unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned Editorial: Frontiers of Information Technology & Electronic Engineering www.zju.edu.cn/jzus; engineering.cae.cn; www.springerlink.com ISSN 2095-9184 (print); ISSN 2095-9230 (online) E-mail: jzus@zju.edu.cn","",""
1242,"Justin Johnson, B. Hariharan, L. V. D. Maaten, Li Fei-Fei, C. L. Zitnick, Ross B. Girshick","CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",2016,"","","","",186,"2022-07-13 09:19:55","","10.1109/CVPR.2017.215","","",,,,,1242,207.00,207,6,6,"When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover short-comings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.","",""
2,"Z. Hippe, J. Kulikowski, T. Mroczek, J. Wtorek","Issues and Challenges in Artificial Intelligence",2014,"","","","",187,"2022-07-13 09:19:55","","10.1007/978-3-319-06883-1","","",,,,,2,0.25,1,4,8,"","",""
2,"Kyle Richardson, Ashish Sabharwal","Pushing the Limits of Rule Reasoning in Transformers through Natural Language Satisfiability",2021,"","","","",188,"2022-07-13 09:19:55","","10.1609/aaai.v36i10.21371","","",,,,,2,2.00,1,2,1,"Investigating the reasoning abilities of transformer models, and discovering new challenging tasks for them, has been a topic of much interest. Recent studies have found these models to be surprisingly strong at performing deductive reasoning over formal logical theories expressed in natural language. A shortcoming of these studies, however, is that they do not take into account that logical theories, when sampled uniformly at random, do not necessarily lead to hard instances. We propose a new methodology for creating challenging algorithmic reasoning datasets that focus on natural language satisfiability (NLSat) problems. The key idea is to draw insights from empirical sampling of hard propositional SAT problems and from complexity-theoretic studies of language. This methodology allows us to distinguish easy from hard instances, and to systematically increase the complexity of existing reasoning benchmarks such as RuleTaker. We find that current transformers, given sufficient training data, are surprisingly robust at solving the resulting NLSat problems of substantially increased difficulty. They also exhibit some degree of scale-invariance—the ability to generalize to problems of larger size and scope. Our results, however, reveal important limitations too: careful sampling of training data is crucial for building models that generalize to larger problems, and transformer models’ limited scale-invariance suggests they are far from learning robust deductive reasoning algorithms.","",""
11,"L. Eliot","An Ontological AI-and-Law Framework for the Autonomous Levels of AI Legal Reasoning",2020,"","","","",189,"2022-07-13 09:19:55","","","","",,,,,11,5.50,11,1,2,"A framework is proposed that seeks to identify and establish a set of robust autonomous levels articulating the realm of Artificial Intelligence and Legal Reasoning (AILR). Doing so provides a sound and parsimonious basis for being able to assess progress in the application of AI to the law, and can be utilized by scholars in academic pursuits of AI legal reasoning, along with being used by law practitioners and legal professionals in gauging how advances in AI are aiding the practice of law and the realization of aspirational versus achieved results. A set of seven levels of autonomy for AI and Legal Reasoning are meticulously proffered and mindfully discussed.","",""
9,"R. Das, Ameya Godbole, S. Dhuliawala, M. Zaheer, A. McCallum","A Simple Approach to Case-Based Reasoning in Knowledge Bases",2020,"","","","",190,"2022-07-13 09:19:55","","10.24432/C52S3K","","",,,,,9,4.50,2,5,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires \emph{no training}, and is reminiscent of case-based reasoning in classical artificial intelligence (AI).  Consider the task of finding a target entity given a source entity and a binary relation.  Our approach finds multiple \textit{graph path patterns} that connect similar source entities through the given relation, and looks for pattern matches starting from the query source.  Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122.  We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",191,"2022-07-13 09:19:55","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
8,"L. Eliot","Turing Test and the Practice of Law: The Role of Autonomous Levels of AI Legal Reasoning",2020,"","","","",192,"2022-07-13 09:19:55","","","","",,,,,8,4.00,8,1,2,"Artificial Intelligence (AI) is increasingly being applied to law and a myriad of legal tasks amid attempts to bolster AI Legal Reasoning (AILR) autonomous capabilities. A major question that has generally been unaddressed involves how we will know when AILR has achieved autonomous capacities. The field of AI has grappled with similar quandaries over how to assess the attainment of Artificial General Intelligence (AGI), a persistently discussed issue among scholars since the inception of AI, with the Turing Test communally being considered as the bellwether for ascertaining such matters. This paper proposes a variant of the Turing Test that is customized for specific use in the AILR realm, including depicting how this famous gold standard of AI fulfillment can be robustly applied across the autonomous levels of AI Legal Reasoning.","",""
2,"E. Benderskaya, S. V. Zhukova","Multidisciplinary Trends in Modern Artificial Intelligence: Turing's Way",2013,"","","","",193,"2022-07-13 09:19:55","","10.1007/978-3-642-29694-9_13","","",,,,,2,0.22,1,2,9,"","",""
5,"L. Eliot","Authorized and Unauthorized Practices of Law: The Role of Autonomous Levels of AI Legal Reasoning",2020,"","","","",194,"2022-07-13 09:19:55","","","","",,,,,5,2.50,5,1,2,"Advances in Artificial Intelligence (AI) and Machine Learning (ML) that are being applied to legal efforts have raised controversial questions about the existent restrictions imposed on the practice-of-law. Generally, the legal field has sought to define Authorized Practices of Law (APL) versus Unauthorized Practices of Law (UPL), though the boundaries are at times amorphous and some contend capricious and self-serving, rather than being devised holistically for the benefit of society all told. A missing ingredient in these arguments is the realization that impending legal profession disruptions due to AI can be more robustly discerned by examining the matter through the lens of a framework utilizing the autonomous levels of AI Legal Reasoning (AILR). This paper explores a newly derived instrumental grid depicting the key characteristics underlying APL and UPL as they apply to the AILR autonomous levels and offers key insights for the furtherance of these crucial practice-of-law debates.","",""
3,"Lucas Rizzo","Evaluating the Impact of Defeasible Argumentation as a Modelling Technique for Reasoning under Uncertainty",2020,"","","","",195,"2022-07-13 09:19:55","","10.21427/G02A-WG20","","",,,,,3,1.50,3,1,2,"Limited work exists for the comparison across distinct knowledge-based approaches in Artificial Intelligence (AI) for non-monotonic reasoning, and in particular for the examination of their inferential and explanatory capacity. Non-monotonicity, or defeasibility, allows the retraction of a conclusion in the light of new information. It is a similar pattern to human reasoning, which draws conclusions in the absence of information, but allows them to be corrected once new pieces of evidence arise. Thus, this thesis focuses on a comparison of three approaches in AI for implementation of non-monotonic reasoning models of inference, namely: expert systems, fuzzy reasoning and defeasible argumentation. Three applications from the fields of decision-making in healthcare and knowledge representation and reasoning were selected from real-world contexts for evaluation: human mental workload modelling, computational trust modelling, and mortality occurrence modelling with biomarkers. The link between these applications comes from their presumptively non-monotonic nature. They present incomplete, ambiguous and retractable pieces of evidence. Hence, reasoning applied to them is likely suitable for being modelled by non-monotonic reasoning systems. An experiment was performed by exploiting six deductive knowledge bases produced with the aid of domain experts. These were coded into models built upon the selected reasoning approaches and were subsequently elicited with real-world data. The numerical inferences produced by these models were analysed according to common metrics of evaluation for each field of application. For the examination of explanatory capacity, properties such as understandability, extensibility, and post-hoc interpretability were meticulously described and qualitatively compared. Findings suggest that the variance of the inferences produced by expert systems and fuzzy reasoning models was higher, highlighting poor stability. In contrast, the variance of argument-based models was lower, showing a superior stability of its inferences across different system configurations. In addition, when compared in a context with large amounts of conflicting information, defeasible argumentation exhibited a stronger potential for conflict resolution, while presenting robust inferences. An in-depth discussion of the explanatory capacity showed how defeasible argumentation can lead to the","",""
4,"M. Gates, Mukesh Ambani","Non-Parametric Reasoning on Knowledge Bases",2020,"","","","",196,"2022-07-13 09:19:55","","","","",,,,,4,2.00,2,2,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence (AI). Consider the task of finding a target entity given a source entity and a binary relation. Our approach finds multiple graph path patterns that connect similar source entities through the given relation, and looks for pattern matches starting from the query source. Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
0,"Anne-Laure Wozniak, S. Segura, Raúl Mazo, Sarah Leroy","Robustness Testing of a Machine Learning-based Road Object Detection System: An Industrial Case",2022,"","","","",197,"2022-07-13 09:19:55","","","","",,,,,0,0.00,0,4,1,"With the increasing development of critical systems based on artificial intelligence (AI), methods have been proposed and evaluated in academia to assess the reliability of these systems. In the context of computer vision, some approaches use the generation of images altered by common perturbations and realistic transformations to assess the robustness of systems. To better understand the strengths and limitations of these approaches, we report the results obtained on an industrial case of a road object detection system. By comparing these results with those of reference models, we identify areas for improvement regarding the robustness of the system and the metrics used for this evaluation.CCS CONCEPTS • Computing methodologies → Machine learning.","",""
109,"Nadine Abbas, Y. Nasser, Karim Ahmad","Recent advances on artificial intelligence and learning techniques in cognitive radio networks",2015,"","","","",198,"2022-07-13 09:19:55","","10.1186/S13638-015-0381-7","","",,,,,109,15.57,36,3,7,"","",""
0,"Gasmi Safa, Djebbar Akila, Merouani Hayet Farida","A Survey on Hybrid Case-Based Reasoning and Deep Learning Systems for Medical Data Classification",2022,"","","","",199,"2022-07-13 09:19:55","","10.4018/978-1-7998-9016-4.ch006","","",,,,,0,0.00,0,3,1,"Several artificial intelligence approaches, particularly case-based reasoning (CBR), which is analogous to the context of human reasoning for problem resolution, have demonstrated their efficiency and reliability in the medical field. In recent years, deep learning represents the latest iteration of an advance in artificial intelligence technologies in medicine to aid in data classification, diagnosis of new diseases, and complex decision-making. Although these two independent approaches have good results in the medical field, the latter is still a complex field. This chapter reviews the available literature on CBR systems, deep learning systems, and CBR deep learning systems in medicine. The methods used and results obtained are discussed, and key findings are highlighted. Further, in the light of this review, some directions for future research are given. This chapter presents the proposed approach, which helps to make the retrieval phase of the CBR cycle more reliable and robust.","",""
0,"Riccardo Buscaroli, F. Chesani, Giulia Giuliani, Daniela Loreti, P. Mello","A Prolog application for reasoning on maths puzzles with diagrams",2022,"","","","",200,"2022-07-13 09:19:55","","10.1080/0952813x.2022.2062456","","",,,,,0,0.00,0,5,1,"Despite the indisputable progresses of artificial intelligence, some tasks that are rather easy for a human being are still challenging for a machine. An emblematic example is the resolution of mathematical puzzles with diagrams. Sub-symbolical approaches have proven suc-cessful in fields like image recognition and natural language processing, but the combination of these techniques into a multimodal approach towards the identification of the puzzle’s answer appears to be a matter of reasoning, more suitable for the application of a symbolic technique. In this work, we employ logic programming to perform spatial reasoning on the puzzle’s diagram and integrate the deriving knowledge into the solving process. Analysing the resolution strategies required by the puzzles of an international competition for humans, we draw the design principles of a Prolog reasoning library, which interacts with image processing software to formulate the puzzle’s constraints. The library integrates the knowledge from different sources, and relies on the Prolog inference engine to provide the answer. This work can be considered as a first step towards the ambitious goal of a machine autonomously solving a problem in a generic context starting from its textual-graphical presentation. An ability that can help potentially every human–machine interaction.","",""
