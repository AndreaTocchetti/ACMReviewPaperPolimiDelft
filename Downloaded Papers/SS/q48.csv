Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
8,"Dongqi Han, Zhiliang Wang, Ying Zhong, Wenqi Chen, Jiahai Yang, Shuqiang Lu, Xingang Shi, Xia Yin","Evaluating and Improving Adversarial Robustness of Machine Learning-Based Network Intrusion Detectors",2020,"","","","",1,"2022-07-13 09:25:19","","10.1109/JSAC.2021.3087242","","",,,,,8,4.00,1,8,2,"Machine learning (ML), especially deep learning (DL) techniques have been increasingly used in anomaly-based network intrusion detection systems (NIDS). However, ML/DL has shown to be extremely vulnerable to adversarial attacks, especially in such security-sensitive systems. Many adversarial attacks have been proposed to evaluate the robustness of ML-based NIDSs. Unfortunately, existing attacks mostly focused on feature-space and/or white-box attacks, which make impractical assumptions in real-world scenarios, leaving the study on practical gray/black-box attacks largely unexplored. To bridge this gap, we conduct the first systematic study of the gray/black-box traffic-space adversarial attacks to evaluate the robustness of ML-based NIDSs. Our work outperforms previous ones in the following aspects: (i) practical —the proposed attack can automatically mutate original traffic with extremely limited knowledge and affordable overhead while preserving its functionality; (ii) generic —the proposed attack is effective for evaluating the robustness of various NIDSs using diverse ML/DL models and non-payload-based features; (iii) explainable —we propose an explanation method for the fragile robustness of ML-based NIDSs. Based on this, we also propose a defense scheme against adversarial attacks to improve system robustness. We extensively evaluate the robustness of various NIDSs using diverse feature sets and ML/DL models. Experimental results show our attack is effective (e.g., >97% evasion rate in half cases for Kitsune, a state-of-the-art NIDS) with affordable execution cost and the proposed defense method can effectively mitigate such attacks (evasion rate is reduced by >50% in most cases).","",""
19,"Yannick Suter, U. Knecht, Mariana Alão, W. Valenzuela, E. Hewer, P. Schucht, R. Wiest, M. Reyes","Radiomics for glioblastoma survival analysis in pre-operative MRI: exploring feature robustness, class boundaries, and machine learning techniques",2020,"","","","",2,"2022-07-13 09:25:19","","10.1186/s40644-020-00329-8","","",,,,,19,9.50,2,8,2,"","",""
5,"Zhuolin Yang, Zhikuan Zhao, Hengzhi Pei, Boxin Wang, Bojan Karlas, Ji Liu, Heng Guo, Bo Li, Ce Zhang","End-to-end Robustness for Sensing-Reasoning Machine Learning Pipelines",2020,"","","","",3,"2022-07-13 09:25:19","","","","",,,,,5,2.50,1,9,2,"As machine learning (ML) being applied to many mission-critical scenarios, certifying ML model robustness becomes increasingly important. Many previous works focuses on the robustness of independent ML and ensemble models, and can only certify a very small magnitude of the adversarial perturbation. In this paper, we take a different viewpoint and improve learning robustness by going beyond independent ML and ensemble models. We aim at promoting the generic Sensing-Reasoning machine learning pipeline which contains both the sensing (e.g. deep neural networks) and reasoning (e.g. Markov logic networks (MLN)) components enriched with domain knowledge. Can domain knowledge help improve learning robustness? Can we formally certify the end-to-end robustness of such an ML pipeline?  We first theoretically analyze the computational complexity of checking the provable robustness in the reasoning component. We then derive the provable robustness bound for several concrete reasoning components. We show that for reasoning components such as MLN and a specific family of Bayesian networks it is possible to certify the robustness of the whole pipeline even with a large magnitude of perturbation which cannot be certified by existing work. Finally, we conduct extensive real-world experiments on large scale datasets to evaluate the certified robustness for Sensing-Reasoning ML pipelines.","",""
161,"A. Bhagoji, Daniel Cullina, Chawin Sitawarin, Prateek Mittal","Enhancing robustness of machine learning systems via data transformations",2017,"","","","",4,"2022-07-13 09:25:19","","10.1109/CISS.2018.8362326","","",,,,,161,32.20,40,4,5,"We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification.","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",5,"2022-07-13 09:25:19","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
8,"Sakshi Udeshi, Sudipta Chattopadhyay","Grammar Based Directed Testing of Machine Learning Systems",2019,"","","","",6,"2022-07-13 09:25:19","","10.1109/tse.2019.2953066","","",,,,,8,2.67,4,2,3,"The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our Ogma approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. Ogma leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our Ogma approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare Ogma with a random test generation approach and observe that Ogma is more effective than such random test generation by up to 489 percent.","",""
29,"Nishat Koti, Mahak Pancholi, A. Patra, A. Suresh","SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning",2020,"","","","",7,"2022-07-13 09:25:19","","","","",,,,,29,14.50,7,4,2,"Performing ML computation on private data while maintaining data privacy aka Privacy-preserving Machine Learning (PPML) is an emergent field of research. Recently, PPML has seen a visible shift towards the adoption of Secure Outsourced Computation (SOC) paradigm, due to the heavy computation that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the users irrespective of any adversarial behaviour. Robustness, a highly desirable feature, evokes user participation without the fear of denial of service.  At the heart of our framework lies a highly-efficient, maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output delivery (GOD) in the honest-majority setting. To the best of our knowledge, SWIFT is the first robust and efficient PPML framework in the 3PC setting. SWIFT is as fast as the best-known 3PC framework BLAZE (Patra et al. NDSS'20) which only achieves fairness. Fairness ensures either all or none receive the output, whereas GOD ensures guaranteed output delivery no matter what. We extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS'20) and twice faster than the best-known robust 4PC framework FLASH (Byali et al. PETS'20).  We demonstrate the practical relevance of our framework by benchmarking two important applications-- i) ML algorithms: Logistic Regression and Neural Network, and ii) Biometric matching, both over a 64-bit ring in WAN setting. Our readings reflect our claims as above.","",""
46,"F. Yuan, S. A. Zargar, Qiuyi Chen, Shaohan Wang","Machine learning for structural health monitoring: challenges and opportunities",2020,"","","","",8,"2022-07-13 09:25:19","","10.1117/12.2561610","","",,,,,46,23.00,12,4,2,"A physics-based approach to structural health monitoring (SHM) has practical shortcomings which restrict its suitability to simple structures under well controlled environments. With the advances in information and sensing technology (sensors and sensor networks), it has become feasible to monitor large/diverse number of parameters in complex real-world structures either continuously or intermittently by employing large in-situ (wireless) sensor networks. The availability of this historical data has engendered a lot of interest in a data-driven approach as a natural and more viable option for realizing the goal of SHM in such structures. However, the lack of sensor data corresponding to different damage scenarios continues to remain a challenge. Most of the supervised machine-learning/deep-learning techniques, when trained using this inherently limited data, lack robustness and generalizability. Physics-informed learning, which involves the integration of domain knowledge into the learning process, is presented here as a potential remedy to this challenge. As a step towards the goal of automated damage detection (mathematically an inverse problem), preliminary results are presented from dynamic modelling of beam structures using physics-informed artificial neural networks. Forward and inverse problems involving partial differential equations are solved and comparisons reveal a clear superiority of physics-informed approach over one that is purely datadriven vis-à-vis overfitting/generalization. Other ways of incorporating domain knowledge into the machine learning pipeline are then presented through case-studies on various aspects of NDI/SHM (visual inspection, impact diagnosis). Lastly, as the final attribute of an optimal SHM approach, a sensing paradigm for non-contact full-field measurements for damage diagnosis is presented.","",""
27,"Nicholas Shawen, L. Lonini, C. Mummidisetty, Ilona Shparii, Mark V. Albert, Konrad Paul Kording, A. Jayaraman","Fall Detection in Individuals With Lower Limb Amputations Using Mobile Phones: Machine Learning Enhances Robustness for Real-World Applications",2017,"","","","",9,"2022-07-13 09:25:19","","10.2196/mhealth.8201","","",,,,,27,5.40,4,7,5,"Background Automatically detecting falls with mobile phones provides an opportunity for rapid response to injuries and better knowledge of what precipitated the fall and its consequences. This is beneficial for populations that are prone to falling, such as people with lower limb amputations. Prior studies have focused on fall detection in able-bodied individuals using data from a laboratory setting. Such approaches may provide a limited ability to detect falls in amputees and in real-world scenarios. Objective The aim was to develop a classifier that uses data from able-bodied individuals to detect falls in individuals with a lower limb amputation, while they freely carry the mobile phone in different locations and during free-living. Methods We obtained 861 simulated indoor and outdoor falls from 10 young control (non-amputee) individuals and 6 individuals with a lower limb amputation. In addition, we recorded a broad database of activities of daily living, including data from three participants’ free-living routines. Sensor readings (accelerometer and gyroscope) from a mobile phone were recorded as participants freely carried it in three common locations—on the waist, in a pocket, and in the hand. A set of 40 features were computed from the sensors data and four classifiers were trained and combined through stacking to detect falls. We compared the performance of two population-specific models, trained and tested on either able-bodied or amputee participants, with that of a model trained on able-bodied participants and tested on amputees. A simple threshold-based classifier was used to benchmark our machine-learning classifier. Results The accuracy of fall detection in amputees for a model trained on control individuals (sensitivity: mean 0.989, 1.96*standard error of the mean [SEM] 0.017; specificity: mean 0.968, SEM 0.025) was not statistically different (P=.69) from that of a model trained on the amputee population (sensitivity: mean 0.984, SEM 0.016; specificity: mean 0.965, SEM 0.022). Detection of falls in control individuals yielded similar results (sensitivity: mean 0.979, SEM 0.022; specificity: mean 0.991, SEM 0.012). A mean 2.2 (SD 1.7) false alarms per day were obtained when evaluating the model (vs mean 122.1, SD 166.1 based on thresholds) on data recorded as participants carried the phone during their daily routine for two or more days. Machine-learning classifiers outperformed the threshold-based one (P<.001). Conclusions A mobile phone-based fall detection model can use data from non-amputee individuals to detect falls in individuals walking with a prosthesis. We successfully detected falls when the mobile phone was carried across multiple locations and without a predetermined orientation. Furthermore, the number of false alarms yielded by the model over a longer period of time was reasonably low. This moves the application of mobile phone-based fall detection systems closer to a real-world use case scenario.","",""
38,"M. Yoosefzadeh-Najafabadi, H. Earl, D. Tulpan, J. Sulik, M. Eskandari","Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean",2021,"","","","",10,"2022-07-13 09:25:19","","10.3389/fpls.2020.624273","","",,,,,38,38.00,8,5,1,"Recent substantial advances in high-throughput field phenotyping have provided plant breeders with affordable and efficient tools for evaluating a large number of genotypes for important agronomic traits at early growth stages. Nevertheless, the implementation of large datasets generated by high-throughput phenotyping tools such as hyperspectral reflectance in cultivar development programs is still challenging due to the essential need for intensive knowledge in computational and statistical analyses. In this study, the robustness of three common machine learning (ML) algorithms, multilayer perceptron (MLP), support vector machine (SVM), and random forest (RF), were evaluated for predicting soybean (Glycine max) seed yield using hyperspectral reflectance. For this aim, the hyperspectral reflectance data for the whole spectra ranged from 395 to 1005 nm, which were collected at the R4 and R5 growth stages on 250 soybean genotypes grown in four environments. The recursive feature elimination (RFE) approach was performed to reduce the dimensionality of the hyperspectral reflectance data and select variables with the largest importance values. The results indicated that R5 is more informative stage for measuring hyperspectral reflectance to predict seed yields. The 395 nm reflectance band was also identified as the high ranked band in predicting the soybean seed yield. By considering either full or selected variables as the input variables, the ML algorithms were evaluated individually and combined-version using the ensemble–stacking (E–S) method to predict the soybean yield. The RF algorithm had the highest performance with a value of 84% yield classification accuracy among all the individual tested algorithms. Therefore, by selecting RF as the metaClassifier for E–S method, the prediction accuracy increased to 0.93, using all variables, and 0.87, using selected variables showing the success of using E–S as one of the ensemble techniques. This study demonstrated that soybean breeders could implement E–S algorithm using either the full or selected spectra reflectance to select the high-yielding soybean genotypes, among a large number of genotypes, at early growth stages.","",""
3,"H. Vardhan, P. Völgyesi, J. Sztipanovits","Machine learning assisted propeller design",2021,"","","","",11,"2022-07-13 09:25:19","","10.1145/3450267.3452001","","",,,,,3,3.00,1,3,1,"Propellers are one of the most widely used propulsive devices for generating thrust from rotational engine motion both in marine vehicles and subsonic air-crafts. Due to their simplicity, robustness and high efficiency, propellers remained the mainstream design choice over the last hundred years. On the other hand, finding the optimal application-specific geometry is still challenging. This work in progress report describes application of modern and rapidly developing Machine Learning (ML) techniques to gain novel designs. We rely on a rich set of preexisting parametric design patterns and accumulated engineering knowledge supplemented by high-fidelity simulation models to formulate the design process as a supervised learning problem. The aim of our work is to develop and evaluate machine learning models for the parametric design of propellers based on application-specific constraints. While the application of ML techniques in optimal propeller design is at a very nascent level, we believe that our early results are promising with a potentially significant impact on the overall design process. The ML-assisted design flow allows for a more automated design space exploration process with less dependency on human intuition and engineering guidance.","",""
11,"S. Tripathi, David Muhr, Manuel Brunner, F. Emmert‐Streib, H. Jodlbauer, M. Dehmer","Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing",2020,"","","","",12,"2022-07-13 09:25:19","","10.3389/frai.2021.576892","","",,,,,11,5.50,2,6,2,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.","",""
10,"M. Campi, S. Garatti","Scenario optimization with relaxation: a new tool for design and application to machine learning problems",2020,"","","","",13,"2022-07-13 09:25:19","","10.1109/CDC42340.2020.9303914","","",,,,,10,5.00,5,2,2,"Scenario optimization is by now a well established technique to perform designs in the presence of uncertainty. It relies on domain knowledge integrated with first-hand information that comes from data and generates solutions that are also accompanied by precise statements of reliability. In this paper, following recent developments in [22], we venture beyond the traditional set-up of scenario optimization by analyzing the concept of constraints relaxation. By a solid theoretical underpinning, this new paradigm furnishes fundamental tools to perform designs that meet a proper compromise between robustness and performance. After suitably expanding the scope of constraints relaxation as proposed in [22], we focus on various classical Support Vector methods in machine learning – including SVM (Support Vector Machine), SVR (Support Vector Regression) and SVDD (Support Vector Data Description) – and derive new results that attest the ability of these methods to generalize.","",""
9,"Phauk Sokkhey, T. Okazaki","Hybrid Machine Learning Algorithms for Predicting Academic Performance",2020,"","","","",14,"2022-07-13 09:25:19","","10.14569/ijacsa.2020.0110104","","",,,,,9,4.50,5,2,2,"The large volume of data and its complexity in educational institutions require the sakes from informative technologies. In order to facilitate this task, many researchers have focused on using machine learning to extract knowledge from the education database to support students and instructors in getting better performance. In prediction models, the challenging task is to choose the effective techniques which could produce satisfying predictive accuracy. Hence, in this work, we introduced a hybrid approach of principal component analysis (PCA) as conjunction with four machines learning (ML) algorithms: random forest (RF), C5.0 of decision tree (DT), and naive Bayes (NB) of Bayes network and support vector machine (SVM), to improve the performances of classification by solving the misclassification problem. Three datasets were used to confirm the robustness of the proposed models. Through the given datasets, we evaluated the classification accuracy and root mean square error (RSME) as evaluation metrics of the proposed models. In this classification problem, 10-fold cross-validation was proposed to evaluate the predictive performance. The proposed hybrid models produced very prediction results which shown itself as the optimal prediction and classification algorithms.","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",15,"2022-07-13 09:25:19","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
15,"A. Kaur, Kamaldeep Kaur","An Empirical Study of Robustness and Stability of Machine Learning Classifiers in Software Defect Prediction",2014,"","","","",16,"2022-07-13 09:25:19","","10.1007/978-3-319-11218-3_35","","",,,,,15,1.88,8,2,8,"","",""
10,"Yifan Cui, E. Tchetgen","Selective machine learning of doubly robust functionals.",2019,"","","","",17,"2022-07-13 09:25:19","","","","",,,,,10,3.33,5,2,3,"While model selection is a well-studied topic in parametric and nonparametric regression or density estimation, model selection of possibly high-dimensional nuisance parameters in semiparametric problems is far less developed. In this paper, we propose a selective machine learning framework for making inferences about a finite-dimensional functional defined on a semiparametric model, when the latter admits a doubly robust estimating function. We introduce two model selection criteria for bias reduction of functional of interest, each based on a novel definition of pseudo-risk for the functional that embodies this double robustness property and thus may be used to select the candidate model that is nearest to fulfilling this property even when all models are wrong. We establish an oracle property for a multi-fold cross-validation version of the new model selection criteria which states that our empirical criteria perform nearly as well as an oracle with a priori knowledge of the pseudo-risk for each candidate model. We also describe a smooth approximation to the selection criteria which allows for valid post-selection inference. Finally, we apply the approach to model selection of a semiparametric estimator of average treatment effect given an ensemble of candidate machine learners to account for confounding in an observational study.","",""
6,"Roberto Medico, D. Spina, D. Vande Ginste, D. Deschrijver, T. Dhaene","Machine-Learning-Based Error Detection and Design Optimization in Signal Integrity Applications",2019,"","","","",18,"2022-07-13 09:25:19","","10.1109/TCPMT.2019.2916902","","",,,,,6,2.00,1,5,3,"Evaluating the robustness of integrated circuits (ICs) against noise and disturbances is of crucial importance in signal integrity (SI) applications. In this paper, the addressed challenge is to build a software-based framework allowing for automated detection of failures and fast simulation-based evaluation of designs. In particular, these tasks are here addressed using anomaly detection (AD), a branch of machine learning (ML) techniques focused on identifying erroneous or deviant data. In the proposed framework, the ML model only requires the time-domain waveforms and no additional knowledge about the circuit nor about the errors to be identified. Specifically, a two-step approach to detect anomalous behaviors in output waveforms of digital ICs is proposed, comprising a first phase where the ML models are trained to learn relevant features describing the data and a second one where those features are used to identify anomalies with unsupervised or semisupervised AD techniques. Two relevant application examples validate the performance and flexibility of the proposed method.","",""
3,"Yusuke Kawamoto","Towards Logical Specification of Statistical Machine Learning",2019,"","","","",19,"2022-07-13 09:25:19","","10.1007/978-3-030-30446-1_16","","",,,,,3,1.00,3,1,3,"","",""
5,"M. Usama, Muhammad Asim, Junaid Qadir, Ala Al-Fuqaha, M. Imran","Adversarial Machine Learning Attack on Modulation Classification",2019,"","","","",20,"2022-07-13 09:25:19","","10.1109/UCET.2019.8881843","","",,,,,5,1.67,1,5,3,"Modulation classification is an important component of cognitive self-driving networks. Recently many ML-based modulation classification methods have been proposed. We have evaluated the robustness of 9 ML-based modulation classifiers against the powerful Carlini & Wagner (C-W) attack and showed that the current ML-based modulation classifiers do not provide any deterrence against adversarial ML examples. To the best of our knowledge, we are the first to report the results of the application of the C-W attack for creating adversarial examples against various ML models for modulation classification.","",""
79,"Taesik Na, J. Ko, S. Mukhopadhyay","Cascade Adversarial Machine Learning Regularized with a Unified Embedding",2017,"","","","",21,"2022-07-13 09:25:19","","","","",,,,,79,15.80,26,3,5,"Injecting adversarial examples during training, known as adversarial training, can improve robustness against one-step attacks, but not for unknown iterative attacks. To address this challenge, we first show iteratively generated adversarial images easily transfer between networks trained with the same strategy. Inspired by this observation, we propose cascade adversarial training, which transfers the knowledge of the end results of adversarial training. We train a network from scratch by injecting iteratively generated adversarial images crafted from already defended networks in addition to one-step adversarial images from the network being trained. We also propose to utilize embedding space for both classification and low-level (pixel-level) similarity learning to ignore unknown pixel level perturbation. During training, we inject adversarial images without replacing their corresponding clean images and penalize the distance between the two embeddings (clean and adversarial). Experimental results show that cascade adversarial training together with our proposed low-level similarity learning efficiently enhances the robustness against iterative attacks, but at the expense of decreased robustness against one-step attacks. We show that combining those two techniques can also improve robustness under the worst case black box attack scenario.","",""
10,"Runzhe Zhan, Xuebo Liu, Derek F. Wong, Lidia S. Chao","Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation",2021,"","","","",22,"2022-07-13 09:25:19","","","","",,,,,10,10.00,3,4,1,"Meta-learning has been sufficiently validated to be beneficial for low-resource neural machine translation (NMT). However, we find that meta-trained NMT fails to improve the translation performance of the domain unseen at the metatraining stage. In this paper, we aim to alleviate this issue by proposing a novel meta-curriculum learning for domain adaptation in NMT. During meta-training, the NMT first learns the similar curricula from each domain to avoid falling into a bad local optimum early, and finally learns the curricula of individualities to improve the model robustness for learning domain-specific knowledge. Experimental results on 10 different low-resource domains show that meta-curriculum learning can improve the translation performance of both familiar and unfamiliar domains. All the codes and data are freely available at https://github.com/NLP2CT/ Meta-Curriculum.","",""
40,"G. Choudhury, David F. Lynch, Gaurav Thakur, Simon Tse","Two use cases of machine learning for SDN-enabled ip/optical networks: traffic matrix prediction and optical path performance prediction [Invited]",2018,"","","","",23,"2022-07-13 09:25:19","","10.1364/JOCN.10.000D52","","",,,,,40,10.00,10,4,4,"We describe two applications ofmachine learning in the context of internet protocol (IP)/Optical networks. The first one allows agilemanagement of resources in a core IP/Optical network by using machine learning for shorttermand long-term prediction of traffic flows. It also allows joint global optimization of IP and optical layers using colorless/ directionless (CD) reconfigurable optical add-drop multiplexers (ROADMs). Multilayer coordination allows for significant cost savings, flexible new services to meet dynamic capacity needs, and improved robustness by being able to proactively adapt to new traffic patterns and network conditions. The second application is important as we migrate our networks to Open ROADM networks to allow physical routing without the need for detailed knowledge of optical parameters. We discuss a proof-of-concept study, where detailed performance data for established wavelengths in an existing ROADM network is used for machine learning to predict the optical performance of each wavelength. Both applications can be efficiently implemented by using a software-defined network controller.","",""
4,"Abubakar Siddique, Will N. Browne, G. Grimshaw","Lateralized learning for robustness against adversarial attacks in a visual classification system",2020,"","","","",24,"2022-07-13 09:25:19","","10.1145/3377930.3390164","","",,,,,4,2.00,1,3,2,"Deep learning is an important field of machine learning. It is playing a critical role in a variety of applications ranging from self-driving cars to security and surveillance. However, deep networks have deep flaws. For example, they are highly vulnerable to adversarial attacks. One reason may be the homogeneous nature of their knowledge representation, which allows a single disruptive pattern to cause miss-classification. Biological intelligence has lateral asymmetry, which allows heterogeneous, modular learning at different levels of abstraction, enabling different representations of the same object. This work aims to incorporate lateralization and modular learning at different levels of abstraction in an evolutionary machine learning system. The results of image classification tasks show that the lateralized system efficiently learns hierarchical distributions of knowledge, demonstrating performance that is similar to (or better than) other state-of-the-art deep systems as it reasons using multiple representations. Crucially, the novel system outperformed all the state-of-the-art deep models for the classification of normal and adversarial images by 0.43% -- 2.56% and 2.15% -- 25.84%, respectively. Lateralisation enabled the system to exhibit robustness beyond previous work, which advocates for the creation of data sets that enable components of objects and the objects themselves to be learned specifically or in an end-to-end manner.","",""
71,"T. Cohen, M. Freytsis, B. Ostdiek","(Machine) learning to do more with less",2017,"","","","",25,"2022-07-13 09:25:19","","10.1007/JHEP02(2018)034","","",,,,,71,14.20,24,3,5,"","",""
5,"Tom Z. Jiahao, M. Hsieh, E. Forgoston","Knowledge-based learning of nonlinear dynamics and chaos",2020,"","","","",26,"2022-07-13 09:25:19","","10.1063/5.0065617","","",,,,,5,2.50,2,3,2,"Extracting predictive models from nonlinear systems is a central task in scientific machine learning. One key problem is the reconciliation between modern data-driven approaches and first principles. Despite rapid advances in machine learning techniques, embedding domain knowledge into datadriven models remains a challenge. In this work, we present a universal learning framework for extracting predictive models from nonlinear systems based on observations. Our framework can readily incorporate first principle knowledge because it naturally models nonlinear systems as continuous-time systems. This both improves the extracted models’ extrapolation power and reduces the amount of data needed for training. In addition, our framework has the advantages of robustness to observational noise and applicability to irregularly sampled data. We demonstrate the effectiveness of our scheme by learning predictive models for a wide variety of systems including a stiff Van der Pol oscillator, the Lorenz system, and the Kuramoto-Sivashinsky equation. For the Lorenz system, different types of domain knowledge are incorporated to demonstrate the strength of knowledge embedding in data-driven system identification.","",""
54,"M. S. Hossain Lipu, M. Hannan, A. Hussain, M. Saad, A. Ayob, M. Uddin","Extreme Learning Machine Model for State-of-Charge Estimation of Lithium-Ion Battery Using Gravitational Search Algorithm",2019,"","","","",27,"2022-07-13 09:25:19","","10.1109/TIA.2019.2902532","","",,,,,54,18.00,9,6,3,"This paper develops a state-of-charge (SOC) estimation model for a lithium-ion battery using an improved extreme learning machine (ELM) algorithm. ELM is suitable for an SOC estimation since the ELM algorithm has fast estimation speed, good generalization performance, and high accuracy. However, the performance of ELM is highly dependent on training accuracy and the number of neurons in a hidden layer. Hence, a gravitational search algorithm (GSA) is applied to improve the ELM computational intelligence by searching for the optimal value hidden layer neurons. The optimal ELM-based GSA model does not require internal battery knowledge and mathematical model for an SOC estimation. The model robustness is validated at different temperatures using different electric vehicle drive cycles. The performance of the ELM-GSA model is verified with two popular neural network methods: back-propagation neural network (BPNN) and radial basis function neural network (RBFNN). The results are evaluated using different error rates and computation costs. The results demonstrate that the ELM-based GSA model offers a higher accuracy and lower SOC error rate than those of BPNN-based GSA and RBFNN-based GSA models. Furthermore, a detailed comparative study between the proposed model and existing SOC strategies is conducted, which also demonstrates the superiority of the proposed model.","",""
2,"Lukas Hahn, Lutz Roese-Koerner, P. Cremer, Urs Zimmermann, Ori Maoz, A. Kummert","On the Robustness of Active Learning",2019,"","","","",28,"2022-07-13 09:25:19","","10.29007/thws","","",,,,,2,0.67,0,6,3,"Active Learning is concerned with the question of how to identify the most useful samples for a Machine Learning algorithm to be trained with. When applied correctly, it can be a very powerful tool to counteract the immense data requirements of Artificial Neural Networks. However, we find that it is often applied with not enough care and domain knowledge. As a consequence, unrealistic hopes are raised and transfer of the experimental results from one dataset to another becomes unnecessarily hard.  In this work we analyse the robustness of different Active Learning methods with respect to classifier capacity, exchangeability and type, as well as hyperparameters and falsely labelled data. Experiments reveal possible biases towards the architecture used for sample selection, resulting in suboptimal performance for other classifiers. We further propose the new ""Sum of Squared Logits"" method based on the Simpson diversity index and investigate the effect of using the confusion matrix for balancing in sample selection.","",""
8,"Hal S. Greenwald, Carsten K. Oertel","Future Directions in Machine Learning",2017,"","","","",29,"2022-07-13 09:25:19","","10.3389/frobt.2016.00079","","",,,,,8,1.60,4,2,5,"Current machine learning algorithms identify statistical regularities in complex data sets and are regularly used across a range of application domains, but they lack the robustness and generalizability associated with human learning. If machine learning techniques could enable computers to learn from fewer examples, transfer knowledge between tasks, and adapt to changing contexts and environments, the results would have very broad scientific and societal impacts. Increased processing and memory resources have enabled larger, more capable learning models, but there is growing recognition that even greater computing resources would not be sufficient to yield algorithms capable of learning from a few examples and generalizing beyond initial training sets. This paper presents perspectives on feature selection, representation schemes and interpretability, transfer learning, continuous learning, and learning and adaptation in time-varying contexts and environments, five key areas that are essential for advancing machine learning capabilities. Appropriate learning tasks that require these capabilities can demonstrate the strengths of novel machine learning approaches that could address these challenges.","",""
4,"Donglin Jiang, Chen Shan, Zhihui Zhang","Federated Learning Algorithm Based on Knowledge Distillation",2020,"","","","",30,"2022-07-13 09:25:19","","10.1109/ICAICE51518.2020.00038","","",,,,,4,2.00,1,3,2,"Federated learning is a new scheme of distributed machine learning, which enables a large number of edge computing devices to jointly learn a shared model without private data sharing. Federated learning allows nodes to synchronize only the locally trained models instead of their own private data, which provides a guarantee for privacy and security. However, due to the challenges of heterogeneity in federated learning, which are: (1) heterogeneous model architecture among devices; (2) statistical heterogeneity in real federated dataset, which do not obey independent-identical-distribution, resulting in poor performance of traditional federated learning algorithms. To solve the problems above, this paper proposes FedDistill, a new distributed training method based on knowledge distillation. By introducing personalized model on each device, the personalized model aims to improve the local performance even in a situation that global model fails to adapt to the local dataset, thereby improving the ability and robustness of the global model. The improvement of the performance of local device benefits from the effect of knowledge distillation, which can guide the improvement of global model by knowledge transfer between heterogeneous networks. Experiments show that FedDistill can significantly improve the accuracy of classification tasks and meet the needs of heterogeneous users.","",""
13,"Zhifang Liang, Ci Zhang, Hao Sun, An Song, Tao Liu","Improving the Robustness of Prediction Model by Transfer Learning for Interference Suppression of Electronic Nose",2018,"","","","",31,"2022-07-13 09:25:19","","10.1109/JSEN.2017.2778012","","",,,,,13,3.25,3,5,4,"This paper gives a solution to solve the interference problem of electronic nose (e-nose), which is ill-posed due to the uncertainty and unpredictability of its instable behavior. Traditional methods for interference suppression are component correction frameworks, which are laborious or little efficient. With interference (especially background interference and sensor drift), the distribution of test data obtained in practical application is different from that of the previous training data. From the viewpoint of machine learning, a novel domain correction and adaptive extreme learning machines (DC-AELM) framework with transferring capability is proposed to solve the serious interference problem in e-nose. The framework consists of two parts: 1) DC, which makes the distributions of two domains close and 2) AELM, which realizes the knowledge transfer at the decision level and makes the robustness of the prediction model improved. This method is motivated by the idea of transfer learning, especially from the perspective of domain correction and decision-making, to realize the knowledge transfer for interference suppression. A background interference data set obtained by our designed e-nose and a public benchmark sensor drift data set are used to verify the effectiveness of the proposed DC-AELM method.","",""
3,"Sergio Jiménez Celorrio, F. Fernández, D. Borrajo","Machine Learning of Plan Robustness Knowledge About Instances",2005,"","","","",32,"2022-07-13 09:25:19","","10.1007/11564096_60","","",,,,,3,0.18,1,3,17,"","",""
15,"Stien Heremans, J. Van Orshoven","Machine learning methods for sub-pixel land-cover classification in the spatially heterogeneous region of Flanders (Belgium): a multi-criteria comparison",2015,"","","","",33,"2022-07-13 09:25:19","","10.1080/01431161.2015.1054047","","",,,,,15,2.14,8,2,7,"Until now, few research has addressed the use of machine learning methods for classification at the sub-pixel level. To close this knowledge gap, in this article, six machine learning methods were compared for the specific task of sub-pixel land-cover extraction in the spatially heterogeneous region of Flanders (Belgium). In addition to the classification accuracy at the pixel and the municipality level, three evaluation criteria reflecting the methods’ ease-of-use were added to the comparison: the time needed for training, the number of meta-parameters, and the minimum training set size. Robustness to changing training data was also included as the sixth evaluation criterion. Based on their scores for these six criteria, the machine learning methods were ranked according to three multi-criteria ranking scenarios. These ranking scenarios correspond to different decision-making scenarios that differ in their weighting of the criteria. In general, no overall winner could be designated: no method performs best for all evaluation scenarios. However, when both time available for preprocessing and the magnitude of the training data set are unconstrained, Support Vector Machines (SVMs) clearly outperform the other methods.","",""
39,"Krishnamurthy Dvijotham, Jamie Hayes, Borja Balle, J. Z. Kolter, Chongli Qin, A. György, Kai Y. Xiao, Sven Gowal, Pushmeet Kohli","A Framework for robustness Certification of Smoothed Classifiers using F-Divergences",2020,"","","","",34,"2022-07-13 09:25:19","","","","",,,,,39,19.50,4,9,2,"Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far requires knowledge of the architecture of the machine learning model and remains hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using $f$-divergences. Our methodology achieves state-of-the-art}certified robustness on MNIST, CIFAR-10 and ImageNet and also audio classification task, Librispeech, with respect to several classes of adversarial perturbations.","",""
17,"V. Mir, evská, M. Luštrek, M. Gams","Combining machine learning and expert knowledge for classifying human posture",2009,"","","","",35,"2022-07-13 09:25:19","","","","",,,,,17,1.31,4,4,13,"This paper presents a rule engine for classifying h uman posture according to information about the location f body parts. The rule engine was developed by enrich i g decision trees with expert knowledge. Results show 5 percentage points improvement in accuracy compared to support vector machines and a significant 11 percentage points compared to decision trees. The incorporation of expert knowledge overcomes the problem of classifier over-fitting observed with classifiers induced with machine learning. Better robustness of the posture classification rule engin e is expected in real-life tests in comparison to classi fiers induced with machine learning.","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",36,"2022-07-13 09:25:19","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
4,"Blanca Rodríguez, Óscar Pérez, Jesús García, J. M. Molina","MACHINE LEARNING TECHNIQUES FOR ACQUIRING NEW KNOWLEDGE IN IMAGE TRACKING",2008,"","","","",37,"2022-07-13 09:25:19","","10.1080/08839510701821652","","",,,,,4,0.29,1,4,14,"The purpose of this research is to apply data mining (DM) to an optimized surveillance video system with the objective of improving tracking robustness and stability. Specifically, the machine learning has been applied to blob extraction and detection, in order to decide whether a detected blob corresponds to a real target or not. Performance is assessed with an Evaluation function, which has been developed for optimizing the video surveillance system. This Evaluation function measures the quality level reached by the tracking system.","",""
15,"Ali Hürriyetoǧlu, Erdem Yörük, Osman Mutlu, Fırat Duruşan, Çağrı Yoltar, Deniz Yüret, Burak Gürel","Cross-Context News Corpus for Protest Event-Related Knowledge Base Construction",2021,"","","","",38,"2022-07-13 09:25:19","","10.1162/dint_a_00092","","",,,,,15,15.00,2,7,1,"Abstract We describe a gold standard corpus of protest events that comprise various local and international English language sources from various countries. The corpus contains document-, sentence-, and token-level annotations. This corpus facilitates creating machine learning models that automatically classify news articles and extract protest event-related information, constructing knowledge bases that enable comparative social and political science studies. For each news source, the annotation starts with random samples of news articles and continues with samples drawn using active learning. Each batch of samples is annotated by two social and political scientists, adjudicated by an annotation supervisor, and improved by identifying annotation errors semi-automatically. We found that the corpus possesses the variety and quality that are necessary to develop and benchmark text classification and event extraction systems in a cross-context setting, contributing to the generalizability and robustness of automated text processing systems. This corpus and the reported results will establish a common foundation in automated protest event collection studies, which is currently lacking in the literature.","",""
10,"Sharif Amit Kamran, A. Tavakkoli, S. Zuckerbrod","Improving Robustness Using Joint Attention Network for Detecting Retinal Degeneration From Optical Coherence Tomography Images",2020,"","","","",39,"2022-07-13 09:25:19","","10.1109/ICIP40778.2020.9190742","","",,,,,10,5.00,3,3,2,"Noisy data and the similarity in the ocular appearances caused by different ophthalmic pathologies pose significant challenges for an automated expert system to accurately detect retinal diseases. In addition, the lack of knowledge transferability and the need for unreasonably large datasets limit clinical application of current machine learning systems. To increase robustness, a better understanding of how the retinal subspace deformations lead to various levels of disease severity needs to be utilized for prioritizing disease-specific model details. In this paper we propose the use of disease-specific feature representation as a novel architecture comprised of two joint networks - one for supervised encoding of disease model and the other for producing attention maps in an unsupervised manner to retain disease specific spatial information. Our experimental results on publicly available datasets show the proposed joint-network significantly improves the accuracy and robustness of state-of-the-art retinal disease classification networks on unseen datasets.","",""
13,"Cong T. Nguyen, Nguyen Van Huynh, Nam H. Chu, Y. Saputra, D. Hoang, Diep N. Nguyen, Quoc-Viet Pham, D. Niyato, E. Dutkiewicz, W. Hwang","Transfer Learning for Future Wireless Networks: A Comprehensive Survey",2021,"","","","",40,"2022-07-13 09:25:19","","","","",,,,,13,13.00,1,10,1,"With outstanding features, Machine Learning (ML) has become the backbone of numerous applications in wireless networks. However, the conventional ML approaches face many challenges in practical implementation, such as the lack of labeled data, the constantly changing wireless environments, the long training process, and the limited capacity of wireless devices. These challenges, if not addressed, can impede the effectiveness and applicability of ML in wireless networks. To address these problems, Transfer Learning (TL) has recently emerged to be a promising solution. The core idea of TL is to leverage and synthesize distilled knowledge from similar tasks as well as from valuable experiences accumulated from the past to facilitate the learning of new problems. Doing so, TL techniques can reduce the dependence on labeled data, improve the learning speed, and enhance the ML methods’ robustness to different wireless environments. This article aims to provide a comprehensive survey on applications of TL in wireless networks. Particularly, we first provide an overview of TL including formal definitions, classification, and various types of TL techniques. We then discuss diverse TL approaches proposed to address emerging issues in wireless networks. The issues include spectrum management, localization, signal recognition, security, human activity recognition and caching, which are all important to nextgeneration networks such as 5G and beyond. Finally, we highlight important challenges, open issues, and future research directions of TL in future wireless networks.","",""
55,"Zan Gao, Yinming Li, S. Wan","Exploring Deep Learning for View-Based 3D Model Retrieval",2020,"","","","",41,"2022-07-13 09:25:19","","10.1145/3377876","","",,,,,55,27.50,18,3,2,"In recent years, view-based 3D model retrieval has become one of the research focuses in the field of computer vision and machine learning. In fact, the 3D model retrieval algorithm consists of feature extraction and similarity measurement, and the robust features play a decisive role in the similarity measurement. Although deep learning has achieved comprehensive success in the field of computer vision, deep learning features are used for 3D model retrieval only in a small number of works. To the best of our knowledge, there is no benchmark to evaluate these deep learning features. To tackle this problem, in this work we systematically evaluate the performance of deep learning features in view-based 3D model retrieval on four popular datasets (ETH, NTU60, PSB, and MVRED) by different kinds of similarity measure methods. In detail, the performance of hand-crafted features and deep learning features are compared, and then the robustness of deep learning features is assessed. Finally, the difference between single-view deep learning features and multi-view deep learning features is also evaluated. By quantitatively analyzing the performances on different datasets, it is clear that these deep learning features can consistently outperform all of the hand-crafted features, and they are also more robust than the hand-crafted features when different degrees of noise are added into the image. The exploration of latent relationships among different views in multi-view deep learning network architectures shows that the performance of multi-view deep learning outperforms that of single-view deep learning features with low computational complexity.","",""
28,"Pouya Pezeshkpour, Yifan Tian, Sameer Singh","Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications",2018,"","","","",42,"2022-07-13 09:25:19","","10.18653/v1/N19-1337","","",,,,,28,7.00,9,3,4,"Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on improving accuracy and overlook other aspects such as robustness and interpretability. In this paper, we propose adversarial modifications for link prediction models: identifying the fact to add into or remove from the knowledge graph that changes the prediction for a target fact after the model is retrained. Using these single modifications of the graph, we identify the most influential fact for a predicted link and evaluate the sensitivity of the model to the addition of fake facts. We introduce an efficient approach to estimate the effect of such modifications by approximating the change in the embeddings when the knowledge graph changes. To avoid the combinatorial search over all possible facts, we train a network to decode embeddings to their corresponding graph components, allowing the use of gradient-based optimization to identify the adversarial modification. We use these techniques to evaluate the robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability through the facts most responsible for predictions (by identifying the most influential neighbors), and detect incorrect facts in the knowledge base.","",""
5,"S. S. Rodríguez, C. Mascolo, Young D. Kwon","Knowing when we do not know: Bayesian continual learning for sensing-based analysis tasks",2021,"","","","",43,"2022-07-13 09:25:19","","","","",,,,,5,5.00,2,3,1,"Despite much research targeted at enabling conventional machine learning models to continually learn tasks and data distributions sequentially without forgetting the knowledge acquired, little effort has been devoted to account for more realistic situations where learning some tasks accurately might be more critical than forgetting previous ones. In this paper we propose a Bayesian inference based framework to continually learn a set of real-world, sensing-based analysis tasks that can be tuned to prioritize the remembering of previously learned tasks or the learning of new ones. Our experiments prove the robustness and reliability of the learned models to adapt to the changing sensing environment, and show the suitability of using uncertainty of the predictions to assess their reliability.","",""
5,"S. Hamida, Oussama El Gannour, B. Cherradi, A. Raihani, H. Moujahid, H. Ouajji","A Novel COVID-19 Diagnosis Support System Using the Stacking Approach and Transfer Learning Technique on Chest X-Ray Images",2021,"","","","",44,"2022-07-13 09:25:19","","10.1155/2021/9437538","","",,,,,5,5.00,1,6,1,"COVID-19 is an infectious disease-causing flu-like respiratory problem with various symptoms such as cough or fever, which in severe cases can cause pneumonia. The aim of this paper is to develop a rapid and accurate medical diagnosis support system to detect COVID-19 in chest X-ray images using a stacking approach combining transfer learning techniques and KNN algorithm for selection of the best model. In deep learning, we have multiple approaches for building a classification system for analyzing radiographic images. In this work, we used the transfer learning technique. This approach makes it possible to store and use the knowledge acquired from a pretrained convolutional neural network to solve a new problem. To ensure the robustness of the proposed system for diagnosing patients with COVID-19 using X-ray images, we used a machine learning method called the stacking approach to combine the performances of the many transfer learning-based models. The generated model was trained on a dataset containing four classes, namely, COVID-19, tuberculosis, viral pneumonia, and normal cases. The dataset used was collected from a six-source dataset of X-ray images. To evaluate the performance of the proposed system, we used different common evaluation measures. Our proposed system achieves an extremely good accuracy of 99.23% exceeding many previous related studies.","",""
4,"Henriette Violante","Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications",2019,"","","","",45,"2022-07-13 09:25:19","","","","",,,,,4,1.33,4,1,3,"Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on improving accuracy and overlook other aspects of knowledge base representations, such as robustness and interpretability. In this paper, we propose adversarial modifications for link prediction models: identifying the fact to add into or remove from the knowledge graph that changes the prediction for a target fact after the model is retrained. Using these single modifications of the graph, we are able to identify the most influential fact for a predicted link and evaluate the sensitivity of the model to the addition of fake facts. We introduce an efficient approach to estimate the effect of such modifications by approximating the change in the embeddings when the knowledge graph changes. To avoid the combinatorial search over all possible facts, we train a network to decode embeddings to their corresponding graph components, allowing the use of gradient-based optimization to identify the adversarial modification. We use these techniques to evaluate the robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability through the facts most responsible for predictions (by identifying the most influential neighbors), and detect incorrect facts in the knowledge base.","",""
4,"Wei Huang, Xingyu Zhao, Xiaowei Huang","Embedding and extraction of knowledge in tree ensemble classifiers",2020,"","","","",46,"2022-07-13 09:25:19","","10.1007/s10994-021-06068-6","","",,,,,4,2.00,1,3,2,"","",""
13,"Makhamisa Senekane","Differentially Private Image Classification Using Support Vector Machine and Differential Privacy",2019,"","","","",47,"2022-07-13 09:25:19","","10.3390/MAKE1010029","","",,,,,13,4.33,13,1,3,"The ubiquity of data, including multi-media data such as images, enables easy mining and analysis of such data. However, such an analysis might involve the use of sensitive data such as medical records (including radiological images) and financial records. Privacy-preserving machine learning is an approach that is aimed at the analysis of such data in such a way that privacy is not compromised. There are various privacy-preserving data analysis approaches such as k-anonymity, l-diversity, t-closeness and Differential Privacy (DP). Currently, DP is a golden standard of privacy-preserving data analysis due to its robustness against background knowledge attacks. In this paper, we report a scheme for privacy-preserving image classification using Support Vector Machine (SVM) and DP. SVM is chosen as a classification algorithm because unlike variants of artificial neural networks, it converges to a global optimum. SVM kernels used are linear and Radial Basis Function (RBF), while ϵ -differential privacy was the DP framework used. The proposed scheme achieved an accuracy of up to 98%. The results obtained underline the utility of using SVM and DP for privacy-preserving image classification.","",""
46,"F. Neri","Agent-based modeling under partial and full knowledge learning settings to simulate financial markets",2012,"","","","",48,"2022-07-13 09:25:19","","10.3233/AIC-2012-0537","","",,,,,46,4.60,46,1,10,"In the paper we show how L-FABS can be applied in a partial knowledge learning scenario or a full knowledge learning scenario to approximate financial time series. L-FABS combines agent-based simulation with machine learning to model the behavior of financial time series.We also discuss why Partial Knowledge and Full Knowledge learning scenario are relevant to the modeling of financial time series and how they can be used to assess the robustness of a modeling system for financial time series. In a Partial Knowledge learning setting usually only the initial conditions of the time series are provided, while in a Full Knowledge learning scenario any value of the financial time series is exploited as soon as it is available.An extensive experimental analysis of L-FABS is reported under a variety of financial time series and time frames.","",""
55,"He Fang, Xianbin Wang, L. Hanzo","Learning-Aided Physical Layer Authentication as an Intelligent Process",2018,"","","","",49,"2022-07-13 09:25:19","","10.1109/TCOMM.2018.2881117","","",,,,,55,13.75,18,3,4,"Performance of the existing physical layer authentication schemes could be severely affected by the imperfect estimates and variations of the communication link attributes used. The commonly adopted static hypothesis testing for physical layer authentication faces significant challenges in time-varying communication channels due to the changing propagation and interference conditions, which are typically unknown at the design stage. To circumvent this impediment, we propose an adaptive physical layer authentication scheme based on machine-learning as an intelligent process to learn and utilize the complex time-varying environment, and hence to improve the reliability and robustness of physical layer authentication. Explicitly, a physical layer attribute fusion model based on a kernel machine is designed for dealing with multiple attributes without requiring the knowledge of their statistical properties. By modeling the physical layer authentication as a linear system, the proposed technique directly reduces the authentication scope from a combined  $N$ -dimensional feature space to a single-dimensional (scalar) space, hence leading to reduced authentication complexity. By formulating the learning (training) objective of the physical layer authentication as a convex problem, an adaptive algorithm based on kernel least mean square is then proposed as an intelligent process to learn and track the variations of multiple attributes, and therefore to enhance the authentication performance. Both the convergence and the authentication performance of the proposed intelligent authentication process are theoretically analyzed. Our simulations demonstrate that our solution significantly improves the authentication performance in time-varying environments.","",""
10,"Zheyan Shen, Peng Cui, Jiashuo Liu, Tong Zhang, Bo Li, Zhitang Chen","Stable Learning via Differentiated Variable Decorrelation",2020,"","","","",50,"2022-07-13 09:25:19","","10.1145/3394486.3403269","","",,,,,10,5.00,2,6,2,"Recently, as the applications of artificial intelligence gradually seeping into some risk-sensitive areas such as justice, healthcare and autonomous driving, an upsurge of research interest on model stability and robustness has arisen in the field of machine learning. Rather than purely fitting the observed training data, stable learning tries to learn a model with uniformly good performance under non-stationary and agnostic testing data. The key challenge of stable learning in practice is that we do not have any knowledge about the true model and test data distribution as a priori. Under such condition, we cannot expect a faithful estimation of model parameters and its stability over wild changing environments. Previous methods resort to a reweighting scheme to remove the correlations between all the variables through a set of new sample weights. However, we argue that such aggressive decorrelation between all the variables may cause the over-reduced sample size, which leads to the variance inflation and possible underperformance. In this paper, we incorporate the unlabled data from multiple environments into the variable decorrelation framework and propose a Differentiated Variable Decorrelation (DVD) algorithm based on the clustering of variables. Specifically, the variables are clustered according to the stability of their correlations and the variable decorrelation module learns a set of sample weights to remove the correlations merely between the variables of different clusters. Empirical studies on both synthetic and real world datasets clearly demonstrate the efficacy of our DVD algorithm on improving the model parameter estimation and the prediction stability over changing distributions.","",""
11,"Anirudh Som, Hongjun Choi, K. Ramamurthy, M. Buman, P. Turaga","PI-Net: A Deep Learning Approach to Extract Topological Persistence Images",2019,"","","","",51,"2022-07-13 09:25:19","","10.1109/CVPRW50498.2020.00425","","",,,,,11,3.67,2,5,3,"Topological features such as persistence diagrams and their functional approximations like persistence images (PIs) have been showing substantial promise for machine learning and computer vision applications. This is greatly attributed to the robustness topological representations provide against different types of physical nuisance variables seen in real-world data, such as view-point, illumination, and more. However, key bottlenecks to their large scale adoption are computational expenditure and difficulty incorporating them in a differentiable architecture. We take an important step in this paper to mitigate these bottlenecks by proposing a novel one-step approach to generate PIs directly from the input data. We design two separate convolutional neural network architectures, one designed to take in multi-variate time series signals as input and another that accepts multi-channel images as input. We call these networks Signal PI-Net and Image PI- Net respectively. To the best of our knowledge, we are the first to propose the use of deep learning for computing topological features directly from data. We explore the use of the proposed PI-Net architectures on two applications: human activity recognition using tri-axial accelerometer sensor data and image classification. We demonstrate the ease of fusion of PIs in supervised deep learning architectures and speed up of several orders of magnitude for extracting PIs from data. Our code is available at https://github.com/anirudhsom/PI-Net.","",""
8,"Ali Hürriyetoǧlu, Erdem Yörük, Deniz Yuret, Osman Mutlu, Çağrı Yoltar, Fırat Duruşan, Burak Gürel","Cross-context News Corpus for Protest Events related Knowledge Base Construction",2020,"","","","",52,"2022-07-13 09:25:19","","10.24432/C5D59R","","",,,,,8,4.00,1,7,2,"We describe a gold standard corpus of protest events that comprise of various local and international sources from various countries in English. The corpus contains document, sentence, and token level annotations. This corpus facilitates creating machine learning models that automatically classify news articles and extract protest event related information, constructing databases which enable comparative social and political science studies. For each news source, the annotation starts on random samples of news articles and continues with samples that are drawn using active learning. Each batch of samples was annotated by two social and political scientists, adjudicated by an annotation supervisor, and was improved by identifying annotation errors semi-automatically. We found that the corpus has the variety and quality to develop and benchmark text classification and event extraction systems in a cross-context setting, which contributes to generalizability and robustness of automated text processing systems. This corpus and the reported results will set the currently lacking common ground in automated protest event collection studies.","",""
325,"Jiwen Lu, Venice Erin Liong, Xiuzhuang Zhou, Jie Zhou","Learning Compact Binary Face Descriptor for Face Recognition",2015,"","","","",53,"2022-07-13 09:25:19","","10.1109/TPAMI.2015.2408359","","",,,,,325,46.43,81,4,7,"Binary feature descriptors such as local binary patterns (LBP) and its variations have been widely used in many face recognition systems due to their excellent robustness and strong discriminative power. However, most existing binary face descriptors are hand-crafted, which require strong prior knowledge to engineer them by hand. In this paper, we propose a compact binary face descriptor (CBFD) feature learning method for face representation and recognition. Given each face image, we first extract pixel difference vectors (PDVs) in local patches by computing the difference between each pixel and its neighboring pixels. Then, we learn a feature mapping to project these pixel difference vectors into low-dimensional binary vectors in an unsupervised manner, where 1) the variance of all binary codes in the training set is maximized, 2) the loss between the original real-valued codes and the learned binary codes is minimized, and 3) binary codes evenly distribute at each learned bin, so that the redundancy information in PDVs is removed and compact binary codes are obtained. Lastly, we cluster and pool these binary codes into a histogram feature as the final representation for each face image. Moreover, we propose a coupled CBFD (C-CBFD) method by reducing the modality gap of heterogeneous faces at the feature level to make our method applicable to heterogeneous face recognition. Extensive experimental results on five widely used face datasets show that our methods outperform state-of-the-art face descriptors.","",""
8,"A. Mitrokhin, P. Sutor, Douglas Summers-Stay, C. Fermüller, Y. Aloimonos","Symbolic Representation and Learning With Hyperdimensional Computing",2020,"","","","",54,"2022-07-13 09:25:19","","10.3389/frobt.2020.00063","","",,,,,8,4.00,2,5,2,"It has been proposed that machine learning techniques can benefit from symbolic representations and reasoning systems. We describe a method in which the two can be combined in a natural and direct way by use of hyperdimensional vectors and hyperdimensional computing. By using hashing neural networks to produce binary vector representations of images, we show how hyperdimensional vectors can be constructed such that vector-symbolic inference arises naturally out of their output. We design the Hyperdimensional Inference Layer (HIL) to facilitate this process and evaluate its performance compared to baseline hashing networks. In addition to this, we show that separate network outputs can directly be fused at the vector symbolic level within HILs to improve performance and robustness of the overall model. Furthermore, to the best of our knowledge, this is the first instance in which meaningful hyperdimensional representations of images are created on real data, while still maintaining hyperdimensionality.","",""
6,"A. Ulhaq, O. Burmeister","COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework",2020,"","","","",55,"2022-07-13 09:25:19","","","","",,,,,6,3.00,3,2,2,"To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data. In this paper, we introduce differential privacy by design (dPbD) framework and discuss its embedding into the federated machine learning system. To limit the scope of our paper, we focus on the problem scenario of COVID-19 imaging data privacy for disease diagnosis by computer vision and deep learning approaches. We discuss the evaluation of the proposed design of federated machine learning systems and discuss how differential privacy by design (dPbD) framework can enhance data privacy in federated learning systems with scalability and robustness. We argue that scalable differentially private federated learning design is a promising solution for building a secure, private and collaborative machine learning model such as required to combat COVID19 challenge.","",""
24,"Sanaz Nikfalazar, C. Yeh, S. Bedingfield, H. Khorshidi","Missing data imputation using decision trees and fuzzy clustering with iterative learning",2019,"","","","",56,"2022-07-13 09:25:19","","10.1007/s10115-019-01427-1","","",,,,,24,8.00,6,4,3,"","",""
8,"Yadan Luo, Zi Huang, Zheng Zhang, Ziwei Wang, Mahsa Baktashmotlagh, Yang Yang","Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks",2020,"","","","",57,"2022-07-13 09:25:19","","10.1609/AAAI.V34I04.5942","","",,,,,8,4.00,1,6,2,"Meta-learning for few-shot learning allows a machine to leverage previously acquired knowledge as a prior, thus improving the performance on novel tasks with only small amounts of data. However, most mainstream models suffer from catastrophic forgetting and insufficient robustness issues, thereby failing to fully retain or exploit long-term knowledge while being prone to cause severe error accumulation. In this paper, we propose a novel Continual Meta-Learning approach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically formulates meta-learning as continual learning of a sequence of tasks. With each task forming as a graph, the intra- and inter-task correlations can be well preserved via message-passing and history transition. To remedy topological uncertainty from graph initialization, we utilize Bayes by Backprop strategy that approximates the posterior distribution of task-specific parameters with amortized inference networks, which are seamlessly integrated into the end-to-end edge learning. Extensive experiments conducted on the miniImageNet and tieredImageNet datasets demonstrate the effectiveness and efficiency of the proposed method, improving the performance by 42.8% compared with state-of-the-art on the miniImageNet 5-way 1-shot classification task.","",""
4,"Guanyu Tian, Qun Zhou, Rahul Birari, Junjian Qi, Z. Qu","A Hybrid-Learning Algorithm for Online Dynamic State Estimation in Multimachine Power Systems",2020,"","","","",58,"2022-07-13 09:25:19","","10.1109/TNNLS.2020.2968486","","",,,,,4,2.00,1,5,2,"With the increasing penetration of distributed generators in the smart grids, having knowledge of rapid real-time electromechanical dynamic states has become crucial to system stability control. Conventional Supervisory Control and Data Acquisition (SCADA)-based dynamic state estimation (DSE) techniques are limited by the slow sampling rates, while the emerging phasor measurement units (PMUs) technology enables rapid real-time measurements at network nodes. Using generator bus terminal voltages, we propose a hybrid-learning DSE (HL-DSE) algorithm to estimate the synchronous machine rotor angle and speed in real time. The HL-DSE takes the power system model into account and trains neuroestimators with real-time data in an online manner. Compared with traditional DSE methods, the HL-DSE overcomes limitations by using a data-driven approach in conjunction with the physical power system model. The time efficiency, accuracy, convergence, and robustness of the proposed algorithm are tested under noises and fault conditions in both small- and large-scale test systems. Simulation results show that the proposed HL-DSE is much more computationally efficient than widely used Kalman filter (KF)-based methods while maintaining comparable accuracy and robustness. In particular, HL-DSE is over 100 times faster than square-root unscented KF (SR-UKF) and 80 times faster than extended KF (EKF). The advantages and challenges of the HL-DSE are also discussed.","",""
5,"Y. Hsu, Zining Zhu, Chi-Te Wang, Shih-Hau Fang, F. Rudzicz, Yu Tsao","Robustness against the channel effect in pathological voice detection",2018,"","","","",59,"2022-07-13 09:25:19","","","","",,,,,5,1.25,1,6,4,"Many people are suffering from voice disorders, which can adversely affect the quality of their lives. In response, some researchers have proposed algorithms for automatic assessment of these disorders, based on voice signals. However, these signals can be sensitive to the recording devices. Indeed, the channel effect is a pervasive problem in machine learning for healthcare. In this study, we propose a detection system for pathological voice, which is robust against the channel effect. This system is based on a bidirectional LSTM network. To increase the performance robustness against channel mismatch, we integrate domain adversarial training (DAT) to eliminate the differences between the devices. When we train on data recorded on a high-quality microphone and evaluate on smartphone data without labels, our robust detection system increases the PR-AUC from 0.8448 to 0.9455 (and 0.9522 with target sample labels). To the best of our knowledge, this is the first study applying unsupervised domain adaptation to pathological voice detection. Notably, our system does not need target device sample labels, which allows for generalization to many new devices.","",""
13,"A. Naimi, Edward H. Kennedy","Nonparametric Double Robustness",2017,"","","","",60,"2022-07-13 09:25:19","","","","",,,,,13,2.60,7,2,5,"Use of nonparametric techniques (e.g., machine learning, kernel smoothing, stacking) are increasingly appealing because they do not require precise knowledge of the true underlying models that generated the data under study. Indeed, numerous authors have advocated for their use with standard methods (e.g., regression, inverse probability weighting) in epidemiology. However, when used in the context of such singly robust approaches, nonparametric methods can lead to suboptimal statistical properties, including inefficiency and no valid confidence intervals. Using extensive Monte Carlo simulations, we show how doubly robust methods offer improvements over singly robust approaches when implemented via nonparametric methods. We use 10,000 simulated samples and 50, 100, 200, 600, and 1200 observations to investigate the bias and mean squared error of singly robust (g Computation, inverse probability weighting) and doubly robust (augmented inverse probability weighting, targeted maximum likelihood estimation) estimators under four scenarios: correct and incorrect model specification; and parametric and nonparametric estimation. As expected, results show best performance with g computation under correctly specified parametric models. However, even when based on complex transformed covariates, double robust estimation performs better than singly robust estimators when nonparametric methods are used. Our results suggest that nonparametric methods should be used with doubly instead of singly robust estimation techniques.","",""
8,"Ingo Glöckner, Björn Pelzer","Combining Logic and Machine Learning for Answering Questions",2008,"","","","",61,"2022-07-13 09:25:19","","10.1007/978-3-642-04447-2_47","","",,,,,8,0.57,4,2,14,"","",""
10,"Vaishak Belle, Brendan A. Juba","Implicitly Learning to Reason in First-Order Logic",2019,"","","","",62,"2022-07-13 09:25:19","","","","",,,,,10,3.33,5,2,3,"We consider the problem of answering queries about formulas of first-order logic based on background knowledge partially represented explicitly as other formulas, and partially represented as examples independently drawn from a fixed probability distribution. PAC semantics, introduced by Valiant, is one rigorous, general proposal for learning to reason in formal languages: although weaker than classical entailment, it allows for a powerful model theoretic framework for answering queries while requiring minimal assumptions about the form of the distribution in question. To date, however, the most significant limitation of that approach, and more generally most machine learning approaches with robustness guarantees, is that the logical language is ultimately essentially propositional, with finitely many atoms. Indeed, the theoretical findings on the learning of relational theories in such generality have been resoundingly negative. This is despite the fact that first-order logic is widely argued to be most appropriate for representing human knowledge. In this work, we present a new theoretical approach to robustly learning to reason in first-order logic, and consider universally quantified clauses over a countably infinite domain. Our results exploit symmetries exhibited by constants in the language, and generalize the notion of implicit learnability to show how queries can be computed against (implicitly) learned first-order background knowledge.","",""
9,"Yadan Luo, Zi-Yu Huang, Zheng Zhang, Ziwei Wang, Mahsa Baktash, Yang Yang","Learning from the Past: Continual Meta-Learning via Bayesian Graph Modeling",2019,"","","","",63,"2022-07-13 09:25:19","","","","",,,,,9,3.00,2,6,3,"Meta-learning for few-shot learning allows a machine to leverage previously acquired knowledge as a prior, thus improving the performance on novel tasks with only small amounts of data. However, most mainstream models suffer from catastrophic forgetting and insufficient robustness issues, thereby failing to fully retain or exploit long-term knowledge while being prone to cause severe error accumulation. In this paper, we propose a novel Continual Meta-Learning approach with Bayesian Graph Neural Networks (CML-BGNN) that mathematically formulates meta-learning as continual learning of a sequence of tasks. With each task forming as a graph, the intra- and inter-task correlations can be well preserved via message-passing and history transition. To remedy topological uncertainty from graph initialization, we utilize Bayes by Backprop strategy that approximates the posterior distribution of task-specific parameters with amortized inference networks, which are seamlessly integrated into the end-to-end edge learning. Extensive experiments conducted on the miniImageNet and tieredImageNet datasets demonstrate the effectiveness and efficiency of the proposed method, improving the performance by 42.8% compared with state-of-the-art on the miniImageNet 5-way 1-shot classification task.","",""
4,"Antonios Karatzoglou, M. Beigl","Semantic-Enhanced Learning (SEL) on Artificial Neural Networks Using the Example of Semantic Location Prediction",2019,"","","","",64,"2022-07-13 09:25:19","","10.1145/3347146.3359089","","",,,,,4,1.33,2,2,3,"Recent machine learning models find a widespread use whether in respect of data mining and forecasting or in the classification domain. However, real-world situations comprise complex estimation tasks that carry a certain semantic load and bring a certain degree of fuzziness with them. This is a fuzziness which humans, due to their common sense knowledge and their personal experience, can easily understand by linking the underlying concepts together, while machines may from scratch not. A vast amount of both training data and time are necessary in order for a computational model to be capable of learning such kind of relations and adapting to new situations. In this work, we show that letting explicit semantic knowledge flow into a predictive model leads to an improved performance with regard to training time, accuracy and robustness. In particular, we propose adding an auxiliary semantic layer to the model, whose role is to provide it with information about the semantic interrelation of the treated classes creating in this way shortcuts and saving valuable training time while improving its quality at the same time. We explore several versions of our approach and we illustrate their functionality in a semantic location prediction scenario using 2 different real-world datasets.","",""
158,"M. Elgendi","Fast QRS Detection with an Optimized Knowledge-Based Method: Evaluation on 11 Standard ECG Databases",2013,"","","","",65,"2022-07-13 09:25:19","","10.1371/journal.pone.0073557","","",,,,,158,17.56,158,1,9,"The current state-of-the-art in automatic QRS detection methods show high robustness and almost negligible error rates. In return, the methods are usually based on machine-learning approaches that require sufficient computational resources. However, simple-fast methods can also achieve high detection rates. There is a need to develop numerically efficient algorithms to accommodate the new trend towards battery-driven ECG devices and to analyze long-term recorded signals in a time-efficient manner. A typical QRS detection method has been reduced to a basic approach consisting of two moving averages that are calibrated by a knowledge base using only two parameters. In contrast to high-accuracy methods, the proposed method can be easily implemented in a digital filter design.","",""
29,"Yu Li, Zhongxiao Li, Lizhong Ding, Peng Yang, Yuhui Hu, Wei Chen, Xin Gao","SupportNet: solving catastrophic forgetting in class incremental learning with support data",2018,"","","","",66,"2022-07-13 09:25:19","","","","",,,,,29,7.25,4,7,4,"A plain well-trained deep learning model often does not have the ability to learn new knowledge without forgetting the previously learned knowledge, which is known as catastrophic forgetting. Here we propose a novel method, SupportNet, to efficiently and effectively solve the catastrophic forgetting problem in the class incremental learning scenario. SupportNet combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of the old data when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. We validate our method with comprehensive experiments on various tasks, which show that SupportNet drastically outperforms the state-of-the-art incremental learning methods and even reaches similar performance as the deep learning model trained from scratch on both old and new data. Our program is accessible at: this https URL","",""
88,"Ning Wang, Jing-Chao Sun, M. Er, Yancheng Liu","A Novel Extreme Learning Control Framework of Unmanned Surface Vehicles",2016,"","","","",67,"2022-07-13 09:25:19","","10.1109/TCYB.2015.2423635","","",,,,,88,14.67,22,4,6,"In this paper, an extreme learning control (ELC) framework using the single-hidden-layer feedforward network (SLFN) with random hidden nodes for tracking an unmanned surface vehicle suffering from unknown dynamics and external disturbances is proposed. By combining tracking errors with derivatives, an error surface and transformed states are defined to encapsulate unknown dynamics and disturbances into a lumped vector field of transformed states. The lumped nonlinearity is further identified accurately by an extreme-learning-machine-based SLFN approximator which does not require a priori system knowledge nor tuning input weights. Only output weights of the SLFN need to be updated by adaptive projection-based laws derived from the Lyapunov approach. Moreover, an error compensator is incorporated to suppress approximation residuals, and thereby contributing to the robustness and global asymptotic stability of the closed-loop ELC system. Simulation studies and comprehensive comparisons demonstrate that the ELC framework achieves high accuracy in both tracking and approximation.","",""
6,"Weilin Wu, Jianyong Duan, R. Lu, F. Gao, Yuquan Chen","Embedded machine learning systems for robust spoken language parsing",2005,"","","","",68,"2022-07-13 09:25:19","","10.1109/NLPKE.2005.1598729","","",,,,,6,0.35,1,5,17,"In processing ill-formed spontaneous spoken utterance, many state-of-the-art robust parsers achieve robustness by allowing skipping of words and rule symbols. The parser's ability to skip words and rule symbols, however, results in a much bigger search space and greatly increases the parse ambiguity. Previous approaches resolved these issues through manually labeling the types of rule symbols, or by utilizing heuristic scores or statistical probabilities. However, these approaches have certain drawbacks. This paper proposes to exploit embedded machine learning techniques to help with pruning and disambiguation in robust parsers. An embedded machine learning system is integrated with the heuristic score and the strategy of basing the types of rule symbols upon their correspondence to the domain model. This integration can considerably relieve the reliance of robust parser development on linguistic expert handcrafting. Our experiments show that this integration offers stronger capability in ambiguity resolution, thereby enabling the robust parser to achieve better parsing accuracy.","",""
5,"M. Selfridge, D. J. Dickerson, S. F. Biggs","Cognitive Expert Systems and Machine Learning: Artificial Intelligence Research at the University of Connecticut",1987,"","","","",69,"2022-07-13 09:25:19","","10.1609/AIMAG.V8I1.577","","",,,,,5,0.14,2,3,35,"In order for next-generation expert systems to demonstrate the performance, robustness, flexibility, and learning ability of human experts, they will have to be based on cognitive models of expert human reasoning and learning. We call such next-generation systems cognitive expert systems. Research at the Artificial Intelligence Laboratory at the University of Connecticut is directed toward understanding the principles underlying cognitive expert systems and developing computer programs embodying those principles. The Causal Model Acquisition System (CMACS) learns causal models of physical mechanisms by understanding real-world natural language explanations of those mechanisms. The going Concern Expert ( GCX) uses business and environmental knowledge to assess whether a company will remain in business for at least the following year. The Business Information System (BIS) acquires business and environmental knowledge from in-depth reading of real-world news stories. These systems are based on theories of expert human reasoning and learning, and thus represent steps toward next-generation cognitive expert systems.","",""
22,"Chun-Nan Hsu, Craig A. Knoblock","Estimating the Robustness of Discovered Knowledge",1995,"","","","",70,"2022-07-13 09:25:19","","","","",,,,,22,0.81,11,2,27,"This paper introduces a new measurement, robustness, to measure the quality of machine-discovered knowledge from real-world databases that change over time. A piece of knowledge is robust if it is unlikely to become inconsistent with new database states. Robustness is different from predictive accuracy in that by the latter, the system considers only the consistency of a rule with unseen data, while by the former, the consistency after deletions and updates of existing data is also considered. Combining robustness with other utility measurements, a system can make intelligent decisions in learning and maintenance of knowledge learned from changing databases. This paper defines robustness, then presents an estimation approach for the robustness of Horn-clause rules learned from a relational database. The estimation approach applies the Laplace law of succession, which can be efficiently computed. The estimation is based on database schemas and transaction logs. No domain-specific information is required. However, if it is available, the approach can exploit it.","",""
38,"L. Mo, Fan Li, Yanjia Zhu, Anjie Huang","Human physical activity recognition based on computer vision with deep learning model",2016,"","","","",71,"2022-07-13 09:25:19","","10.1109/I2MTC.2016.7520541","","",,,,,38,6.33,10,4,6,"Human activity recognition is an active research area in the computer science because it is widely used in the fields of the security monitoring, health assessment, human machine interaction and other human related content searching. In this paper, a computer vision model based on the deep learning algorithm is proposed, which can recognize the human physical activity based on the skeleton data of the human body from the sensor of Microsoft Kinect. This model uses the human skeletons data from the CAD-60 dataset to recognize the human physical activity without using any prior knowledge. It can reduce the works on the stage of data preprocessing and feature extraction. It can also improve the generalization performance and robustness of the model, and give a better understanding of the human physical activity. Different tricks which can improve the performance of the neural networks, such as some regularization methods and other activation functions are tested. Finally, a convolutional neural network is used for the feature extraction, and a multilayer perceptron is used as the following classifier. The model can recognize twelve types of activities and the accuracy rate is 81.8%. It demonstrates that it is very effective to use the convolutional neural network to supervised learning and this model applies to human physical activity recognition.","",""
10,"A. Tahir, Jawad Ahmad, G. Morison, H. Larijani, Ryan M. Gibson, D. Skelton","HRNN4F: HYBRID DEEP RANDOM NEURAL NETWORK FOR MULTI-CHANNEL FALL ACTIVITY DETECTION",2019,"","","","",72,"2022-07-13 09:25:19","","10.1017/S0269964819000317","","",,,,,10,3.33,2,6,3,"Falls are a major health concern in older adults. Falls lead to mortality, immobility and high costs to social and health care services. Early detection and classification of falls is imperative for timely and appropriate medical aid response. Traditional machine learning models have been explored for fall classification. While newly developed deep learning techniques have the ability to potentially extract high-level features from raw sensor data providing high accuracy and robustness to variations in sensor position, orientation and diversity of work environments that may skew traditional classification models. However, frequently used deep learning models like Convolutional Neural Networks (CNN) are computationally intensive. To the best of our knowledge, we present the first instance of a Hybrid Multichannel Random Neural Network (HMCRNN) architecture for fall detection and classification. The proposed architecture provides the highest accuracy of 92.23% with dropout regularization, compared to other deep learning implementations. The performance of the proposed technique is approximately comparable to a CNN yet requires only half the computation cost of the CNN-based implementation. Furthermore, the proposed HMCRNN architecture provides 34.12% improvement in accuracy on average than a Multilayer Perceptron.","",""
32,"Himabindu Lakkaraju, Nino Arsov, Osbert Bastani","Robust and Stable Black Box Explanations",2020,"","","","",73,"2022-07-13 09:25:19","","","","",,,,,32,16.00,11,3,2,"As machine learning black boxes are increasingly being deployed in real-world applications, there has been a growing interest in developing post hoc explanations that summarize the behaviors of these black boxes. However, existing algorithms for generating such explanations have been shown to lack stability and robustness to distribution shifts. We propose a novel framework for generating robust and stable explanations of black box models based on adversarial training. Our framework optimizes a minimax objective that aims to construct the highest fidelity explanation with respect to the worst-case over a set of adversarial perturbations. We instantiate this algorithm for explanations in the form of linear models and decision sets by devising the required optimization procedures. To the best of our knowledge, this work makes the first attempt at generating post hoc explanations that are robust to a general class of adversarial perturbations that are of practical interest. Experimental evaluation with real-world and synthetic datasets demonstrates that our approach substantially improves robustness of explanations without sacrificing their fidelity on the original data distribution.","",""
30,"Bitanu Chatterjee, Trinav Bhattacharyya, K. Ghosh, P. Singh, Z. Geem, R. Sarkar","Late Acceptance Hill Climbing Based Social Ski Driver Algorithm for Feature Selection",2020,"","","","",74,"2022-07-13 09:25:19","","10.1109/ACCESS.2020.2988157","","",,,,,30,15.00,5,6,2,"Feature selection (FS) is mainly used as a pre-processing tool to reduce dimensionality by eliminating irrelevant or redundant features to be used for a machine learning or data mining algorithm. In this paper, we have introduced binary variant of a recently proposed meta-heuristic algorithm called Social Ski Driver (SSD) optimization. To the best of our knowledge, SSD has not been used yet in the domain of FS. Two binary variants of SSD are proposed using S-shaped and V-shaped transfer functions. Besides, the exploitation ability of SSD is improved by using a local search method, called Late Acceptance Hill Climbing (LAHC). The hybrid meta-heuristic is then converted to binary version by using said transfer functions. The proposed methods are applied on 18 standard UCI datasets and compared with 15 state-of-the-art FS methods. Also to check the robustness of the proposed method, we have applied it to 3 high dimensional microarray datasets and compared with 6 state-of-the-art methods. Achieved results confirm the superiority of the proposed methods compared to other meta-heuristic wrapper based FS methods considered here. Source code of this work is available at https://github.com/consigliere19/SSD-LAHC.","",""
38,"M. Zareef, Quansheng Chen, M. Hassan, Muhammad Arslan, M. M. Hashim, Waqas Ahmad, F. Kutsanedzie, A. A. Agyekum","An Overview on the Applications of Typical Non-linear Algorithms Coupled With NIR Spectroscopy in Food Analysis",2020,"","","","",75,"2022-07-13 09:25:19","","10.1007/s12393-020-09210-7","","",,,,,38,19.00,5,8,2,"","",""
112,"Lichao Sun, Yingtong Dou, Ji Wang, Philip S. Yu, B. Li","Adversarial Attack and Defense on Graph Data: A Survey",2018,"","","","",76,"2022-07-13 09:25:19","","","","",,,,,112,28.00,22,5,4,"Deep neural networks (DNNs) have been widely applied to various applications including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that DNNs are vulnerable to adversarial attacks. Though there are several works studying adversarial attack and defense strategies on domains such as images and natural language processing, it is still difficult to directly transfer the learned knowledge to graph structure data due to its representation challenges. Given the importance of graph analysis, an increasing number of works start to analyze the robustness of machine learning models on graph data. Nevertheless, current studies considering adversarial behaviors on graph data usually focus on specific types of attacks with certain assumptions. In addition, each work proposes its own mathematical formulation which makes the comparison among different methods difficult. Therefore, in this paper, we aim to survey existing adversarial learning strategies on graph data and first provide a unified formulation for adversarial learning on graph data which covers most adversarial learning studies on graph. Moreover, we also compare different attacks and defenses on graph data and discuss their corresponding contributions and limitations. In this work, we systemically organize the considered works based on the features of each topic. This survey not only serves as a reference for the research community, but also brings a clear image researchers outside this research domain. Besides, we also create an online resource and keep updating the relevant papers during the last two years. More details of the comparisons of various studies based on this survey are open-sourced at this https URL.","",""
13,"Berfu Büyüköz, Ali Hürriyetoǧlu, Arzucan Özgür","Analyzing ELMo and DistilBERT on Socio-political News Classification",2020,"","","","",77,"2022-07-13 09:25:19","","","","",,,,,13,6.50,4,3,2,"This study evaluates the robustness of two state-of-the-art deep contextual language representations, ELMo and DistilBERT, on supervised learning of binary protest news classification (PC) and sentiment analysis (SA) of product reviews. A ”cross-context” setting is enabled using test sets that are distinct from the training data. The models are fine-tuned and fed into a Feed-Forward Neural Network (FFNN) and a Bidirectional Long Short Term Memory network (BiLSTM). Multinomial Naive Bayes (MNB) and Linear Support Vector Machine (LSVM) are used as traditional baselines. The results suggest that DistilBERT can transfer generic semantic knowledge to other domains better than ELMo. DistilBERT is also 30% smaller and 83% faster than ELMo, which suggests superiority for smaller computational training budgets. When generalization is not the utmost preference and test domain is similar to the training domain, the traditional machine learning (ML) algorithms can still be considered as more economic alternatives to deep language representations.","",""
86,"S. Thrun, Joseph O'Sullivan","Clustering Learning Tasks and the Selective Cross-Task Transfer of Knowledge",1998,"","","","",78,"2022-07-13 09:25:19","","10.1007/978-1-4615-5529-2_10","","",,,,,86,3.58,43,2,24,"","",""
5,"Nicholas Soures","Deep Liquid State Machines with Neural Plasticity and On-Device Learning",2017,"","","","",79,"2022-07-13 09:25:19","","","","",,,,,5,1.00,5,1,5,"The Liquid State Machine (LSM) is a recurrent spiking neural network designed for efficient processing of spatio-temporal streams of information. LSMs have several inbuilt features such as robustness, fast training and inference speed, generalizability, continual learning (no catastrophic forgetting), and energy efficiency. These features make LSMs an ideal network for deploying intelligence on-device. In general, single LSMs are unable to solve complex real-world tasks. Recent literature has shown emergence of hierarchical architectures to support temporal information processing over different time scales. However, these approaches do not typically investigate the optimum topology for communication between layers in the hierarchical network, or assume prior knowledge about the target problem and are not generalizable. In this thesis, a deep Liquid State Machine (deep-LSM) network architecture is proposed. The deep-LSM uses staggered reservoirs to process temporal information on multiple timescales. A key feature of this network is that neural plasticity and attention are embedded in the topology to bolster its performance for complex spatio-temporal tasks. An advantage of the deep-LSM is that it exploits the random projection native to the LSM as well as local plasticity mechanisms to optimize the data transfer between sequential layers. Both random projections and local plasticity mechanisms are ideal for on-device learning due to their low computational complexity and the absence of backpropagating error. The deep-LSM is deployed on a custom learning architecture with memristors to study the feasibility of on-device learning. The performance of the deep-LSM is demonstrated on speech recognition and seizure detection applications.","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",80,"2022-07-13 09:25:19","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
19,"Xizhao Wang, Abdallah Bashir Musa","Advances in neural network based learning",2014,"","","","",81,"2022-07-13 09:25:19","","10.1007/s13042-013-0220-2","","",,,,,19,2.38,10,2,8,"","",""
30,"Ariana Mendible, S. Brunton, A. Aravkin, W. Lowrie, J. Kutz","Dimensionality reduction and reduced-order modeling for traveling wave physics",2019,"","","","",82,"2022-07-13 09:25:19","","10.1007/S00162-020-00529-9","","",,,,,30,10.00,6,5,3,"","",""
27,"C. Janikow","Inductive learning of decision rules from attribute-based examples: a knowledge-intensive genetic algorithm approach",1992,"","","","",83,"2022-07-13 09:25:19","","","","",,,,,27,0.90,27,1,30,"Genetic algorithms are stochastic adaptive systems whose search method models natural genetic inheritance and the Darwinian struggle for survival. Their importance results from the robustness and domain independence of such a search. Robustness is a desirable quality of any search method. In particular, this property has led to many successful genetic algorithm applications involving parameter optimization of unknown, possibly non-smooth and discontinuous functions. Domain independence of the search is also a praised characteristic since it allows for easy applications in different domains. However, it is a potential source of limitations of the method as well.  In this dissertation, we present a modified genetic algorithm designed for the problem of supervised inductive learning in feature-based spaces which utilizes domain dependent task-specific knowledge. Supervised learning is one of the most popular problems studied in machine learning and, consequently, has attracted considerable attention of the genetic algorithm community. Thus far, these efforts have lacked the level of success achieved in parameter optimization. The approach developed here uses the same high level descriptive language that is used in rule-based supervised learning methods. This allows for an easy utilization of inference rules of the well known inductive learning methodology, which replace the traditional domain independent operators. Moreover, a closer relationship between the underlying task and the processing mechanisms provides a setting for an application of more powerful task-specific heuristics.  Initial results indicate that genetic algorithms can be effectively used to process high level concepts and incorporate task-specific knowledge. In this particular case of supervised learning, this new method proves to be competitive to other symbolic systems. Moreover, it is potentially more robust as it provides a powerful framework that uses cooperation among competing solutions and does not assume any prior relationships among attributes.","",""
10,"K. Narendra, Yu Wang","Improving the Speed of Response of Learning Algorithms Using Multiple Models",2015,"","","","",84,"2022-07-13 09:25:19","","","","",,,,,10,1.43,5,2,7,"This is the first of a series of papers that the authors propose to write on the subject of improving the speed of response of learning systems using multiple models. During the past two decades, the first author has worked on numerous methods for improving the stability, robustness, and performance of adaptive systems using multiple models and the other authors have collaborated with him on some of them. Independently, they have also worked on several learning methods, and have considerable experience with their advantages and limitations. In particular, they are well aware that it is common knowledge that machine learning is in general very slow. Numerous attempts have been made by researchers to improve the speed of convergence of algorithms in different contexts. In view of the success of multiple model based methods in improving the speed of convergence in adaptive systems, the authors believe that the same approach will also prove fruitful in the domain of learning. In this paper, a first attempt is made to use multiple models for improving the speed of response of the simplest learning schemes that have been studied. i.e. Learning Automata.","",""
7,"G. Vacanti, A. V. Looveren","Adversarial Detection and Correction by Matching Prediction Distributions",2020,"","","","",85,"2022-07-13 09:25:19","","","","",,,,,7,3.50,4,2,2,"We present a novel adversarial detection and correction method for machine learning classifiers.The detector consists of an autoencoder trained with a custom loss function based on the Kullback-Leibler divergence between the classifier predictions on the original and reconstructed instances.The method is unsupervised, easy to train and does not require any knowledge about the underlying attack. The detector almost completely neutralises powerful attacks like Carlini-Wagner or SLIDE on MNIST and Fashion-MNIST, and remains very effective on CIFAR-10 when the attack is granted full access to the classification model but not the defence. We show that our method is still able to detect the adversarial examples in the case of a white-box attack where the attacker has full knowledge of both the model and the defence and investigate the robustness of the attack. The method is very flexible and can also be used to detect common data corruptions and perturbations which negatively impact the model performance. We illustrate this capability on the CIFAR-10-C dataset.","",""
25,"Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, A. Buduru","A Survey of Black-Box Adversarial Attacks on Computer Vision Models",2019,"","","","",86,"2022-07-13 09:25:19","","","","",,,,,25,8.33,6,4,3,"Machine learning has seen tremendous advances in the past few years, which has lead to deep learning models being deployed in varied applications of day-to-day life. Attacks on such models using perturbations, particularly in real-life scenarios, pose a severe challenge to their applicability, pushing research into the direction which aims to enhance the robustness of these models. After the introduction of these perturbations by Szegedy et al. [1], significant amount of research has focused on the reliability of such models, primarily in two aspects - white-box, where the adversary has access to the targeted model and related parameters; and the black-box, which resembles a real-life scenario with the adversary having almost no knowledge of the model to be attacked. To provide a comprehensive security cover, it is essential to identify, study, and build defenses against such attacks. Hence, in this paper, we propose to present a comprehensive comparative study of various black-box adversarial attacks and defense techniques.","",""
26,"Lina Zhuang, Chia-Hsiang Lin, Mário A. T. Figueiredo, J. Bioucas-Dias","Regularization Parameter Selection in Minimum Volume Hyperspectral Unmixing",2019,"","","","",87,"2022-07-13 09:25:19","","10.1109/TGRS.2019.2929776","","",,,,,26,8.67,7,4,3,"Linear hyperspectral unmixing (HU) aims at factoring the observation matrix into an endmember matrix and an abundance matrix. Linear HU via variational minimum volume (MV) regularization has recently received considerable attention in the remote sensing and machine learning areas, mainly owing to its robustness against the absence of pure pixels. We put some popular linear HU formulations under a unifying framework, which involves a data-fitting term and an MV-based regularization term, and collectively solve it via a nonconvex optimization. As the former and the latter terms tend, respectively, to expand (reducing the data-fitting errors) and to shrink the simplex enclosing the measured spectra, it is critical to strike a balance between those two terms. To the best of our knowledge, the existing methods find such balance by tuning a regularization parameter manually, which has little value in unsupervised scenarios. In this paper, we aim at selecting the regularization parameter automatically by exploiting the fact that a too large parameter overshrinks the volume of the simplex defined by the endmembers, making many data points be left outside of the simplex and hence inducing a large data-fitting error, while a sufficiently small parameter yields a large simplex making data-fitting error very small. Roughly speaking, the transition point happens when the simplex still encloses the data cloud but there are data points on all its facets. These observations are systematically formulated to find the transition point that, in turn, yields a good parameter. The competitiveness of the proposed selection criterion is illustrated with simulated and real data.","",""
6,"Fangming Ye","Knowledge-Driven Board-Level Functional Fault Diagnosis",2016,"","","","",88,"2022-07-13 09:25:19","","10.1007/978-3-319-40210-9","","",,,,,6,1.00,6,1,6,"","",""
8,"Chaojin Qing, Yu Wang, Bin Cai, Jiafan Wang, Chuan Huang","ELM-Based Frame Synchronization in Burst-Mode Communication Systems With Nonlinear Distortion",2020,"","","","",89,"2022-07-13 09:25:19","","10.1109/LWC.2020.2975651","","",,,,,8,4.00,2,5,2,"In burst-mode communication systems, the quality of frame synchronization (FS) at receivers significantly impacts the overall system performance. To guarantee FS, an extreme learning machine (ELM)-based synchronization method is proposed to overcome the nonlinear distortion caused by nonlinear devices or blocks. In the proposed method, a preprocessing is first performed to capture the coarse features of synchronization metric (SM) by using empirical knowledge. Then, an ELM-based FS network is employed to reduce system’s nonlinear distortion and improve SMs. Experimental results indicate that, compared with existing methods, our approach could significantly reduce the error probability of FS while improve the performance in terms of robustness and generalization.","",""
18,"Jinyin Chen, Yangyang Wu, Xiang Lin, Qi Xuan","Can Adversarial Network Attack be Defended?",2019,"","","","",90,"2022-07-13 09:25:19","","","","",,,,,18,6.00,5,4,3,"Machine learning has been successfully applied to complex network analysis in various areas, and graph neural networks (GNNs) based methods outperform others. Recently, adversarial attack on networks has attracted special attention since carefully crafted adversarial networks with slight perturbations on clean network may invalid lots of network applications, such as node classification, link prediction, and community detection etc. Such attacks are easily constructed with serious security threat to various analyze methods, including traditional methods and deep models. To the best of our knowledge, it is the first time that defense method against network adversarial attack is discussed. In this paper, we are interested in the possibility of defense against adversarial attack on network, and propose defense strategies for GNNs against attacks. First, we propose novel adversarial training strategies to improve GNNs' defensibility against attacks. Then, we analytically investigate the robustness properties for GNNs granted by the use of smooth defense, and propose two special smooth defense strategies: smoothing distillation and smoothing cross-entropy loss function. Both of them are capable of smoothing gradient of GNNs, and consequently reduce the amplitude of adversarial gradients, which benefits gradient masking from attackers. The comprehensive experiments show that our proposed strategies have great defensibility against different adversarial attacks on four real-world networks in different network analyze tasks.","",""
17,"Ziqi Yang, Hung Dang, E. Chang","Effectiveness of Distillation Attack and Countermeasure on Neural Network Watermarking",2019,"","","","",91,"2022-07-13 09:25:19","","","","",,,,,17,5.67,6,3,3,"The rise of machine learning as a service and model sharing platforms has raised the need of traitor-tracing the models and proof of authorship. Watermarking technique is the main component of existing methods for protecting copyright of models. In this paper, we show that distillation, a widely used transformation technique, is a quite effective attack to remove watermark embedded by existing algorithms. The fragility is due to the fact that distillation does not retain the watermark embedded in the model that is redundant and independent to the main learning task. We design ingrain in response to the destructive distillation. It regularizes a neural network with an ingrainer model, which contains the watermark, and forces the model to also represent the knowledge of the ingrainer. Our extensive evaluations show that ingrain is more robust to distillation attack and its robustness against other widely used transformation techniques is comparable to existing methods.","",""
16,"El Mahdi El Mhamdi, R. Guerraoui, Arsany Guirguis, Sébastien Rouault","SGD: Decentralized Byzantine Resilience",2019,"","","","",92,"2022-07-13 09:25:19","","","","",,,,,16,5.33,4,4,3,"The size of the datasets available today leads to distribute Machine Learning (ML) tasks. An SGD--based optimization is for instance typically carried out by two categories of participants: parameter servers and workers. Some of these nodes can sometimes behave arbitrarily (called \emph{Byzantine} and caused by corrupt/bogus data/machines), impacting the accuracy of the entire learning activity. Several approaches recently studied how to tolerate Byzantine workers, while assuming honest and trusted parameter servers. In order to achieve total ML robustness, we introduce GuanYu, the first algorithm (to the best of our knowledge) to handle Byzantine parameter servers as well as Byzantine workers. We prove that GuanYu ensures convergence against $\frac{1}{3}$ Byzantine parameter servers and $\frac{1}{3}$ Byzantine workers, which is optimal in asynchronous networks (GuanYu does also tolerate unbounded communication delays, i.e.\ asynchrony). To prove the Byzantine resilience of GuanYu, we use a contraction argument, leveraging geometric properties of the median in high dimensional spaces to prevent (with probability 1) any drift on the models within each of the non-Byzantine servers. % To convey its practicality, we implemented GuanYu using the low-level TensorFlow APIs and deployed it in a distributed setup using the CIFAR-10 dataset. The overhead of tolerating Byzantine participants, compared to a vanilla TensorFlow deployment that is vulnerable to a single Byzantine participant, is around 30\% in terms of throughput (model updates per second) - while maintaining the same convergence rate (model updates required to reach some accuracy).","",""
9,"Chun-Nan Hsu","Learning effective and robust knowledge for semantic query optimization",1996,"","","","",93,"2022-07-13 09:25:19","","","","",,,,,9,0.35,9,1,26,"Optimizing queries to heterogeneous, distributed multidatabases is an important problem. Due to the query complexity and the heterogeneity of databases, it is difficult for conventional optimization approaches to solve the problem satisfactorily. Semantic Query Optimization (SQO) can complement conventional approaches to overcome the heterogeneity and considerably reduce redundant data transmission. SQO optimizers use rules about data regularities to yield significant cost reduction. However, hand coding useful rules for SQO is impracticable. This dissertation presents a machine learning approach to this knowledge bottleneck problem.  Unlike search control rules or classification rules studied extensively in machine learning, two roughly correlated measures must be maximized in the learning of high utility rules for SQO. The first measure is the effectiveness. Effective rules must be applicable in many different queries and yield high cost reduction. The second measure is the robustness against database changes. That is, they must remain valid regardless of database changes. This dissertation presents a new inductive learning approach to learning effective and robust rules. The learning approach considers both applicability and cost-reduction in rule induction to learn effective rules. The learned rules are robust because the learner is able to guide the learning for robust rules with an approach to estimating the probabilities of database changes.  To evaluate the utility of the learning approach, this dissertation also describes an extended SQO approach for query plans that retrieve data from heterogeneous multidatabases. The experimental results show that the learned rules produce significant savings while being robust against database changes. The learning and optimization approaches provide a complete solution for multidatabase information systems to effectively optimize queries using SQO that does not require an expensive coding effort to produce useful rules.","",""
31,"Philippe E. Thomas, Roman Klinger, U. Leser","Learning Protein–Protein Interaction Extraction using Distant Supervision",2011,"","","","",94,"2022-07-13 09:25:19","","","","",,,,,31,2.82,10,3,11,"Most relation extraction methods, especially in the domain of biology, rely on machine learning methods to classify a cooccurring pair of entities in a sentence to be related or not. Such an approach requires a training corpus, which involves expert annotation and is tedious, timeconsuming, and expensive. We overcome this problem by the use of existing knowledge in structured databases to automatically generate a training corpus for protein-protein interactions. An extensive evaluation of different instance selection strategies is performed to maximize robustness on this presumably noisy resource. Successful strategies to consistently improve performance include a majority voting ensemble of classifiers trained on subsets of the training corpus and the use of knowledge bases consisting of proven non-interactions. Our best configured model built without manually annotated data shows very competitive results on several publicly available benchmark corpora.","",""
14,"H. Shirazi, Bruhadeshwar Bezawada, I. Ray, Charles Anderson","Adversarial Sampling Attacks Against Phishing Detection",2019,"","","","",95,"2022-07-13 09:25:19","","10.1007/978-3-030-22479-0_5","","",,,,,14,4.67,4,4,3,"","",""
25,"Zhinus Marzi, Soorya Gopalakrishnan, Upamanyu Madhow, Ramtin Pedarsani","Sparsity-based Defense Against Adversarial Attacks on Linear Classifiers",2018,"","","","",96,"2022-07-13 09:25:19","","10.1109/ISIT.2018.8437638","","",,,,,25,6.25,6,4,4,"Deep neural networks represent the state of the art in machine learning in a growing number of fields, including vision, speech and natural language processing. However, recent work raises important questions about the robustness of such architectures, by showing that it is possible to induce classification errors through tiny, almost imperceptible, perturbations. Vulnerability to such “adversarial attacks”, or “adversarial examples”, has been conjectured to be due to the excessive linearity of deep networks. In this paper, we study this phenomenon in the setting of a linear classifier, and show that it is possible to exploit sparsity in natural data to combat $\ell_{\infty}$ -bounded adversarial perturbations. Specifically, we demonstrate the efficacy of a sparsifying front end via an ensemble averaged analysis, and experimental results for the MNIST handwritten digit database. To the best of our knowledge, this is the first work to show that sparsity provides a theoretically rigorous framework for defense against adversarial attacks.","",""
12,"Dai, Tang, Shao, Huang, Wang","Fault Diagnosis of Rolling Bearing Based on Multiscale Intrinsic Mode Function Permutation Entropy and a Stacked Sparse Denoising Autoencoder",2019,"","","","",97,"2022-07-13 09:25:19","","10.3390/APP9132743","","",,,,,12,4.00,2,5,3,"Effective intelligent fault diagnosis of bearings is important for improving safety and reliability of machine. Benefiting from the training advantages, deep learning method can automatically and adaptively learn more abstract and high-level features without much priori knowledge. To realize representative features mining and automatic recognition of bearing health condition, a diagnostic model of stacked sparse denoising autoencoder (SSDAE) which combines sparse autoencoder (SAE) and denoising autoencoder (DAE) is proposed in this paper. The sparse criterion in SAE, corrupting operation in DAE and reasonable designing of the stack order of autoencoders help to mine essential information of the input and improve fault pattern classification robustness. In order to provide better input features for the constructed network, the raw non-stationary and nonlinear vibration signals are processed with ensemble empirical mode decomposition (EEMD) and multiscale permutation entropy (MPE). MPE features which are extracted based on both the selected characteristic frequency-related intrinsic mode function components (IMFs) and the raw signal, are used as low-level feature for the input of the proposed diagnostic model for health condition recognition and classification. Two experiments based on the Case Western Reserve University (CWRU) dataset and the measurement dataset from laboratory were conducted, and results demonstrate the effectiveness of the proposed method and highlight its excellent performance relative to existing methods.","",""
12,"Teresa Yeo, Parameswaran Kamalaruban, A. Singla, Arpit Merchant, Thibault Asselborn, Louis Faucon, P. Dillenbourg, V. Cevher","Iterative Classroom Teaching",2018,"","","","",98,"2022-07-13 09:25:19","","10.1609/aaai.v33i01.33015684","","",,,,,12,3.00,2,8,4,"We consider the machine teaching problem in a classroom-like setting wherein the teacher has to deliver the same examples to a diverse group of students. Their diversity stems from differences in their initial internal states as well as their learning rates. We prove that a teacher with full knowledge about the learning dynamics of the students can teach a target concept to the entire classroom using O(min{d,N}log 1/ɛ) exam-ples, where d is the ambient dimension of the problem, N is the number of learners, and ɛ is the accuracy parameter. We show the robustness of our teaching strategy when the teacher has limited knowledge of the learners’ internal dynamics as provided by a noisy oracle. Further, we study the trade-off between the learners’ workload and the teacher’s cost in teaching the target concept. Our experiments validate our theoretical results and suggest that appropriately partitioning the classroom into homogenous groups provides a balance between these two objectives.","",""
68,"P. Russu, Ambra Demontis, B. Biggio, G. Fumera, F. Roli","Secure Kernel Machines against Evasion Attacks",2016,"","","","",99,"2022-07-13 09:25:19","","10.1145/2996758.2996771","","",,,,,68,11.33,14,5,6,"Machine learning is widely used in security-sensitive settings like spam and malware detection, although it has been shown that malicious data can be carefully modified at test time to evade detection. To overcome this limitation, adversary-aware learning algorithms have been developed, exploiting robust optimization and game-theoretical models to incorporate knowledge of potential adversarial data manipulations into the learning algorithm. Despite these techniques have been shown to be effective in some adversarial learning tasks, their adoption in practice is hindered by different factors, including the difficulty of meeting specific theoretical requirements, the complexity of implementation, and scalability issues, in terms of computational time and space required during training. In this work, we aim to develop secure kernel machines against evasion attacks that are not computationally more demanding than their non-secure counterparts. In particular, leveraging recent work on robustness and regularization, we show that the security of a linear classifier can be drastically improved by selecting a proper regularizer, depending on the kind of evasion attack, as well as unbalancing the cost of classification errors. We then discuss the security of nonlinear kernel machines, and show that a proper choice of the kernel function is crucial. We also show that unbalancing the cost of classification errors and varying some kernel parameters can further improve classifier security, yielding decision functions that better enclose the legitimate data. Our results on spam and PDF malware detection corroborate our analysis.","",""
82,"F. Nie, Hua Wang, Heng Huang, C. Ding","Joint Schatten $$p$$p-norm and $$\ell _p$$ℓp-norm robust matrix completion for missing value recovery",2013,"","","","",100,"2022-07-13 09:25:19","","10.1007/s10115-013-0713-z","","",,,,,82,9.11,21,4,9,"","",""
15,"Alexander Klaas, C. Laroque, W. Dangelmaier, M. Fischer","Simulation aided, knowledge based routing for AGVs in a distribution warehouse",2011,"","","","",101,"2022-07-13 09:25:19","","10.1109/WSC.2011.6147883","","",,,,,15,1.36,4,4,11,"Traditional routing algorithms for real world AGV systems in warehouses compute static paths, which can only be adjusted to a limited degree in the event of unplanned disturbances. In our approach, we aim for a higher reactivity in such events and plan small steps of a path incrementally. The current traffic situation and also up to date time constraints for each AGV can then be considered. We compute each step in real time based on empirical data stored in a knowledge base. It contains information covering a broad temporal horizon of the system to prevent costly decisions that may occur when only considering short term consequences. The knowledge is gathered through machine learning from the results of multiple experiments in a discrete event simulation during preprocessing. We implemented and experimentally evaluated the algorithm in a test scenario and achieve a natural robustness against delays and failures.","",""
9,"Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, A. Buduru","A Study of Black Box Adversarial Attacks in Computer Vision",2019,"","","","",102,"2022-07-13 09:25:19","","","","",,,,,9,3.00,2,4,3,"Machine learning has seen tremendous advances in the past few years which has lead to deep learning models being deployed in varied applications of day-to-day life. Attacks on such models using perturbations, particularly in real-life scenarios, pose a serious challenge to their applicability, pushing research into the direction which aims to enhance the robustness of these models. After the introduction of these perturbations by Szegedy et al., significant amount of research has focused on the reliability of such models, primarily in two aspects - white-box, where the adversary has access to the targeted model and related parameters; and the black-box, which resembles a real-life scenario with the adversary having almost no knowledge of the model to be attacked. We propose to attract attention on the latter scenario and thus, present a comprehensive comparative study among the different adversarial black-box attack approaches proposed till date. The second half of this literature survey focuses on the defense techniques. This is the first study, to the best of our knowledge, that specifically focuses on the black-box setting to motivate future work on the same.","",""
27,"Yuan Shi, Zhenzhong Lan, W. Liu, Wei Bi","Extending Semi-supervised Learning Methods for Inductive Transfer Learning",2009,"","","","",103,"2022-07-13 09:25:19","","10.1109/ICDM.2009.75","","",,,,,27,2.08,7,4,13,"Inductive transfer learning and semi-supervised learning are two different branches of machine learning. The former tries to reuse knowledge in labeled out-of-domain instances while the later attempts to exploit the usefulness of unlabeled in-domain instances. In this paper, we bridge the two branches by pointing out that many semi-supervised learning methods can be extended for inductive transfer learning, if the step of labeling an unlabeled instance is replaced by re-weighting a diff-distribution instance. Based on this recognition, we develop a new transfer learning method, namely COITL, by extending the co-training method in semi-supervised learning. Experimental results reveal that COITL can achieve significantly higher generalization and robustness, compared with two state-of-the-art methods in inductive transfer learning.","",""
15,"Ingo Glöckner, Björn Pelzer","Exploring Robustness Enhancements for Logic-Based Passage Filtering",2008,"","","","",104,"2022-07-13 09:25:19","","10.1007/978-3-540-85563-7_77","","",,,,,15,1.07,8,2,14,"","",""
82,"Qinghua Hu, Weiwei Pan, Lei Zhang, David Zhang, Yanping Song, Maozu Guo, Daren Yu","Feature Selection for Monotonic Classification",2012,"","","","",105,"2022-07-13 09:25:19","","10.1109/TFUZZ.2011.2167235","","",,,,,82,8.20,12,7,10,"Monotonic classification is a kind of special task in machine learning and pattern recognition. Monotonicity constraints between features and decision should be taken into account in these tasks. However, most existing techniques are not able to discover and represent the ordinal structures in monotonic datasets. Thus, they are inapplicable to monotonic classification. Feature selection has been proven effective in improving classification performance and avoiding overfitting. To the best of our knowledge, no technique has been specially designed to select features in monotonic classification until now. In this paper, we introduce a function, which is called rank mutual information, to evaluate monotonic consistency between features and decision in monotonic tasks. This function combines the advantages of dominance rough sets in reflecting ordinal structures and mutual information in terms of robustness. Then, rank mutual information is integrated with the search strategy of min-redundancy and max-relevance to compute optimal subsets of features. A collection of numerical experiments are given to show the effectiveness of the proposed technique.","",""
245,"S. Thrun, Joseph O'Sullivan","Discovering Structure in Multiple Learning Tasks: The TC Algorithm",1996,"","","","",106,"2022-07-13 09:25:19","","","","",,,,,245,9.42,123,2,26,"Recently, there has been an increased interest in “lifelong” machine learning methods, that transfer knowledge across multiple learning tasks. Such methods have repeatedly been found to outperform conventional, single-task learning algorithms when the learning tasks are appropriately related. To increase robustness of such approaches, methods are desirable that can reason about the relatedness of individual learning tasks, in order to avoid the danger arising from tasks that are unrelated and thus potentially misleading. This paper describes the task-clustering (TC) algorithm. TC clusters learning tasks into classes of mutually related tasks. When facing a new learning task, TC first determines the most related task cluster, then exploits information selectively from this task cluster only. An empirical study carried out in a mobile robot domain shows that TC outperforms its non-selective counterpart in situations where only a small number of tasks is relevant.","",""
4,"H. Chaoui, P. Sicard","Robust ANN-based nonlinear speed observer for permanent magnet synchronous machine drives",2011,"","","","",107,"2022-07-13 09:25:19","","10.1109/IEMDC.2011.5994875","","",,,,,4,0.36,2,2,11,"This paper introduces a robust artificial neural network (ANN) based nonlinear speed observer for permanent magnet synchronous machines (PMSMs). A multilayer perception is trained online using back-propagation learning algorithm to estimate the rotor speed without any a priori dynamics knowledge. Thus, the proposed observer is able to cope with higher degrees of nonlinearity since it is not based on a linear-in-parameters model, unlike many neural network observers. Therefore, robustness to parameter variations is achieved. Simulation results for different situations highlight the performance of the proposed observer in the presence of high parametric uncertainties. The proposed observer is reliable and effective for PMSM drives.","",""
63,"R. Calandra, N. Gopalan, A. Seyfarth, Jan Peters, M. Deisenroth","Bayesian Gait Optimization for Bipedal Locomotion",2014,"","","","",108,"2022-07-13 09:25:19","","10.1007/978-3-319-09584-4_25","","",,,,,63,7.88,13,5,8,"","",""
119,"S. Mounce, R. Mounce, J. Boxall","Novelty detection for time series data analysis in water distribution systems using support vector machines",2011,"","","","",109,"2022-07-13 09:25:19","","10.2166/HYDRO.2010.144","","",,,,,119,10.82,40,3,11,"The sampling frequency and quantity of time series data collected from water distribution systems has been increasing in recent years, giving rise to the potential for improving system knowledge if suitable automated techniques can be applied, in particular, machine learning. Novelty (or anomaly) detection refers to the automatic identification of novel or abnormal patterns embedded in large amounts of “normal” data. When dealing with time series data (transformed into vectors), this means abnormal events embedded amongst many normal time series points. The support vector machine is a data-driven statistical technique that has been developed as a tool for classification and regression. The key features include statistical robustness with respect to non-Gaussian errors and outliers, the selection of the decision boundary in a principled way, and the introduction of nonlinearity in the feature space without explicitly requiring a nonlinear algorithm by means of kernel functions. In this research, support vector regression is used as a learning method for anomaly detection from water flow and pressure time series data. No use is made of past event histories collected through other information sources. The support vector regression methodology, whose robustness derives from the training error function, is applied to a case study.","",""
32,"Hongjie Shi, Takashi Ushio, M. Endo, K. Yamagami, Noriaki Horii","A multichannel convolutional neural network for cross-language dialog state tracking",2016,"","","","",110,"2022-07-13 09:25:19","","10.1109/SLT.2016.7846318","","",,,,,32,5.33,6,5,6,"The fifth Dialog State Tracking Challenge (DSTC5) introduces a new cross-language dialog state tracking scenario, where the participants are asked to build their trackers based on the English training corpus, while evaluating them with the unlabeled Chinese corpus. Although the computer-generated translations for both English and Chinese corpus are provided in the dataset, these translations contain errors and careless use of them can easily hurt the performance of the built trackers. To address this problem, we propose a multichannel Convolutional Neural Networks (CNN) architecture, in which we treat English and Chinese language as different input channels of one single CNN model. In the evaluation of DSTC5, we found that such multichannel architecture can effectively improve the robustness against translation errors. Additionally, our method for DSTC5 is purely machine learning based and requires no prior knowledge about the target language. We consider this a desirable property for building a tracker in the cross-language context, as not every developer will be familiar with both languages.","",""
46,"Reinhold Scherer, J. Faller, David Balderas, E. Friedrich, M. Pröll, B. Allison, G. Müller-Putz","Brain–computer interfacing: more than the sum of its parts",2013,"","","","",111,"2022-07-13 09:25:19","","10.1007/s00500-012-0895-4","","",,,,,46,5.11,7,7,9,"","",""
14,"Ishai Rosenberg, A. Shabtai, Y. Elovici, L. Rokach","Low Resource Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers",2018,"","","","",112,"2022-07-13 09:25:19","","","","",,,,,14,3.50,4,4,4,"In this paper, we present a black-box attack against API call based machine learning malware classifiers. We generate adversarial examples combining API call sequences and static features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. Our attack only requires access to the predicted label of the attacked model (without the confidence level) and minimizes the number of target classifier queries. We evaluate the attack's effectiveness against many classifiers such as RNN variants, DNN, SVM, GBDT, etc. We show that the attack requires fewer queries and less knowledge about the attacked model's architecture than other existing black-box attacks. We also implement BADGER, a software framework to recraft any malware binary so that it won't be detected by classifiers, without access to the malware source code. Finally, we discuss the robustness of this attack to existing defense mechanisms.","",""
13,"Behrooz Hosseini, K. Kiani","A Robust Distributed Big Data Clustering-based on Adaptive Density Partitioning using Apache Spark",2018,"","","","",113,"2022-07-13 09:25:19","","10.3390/sym10080342","","",,,,,13,3.25,7,2,4,"Unsupervised machine learning and knowledge discovery from large-scale datasets have recently attracted a lot of research interest. The present paper proposes a distributed big data clustering approach-based on adaptive density estimation. The proposed method is developed-based on Apache Spark framework and tested on some of the prevalent datasets. In the first step of this algorithm, the input data is divided into partitions using a Bayesian type of Locality Sensitive Hashing (LSH). Partitioning makes the processing fully parallel and much simpler by avoiding unneeded calculations. Each of the proposed algorithm steps is completely independent of the others and no serial bottleneck exists all over the clustering procedure. Locality preservation also filters out the outliers and enhances the robustness of the proposed approach. Density is defined on the basis of Ordered Weighted Averaging (OWA) distance which makes clusters more homogenous. According to the density of each node, the local density peaks will be detected adaptively. By merging the local peaks, final cluster centers will be obtained and other data points will be a member of the cluster with the nearest center. The proposed method has been implemented and compared with similar recently published researches. Cluster validity indexes achieved from the proposed method shows its superiorities in precision and noise robustness in comparison with recent researches. Comparison with similar approaches also shows superiorities of the proposed method in scalability, high performance, and low computation cost. The proposed method is a general clustering approach and it has been used in gene expression clustering as a sample of its application.","",""
13,"Yirui Wu, Weigang Xu, Jun Feng, P. Shivakumara, Tong Lu","Local and Global Bayesian Network based Model for Flood Prediction",2018,"","","","",114,"2022-07-13 09:25:19","","10.1109/ICPR.2018.8546257","","",,,,,13,3.25,3,5,4,"To minimize the negative impacts brought by floods, researchers from pattern recognition community pay special attention to the problem of flood prediction by involving technologies of machine learning. In this paper, we propose to construct hierarchical Bayesian network to predict floods for small rivers, which appropriately embed hydrology expert knowledge for high rationality and robustness. We present the construction of the hierarchical Bayesian network in two stages comprising local and global network construction. During the local network construction, we firstly divide the river watershed into small local regions. Following the idea of a famous hydrology model - the Xinanjiang model, we establish the entities and connections of the local Bayesian network to represent the variables and physical processes of the Xinanjiang model, respectively. During the global network construction, intermediate variables for local regions, computed by the local Bayesian network, are coupled to offer an estimation for time-varying values of flow rate by proper inferences of the global network. At last, we propose to improve the output of Bayesian network by utilizing former flow rate values. We demonstrate the accuracy and robustness of the proposed method by conducting experiments on a collected dataset with several comparative methods.","",""
9,"Javier Prado, Francisco Yandún, Miguel Torres Torriti, F. A. Auat Cheein","Overcoming the Loss of Performance in Unmanned Ground Vehicles Due to the Terrain Variability",2018,"","","","",115,"2022-07-13 09:25:19","","10.1109/ACCESS.2018.2808538","","",,,,,9,2.25,2,4,4,"Performance in autonomous driven vehicles is susceptible of degradation when traversing different terrains, thus needing motion controllers to be tuned for different terrain profiles. Such tuning stage is a time consuming process for the programmer or operator, and it is often based on intuition or heuristic approaches, and once tuned, the performance of the vehicle varies according to the terrain nature. In this context, we provide a visual based approach to identify terrain variability and its transitions, while observing and learning the performance of the vehicle using machine learning techniques. Based on the identified terrain and the knowledge regarding the performance of the vehicle, our system self-tunes the motion controller, in real time, to enhance its performance. In particular, the trajectory tracking errors are reduced, the control input effort is decreased, and the effects of the wheel-terrain interaction are mitigated preserving the system robustness. The tests were carried out by simulation and experimentation using a robotized commercial platform. Finally, implementation details and results are included in this paper, showing an enhancement in the motion performance up to 92.4% when the highest accuracy of the terrain classifier was 84.3%.","",""
27,"M. Schnitzer, J. Lok, Susan Gruber","Variable Selection for Confounder Control, Flexible Modeling and Collaborative Targeted Minimum Loss-Based Estimation in Causal Inference",2016,"","","","",116,"2022-07-13 09:25:19","","10.1515/ijb-2015-0017","","",,,,,27,4.50,9,3,6,"Abstract This paper investigates the appropriateness of the integration of flexible propensity score modeling (nonparametric or machine learning approaches) in semiparametric models for the estimation of a causal quantity, such as the mean outcome under treatment. We begin with an overview of some of the issues involved in knowledge-based and statistical variable selection in causal inference and the potential pitfalls of automated selection based on the fit of the propensity score. Using a simple example, we directly show the consequences of adjusting for pure causes of the exposure when using inverse probability of treatment weighting (IPTW). Such variables are likely to be selected when using a naive approach to model selection for the propensity score. We describe how the method of Collaborative Targeted minimum loss-based estimation (C-TMLE; van der Laan and Gruber, 2010 [27]) capitalizes on the collaborative double robustness property of semiparametric efficient estimators to select covariates for the propensity score based on the error in the conditional outcome model. Finally, we compare several approaches to automated variable selection in low- and high-dimensional settings through a simulation study. From this simulation study, we conclude that using IPTW with flexible prediction for the propensity score can result in inferior estimation, while Targeted minimum loss-based estimation and C-TMLE may benefit from flexible prediction and remain robust to the presence of variables that are highly correlated with treatment. However, in our study, standard influence function-based methods for the variance underestimated the standard errors, resulting in poor coverage under certain data-generating scenarios.","",""
5,"D. Hagos, P. Engelstad, A. Yazidi, Ø. Kure","Recurrent Neural Network-Based Prediction of TCP Transmission States from Passive Measurements",2018,"","","","",117,"2022-07-13 09:25:19","","10.1109/NCA.2018.8548064","","",,,,,5,1.25,1,4,4,"Long Short-Term Memory (LSTM) neural networks are a state-of-the-art techniques when it comes to sequence learning and time series prediction models. In this paper, we have used LSTM-based Recurrent Neural Networks (RNN) for building a generic prediction model for Transmission Control Protocol (TCP) connection characteristics from passive measurements. To the best of our knowledge, this is the first work that attempts to apply LSTM for demonstrating how a network operator can identify the most important system-wide TCP per-connection states of a TCP client that determine a network condition (e.g., cwnd) from passive traffic measured at an intermediate node of the network without having access to the sender. We found out that LSTM learners outperform the state-of-the-art classical machine learning prediction models. Through an extensive experimental evaluation on multiple scenarios, we demonstrate the scalability and robustness of our approach and its potential for monitoring TCP transmission states related to network congestion from passive measurements. Our results based on emulated and realistic settings suggest that Deep Learning is a promising tool for monitoring system-wide TCP states from passive measurements and we believe that the methodology presented in our paper may strengthen future research work in the computer networking community.","",""
16,"M. Copelli, R. Eichhorn, O. Kinouchi, Michael Biehl, R. Simonetti, P. Riegler, N. Caticha","Noise robustness in multilayer neural networks",1997,"","","","",118,"2022-07-13 09:25:19","","10.1209/EPL/I1997-00167-2","","",,,,,16,0.64,2,7,25,"The training of multilayered neural networks in the presence of different types of noise is studied. We consider the learning of realizable rules in nonoverlapping architectures. Achieving optimal generalization depends on the knowledge of the noise level, however its misestimation may lead to partial or complete loss of the generalization ability. We demonstrate this effect in the framework of online learning and present the results in terms of noise robustness phase diagrams. While for additive (weight) noise the robustness properties depend on the architecture and size of the networks, this is not so for multiplicative (output) noise. In this case we find a universal behaviour independent of the machine size for both the tree parity and committee machines.","",""
37,"D. Bohus, Alexander I. Rudnicky","Integrating Multiple Knowledge Sources for Utterance-Level Confidence Annotation in the CMU Communicator Spoken Dialog System",2002,"","","","",119,"2022-07-13 09:25:19","","10.21236/ada461099","","",,,,,37,1.85,19,2,20,"Abstract : In the recent years, automated speech recognition has been the main drive behind the advent of spoken language interfaces, but at the same a time a severe limiting factor in the development of these systems. We believe that increased robustness in the face of recognition errors can be achieved by making the systems aware of their own misunderstandings, and employing appropriate recovery techniques when breakdowns in interacted occur. In this paper we address the first problem: the development of an utterance-level confidence annotator for a spoken dialog system. After a brief introduction to the CMU Communicator spoken dialog system (which provided the target platform for the developed annotator), we cast the confidence annotation problem as a machine learning classification task, and focus on selecting relevant features and on empirically identifying the best classification techniques for this task. The results indicate that significant reductions in classification error rate can be obtained using several different classifiers. Furthermore, we propose a data driven approach to assessing the impact of the errors committed by the confidence annotator on dialog performance, with a view to optimally fine-tuning the annotator. Several models were constructed, and the resulting error costs were in accordance with our intuition. We found, surprisingly, that, at least for a mixed-initiative spoken dialog system as the CMU Communicator, these errors trade-all equally over a wide operating characteristic range.","",""
35,"M. R. Mendoza, G. C. da Fonseca, Guilherme Loss-Morais, Ronnie Alves, R. Margis, A. Bazzan","RFMirTarget: Predicting Human MicroRNA Target Genes with a Random Forest Classifier",2013,"","","","",120,"2022-07-13 09:25:19","","10.1371/journal.pone.0070153","","",,,,,35,3.89,6,6,9,"MicroRNAs are key regulators of eukaryotic gene expression whose fundamental role has already been identified in many cell pathways. The correct identification of miRNAs targets is still a major challenge in bioinformatics and has motivated the development of several computational methods to overcome inherent limitations of experimental analysis. Indeed, the best results reported so far in terms of specificity and sensitivity are associated to machine learning-based methods for microRNA-target prediction. Following this trend, in the current paper we discuss and explore a microRNA-target prediction method based on a random forest classifier, namely RFMirTarget. Despite its well-known robustness regarding general classifying tasks, to the best of our knowledge, random forest have not been deeply explored for the specific context of predicting microRNAs targets. Our framework first analyzes alignments between candidate microRNA-target pairs and extracts a set of structural, thermodynamics, alignment, seed and position-based features, upon which classification is performed. Experiments have shown that RFMirTarget outperforms several well-known classifiers with statistical significance, and that its performance is not impaired by the class imbalance problem or features correlation. Moreover, comparing it against other algorithms for microRNA target prediction using independent test data sets from TarBase and starBase, we observe a very promising performance, with higher sensitivity in relation to other methods. Finally, tests performed with RFMirTarget show the benefits of feature selection even for a classifier with embedded feature importance analysis, and the consistency between relevant features identified and important biological properties for effective microRNA-target gene alignment.","",""
24,"L. Stetson, Taylor Pearl, Yanwen Chen, J. Barnholtz-Sloan","Computational identification of multi-omic correlates of anticancer therapeutic response",2014,"","","","",121,"2022-07-13 09:25:19","","10.1186/1471-2164-15-S7-S2","","",,,,,24,3.00,6,4,8,"","",""
238,"A. Varsek, T. Urbancic, B. Filipič","Genetic algorithms in controller design and tuning",1993,"","","","",122,"2022-07-13 09:25:19","","10.1109/21.260663","","",,,,,238,8.21,79,3,29,"A three-phased framework for learning dynamic system control is presented. A genetic algorithm is employed to derive control rules encoded as decision tables. Next, the rules are automatically transformed into comprehensible form by means of inductive machine learning. Finally, a genetic algorithm is applied again to optimize the numerical parameters of the induced rules. The approach is experimentally verified on a benchmark problem of inverted pendulum control, with special emphasis on robustness and reliability. It is also shown that the proposed framework enables exploiting available domain knowledge. In this case, genetic algorithm makes qualitative control rules operational by providing interpretation of symbols in terms of numerical values. >","",""
29,"Shengjun Li, Rui-min Shen","Fuzzy cognitive map learning based on improved nonlinear Hebbian rule",2004,"","","","",123,"2022-07-13 09:25:19","","10.1109/ICMLC.2004.1382183","","",,,,,29,1.61,15,2,18,"Fuzzy cognitive map (FCM) is a powerful soft computing technique for modeling complex systems. It is a combination of fuzzy logic theory and neural networks. Developing of FCM is easy and adaptable based on human knowledge and experience. On the other hand, the main dependence on experts' knowledge and opinion, and the potential convergence to undesire steady states are the shortcomings of FCMs. Learning methods are good choices used to overcome the shortcomings and strengthen the efficiency and robustness of FCM. This paper proposes one improved Hebbian algorithm on non-linear units for training FCMs. With the proposed learning procedure, FCM can modify its fuzzy causal web as casual pattern change and update their causal knowledge as experts.","",""
9,"Niannan Xue, Yannis Panagakis, S. Zafeiriou","Side Information in Robust Principal Component Analysis: Algorithms and Applications",2017,"","","","",124,"2022-07-13 09:25:19","","10.1109/ICCV.2017.463","","",,,,,9,1.80,3,3,5,"Robust Principal Component Analysis (RPCA) aims at recovering a low-rank subspace from grossly corrupted high-dimensional (often visual) data and is a cornerstone in many machine learning and computer vision applications. Even though RPCA has been shown to be very successful in solving many rank minimisation problems, there are still cases where degenerate or suboptimal solutions are obtained. This is likely to be remedied by taking into account of domain-dependent prior knowledge. In this paper, we propose two models for the RPCA problem with the aid of side information on the low-rank structure of the data. The versatility of the proposed methods is demonstrated by applying them to four applications, namely background subtraction, facial image denoising, face and facial expression recognition. Experimental results on synthetic and five real world datasets indicate the robustness and effectiveness of the proposed methods on these application domains, largely outperforming six previous approaches.","",""
2,"I. Kollia, N. Simou, G. Stamou, A. Stafylopatis","Interweaving Knowledge Representation and Adaptive Neural Networks",2009,"","","","",125,"2022-07-13 09:25:19","","","","",,,,,2,0.15,1,4,13,"Both symbolic knowledge representation systems and machine learning techniques, including artificial neural networks, play a significant role in Artificial Intelligence. Interweaving these techniques, in order to achieve adaptation and robustness in classification problems is of great importance. In this paper we present a novel architecture that can provide effective connectionist adaptation of ontological knowledge. The proposed architecture can be used to improve performance of multimedia analysis and man machine interaction systems.","",""
15,"Der-Chiang Li, Wen-Chih Chen, Che-Jung Chang, C. Chen, I-Hsiang Wen","Practical information diffusion techniques to accelerate new product pilot runs",2015,"","","","",126,"2022-07-13 09:25:19","","10.1080/00207543.2015.1032437","","",,,,,15,2.14,3,5,7,"Under the increasing pressure of global competition, product life cycles are becoming shorter and shorter. This means that better methods are needed to analyse the limited information obtained at the trial stage in order to derive useful knowledge that can aid in mass production. Machine learning algorithms, such as data mining techniques, are widely applied to solve this problem. However, a certain amount of training samples is usually required to determine the validity of the information that is obtained. This study uses only a few data points to estimate the range of data attribute domains using a data diffusion method, in order to derive more useful information. Then, based on practical engineering experience, we generate virtual samples with a noise disturbance method to improve the robustness of the predictions derived from a multiple linear regression. One real data set obtained from a large TFT-LCD company is examined in the experiment, and the results show the proposed approach to be effective.","",""
51,"U. Furbach, Ingo Glöckner, Björn Pelzer","An application of automated reasoning in natural language question answering",2010,"","","","",127,"2022-07-13 09:25:19","","10.3233/AIC-2010-0461","","",,,,,51,4.25,17,3,12,"The LogAnswer system is an application of automated reasoning to the field of open domain question answering. In order to find answers to natural language questions regarding arbitrary topics, the system integrates an automated theorem prover in a framework of natural language processing tools. The latter serve to construct an extensive knowledge base automatically from given textual sources, while the automated theorem prover makes it possible to derive answers by deductive reasoning. In the paper, we discuss the requirements to the prover that arise in this application, especially concerning efficiency and robustness. The proposed solution rests on incremental reasoning, relaxation of the query (if no proof of the full query is found), and other techniques. In order to improve the robustness of the approach to gaps of the background knowledge, the results of deductive processing are combined with shallow linguistic features by machine learning.","",""
7,"A. Derville, J. Baderot, G. Bernard, J. Foucher, Hanna Grönqvist, A. Labrosse, S. Martínez, Y. Zimmermann","Designed tools for analysis of lithography patterns and nanostructures",2017,"","","","",128,"2022-07-13 09:25:19","","10.1117/12.2258612","","",,,,,7,1.40,1,8,5,"We introduce a set of designed tools for the analysis of lithography patterns and nano structures. The classical metrological analysis of these objects has the drawbacks of being time consuming, requiring manual tuning and lacking robustness and user friendliness. With the goal of improving the current situation, we propose new image processing tools at different levels: semi automatic, automatic and machine-learning enhanced tools. The complete set of tools has been integrated into a software platform designed to transform the lab into a virtual fab. The underlying idea is to master nano processes at the research and development level by accelerating the access to knowledge and hence speed up the implementation in product lines.","",""
4,"C. Shulby, M. D. Ferreira, R. Mello, S. Aluísio","Acoustic Modeling Using a Shallow CNN-HTSVM Architecture",2017,"","","","",129,"2022-07-13 09:25:19","","10.1109/BRACIS.2017.62","","",,,,,4,0.80,1,4,5,"High-accuracy speech recognition is especially challenging when large datasets are not available. It is possible to bridge this gap with careful and knowledge-driven parsing combined with the biologically inspired CNN and the learning guarantees of the Vapnik Chervonenkis (VC) theory. This work presents a Shallow-CNN-HTSVM (Hierarchical Tree Support Vector Machine classifier) architecture which uses a predefined knowledge-based set of rules with statistical machine learning techniques. Here we show that gross errors present even in state-of-the-art systems can be avoided and that an accurate acoustic model can be built in a hierarchical fashion. The CNNHTSVM acoustic model outperforms traditional GMM-HMM (Gaussian Mixture Model - Hidden Markov Model) models and the HTSVM structure outperforms a MLP multi-class classifier. More importantly we isolate the performance of the acoustic model and provide results on both the frame and phoneme level, considering the true robustness of the model. We show that even with a small amount of data, accurate and robust recognition rates can be obtained.","",""
10,"Yi Wang, Yi Li, M. Xiong, Li Jin","Random bits regression: a strong general predictor for big data",2015,"","","","",130,"2022-07-13 09:25:19","","10.1186/s41044-016-0010-4","","",,,,,10,1.43,3,4,7,"","",""
8,"K. Reddy, S. Somasundharam","An Inverse Method for Simultaneous Estimation of Thermal Properties of Orthotropic Materials using Gaussian Process Regression",2016,"","","","",131,"2022-07-13 09:25:19","","10.1088/1742-6596/745/3/032090","","",,,,,8,1.33,4,2,6,"In this work, inverse heat conduction problem (IHCP) involving the simultaneous estimation of principal thermal conductivities (kxx,kyy,kzz ) and specific heat capacity of orthotropic materials is solved by using surrogate forward model. Uniformly distributed random samples for each unknown parameter is generated from the prior knowledge about these parameters and Finite Volume Method (FVM) is employed to solve the forward problem for temperature distribution with space and time. A supervised machine learning technique- Gaussian Process Regression (GPR) is used to construct the surrogate forward model with the available temperature solution and randomly generated unknown parameter data. The statistical and machine learning toolbox available in MATLAB R2015b is used for this purpose. The robustness of the surrogate model constructed using GPR is examined by carrying out the parameter estimation for 100 new randomly generated test samples at a measurement error of ±0.3K. The temperature measurement is obtained by adding random noise with the mean at zero and known standard deviation (σ = 0.1) to the FVM solution of the forward problem. The test results show that Mean Percentage Deviation (MPD) of all test samples for all parameters is < 10%.","",""
29,"Y. Oussar, I. Ahriz, B. Denby, G. Dreyfus","Indoor localization based on cellular telephony RSSI fingerprints containing very large numbers of carriers",2011,"","","","",132,"2022-07-13 09:25:19","","10.1186/1687-1499-2011-81","","",,,,,29,2.64,7,4,11,"","",""
7,"Martina Friese, T. Bartz-Beielstein","BUILDING ENSEMBLES OF SURROGATES BY OPTIMAL CONVEX COMBINATION",2016,"","","","",133,"2022-07-13 09:25:19","","","","",,,,,7,1.17,4,2,6,"When using machine learning techniques for learning a function approximation from given data it can be di cult to select the right modelling technique. Without preliminary knowledge about the function it might be beneficial if the algorithm could learn all models by itself and select the model that suits best to the problem, an approach known as automated model selection. We propose a generalization of this approach that also allows to combine the predictions of several surrogate models into one more accurate ensemble surrogate model. This approach is studied in a fundamental way, by first evaluating minimalistic ensembles of only two surrogate models in detail and then proceeding to ensembles with more surrogate models. The results show to what extent combinations of models can perform better than single surrogate models and provide insights into the scalability and robustness of the approach. The focus is on multi-modal functions which are important in surrogate-assisted global optimization.","",""
9,"R. Das Roy, D. Dash","Selection of relevant features from amino acids enables development of robust classifiers",2014,"","","","",134,"2022-07-13 09:25:19","","10.1007/s00726-014-1697-z","","",,,,,9,1.13,5,2,8,"","",""
53,"R. Alcalá, J. Alcalá-Fdez, María José Gacto, F. Herrera","Improving fuzzy logic controllers obtained by experts: a case study in HVAC systems",2009,"","","","",135,"2022-07-13 09:25:19","","10.1007/s10489-007-0107-6","","",,,,,53,4.08,13,4,13,"","",""
9,"Chu-Ren Huang, Nianwen Xue","Words without Boundaries: Computational Approaches to Chinese Word Segmentation",2012,"","","","",136,"2022-07-13 09:25:19","","10.1002/LNC3.357","","",,,,,9,0.90,5,2,10,"The fact that words are not conventionally demarcated in Chinese orthography makes the process of word segmentation non-trivial. Chinese word segmentation remains a challenging topic in Chinese computational linguistics. We survey previous approaches to Chinese word segmentation, including dictionary look-up, strength of internal binding, as well as character tagging and machine learning. The Word Boundary Decision (WBD) approach which requires no prior lexical knowledge is proposed. It is shown that the WBD model greatly reduces the complexity of Chinese word segmentation and may provide a promising approach to address domain adaption and robustness issues.","",""
43,"D. Magness, F. Huettmann, J. Morton","Using Random Forests to Provide Predicted Species Distribution Maps as a Metric for Ecological Inventory & Monitoring Programs",2008,"","","","",137,"2022-07-13 09:25:19","","10.1007/978-3-540-78534-7_9","","",,,,,43,3.07,14,3,14,"","",""
9,"H. Zou, Hao Sun, K. Ji","Real-time infrared pedestrian detection via sparse representation",2012,"","","","",138,"2022-07-13 09:25:19","","10.1109/CVRS.2012.6421259","","",,,,,9,0.90,3,3,10,"This paper presents a simple, novel, yet very powerful approach for real-time infrared pedestrian detection based on random projection. In our framework, firstly, a feature-centric efficient sliding window scheme is proposed for candidate pedestrians searching. Different from the traditional threshold or edge based region of interest (ROI) generation techniques, it performs robustly under different scenes without delicate parameter tuning. Secondly, at the feature extraction stage, a small set of random features is extracted from local image patches. To the best of our knowledge, this paper is the first to investigate random projection (RP) for infrared pedestrian feature representation. Finally, the random features in a pyramid grid are concatenated to perform sub-image classification using a support vector machine (SVM) classifier. In our case, both learning and classification are carried out in a compressed domain. Experimental results in various scenarios demonstrate the robustness and effectiveness of our method.","",""
11,"D. Moody, S. Brumby, Kary L. Myers, N. Pawley","Sparse classification of rf transients using chirplets and learned dictionaries",2011,"","","","",139,"2022-07-13 09:25:19","","10.1109/ACSSC.2011.6190351","","",,,,,11,1.00,3,4,11,"We assess the performance of a sparse classification approach for radiofrequency (RF) transient signals using dictionaries adapted to the data. We explore two approaches: pursuit-type decompositions over analytical, over-complete dictionaries, and dictionaries learned directly from data. Pursuit-type decompositions over analytical, over-complete dictionaries yield sparse representations by design and can work well for target signals in the same function class as the dictionary atoms. Discriminative dictionaries learned directly from data do not rely on analytical constraints or additional knowledge about the signal characteristics, and provide sparse representations that can perform well when used with a statistical classifier. We present classification results for learned dictionaries on simulated test data, and discuss robustness compared to conventional Fourier methods. We draw from techniques of adaptive feature extraction, statistical machine learning, and image processing.","",""
6,"A. Veillard, S. Bressan, D. Racoceanu","SVM-based Framework for the Robust Extraction of Objects from Histopathological Images Using Color, Texture, Scale and Geometry",2012,"","","","",140,"2022-07-13 09:25:19","","10.1109/ICMLA.2012.21","","",,,,,6,0.60,2,3,10,"The extraction of nuclei from Haematoxylin and Eosin (H&E) stained biopsies present a particularly steep challenge in part due to the irregularity of the high-grade (most malignant) tumors. To your best knowledge, although some existing solutions perform adequately with relatively predictable low-grade cancers, solutions for the problematic high-grade cancers have yet to be proposed. In this paper, we propose a method for the extraction of cell nuclei from H&E stained biopsies robust enough to deal with the full range of histological grades observed in daily clinical practice. The robustness is achieved by combining a wide range of information including color, texture, scale and geometry in a multi-stage, Support Vector Machine (SVM) based framework to replace the original image with a new, probabilistic image modality with stable characteristics. The actual extraction of the nuclei is performed from the new image using Mark Point Processes (MPP), a state-of-the-art stochastic method. An empirical evaluation on clinical data provided and annotated by pathologists shows that our method greatly improves detection and extraction results, and provides a reliable solution with high grade cancers. Moreover, our method based on machine learning can easily adapt to specific clinical conditions. In many respects, our method contributes to bridging the gap between the computer vision technologies and their actual clinical use for breast cancer grading.","",""
30,"Johan Bos, K. Markert","Recognising Textual Entailment with Robust Logical Inference",2005,"","","","",141,"2022-07-13 09:25:19","","10.1007/11736790_23","","",,,,,30,1.76,15,2,17,"","",""
14,"Gyeongyong Heo, P. Gader","Fuzzy SVM for noisy data: A robust membership calculation method",2009,"","","","",142,"2022-07-13 09:25:19","","10.1109/FUZZY.2009.5277191","","",,,,,14,1.08,7,2,13,"Support vector machine (SVM) is a theoretically well motivated algorithm developed from statistical learning theory, that have shown good performance in many fields. In spite of its success, it still suffers from a noise sensitivity problem. To relax this problem, the SVM was extended by the introduction of fuzzy memberships to the fuzzy SVM (FSVM). The FSVM also has been extended further in two ways: by adopting a different objective function with the help of domain-specific knowledge and by employing a different membership calculation method. In this paper, we propose a new membership calculation method, that belongs to the second group. It is different from previous ones in that it does not assume any simple data distribution and does not need any prior knowledge. The proposed method is based on reconstruction error, which measures the agreement between the overall data structure and a data point. Thus the reconstruction error can represent the degree of outlier-ness and help in achieving noise robustness. Experimental results with synthetic and real data sets also support this.","",""
6,"Yoshitaka Kameya","Time Series Discretization via MDL-Based Histogram Density Estimation",2011,"","","","",143,"2022-07-13 09:25:19","","10.1109/ICTAI.2011.115","","",,,,,6,0.55,6,1,11,"In knowledge discovery from real-valued time series, discretization is often a key preprocessing that extends the applicability of sophisticated tools for symbolic data mining or logic-based machine learning. For finding meaningful discrete values that can be directly translated into some intuitive symbols, this paper proposes a novel discretization method based on density estimation using a two-dimensional (measurement vs. time) histogram of variable-width bins. We extend Kontkanen and Myllymaki's histogram construction method into our two dimensional case, keeping the efficiency brought by dynamic programming. Experimental results with artificial and real datasets show the robustness and the usefulness of the proposed method.","",""
12,"Chin-Hui Lee","Principles of Spoken Language Recognition",2008,"","","","",144,"2022-07-13 09:25:19","","10.1007/978-3-540-49127-9_39","","",,,,,12,0.86,12,1,14,"","",""
6,"M. Mramor, Marko Toplak, Gregor Leban, Tomaž Curk, J. Demšar, B. Zupan","On utility of gene set signatures in gene expression-based cancer class prediction",2009,"","","","",145,"2022-07-13 09:25:19","","","","",,,,,6,0.46,1,6,13,"Machine learning methods that can use additional knowledge in their inference process are central to the development of integrative bioinformatics. Inclusion of background knowledge improves robustness, predictive accuracy and interpretability. Recently, a set of such techniques has been proposed that use information on gene sets for supervised data mining of class-labeled microarray data sets. We here present a new gene set-based supervised learning approach named SetSig and systematically investigate the predictive accuracy of this and other gene set approaches compared to the standard inference model where only gene expression information is used. Our results indicate that SetSig outperforms other gene set approaches, but contrary to earlier reports, transformation of gene expression data to the space of gene set signatures does not result in increased accuracy of predictive models when compared to those trained directly from original (not transformed) data.","",""
7,"T. Krüger, Michael Mossner, J. Axmann, P. Vörsmann, Andreas Kuhn","Adaptive Flight Control for Unmanned Aircraft Using a Stable Neural Network Observer",2010,"","","","",146,"2022-07-13 09:25:19","","10.2514/6.2010-3396","","",,,,,7,0.58,1,5,12,"There is a high potential to improve the degree of automation of unmanned aerial systems (UAS) by implementing adaptive flight control strategies. This is especially the case in autonomous operation under difficult atmospheric conditions or even system failures. Machine learning techniques may enable the UAS to improve its control accuracy during operation and to respond to unknown, non-linear flight conditions. Here, artificial neural networks (ANN) are used to implement a learning flight control system. This is realised with a systematic two-stage approach by firstly implementing a sustainable offline-trained basic knowledge and improving these characteristics during flight. In the automated offline-step large groups of neural control elements are trained with the required behaviour, which is derived from measured data. This phase showed that the necessary learning task can be achieved by multi-layered feedforward-networks. The training success of all networks regarding generalisation capabilities and robustness is then evaluated with statistical methods and networks are selected for online application. The online learning step is realised with a controller architecture comprising a neural network controller and a neural observer which predicts the system’s dynamics and delivers the quality signal for contoller training. An important element of the control strategy is to determine a consistent error signal for online training of the neural controller. This is done by backpropagation of a measured error through the inverse dynamics of the observer network. Since the inverse dynamics have to be precise in order to train the controller adequately a stable network training algorithm is derived from the field sliding mode control (SMC), which significantly improves the observer’s charcteristics. In summary, the statisical analysis of the robustness of the basic knowledge as well as the implementation of a stable neural predictor into the control process proved to be central aspects of the control strategy.","",""
13,"Erinija Pranckevičienė, R. Somorjai, M. Tran","Feature/Model Selection by the Linear Programming SVM Combined with State-of-Art Classifiers: What Can We Learn About the Data",2007,"","","","",147,"2022-07-13 09:25:19","","10.1109/IJCNN.2007.4371201","","",,,,,13,0.87,4,3,15,"Many real-world classification problems are represented by very sparse and high-dimensional data. The recent successes of a linear programming support vector machine (LPSVM) for feature selection motivated a deeper analysis of the method when applied to sparse, multivariate data. Due to the sparseness, the selection of a classification model is greatly influenced by the characteristics of that particular dataset. In this study, we investigate a feature selection strategy based on LPSVM as the initial feature filter, combined with state-of-art classification rules, and apply to five real-life datasets of the agnostic learning vs. prior knowledge challenge of IJCNN2007. Our goal is to better understand the robustness of LPSVM as a feature filter. Our analysis suggests that LPSVM can be a useful black box method for identification of the profile of the informative features in the data. If the data are complex and better separable by nonlinear methods, then feature pre-filtering by LPSVM enhances the data representation for other classifiers.","",""
12,"C. Bauckhage, M. Hanheide, S. Wrede, Thomas Käster, M. Pfeiffer, G. Sagerer","Vision Systems with the Human in the Loop",2005,"","","","",148,"2022-07-13 09:25:19","","10.1155/ASP.2005.2375","","",,,,,12,0.71,2,6,17,"The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.","",""
9,"A. W. Example","Belief Propagation in Fuzzy Bayesian Networks",2008,"","","","",149,"2022-07-13 09:25:19","","","","",,,,,9,0.64,9,1,14,"Fuzzy Bayesian networks (FBN) are a graphical machine learning model representation with variables which are simultaneously fuzzy and uncertain[2]. Bayesian networks (BN) are commonly used in machine learning. This is due to their statistical rationality, capacity for rigorous causal inference, and robustness in the face of noisy, partially missing and realistic data. They are also more easily human-interpretable than other machine learning representations such as neural networks, and experts can specify prior knowledge in a principled manner to guide the machine learning search. A wide range of search algorithms have been developed for structural and parameter inference, including structural EM [3] and MCMC. Classically, Bayesian networks use continuous (Gaussian) or multinomial variables. Similarly, a fuzzy model has a wide range of advantages. Fuzzy models are also robust in the face of noise-corrupted data. The use of linguistic terms aids human comprehension of the learnt model, and they are particularly useful when the data is insufficient to formulate a precise model. The need to specify membership functions also forces the designer to consider the semantic interpretation of the model parameterisation and construction more explicitly. For these reasons, FBN (which combine these advantages) may be useful. Theoretical analysis in current research[1] indicates that fuzzy variables can be more expressive than multinomial or continuous variables. FBN may also be used as part of an integrated sequence of machine learning techniques that include reversible dimensionality reduction techniques such as fuzzy cover clustering algorithms. This may allow larger problems to be addressed with FBN than with classic BN.","",""
10,"Zhiqiang Geng, Qunxiong Zhu","A New Rough set-based Heuristic Algorithm for Attribute Reduct",2006,"","","","",150,"2022-07-13 09:25:19","","10.1109/WCICA.2006.1712934","","",,,,,10,0.63,5,2,16,"Learning algorithms of data mining are known to degrade in performance when faced with many attributes that are not necessary for rule discovery. Rough set theory has been a topic of general interest in the field of knowledge discovery. A new rough set-based greedy heuristic algorithm is proposed for attributes reduct and emphasized the role of basic constructs of rough set approach. The approach can select an optimal subset of attributes quickly and effectively from a large database with a lot of attributes. So the sensitivity of rough set to noise can be depressed and the system's robustness is to be improved. The validity of the proposed algorithms is verified by comparing with genetic algorithms, Johnson's algorithm and dynamic reducts in using practical machine learning databases","",""
4,"D. Tjondronegoro, Yi-Ping Phoebe Chen","Using Decision-Tree to Automatically Construct Learned-Heuristics for Events Classification in Sports Video",2006,"","","","",151,"2022-07-13 09:25:19","","10.1109/ICME.2006.262818","","",,,,,4,0.25,2,2,16,"Automatic events classification is an essential requirement for constructing an effective sports video summary. It has become a well-known theory that the high-level semantics in sport video can be ""computationally interpreted"" based on the occurrences of specific audio and visual features which can be extracted automatically. State-of-the-art solutions for features-based event classification have only relied on either manual-knowledge based heuristics or machine learning. To bridge the gaps, we have successfully combined the two approaches by using learning-based heuristics. The heuristics are constructed automatically using decision tree while manual supervision is only required to check the features and highlight contained in each training segment. Thus, fully automated construction of classification system for sports video events has been achieved. A comprehensive experiment on 10 hours video dataset, with five full-match soccer and five full-match basketball videos, has demonstrated the effectiveness/robustness of our algorithms","",""
5,"A. Takác","Cellular Genetic Programming Algorithm Applied to Classification Task",2004,"","","","",152,"2022-07-13 09:25:19","","","","",,,,,5,0.28,5,1,18,"The focus of this paper is the application of the genetic programming framework in the problem of knowledge discovery in databases, more precisely in the task of classification. Genetic programming possesses certain advantages that make it suitable for application in data mining, such as robustness of algorithm or its convenient structure for rule generation to name a few. This study concentrates on one type of parallel genetic algorithms – cellular (diffusion) model. Emphasis is placed on the improvement of efficiency and scalability of the data mining algorithm, which could be achieved by integrating the algorithm with databases and employing a cellular framework. Cellular model of genetic programming that exploits SQL queries is implemented and applied to the classification task. Achieved results are presented and compared with other machine learning algorithms.","",""
6,"D. Luzeaux, B. Zavidovique","Acquisition of a qualitative model",1990,"","","","",153,"2022-07-13 09:25:19","","10.1145/98784.98864","","",,,,,6,0.19,3,2,32,"The application exposed below is part of a vast program which aims to enable a system to control a process without any initial knowledge about itI3,2]. The targeted control is very similar to a rule-based contro1[4,6,12], the main difference is that we do not consider a fixed set of rules : the rules may be improved by a machine learning loop. These rules create a similar behavior to reflex rules, at each sampling time, one of them is selected and fired, the system reacting “instinctively” to each little variation of the external world. The consequence is a robustness which is not granted by more conventional ways of controlliug varying processes in unknown worlds.","",""
3,"Suk Joon Hong, B. Bennett","Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning and Machine Learning",2020,"","","","",154,"2022-07-13 09:25:19","","10.4230/OASIcs.LDK.2021.41","","",,,,,3,1.50,2,2,2,"The Winograd Schema Challenge (WSC) is a common-sense reasoning task that requires background knowledge. In this paper, we contribute to tackling WSC in four ways. Firstly, we suggest a keyword method to define a restricted domain where distinctive high-level semantic patterns can be found. A thanking domain was defined by key-words, and the data set in this domain is used in our experiments. Secondly, we develop a high-level knowledge-based reasoning method using semantic roles which is based on the method of Sharma [2019]. Thirdly, we propose an ensemble method to combine knowledge-based reasoning and machine learning which shows the best performance in our experiments. As a machine learning method, we used Bidirectional Encoder Representations from Transformers (BERT) [Kocijan et al., 2019]. Lastly, in terms of evaluation, we suggest a ""robust"" accuracy measurement by modifying that of Trichelair et al. [2018]. As with their switching method, we evaluate a model by considering its performance on trivial variants of each sentence in the test set.","",""
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",155,"2022-07-13 09:25:19","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
17,"Zhenfeng Lei, Yuandong Sun, Y. Nanehkaran, Shuangyuan Yang, Md. Saiful Islam, Huiqing Lei, De-fu Zhang","A novel data-driven robust framework based on machine learning and knowledge graph for disease classification",2020,"","","","",156,"2022-07-13 09:25:19","","10.1016/j.future.2019.08.030","","",,,,,17,8.50,2,7,2,"","",""
665,"Weihua Hu, Matthias Fey, M. Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, J. Leskovec","Open Graph Benchmark: Datasets for Machine Learning on Graphs",2020,"","","","",157,"2022-07-13 09:25:19","","","","",,,,,665,332.50,83,8,2,"We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .","",""
87,"G. Peng, M. Alber, A. Buganza Tepole, W. R. Cannon, S. De, Savador Dura-Bernal, K. Garikipati, G. Karniadakis, W. Lytton, P. Perdikaris, L. Petzold, E. Kuhl","Multiscale modeling meets machine learning: What can we learn?",2019,"","","","",158,"2022-07-13 09:25:19","","10.1007/s11831-020-09405-5","","",,,,,87,29.00,9,12,3,"","",""
75,"K. Kashinath, M. Mustafa, A. Albert, J.-L. Wu, C. Jiang, S. Esmaeilzadeh, K. Azizzadenesheli, R. Wang, A. Chattopadhyay, A. Singh, A. Manepalli, D. Chirila, R. Yu, R. Walters, B. White, H. Xiao, H. Tchelepi, P. Marcus, A. Anandkumar, P. Hassanzadeh, Prabhat","Physics-informed machine learning: case studies for weather and climate modelling",2021,"","","","",159,"2022-07-13 09:25:19","","10.1098/rsta.2020.0093","","",,,,,75,75.00,8,21,1,"Machine learning (ML) provides novel and powerful ways of accurately and efficiently recognizing complex patterns, emulating nonlinear dynamics, and predicting the spatio-temporal evolution of weather and climate processes. Off-the-shelf ML models, however, do not necessarily obey the fundamental governing laws of physical systems, nor do they generalize well to scenarios on which they have not been trained. We survey systematic approaches to incorporating physics and domain knowledge into ML models and distill these approaches into broad categories. Through 10 case studies, we show how these approaches have been used successfully for emulating, downscaling, and forecasting weather and climate processes. The accomplishments of these studies include greater physical consistency, reduced training time, improved data efficiency, and better generalization. Finally, we synthesize the lessons learned and identify scientific, diagnostic, computational, and resource challenges for developing truly robust and reliable physics-informed ML models for weather and climate processes. This article is part of the theme issue ‘Machine learning for weather and climate modelling’.","",""
23,"Sina Shaham, Ming Ding, Bo Liu, Shuping Dang, Zihuai Lin, Jun Li","Privacy Preserving Location Data Publishing: A Machine Learning Approach",2019,"","","","",160,"2022-07-13 09:25:19","","10.1109/tkde.2020.2964658","","",,,,,23,7.67,4,6,3,"Publishing datasets plays an essential role in open data research and promoting transparency of government agencies. However, such data publication might reveal users’ private information. One of the most sensitive sources of data is spatiotemporal trajectory datasets. Unfortunately, merely removing unique identifiers cannot preserve the privacy of users. Adversaries may know parts of the trajectories or be able to link the published dataset to other sources for the purpose of user identification. Therefore, it is crucial to apply privacy preserving techniques before the publication of spatiotemporal trajectory datasets. In this paper, we propose a robust framework for the anonymization of spatiotemporal trajectory datasets termed as machine learning based anonymization (MLA). By introducing a new formulation of the problem, we are able to apply machine learning algorithms for clustering the trajectories and propose to use <inline-formula><tex-math notation=""LaTeX"">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=""shaham-ieq1-2964658.gif""/></alternatives></inline-formula>-means algorithm for this purpose. A variation of <inline-formula><tex-math notation=""LaTeX"">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=""shaham-ieq2-2964658.gif""/></alternatives></inline-formula>-means algorithm is also proposed to preserve the privacy in overly sensitive datasets. Moreover, we improve the alignment process by considering multiple sequence alignment as part of the MLA. The framework and all the proposed algorithms are applied to T-Drive, Geolife, and Gowalla location datasets. The experimental results indicate a significantly higher utility of datasets by anonymization based on MLA framework.","",""
22,"F. Emmert‐Streib, M. Dehmer","A Machine Learning Perspective on Personalized Medicine: An Automized, Comprehensive Knowledge Base with Ontology for Pattern Recognition",2018,"","","","",161,"2022-07-13 09:25:19","","10.3390/MAKE1010009","","",,,,,22,5.50,11,2,4,"Personalized or precision medicine is a new paradigm that holds great promise for individualized patient diagnosis, treatment, and care. However, personalized medicine has only been described on an informal level rather than through rigorous practical guidelines and statistical protocols that would allow its robust practical realization for implementation in day-to-day clinical practice. In this paper, we discuss three key factors, which we consider dimensions that effect the experimental design for personalized medicine: (I) phenotype categories; (II) population size; and (III) statistical analysis. This formalization allows us to define personalized medicine from a machine learning perspective, as an automized, comprehensive knowledge base with an ontology that performs pattern recognition of patient profiles.","",""
16,"Yonghan Jung, Jin Tian, E. Bareinboim","Estimating Identifiable Causal Effects through Double Machine Learning",2021,"","","","",162,"2022-07-13 09:25:19","","","","",,,,,16,16.00,5,3,1,"Identifying causal effects from observational data is a perva- sive challenge found throughout the empirical sciences. Very general methods have been developed to decide the identiﬁ- ability of a causal quantity from a combination of observational data and causal knowledge about the underlying sys- tem. In practice, however, there are still challenges to estimating identiﬁable causal functionals from ﬁnite samples. Re- cently, a method known as double/debiased machine learning (DML) (Chernozhukov et al. 2018) has been proposed to learn parameters leveraging modern machine learning techniques, which is both robust to model misspeciﬁcation and bias-reducing. Still, DML has only been used for causal estimation in settings when the back-door condition (also known as conditional ignorability) holds. In this paper, we develop a new, general class of estimators for any identiﬁable causal functionals that exhibit DML properties, which we name DML-ID. In particular, we introduce a complete identiﬁca- tion algorithm that returns an inﬂuence function (IF) for any identiﬁable causal functional. We then construct the DML es- timator based on the derived IF. We show that DML-ID estimators hold the key properties of debiasedness and doubly robustness. Simulation results corroborate with the theory.","",""
21,"A. Naimi, Alan Mishler, Edward H. Kennedy","Challenges in Obtaining Valid Causal Effect Estimates with Machine Learning Algorithms.",2017,"","","","",163,"2022-07-13 09:25:19","","10.1093/aje/kwab201","","",,,,,21,4.20,7,3,5,"Unlike parametric regression, machine learning (ML) methods do not generally require precise knowledge of the true data generating mechanisms. As such, numerous authors have advocated for ML methods to estimate causal effects. Unfortunately, ML algorithmscan perform worse than parametric regression. We demonstrate the performance of ML-based single- and double-robust estimators. We use 100 Monte Carlo samples with sample sizes of 200, 1200, and 5000 to investigate bias and confidence interval coverage under several scenarios. In a simple confounding scenario, confounders were related to the treatment and the outcome via parametric models. In a complex confounding scenario, the simple confounders were transformed to induce complicated nonlinear relationships. In the simple scenario, when ML algorithms were used, double-robust estimators were superior to single-robust estimators. In the complex scenario, single-robust estimators with ML algorithms were at least as biased as estimators using misspecified parametric models. Double-robust estimators were less biased, but coverage was well below nominal. The use of sample splitting, inclusion of confounder interactions, reliance on a richly specified ML algorithm, and use of doubly robust estimators was the only explored approach that yielded negligible bias and nominal coverage. Our results suggest that ML based singly robust methods should be avoided.","",""
6,"C. Yeomans, R. Shail, S. Grebby, V. Nykänen, M. Middleton, P. Lusty","A machine learning approach to tungsten prospectivity modelling using knowledge-driven feature extraction and model confidence",2019,"","","","",164,"2022-07-13 09:25:19","","10.31223/osf.io/9fet8","","",,,,,6,2.00,1,6,3,"Abstract Novel mineral prospectivity modelling presented here applies knowledge-driven feature extraction to a data-driven machine learning approach for tungsten mineralisation. The method emphasises the importance of appropriate model evaluation and develops a new Confidence Metric to generate spatially refined and robust exploration targets. The data-driven Random Forest™ algorithm is employed to model tungsten mineralisation in SW England using a range of geological, geochemical and geophysical evidence layers which include a depth to granite evidence layer. Two models are presented, one using standardised input variables and a second that implements fuzzy set theory as part of an augmented feature extraction step. The use of fuzzy data transformations mean feature extraction can incorporate some user-knowledge about the mineralisation into the model. The typically subjective approach is guided using the Receiver Operating Characteristics (ROC) curve tool where transformed data are compared to known training samples. The modelling is conducted using 34 known true positive samples with 10 sets of randomly generated true negative samples to test the random effect on the model. The two models have similar accuracy but show different spatial distributions when identifying highly prospective targets. Areal analysis shows that the fuzzy-transformed model is a better discriminator and highlights three areas of high prospectivity that were not previously known. The Confidence Metric, derived from model variance, is employed to further evaluate the models. The new metric is useful for refining exploration targets and highlighting the most robust areas for follow-up investigation. The fuzzy-transformed model is shown to contain larger areas of high model confidence compared to the model using standardised variables. Finally, legacy mining data, from drilling reports and mine descriptions, is used to further validate the fuzzy-transformed model and gauge the depth of potential deposits. Descriptions of mineralisation corroborate that the targets generated in these models could be undercover at depths of less than 300 ​m. In summary, the modelling workflow presented herein provides a novel integration of knowledge-driven feature extraction with data-driven machine learning modelling, while the newly derived Confidence Metric generates reliable mineral exploration targets.","",""
14,"M. Levine, A. Stuart","A Framework for Machine Learning of Model Error in Dynamical Systems",2021,"","","","",165,"2022-07-13 09:25:19","","","","",,,,,14,14.00,7,2,1,"The development of data-informed predictive models for dynamical systems is of widespread interest in many disciplines. We present a unifying framework for blending mechanistic and machine-learning approaches to identify dynamical systems from noisily and partially observed data. We compare pure data-driven learning with hybrid models which incorporate imperfect domain knowledge, referring to the discrepancy between an assumed truth model and the imperfect mechanistic model as model error. Our formulation is agnostic to the chosen machine learning model, is presented in both continuousand discrete-time settings, and is compatible both with model errors that exhibit substantial memory and errors that are memoryless. First, we study memoryless linear (w.r.t. parametric-dependence) model error from a learning theory perspective, defining excess risk and generalization error. For ergodic continuous-time systems, we prove that both excess risk and generalization error are bounded above by terms that diminish with the square-root of T , the time-interval over which training data is specified. Secondly, we study scenarios that benefit from modeling with memory, proving universal approximation theorems for two classes of continuous-time recurrent neural networks (RNNs): both can learn memory-dependent model error, assuming that it is governed by a finite-dimensional hidden variable and that, together, the observed and hidden variables form a continuous-time Markovian system. In addition, we connect one class of RNNs to reservoir computing, thereby relating learning of memory-dependent error to recent work on supervised learning between Banach spaces using random features. Numerical results are presented (Lorenz ’63, Lorenz ’96 Multiscale systems) to compare purely data-driven and hybrid approaches, finding hybrid methods less data-hungry and more parametrically efficient. We also find that, while a continuous-time framing allows for robustness to irregular sampling and desirable domain-interpretability, a discrete-time framing can provide similar or better predictive performance, especially when data are undersampled and the vector field defining the true dynamics cannot be identified. Finally, we demonstrate numerically how data assimilation can be leveraged to learn hidden dynamics from noisy, partially-observed data, and illustrate challenges in representing memory by this approach, and in the training of such models. Received by the editors July 13, 2021. 2020 Mathematics Subject Classification. Primary 68T30, 37A30, 37M10; Secondary 37M25,","",""
14,"M. Vollmer, B. Glampson, T. Mellan, Swapnil Mishra, L. Mercuri, Ceire Costello, R. Klaber, G. Cooke, S. Flaxman, S. Bhatt","A unified machine learning approach to time series forecasting applied to demand at emergency departments",2020,"","","","",166,"2022-07-13 09:25:19","","10.1186/s12873-020-00395-y","","",,,,,14,7.00,1,10,2,"","",""
25,"H. Yoon, Jae-Hoon Sim, M. Han","Analytic continuation via domain knowledge free machine learning",2018,"","","","",167,"2022-07-13 09:25:19","","10.1103/PhysRevB.98.245101","","",,,,,25,6.25,8,3,4,"We present a machine-learning approach to a long-standing issue in quantum many-body physics, namely, analytic continuation. This notorious ill-conditioned problem of obtaining spectral function from an imaginary time Green's function has been a focus of new method developments for past decades. Here we demonstrate the usefulness of modern machine-learning techniques including convolutional neural networks and the variants of a stochastic gradient descent optimizer. The machine-learning continuation kernel is successfully realized without any ``domain knowledge,'' which means that any physical ``prior'' is not utilized in the kernel construction and the neural networks ``learn'' the knowledge solely from ``training.'' The outstanding performance is achieved for both insulating and metallic band structure. Our machine-learning-based approach not only provides the more accurate spectrum than the conventional methods in terms of peak positions and heights, but is also more robust against the noise which is the required key feature for any continuation technique to be successful. Furthermore, its computation speed is ${10}^{4}\text{--}{10}^{5}$ times faster than the maximum entropy method.","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",168,"2022-07-13 09:25:19","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
75,"M. Prosperi, Yi Guo, M. Sperrin, J. Koopman, Jae Min, Xing He, S. Rich, Mo Wang, I. Buchan, J. Bian","Causal inference and counterfactual prediction in machine learning for actionable healthcare",2020,"","","","",169,"2022-07-13 09:25:19","","10.1038/s42256-020-0197-y","","",,,,,75,37.50,8,10,2,"","",""
5,"Furkan M. Torun, S. V. Winter, Sophia Doll, Felix M. Riese, A. Vorobyev, Johannes B. Mueller‐Reif, Philipp E. Geyer, Maximilian T. Strauss","Transparent exploration of machine learning for biomarker discovery from proteomics and omics data",2021,"","","","",170,"2022-07-13 09:25:19","","10.1101/2021.03.05.434053","","",,,,,5,5.00,1,8,1,"Biomarkers are of central importance for assessing the health state and to guide medical interventions and their efficacy, but they are lacking for most diseases. Mass spectrometry (MS)-based proteomics is a powerful technology for biomarker discovery, but requires sophisticated bioinformatics to identify robust patterns. Machine learning (ML) has become indispensable for this purpose, however, it is sometimes applied in an opaque manner, generally requires expert knowledge and complex and expensive software. To enable easy access to ML for biomarker discovery without any programming or bioinformatic skills, we developed ‘OmicLearn’ (https://OmicLearn.com), an open-source web-based ML tool using the latest advances in the Python ML ecosystem. We host a web server for the exploration of the researcher’s results that can readily be cloned for internal use. Output tables from proteomics experiments are easily uploaded to the central or a local webserver. OmicLearn enables rapid exploration of the suitability of various ML algorithms for the experimental datasets. It fosters open science via transparent assessment of state-of-the-art algorithms in a standardized format for proteomics and other omics sciences. Graphical Abstract Highlights OmicLearn is an open-source platform allows researchers to apply machine learning (ML) for biomarker discovery The ready-to-use structure of OmicLearn enables accessing state-of-the-art ML algorithms without requiring any prior bioinformatics knowledge OmicLearn’s web-based interface provides an easy-to-follow platform for classification and gaining insights into the dataset Several algorithms and methods for preprocessing, feature selection, classification and cross-validation of omics datasets are integrated All results, settings and method text can be exported in publication-ready formats","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",171,"2022-07-13 09:25:19","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",172,"2022-07-13 09:25:19","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
242,"Yudong Chen, Lili Su, Jiaming Xu","Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent",2017,"","","","",173,"2022-07-13 09:25:19","","10.1145/3308809.3308857","","",,,,,242,48.40,81,3,5,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server andm working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of them working machines suffer Byzantine faults - a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks.","",""
21,"Christopher Culley, S. Vijayakumar, Guido Zampieri, C. Angione","A mechanism-aware and multiomic machine-learning pipeline characterizes yeast cell growth",2020,"","","","",174,"2022-07-13 09:25:19","","10.1073/pnas.2002959117","","",,,,,21,10.50,5,4,2,"Significance Linking genotype and phenotype is a fundamental problem in biology, key to several biomedical and biotechnological applications. Cell growth is a central phenotypic trait, resulting from interactions between environment, gene regulation, and metabolism, yet its functional bases are still not completely understood. We propose and test a machine-learning approach that integrates large-scale gene expression profiles and mechanistic metabolic models, for characterizing cell growth and understanding its driving mechanisms in Saccharomyces cerevisiae. At its core, a custom-built multimodal learning method merges experimentally generated and model-generated data. We show that our approach can leverage the advantages of both machine learning and metabolic modeling, revealing unknown interactions between biological domains, incorporating mechanistic knowledge, and therefore overcoming black-box limitations of conventional data-driven approaches. Metabolic modeling and machine learning are key components in the emerging next generation of systems and synthetic biology tools, targeting the genotype–phenotype–environment relationship. Rather than being used in isolation, it is becoming clear that their value is maximized when they are combined. However, the potential of integrating these two frameworks for omic data augmentation and integration is largely unexplored. We propose, rigorously assess, and compare machine-learning–based data integration techniques, combining gene expression profiles with computationally generated metabolic flux data to predict yeast cell growth. To this end, we create strain-specific metabolic models for 1,143 Saccharomyces cerevisiae mutants and we test 27 machine-learning methods, incorporating state-of-the-art feature selection and multiview learning approaches. We propose a multiview neural network using fluxomic and transcriptomic data, showing that the former increases the predictive accuracy of the latter and reveals functional patterns that are not directly deducible from gene expression alone. We test the proposed neural network on a further 86 strains generated in a different experiment, therefore verifying its robustness to an additional independent dataset. Finally, we show that introducing mechanistic flux features improves the predictions also for knockout strains whose genes were not modeled in the metabolic reconstruction. Our results thus demonstrate that fusing experimental cues with in silico models, based on known biochemistry, can contribute with disjoint information toward biologically informed and interpretable machine learning. Overall, this study provides tools for understanding and manipulating complex phenotypes, increasing both the prediction accuracy and the extent of discernible mechanistic biological insights.","",""
14,"Zi Zhang, Hong Pan, Xingyu Wang, Zhibin Lin","Machine Learning-Enriched Lamb Wave Approaches for Automated Damage Detection",2020,"","","","",175,"2022-07-13 09:25:19","","10.3390/s20061790","","",,,,,14,7.00,4,4,2,"Lamb wave approaches have been accepted as efficiently non-destructive evaluations in structural health monitoring for identifying damage in different states. Despite significant efforts in signal process of Lamb waves, physics-based prediction is still a big challenge due to complexity nature of the Lamb wave when it propagates, scatters and disperses. Machine learning in recent years has created transformative opportunities for accelerating knowledge discovery and accurately disseminating information where conventional Lamb wave approaches cannot work. Therefore, the learning framework was proposed with a workflow from dataset generation, to sensitive feature extraction, to prediction model for lamb-wave-based damage detection. A total of 17 damage states in terms of different damage type, sizes and orientations were designed to train the feature extraction and sensitive feature selection. A machine learning method, support vector machine (SVM), was employed for the learning model. A grid searching (GS) technique was adopted to optimize the parameters of the SVM model. The results show that the machine learning-enriched Lamb wave-based damage detection method is an efficient and accuracy wave to identify the damage severity and orientation. Results demonstrated that different features generated from different domains had certain levels of sensitivity to damage, while the feature selection method revealed that time-frequency features and wavelet coefficients exhibited the highest damage-sensitivity. These features were also much more robust to noise. With increase of noise, the accuracy of the classification dramatically dropped.","",""
12,"H. Sufriyana, Yu-Wei Wu, E. C. Su","Prediction of Preeclampsia and Intrauterine Growth Restriction: Development of Machine Learning Models on a Prospective Cohort",2020,"","","","",176,"2022-07-13 09:25:19","","10.2196/15411","","",,,,,12,6.00,4,3,2,"Background Preeclampsia and intrauterine growth restriction are placental dysfunction–related disorders (PDDs) that require a referral decision be made within a certain time period. An appropriate prediction model should be developed for these diseases. However, previous models did not demonstrate robust performances and/or they were developed from datasets with highly imbalanced classes. Objective In this study, we developed a predictive model of PDDs by machine learning that uses features at 24-37 weeks’ gestation, including maternal characteristics, uterine artery (UtA) Doppler measures, soluble fms-like tyrosine kinase receptor-1 (sFlt-1), and placental growth factor (PlGF). Methods A public dataset was taken from a prospective cohort study that included pregnant women with PDDs (66/95, 69%) and a control group (29/95, 31%). Preliminary selection of features was based on a statistical analysis using SAS 9.4 (SAS Institute). We used Weka (Waikato Environment for Knowledge Analysis) 3.8.3 (The University of Waikato, Hamilton, NZ) to automatically select the best model using its optimization algorithm. We also manually selected the best of 23 white-box models. Models, including those from recent studies, were also compared by interval estimation of evaluation metrics. We used the Matthew correlation coefficient (MCC) as the main metric. It is not overoptimistic to evaluate the performance of a prediction model developed from a dataset with a class imbalance. Repeated 10-fold cross-validation was applied. Results The classification via regression model was chosen as the best model. Our model had a robust MCC (.93, 95% CI .87-1.00, vs .64, 95% CI .57-.71) and specificity (100%, 95% CI 100-100, vs 90%, 95% CI 90-90) compared to each metric of the best models from recent studies. The sensitivity of this model was not inferior (95%, 95% CI 91-100, vs 100%, 95% CI 92-100). The area under the receiver operating characteristic curve was also competitive (0.970, 95% CI 0.966-0.974, vs 0.987, 95% CI 0.980-0.994). Features in the best model were maternal weight, BMI, pulsatility index of the UtA, sFlt-1, and PlGF. The most important feature was the sFlt-1/PlGF ratio. This model used an M5P algorithm consisting of a decision tree and four linear models with different thresholds. Our study was also better than the best ones among recent studies in terms of the class balance and the size of the case class (66/95, 69%, vs 27/239, 11.3%). Conclusions Our model had a robust predictive performance. It was also developed to deal with the problem of a class imbalance. In the context of clinical management, this model may improve maternal mortality and neonatal morbidity and reduce health care costs.","",""
11,"M. Elgendi, C. Menon","Machine Learning Ranks ECG as an Optimal Wearable Biosignal for Assessing Driving Stress",2020,"","","","",177,"2022-07-13 09:25:19","","10.1109/ACCESS.2020.2974933","","",,,,,11,5.50,6,2,2,"The demand for wearable devices that can detect anxiety and stress when driving is increasing. Recent studies have attempted to use multiple biosignals to detect driving stress. However, collecting multiple biosignals can be complex and is associated with numerous challenges. Determining the optimal biosignal for assessing driving stress can save lives. To the best of our knowledge, no study has investigated both longitudinal and transitional stress assessment using supervised and unsupervised ML techniques. Thus, this study hypothesizes that the optimal signal for assessing driving stress will consistently detect stress using supervised and unsupervised machine learning (ML) techniques. Two different approaches were used to assess driving stress: longitudinal (a combined repeated measurement of the same biosignals over three driving states) and transitional (switching from state to state such as city to highway driving). The longitudinal analysis did not involve a feature extraction phase while the transitional analysis involved a feature extraction phase. The longitudinal analysis consists of a novel interaction ensemble (INTENSE) that aggregates three unsupervised ML approaches: interaction principal component analysis, connectivity-based clustering, and K-means clustering. INTENSE was developed to uncover new knowledge by revealing the strongest correlation between the biosignal and driving stress marker. These three MLs each have their well-known and distinctive geometrical basis. Thus, the aggregation of their result would provide a more robust examination of the simultaneous non-causal associations between six biosignals: electrocardiogram (ECG), electromyogram, hand galvanic skin resistance, foot galvanic skin resistance, heart rate, respiration, and the driving stress marker. INTENSE indicates that ECG is highly correlated with the driving stress marker. The supervised ML algorithms confirmed that ECG is the most informative biosignal for detecting driving stress, with an overall accuracy of 75.02%.","",""
7,"Md. Kowsher, A. Tahabilder, S. Murad","Impact-Learning: A Robust Machine Learning Algorithm",2020,"","","","",178,"2022-07-13 09:25:19","","10.1145/3411174.3411185","","",,,,,7,3.50,2,3,2,"The ultimate goal of this research paper is to introduce a robust machine learning algorithm called Impact-Learning, which is being used widely to achieve more advanced results on many machine-learning related challenges. Impact learning is a supervised machine learning algorithm for resolving classification and linear or polynomial regression knowledge from examples. It also contributes to analyzing systems for competitive data. This algorithm is unique for being capable of learning from a competition, which is the impact of independent features. In other words, it is trained by the impacts of the features from the intrinsic rate of natural increase (RNI). The input to the Impact Learning is a training set of numerical data. In this work, we used six datasets related to regressions and classifications as the experiment of the Impact Learning, and the comparison indicates that at outperforms other standard machine learning regressions and classifications algorithms such as Random forest tree, SVM, Naive Bayes, Logistic regression and so forth.","",""
7,"D. Jacob","Cross-Fitting and Averaging for Machine Learning Estimation of Heterogeneous Treatment Effects",2020,"","","","",179,"2022-07-13 09:25:19","","","","",,,,,7,3.50,7,1,2,"We investigate the finite sample performance of sample splitting, cross-fitting and averaging for the estimation of the conditional average treatment effect. Recently proposed methods, so-called meta-learners, make use of machine learning to estimate different nuisance functions and hence allow for fewer restrictions on the underlying structure of the data. To limit a potential overfitting bias that may result when using machine learning methods, cross-fitting estimators have been proposed. This includes the splitting of the data in different folds to reduce bias and averaging over folds to restore efficiency. To the best of our knowledge, it is not yet clear how exactly the data should be split and averaged. We employ a Monte Carlo study with different data generation processes and consider twelve different estimators that vary in sample-splitting, cross-fitting and averaging procedures. We investigate the performance of each estimator independently on four different meta-learners: the doubly-robust-learner, R-learner, T-learner and X-learner. We find that the performance of all meta-learners heavily depends on the procedure of splitting and averaging. The best performance in terms of mean squared error (MSE) among the sample split estimators can be achieved when applying cross-fitting plus taking the median over multiple different sample-splitting iterations. Some meta-learners exhibit a high variance when the lasso is included in the ML methods. Excluding the lasso decreases the variance and leads to robust and at least competitive results.","",""
7,"Jina Suh, S. Ghorashi, Gonzalo A. Ramos, N. Chen, S. Drucker, J. Verwey, P. Simard","AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning",2019,"","","","",180,"2022-07-13 09:25:19","","10.1145/3241379","","",,,,,7,2.33,1,7,3,"When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.","",""
6,"Wienand A. Omta, Roy G. van Heesbeen, I. Shen, Jacob de Nobel, D. Robers, Lieke M. van der Velden, R. Medema, A. Siebes, A. Feelders, S. Brinkkemper, J. Klumperman, M. Spruit, Matthieu J. S. Brinkhuis, D. Egan","Combining Supervised and Unsupervised Machine Learning Methods for Phenotypic Functional Genomics Screening",2020,"","","","",181,"2022-07-13 09:25:19","","10.1177/2472555220919345","","",,,,,6,3.00,1,14,2,"There has been an increase in the use of machine learning and artificial intelligence (AI) for the analysis of image-based cellular screens. The accuracy of these analyses, however, is greatly dependent on the quality of the training sets used for building the machine learning models. We propose that unsupervised exploratory methods should first be applied to the data set to gain a better insight into the quality of the data. This improves the selection and labeling of data for creating training sets before the application of machine learning. We demonstrate this using a high-content genome-wide small interfering RNA screen. We perform an unsupervised exploratory data analysis to facilitate the identification of four robust phenotypes, which we subsequently use as a training set for building a high-quality random forest machine learning model to differentiate four phenotypes with an accuracy of 91.1% and a kappa of 0.85. Our approach enhanced our ability to extract new knowledge from the screen when compared with the use of unsupervised methods alone.","",""
5,"Dan Jiang, Weihua Lin, N. Raghavan","A Novel Framework for Semiconductor Manufacturing Final Test Yield Classification Using Machine Learning Techniques",2020,"","","","",182,"2022-07-13 09:25:19","","10.1109/ACCESS.2020.3034680","","",,,,,5,2.50,2,3,2,"Advanced data analysis tools and techniques are important for semiconductor companies to gain competitive advantage. In particular, yield prediction tools, which fully utilize production data, help to improve operational efficiency and reduce production costs. This paper introduces a novel and scalable framework for semiconductor manufacturing Final Test (FT) yield prediction leveraging machine learning techniques. This framework is able to predict FT yield at wafer fabrication stage, so that FT low yield problems can be caught at an earlier production stage compared to past studies. Our work presents a robust solution to automatically handle both numerical and categorical production related data without prior knowledge of the low yield root cause. Gaussian Mixture Models, One Hot Encoder and Label Encoder techniques are adopted for data pre-processing. To improve model performance for both binary and multi-class classification, model selection and model ensemble using the F1-macro method is demonstrated. The framework has been applied to three mass production products with different wafer technologies and manufacturing flows. All of them achieved high F1-macro test score indicative of the robustness of our framework.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",183,"2022-07-13 09:25:19","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
657,"Wieland Brendel, Jonas Rauber, M. Bethge","Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",2017,"","","","",184,"2022-07-13 09:25:19","","","","",,,,,657,131.40,219,3,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .","",""
37,"Tianwei Yu, Dean P. Jones","Improving peak detection in high-resolution LC/MS metabolomics data using preexisting knowledge and machine learning approach",2014,"","","","",185,"2022-07-13 09:25:19","","10.1093/bioinformatics/btu430","","",,,,,37,4.63,19,2,8,"MOTIVATION Peak detection is a key step in the preprocessing of untargeted metabolomics data generated from high-resolution liquid chromatography-mass spectrometry (LC/MS). The common practice is to use filters with predetermined parameters to select peaks in the LC/MS profile. This rigid approach can cause suboptimal performance when the choice of peak model and parameters do not suit the data characteristics.   RESULTS Here we present a method that learns directly from various data features of the extracted ion chromatograms (EICs) to differentiate between true peak regions from noise regions in the LC/MS profile. It utilizes the knowledge of known metabolites, as well as robust machine learning approaches. Unlike currently available methods, this new approach does not assume a parametric peak shape model and allows maximum flexibility. We demonstrate the superiority of the new approach using real data. Because matching to known metabolites entails uncertainties and cannot be considered a gold standard, we also developed a probabilistic receiver-operating characteristic (pROC) approach that can incorporate uncertainties.   AVAILABILITY AND IMPLEMENTATION The new peak detection approach is implemented as part of the apLCMS package available at http://web1.sph.emory.edu/apLCMS/ CONTACT: tyu8@emory.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
3,"A. Appice, P. Rodrigues, V. S. Costa, Carlos Soares, João Gama, A. Jorge","Machine Learning and Knowledge Discovery in Databases",2015,"","","","",186,"2022-07-13 09:25:19","","10.1007/978-3-319-23525-7","","",,,,,3,0.43,1,6,7,"","",""
41,"Xiang Lu, M. Hasanipanah, Kathirvel Brindhadevi, H. Bakhshandeh Amnieh, Seyedamirhesam Khalafi","ORELM: A Novel Machine Learning Approach for Prediction of Flyrock in Mine Blasting",2019,"","","","",187,"2022-07-13 09:25:19","","10.1007/s11053-019-09532-2","","",,,,,41,13.67,8,5,3,"","",""
29,"Violeta Mirchevska, M. Luštrek, M. Gams","Combining domain knowledge and machine learning for robust fall detection",2014,"","","","",188,"2022-07-13 09:25:19","","10.1111/exsy.12019","","",,,,,29,3.63,10,3,8,"This paper presents a method for combining domain knowledge and machine learning (CDKML) for classifier generation and online adaptation. The method exploits advantages in domain knowledge and machine learning as complementary information sources. Whereas machine learning may discover patterns in interest domains that are too subtle for humans to detect, domain knowledge may contain information on a domain not present in the available domain dataset. CDKML has three steps. First, prior domain knowledge is enriched with relevant patterns obtained by machine learning to create an initial classifier. Second, genetic algorithms refine the classifier. Third, the classifier is adapted online on the basis of user feedback using the Markov decision process. CDKML was applied in fall detection. Tests showed that the classifiers developed by CDKML have better performance than machine‐learning classifiers generated on a training dataset that does not adequately represent all real‐life cases of the learned concept. The accuracy of the initial classifier was 10 percentage points higher than the best machine‐learning classifier and the refinement added 3 percentage points. The online adaptation improved the accuracy of the refined classifier by an additional 15 percentage points.","",""
33,"Jana Sperschneider","Machine learning in plant-pathogen interactions: empowering biological predictions from field scale to genome scale.",2020,"","","","",189,"2022-07-13 09:25:19","","10.1111/nph.15771","","",,,,,33,16.50,33,1,2,"Contents Summary I. A primer on machine learning: what is it and what are the common pitfalls? II. Machine learning applications in plant-pathogen interactions III. Conclusion Acknowledgements References SUMMARY: Machine learning (ML) encompasses statistical methods that learn to identify patterns in complex datasets. Here, I review application areas in plant-pathogen interactions that have recently benefited from ML, such as disease monitoring, the discovery of gene regulatory networks, genomic selection for disease resistance and prediction of pathogen effectors. However, achieving robust performance from ML is not trivial and requires knowledge of both the methodology and the biology. I discuss common pitfalls and challenges in using ML approaches. Finally, I highlight future opportunities for ML as a tool for dissecting plant-pathogen interactions using high-throughput data, for example, through integration of diverse data sources and the analysis with higher resolution, such as from individual cells or on elaborate spatial and temporal scales.","",""
35,"Feng Ren, Chenglei Wang, Hui Tang","Active control of vortex-induced vibration of a circular cylinder using machine learning",2019,"","","","",190,"2022-07-13 09:25:19","","10.1063/1.5115258","","",,,,,35,11.67,12,3,3,"We demonstrate the use of high-fidelity computational fluid dynamics simulations in machine-learning based active flow control. More specifically, for the first time, we adopt the genetic programming (GP) to select explicit control laws, in a data-driven and unsupervised manner, for the suppression of vortex-induced vibration (VIV) of a circular cylinder in a low-Reynolds-number flow (Re = 100), using blowing/suction at fixed locations. A cost function that balances both VIV suppression and energy consumption for the control is carefully chosen according to the knowledge obtained from pure blowing/suction open-loop controls. By implementing reasonable constraints to VIV amplitude and actuation strength during the GP evolution, the GP-selected best ten control laws all point to suction-type actuation. The best control law suggests that the suction strength should be nonzero when the cylinder is at its equilibrium position and should increase nonlinearly with the cylinder’s transverse displacement. Applying this control law suppresses 94.2% of the VIV amplitude and achieves 21.4% better overall performance than the best open-loop controls. Furthermore, it is found that the GP-selected control law is robust, being effective in flows ranging from Re = 100 to 400. On the contrary, although the P-control can achieve similar performance as the GP-selected control at Re = 100, it deteriorates in higher Reynolds number flows. Although for demonstration purpose the chosen control problem is relatively simple, the training experience and insights obtained from this study can shed some light on future GP-based control of more complicated problems.We demonstrate the use of high-fidelity computational fluid dynamics simulations in machine-learning based active flow control. More specifically, for the first time, we adopt the genetic programming (GP) to select explicit control laws, in a data-driven and unsupervised manner, for the suppression of vortex-induced vibration (VIV) of a circular cylinder in a low-Reynolds-number flow (Re = 100), using blowing/suction at fixed locations. A cost function that balances both VIV suppression and energy consumption for the control is carefully chosen according to the knowledge obtained from pure blowing/suction open-loop controls. By implementing reasonable constraints to VIV amplitude and actuation strength during the GP evolution, the GP-selected best ten control laws all point to suction-type actuation. The best control law suggests that the suction strength should be nonzero when the cylinder is at its equilibrium position and should increase nonlinearly with the cylinder’s transverse displacement. Applying...","",""
52,"Yudong Chen, Lili Su, Jiaming Xu","Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent",2017,"","","","",191,"2022-07-13 09:25:19","","10.1145/3219617.3219655","","",,,,,52,10.40,17,3,5,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q łe m for an arbitrarily small but fixed constant ε>0. The parameter estimate converges in O(łog N) rounds with an estimation error on the order of max √dq/N, ~√d/N , which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q . The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log 3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.","",""
10,"Yifan Cui, E. Tchetgen","Bias-aware model selection for machine learning of doubly robust functionals",2019,"","","","",192,"2022-07-13 09:25:19","","","","",,,,,10,3.33,5,2,3,"While model selection is a well-studied topic in parametric and nonparametric regression or density estimation, model selection of possibly high dimensional nuisance parameters in semiparametric problems is far less developed. In this paper, we propose a new model selection framework for making inferences about a finite dimensional functional defined on a semiparametric model, when the latter admits a doubly robust estimating function. The class of such doubly robust functionals is quite large, including many missing data and causal inference problems. Under double robustness, the estimated functional should incur no bias if either of two nuisance parameters is evaluated at the truth while the other spans a large collection of candidate models. We introduce two model selection criteria for bias reduction of functional of interest, each based on a novel definition of pseudo-risk for the functional that embodies this double robustness property and thus may be used to select the candidate model that is nearest to fulfilling this property even when all models are wrong. Both selection criteria have a bias awareness property that selection of one nuisance parameter can be made to compensate for excessive bias due to poor learning of the other nuisance parameter. We establish an oracle property for a multi-fold cross-validation version of the new model selection criteria which states that our empirical criteria perform nearly as well as an oracle with a priori knowledge of the pseudo-risk for each candidate model. We also describe a smooth approximation to the selection criteria which allows for valid post-selection inference. Finally, we apply the approach to perform model selection of a semiparametric estimator of average treatment effect given an ensemble of candidate machine learning methods to account for confounding in a study of right heart catheterization in the intensive care unit of critically ill patients.","",""
20,"Di Wu, Binxing Fang, Junnan Wang, Qixu Liu, Xiang Cui","Evading Machine Learning Botnet Detection Models via Deep Reinforcement Learning",2019,"","","","",193,"2022-07-13 09:25:19","","10.1109/ICC.2019.8761337","","",,,,,20,6.67,4,5,3,"Botnets are one of predominant threats to Internet security. To date, machine learning technology has wide application in botnet detection because that it is able to summarize the features of existing attacks and generalize to never-before-seen botnet families. However, recent works in adversarial machine learning have shown that attackers are able to bypass the detection model by constructing specific samples, which due to many algorithms are vulnerable to almost imperceptible perturbations of their inputs. According to the degree of adversaries' knowledge about the model, adversarial attacks can be classified into several groups, such as gradient- and score-based attacks. In this paper, we propose a more general framework based on deep reinforcement learning (DRL), which effectively generates adversarial traffic flows to deceive the detection model by automatically adding perturbations to samples. Throughout the process, the target detector will be regarded as a black box and more close to realistic attack circumstance. A reinforcement learning agent is equipped for updating the adversarial samples by combining the feedback from the target model (i.e. benign or malicious) and the sequence of actions, which is able to change the temporal and spatial features of the traffic flows while maintaining the original functionality and executability. The experiment results show that the evasion rates of adversarial botnet flows are significantly improved. Furthermore, with the perspective of defense, this research can help the detection model spot its defect and thus enhance the robustness.","",""
22,"Mohamed Maher, S. Sakr","SmartML: A Meta Learning-Based Framework for Automated Selection and Hyperparameter Tuning for Machine Learning Algorithms",2019,"","","","",194,"2022-07-13 09:25:19","","10.5441/002/edbt.2019.54","","",,,,,22,7.33,11,2,3,"Due to the increasing success of machine learning techniques, nowadays, thay have been widely utilized in almost every domain such as financial applications, marketing, recommender systems and user behavior analytics, just to name a few. In practice, the machine learning model creation process is a highly iterative exploratory process. In particular, an effective machine learning modeling process requires solid knowledge and understanding of the different types of machine learning algorithms. In addition, all machine learning algorithms require user-defined inputs to achieve a balance between accuracy and generalizability. This task is referred to as Hyperparameter Tuning . Thus, in practice, data scientists work hard to find the best model or algorithm that meets the specifications of their prob-lem. Such iterative and explorative nature of the modeling process is commonly tedious and time-consuming. We demonstrate SmartML , a meta learning-based framework for automated selection and hyperparameter tuning for machine learning algorithms. Being meta learning-based, the framework is able to simulate the role of the machine learning expert. In particular, the framework is equipped with a continuously updated knowledge base that stores information about the meta-features of all processed datasets along with the associated performance of the different classifiers and their tuned parameters. Thus, for any new dataset, SmartML automatically extracts its meta features and searches its knowledge base for the best performing algorithm to start its optimization process. In addition, SmartML makes use of the new runs to continuously en-rich its knowledge base to improve its performance and robustness for future runs. We will show how our approach outperforms the-state-of-the-art techniques in the domain of automated machine learning frameworks.","",""
18,"P. Fusar-Poli, Dominic Stringer, Alice M. S. Durieux, G. Rutigliano, I. Bonoldi, A. De Micheli, D. Ståhl","Clinical-learning versus machine-learning for transdiagnostic prediction of psychosis onset in individuals at-risk",2019,"","","","",195,"2022-07-13 09:25:19","","10.1038/s41398-019-0600-9","","",,,,,18,6.00,3,7,3,"","",""
19,"T. Le, M. Penna, D. Winkler, I. Yarovsky","Quantitative design rules for protein-resistant surface coatings using machine learning",2019,"","","","",196,"2022-07-13 09:25:19","","10.1038/s41598-018-36597-5","","",,,,,19,6.33,5,4,3,"","",""
16,"Mo Zhou, Yoshimi Fukuoka, Ken Goldberg, E. Vittinghoff, Anil Aswani","Applying machine learning to predict future adherence to physical activity programs",2019,"","","","",197,"2022-07-13 09:25:19","","10.1186/s12911-019-0890-0","","",,,,,16,5.33,3,5,3,"","",""
13,"Karolis Liulys","Machine Learning Application in Predictive Maintenance",2019,"","","","",198,"2022-07-13 09:25:19","","10.1109/ESTREAM.2019.8732146","","",,,,,13,4.33,13,1,3,"Industrial organizations worldwide cannot ignore Industry 4.0 and its impact to their businesses. The biggest struggle is to find the way how to adopt all the possibilities for each plants unique use cases. In those situations where it is hard to find unified solutions internet is playing major part. Inseparable part of Industry 4.0 is Internet of Things (IoT) paradigm, where it is possible to connect all devices into united system. While robust Distributed Control Systems (DCS) are preferred for their safety, Industrial IoT (IIoT) allows next level prospects: big data performance analyzation, control patterns identification and predictive preventative maintenance by using machine learning algorithms. The study shows how implementing open-source software enables engineers to develop predictive maintenance applications with basic programming knowledge. These type of applications can be widely used in industrial field to inform about possible equipment malfunction helping reduce possible damages.","",""
4,"Esther Heid, W. Green","Machine Learning of Reaction Properties via Learned Representations of the Condensed Graph of Reaction",2021,"","","","",199,"2022-07-13 09:25:19","","10.1021/acs.jcim.1c00975","","",,,,,4,4.00,2,2,1,"The estimation of chemical reaction properties such as activation energies, rates, or yields is a central topic of computational chemistry. In contrast to molecular properties, where machine learning approaches such as graph convolutional neural networks (GCNNs) have excelled for a wide variety of tasks, no general and transferable adaptations of GCNNs for reactions have been developed yet. We therefore combined a popular cheminformatics reaction representation, the so-called condensed graph of reaction (CGR), with a recent GCNN architecture to arrive at a versatile, robust, and compact deep learning model. The CGR is a superposition of the reactant and product graphs of a chemical reaction and thus an ideal input for graph-based machine learning approaches. The model learns to create a data-driven, task-dependent reaction embedding that does not rely on expert knowledge, similar to current molecular GCNNs. Our approach outperforms current state-of-the-art models in accuracy, is applicable even to imbalanced reactions, and possesses excellent predictive capabilities for diverse target properties, such as activation energies, reaction enthalpies, rate constants, yields, or reaction classes. We furthermore curated a large set of atom-mapped reactions along with their target properties, which can serve as benchmark data sets for future work. All data sets and the developed reaction GCNN model are available online, free of charge, and open source.","",""
32,"Qigang Li, Keyan Zhao, C. Bustamante, Xin Ma, W. Wong","Xrare: a machine learning method jointly modeling phenotypes and genetic evidence for rare disease diagnosis",2019,"","","","",200,"2022-07-13 09:25:19","","10.1038/s41436-019-0439-8","","",,,,,32,10.67,6,5,3,"","",""
