Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"E. Kondrateva, Polina Belozerova, M. Sharaev, Evgeny Burnaev, A. Bernstein, I. Samotaeva","Machine learning models reproducibility and validation for MR images recognition",2020,"","","","",1,"2022-07-13 09:24:54","","10.1117/12.2559525","","",,,,,0,0.00,0,6,2,"In the present work, we introduce a data processing and analysis pipeline, which ensures the reproducibility of machine learning models chosen for MR image recognition. The proposed pipeline is applied to solve the binary classification problems: epilepsy and depression diagnostics based on vectorized features from MR images. This model is then assessed in terms of classification performance, robustness and reliability of the results, including predictive accuracy on unseen data. The classification performance achieved with our approach compares favorably to ones reported in the literature, where usually no thorough model evaluation is performed.","",""
0,"Svitlana Volkova, Dustin L. Arendt, Emily Saldanha, M. Glenski, Ellyn Ayton, Joseph A. Cottam, Sinan G. Aksoy, Brett Jefferson, Karthnik Shrivaram","Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods",2021,"","","","",2,"2022-07-13 09:24:54","","10.1007/s10588-021-09351-y","","",,,,,0,0.00,0,9,1,"","",""
14,"L. Claude, J. Houenou, E. Duchesnay, P. Favre","Will machine learning applied to neuroimaging in bipolar disorder help the clinician? A critical review and methodological suggestions",2020,"","","","",3,"2022-07-13 09:24:54","","10.1111/bdi.12895","","",,,,,14,7.00,4,4,2,"The existence of anatomofunctional brain abnormalities in bipolar disorder (BD) is now well established by magnetic resonance imaging (MRI) studies. To create diagnostic and prognostic tools, as well as identifying biologically valid subtypes of BD, research has recently turned towards the use of machine learning (ML) techniques. We assessed both supervised ML and unsupervised ML studies in BD to evaluate their robustness, reproducibility and the potential need for improvement.","",""
21,"Nidan Qiao","A systematic review on machine learning in sellar region diseases: quality and reporting items",2019,"","","","",4,"2022-07-13 09:24:54","","10.1530/EC-19-0156","","",,,,,21,7.00,21,1,3,"Introduction Machine learning methods in sellar region diseases present a particular challenge because of the complexity and the necessity for reproducibility. This systematic review aims to compile the current literature on sellar region diseases that utilized machine learning methods and to propose a quality assessment tool and reporting checklist for future studies. Methods PubMed and Web of Science were searched to identify relevant studies. The quality assessment included five categories: unmet needs, reproducibility, robustness, generalizability and clinical significance. Results Seventeen studies were included with the diagnosis of general pituitary neoplasms, acromegaly, Cushing’s disease, craniopharyngioma and growth hormone deficiency. 87.5% of the studies arbitrarily chose one or two machine learning models. One study chose ensemble models, and one study compared several models. 43.8% of studies did not provide the platform for model training, and roughly half did not offer parameters or hyperparameters. 62.5% of the studies provided a valid method to avoid over-fitting, but only five reported variations in the validation statistics. Only one study validated the algorithm in a different external database. Four studies reported how to interpret the predictors, and most studies (68.8%) suggested possible clinical applications of the developed algorithm. The workflow of a machine-learning study and the recommended reporting items were also provided based on the results. Conclusions Machine learning methods were used to predict diagnosis and posttreatment outcomes in sellar region diseases. Though most studies had substantial unmet need and proposed possible clinical application, replicability, robustness and generalizability were major limits in current studies.","",""
2,"Jian Wu, Rajal Nivargi, Sree Sai Teja Lanka, A. Menon, Sai Ajay Modukuri, Nishanth Nakshatri, Xin Wei, Zhuoer Wang, James Caverlee, S. Rajtmajer, C. Lee Giles","Predicting the Reproducibility of Social and Behavioral Science Papers Using Supervised Learning Models",2021,"","","","",5,"2022-07-13 09:24:54","","","","",,,,,2,2.00,0,11,1,"In recent years, significant effort has been invested verifying the reproducibility and robustness of research claims in social and behavioral sciences (SBS), much of which has involved resourceintensive replication projects. In this paper, we investigate prediction of the reproducibility of SBS papers using machine learning methods based on a set of features. We propose a framework that extracts five types of features from scholarly work that can be used to support assessments of reproducibility of published research claims. Bibliometric features, venue features, and author features are collected from public APIs or extracted using open source machine learning libraries with customized parsers. Statistical features, such as p-values, are extracted by recognizing patterns ar X iv :2 10 4. 04 58 0v 2 [ cs .D L ] 2 1 O ct 2 02 1 A PREPRINT OCTOBER 22, 2021 in the body text. Semantic features, such as funding information, are obtained from public APIs or are extracted using natural language processing models. We analyze pairwise correlations between individual features and their importance for predicting a set of human-assessed ground truth labels. In doing so, we identify a subset of 9 top features that play relatively more important roles in predicting the reproducibility of SBS papers in our corpus. Results are verified by comparing performances of 10 supervised predictive classifiers trained on different sets of features.","",""
92,"Martin Rozycki, T. Satterthwaite, N. Koutsouleris, G. Erus, J. Doshi, D. Wolf, Yong Fan, R. Gur, R. Gur, E. Meisenzahl, C. Zhuo, Hong Yin, Hao Yan, W. Yue, Dai Zhang, C. Davatzikos","Multisite Machine Learning Analysis Provides a Robust Structural Imaging Signature of Schizophrenia Detectable Across Diverse Patient Populations and Within Individuals",2018,"","","","",6,"2022-07-13 09:24:54","","10.1093/schbul/sbx137","","",,,,,92,23.00,9,16,4,"Past work on relatively small, single-site studies using regional volumetry, and more recently machine learning methods, has shown that widespread structural brain abnormalities are prominent in schizophrenia. However, to be clinically useful, structural imaging biomarkers must integrate high-dimensional data and provide reproducible results across clinical populations and on an individual person basis. Using advanced multi-variate analysis tools and pooled data from case-control imaging studies conducted at 5 sites (941 adult participants, including 440 patients with schizophrenia), a neuroanatomical signature of patients with schizophrenia was found, and its robustness and reproducibility across sites, populations, and scanners, was established for single-patient classification. Analyses were conducted at multiple scales, including regional volumes, voxelwise measures, and complex distributed patterns. Single-subject classification was tested for single-site, pooled-site, and leave-site-out generalizability. Regional and voxelwise analyses revealed a pattern of widespread reduced regional gray matter volume, particularly in the medial prefrontal, temporolimbic and peri-Sylvian cortex, along with ventricular and pallidum enlargement. Multivariate classification using pooled data achieved a cross-validated prediction accuracy of 76% (AUC = 0.84). Critically, the leave-site-out validation of the detected schizophrenia signature showed accuracy/AUC range of 72-77%/0.73-0.91, suggesting a robust generalizability across sites and patient cohorts. Finally, individualized patient classifications displayed significant correlations with clinical measures of negative, but not positive, symptoms. Taken together, these results emphasize the potential for structural neuroimaging data to provide a robust and reproducible imaging signature of schizophrenia. A web-accessible portal is offered to allow the community to obtain individualized classifications of magnetic resonance imaging scans using the methods described herein.","",""
1,"Rober Boshra","Automated Machine Learning Framework for EEG/ERP Analysis: Viable Improvement on Traditional Approaches?",2016,"","","","",7,"2022-07-13 09:24:54","","","","",,,,,1,0.17,1,1,6,"Event Related Potential (ERP) measures derived from the electroencephalogram (EEG) have been widely used in research on language, cognition, and pathology. The high dimensionality (time x channel x condition) of a typical EEG/ERP dataset makes it a timeconsuming prospect to properly analyze, explore, and validate knowledge without a particular restricted hypothesis. This study proposes an automated empirical greedy approach to the analysis process to datamine an EEG dataset for the location, robustness, and latency of ERPs, if any, present in a given dataset. We utilize Support Vector Machines (SVM), a well established machine learning model, on top of a preprocessing pipeline that focuses on detecting differences across experimental conditions. A hybrid of monte-carlo bootstrapping, cross-validation, and permutation tests is used to ensure the reproducibility of results. This framework serves to reduce researcher bias, time spent during analysis, and provide statistically sound results that are agnostic to dataset specifications including the ERPs in question. This method has been tested and validated on three different datasets with different ERPs (N100, Mismatch Negativity (MMN), N2b, Phonological Mapping Negativity (PMN), and P300). Results show statistically significant, above-chance level identification of all ERPs in their respective experimental conditions, latency, and location.","",""
0,"Sebastian A. Schober, Y. Bahri, Cecilia Carbonelli, R. Wille","Neural Network Robustness Analysis Using Sensor Simulations for a Graphene-Based Semiconductor Gas Sensor",2022,"","","","",8,"2022-07-13 09:24:54","","10.3390/chemosensors10050152","","",,,,,0,0.00,0,4,1,"Despite their advantages regarding production costs and flexibility, chemiresistive gas sensors often show drawbacks in reproducibility, signal drift and ageing. As pattern recognition algorithms, such as neural networks, are operating on top of raw sensor signals, assessing the impact of these technological drawbacks on the prediction performance is essential for ensuring a suitable measuring accuracy. In this work, we propose a characterization scheme to analyze the robustness of different machine learning models for a chemiresistive gas sensor based on a sensor simulation model. Our investigations are structured into four separate studies: in three studies, the impact of different sensor instabilities on the concentration prediction performance of the algorithms is investigated, including sensor-to-sensor variations, sensor drift and sensor ageing. In a further study, the explainability of the machine learning models is analyzed by applying a state-of-the-art feature ranking method called SHAP. Our results show the feasibility of model-based algorithm testing and substantiate the need for the thorough characterization of chemiresistive sensor algorithms before sensor deployment in order to ensure robust measurement performance.","",""
3,"Salim Khazem, S. Chevallier, Q. Barthélemy, Karim Haroun, C. Noûs","Minimizing Subject-dependent Calibration for BCI with Riemannian Transfer Learning",2021,"","","","",9,"2022-07-13 09:24:54","","10.1109/NER49283.2021.9441279","","",,,,,3,3.00,1,5,1,"Calibration is still an important issue for user experience in Brain-Computer Interfaces (BCI). Common experimental designs often involve a lengthy training period that raises the cognitive fatigue, before even starting to use the BCI. Reducing or suppressing this subject-dependent calibration is possible by relying on advanced machine learning techniques, such as transfer learning. Building on Riemannian BCI, we present a simple and effective scheme to train a classifier on data recorded from different subjects, to reduce the calibration while preserving good performances. The main novelty of this paper is to propose a unique approach that could be applied on very different paradigms. To demonstrate the robustness of this approach, we conducted a meta-analysis on multiple datasets for three BCI paradigms: motor imagery, event-related potentials (P300) and SSVEP. Relying on the MOABB open source framework to ensure the reproducibility of the experiments and the statistical analysis, the results clearly show that the proposed approach could be applied on any kind of BCI paradigm and in most of the cases to significantly improve the classifier reliability. We point out some key features to further improve transfer learning methods.","",""
54,"Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Michael C. Hughes, Tristan Naumann, M. Ghassemi","MIMIC-Extract: a data extraction, preprocessing, and representation pipeline for MIMIC-III",2019,"","","","",10,"2022-07-13 09:24:54","","10.1145/3368555.3384469","","",,,,,54,18.00,9,6,3,"Machine learning for healthcare researchers face challenges to progress and reproducibility due to a lack of standardized processing frameworks for public datasets. We present MIMIC-Extract, an open source pipeline for transforming the raw electronic health record (EHR) data of critical care patients from the publicly-available MIMIC-III database into data structures that are directly usable in common time-series prediction pipelines. MIMIC-Extract addresses three challenges in making complex EHR data accessible to the broader machine learning community. First, MIMIC-Extract transforms raw vital sign and laboratory measurements into usable hourly time series, performing essential steps such as unit conversion, outlier handling, and aggregation of semantically similar features to reduce missingness and improve robustness. Second, MIMIC-Extract extracts and makes prediction of clinically-relevant targets possible, including outcomes such as mortality and length-of-stay as well as comprehensive hourly intervention signals for ventilators, vasopressors, and fluid therapies. Finally, the pipeline emphasizes reproducibility and extensibility to future research questions. We demonstrate the pipeline's effectiveness by developing several benchmark tasks for outcome and intervention forecasting and assessing the performance of competitive models.","",""
38,"M. Zareef, Quansheng Chen, M. Hassan, Muhammad Arslan, M. M. Hashim, Waqas Ahmad, F. Kutsanedzie, A. A. Agyekum","An Overview on the Applications of Typical Non-linear Algorithms Coupled With NIR Spectroscopy in Food Analysis",2020,"","","","",11,"2022-07-13 09:24:54","","10.1007/s12393-020-09210-7","","",,,,,38,19.00,5,8,2,"","",""
5,"M. E. Laino, Angela Ammirabile, A. Posa, Pierandrea Cancian, Sherif Shalaby, V. Savevski, E. Neri","The Applications of Artificial Intelligence in Chest Imaging of COVID-19 Patients: A Literature Review",2021,"","","","",12,"2022-07-13 09:24:54","","10.3390/diagnostics11081317","","",,,,,5,5.00,1,7,1,"Diagnostic imaging is regarded as fundamental in the clinical work-up of patients with a suspected or confirmed COVID-19 infection. Recent progress has been made in diagnostic imaging with the integration of artificial intelligence (AI) and machine learning (ML) algorisms leading to an increase in the accuracy of exam interpretation and to the extraction of prognostic information useful in the decision-making process. Considering the ever expanding imaging data generated amid this pandemic, COVID-19 has catalyzed the rapid expansion in the application of AI to combat disease. In this context, many recent studies have explored the role of AI in each of the presumed applications for COVID-19 infection chest imaging, suggesting that implementing AI applications for chest imaging can be a great asset for fast and precise disease screening, identification and characterization. However, various biases should be overcome in the development of further ML-based algorithms to give them sufficient robustness and reproducibility for their integration into clinical practice. As a result, in this literature review, we will focus on the application of AI in chest imaging, in particular, deep learning, radiomics and advanced imaging as quantitative CT.","",""
5,"A. Ouranidis, Christina Davidopoulou, Reald-Konstantinos Tashi, K. Kachrimanis","Pharma 4.0 Continuous mRNA Drug Products Manufacturing",2021,"","","","",13,"2022-07-13 09:24:54","","10.3390/pharmaceutics13091371","","",,,,,5,5.00,1,4,1,"Continuous mRNA drugs manufacturing is perceived to nurture flow processes featuring quality by design, controlled automation, real time validation, robustness, and reproducibility, pertaining to regulatory harmonization. However, the actual adaptation of the latter remains elusive, hence batch-to-continuous transition would a priori necessitate holistic process understanding. In addition, the cost related to experimental, pilot manufacturing lines development and operations thereof renders such venture prohibitive. Systems-based Pharmaceutics 4.0 digital design enabling tools, i.e., converging mass and energy balance simulations, Monte-Carlo machine learning iterations, and spatial arrangement analysis were recruited herein to overcome the aforementioned barriers. The primary objective of this work is to hierarchically design the related bioprocesses, embedded in scalable devices, compatible with continuous operation. Our secondary objective is to harvest the obtained technological data and conduct resource commitment analysis. We herein demonstrate for first time the feasibility of the continuous, end-to-end production of sterile mRNA formulated into lipid nanocarriers, defining the equipment specifications and the desired operational space. Moreover, we find that the cell lysis modules and the linearization enzymes ascend as the principal resource-intensive model factors, accounting for 40% and 42% of the equipment and raw material, respectively. We calculate MSPD 1.30–1.45 €, demonstrating low margin lifecycle fluctuation.","",""
2,"Nathan Kau, Stuart Bowers","Stanford Pupper: A Low-Cost Agile Quadruped Robot for Benchmarking and Education",2021,"","","","",14,"2022-07-13 09:24:54","","","","",,,,,2,2.00,1,2,1,"We present Stanford Pupper, an easily-replicated open source quadruped robot designed specifically as a benchmark platform for legged robotics research. The robot features torque-controllable brushless motors with high specific power that enable testing of impedance and torque-based machine learning and optimization control approaches. Pupper can be built from the ground up in under 8 hours for a total cost under $2000, with all components either easily purchased or 3D printed. To rigorously compare control approaches, we introduce two benchmarks, Sprint and Scramble with a leaderboard maintained by Stanford Student Robotics. These benchmarks test high-speed dynamic locomotion capability, and robustness to unstructured terrain. We provide a reference controller with dynamic, omnidirectional gaits that serves as a baseline for comparison. Reproducibility is demonstrated across multiple institutions with robots made independently. All material is available at https: //stanfordstudentrobotics.org/quadruped-benchmark.","",""
0,"P. Icer","Bioinformatics Methods For Studying Intra-Host and Inter-Host Evolution Of Highly Mutable Viruses",2021,"","","","",15,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,1,1,"Understanding viral disease progression is vital to the detection of outbreaks and subsequent planning for public health actions. Bioinformatics methods are extremely useful for this purpose through a range of applications among which the analysis of viral next-generation sequencing (NGS) data, tracing virus evolution and reconstruction of transmission networks have been explored in this research. The first part of this research focuses on the processing of NGS data where quantification methods are proposed to describe the robustness and reproducibility of the output of bioinformatics tools. This research shows the importance of assessing the reliability of genomic tools. The second part of this study is the application of processed NGS data to investigate the intra-host evolution of Hepatitis C Virus (HCV) to diagnose and detect new and incident HCV cases. A computational method based on Machine Learning algorithms is proposed to solve this problem. This genomic multi feature-based model not only aims to predict the stage of infection but also aims to understand the evolution of HCV and its underlying complex mechanism. The third part of this research aims to reconstruct transmission networks for new cases which were identified during the aforementioned research. In this part the inter-host evolution of highly mutable viruses is studied. A Maximum Likelihood approach consisting of Uncapacitated Facility Location Algorithm is proposed to solve this problem. Finally, the last part of this dissertation focuses on the inference of the global transmission network of SARS-CoV-2 prior to the pandemic state. INDEX WORDS: Robustness, Quasispecies, Transmission Network, Machine Learning, Hepatitis C Virus, SARS-CoV-2 BIONFORMATICS METHODS FOR STUDYING INTRA-HOST AND INTER-HOST EVOLUTION OF HIGHLY MUTABLE VIRUSES","",""
0,"Junwei Ma, D. Xia, Hai-Li Guo, Yankun Wang, Xiaoxu Niu, Zhiyang Liu, Sheng Jiang","Metaheuristic-based support vector regression for landslide displacement prediction: a comparative study",2022,"","","","",16,"2022-07-13 09:24:54","","10.1007/s10346-022-01923-6","","",,,,,0,0.00,0,7,1,"","",""
0,"Bingsi Li, Jing Su, Guangliang Zhang, Jiayue Xu, Jianlong Peng, Ya Zhou, F. Qiu, Shuai Fang, Xiaofang Wen, Guoqiang Wang, Jing Zhao, Hao-Ying Wang, S. Cai, Zhihong Zhang","Abstract 5116: Analytical performance of ELSA-seq, a blood-based test for early detection of multiple cancers",2022,"","","","",17,"2022-07-13 09:24:54","","10.1158/1538-7445.am2022-5116","","",,,,,0,0.00,0,14,1,"  Introduction: Detection of cancer is its early stages can potentially improve therapeutic effectiveness. Previously, we demonstrated that ELSA-seq, a machine-learning-aided methylation profiling test, can detect and locate multiple cancers with high accuracy in plasma samples. Here, we evaluated the analytical performance of a refined test version of ELSA-seq, including analytical sensitivity, specificity, repeatability/reproducibility, and robustness.  Methods: The classification algorithm and cut-offs for the ELSA-seq test were established in the THUNDER study (NCT04820868). Here, we describe the analytical performance using both plasma samples from the THUNDER study and DNA blends from cell lines. Analytical sensitivity was established by defining the limit of detection (LoD) using in-house cfDNA Methylation Reference Standards (MRS) with lowest DNA input for the assay. In brief, fragmented genomic control DNA (NA24385, Coriell Institute) was used as a diluent to contrive human cancer cell lines with defined mixing ratios (tumor fractions), which was further verified by digital droplet PCR (ddPCR). The LoD was determined by the lowest tumor fractions at which accurate DOC and TOO was reported in at least 95% of replicates. As variant allele frequency (VAF) is widely used as a surrogate measurement for tumour fractions, we also used ultra-deep mutation sequencing to attain VAF as an independent piece of evidence. Analytical specificity was assessed by the true negative rate in 120 plasma samples from age-matched healthy donors. A batch-to-batch repeatability/reproducibility study was carried out using 168 clinical samples processed across multiple reagent lots, instruments, and operators. Robustness was evaluated using common interfering substances that potentially could be present in plasma samples such as hemoglobin, bilirubin, triglycerides, and genomic DNA. Testing was performed using 24 cancer and 24 non-cancer samples, with or without interfering substances.  Results: At 5ng input mass (approximating from 1ml plasma), the LOD95 was estimated down to 0.05% (tumor fractions) or 0.02% (VAF) among 6 cancer cell lines. 2 false positives were detected in 120 age-matched healthy donor samples, yielding a specificity of 98.3% (95%CI: 93.5-99.7%). All test results were concordant across multiple reagent lots, instruments, and operators (100% repeatability and reproducibility), and high Pearson correlation coefficients (>99%) were observed in the pair-wise comparison. In addition, none of the substances tested interfered with the assay.  Conclusions: These results suggest that ELSA-seq is a highly sensitive test for detection of the trace amount of tumor-derived methylation signals in plasma samples. The performance is highly reproducible and robust, which is critical for clinical implementations.  Citation Format: Bingsi Li, Jing Su, Guangliang Zhang, Jiayue Xu, Jianlong Peng, Ya Zhou, Fujun Qiu, Shuai Fang, Xiaofang Wen, Guoqiang Wang, Jing Zhao, Hao Wang, Shangli Cai, Zhihong Zhang. Analytical performance of ELSA-seq, a blood-based test for early detection of multiple cancers [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2022; 2022 Apr 8-13. Philadelphia (PA): AACR; Cancer Res 2022;82(12_Suppl):Abstract nr 5116.","",""
0,"Jyoti Kanwar Shekhawat, M. Banerjee","Role of breath biopsy in COVID-19.",2022,"","","","",18,"2022-07-13 09:24:54","","10.1093/jalm/jfac040","","",,,,,0,0.00,0,2,1,"BACKGROUND COVID-19 is a highly contagious respiratory disease that can be transmitted through human exhaled breath. It has caused immense loss and has challenged the healthcare sector. It has affected the economy of countries and thereby affecting numerous sectors. Analysis of human breath samples is an attractive strategy for rapid diagnosis of COVID-19 by monitoring breath biomarkers.   CONTENT Breath collection is a non-invasive process. Various technologies are employed for detection of breath biomarkers like mass spectrometry, biosensors, artificial learning, machine learning. These tools have low turn-around time, robustness, onsite results, Also, MS based approaches are promising tools with high speed, specificity, sensitivity, reproducibility and broader coverage as well as its coupling with various chromatographic separation techniques provides better clinical and biochemical understanding of COVID-19 using breath samples.   SUMMARY Herein, we have tried to review the MS based approaches as well as other techniques used for analysis of breath samples for COVID-19 diagnosis. We have also highlighted the different breath analyzers being developed for COVID-19 detection.","",""
37,"B. I. Hutchins, Kirk L Baker, Matthew T Davis, Mario Diwersy, Ehsanul Haque, Robert M. Harriman, Travis Hoppe, Stephen A Leicht, P. Meyer, George M. Santangelo","The NIH Open Citation Collection: A public access, broad coverage resource",2019,"","","","",19,"2022-07-13 09:24:54","","10.1371/journal.pbio.3000385","","",,,,,37,12.33,4,10,3,"Citation data have remained hidden behind proprietary, restrictive licensing agreements, which raises barriers to entry for analysts wishing to use the data, increases the expense of performing large-scale analyses, and reduces the robustness and reproducibility of the conclusions. For the past several years, the National Institutes of Health (NIH) Office of Portfolio Analysis (OPA) has been aggregating and enhancing citation data that can be shared publicly. Here, we describe the NIH Open Citation Collection (NIH-OCC), a public access database for biomedical research that is made freely available to the community. This dataset, which has been carefully generated from unrestricted data sources such as MedLine, PubMed Central (PMC), and CrossRef, now underlies the citation statistics delivered in the NIH iCite analytic platform. We have also included data from a machine learning pipeline that identifies, extracts, resolves, and disambiguates references from full-text articles available on the internet. Open citation links are available to the public in a major update of iCite (https://icite.od.nih.gov).","",""
81,"Yang Young Lu, Yingying Fan, Jinchi Lv, William Stafford Noble","DeepPINK: reproducible feature selection in deep neural networks",2018,"","","","",20,"2022-07-13 09:24:54","","","","",,,,,81,20.25,20,4,4,"Deep learning has become increasingly popular in both supervised and unsupervised machine learning thanks to its outstanding empirical performance. However, because of their intrinsic complexity, most deep learning methods are largely treated as black box tools with little interpretability. Even though recent attempts have been made to facilitate the interpretability of deep neural networks (DNNs), existing methods are susceptible to noise and lack of robustness. Therefore, scientists are justifiably cautious about the reproducibility of the discoveries, which is often related to the interpretability of the underlying statistical models. In this paper, we describe a method to increase the interpretability and reproducibility of DNNs by incorporating the idea of feature selection with controlled error rate. By designing a new DNN architecture and integrating it with the recently proposed knockoffs framework, we perform feature selection with a controlled error rate, while maintaining high power. This new method, DeepPINK (Deep feature selection using Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data sets to demonstrate its empirical utility.","",""
1,"Cemal Erdem, Ethan M. Bensman, Arnab Mutsuddy, Michael M. Saint-Antoine, M. Bouhaddou, R. Blake, William B. Dodd, Sean M. Gross, Laura M. Heiser, F. Feltus, M. Birtwistle","A Simple and Efficient Pipeline for Construction, Merging, Expansion, and Simulation of Large-Scale, Single-Cell Mechanistic Models",2020,"","","","",21,"2022-07-13 09:24:54","","10.1101/2020.11.09.373407","","",,,,,1,0.50,0,11,2,"The current era of big biomedical data accumulation and availability brings data integration opportunities for leveraging its totality to make new discoveries and/or clinically predictive models. Black-box statistical and machine learning methods are powerful for such integration, but often cannot provide mechanistic reasoning, particularly on the single-cell level. While single-cell mechanistic models clearly enable such reasoning, they are predominantly “small-scale”, and struggle with the scalability and reusability required for meaningful data integration. Here, we present an open-source pipeline for scalable, single-cell mechanistic modeling from simple, annotated input files that can serve as a foundation for mechanistic data integration. As a test case, we convert one of the largest existing single-cell mechanistic models to this format, demonstrating robustness and reproducibility of the approach. We show that the model cell line context can be changed with simple replacement of input file parameter values. We next use this new model to test alternative mechanistic hypotheses for the experimental observations that interferon-gamma (IFNG) inhibits epidermal growth factor (EGF)-induced cell proliferation. Model- based analysis suggested, and experiments support that these observations are better explained by IFNG-induced SOCS1 expression sequestering activated EGF receptors, thereby downregulating AKT activity, as opposed to direct IFNG-induced upregulation of p21 expression. Overall, this new pipeline enables large-scale, single-cell, and mechanistically-transparent modeling as a data integration modality complementary to machine learning.","",""
17,"R. Du, V. Lee, Hui Yuan, K. Lam, H. Pang, Yu Chen, E. Lam, P. Khong, A. Lee, D. Kwong, V. Vardhanabhuti","Radiomics Model to Predict Early Progression of Nonmetastatic Nasopharyngeal Carcinoma after Intensity Modulation Radiation Therapy: A Multicenter Study.",2019,"","","","",22,"2022-07-13 09:24:54","","10.1148/RYAI.2019180075","","",,,,,17,5.67,2,11,3,"Purpose To examine the prognostic value of a machine learning model trained with pretreatment MRI radiomic features in the assessment of patients with nonmetastatic nasopharyngeal carcinoma (NPC) who are at risk for 3-year disease progression after intensity-modulated radiation therapy and to explain the radiomics features in the model.   Materials and Methods A total of 277 patients with nonmetastatic NPC admitted between March 2008 and December 2014 at two imaging centers were retrospectively reviewed. Patients were allocated to a discovery or validation cohort based on where they underwent MRI (discovery cohort, n = 217; validation cohort, n = 60). A total of 525 radiomics features extracted from contrast material-enhanced T1- or T2-weighted MRI studies and five clinical features were subjected to radiomic machine learning modeling to predict 3-year disease progression. Feature selection was performed by analyzing robustness to resampling, reproducibility between observers, and redundancy. Features for the final model were selected with Kaplan-Meier analysis and the log-rank test. A support vector machine was used as the classifier for the model. To interpret the pattern learned from the model, Shapley additive explanations (SHAP) was applied.   Results The final model yielded an area under the receiver operating characteristic curve of 0.80 in both the discovery (95% bootstrap confidence interval: 0.80, 0.81) and independent validation (95% bootstrap confidence interval: 0.73, 0.89) cohorts. Analysis with SHAP revealed that tumor shape sphericity, first-order mean absolute deviation, T stage, and overall stage were important factors in 3-year disease progression.   Conclusion These results add to the growing evidence of the role of radiomics in the assessment of NPC. By using explanatory techniques, such as SHAP, the complex interaction of features learned by the model may be understood.© RSNA, 2019Supplemental material is available for this article.","",""
18,"M. Bruijning, M. Visser, C. Hallmann, E. Jongejans","trackdem: Automated particle tracking to obtain population counts and size distributions from videos in r",2018,"","","","",23,"2022-07-13 09:24:54","","10.1111/2041-210X.12975","","",,,,,18,4.50,5,4,4,"The possibilities for image analysis in scientific research are substantial: the costs of digital cameras and data storage are sharply decreasing, and automated image analyses greatly increase the scale, reproducibility and robustness of biological studies. However, automated image analysis in ecological and evolutionary studies is still in its infancy. There is a clear need for easy to use and accessible tools. Here, we provide a general purpose method to obtain estimates of population densities, individual body sizes and behavioural metrics from video material of moving organisms. The methods are supplied as a new r‐package trackdem, which provides a flexible, easy to install and use, generally applicable and accurate way to analyse ecological video data. The package can detect and track moving particles, count individuals and estimate individual sizes using background detection, particle identification and particle tracking algorithms. Machine learning is implemented to reduce the influence of noise in lower quality videos or to distinguish a single species in multi‐species systems. We show that trackdem provides accurate population counts and body size distributions. Using a series of simulations, we show that our estimates are robust against high levels of noise in videos. When applied to live populations of Daphnia magna, our methods obtained accurate and unbiased estimates of population counts, individual sizes and size distributions, as verified by manual counting and measuring. The package trackdem is also directly usable for movement analysis, for instance in behavioural ecology, as illustrated by the tracking of insects, fish, cars and humans. Within 24 hr, we obtained 192 accurate population counts and body sizes of 22,154 individuals. Such results underscore that automated analysis can improve robustness and reproducibility, and greatly increase the scope of studies in ecology and evolution.","",""
10,"André Anjos, Laurent El Shafey, S. Marcel","BEAT: An Open-Source Web-Based Open-Science Platform",2017,"","","","",24,"2022-07-13 09:24:54","","","","",,,,,10,2.00,3,3,5,"With the increased interest in computational sciences, machine learning (ML), pattern recognition (PR) and big data, governmental agencies, academia and manufacturers are overwhelmed by the constant influx of new algorithms and techniques promising improved performance, generalization and robustness. Sadly, result reproducibility is often an overlooked feature accompanying original research publications, competitions and benchmark evaluations. The main reasons behind such a gap arise from natural complications in research and development in this area: the distribution of data may be a sensitive issue; software frameworks are difficult to install and maintain; Test protocols may involve a potentially large set of intricate steps which are difficult to handle. Given the raising complexity of research challenges and the constant increase in data volume, the conditions for achieving reproducible research in the domain are also increasingly difficult to meet. To bridge this gap, we built an open platform for research in computational sciences related to pattern recognition and machine learning, to help on the development, reproducibility and certification of results obtained in the field. By making use of such a system, academic, governmental or industrial organizations enable users to easily and socially develop processing toolchains, re-use data, algorithms, workflows and compare results from distinct algorithms and/or parameterizations with minimal effort. This article presents such a platform and discusses some of its key features, uses and limitations. We overview a currently operational prototype and provide design insights.","",""
3,"H. Gan, Rasyiqah 'Annani Mohd Rosidi, Haziqah Hamidur, K. A. Sayuti, M. H. Ramlee, A. A. Abdul Karim, Bakthiar Al-Jefry Abd Salam","Binary Seeds Auto Generation Model for Knee Cartilage Segmentation",2018,"","","","",25,"2022-07-13 09:24:54","","10.1109/ICIAS.2018.8540570","","",,,,,3,0.75,0,7,4,"Segmentation is an instrumental task in medical image analysis. In addition to existing manual, semi-automatic and automatic segmentation models, deep learning has been the niftiest machine learning technique in current research interests. However, none of the models or technique can escape from the overdependence on training data and user intervention. As a result, the use of computer-aided and learning algorithms have reported lackluster robustness in the presence of high anatomical disparity. In recognition of this, we have proposed a binary seeds auto-generation model to reduce the reliance on manually crafted priori information in deep learning. Then, we computed the reproducibility of the proposed model against manual segmentation using normal and osteoarthritic knee magnetic resonance image. In normal knee image, mean agreements of the proposed model and manual segmentation were $0.94 \pm 0.022$ and $0.83 \pm 0.028$ respectively. In osteoarthritic knee image, mean agreements of the proposed model and manual segmentation were $\mathbf{0.92}\pm\mathbf{0.051}$ and $\mathbf{0.79}\pm \mathbf{0.073}$ respectively. Pair t test showed that our method has better accuracy than manual segmentation in both cases (normal: $\text{P}=1.03\times 10^{-9}$; osteoarthritic: $\text{P}=4.94\times 10^{-8}$). Therefore, we can conclude the model is robust to be implemented as part of deep learning based segmentation framework.","",""
4,"André Anjos, Laurent El Shafey, S. Marcel","BEAT: An Open-Science Web Platform",2017,"","","","",26,"2022-07-13 09:24:54","","","","",,,,,4,0.80,1,3,5,"With the increased interest in computational sciences, machine learning (ML), pattern recognition (PR) and big data, governmental agencies, academia and manufacturers are overwhelmed by the constant influx of new algorithms and techniques promising improved performance, generalization and robustness. Sadly, result reproducibility is often an overlooked feature accompanying original research publications, competitions and benchmark evaluations. The main reasons behind such a gap arise from natural complications in research and development in this area: the distribution of data may be a sensitive issue; software frameworks are difficult to install and maintain; Test protocols may involve a potentially large set of intricate steps which are difficult to handle. To bridge this gap, we built an open platform for research in computational sciences related to pattern recognition and machine learning, to help on the development, reproducibility and certification of results obtained in the field. By making use of such a system, academic, governmental or industrial organizations enable users to easily and socially develop processing toolchains, re-use data, algorithms, workflows and compare results from distinct algorithms and/or parameterizations with minimal effort. This article presents such a platform and discusses some of its key features, uses and limitations. We overview a currently operational prototype and provide design insights.","",""
3,"W. Strothmann, A. Kielhorn, V. Tsukor, D. Trautz, A. Ruckelshausen","Interactive Image Segmentation for Model Adaption and Decision Support",2013,"","","","",27,"2022-07-13 09:24:54","","","","",,,,,3,0.33,1,5,9,"In many fields of Agricultural Management and Agricultural Engineering sophisticated algorithms based on complex environment models are used to generate decision-supporting information from various data sources. However, often these models highly depend on the proper adaption of their complex parameter sets to local ambient conditions and in many cases practitioners are not able to perform this adaption. Therefore a concept is shown here that allows the identification of objects in images and their linkage with meta-data in semi-automatic human-machine interaction. The approach combines the robustness of human experiences against spatially and temporarily local variations and the performance and reproducibility of statistical models. It can also be used as an easy way to adapt models to local ambient conditions, which allows recalibrating them more often, thereby increases stability against changes, iteratively improves them and opens the door for life-long machine learning. The software has been developed within the collaborative research project RemoteFarming.1 in which a remote farming robotic weed control system is being developed. The robotic weed control system will be used for in-row weed treatment in carrots at BBCH-scales 10 to 20 in organic farming. In this field weed control is currently conducted by hand. Within the project's first part RemoteFarming.1a an autonomous field robot – based on the platform BoniRob is being built. It is able to autonomously navigate on the field and has an actuator for mechanical treatment of weeds. Furthermore it uses synchronously triggered cameras and lighting units at different wavelengths which can capture high-contrast images of the plants in a shaded space underneath the robot. The detection/identification of weeds in RemoteFarming.1a is performed in a web-based approach by a remote worker, who marks the weeds in images captured by the robot on the field. Afterwards the mechanical actuator of the robot moves to those positions in the field which have been marked in the respective images and eliminates the weed plants. In the second part RemoteFarming.1b this system will be enriched with weed/crop classifiers and the detection/identification. The user will get a suggestion of possible weeds marked in his view and he can confirm or modify these suggestions before the weed will be treated. The software framework described here allows iteratively generating segmentations for images by human-machine interaction. After a first-shot segmentation the user can add marks in the image and after any added mark the segmentation gets improved. The segmentation is visualized by a semi-transparent ImageMap overlaying the original image. The algorithms that have been tested for performing the segmentation so far are Watershed and Graph-Cuts. During the process any arbitrary segment in the ImageMap – even unconnected regions can be assigned to an object. These objects then can be separated into groups and enriched with additional meta-data. Furthermore the ImageMaps can be grouped into Situations representing different field conditions. The framework's design is flexible with abstraction of front-end and back-end. On the back-end side a server version saves data in a relational database. Alternatively a stand-alone version provides the same functionality using XML to persist data. For the front-end a web-based version can be deployed on servers. Another front-end is implemented as App. This allows using the framework on mobile devices even without Internet connection, saving the gathered data temporarily in XML and persisting into DB once connected. The framework has been used within the collaborative research project RemoteFarming.1 for labeling of crop and weed plants. It allowed generating a sophisticated ground-truth for shape-matching algorithms and weed/crop classifiers. Regions of plants and even overlapping leafs have been marked, grouped to plants and assigned with labels (Species) and meta-data (BBCH-scale etc.). In the on-going project the system will be enriched with statistical models to provide the user improved first-shots for segmentation and plant classification. But geometric analyses of the labelled data collected at project beginning has already served as specific input for vague issues in requirement analysis for the remote farming robotic weed control system that will be developed.","",""
0,"B. Ljubomir","On the optimal number of gene expression markers for tissue of origin cancer diagnostics",2007,"","","","",28,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,1,15,"B4 Diagnostic tests based on patterns of gene expression combine measurements of multiple markers into a clinically useful test reports. We examined how many markers are needed to achieve optimal performance of a particularly challenging diagnostic problem: determining the tissue of origin of a given cancer specimen. The number of markers has implications for the choice of gene expression measurement technology (such as DNA microarrays or quantitative PCR), as well as the reproducibility and robustness of this test. Materials and Methods: We used machine learning to develop automated classifiers with variable number of markers to determine the cancer tissue of  origin based on gene expression patterns. The expression was measured by hybridization to Affymetrix microarrays U133A and U133 Plus 2.0. The training dataset consisted of 2034 tumor specimens from 15 tissues of origin. The independent test dataset consisted of 477 specimens. For each specimen, a classifier produced 15 similarity scores, reflecting likelihoods that the specimen originated from the corresponding tissue. The predicted tissue of origin was the tissue receiving the highest similarity score. The predictions were compared with clinical truth, and the different classifiers compared by counting the number of incorrect calls (error rate). Results: We achieved cross-validation error rates of 16.3% with 25 markers, 9.9% with 50 markers, 7.2% with 100 markers and 5.4% with 1550 markers on the training set. The difference in error rate between 1550 and 100 markers was statistically significant at .05 level (two-sample chi-square test, chi-square = 4.7, P = .03). Discussion: Cancer classification diagnostic tests based on gene expression may require relatively high number of markers to approach the clinically useful performance. This preliminary finding appears to favor technologies, such as DNA microarrays, which are capable of measuring expression of hundreds or thousands of genes simultaneously. Pathwork Diagnostics is continuing research into this and other classes of problems to further elucidate this issue.","",""
106,"Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, V. Larivière, A. Beygelzimer, Florence d'Alché-Buc, E. Fox, H. Larochelle","Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)",2020,"","","","",29,"2022-07-13 09:24:54","","","","",,,,,106,53.00,13,8,2,"One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.","",""
43,"Matthew B. A. McDermott, Shirly Wang, N. Marinsek, R. Ranganath, L. Foschini, M. Ghassemi","Reproducibility in machine learning for health research: Still a ways to go",2021,"","","","",30,"2022-07-13 09:24:54","","10.1126/scitranslmed.abb1655","","",,,,,43,43.00,7,6,1,"Machine learning applied to health falls short on several reproducibility metrics compared to other machine learning subfields. Machine learning for health must be reproducible to ensure reliable clinical use. We evaluated 511 scientific papers across several machine learning subfields and found that machine learning for health compared poorly to other areas regarding reproducibility metrics, such as dataset and code accessibility. We propose recommendations to address this problem.","",""
31,"Benjamin J. Heil, M. M. Hoffman, F. Markowetz, Su-In Lee, C. Greene, S. C. Hicks","Reproducibility standards for machine learning in the life sciences.",2021,"","","","",31,"2022-07-13 09:24:54","","10.1038/s41592-021-01256-7","","",,,,,31,31.00,5,6,1,"","",""
109,"Andrew Beam, A. Manrai, M. Ghassemi","Challenges to the Reproducibility of Machine Learning Models in Health Care.",2020,"","","","",32,"2022-07-13 09:24:54","","10.1001/jama.2019.20866","","",,,,,109,54.50,36,3,2,"Reproducibility has been an important and intensely debated topic in science and medicine for the past few decades.1 As the scientific enterprise has grown in scope and complexity, concerns regarding how well new findings can be reproduced and validated across different scientific teams and study populations have emerged. In some instances,2 the failure to replicate numerous previous studies has added to the growing concern that science and biomedicine may be in the midst of a “reproducibility crisis.” Against this backdrop, high-capacity machine learning models are beginning to demonstrate early successes in clinical applications,3 and some have received approval from the US Food and Drug Administration. This new class of clinical prediction tools presents unique challenges and obstacles to reproducibility, which must be carefully considered to ensure that these techniques are valid and deployed safely and effectively. Reproducibility is a minimal prerequisite for the creation of new knowledge and scientific progress, but defining precisely what it means for a scientific study to be “reproducible” is complex and has been the subject of considerable effort by both individual researchers and organizations like the National Academies of Science, Engineering, and Medicine. First, it is important to distinguish between the notions of reproducibility and replication. A study is reproducible if, given access to the underlying data and analysis code, an independent group can obtain the same result observed in the original study. However, being reproducible does not imply that a study is correct, only thattheresultswereabletobeverifiedbyadifferentgroup not involved in the original study. A study is replicable if an independent group studying the same phenomenon reaches the same conclusion after performing the same set of experiments or analyses after collecting new data. The discussion around reproducibility and replication has primarily focused on traditional statistical models and the results from randomized clinical trials, but these considerations can and should apply equally to machine learning studies. Challenges to reproducibility and replication include confounding, multiple hypothesis testing, randomness inherent to the analysis procedure, incomplete documentation, and restricted access to the underlying data and code. The last concern, data access, is especially germane for medicine, as privacy barriers are important considerations for data sharing. However, by definition, replication does not require access to the original data or code because a replication exercise examines the extent to which the original phenomenon generalizes to new contexts and new populations. This Viewpoint focuses on reproducibility, even though it is important to acknowledge that replication is often the ultimate goal. Replication is especially important for studies that use observational data (which is almost always the case for machine learning studies) because these dataareoftenbiased,andmodelscouldoperationalizethis bias if not replicated. The challenges of reproducing a machinelearningmodeltrainedbyanotherresearchteamcan be difficult, perhaps even prohibitively so, even with unfettered access to raw data and code.","",""
6,"Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, Jie Tang","Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning",2021,"","","","",33,"2022-07-13 09:24:54","","","","",,,,,6,6.00,1,8,1,"Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.","",""
0,"Shaoyan Guo, Huifu Xu, Liwei Zhang","Statistical Robustness of Empirical Risks in Machine Learning",2020,"","","","",34,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,2,"This paper studies convergence of empirical risks in reproducing kernel Hilbert spaces (RKHS). A conventional assumption in the existing research is that empirical training data do not contain any noise but this may not be satisfied in some practical circumstances. Consequently the existing convergence results do not provide a guarantee as to whether empirical risks based on empirical data are reliable or not when the data contain some noise. In this paper, we fill out the gap in a few steps. First, we derive moderate sufficient conditions under which the expected risk changes stably (continuously) against small perturbation of the probability distribution of the underlying random variables and demonstrate how the cost function and kernel affect the stability. Second, we examine the difference between laws of the statistical estimators of the expected optimal loss based on pure data and contaminated data using Prokhorov metric and Kantorovich metric and derive some qualitative and quantitative statistical robustness results. Third, we identify appropriate metrics under which the statistical estimators are uniformly asymptotically consistent. These results provide theoretical grounding for analysing asymptotic convergence and examining reliability of the statistical estimators in a number of well-known machine learning models.","",""
43,"B. Koçak, Ece Ateş, E. S. Durmaz, M. Ulusan, O. Kilickesmez","Influence of segmentation margin on machine learning–based high-dimensional quantitative CT texture analysis: a reproducibility study on renal clear cell carcinomas",2019,"","","","",35,"2022-07-13 09:24:54","","10.1007/s00330-019-6003-8","","",,,,,43,14.33,9,5,3,"","",""
31,"Matthew B. A. McDermott, Shirly Wang, N. Marinsek, R. Ranganath, M. Ghassemi, L. Foschini","Reproducibility in Machine Learning for Health",2019,"","","","",36,"2022-07-13 09:24:54","","","","",,,,,31,10.33,5,6,3,"Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning.  In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.","",""
312,"Jonas Rauber, Wieland Brendel, M. Bethge","Foolbox: A Python toolbox to benchmark the robustness of machine learning models",2017,"","","","",37,"2022-07-13 09:24:54","","","","",,,,,312,62.40,104,3,5,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox. The most up-to-date documentation can be found at http://foolbox.readthedocs.io. In 2013, Szegedy et al. demonstrated that minimal perturbations, often almost imperceptible to humans, can have devastating effects on machine predictions. These so-called adversarial perturbations thus demonstrate a striking difference between human and machine perception. As a result, adversarial perturbations have been subject to many Equal contribution Centre for Integrative Neuroscience, University of Tübingen, Germany Bernstein Center for Computational Neuroscience, Tübingen, Germany International Max Planck Research School for Intelligent Systems, Tübingen, Germany Max Planck Institute for Biological Cybernetics, Tübingen, Germany Institute for Theoretical Physics, University of Tübingen, Germany. Correspondence to: Jonas Rauber <jonas.rauber@bethgelab.org>. Reliable Machine Learning in the Wild Workshop, 34 th International Conference on Machine Learning, Sydney, Australia, 2017. studies concerning the generation of such perturbations and strategies to protect machine learning models such as deep neural networks against them. A practical definition of the robustness R of a model, first used by Szegedy et al. (2013), is the average size of the minimum adversarial perturbation ρ(x) across many samples x, R = 〈ρ(x)〉 x where (1) ρ(x) = min δ d(x,x+ δ) s.t. x+ δ is adversarial (2) and d(·) is some distance measure. Unfortunately, finding the global minimum adversarial perturbation is close to impossible in any practical setting, and we thus employ heuristic attacks to find a suitable approximation. Such heuristics, however, can fail, in which case we could easily be mislead to believe that a model is robust (Brendel & Bethge, 2017). Our best strategy is thus to employ as many attacks as possible, and to use the minimal perturbation found across all attacks as an approximation to the true global minimum. At the moment, however, such a strategy is severely obstructed by two problems: first, the code for most known attack methods is either not available at all, or only available for one particular deep learning framework. Second, implementations of the same attack often differ in many details and are thus not directly comparable. Foolbox improves upon the existing Python package cleverhans by Papernot et al. (2016b) in three important aspects: 1. It interfaces with most popular machine learning frameworks such as PyTorch, Keras, TensorFlow, Theano, Lasagne and MXNet and provides a straight forward way to add support for other frameworks, 2. it provides reference implementations for more than 15 adversarial attacks with a simple and consistent API, and 3. it supports many different criteria for adversarial examples, including custom ones. This technical report is structured as follows: In section 1 we provide an overview over Foolbox and demonstrate Foolbox: A Python toolbox to benchmark the robustness of machine learning models how to benchmark a model and report the result. In section 2 we describe the adversarial attack methods that are implemented in Foolbox and explain the internal hyperparameter tuning.","",""
0,"Benjamin Holzschuh, C. M. O’Riordan, S. Vegetti, V. Rodriguez-Gomez, Nils Thuerey","Realistic galaxy images and improved robustness in machine learning tasks from generative modelling",2022,"","","","",38,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,5,1,"We examine the capability of generative models to produce realistic galaxy images. We show that mixing generated data with the original data improves the robustness in downstream machine learning tasks. We focus on three different data sets; analytical Sérsic profiles, real galaxies from the COSMOS survey, and galaxy images produced with the SKIRT code, from the IllustrisTNG simulation. We quantify the performance of each generative model using the Wasserstein distance between the distributions of morphological properties (e.g. the Gini-coefficient, the asymmetry, and ellipticity), the surface brightness distribution on various scales (as encoded by the power-spectrum), the bulge statistic and the colour for the generated and source data sets. With an average Wasserstein distance (Fréchet Inception Distance) of 7.19 × 10−2 (0.55), 5.98 × 10−2 (1.45) and 5.08 × 10−2 (7.76) for the Sérsic, COSMOS and SKIRT data set, respectively, our best models convincingly reproduce even themost complicated galaxy properties and create images that are visually indistinguishable from the source data. We demonstrate that by supplementing the training data set with generated data, it is possible to significantly improve the robustness against domain-shifts and out-ofdistribution data. In particular, we train a convolutional neural network to denoise a data set of mock observations. By mixing generated images into the original training data, we obtain an improvement of 11 and 45 per cent in the model performance regarding domain-shifts in the physical pixel size and background noise level, respectively.","",""
0,"Junbo Wang, Amitangshu Pal, Qinglin Yang, K. Kant, Kaiming Zhu, Song Guo","Collaborative Machine Learning: Schemes, Robustness, and Privacy.",2022,"","","","",39,"2022-07-13 09:24:54","","10.1109/TNNLS.2022.3169347","","",,,,,0,0.00,0,6,1,"Distributed machine learning (ML) was originally introduced to solve a complex ML problem in a parallel way for more efficient usage of computation resources. In recent years, such learning has been extended to satisfy other objectives, namely, performing learning in situ on the training data at multiple locations and keeping the training datasets private while still allowing sharing of the model. However, these objectives have led to considerable research on the vulnerabilities of distributed learning both in terms of privacy concerns of the training data and the robustness of the learned overall model due to bad or maliciously crafted training data. This article provides a comprehensive survey of various privacy, security, and robustness issues in distributed ML.","",""
49,"Eric Wong, J. Z. Kolter","Learning perturbation sets for robust machine learning",2020,"","","","",40,"2022-07-13 09:24:54","","","","",,,,,49,24.50,25,2,2,"Although much progress has been made towards robust deep learning, a significant gap in robustness remains between real-world perturbations and more narrowly defined sets typically studied in adversarial defenses. In this paper, we aim to bridge this gap by learning perturbation sets from data, in order to characterize real-world effects for robust training and evaluation. Specifically, we use a conditional generator that defines the perturbation set over a constrained region of the latent space. We formulate desirable properties that measure the quality of a learned perturbation set, and theoretically prove that a conditional variational autoencoder naturally satisfies these criteria. Using this framework, our approach can generate a variety of perturbations at different complexities and scales, ranging from baseline spatial transformations, through common image corruptions, to lighting variations. We measure the quality of our learned perturbation sets both quantitatively and qualitatively, finding that our models are capable of producing a diverse set of meaningful perturbations beyond the limited data seen during training. Finally, we leverage our learned perturbation sets to train models which are empirically and certifiably robust to adversarial image corruptions and adversarial lighting variations, while improving generalization on non-adversarial data. All code and configuration files for reproducing the experiments as well as pretrained model weights can be found at this https URL.","",""
270,"Jonas Rauber, Wieland Brendel, M. Bethge","Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models",2017,"","","","",41,"2022-07-13 09:24:54","","","","",,,,,270,54.00,90,3,5,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at this https URL . The most up-to-date documentation can be found at this http URL .","",""
139,"T. Luechtefeld, Dan Marsh, C. Rowlands, T. Hartung","Machine Learning of Toxicological Big Data Enables Read-Across Structure Activity Relationships (RASAR) Outperforming Animal Test Reproducibility",2018,"","","","",42,"2022-07-13 09:24:54","","10.1093/toxsci/kfy152","","",,,,,139,34.75,35,4,4,"Abstract Earlier we created a chemical hazard database via natural language processing of dossiers submitted to the European Chemical Agency with approximately 10 000 chemicals. We identified repeat OECD guideline tests to establish reproducibility of acute oral and dermal toxicity, eye and skin irritation, mutagenicity and skin sensitization. Based on 350–700+ chemicals each, the probability that an OECD guideline animal test would output the same result in a repeat test was 78%–96% (sensitivity 50%–87%). An expanded database with more than 866 000 chemical properties/hazards was used as training data and to model health hazards and chemical properties. The constructed models automate and extend the read-across method of chemical classification. The novel models called RASARs (read-across structure activity relationship) use binary fingerprints and Jaccard distance to define chemical similarity. A large chemical similarity adjacency matrix is constructed from this similarity metric and is used to derive feature vectors for supervised learning. We show results on 9 health hazards from 2 kinds of RASARs—“Simple” and “Data Fusion”. The “Simple” RASAR seeks to duplicate the traditional read-across method, predicting hazard from chemical analogs with known hazard data. The “Data Fusion” RASAR extends this concept by creating large feature vectors from all available property data rather than only the modeled hazard. Simple RASAR models tested in cross-validation achieve 70%–80% balanced accuracies with constraints on tested compounds. Cross validation of data fusion RASARs show balanced accuracies in the 80%–95% range across 9 health hazards with no constraints on tested compounds.","",""
0,"F. Moiseev, Artem Lukoianov, N. Durasov","Machine Learning Course, Project 2 Unsupervised Object Segmentation by Redrawing: reproducibility challenge",2019,"","","","",43,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,3,"Semantic Segmentation is one of the core tasks in the area of Computer Vision and in most cases, it’s solved in a supervised manner. This approach demands huge datasets of pixellevel labeled data consisted of image-mask pairs which often are unavailable. In this work we provide an ablation study for the ReDO paper [1] where authors use GAN based segmentation model for Unsupervised Semantic Segmentation task: after prediction of object mask input image is redrawn by generator guided by predicted mask, then generated images are fed to discriminator to align them to the original dataset. However, the proposed approach has one significant shortcoming – the network collapses in ∼ 35% cases. We suggest a modification of this approach based on mask regularization which shows the same performance but is more robust. In the final part, we study the ability of the network to produce meaningful embeddings and show that it contains enough information to be used in semi-supervised classification problems.","",""
3,"","Moving towards reproducible machine learning",2021,"","","","",44,"2022-07-13 09:24:54","","10.1038/s43588-021-00152-6","","",,,,,3,3.00,0,0,1,"","",""
4,"I. Scott","Demystifying machine learning: a primer for physicians",2021,"","","","",45,"2022-07-13 09:24:54","","10.1111/imj.15200","","",,,,,4,4.00,4,1,1,"Machine learning is a tool for analysing digitised data sets and formulating predictions that can optimise clinical decision‐making. It aims to identify complex patterns in large data sets and encode them into models that can then classify new unseen cases or make predictions on new data. Machine learning methods take several forms and individual models can be of many different types. More than 50 models have been approved for use in routine healthcare, and the numbers continue to grow exponentially. The reliability and robustness of any model depends on multiple factors, including the quality and quantity of the data used to develop the models, and the selection of features in the data considered most important to maximising accuracy. In ensuring models are safe, effective and reproducible in routine care, physicians need to have some understanding of how these models are developed and evaluated, and to collaborate with data and computer scientists in their design and validation. This narrative review introduces principles, methods and examples of machine learning in a way that does not require mastery of highly complex statistical and computational concepts.","",""
0,"Ziyu Ning, Shuang Yu, Yanqiao Zhao, Xiaoming Sun, Haibin Wu, Xiaoyang Yu","Identification of miRNA-Mediated Subpathways as Prostate Cancer Biomarkers Based on Topological Inference in a Machine Learning Process Using Integrated Gene and miRNA Expression Data",2021,"","","","",46,"2022-07-13 09:24:54","","10.3389/fgene.2021.656526","","",,,,,0,0.00,0,6,1,"Accurately identifying classification biomarkers for distinguishing between normal and cancer samples is challenging. Additionally, the reproducibility of single-molecule biomarkers is limited by the existence of heterogeneous patient subgroups and differences in the sequencing techniques used to collect patient data. In this study, we developed a method to identify robust biomarkers (i.e., miRNA-mediated subpathways) associated with prostate cancer based on normal prostate samples and cancer samples from a dataset from The Cancer Genome Atlas (TCGA; n = 546) and datasets from the Gene Expression Omnibus (GEO) database (n = 139 and n = 90, with the latter being a cell line dataset). We also obtained 10 other cancer datasets to evaluate the performance of the method. We propose a multi-omics data integration strategy for identifying classification biomarkers using a machine learning method that involves reassigning topological weights to the genes using a directed random walk (DRW)-based method. A global directed pathway network (GDPN) was constructed based on the significantly differentially expressed target genes of the significantly differentially expressed miRNAs, which allowed us to identify the robust biomarkers in the form of miRNA-mediated subpathways (miRNAs). The activity value of each miRNA-mediated subpathway was calculated by integrating multiple types of data, which included the expression of the miRNA and the miRNAs’ target genes and GDPN topological information. Finally, we identified the high-frequency miRNA-mediated subpathways involved in prostate cancer using a support vector machine (SVM) model. The results demonstrated that we obtained robust biomarkers of prostate cancer, which could classify prostate cancer and normal samples. Our method outperformed seven other methods, and many of the identified biomarkers were associated with known clinical treatments.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",47,"2022-07-13 09:24:54","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
0,"W. Zong, Yang-Wai Chow, W. Susilo","Visual Analysis of Adversarial Examples in Machine Learning",2021,"","","","",48,"2022-07-13 09:24:54","","10.1007/978-981-33-6726-5_4","","",,,,,0,0.00,0,3,1,"","",""
0,"Cameron Fen, Samir S Undavia","Improving External Validity of Machine Learning, Reduced Form, and Structural Macroeconomic Models using Panel Data",2021,"","","","",49,"2022-07-13 09:24:54","","10.2139/ssrn.3839863","","",,,,,0,0.00,0,2,1,"We show that adding countries as a panel dimension to macroeconomic data can statistically significantly improve the generalization ability of structural and reduced-form models, as well as allow machine learning methods to outperform these and other macroeconomic forecasting models. Using GDP forecasts for evaluation, this procedure reduces root mean squared error (RMSE) by 12% across horizons and models for certain reduced-form models and by 24% across horizons for structural DSGE models. Removing US data from the training set and forecasting out-of-sample country-wise, we show that both reduced form and structural models become more policy invariant, and outperform a baseline model that uses US data only. Finally, given the comparative advantage of ""nonparametric"" machine learning forecasting models in a data-rich regime, we demonstrate that our recurrent neural network (RNN) model and automated machine learning (AutoML) approach outperforms all baseline economic models in this regime. Robustness checks indicate that machine learning outperformance is reproducible, numerically stable, and generalizes across models.","",""
0,"Yan Zhou, Murat Kantarcioglu, B. Xi","A Game Theoretic Perspective on Adversarial Machine Learning and Related Cybersecurity Applications",2021,"","","","",50,"2022-07-13 09:24:54","","10.1002/9781119723950.ch13","","",,,,,0,0.00,0,3,1,"In cybersecurity applications where machine learning algorithms are increasingly used to detect vulnerabilities, a somewhat unique challenge arises as exploits targeting machine learning models are constantly devised by the attackers. Traditional machine learning models are no longer robust and reliable when they are under attack. The action and reaction between machine learning systems and the adversary can be modeled as a game between two or more players. Under well‐defined attack models, game theory can provide robustness guarantee for machine learning models that are otherwise vulnerable to application‐time data corruption. We review two cases of game theory‐based machine learning techniques: in one case, players play a zero sum game by following a minimax strategy, while in the other case, players play a sequential game with one player as the leader and the rest as the followers. Experimental results on e‐mail spam and web spam datasets are presented. In the zero sum game, we demonstrate that an adversarial SVM model built upon the minimax strategy is much more resilient to adversarial attacks than standard SVM and one‐class SVM models. We also show that optimal learning strategies derived to counter overly pessimistic attack models can produce unsatisfactory results when the real attacks are much weaker. In the sequential game, we demonstrate that the mixed strategy, allowing a player to randomize over available strategies, is the best solution in general without knowing what types of adversaries machine learning applications are facing in the wild. We also discuss scenarios where players' behavior may derail rational decision making and models that consider such decision risks.","",""
0,"Murilo Cruz Lopes, Marília de Matos Amorim, V. S. Freitas, R. Calumby","Survival Prediction for Oral Cancer Patients: A Machine Learning Approach",2021,"","","","",51,"2022-07-13 09:24:54","","10.5753/kdmile.2021.17466","","",,,,,0,0.00,0,4,1,"There is a high incidence of oral cancer in Brazil, with 150,000 new cases estimated for 2020-2022. In most cases, it is diagnosed at an advanced stage and are related to many risk factors. The Registro Hospitalar de Câncer (RHC), managed by Instituto Nacional de Câncer (INCA), is a nation-wide database that integrates cancer registers from several hospitals in Brazil. RHC is mostly an administrative database but also include clinical, socioeconomic and hospitalization data for each patient with a cancer diagnostic in the country. For these patients, prognostication is always a difficult task a demand multi-dimensional analysis. Therefore, exploiting large-scale data and machine intelligence approaches emerge as promising tool for computer-aided decision support on death risk estimation. Given the importance of this context, some works have reported high prognostication effectiveness, however with extremely limited data collections, relying on weak validation protocols or simple robustness analysis. Hence, this work describes a detailed workflow and experimental analysis for oral cancer patient survival prediction considering careful data curation and strict validation procedures. By exploiting multiple machine learning algorithms and optimization techniques the proposed approach allowed promising survival prediction effectiveness with F1 and AuC-ROC over 0.78 and 0.80, respectively. Moreover, a detailed analysis have shown that the minimization of different types of prediction errors were achieved by different models, which highlights the importance of the rigour in this kind of validation.","",""
0,"A. Chakrabarty, E. Maddalena, Hongtao Qiao, C. Laughman","Data-driven calibration of physics-informed models of joint building/equipment dynamics using Bayesian optimization /Author=Chakrabarty, Ankush; Maddalena, Emilio; Qiao, Hongtao; Laughman, Christopher R. /CreationDate=September 16, 2021 /Subject=Machine Learning, Multi-Physical Modeling, Optimizatio",2021,"","","","",52,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,4,1,"Physics-informed simulation models of heating, ventilation, and cooling (HVAC) systems play a critical role in predicting system dynamics and enabling analysis, control, and optimization of buildings and equipment. The predictive performance of these simulation models are strongly linked to calibration mechanisms: algorithms that systematically select parameter values that optimize a given calibration-cost map (e.g., L-2 error). Poorly selected parameter values typically result in large deviations between measured building data and simulated data, limiting the utility of the simulation model in subsequent design. State-of-the-art calibration methods explore the parameter space by computing numerical gradients that are susceptible to measurement noise or employing population-based search mechanisms that require exorbitant data. To improve robustness and curtail data requirements, one can ‘learn’ or approximate the calibration-cost map and subsequently leverage the topology of the approximated function to find good search directions despite noisy measurements. Concretely, we employ machine learning to construct a calibration-cost map to direct model calibration for systems with joint dynamics of buildings and HVAC equipment. The learner explores subregions of the parameter space with high uncertainty and queries the model only where collecting simulation data yields useful information. This leads to lower simulation datarequirements compared to widely used calibration mechanisms. 2021 Building Simulation Conference c © 2021 MERL. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Mitsubishi Electric Research Laboratories, Inc. 201 Broadway, Cambridge, Massachusetts 02139 Data-driven calibration of joint building and HVAC dynamic models using scalable Bayesian optimization Ankush Chakrabarty1,∗, Emilio Maddalena, Hongtao Qiao, Christopher R. Laughman Mitsubishi Electric Research Laboratories, Cambridge, MA, USA. 2 École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland. ∗Corresponding Author. Email: chakrabarty@merl.com. Phone: +1 (617) 758-6175.","",""
299,"J Zhang, M. Harman, Lei Ma, Yang Liu","Machine Learning Testing: Survey, Landscapes and Horizons",2019,"","","","",53,"2022-07-13 09:24:54","","10.1109/tse.2019.2962027","","",,,,,299,99.67,75,4,3,"This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.","",""
10,"Alan Le Goallec, B. Tierney, Jacob M. Luber, Evan M. Cofer, A. Kostic, C. Patel","A systematic machine learning and data type comparison yields metagenomic predictors of infant age, sex, breastfeeding, antibiotic usage, country of origin, and delivery type",2020,"","","","",54,"2022-07-13 09:24:54","","10.1371/journal.pcbi.1007895","","",,,,,10,5.00,2,6,2,"The microbiome is a new frontier for building predictors of human phenotypes. However, machine learning in the microbiome is fraught with issues of reproducibility, driven in large part by the wide range of analytic models and metagenomic data types available. We aimed to build robust metagenomic predictors of host phenotype by comparing prediction performances and biological interpretation across 8 machine learning methods and 4 different types of metagenomic data. Using 1,570 samples from 300 infants, we fit 7,865 models for 6 host phenotypes. We demonstrate the dependence of accuracy on algorithm choice and feature definition in microbiome data and propose a framework for building microbiome-derived indicators of host phenotype. We additionally identify biological features predictive of age, sex, breastfeeding status, historical antibiotic usage, country of origin, and delivery type. Our complete results can be viewed at http://apps.chiragjpgroup.org/ubiome_predictions/.","",""
8,"K. Ambrosen, Martin W. Skjerbæk, Jonathan Foldager, Martin C. Axelsen, N. Bak, L. Arvastson, S. Christensen, L. B. Johansen, J. Raghava, B. Oranje, E. Rostrup, M. Nielsen, M. Osler, B. Fagerlund, C. Pantelis, B. Kinon, B. Glenthøj, L. K. Hansen, B. Ebdrup","A machine-learning framework for robust and reliable prediction of short- and long-term treatment response in initially antipsychotic-naïve schizophrenia patients based on multimodal neuropsychiatric data",2020,"","","","",55,"2022-07-13 09:24:54","","10.1038/s41398-020-00962-8","","",,,,,8,4.00,1,19,2,"","",""
665,"Weihua Hu, Matthias Fey, M. Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, J. Leskovec","Open Graph Benchmark: Datasets for Machine Learning on Graphs",2020,"","","","",56,"2022-07-13 09:24:54","","","","",,,,,665,332.50,83,8,2,"We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .","",""
39,"Maral Dadvar, K. Eckert","Cyberbullying Detection in Social Networks Using Deep Learning Based Models; A Reproducibility Study",2018,"","","","",57,"2022-07-13 09:24:54","","10.1007/978-3-030-59065-9_20","","",,,,,39,9.75,20,2,4,"","",""
1,"M. Hoeren, D. Zontar, A. Tavakolian, M. Berger, S. Ehret, Temirlan Mussagaliyev, C. Brecher","Performance comparison between model-based and machine learning approaches for the automated active alignment of FAC-lenses",2020,"","","","",58,"2022-07-13 09:24:54","","10.1117/12.2546607","","",,,,,1,0.50,0,7,2,"Due to their short focal lengths, FAC lenses significantly influence the performance of high-power diode laser systems. In addition to the shape, coating and surface quality, high demands are placed on the assembly accuracy for these microoptical components. In order to optimally align and position the lenses despite varying properties (e.g. focal length), active alignment strategies are used. The automation of the active alignment process for production offers enormous potential. Compared to manual processes, the reproducibility and accuracy of the alignment is increased. For the automation of the active alignment process, a deep understanding of the system behaviour is necessary. To control a diversity of variants cost-effectively and robust, new approaches must be taken into account. Concepts of AI or machine learning are great for this kind of generalization and adoption and they have many advantages for the active alignment of systems like DOEs or free-form-optics, with a complex system behaviour. In this publication, we want to compare the performance of a classically model-based algorithm and a machine learning approach for the automated active alignment of FAC-lenses. The model-based algorithm uses a physical model of the metrology system (including the FAC to be aligned) to estimate a misalignment in 4-DOF. The machine learning algorithm consist of a deep neuronal network which was trained with image data.","",""
1,"S. Valverde, Llucia Coll, Liliana Valencia, Albert Clérigues, A. Oliver, J. Vilanova, L. Ramió-Torrentá, À. Rovira, X. Lladó","Assessing the Accuracy and Reproducibility of PARIETAL: A Deep Learning Brain Extraction Algorithm.",2021,"","","","",59,"2022-07-13 09:24:54","","10.1002/jmri.27776","","",,,,,1,1.00,0,9,1,"BACKGROUND Manual brain extraction from magnetic resonance (MR) images is time-consuming and prone to intra- and inter-rater variability. Several automated approaches have been developed to alleviate these constraints, including deep learning pipelines. However, these methods tend to reduce their performance in unseen magnetic resonance imaging (MRI) scanner vendors and different imaging protocols.   PURPOSE To present and evaluate for clinical use PARIETAL, a pre-trained deep learning brain extraction method. We compare its reproducibility in a scan/rescan analysis and its robustness among scanners of different manufacturers.   STUDY TYPE Retrospective.   POPULATION Twenty-one subjects (12 women) with age range 22-48 years acquired using three different MRI scanner machines including scan/rescan in each of them.   FIELD STRENGTH/SEQUENCE T1-weighted images acquired in a 3-T Siemens with magnetization prepared rapid gradient-echo sequence and two 1.5 T scanners, Philips and GE, with spin-echo and spoiled gradient-recalled (SPGR) sequences, respectively.   ASSESSMENT Analysis of the intracranial cavity volumes obtained for each subject on the three different scanners and the scan/rescan acquisitions.   STATISTICAL TESTS Parametric permutation tests of the differences in volumes to rank and statistically evaluate the performance of PARIETAL compared to state-of-the-art methods.   RESULTS The mean absolute intracranial volume differences obtained by PARIETAL in the scan/rescan analysis were 1.88 mL, 3.91 mL, and 4.71 mL for Siemens, GE, and Philips scanners, respectively. PARIETAL was the best-ranked method on Siemens and GE scanners, while decreasing to Rank 2 on the Philips images. Intracranial differences for the same subject between scanners were 5.46 mL, 27.16 mL, and 30.44 mL for GE/Philips, Siemens/Philips, and Siemens/GE comparison, respectively. The permutation tests revealed that PARIETAL was always in Rank 1, obtaining the most similar volumetric results between scanners.   DATA CONCLUSION PARIETAL accurately segments the brain and it generalizes to images acquired at different sites without the need of training or fine-tuning it again. PARIETAL is publicly available.   LEVEL OF EVIDENCE 2 TECHNICAL EFFICACY STAGE: 2.","",""
0,"D. Efremenko, Himani Jain, Jian Xu","Two Machine Learning Based Schemes for Solving Direct and Inverse Problems of Radiative Transfer Theory",2020,"","","","",60,"2022-07-13 09:24:54","","10.51130/graphicon-2020-2-3-45","","",,,,,0,0.00,0,3,2,"Artificial neural networks (ANNs) are used to substitute computationally expensive radiative transfer models (RTMs) and inverse operators (IO) for retrieving optical parameters of the medium. However, the direct parametrization of RTMs and IOs by means of ANNs has certain drawbacks, such as loss of generality, computations of huge training datasets, robustness issues etc. This paper provides an analysis of different ANN-related methods, based on our results and those published by other authors. In particular, two techniques are proposed. In the first method, the ANN substitutes the eigenvalue solver in the discrete ordinate RTM, thereby reducing the computational time. Unlike classical RTM parametrization schemes based on ANN, in this method the resulting ANN can be used for arbitrary geometry and layer optical thicknesses. In the second method, the IO is trained by using the real measurements (preprocessed Level-2 TROPOMI data) to improve the stability of the inverse operator. This method provides robust results even without applying the Tikhonov regularization method.","",""
66,"R. Cuocolo, Maria Brunella Cipullo, A. Stanzione, L. Ugga, V. Romeo, L. Radice, A. Brunetti, M. Imbriaco","Machine learning applications in prostate cancer magnetic resonance imaging",2019,"","","","",61,"2022-07-13 09:24:54","","10.1186/s41747-019-0109-2","","",,,,,66,22.00,8,8,3,"","",""
49,"Edward Raff","A Step Toward Quantifying Independently Reproducible Machine Learning Research",2019,"","","","",62,"2022-07-13 09:24:54","","","","",,,,,49,16.33,49,1,3,"What makes a paper independently reproducible? Debates on reproducibility center around intuition or assumptions but lack empirical results. Our field focuses on releasing code, which is important, but is not sufficient for determining reproducibility. We take the first step toward a quantifiable answer by manually attempting to implement 255 papers published from 1984 until 2017, recording features of each paper, and performing statistical analysis of the results. For each paper, we did not look at the authors code, if released, in order to prevent bias toward discrepancies between code and paper.","",""
27,"A. Kokhanovskiy, A. Ivanenko, S. Kobtsev, S. Smirnov, S. Turitsyn","Machine Learning Methods for Control of Fibre Lasers with Double Gain Nonlinear Loop Mirror",2019,"","","","",63,"2022-07-13 09:24:54","","10.1038/s41598-019-39759-1","","",,,,,27,9.00,5,5,3,"","",""
0,"","Machine learning based alignment of mass spectrometry data for improved clinical biomarker discovery",2022,"","","","",64,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,0,1,"Challenges: To date, although few algorithms have been proposed to do so, there does not exist any generic methodological framework allowing for the alignment of several samples, in order to subsequently provide a robust identification transfer between samples. An innovation in this direction will therefore strongly impact the reproducibility of MS-based molecular profiling, and subsequently, clinical research tools.","",""
23,"P. Mondal, Xue Liu, T. Fatoyinbo, D. Lagomasino","Evaluating Combinations of Sentinel-2 Data and Machine-Learning Algorithms for Mangrove Mapping in West Africa",2019,"","","","",65,"2022-07-13 09:24:54","","10.3390/rs11242928","","",,,,,23,7.67,6,4,3,"Creating a national baseline for natural resources, such as mangrove forests, and monitoring them regularly often requires a consistent and robust methodology. With freely available satellite data archives and cloud computing resources, it is now more accessible to conduct such large-scale monitoring and assessment. Yet, few studies examine the reproducibility of such mangrove monitoring frameworks, especially in terms of generating consistent spatial extent. Our objective was to evaluate a combination of image processing approaches to classify mangrove forests along the coast of Senegal and The Gambia. We used freely available global satellite data (Sentinel-2), and cloud computing platform (Google Earth Engine) to run two machine learning algorithms, random forest (RF), and classification and regression trees (CART). We calibrated and validated the algorithms using 800 reference points collected using high-resolution images. We further re-ran 10 iterations for each algorithm, utilizing unique subsets of the initial training data. While all iterations resulted in thematic mangrove maps with over 90% accuracy, the mangrove extent ranges between 827–2807 km2 for Senegal and 245–1271 km2 for The Gambia with one outlier for each country. We further report “Places of Agreement” (PoA) to identify areas where all iterations for both methods agree (506.6 km2 and 129.6 km2 for Senegal and The Gambia, respectively), thus have a high confidence in predicting mangrove extent. While we acknowledge the timeand cost-effectiveness of such methods for the landscape managers, we recommend utilizing them with utmost caution, as well as post-classification on-the-ground checks, especially for decision making.","",""
0,"Samuel J Bell, Onno P. Kampman, Jesse Dodge, Neil D. Lawrence","Modeling the Machine Learning Multiverse",2022,"","","","",66,"2022-07-13 09:24:54","","10.48550/arXiv.2206.05985","","",,,,,0,0.00,0,4,1,"Amid mounting concern about the reliability and credibility of machine learning research, we present a principled framework for making robust and generalizable claims: the Multiverse Analysis. Our framework builds upon the Multiverse Analysis [1] introduced in response to psychology’s own reproducibility crisis. To efficiently explore high-dimensional and often continuous ML search spaces, we model the multiverse with a Gaussian Process surrogate and apply Bayesian experimental design. Our framework is designed to facilitate drawing robust scientific conclusions about model performance, and thus our approach focuses on exploration rather than conventional optimization. In the first of two case studies, we investigate disputed claims about the relative merit of adaptive optimizers. Second, we synthesize conflicting research on the effect of learning rate on the large batch training generalization gap. For the machine learning community, the Multiverse Analysis is a simple and effective technique for identifying robust claims, for increasing transparency, and a step toward improved reproducibility.","",""
0,"S. Al-Zaiti, Alaa A. Alghwiri, Xiao Hu, G. Clermont, A. Peace, P. Macfarlane, R. Bond","A clinician’s guide to understanding and critically appraising machine learning studies: a checklist for Ruling Out Bias Using Standard Tools in Machine Learning (ROBUST-ML)",2022,"","","","",67,"2022-07-13 09:24:54","","10.1093/ehjdh/ztac016","","",,,,,0,0.00,0,7,1,"  Developing functional machine learning (ML)-based models to address unmet clinical needs requires unique considerations for optimal clinical utility. Recent debates about the rigours, transparency, explainability, and reproducibility of ML models, terms which are defined in this article, have raised concerns about their clinical utility and suitability for integration in current evidence-based practice paradigms. This featured article focuses on increasing the literacy of ML among clinicians by providing them with the knowledge and tools needed to understand and critically appraise clinical studies focused on ML. A checklist is provided for evaluating the rigour and reproducibility of the four ML building blocks: data curation, feature engineering, model development, and clinical deployment. Checklists like this are important for quality assurance and to ensure that ML studies are rigourously and confidently reviewed by clinicians and are guided by domain knowledge of the setting in which the findings will be applied. Bridging the gap between clinicians, healthcare scientists, and ML engineers can address many shortcomings and pitfalls of ML-based solutions and their potential deployment at the bedside.","",""
0,"G. Sasikala, M. Laavanya, B. Sathyasri, C. Supraja, V. Mahalakshmi, S. Mole, J. Mulerikkal, S. Chidambaranathan, C. Arvind, K. Srihari, Minilu Dejene","An Innovative Sensing Machine Learning Technique to Detect Credit Card Frauds in Wireless Communications",2022,"","","","",68,"2022-07-13 09:24:54","","10.1155/2022/2439205","","",,,,,0,0.00,0,11,1,"There has been an increase in credit card fraud as e-commerce has become more widespread. Financial transactions are essential to our economy, so detecting bank fraud is essential. Experiments on automated and real-time fraud detection are needed here. There are numerous machine learning techniques for identifying credit card fraud, and the most prevalent are support vector machine (SVM), logic regression, and random forest. When models penalise all errors equally during training, the quality of these detection approaches becomes crucial. This paper uses an innovative sensing method to judge the classification algorithm by considering the misclassification cost and at the same time by employing SVM hyperparameter optimization using grid search cross-validation and separating the hyperplane using the theory of reproducing kernels like linear, Gaussian, and polynomial, and the robustness is maintained. Because of this, credit card fraud has been identified significantly more successful than in the past.","",""
11,"B. Celik, J. Vanschoren","Adaptation Strategies for Automated Machine Learning on Evolving Data",2020,"","","","",69,"2022-07-13 09:24:54","","10.1109/TPAMI.2021.3062900","","",,,,,11,5.50,6,2,2,"Automated Machine Learning (AutoML) systems have been shown to efficiently build good models for new datasets. However, it is often not clear how well they can adapt when the data evolves over time. The main goal of this study is to understand the effect of concept drift on the performance of AutoML methods, and which adaptation strategies can be employed to make them more robust to changes in the underlying data. To that end, we propose 6 concept drift adaptation strategies and evaluate their effectiveness on a variety of AutoML approaches for building machine learning pipelines, including Bayesian optimization, genetic programming, and random search with automated stacking. These are evaluated empirically on real-world and synthetic data streams with different types of concept drift. Based on this analysis, we propose ways to develop more sophisticated and robust AutoML techniques.","",""
0,"J. Stein, Vinay Pulim, T. Cottrell, P. Forde, J. Taube","Abstract 463: Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies",2022,"","","","",70,"2022-07-13 09:24:54","","10.1158/1538-7445.am2022-463","","",,,,,0,0.00,0,5,1,"  Pathological complete response (no residual viable tumor, RVT) and/or major pathologic response (≤10% RVT) are now primary or secondary endpoints for a large proportion of clinical trials studying neoadjuvant immunotherapeutic regimens. We previously developed a scoring system for assessing pathologic response after immunotherapy, termed irPRC (Cottrell et al. Ann Oncol 2018). By these criteria, %RVT is assessed by dividing RVT by the sum of the surface area on the slide composed of RVT + necrosis + regression bed– the latter feature is where the tumor used to be and is characterized by fibroinflammatory stroma that is distinct from tumoral stroma. We have previously reported high inter-observer reproducibility for pathologic response assessment following immunotherapy. However, these assessments involve performing evaluations that are currently outside the scope of routine surgical pathology training and may be time-consuming. To date, these assessments have primarily been performed by academic pathologists who have seen the largest number of these cases as a part of clinical trials. A machine learning (ML)-powered assessment of irPRC would allow for faster, standardized evaluation and expanded access to patients treated outside of large academic centers. We trained a supervised convolutional neural network to assess pathologic response using irPRC on n=92 H&E-stained slides from patients with advanced, resectable NSCLC treated with neoadjuvant anti-PD-1 +/- anti-CTLA-4 at a single institution. The ML algorithm was trained based on ground-truth manual annotations by pathologists on whole slide digital scans and tested using leave-one-out cross validation. Each of ~830,000 image tiles was classified into one of four classes: tumor, necrosis, immune-mediated regression, or background lung tissue. Receiver operating curves showed that the algorithm exhibited high accuracy for predicting the various tissue classes with an area under the curve of 0.95, 0.96, 0.90, and 0.90 for the four classes, respectively. %RVT was calculated by dividing the surface area of RVT by total tumor bed surface area (RVT + necrosis + regression). There was a strong positive correlation between the machine assessed RVT and the human assessed RVT at both the slide level and case level (aggregate %RVT based on surface area from all slides for a given patient), Pearson’s r=0.95 and r=0.99, respectively. Here, we demonstrate that a ML algorithm performs as well as an experienced pathologist assessment in scoring pathologic response. These findings will need to be validated in larger studies. Additionally, the association of pathologic response with longer term patient outcomes will be evaluated as survival data matures to determine whether pathologic response is a robust surrogate of survival.  Citation Format: Julie E. Stein, Vinay Pulim, Tricia R. Cottrell, Patrick M. Forde, Janis M. Taube. Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2022; 2022 Apr 8-13. Philadelphia (PA): AACR; Cancer Res 2022;82(12_Suppl):Abstract nr 463.","",""
0,"Wen Pan, C. Torres‐Verdín, I. Duncan, M. Pyrcz","REDUCING THE UNCERTAINTY OF MULTI-WELL PETROPHYSICAL INTERPRETATION FROM WELL LOGS VIA MACHINE-LEARNING AND STATISTICAL MODELS",2022,"","","","",71,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,4,1,"Well-log interpretation provides in situ estimates of formation properties such as porosity, hydrocarbon pore volume, and permeability. Reservoir models based on well-log-derived formation properties deliver reserve-volume estimates, production forecasts, and help with decision making in reservoir development. However, due to measurement errors, variability of well logs due to multiple measurement vendors, different borehole tools, and non-uniform drilling/borehole conditions, conventional well-log interpretation methods may not yield accurate estimates of formation properties, especially in the context of multi-well interpretation. To improve the robustness of multi-well petrophysical interpretation, well-log normalization techniques such as two-point scaling and mean-variance normalization are commonly used to impose stationarity constraints for well logs requiring correction. However, these techniques are mostly based on the marginal distribution of well logs and require expert knowledge to be effectively implemented. To reduce the uncertainties and time associated with multi-well petrophysical interpretation, we develop the discriminative adversarial (DA) model and the linear constraint model for well-log normalization and interpretation. We also develop a new divergence-based type well identification method for improved test-well and trainingwell adaptation. The DA neural network model developed for well-log normalization and interpretation can perform both linear and nonlinear well-log normalization by considering the joint distribution of all types of well logs and formation properties. To train the DA model, classical machinelearning models or classical petrophysical models are first trained to minimize the prediction error of formation properties in the training data set; then the adversarial model is trained to normalize well logs in the test set, such that the joint distribution of normalized well logs and formation property estimates of the test data set reproduce those of the training data set. The linear constraint model uses an ensemble of predictions from linear models to constrain both well-log normalization and interpretation. To identify wells with stationary formation properties as well as well logs, the divergence-based type well identification method is Petrophysical Interpretation via Machine-Learning and Statistical Models 3 developed to choose type wells for wells requiring correction based on well-log statistical similarity instead of closeness of wells. We apply the developed methods to improve the accuracy of well-log normalization and the estimation of permeability in a carbonate reservoir. Six types of well logs and over 9000 feet of core measurements from 30 wells drilled between 1980s and 2010s in the Seminole San Andres Unit are available to validate the new multi-well interpretation workflow. Our interpretation models is flexible to integrate any types of classical machine-learning methods and petrophysical assumptions for robust petrophysical estimations. In comparison to classical machine-learning models with no normalization, with two-point scaling normalization and with linear constraints, the DA method yields better performance, e.g., the mean-squared error of permeability estimation decreases by approximately 20-50%. Our interpretation workflow can be applied to other stationary signal and image processing problems to mitigate errors introduced by biased measurements, and to better adapt models calibrated with data from one field to other neighboring fields.","",""
0,"Suleyman Emre Isik, Ali Eren Aytekin, Halil Vurus","A machine learning approach for abstraction and reasoning problems without large amounts of data",2022,"","","","",72,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,1,"Journal of Emerging Investigators • www.emerginginvestigators.org level abstraction-reasoning ability which makes it difficult for algorithms to handle volatile and hard-to-predict real-life problems. The problems caused by this task-based nature necessitated flexibility and robustness for certain broader subfields of AI, such as L5 self-driving, domestic robotics, or personal assistants; there is even increasing interest in generality itself (e.g., developmental robotics, artificial general intelligence) (2, 3). The first and most important step to take in order to offer an approach that is closer to human intelligence is to examine the concept of intelligence and to define it in the most useful way. Various definitions have been made for intelligence in the past. Legg and Hutter summarized the definitions made in the context of artificial intelligence research as follows: ""Intelligence measures a person's ability to achieve goals in a wide and varied environment (4)."" Two main characteristics are emphasized here: a task-goal focus and generalizability to a wide range of environments. Accordingly, while human intelligence can perform tasks with its high ability, these abilities can also be generalized for new tasks in new environments (skill acquisition). This feature is a mechanism that human nature has developed in line with evolutionary psychology to solve new unknown tasks and problems (5, 6). In the direction of the development of AI, many approaches have emerged to develop and evaluate AI models. One of them is the human observational approach that examines, judges, and scores the system’s inputs and outputs. This is a highly subjective, difficult, and expensive method to automate. White-box analysis, on the other hand, is inspecting the implementation of the system to determine its input-output response and score it (e.g., an algorithm that plays “Connect Four”) (7). Peer confrontation, for example, is having the system compete against either other AIs or humans. This is the preferred mode of evaluation for player-versus-player games, such as chess. The benchmarking approach, which is based on enabling the system through algorithms to produce outputs for a ""test set"" of inputs (or environments) for which the desired outcome is known (solvable by humans), is another of the most valuable approaches for the evaluation of artificial intelligence. In particular, it is reproducible (test set fixed), scalable (cheap to run the evaluation multiple times), easy to set up, and flexible enough to be applied to a wide variety of possible tasks (8). For this reason, benchmarking has been an important part of progress in artificial intelligence A machine learning approach for abstraction and reasoning problems without large amounts of data","",""
132,"Trang T. Le, Weixuan Fu, J. Moore","Scaling tree-based automated machine learning to biomedical big data with a feature set selector",2019,"","","","",73,"2022-07-13 09:24:54","","10.1093/bioinformatics/btz470","","",,,,,132,44.00,44,3,3,"Abstract Motivation Automated machine learning (AutoML) systems are helpful data science assistants designed to scan data for novel features, select appropriate supervised learning models and optimize their parameters. For this purpose, Tree-based Pipeline Optimization Tool (TPOT) was developed using strongly typed genetic programing (GP) to recommend an optimized analysis pipeline for the data scientist’s prediction problem. However, like other AutoML systems, TPOT may reach computational resource limits when working on big data such as whole-genome expression data. Results We introduce two new features implemented in TPOT that helps increase the system’s scalability: Feature Set Selector (FSS) and Template. FSS provides the option to specify subsets of the features as separate datasets, assuming the signals come from one or more of these specific data subsets. FSS increases TPOT’s efficiency in application on big data by slicing the entire dataset into smaller sets of features and allowing GP to select the best subset in the final pipeline. Template enforces type constraints with strongly typed GP and enables the incorporation of FSS at the beginning of each pipeline. Consequently, FSS and Template help reduce TPOT computation time and may provide more interpretable results. Our simulations show TPOT-FSS significantly outperforms a tuned XGBoost model and standard TPOT implementation. We apply TPOT-FSS to real RNA-Seq data from a study of major depressive disorder. Independent of the previous study that identified significant association with depression severity of two modules, TPOT-FSS corroborates that one of the modules is largely predictive of the clinical diagnosis of each individual. Availability and implementation Detailed simulation and analysis code needed to reproduce the results in this study is available at https://github.com/lelaboratoire/tpot-fss. Implementation of the new TPOT operators is available at https://github.com/EpistasisLab/tpot. Supplementary information Supplementary data are available at Bioinformatics online.","",""
9,"Doris Xin, Hui Miao, Aditya G. Parameswaran, Neoklis Polyzotis","Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities",2021,"","","","",74,"2022-07-13 09:24:54","","10.1145/3448016.3457566","","",,,,,9,9.00,2,4,1,"Machine learning (ML) is now commonplace, powering data-driven applications in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple times on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for optimization, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can reduce wasted computation cost by 50% without compromising the model deployment cadence.","",""
2,"Chris Emmery, Ákos Kádár, Travis J. Wiltshire, Andrew T. Hendrickson","Towards Replication in Computational Cognitive Modeling: a Machine Learning Perspective",2019,"","","","",75,"2022-07-13 09:24:54","","10.1007/S42113-019-00055-W","","",,,,,2,0.67,1,4,3,"","",""
3,"Haoyu Yang, Wen Chen, P. Pathak, Frank Gennari, Ya-Chieh Lai, Bei Yu","Automatic Layout Generation with Applications in Machine Learning Engine Evaluation",2019,"","","","",76,"2022-07-13 09:24:54","","10.1109/MLCAD48534.2019.9142121","","",,,,,3,1.00,1,6,3,"Machine learning-based lithography hotspot detection has been deeply studied recently, from varies feature extraction techniques to efficient learning models. It has been observed that such machine learning-based frameworks are providing satisfactory metal layer hotspot prediction results on known public metal layer benchmarks. In this work, we seek to evaluate how these machine learning-based hotspot detectors generalize to complicated patterns. We first introduce a automatic layout generation tool that can synthesize varies layout patterns given a set of design rules. The tool currently supports both metal layer and via layer generation. As a case study, we conduct hotspot detection on the generated via layer layouts with representative machine learning-based hotspot detectors, which shows that continuous study on model robustness and generality is necessary to prototype and integrate the learning engines in DFM flows. The source code of the layout generation tool will be available at https://github.com/phdyang007/layout-generation.","",""
3,"Minsung Hong, R. Akerkar","Analytics and Evolving Landscape of Machine Learning for Emergency Response",2019,"","","","",77,"2022-07-13 09:24:54","","10.1007/978-3-030-15628-2_11","","",,,,,3,1.00,2,2,3,"","",""
6,"H. Bonakdari, Ali Jamshidi, J. Pelletier, F. Abram, G. Tardif, J. Martel-Pelletier","A warning machine learning algorithm for early knee osteoarthritis structural progressor patient screening",2021,"","","","",78,"2022-07-13 09:24:54","","10.1177/1759720X21993254","","",,,,,6,6.00,1,6,1,"Aim: In osteoarthritis (OA) there is a need for automated screening systems for early detection of structural progressors. We built a comprehensive machine learning (ML) model that bridges major OA risk factors and serum levels of adipokines/related inflammatory factors at baseline for early prediction of at-risk knee OA patient structural progressors over time. Methods: The patient- and gender-based model development used baseline serum levels of six adipokines, three related inflammatory factors and their ratios (36), as well as major OA risk factors [age and bone mass index (BMI)]. Subjects (677) were selected from the Osteoarthritis Initiative (OAI) progression subcohort. The probability values of being structural progressors (PVBSP) were generated using our previously published prediction model, including five baseline structural features of the knee, i.e. two X-rays and three magnetic resonance imaging variables. To identify the most important variables amongst the 47 studied in relation to PVBSP, we employed the ML feature classification methodology. Among five supervised ML algorithms, the support vector machine (SVM) demonstrated the best accuracy and use for gender-based classifiers development. Performance and sensitivity of the models were assessed. A reproducibility analysis was performed with clinical trial OA patients. Results: Feature selections revealed that the combination of age, BMI, and the ratios CRP/MCP-1 and leptin/CRP are the most important variables in predicting OA structural progressors in both genders. Classification accuracies for both genders in the testing stage (OAI) were >80%, with the highest sensitivity of CRP/MCP-1. Reproducibility analysis showed an accuracy ⩾92%; the ratio CRP/MCP-1 demonstrated the highest sensitivity in women and leptin/CRP in men. Conclusion: This is the first time that such a framework was built for predicting knee OA structural progressors. Using this automated ML patient- and gender-based model, early prediction of knee structural OA progression can be performed with high accuracy using only three baseline serum biomarkers and two risk factors. Plain language summary Machine learning model for early knee osteoarthritis structural progression Knee osteoarthritis is a well-known debilitating disease leading to reduced mobility and quality of life – the main causes of chronic invalidity. Disease evolution can be slow and span many years; however, for some individuals, the progression/evolution can be fast. Current treatments are only symptomatic and conventional diagnosis of osteoarthritis is not very effective in early identification of patients who will progress rapidly. To improve therapeutic approaches, we need a robust prediction model to stratify osteoarthritis patients at an early stage according to risk of joint structure disease progression. We hypothesize that a prediction model using a machine learning system would enable such an early identification of individuals for whom osteoarthritis knee structure will degrade rapidly. Data were from the Osteoarthritis Initiative, a National Institute of Health (United States) databank, and the robustness and generalizability of the developed model was further evaluated using osteoarthritis patients from an external cohort. Using the supervised machine learning system (support vector machine), we developed an automated patient- and gender-based model enabling an early clinical prognosis for individuals at high risk of structural progressive osteoarthritis. In brief, this model employed at baseline (when the subject sees a physician) easily obtained features consisting of the two main osteoarthritis risk factors, age and bone mass index (BMI), in addition to the serum levels of three molecules. Two of these molecules belong to a family of factors names adipokines and one to a related inflammatory factor. In brief, the model comprising a combination of age, BMI, and the ratios CRP/MCP-1 and leptin/CRP were found very robust for both genders, and the high accuracy persists when tested with an external cohort conferring the gender-based model generalizability. This study offers a new automated system for identifying early knee osteoarthritis structural progressors, which will significantly improve clinical prognosis with real time patient monitoring.","",""
6,"O. Spjuth, Jens Frid, A. Hellander","The machine learning life cycle and the cloud: implications for drug discovery",2021,"","","","",79,"2022-07-13 09:24:54","","10.1080/17460441.2021.1932812","","",,,,,6,6.00,2,3,1,"ABSTRACT Introduction: Artificial intelligence (AI) and machine learning (ML) are increasingly used in many aspects of drug discovery. Larger data sizes and methods such as Deep Neural Networks contribute to challenges in data management, the required software stack, and computational infrastructure. There is an increasing need in drug discovery to continuously re-train models and make them available in production environments. Areas covered: This article describes how cloud computing can aid the ML life cycle in drug discovery. The authors discuss opportunities with containerization and scientific workflows and introduce the concept of MLOps and describe how it can facilitate reproducible and robust ML modeling in drug discovery organizations. They also discuss ML on private, sensitive and regulated data. Expert opinion: Cloud computing offers a compelling suite of building blocks to sustain the ML life cycle integrated in iterative drug discovery. Containerization and platforms such as Kubernetes together with scientific workflows can enable reproducible and resilient analysis pipelines, and the elasticity and flexibility of cloud infrastructures enables scalable and efficient access to compute resources. Drug discovery commonly involves working with sensitive or private data, and cloud computing and federated learning can contribute toward enabling collaborative drug discovery within and between organizations. Abbreviations: AI = Artificial Intelligence; DL = Deep Learning; GPU = Graphics Processing Unit; IaaS = Infrastructure as a Service; K8S = Kubernetes; ML = Machine Learning; MLOps = Machine Learning and Operations; PaaS = Platform as a Service; QC = Quality Control; SaaS = Software as a Service","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",80,"2022-07-13 09:24:54","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
74,"G. Chand, D. Dwyer, G. Erus, A. Sotiras, E. Varol, D. Srinivasan, J. Doshi, Raymond Pomponio, A. Pigoni, P. Dazzan, R. Kahn, H. Schnack, M. Zanetti, E. Meisenzahl, G. Busatto, B. Crespo-Facorro, C. Pantelis, S. Wood, C. Zhuo, R. Shinohara, H. Shou, Yong Fan, R. Gur, R. Gur, T. Satterthwaite, N. Koutsouleris, D. Wolf, C. Davatzikos","Two distinct neuroanatomical subtypes of schizophrenia revealed using machine learning.",2020,"","","","",81,"2022-07-13 09:24:54","","10.1093/brain/awaa025","","",,,,,74,37.00,7,28,2,"Neurobiological heterogeneity in schizophrenia is poorly understood and confounds current analyses. We investigated neuroanatomical subtypes in a multi-institutional multi-ethnic cohort, using novel semi-supervised machine learning methods designed to discover patterns associated with disease rather than normal anatomical variation. Structural MRI and clinical measures in established schizophrenia (n = 307) and healthy controls (n = 364) were analysed across three sites of PHENOM (Psychosis Heterogeneity Evaluated via Dimensional Neuroimaging) consortium. Regional volumetric measures of grey matter, white matter, and CSF were used to identify distinct and reproducible neuroanatomical subtypes of schizophrenia. Two distinct neuroanatomical subtypes were found. Subtype 1 showed widespread lower grey matter volumes, most prominent in thalamus, nucleus accumbens, medial temporal, medial prefrontal/frontal and insular cortices. Subtype 2 showed increased volume in the basal ganglia and internal capsule, and otherwise normal brain volumes. Grey matter volume correlated negatively with illness duration in Subtype 1 (r = -0.201, P = 0.016) but not in Subtype 2 (r = -0.045, P = 0.652), potentially indicating different underlying neuropathological processes. The subtypes did not differ in age (t = -1.603, d.f. = 305, P = 0.109), sex (chi-square = 0.013, d.f. = 1, P = 0.910), illness duration (t = -0.167, d.f. = 277, P = 0.868), antipsychotic dose (t = -0.439, d.f. = 210, P = 0.521), age of illness onset (t = -1.355, d.f. = 277, P = 0.177), positive symptoms (t = 0.249, d.f. = 289, P = 0.803), negative symptoms (t = 0.151, d.f. = 289, P = 0.879), or antipsychotic type (chi-square = 6.670, df = 3, P = 0.083). Subtype 1 had lower educational attainment than Subtype 2 (chi-square = 6.389, d.f. = 2, P = 0.041). In conclusion, we discovered two distinct and highly reproducible neuroanatomical subtypes. Subtype 1 displayed widespread volume reduction correlating with illness duration, and worse premorbid functioning. Subtype 2 had normal and stable anatomy, except for larger basal ganglia and internal capsule, not explained by antipsychotic dose. These subtypes challenge the notion that brain volume loss is a general feature of schizophrenia and suggest differential aetiologies. They can facilitate strategies for clinical trial enrichment and stratification, and precision diagnostics.","",""
74,"Kai Fukami, K. Fukagata, K. Taira","Machine-learning-based spatio-temporal super resolution reconstruction of turbulent flows",2020,"","","","",82,"2022-07-13 09:24:54","","10.1017/jfm.2020.948","","",,,,,74,37.00,25,3,2,"Abstract We present a new data reconstruction method with supervised machine learning techniques inspired by super resolution and inbetweening to recover high-resolution turbulent flows from grossly coarse flow data in space and time. For the present machine-learning-based data reconstruction, we use the downsampled skip-connection/multiscale model based on a convolutional neural network, incorporating the multiscale nature of fluid flows into its network structure. As an initial example, the model is applied to the two-dimensional cylinder wake at $Re_D = 100$. The reconstructed flow fields by the present method show great agreement with the reference data obtained by direct numerical simulation. Next, we apply the current model to a two-dimensional decaying homogeneous isotropic turbulence. The machine-learned model is able to track the decaying evolution from spatial and temporal coarse input data. The proposed concept is further applied to a complex turbulent channel flow over a three-dimensional domain at $Re_{\tau }=180$. The present model reconstructs high-resolved turbulent flows from very coarse input data in space, and also reproduces the temporal evolution for appropriately chosen time interval. The dependence on the number of training snapshots and duration between the first and last frames based on a temporal two-point correlation coefficient are also assessed to reveal the capability and robustness of spatio-temporal super resolution reconstruction. These results suggest that the present method can perform a range of flow reconstructions in support of computational and experimental efforts.","",""
4,"Mahender Singh, K. Singh","A Review of Publicly Available Automatic Brain Segmentation Methodologies, Machine Learning Models, Recent Advancements, and Their Comparison",2021,"","","","",83,"2022-07-13 09:24:54","","10.1177/0972753121990175","","",,,,,4,4.00,2,2,1,"Background: The noninvasive study of the structure and functions of the brain using neuroimaging techniques is increasingly being used for its clinical and research perspective. The morphological and volumetric changes in several regions and structures of brains are associated with the prognosis of neurological disorders such as Alzheimer’s disease, epilepsy, schizophrenia, etc. and the early identification of such changes can have huge clinical significance. The accurate segmentation of three-dimensional brain magnetic resonance images into tissue types (i.e., grey matter, white matter, cerebrospinal fluid) and brain structures, thus, has huge importance as they can act as early biomarkers. The manual segmentation though considered the “gold standard” is time-consuming, subjective, and not suitable for bigger neuroimaging studies. Several automatic segmentation tools and algorithms have been developed over the years; the machine learning models particularly those using deep convolutional neural network (CNN) architecture are increasingly being applied to improve the accuracy of automatic methods. Purpose: The purpose of the study is to understand the current and emerging state of automatic segmentation tools, their comparison, machine learning models, their reliability, and shortcomings with an intent to focus on the development of improved methods and algorithms. Methods: The study focuses on the review of publicly available neuroimaging tools, their comparison, and emerging machine learning models particularly those based on CNN architecture developed and published during the last five years. Conclusion: Several software tools developed by various research groups and made publicly available for automatic segmentation of the brain show variability in their results in several comparison studies and have not attained the level of reliability required for clinical studies. The machine learning models particularly three dimensional fully convolutional network models can provide a robust and efficient alternative with relation to publicly available tools but perform poorly on unseen datasets. The challenges related to training, computation cost, reproducibility, and validation across distinct scanning modalities for machine learning models need to be addressed.","",""
0,"Jha","Robust Optimization for Trajectory-Centric Model-based Reinforcement Learning /Author=Jha, D.; Kolaric, P.; Romeres, D.; Raghunathan, A.; Benosman, M.; Nikovski, D.N. /CreationDate=December 18, 2019 /Subject=Control, Machine Learning, Robotics",2019,"","","","",84,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,1,3,"This paper presents a method to perform robust trajectory optimization for trajectory-centric Model-based Reinforcement Learning (MBRL). We propose a method that allows us to use the uncertainty estimates present in predictions obtained from a model-learning algorithm to generate robustness certificates for trajectory optimization. This is done by simultaneously solving for a time-invariant controller which is optimized to satisfy a constraint to generate the robustness certificate. We first present a novel formulation of the proposed method for the robust optimization that incorporates use of local sets around a trajectory where the closed-loop dynamics of the system is stabilized using a time-invariant policy. The method is demonstrated on an inverted pendulum system with parametric uncertainty. A Gaussian process is used to learn the residual dynamics and the uncertainty sets generated by the Gaussian process are then used to generate the trajectories with the local stabilizing policy. NeurIPS Workshop on Safety and Robustness in Decision Making This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2019 201 Broadway, Cambridge, Massachusetts 02139 Robust Optimization for Trajectory-Centric Model-based Reinforcement Learning Patrik Kolaric Univ. of Texas at Arlington Fort Worth, TX patrik.kolaric@mavs.uta.edu Devesh K. Jha MERL Cambridge, MA jha@merl.com Diego Romeres MERL Cambridge, MA romeres@merl.com Arvind U. Raghunathan MERL Cambridge, MA raghunathan@merl.com Mouhacine Benosman MERL Cambridge, MA benosman@merl.com Daniel Nikovski MERL Cambridge, MA nikovski@merl.com","",""
20,"Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae","Engineering problems in machine learning systems",2019,"","","","",85,"2022-07-13 09:24:54","","10.1007/s10994-020-05872-w","","",,,,,20,6.67,7,3,3,"","",""
2,"Vuong Van Pham, E. Fathi, Fatemeh Belyadi","New Hybrid Approach for Developing Automated Machine Learning Workflows: A Real Case Application in Evaluation of Marcellus Shale Gas Production",2021,"","","","",86,"2022-07-13 09:24:54","","10.3390/fuels2030017","","",,,,,2,2.00,1,3,1,"The success of machine learning (ML) techniques implemented in different industries heavily rely on operator expertise and domain knowledge, which is used in manually choosing an algorithm and setting up the specific algorithm parameters for a problem. Due to the manual nature of model selection and parameter tuning, it is impossible to quantify or evaluate the quality of this manual process, which in turn limits the ability to perform comparison studies between different algorithms. In this study, we propose a new hybrid approach for developing machine learning workflows to help automated algorithm selection and hyperparameter optimization. The proposed approach provides a robust, reproducible, and unbiased workflow that can be quantified and validated using different scoring metrics. We have used the most common workflows implemented in the application of artificial intelligence (AI) and ML in engineering problems including grid/random search, Bayesian search and optimization, genetic programming, and compared that with our new hybrid approach that includes the integration of Tree-based Pipeline Optimization Tool (TPOT) and Bayesian optimization. The performance of each workflow is quantified using different scoring metrics such as Pearson correlation (i.e., R2 correlation) and Mean Square Error (i.e., MSE). For this purpose, actual field data obtained from 1567 gas wells in Marcellus Shale, with 121 features from reservoir, drilling, completion, stimulation, and operation is tested using different proposed workflows. A proposed new hybrid workflow is then used to evaluate the type well used for evaluation of Marcellus shale gas production. In conclusion, our automated hybrid approach showed significant improvement in comparison to other proposed workflows using both scoring matrices. The new hybrid approach provides a practical tool that supports the automated model and hyperparameter selection, which is tested using real field data that can be implemented in solving different engineering problems using artificial intelligence and machine learning. The new hybrid model is tested in a real field and compared with conventional type wells developed by field engineers. It is found that the type well of the field is very close to P50 predictions of the field, which shows great success in the completion design of the field performed by field engineers. It also shows that the field average production could have been improved by 8% if shorter cluster spacing and higher proppant loading per cluster were used during the frac jobs.","",""
2,"Recep Onler, Ahmet Selim Koca, Baris Kirim, E. Soylemez","Multi-objective optimization of binder jet additive manufacturing of Co-Cr-Mo using machine learning",2021,"","","","",87,"2022-07-13 09:24:54","","10.1007/s00170-021-08183-z","","",,,,,2,2.00,1,4,1,"","",""
1,"Vikrant V. Jadhav, C. Pennock, A. Subramaniam, R. Sagar, P. K. Nayak","UOCS – III. UVIT catalogue of open clusters with machine learning-based membership using Gaia EDR3 astrometry",2021,"","","","",88,"2022-07-13 09:24:54","","10.1093/mnras/stab213","","",,,,,1,1.00,0,5,1,"We present a study of six open clusters (Berkeley 67, King 2, NGC 2420, NGC 2477, NGC 2682 and NGC 6940) using the Ultra Violet Imaging Telescope (UVIT) aboard ASTROSAT and Gaia EDR3. We used combinations of astrometric, photometric and systematic parameters to train and supervise a machine learning algorithm along with a Gaussian mixture model for the determination of cluster membership. This technique is robust, reproducible and versatile in various cluster environments. In this study, the Gaia EDR3 membership catalogues are provided along with classification of the stars as members, candidates and field in the six clusters. We could detect 200–2500 additional members using our method with respect to previous studies, which helped estimate mean space velocities, distances, number of members and core radii. UVIT photometric catalogues, which include blue stragglers, main-sequence and red giants are also provided. From UV–Optical colour-magnitude diagrams, we found that majority of the sources in NGC 2682 and a few in NGC 2420, NGC 2477 and NGC 6940 showed excess UV flux. NGC 2682 images have ten white dwarf detection in far-UV. The far-UV and near-UV images of the massive cluster NGC 2477 have 92 and 576 members respectively, which will be useful to study the UV properties of stars in the extended turn-off and in various evolutionary stages from main-sequence to red clump. Future studies will carry out panchromatic and spectroscopic analysis of noteworthy members detected in this study.","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",89,"2022-07-13 09:24:54","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
2,"Martina Bertazzo, D. Gobbo, S. Decherchi, A. Cavalli","Machine Learning and Enhanced Sampling Simulations for Computing the Potential of Mean Force and Standard Binding Free Energy",2021,"","","","",90,"2022-07-13 09:24:54","","10.1021/acs.jctc.1c00177","","",,,,,2,2.00,1,4,1,"Computational capabilities are rapidly increasing, primarily because of the availability of GPU-based architectures. This creates unprecedented simulative possibilities for the systematic and robust computation of thermodynamic observables, including the free energy of a drug binding to a target. In contrast to calculations of relative binding free energy, which are nowadays widely exploited for drug discovery, we here push the boundary of computing the binding free energy and the potential of mean force. We introduce a novel protocol that leverages enhanced sampling, machine learning, and ad hoc algorithms to limit human intervention, computing time, and free parameters in free energy calculations. We first validate the method on a host–guest system, and then we apply the protocol to glycogen synthase kinase 3 beta, a protein kinase of pharmacological interest. Overall, we obtain a good correlation with experimental values in relative and absolute terms. While we focus on protein–ligand binding, the strategy is of broad applicability to any complex event that can be described with a path collective variable. We systematically discuss key details that influence the final result. The parameters and simulation settings are available at PLUMED-NEST to allow full reproducibility.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",91,"2022-07-13 09:24:54","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
0,"J. Figuerêdo, V. T. Sarinho, R. Calumby","Low-Cost Machine Learning for Effective and Efficient Bad Smells Detection",2021,"","","","",92,"2022-07-13 09:24:54","","10.5753/kdmile.2021.17468","","",,,,,0,0.00,0,3,1,"Bad smells are characteristics of software that indicate a code or design problem which can make information system hard to understand, evolve, and maintain. To address this problem, different approaches, manual and automated, have been proposed over the years, including more recently machine learning alternatives. However, despite the advances achieved, some machine learning techniques have not yet been effectively explored, such as the use of feature selection techniques. Moreover, it is not clear to what extent the use of numerous source-code features are necessary for reasonable bad smell detection success. Therefore, in this work we propose an approach using low-cost machine learning for effective and efficient detection of bad smells, through explicit feature selection. Our results showed that the selection allowed to statistically improve the effectiveness of the models. For some cases, the models achieved statistical equivalence, but relying on a highly reduced set of features. Indeed, by using explicit feature selection, simpler models such as Naive Bayes became statistically equivalent to robust models such as Random Forest. Therefore, the selection of features allowed keeping competitive or even superior effectiveness while also improving the efficiency of the models, demanding less computational resources for source-code preprocessing, model training and bad smell detection.","",""
0,"Olga Gorodetskaya, Yana L. Gobareva, M. Koroteev","A Machine Learning Pipeline for Forecasting Time Series in the Banking Sector",2021,"","","","",93,"2022-07-13 09:24:54","","10.3390/economies9040205","","",,,,,0,0.00,0,3,1,"The problem of forecasting time series is very widely debated. In recent years, machine learning algorithms have been very prolific in this area. This paper describes a systematic approach to building a machine learning predictive model for solving optimization problems in the banking sector. A literature analysis on applying such methods in this particular area is presented. As a direct result of the described research, a universal scenario for forecasting various non-stationary time series in automatic mode was developed. The developed scenario for solving specific banking tasks to improve business efficiency, including optimizing demand for ATMs, forecasting the load on the call center and cash center, is considered. A machine learning methodology in economics that can yield robust and reproducible results and can be reused in solving other similar tasks is described. The methodology described in the article was tested on three cases and showed the ability to generate models that are superior in accuracy to similar predictive models described in the literature by at least three percentage points. This article will be helpful to specialists dealing with the problem of forecasting economic time series and students and researchers due to a large number of links to systematic literature reviews on this topic.","",""
0,"N. Kirlic, E. Akeman, Danielle C DeVille, Hung-wen Yeh, K. Cosgrove, Timothy McDermott, James Touthang, A. Clausen, M. Paulus, R. Aupperle","A machine learning analysis of risk and protective factors of suicidal thoughts and behaviors in college students.",2021,"","","","",94,"2022-07-13 09:24:54","","10.1080/07448481.2021.1947841","","",,,,,0,0.00,0,10,1,"OBJECTIVE To identify robust and reproducible factors associated with suicidal thoughts and behaviors (STBs) in college students.   METHODS 356 first-year university students completed a large battery of demographic and clinically-relevant self-report measures during the first semester of college and end-of-year (n = 228). Suicide Behaviors Questionnaire-Revised (SBQ-R) assessed STBs. A machine learning (ML) pipeline using stacking and nested cross-validation examined correlates of SBQ-R scores.   RESULTS 9.6% of students were identified at significant STBs risk by the SBQ-R. The ML algorithm explained 28.3% of variance (95%CI: 28-28.5%) in baseline SBQ-R scores, with depression severity, social isolation, meaning and purpose in life, and positive affect among the most important factors. There was a significant reduction in STBs at end-of-year with only 1.8% of students identified at significant risk.   CONCLUSION Analyses replicated known factors associated with STBs during the first semester of college and identified novel, potentially modifiable factors including positive affect and social connectedness.","",""
0,"S. Turner","Extragalactic machine learning: in theory and in practice",2021,"","","","",95,"2022-07-13 09:24:54","","10.24377/LJMU.T.00014348","","",,,,,0,0.00,0,1,1,"Galaxy evolution is complicated. Throughout their lifetimes, galaxies are subject to an amalgamation of astrophysical and cosmological processes that direct the growth of their stellar masses, the transformation of their morphologies, and the cessation of their star formation. The variable action of these processes begets a diverse population of galaxies, which exhibit a variety of brightnesses, colours, shapes, and sizes, among myriad other features. Many of these features are bimodally distributed, which has led to the general acceptance of a simple empirical paradigm of galaxy evolution. However, connecting this diversity among galaxies with the array of processes that are involved in their evolution, and constraining the relative influences of each of these processes, requires that several features are analysed simultaneously. This has been enabled by the recent advent of machine learning techniques, which are capable of extracting scientifically useful information from complicated, multi-dimensional datasets, to astronomy and astrophysics. Unsupervised machine learning techniques, free from the requirement for pre-labelled training data, are especially well suited to the exploration of the data structures of galaxy samples in multi-dimensional feature spaces. This thesis assesses the use of clustering, an unsupervised machine learning technique, for the research of galaxy evolution. Clustering is first tested on a well-characterised sample of galaxies from the GAMA survey. Galaxies are represented in five dimensions by a set of intrinsic astrophysical features. Use of a unique cluster evaluation framework enables the robust identification of reproducible and astrophysically meaningful clustering structures via the k-means method. Outcomes consisting of two, three, five, and six clusters are deemed stable, and form a hierarchical structure that agrees well with established notions of the galaxy bimodality. The two- and three-cluster outcomes are dominated in their structures by the stellar masses, colours, and star formation activity of galaxies, with Sersic indices and half-light radii becoming important for the five- and six-cluster outcomes. Clusters also exhibit broad correspondence with detailed morphological classifications, and it is suggested that the inclusion of additional morphological features might improve this correspondence further. The five- and six-cluster outcomes indicate the differential role of environment in the evolution of galaxies with intermediate colours. This cluster evaluation framework is then applied for the validation of the cosmological, hydrodynamical EAGLE simulations against the GAMA survey. Outcomes consisting of seven and five clusters respectively, determined using the same five features for both samples, are selected for analysis. These outcomes produce an agreement score of Vₐ = 0.76, indicating broad, overall agreement, but differences in their substructures. These differences include discrepancies in the growth of the central bulges of galaxies along the star-forming main sequence, an over-abundance of low-mass, bulge-dominated, star-forming galaxies in the EAGLE sample, and a subpopulation of high-mass, disc-dominated, star-forming galaxies in the EAGLE sample that is not present in the GAMA sample. These differences are attributed to the resolution of EAGLE, and to an active galactic nucleus feedback prescription that is not sufficiently effective in EAGLE. Finally, clustering is used to compare samples of galaxies at low (z ~ 0.06; GSWLC-2) and intermediate (z ~ 0.67; VIPERS) redshifts, in order to examine the evolution of subpopulations of galaxies. Galaxies are clustered in a nine-dimensional feature space defined by a series of ultraviolet-through-near-infrared colours using the Subspace Expectation-Maximisation algorithm, which includes iterative dimensionality reduction. The algorithm models both samples using seven clusters: four containing mostly star-forming galaxies, and three containing mostly passive galaxies. Both sets of star-forming clusters form clear morphological sequences, capturing the gradual internally-driven growth of galaxy bulges at both epochs. At high stellar masses, this growth is linked with quenching. However, it is only at low redshifts that additional, environmental processes appear to be involved in the evolution of low-mass passive galaxies. The results of this thesis demonstrate the utility of clustering as a method with which to analyse the large galaxy samples that are anticipated from next-generation surveys, and with which to facilitate the multi-dimensional comparison of cosmological galaxy simulations with observations. Clustering is robustly able to identify astrophysically meaningful substructures in complex, multi-dimensional feature spaces, and these substructures may readily be interpreted with respect to the evolutionary contexts of the galaxies that they encompass.","",""
0,"Uma Gunasilan","Debate as a learning activity for teaching programming: a case in the subject of machine learning",2021,"","","","",96,"2022-07-13 09:24:54","","10.1108/heswbl-01-2021-0006","","",,,,,0,0.00,0,1,1,"PurposeDebates are well known to encompass a variety of skills we would like higher education candidates to embody when they graduate.Design/methodology/approachDebates in a classroom with computer science as the main subject has been popular in high schools particularly with emerging issues around the area, however it does not have as an extensive similar documented outreach in tertiary education, particularly in the area of hard computer sciences and more recent concentrations of computer science, such as machine learning, artificial intelligence and cloud computing.FindingsTo explore further, the debate dataset had more methodologies applied and was split into training and testing sets, whose results were then compared by a standardized measure: Root Mean Square Error (RMSE) which is currently standard in the industry. The rationale of the approach is to quantify that debate activities have an immensely positive impact towards both the teaching and learning in technical subjects and needs to be more often and robustly used within higher education.Originality/valueThe rationale of the approach is that classroom debate activities equip students with verbal and social learning styles and an opportunity to engage with content in a way that is more comfortable than working with traditional lecture-and-laboratory style learning.","",""
0,"Yinyihong Liu","Airbnb Pricing Based on Statistical Machine Learning Models",2021,"","","","",97,"2022-07-13 09:24:54","","10.1109/CONF-SPML54095.2021.00042","","",,,,,0,0.00,0,1,1,"Being one of the largest online accommodation booking platforms, Airbnb has many hosts who are seeking for more proper prices to increase their booking rate. To develop a good pricing prediction model, this paper has employed machine learning models including KNN, MLR, LASSO regression, Ridge regression, Random Forest, Gradient Boosting and XGBoost etc. While past studies on Airbnb pricing have applied quantitative pricing, some face the problems that the models are not robust enough and some face the problem of not training the model plentily. To fill this gap, we give careful consideration in exploratory data analysis to make the dataset more reasonable, apply many robust models ranging from regularized regression to ensemble models and use cross validation and random search to tune each parameter in each model. In this way, we not only select XGBoost as the best model for price prediction with R2 score 0.6321, but also uncover the features which have statistical significance with the target price.","",""
0,"Maria Sailer, F. Schiller, Thorsten Falk, A. Jud, Sven Arke Lang, J. Ruf, M. Mix","Prediction of the histopathological tumor type of newly diagnosed liver lesions from standard abdominal computer tomography with a machine-learning classifier based on convolutional neural networks",2021,"","","","",98,"2022-07-13 09:24:54","","10.1515/cdbme-2021-1032","","",,,,,0,0.00,0,7,1,"Abstract Background and objectives: Liver lesions are a relatively common incidental finding in computer tomography (CT) of the abdomen. The current gold standard is liver biopsy, which has the downside of respecting only a small part of the total lesion volume. Furthermore, this invasive method carries interventional risks like bleeding or infection. Therefore, an image-based biomarker would be highly desirable. Conventional “radiomics” methods have often been utilized for similar problems, but the results are often not reproducible. This is mainly due to sampling errors and interobserver variability, but also the seemingly complex nature of the problem. We present a new approach that implements cutting-edge research in machine learning which is nevertheless cheap and easily applicable in a routine clinical setting. To achieve this, we use convolutional neural networks (CNN) to predict the histopathological findings from liver lesions from preoperative liver CT. Methods: After splitting the study population into a training and test set we trained a CNN to predict the histopathological tumor type from CT data. Results: The developed CNN workflow is able to predict liver tumor histology from routine CT images. We also evaluated in how far transfer learning and data augmentation can help in solving this problem and implemented the developed workflow in a clinical routine setting. Conclusion: We propose a robust semiautomatic end-to-end classification workflow for the prediction of the histopathological type of tumor lesions based on abdominal CT and a deep convolutional neural network model. In our cohort, the model shows reliable and accurate results even with limited computational resources.","",""
26,"A. Michel, A. Morrison, Victoria L. Preston, Charles T. Marx, Beckett C. Colson, H. K. White","Rapid Identification of Marine Plastic Debris via Spectroscopic Techniques and Machine Learning Classifiers.",2020,"","","","",99,"2022-07-13 09:24:54","","10.1021/acs.est.0c02099","","",,,,,26,13.00,4,6,2,"To advance our understanding of the environmental fate and transport of macro- and micro-plastic debris, robust and reproducible methods, technologies, and analytical approaches are necessary for in situ plastic-type identification and characterization. This investigation compares four spectroscopic techniques: attenuated total reflectance - Fourier transform infrared spectroscopy (ATR-FTIR), near-infrared (NIR) reflectance spectroscopy, laser-induced breakdown spectroscopy (LIBS), and X-ray fluorescence (XRF) spectroscopy, coupled to seven classification methods, including machine learning classifiers, to determine accuracy for identifying type of both consumer plastics and marine plastic debris. With machine learning classifiers, consumer plastic types were identified with 99%, 91%, 97%, and 70% success rates for ATR-FTIR, NIR reflectance spectroscopy, LIBS, and XRF respectively. The classification of marine plastic debris had similar or lower success rates likely arising from alterations to the plastic from environmental weathering processes with success rates of 99%, 81%, 76%, and 66% for ATR-FTIR, NIR reflectance spectroscopy, LIBS, and XRF respectively. Success rates of 76% and higher indicate that ATR-FTIR, NIR reflectance spectroscopy, and LIBS coupled to machine learning classifiers can be used to robustly identify both consumer and environmental plastic samples.","",""
8,"Mustafa Anil Koçak, David Ramirez, E. Erkip, D. Shasha","SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness",2017,"","","","",100,"2022-07-13 09:24:54","","10.1109/TPAMI.2019.2932415","","",,,,,8,1.60,2,4,5,"<italic>SafePredict</italic> is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, <inline-formula><tex-math notation=""LaTeX"">$1-\epsilon$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""kocak-ieq1-2932415.gif""/></alternatives></inline-formula>, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm so that the error rate on non-refused predictions does not exceed <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq2-2932415.gif""/></alternatives></inline-formula>. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq3-2932415.gif""/></alternatives></inline-formula>, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the-art confidence-based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software is included in the supplementary material, which can be found on the Computer Society Digital Library at <uri>http://doi.ieeecomputersociety.org/10.1109/TPAMI.2019.2932415</uri>.","",""
0,"Ransalu Senanayake, Daniel J. Fremont, Mykel J. Kochenderfer, A. Lomuscio, D. Margineantu, Cheng Soon Ong","Guest Editorial: Special issue on robust machine learning",2021,"","","","",101,"2022-07-13 09:24:54","","10.1007/s10994-021-06113-4","","",,,,,0,0.00,0,6,1,"","",""
5,"R. Gafeira, D. O. Su'arez, I. Milić, C. Q. Noda, B. R. Cobo, H. Uitenbroek","Machine learning initialization to accelerate Stokes profile inversions",2021,"","","","",102,"2022-07-13 09:24:54","","10.1051/0004-6361/201936910","","",,,,,5,5.00,1,6,1,"Context. At present, an exponential growth in scientific data from current and upcoming solar observatories is expected. Most of the data consist of high spatial and temporal resolution cubes of Stokes profiles taken in both local thermodynamic equilibrium (LTE) and non-LTE spectral lines. The analysis of such solar observations requires complex inversion codes. Hence, it is necessary to develop new tools to boost the speed and efficiency of inversions and reduce computation times and costs. Aims. In this work we discuss the application of convolutional neural networks (CNNs) as a tool to advantageously initialize Stokes profile inversions. Methods. To demonstrate the usefulness of CNNs, we concentrate in this paper on the inversion of LTE Stokes profiles. We use observations taken with the spectropolarimeter on board the Hinode spacecraft as a test bench mark. First, we carefully analyse the data with the SIR inversion code using a given initial atmospheric model. The code provides a set of atmospheric models that reproduce the observations well. These models are then used to train a CNN. Afterwards, the same data are again inverted with SIR but using the trained CNN to provide the initial guess atmospheric models for SIR. Results. The CNNs allow us to significantly reduce the number of inversion cycles when used to compute initial guess model atmospheres (‘assisted inversions’), therefore decreasing the computational time for LTE inversions by a factor of two to four. CNNs alone are much faster than assisted inversions, but the latter are more robust and accurate. CNNs also help to automatically cluster pixels with similar physical properties, allowing the association with different solar features on the solar surface, which is useful when inverting huge datasets where completely different regimes are present. The advantages and limitations of machine learning techniques for estimating optimum initial atmospheric models for spectral line inversions are discussed. Finally, we describe a python wrapper for the SIR and DeSIRe codes that allows for the easy setup of parallel inversions. The tool implements the assisted inversion method described in this paper. The parallel wrapper can also be used to synthesize Stokes profiles with the RH code. Conclusions. The assisted inversions can speed up the inversion process, but the efficiency and accuracy of the inversion results depend strongly on the solar scene and the data used for the CNN training. This method (assisted inversions) will not obviate the need for analysing individual events with the utmost care but will provide solar scientists with a much better opportunity to sample large amounts of inverted data, which will undoubtedly broaden the physical discovery space.","",""
5,"Stefan Klus, Patrick Gelß, F. Nüske, Frank No'e","Symmetric and antisymmetric kernels for machine learning problems in quantum physics and chemistry",2021,"","","","",103,"2022-07-13 09:24:54","","10.1088/2632-2153/ac14ad","","",,,,,5,5.00,1,4,1,"We derive symmetric and antisymmetric kernels by symmetrizing and antisymmetrizing conventional kernels and analyze their properties. In particular, we compute the feature space dimensions of the resulting polynomial kernels, prove that the reproducing kernel Hilbert spaces induced by symmetric and antisymmetric Gaussian kernels are dense in the space of symmetric and antisymmetric functions, and propose a Slater determinant representation of the antisymmetric Gaussian kernel, which allows for an efficient evaluation even if the state space is high-dimensional. Furthermore, we show that by exploiting symmetries or antisymmetries the size of the training data set can be significantly reduced. The results are illustrated with guiding examples and simple quantum physics and chemistry applications.","",""
3,"Dohoon Lee, Youngjune Park, Sun Kim","Towards multi-omics characterization of tumor heterogeneity: a comprehensive review of statistical and machine learning approaches",2020,"","","","",104,"2022-07-13 09:24:54","","10.1093/bib/bbaa188","","",,,,,3,1.50,1,3,2,"The multi-omics molecular characterization of cancer opened a new horizon for our understanding of cancer biology and therapeutic strategies. However, a tumor biopsy comprises diverse types of cells limited not only to cancerous cells but also to tumor microenvironmental cells and adjacent normal cells. This heterogeneity is a major confounding factor that hampers a robust and reproducible bioinformatic analysis for biomarker identification using multi-omics profiles. Besides, the heterogeneity itself has been recognized over the years for its significant prognostic values in some cancer types, thus offering another promising avenue for therapeutic intervention. A number of computational approaches to unravel such heterogeneity from high-throughput molecular profiles of a tumor sample have been proposed, but most of them rely on the data from an individual omics layer. Since the heterogeneity of cells is widely distributed across multi-omics layers, methods based on an individual layer can only partially characterize the heterogeneous admixture of cells. To help facilitate further development of the methodologies that synchronously account for several multi-omics profiles, we wrote a comprehensive review of diverse approaches to characterize tumor heterogeneity based on three different omics layers: genome, epigenome and transcriptome. As a result, this review can be useful for the analysis of multi-omics profiles produced by many large-scale consortia. Contact:sunkim.bioinfo@snu.ac.kr.","",""
3,"Dohoon Lee, Youngjune Park, Sun Kim","Towards multi-omics characterization of tumor heterogeneity: a comprehensive review of statistical and machine learning approaches.",2021,"","","","",105,"2022-07-13 09:24:54","","10.1093/bib/bbaa188","","",,,,,3,3.00,1,3,1,"The multi-omics molecular characterization of cancer opened a new horizon for our understanding of cancer biology and therapeutic strategies. However, a tumor biopsy comprises diverse types of cells limited not only to cancerous cells but also to tumor microenvironmental cells and adjacent normal cells. This heterogeneity is a major confounding factor that hampers a robust and reproducible bioinformatic analysis for biomarker identification using multi-omics profiles. Besides, the heterogeneity itself has been recognized over the years for its significant prognostic values in some cancer types, thus offering another promising avenue for therapeutic intervention. A number of computational approaches to unravel such heterogeneity from high-throughput molecular profiles of a tumor sample have been proposed, but most of them rely on the data from an individual omics layer. Since the heterogeneity of cells is widely distributed across multi-omics layers, methods based on an individual layer can only partially characterize the heterogeneous admixture of cells. To help facilitate further development of the methodologies that synchronously account for several multi-omics profiles, we wrote a comprehensive review of diverse approaches to characterize tumor heterogeneity based on three different omics layers: genome, epigenome and transcriptome. As a result, this review can be useful for the analysis of multi-omics profiles produced by many large-scale consortia. Contact:sunkim.bioinfo@snu.ac.kr.","",""
1,"Devontae C. Baxter, M. Cooper, S. Fillingham","A machine learning approach to measuring the quenched fraction of low-mass satellites beyond the Local Group",2021,"","","","",106,"2022-07-13 09:24:54","","10.1093/mnras/stab523","","",,,,,1,1.00,0,3,1,"Observations suggest that satellite quenching plays a major role in the buildup of passive, low-mass galaxies at late cosmic times. Studies of low-mass satellites, however, are limited by the ability to robustly characterize the local environment and star-formation activity of faint systems. In an effort to overcome the limitations of existing data sets, we utilize deep photometry in Stripe 82 of the Sloan Digital Sky Survey, in conjunction with a neural network classification scheme, to study the suppression of star formation in low-mass satellite galaxies in the local Universe. Using a statistically-driven approach, we are able to push beyond the limits of existing spectroscopic data sets, measuring the satellite quenched fraction down to satellite stellar masses of ∼107 M in group environments (Mhalo = 1013−14 h−1 M ). At high satellite stellar masses (& 10 M ), our analysis successfully reproduces existing measurements of the quenched fraction based on spectroscopic samples. Pushing to lower masses, we find that the fraction of passive satellites increases, potentially signaling a change in the dominant quenching mechanism at M? ∼ 10 M . Similar to the results of previous studies of the Local Group, this increase in the quenched fraction at low satellite masses may correspond to an increase in the efficacy of ram-pressure stripping as a quenching mechanism in groups.","",""
1,"Zhen Guo, J. Song, G. Barbastathis, M. Glinsky, C. Vaughan, K. Larson, B. Alpert, Z. Levine","Advantage of Machine Learning over Maximum Likelihood in Limited-Angle Low-Photon X-Ray Tomography",2021,"","","","",107,"2022-07-13 09:24:54","","","","",,,,,1,1.00,0,8,1,"Limited-angle X-ray tomography reconstruction is an illconditioned inverse problem in general. Especially when the projection angles are limited and the measurements are taken in a photon-limited condition, reconstructions from classical algorithms such as filtered backprojection may lose fidelity and acquire artifacts due to the missing-cone problem. To obtain satisfactory reconstruction results, prior assumptions, such as total variation minimization and nonlocal image similarity, are usually incorporated within the reconstruction algorithm. In this work, we introduce deep neural networks to determine and apply a prior distribution in the reconstruction process. Our neural networks learn the prior directly from synthetic training samples. The neural nets thus obtain a prior distribution that is specific to the class of objects we are interested in reconstructing. In particular, we used deep generative models with 3D convolutional layers and 3D attention layers which are trained on 3D synthetic integrated circuit (IC) data from a model dubbed CircuitFaker. We demonstrate that, when the projection angles and photon budgets are limited, the priors from our deep generative models can dramatically improve the IC reconstruction quality on synthetic data compared with maximum likelihood estimation. Training the deep generative models with synthetic IC data from CircuitFaker illustrates the capabilities of the learned prior from machine learning. We expect that if the process were reproduced with experimental data, the advantage of the machine learning would persist. The advantages of machine learning in limited angle X-ray tomography may further enable applications in low-photon nanoscale imaging. Background Limited-angle X-ray tomography has the ability to image the interior of three-dimensional (3D) objects non-invasively without collecting the measurements from a full set of rotation angles. It has drawn wide attention in practical nanoscale imaging due to its advantage in having a relatively short data acquisition time. Also, in some cases, not all angles are physically accessible. Typically, the tomographic imaging system consists of a sample holder, an objective zone plate, and a CCD camera, and the illumination is generated from the X-ray source. The measurements are taken from a series of rotational angles with respect to the sample of interest, where a cone-beam geometry is generally assumed to produce the ray projection from the source point to the sample, and then from sample to the center of each detector pixel. After the measurements, objects subsequently can be reconstructed based on 3D computed tomography algorithms. Theoretically, full-angle measurement is preferred to avoid the missing cone problem in the reconstruction process. In practice, however, limited-angle measurement is often used due to the time of acquiring the full angle measurement. For objects or samples that are radiation sensitive, a low-photon budget per scan is also preferred to minimize the total exposure and potential damage. Limited-angle X-ray tomography is an ill-conditioned inverse problem [1, 2], where the goal is to find a discrete representation of an object f based on the observations g taken on a digital camera at limited number of angles. When limited-angle tomography is applied where the illumination is limited to only a few photons, the noise sensitivity of poor conditioning becomes even more evident: not only do the collected Fourier slices cover the Fourier space unevenly due to the limited scans, they are also inaccurate due to the presence of shot noise in the measurements. Limited angle X-ray tomography therefore has had limited utility for radiation sensitive samples. To solve the limited angle X-ray tomography with photon scarcity, regularization is required during the reconstruction process. Some improvement can be obtained by extrapolating missing data [3]. Data consistency conditions, e.g., the Helgason-Ludwig consistency conditions, further improves the quality of extrapolation [4]. Still, extrapolating methods are struggling with complex structures and are not robust to noise in the experimental measurements. Iterative algorithms with constraints known a priori reconstruct the object using multiple steps. The algorithms start with an assumed object, simulate the measurement from the assumed object, compare the experimental measurements and simulated measurements, and then update the object based on the difference between measurements and simulations. The last step also includes discrepancy in the prior terms into the computation of the update. The process continues until a certain convergence criterion is achieved. Iterative algorithms with prior constraints such as total variation minimization and nonlocal image similarity often exhibit improved resilience to noise. Previously, we also have shown a Bayesian approach [5] based on the Bouman-Sauer formulation for the iterative reconstruction algorithm [6]. The regularization constrains the iterative optimization to a subdomain in which the object belongs, thereby effectively improving the reconstruction quality [7, 8]. Recently, machine learning has been applied successfully to ar X iv :2 11 1. 08 01 1v 2 [ ee ss .I V ] 1 8 D ec 2 02 1 limited-angle tomography to overcome the challenge in solving the inverse problem. Efforts have been made in using learned priors to provide information of missing data during reconstruction [9, 10, 11]. In particular, deep learning, a subset of machine learning that is based on artificial neural networks with representation learning, achieved promising results [11, 12, 13]. For tomographic inverse problems, U-net-like neural network architectures [14] have been widely used to produce reconstruction pixel-by-pixel. For example, U-net has been used to predict invisible singularities in the image object [12], to generate missing projections with a data-consistent reconstruction method [13], and to improve the reconstruction quality from the conventional FBP method [11]. Unlike the general priors in iterative algorithms, the learned prior from a deep learning method is conditioned on a large amount of paired training data. Therefore, the learned prior explores the statistical property of the training distribution. In this work, we extend the application of limited-angle Xray tomography to experimental conditions of low-photon incidence. To approximate the resulting ill-conditioned inverse problem and to obtain a satisfactory reconstruction quality, we apply machine learning to determine a prior distribution for the reconstruction process. In particular, we use deep generative models with 3D convolution and 3D attention which are trained on 3D synthetic integrated circuit (IC) data from a model dubbed CircuitFaker. We demonstrate that the priors from our deep generative models drastically improve the IC reconstruction quality on synthetic data from maximum likelihood estimation when the projection angles and photon budgets are limited. Beyond existing research that uses machine learning for limited angle X-ray tomography, our generative model exhibits improvements over maximum likelihood reconstructions under low-photon conditions. We further examine different neural network architectures to reveal some of the important network design choices for solving the inverse problem. Method The overall pipeline of our method is organized as follows: First, we generate synthetic integrated circuit (IC) layouts using CircuitFaker, an in-house model. Then, we simulate the limitedangle X-ray tomography radiographs. Next, we apply the maximum likelihood method to generate an initial IC reconstruction. Finally, we feed the initial IC reconstruction to the (trained) deep generative model and compare the reconstruction quality of the test set by calculating the bit error rate. CircuitFaker CircuitFaker is an algorithm that generates a random set of voxels with binary values which resembles an integrated circuit interconnect. The synthetic circuits from CircuitFaker is the class of artificial objects for tomographic reconstruction, and the implicit correlations in their spatial features are the priors to be assumed or to be learned for the inverse algorithms. A particular draw of CircuitFaker assigns a bit in each of N = NxNyNz locations. These locations are indexed as i` = 1, ...,N`, with ` = 1, 2, 3 for x, y, and z. All bits are initialized to 0. In the first round, there are wire seed points for all locations (i1, i2, i3) with i1, ..., i3 odd. Each seed point is set by a Bernoulli draw with probability pw of getting a 1. There are three kinds of layers, x, y, and via Figure 1. Selected 16× 16× 8 circuit from CircuitFaker. Each image is a slice of 2D layer in the z dimension. The value of z increases as a raster scan of the 8 slices shown. Black indicates copper and white indicates silicon. Here, x layers are the first and fifth layers in z, y layers are the third and seventh layers in z. Others are via layers. layers. The x wiring layers have index i3 = 1 mod 4. The y wiring layers have i3 = 3 mod 4. The via layers are the others, i.e., i3 even. In the second round, a point on an x wiring layer to the immediate right of a point with value 1 is set to 1 with probability px. A point on a y wiring layer immediately above in plan view a point with a value 1 is set to 1 with probability py. Similarly, a point on a via layer immediately above a point with a value 1 is set to 1 with probability pz. In this paper, we chose these parameters: Nx = Ny = 16, Nz = 8, pw = 0.75, px = py = 0.8, and pz = 0.5. Fig. 1 shows one of the generated circuits with size 16×16×8. Imaging geometry for X-ray tomography We assumed that each voxel in the circuit is in size of size 0.15 μm × 0.15 μm × 0.30 μm. Therefore, the total volume of the circuit is 2.4 μm× 2.4 μm× 2.4 μm. The detector is assumed to be in the x-z plane at a tilt angle of φ = 0◦. The rotation axis is ","",""
0,"T. Martin, S. Areibi, G. Grewal","Effective Machine-Learning Models for Predicting Routability During FPGA Placement",2021,"","","","",108,"2022-07-13 09:24:54","","10.1109/MLCAD52597.2021.9531243","","",,,,,0,0.00,0,3,1,"The ability to efficiently and accurately predict placement routability, while avoiding the large computational cost of performing routing, is an asset when seeking to reduce total placement and routing runtime. In this paper, we present a series of simple ML models and ensembles to predict the routability of a placement solution. Ensembles based on Bagging, Boosting and Stack of classifiers are introduced to produce more accurate and robust solutions than single/simple models. Our results show an improvement in prediction accuracy and runtime compared to the best published results in the literature.","",""
13,"Jinlong Liu, Christopher J. Ulishney, C. Dumitrescu","Random Forest Machine Learning Model for Predicting Combustion Feedback Information of a Natural Gas Spark Ignition Engine",2020,"","","","",109,"2022-07-13 09:24:54","","10.1115/1.4047761","","",,,,,13,6.50,4,3,2,"  Engine calibration requires detailed feedback information that can reflect the combustion process as the optimized objective. Indicated mean effective pressure (IMEP) is such an indicator describing an engine’s capacity to do work under different combinations of control variables. In this context, it is of interest to find cost-effective solutions that will reduce the number of experimental tests. This paper proposes a random forest machine learning model as a cost-effective tool for optimizing engine performance. Specifically, the model estimated IMEP for a natural gas spark ignited engine obtained from a converted diesel engine. The goal was to develop an economical and robust tool that can help reduce the large number of experiments usually required throughout the design and development of internal combustion engines. The data used for building such correlative model came from engine experiments that varied the spark advance, fuel-air ratio, and engine speed. The inlet conditions and the coolant/oil temperature were maintained constant. As a result, the model inputs were the key engine operation variables that affect engine performance. The trained model was shown to be able to predict the combustion-related feedback information with good accuracy (R2 ≈ 0.9 and MSE ≈ 0). In addition, the model accurately reproduced the effect of control variables on IMEP, which would help narrow the choice of operating conditions for future designs of experiment. Overall, the machine learning approach presented here can provide new chances for cost-efficient engine analysis and diagnostics work.","",""
12,"C. Fisher, H. J. Hoeijmakers, D. Kitzmann, Pablo M'arquez-Neila, S. Grimm, R. Sznitman, K. Heng","Interpreting High-resolution Spectroscopy of Exoplanets using Cross-correlations and Supervised Machine Learning",2019,"","","","",110,"2022-07-13 09:24:54","","10.3847/1538-3881/ab7a92","","",,,,,12,4.00,2,7,3,"We present a new method for performing atmospheric retrieval on ground-based, high-resolution data of exoplanets. Our method combines cross-correlation functions with a random forest, a supervised machine learning technique, to overcome challenges associated with high-resolution data. A series of cross-correlation functions are concatenated to give a ""CCF-sequence"" for each model atmosphere, which reduces the dimensionality by a factor of ~100. The random forest, trained on our grid of ~65,000 models, provides a likelihood-free method of retrieval. The pre-computed grid spans 31 values of both temperature and metallicity, and incorporates a realistic noise model. We apply our method to HARPS-N observations of the ultra-hot Jupiter KELT-9b, and obtain a metallicity consistent with solar (logM = $-0.2\pm0.2$). Our retrieved transit chord temperature (T = $6000^{+0}_{-200}$K) is unreliable as the ion cross-correlations lie outside of the training set, which we interpret as being indicative of missing physics in our atmospheric model. We compare our method to traditional nested-sampling, as well as other machine learning techniques, such as Bayesian neural networks. We demonstrate that the likelihood-free aspect of the random forest makes it more robust than nested-sampling to different error distributions, and that the Bayesian neural network we tested is unable to reproduce complex posteriors. We also address the claim in Cobb et al. (2019) that our random forest retrieval technique can be over-confident but incorrect. We show that this is an artefact of the training set, rather than the machine learning method, and that the posteriors agree with those obtained using nested-sampling.","",""
12,"Liangyuan Hu, Bian Liu, J. Ji, Yan Li","Tree‐Based Machine Learning to Identify and Understand Major Determinants for Stroke at the Neighborhood Level",2020,"","","","",111,"2022-07-13 09:24:54","","10.1161/JAHA.120.016745","","",,,,,12,6.00,3,4,2,"Background Stroke is a major cardiovascular disease that causes significant health and economic burden in the United States. Neighborhood community‐based interventions have been shown to be both effective and cost‐effective in preventing cardiovascular disease. There is a dearth of robust studies identifying the key determinants of cardiovascular disease and the underlying effect mechanisms at the neighborhood level. We aim to contribute to the evidence base for neighborhood cardiovascular health research. Methods and Results We created a new neighborhood health data set at the census tract level by integrating 4 types of potential predictors, including unhealthy behaviors, prevention measures, sociodemographic factors, and environmental measures from multiple data sources. We used 4 tree‐based machine learning techniques to identify the most critical neighborhood‐level factors in predicting the neighborhood‐level prevalence of stroke, and compared their predictive performance for variable selection. We further quantified the effects of the identified determinants on stroke prevalence using a Bayesian linear regression model. Of the 5 most important predictors identified by our method, higher prevalence of low physical activity, larger share of older adults, higher percentage of non‐Hispanic Black people, and higher ozone levels were associated with higher prevalence of stroke at the neighborhood level. Higher median household income was linked to lower prevalence. The most important interaction term showed an exacerbated adverse effect of aging and low physical activity on the neighborhood‐level prevalence of stroke. Conclusions Tree‐based machine learning provides insights into underlying drivers of neighborhood cardiovascular health by discovering the most important determinants from a wide range of factors in an agnostic, data‐driven, and reproducible way. The identified major determinants and the interactive mechanism can be used to prioritize and allocate resources to optimize community‐level interventions for stroke prevention.","",""
11,"H. Jo, Javier E. Santos, M. Pyrcz","Conditioning well data to rule-based lobe model by machine learning with a generative adversarial network",2020,"","","","",112,"2022-07-13 09:24:54","","10.1177/0144598720937524","","",,,,,11,5.50,4,3,2,"Rule-based reservoir modeling methods integrate geological depositional process concepts to generate reservoir models that capture realistic geologic features for improved subsurface predictions and uncertainty models to support development decision making. However, the robust and direct conditioning of these models to subsurface data, such as well logs, core descriptions, and seismic inversions and interpretations, remains as an obstacle for the broad application as a standard subsurface modeling technology. We implement a machine learning-based method for fast and flexible data conditioning of rule-based models. This study builds on a rule-based modeling method for deep-water lobe reservoirs. The model has three geological inputs: (1) the depositional element geometry, (2) the compositional exponent for element stacking pattern, and (3) the distribution of petrophysical properties with hierarchical trends conformable to the surfaces. A deep learning-based workflow is proposed for robust and non-iterative data conditioning. First, a generative adversarial network learns salient geometric features from the ensemble of the training rule-based models. Then, a new rule-based model is generated and a mask is applied to remove the model near local data along the well trajectories. Last, semantic image inpainting restores the mask with the optimum generative adversarial network realization that is consistent with both local data and the surrounding model. For the deep-water lobe example, the generative adversarial network learns the primary geological spatial features to generate reservoir realizations that reproduce hierarchical trend as well as the surface geometries and stacking pattern. Moreover, the trained generative adversarial network explores the latent reservoir manifold and identifies the ensemble of models to represent an uncertainty model. Semantic image inpainting determines the optimum replacement for the near-data mask that is consistent with the local data and the rest of the model. This work results in subsurface models that accurately reproduce reservoir heterogeneity, continuity, and spatial distribution of petrophysical parameters while honoring the local well data constraints.","",""
21,"Aaron M. Smith, J. Walsh, John J Long, Craig B Davis, Peter V. Henstock, M. Hodge, M. Maciejewski, X. Mu, Stephen Ra, Shanrong Zhao, D. Ziemek, Charles K. Fisher","Standard machine learning approaches outperform deep representation learning on phenotype prediction from transcriptomics data",2020,"","","","",113,"2022-07-13 09:24:54","","10.1186/s12859-020-3427-8","","",,,,,21,10.50,2,12,2,"","",""
7,"C. Chang, S. Ku, R. Hager, R. Churchill, J. Hughes, F. Köchl, A. Loarte, V. Parail, R. Pitts","Constructing a new predictive scaling formula for ITER's divertor heat-load width informed by a simulation-anchored machine learning",2020,"","","","",114,"2022-07-13 09:24:54","","10.1063/5.0027637","","",,,,,7,3.50,1,9,2,"Understanding and predicting divertor heat-load width λq is a critically important problem for an easier and more robust operation of ITER with high fusion gain. Previous predictive simulation data for λq using the extreme-scale edge gyrokinetic code XGC1 [S. Ku et al., Phys. Plasmas 25, 056107 (2018)] in the electrostatic limit under attached divertor plasma conditions in three major US tokamaks [C. S. Chang et al., Nucl. Fusion 57, 116023 (2017)] reproduced the Eich and Goldston attached-divertor formula results [formula #14 in T. Eich et al., Nucl. Fusion 53, 093031 (2013) and R. J. Goldston, Nucl. Fusion 52, 013009 (2012)] and furthermore predicted over six times wider λq than the maximal Eich and Goldston formula predictions on a full-power (Q = 10) scenario ITER plasma. After adding data from further predictive simulations on a highest current JET and highest-current Alcator C-Mod, a machine learning program is used to identify a new scaling formula for λq as a simple modification to the Eich formula #14, which reproduces the Eich scaling formula for the present tokamaks and which embraces the wide λqXGC for the full-current Q = 10 ITER plasma. The new formula is then successfully tested on three more ITER plasmas: two corresponding to long burning scenarios with Q = 5 and one at low plasma current to be explored in the initial phases of ITER operation. The new physics that gives rise to the wider λqXGC is identified to be the weakly collisional, trapped-electron-mode turbulence across the magnetic separatrix, which is known to be an efficient transporter of the electron heat and mass. Electromagnetic turbulence and high-collisionality effects on the new formula are the next study topics for XGC1.","",""
189,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, F. Hutter","Auto-sklearn: Efficient and Robust Automated Machine Learning",2019,"","","","",115,"2022-07-13 09:24:54","","10.1007/978-3-030-05318-5_6","","",,,,,189,63.00,32,6,3,"","",""
3,"Ethan G. Armstrong, J. Verhoeven","Machine learning analyses of bacterial oligonucleotide frequencies to assess the benthic impact of aquaculture",2020,"","","","",116,"2022-07-13 09:24:54","","10.3354/aei00353","","",,,,,3,1.50,2,2,2,"Aquaculture is a rapidly expanding industry and is now one of the primary sources of all consumed seafood. Intensive aquaculture production is associated with organic enrichment, which occurs as organic material settles onto the seafloor, creating anoxic conditions which disrupt ecological processes. Bacteria are sensitive bioindicators of organic enrichment, and supervised classifiers using features derived from 16s rRNA gene sequences have shown potential to become useful in aquaculture environmental monitoring. Current taxonomy-based approaches, however, are time intensive and built upon emergent features which cannot easily be condensed into a monitoring pipeline. Here, we used a taxonomy-free approach to examine 16s rRNA gene sequences derived from flocculent matter underneath and in proximity to hard-bottom salmon aquaculture sites in Newfoundland, Canada. Tetranucleotide frequencies (k = 4) were tabulated from sample sequences and included as features in a machine learning pipeline using the random forest algorithm to predict 4 levels of benthic disturbance; resulting classifications were compared to those obtained using a published taxonomy-based approach. Our results show that k-mer count features can effectively be used to create highly accurate predictions of benthic disturbance and can resolve intermediate changes in seafloor condition. In addition, we present a robust assessment of model performance which accounts for the effect of randomness in model creation. This work outlines a flexible framework for environmental assessments at aquaculture sites that is highly reproducible and free of taxonomy-assignment bias.","",""
3,"Morten Ledum, Sigbjørn Løland Bore, M. Cascella","Automated determination of hybrid particle-field parameters by machine learning",2020,"","","","",117,"2022-07-13 09:24:54","","10.1080/00268976.2020.1785571","","",,,,,3,1.50,1,3,2,"The hybrid particle-field molecular dynamics method is an efficient alternative to standard particle-based coarse grained approaches. In this work, we propose an automated protocol for optimisation of the effective parameters that define the interaction energy density functional, based on Bayesian optimisation. The machine-learning protocol makes use of an arbitrary fitness function defined upon a set of observables of relevance, which are optimally matched by an iterative process. Employing phospholipid bilayers as test systems, we demonstrate that the parameters obtained through our protocol are able to reproduce reference data better than currently employed sets derived by Flory-Huggins models. The optimisation procedure is robust and yields physically sound values. Moreover, we show that the parameters are satisfactorily transferable among chemically analogous species. Our protocol is general, and does not require heuristic a posteriori rebalancing. Therefore it is particularly suited for optimisation of reliable hybrid particle-field potentials of complex chemical mixtures, and extends the applicability corresponding simulations to all those systems for which calibration of the density functionals may not be done via simple theoretical models. GRAPHICAL ABSTRACT","",""
4,"Joelle Pineau","Building reproducible, reusable, and robust machine learning software",2020,"","","","",118,"2022-07-13 09:24:54","","10.1145/3401025.3407941","","",,,,,4,2.00,4,1,2,"We have seen significant achievements with machine learning in recent years. Yet reproducing results for state-of-the-art deep learning methods is seldom straightforward. High variance of some methods can make learning particularly difficult. Furthermore, results can be brittle to even minor perturbations in the domain or experimental procedure. In this talk, I will review challenges that arise in experimental techniques and reporting procedures in deep learning, with a particular focus on reinforcement learning. I will also describe several recent results and guidelines designed to make future results more reproducible, reusable and robust.","",""
208,"J. Blanchet, Yang Kang, M. KarthyekRajhaaA.","Robust Wasserstein profile inference and applications to machine learning",2016,"","","","",119,"2022-07-13 09:24:54","","10.1017/jpr.2019.49","","",,,,,208,34.67,69,3,6,"We show that several machine learning estimators, including square-root least absolute shrinkage and selection and regularized logistic regression, can be represented as solutions to distributionally robust optimization problems. The associated uncertainty regions are based on suitably defined Wasserstein distances. Hence, our representations allow us to view regularization as a result of introducing an artificial adversary that perturbs the empirical distribution to account for out-of-sample effects in loss estimation. In addition, we introduce RWPI (robust Wasserstein profile inference), a novel inference methodology which extends the use of methods inspired by empirical likelihood to the setting of optimal transport costs (of which Wasserstein distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence we are able to choose regularization parameters for these machine learning estimators without the use of cross validation. Numerical experiments are also given to validate our theoretical findings.","",""
17,"Yoonha Choi, T. Liu, D. Pankratz, T. Colby, N. Barth, D. Lynch, P. Walsh, G. Raghu, G. Kennedy, Jing Huang","Identification of usual interstitial pneumonia pattern using RNA-Seq and machine learning: challenges and solutions",2018,"","","","",120,"2022-07-13 09:24:54","","10.1186/s12864-018-4467-6","","",,,,,17,4.25,2,10,4,"","",""
1,"C. Duetz, S. Van Gassen, T. Westers, F. I. '. in 't Hout, E. Cremers, C. Alhan, C. Bachas, M. V. van Spronsen, H. Visser-Wisselaar, D. Chitu, A. D. de Graaf, J. Jansen, Y. Saeys, A. A. van de Loosdrecht","Machine Learning-Based Flow Cytometry Diagnostics in Myelodysplastic Syndromes: Validation in the HOVON89 Clinical Trial (EudraCT 2008-002195-10)",2020,"","","","",121,"2022-07-13 09:24:54","","10.1182/BLOOD-2020-136719","","",,,,,1,0.50,0,14,2,"Introduction  Flow cytometry is a recommended tool in the diagnostic work-up of cytopenic patients suspected for myelodysplastic syndromes. Currently used flow cytometry scores rely on human assessment of dysplastic features in the bone marrow. Although proven useful, these methods are labor intensive and require a high level of expertise. Therefore, we previously developed a machine learning-based workflow for flow cytometry diagnostics in MDS by combining computational cell detection and a machine learning-classifier. This workflow outperformed traditional diagnostic scores with respect to accuracy (sensitivity 85-97%, specificity 93-97%), time investment (<30 seconds) and required materials (manuscript submitted). In the present study, we validated sensitivity of the workflow in a well-characterized clinical trial cohort (HOVON89 EudraCT 2008-002195-10) of lower risk MDS patients.  Method  Patient inclusion and characteristics  Very low to intermediate risk MDS patients enrolled in the HOVON89 clinical trial (EudraCT 2008-002195-10) were included. 53 patients met the additional inclusion criteria, concerning written consent for add-on studies and availability of required flow cytometry data.  Sample preparation  Bone marrow samples were processed for flow cytometry analysis according to the European Leukemia Net guidelines. This study focused on the antibody combination optimized for assessment of myeloid progenitors and erythroid dysplasia (CD45, CD34, CD117, HLA-DR, CD71, CD36, CD105, CD33, sideward light scatter (SSC) and forward light scatter (FSC)).  Machine learning-based workflow  The machine learning-based workflow was developed in a prior study based on a reference cohort consisting of MDS patients without excess of blasts(n=67) and non-MDS cases (n=81) (Figure 1). MDS patients were diagnosed based on (cyto)morphology, cytogenetics and clinical follow-up. Non-MDS cases were patients with confirmed non-neoplastic cytopenias (n=69) and age-matched healthy individuals (n=12).  Results  In the validation cohort, the machine learning-based diagnostic workflow classified 49 out of 53 patients correctly, reaching a sensitivity of 92%. The workflow outperformed two currently used diagnostic tools for MDS flow cytometry, the Ogata score and integrated flow cytometry score (iFS). The former obtained 72% sensitivity (McNemar: p = 0.001) and the latter 83% sensitivity (McNemar: p = 0.06) in the validation cohort. Per patient, time required for automated analysis was less than 30 seconds.  All four MDS patients that classified false negatively had a normal karyotype and (very) low risk disease according to the IPSS-r. In three out of four patients, no mutations or MDS-associated immunophenotypic features were detected. One patients was diagnosed as MDS-MLD and three patients as MDS-RS-SLD according to the WHO 2016 classification.  The ten most relevant cellular features that discriminated between MDS and non-MDS patients in the reference data were confirmed in the current validation cohort. All ten features of MDS patients in the validation cohort were significantly different from non-MDS patients of the reference cohort (all features, p < 0.00001) (Figure 2). Seven out of ten features were similar in MDS patients of the validation cohort compared to those of the MDS patients of the reference cohort (p>0.05) (Figure 2).  Conclusion  In this validation study, we confirmed accuracy of machine learning-based flow cytometry diagnostics in lower risk MDS. The workflow obtained 92% sensitivity, which is in accordance with results from our previous study (85-97%), and outperformed currently used diagnostic flow cytometry scores for MDS (i.e. Ogata score and iFS). In our previous study specificity was 95% in both reference and test cohorts. Cellular features, most discriminative for diagnosis, were confirmed in the validation cohort, emphasizing robustness of the method. Additional benefits of this approach are the reduction in analysis time to less than thirty seconds per patient, reduction of required antibodies and increased reproducibility.        van de Loosdrecht: celgene: Honoraria; novartis: Honoraria. ","",""
1,"E. Bollt","Regularized Kernel Machine Learning for Data Driven Forecasting of Chaos",2020,"","","","",122,"2022-07-13 09:24:54","","","","",,,,,1,0.50,1,1,2,"Forecasting outcomes from initial states continues to be an essential task in dynamical systems theory as applied across the sciences and engineering. The data-driven philosophy has become prevalent across the community. While geometric methods founded in time series to rebuild the underlying geometry based on Taken’s embedding theorem have been popular and successful in previous decades, they are complex, computationally expensive, and parametrically intensive. The wave of machine learning methods have come to reveal that a black box oriented approach has a great deal to offer the fundamental problem of forecasting the future. Modelling the flow operator as a linear combination of nonlinear basis functions in terms of regression least squares fitting in a data-driven manner is straight forward to pose. However, there are two major obstacles to overcome. First, model complexity may lead to either underfitting or overfitting, but these can be mitigated by Tikohonov regularization. Another serious issue regards computational complexity, which can be overcome by the kernel trick, so that all necessary inner products in a high dimensional feature (basis function) space are computed implicitly as low-dimensional kernel operations. In particular kernel methods from the broader theory of support vector machines is founded in the functional analytic theory of Mercer’s theorem and also reproducing kernel Hilbert spaces (RKHS), but practically this fundamental concept in machine learning has become central to many efficient algorithms. Putting these concepts together, the efficiency of kernel methods, and the robustness of regularized regression are both possible within an approach called kernelized ridge regression. We show here that these allow for an especially useful way to carry forward time-series forecasting problems, as a simple to use and computationally efficient methodology. We demonstrate the utility of these concepts in terms of a progression of examples from low dimensional where direct analysis is possible, to high-dimensional and spatiotemporally chaotic, and then an experimental data set from physiology of heart rate and breathing interactions.","",""
0,"Bradley Drumheller, M. Amgad, A. Aljudi, Elliott B. Burdette, Leila Kutob, Cameron Neely, Adam J. Perricone, C. Shebelut, D. Jaye","Early Development of a Machine Learning Approach to Quantify MYC Immunohistochemical Staining in Lymphoma",2020,"","","","",123,"2022-07-13 09:24:54","","10.1093/ajcp/aqaa137.034","","",,,,,0,0.00,0,9,2,"  Newer data suggest that double expression of MYC and BCL2 proteins (DE) evaluated by quantitative immunohistochemistry (qIHC) may be a powerful marker of worse prognosis in diffuse large B cell lymphoma (DLBCL). Testing for DE status, defined as >40% MYC+ and >50% BCL2+ tumor cells, is recommended in the WHO 2016 classification and clinical trials are using DE scoring to assign therapy arms. However, other data suggest that significant variability in manual DE scoring diminishes the predictive value. Error sources include high interobserver variability (IOV) associated with field choice, discrimination of tumor immunoreactivity from adjacent non-neoplastic cells, cell-to-cell variability in staining intensity, crush artifacts and necrosis. Thus, there is a need for standardized, reproducible approaches for DE scoring by qIHC. To address this need, we have begun developing a novel machine-learning approach to analyze IHC digital pathology whole-slide images, focusing initially on MYC IHC.  Digital whole-slide images (400x) of 22 DLBCL cases were uploaded to a web-based annotation platform. Using all cases, one annotator created 138 regions of interest (ROIs) containing approximately 200 nucleated cells and representing a variety of tissue types. Eight pathologists were assigned the same 10 ROIs in which to annotate all nuclei from which ground-truth seed nucleus labels (location, classification) were created for a validation set. Nuclei were classified as “tumor-positive”, “tumor-negative”, “non-tumor-positive”, “non-tumor-negative”, or “unknown”. This generated a set of 15,792 annotations with 1974 +/- 272 (Avg+/-STD) labels/annotator. Agglomerative hierarchical clustering afforded the creation of 2299 ground-truth seed locations. A maximum diameter of 3 mm/cluster was set by visual inspection of annotations. Of these seed locations, 1041 (45%) were detected by 8/8 annotators and, on average, 6/8 agreed on class. 302 +/- 72 (Avg+/-STD) “tumor positive” labels per annotator generated 382 seeds locations, 178 (47%) of which were detected by 8/8 annotators, with an average of 7.5/8 agreeing on class. 286 +/- 168 (Avg+/-STD) “tumor-negative” labels per annotator generated 336 seeds, 195 (58%) of which were detected by 8/8 annotators, with an average of 5/8 agreeing on class. Among all classes, the “tumor-positive” label displayed best overall label agreement whereas the “tumor-negative“ label yielded similar localization rate, but lower class agreement. These promising early findings provide a novel basis for quantifying IOV and utilizing multi-observer agreement to create a ground-truth validation set for a supervised machine learning approach to qIHC. Future efforts will make use of these data to optimize the validation set by rationally determining the number of additional annotations required, optimizing the number of annotators per ROI required, devising an adaptive approach to nuclear clustering based on nuclear density, and utilizing the additional 31,422 annotations in hand from all annotators as a robust algorithm training set.","",""
0,"Z. N. Ghaziani, Jesse Sun, R. Chan, H. Rakowski, M. Maron, E. Rowin, Bo Wang, W. Tsang","Abstract 16082: Machine Learning to Improve Left Ventricular Scar Quantification in Hypertrophic Cardiomyopathy Patients",2020,"","","","",124,"2022-07-13 09:24:54","","10.1161/CIRC.142.SUPPL_3.16082","","",,,,,0,0.00,0,8,2,"  Introduction:  Accurate and reproducible scar quantification of late gadolinium enhancement (LGE) images from cardiac magnetic resonance imaging (CMR) is important in risk stratifying hypertrophic cardiomyopathy (HCM) patients. Previous machine learning algorithms for CMR LGE quantification deployed three-dimensional convolutional neural network (CNN) architecture, which required image cropping and custom graphic processing units (GPUs) to function, thus limiting their general applicability. We aim to develop a deep two-dimensional (2D) CNN model that contours the left ventricle (LV) endo- and epicardial borders and quantifies LGE.      Hypothesis:  We hypothesize that a deep 2D CNN model, which uses commercially available GPUs, could be used to efficiently and accurately contour LV endo- and epicardial borders and quantify CMR LGE in HCM patients.      Methods:  We retrospectively studied 296 HCM patients (2423 images) from the University Health Network (Toronto, Canada) and Tufts Medical Center (Boston, USA). LGE images were manually segmented by an expert reader. Scar was defined as 5 standard deviations higher than the mean of the annotated normal region pixels. A 2D U-net CNN variant was used to train a model on 80% of the datasets. Testing was performed on the remaining 20%. We applied a 5-folds cross validation algorithm for training to improve model robustness. Model performance was assessed using the Dice Similarity Coefficient (DSC).      Results:  We were able to develop a deep learning model that could successfully perform both LV segmentation and scar quantification using a generally available GPU card. Our algorithm did not require image cropping and processed one image every 60 milliseconds. DSC scores averaged across the 5-folds was excellent at 0.89+0.22 for the endocardium and 0.81+0.17 for the epicardium, and good at 0.57+0.31 for scar.      Conclusions:  Using novel 2D CNN methods, we have successfully developed an automatic algorithm that rapidly provides LV endo- and epicardial contours and scar quantification on LGE CMR images that is superior to previously published studies. Unlike previous algorithms, our program does not require the use of custom CPUs or image cropping, potentially allowing it to be integrated into routine clinical practice. ","",""
0,"Jin Wook Kim, D. Moon","Optimizing Aging Male Symptom Questionnaire Through Genetic Algorithms Based Machine Learning Techniques",2020,"","","","",125,"2022-07-13 09:24:54","","10.5534/wjmh.190077","","",,,,,0,0.00,0,2,2,"Purpose Genetic algorithm (GA) is a machine learning optimization strategy where sample strategies compete for fitness to evolve an optimum solution. This study evolves the Aging Male Symptoms (AMS) with GA to better identify late onset hypogonadism (LOH) with serum testosterone. Materials and Methods GA was trained on a training set of standard AMS questionnaire on a nationwide LOH epidemiology study. Random matrices of selectors for particular items were generated. Each generation of was evolved through a fitness function determined by sensitivity. Threshold to determine positive serum testosterone level for LOH was randomized for each competing strategy. After 2,000 runs, with each run producing the best result out of a set of 3,000 randomly generated sets evolved through 300 generations, the best AMS selection matrix was then applied to a separately enrolled validation set to compare outcomes. Results Predictability for serum testosterone levels dropped markedly above 3.5 ng/mL during pilot training. Limiting the training to testosterone thresholds between 2.5 and 3.5 ng/mL the GA 93 different strategies. Only a selection of 5 items, determining for a threshold of 20 points and determining for a serum testosterone level of 3.16 ng/mL, showed robust reproducibility within the internal validation set. Applying these conditions to the independent validation set showed sensitivity improved from 0.66 to 0.77, with a specificity of 0.07 to 0.19, respectively. Conclusions GA method of selecting questionnaires improved AMS questionnaire significantly. This method can be easily applied to other questionnaires that do not correlate with physiological markers.","",""
0,"Gabriel D. Patrón, D. León, Edwin Lopez, G. Hernández","An Interpretable Automated Machine Learning Credit Risk Model",2020,"","","","",126,"2022-07-13 09:24:54","","10.1007/978-3-030-61834-6_2","","",,,,,0,0.00,0,4,2,"","",""
12,"Han Cao, A. Meyer-Lindenberg, E. Schwarz","Comparative Evaluation of Machine Learning Strategies for Analyzing Big Data in Psychiatry",2018,"","","","",127,"2022-07-13 09:24:54","","10.3390/ijms19113387","","",,,,,12,3.00,4,3,4,"The requirement of innovative big data analytics has become a critical success factor for research in biological psychiatry. Integrative analyses across distributed data resources are considered essential for untangling the biological complexity of mental illnesses. However, little is known about algorithm properties for such integrative machine learning. Here, we performed a comparative analysis of eight machine learning algorithms for identification of reproducible biological fingerprints across data sources, using five transcriptome-wide expression datasets of schizophrenia patients and controls as a use case. We found that multi-task learning (MTL) with network structure (MTL_NET) showed superior accuracy compared to other MTL formulations as well as single task learning, and tied performance with support vector machines (SVM). Compared to SVM, MTL_NET showed significant benefits regarding the variability of accuracy estimates, as well as its robustness to cross-dataset and sampling variability. These results support the utility of this algorithm as a flexible tool for integrative machine learning in psychiatry.","",""
15,"Chenhao Ma, B. Zhu, Xue-qiao Xu, Weixing Wang","Machine learning surrogate models for Landau fluid closure",2019,"","","","",128,"2022-07-13 09:24:54","","10.1063/1.5129158","","",,,,,15,5.00,4,4,3,"The first result of applying the machine/deep learning technique to the fluid closure problem is presented in this paper. As a start, three different types of neural networks [multilayer perceptron (MLP), convolutional neural network (CNN), and two-layer discrete Fourier transform (DFT) network] were constructed and trained to learn the well-known Hammett–Perkins Landau fluid closure in configuration space. We find that in order to train a well-preformed network, a minimum size of the training data set is needed; MLP also requires a minimum number of neurons in the hidden layers that equals the degrees of freedom in Fourier space, despite the fact that training data are being fed into the configuration space. Out of the three models, DFT performs the best for the clean data, most likely due to the existence of the simple Fourier expression for the Hammett–Perkins closure, but it is the least robust with respect to input noise. Overall, with appropriate tuning and optimization, all three neural networks are able to accurately predict the Hammett–Perkins closure and reproduce the intrinsic nonlocal feature, suggesting a promising path to calculating more sophisticated closures with the machine/deep learning technique.","",""
5,"Sindhu Ghanta, Sriram Ganapathi Subramanian, S. Sundararaman, L. Khermosh, Vinay Sridhar, D. Arteaga, Q. Luo, Dhananjoy Das, Nisha Talagala","Interpretability and Reproducability in Production Machine Learning Applications",2018,"","","","",129,"2022-07-13 09:24:54","","10.1109/ICMLA.2018.00105","","",,,,,5,1.25,1,9,4,"Explainability/Interpretability in machine learning applications is becoming critical, with legal and industry requirements demanding human understandable machine learning results. We describe the additional complexities that occur when a known interpretability technique (canary models) is applied to a real production scenario. We furthermore argue that reproducibility is a key feature in practical usages of such interpretability techniques in production scenarios. With this motivation, we present a production ML reproducibility solution, namely a comprehensive time ordered event sequence for machine learning applications. We demonstrate how our approach can bring this known common interpretability technique into production viability. We further present the system design and early performance characteristics of our reproducibility solution.","",""
174,"Andrew F. Zahrt, J. Henle, Brennan T Rose, Yang Wang, William T. Darrow, S. Denmark","Prediction of higher-selectivity catalysts by computer-driven workflow and machine learning",2019,"","","","",130,"2022-07-13 09:24:54","","10.1126/science.aau5631","","",,,,,174,58.00,29,6,3,"Predicting catalyst selectivity Asymmetric catalysis is widely used in chemical research and manufacturing to access just one of two possible mirror-image products. Nonetheless, the process of tuning catalyst structure to optimize selectivity is still largely empirical. Zahrt et al. present a framework for more efficient, predictive optimization. As a proof of principle, they focused on a known coupling reaction of imines and thiols catalyzed by chiral phosphoric acid compounds. By modeling multiple conformations of more than 800 prospective catalysts, and then training machine-learning algorithms on a subset of experimental results, they achieved highly accurate predictions of enantioselectivities. Science, this issue p. eaau5631 A model encompassing multiple conformations of chiral phosphoric acid catalysts accurately predicts enantioselectivities. INTRODUCTION The development of new synthetic methods in organic chemistry is traditionally accomplished through empirical optimization. Catalyst design, wherein experimentalists attempt to qualitatively identify correlations between catalyst structure and catalyst efficiency, is no exception. However, this approach is plagued by numerous deficiencies, including the lack of mechanistic understanding of a new transformation, the inherent limitations of human cognitive abilities to find patterns in large collections of data, and the lack of quantitative guidelines to aid catalyst identification. Chemoinformatics provides an attractive alternative to empiricism for several reasons: Mechanistic information is not a prerequisite, catalyst structures can be characterized by three-dimensional (3D) descriptors (numerical representations of molecular properties derived from the 3D molecular structure) that quantify the steric and electronic properties of thousands of candidate molecules, and the suitability of a given catalyst candidate can be quantified by comparing its properties with a computationally derived model trained on experimental data. The ability to accurately predict a selective catalyst by using a set of less than optimal data remains a major goal for machine learning with respect to asymmetric catalysis. We report a method to achieve this goal and propose a more efficient alternative to traditional catalyst design. RATIONALE The workflow we have created consists of the following components: (i) construction of an in silico library comprising a large collection of conceivable, synthetically accessible catalysts derived from a particular scaffold; (ii) calculation of relevant chemical descriptors for each scaffold; (iii) selection of a representative subset of the catalysts [this subset is termed the universal training set (UTS) because it is agnostic to reaction or mechanism and thus can be used to optimize any reaction catalyzed by that scaffold]; (iv) collection of the training data; and (v) application of machine learning methods to generate models that predict the enantioselectivity of each member of the in silico library. These models are evaluated with an external test set of catalysts (predicting selectivities of catalysts outside of the training data). The validated models can then be used to select the optimal catalyst for a given reaction. RESULTS To demonstrate the viability of our method, we predicted reaction outcomes with substrate combinations and catalysts different from the training data and simulated a situation in which highly selective reactions had not been achieved. In the first demonstration, a model was constructed by using support vector machines and validated with three different external test sets. The first test set evaluated the ability of the model to predict the selectivity of only reactions forming new products with catalysts from the training set. The model performed well, with a mean absolute deviation (MAD) of 0.161 kcal/mol. Next, the same model was used to predict the selectivity of an external test set of catalysts with substrate combinations from the training set. The performance of the model was still highly accurate, with a MAD of 0.211 kcal/mol. Lastly, reactions forming new products with the external test catalysts were predicted with a MAD of 0.236 kcal/mol. In the second study, no reactions with selectivity above 80% enantiomeric excess were used as training data. Deep feed-forward neural networks accurately reproduced the experimental selectivity data, successfully predicting the most selective reactions. More notably, the general trends in selectivity, on the basis of average catalyst selectivity, were correctly identified. Despite omitting about half of the experimental free energy range from the training data, we could still make accurate predictions in this region of selectivity space. CONCLUSION The capability to predict selective catalysts has the potential to change the way chemists select and optimize chiral catalysts from an empirically guided to a mathematically guided approach. Chemoinformatics-guided optimization protocol. (A) Generation of a large in silico library of catalyst candidates. (B) Calculation of robust chemical descriptors. (C) Selection of a UTS. (D) Acquisition of experimental selectivity data. (E) Application of machine learning to use moderate- to low-selectivity reactions to predict high-selectivity reactions. R, any group; X, O or S; Y, OH, SH, or NHTf; PC, principal component; ΔΔG, mean selectivity. Catalyst design in asymmetric reaction development has traditionally been driven by empiricism, wherein experimentalists attempt to qualitatively recognize structural patterns to improve selectivity. Machine learning algorithms and chemoinformatics can potentially accelerate this process by recognizing otherwise inscrutable patterns in large datasets. Herein we report a computationally guided workflow for chiral catalyst selection using chemoinformatics at every stage of development. Robust molecular descriptors that are agnostic to the catalyst scaffold allow for selection of a universal training set on the basis of steric and electronic properties. This set can be used to train machine learning methods to make highly accurate predictive models over a broad range of selectivity space. Using support vector machines and deep feed-forward neural networks, we demonstrate accurate predictive modeling in the chiral phosphoric acid–catalyzed thiol addition to N-acylimines.","",""
1,"Breschine Cummins, Justin D. Vrana, R. Moseley, Hamed Eramian, A. Deckard, P. Fontanarrosa, D. Bryce, Mark Weston, G. Zheng, Joshua Nowak, Francis C. Motta, Mohammed Eslami, Kara Layne Johnson, R. Goldman, C. Myers, Tessa Johnson, M. Vaughn, N. Gaffney, Joshua Urrutia, S. Gopaulakrishnan, Vanessa Biggers, Trissha R. Higa, Lorraine A. Mosqueda, M. Gameiro, T. Gedeon, K. Mischaikow, Jacob Beal, Bryan A. Bartley, Tom Mitchell, Tramy Nguyen, Nicholas Roehner, S. Haase","Robustness and reproducibility of simple and complex synthetic logic circuit designs using a DBTL loop",2022,"","","","",131,"2022-07-13 09:24:54","","10.1101/2022.06.10.495560","","",,,,,1,1.00,0,32,1,"Computational tools addressing various components of design-build-test-learn loops (DBTL) for the construction of synthetic genetic networks exist, but do not generally cover the entire DBTL loop. This manuscript introduces an end-to-end sequence of tools that together form a DBTL loop called DART (Design Assemble Round Trip). DART provides rational selection and refinement of genetic parts to construct and test a circuit. Computational support for experimental process, metadata management, standardized data collection, and reproducible data analysis is provided via the previously published Round Trip (RT) test-learn loop. The primary focus of this work is on the Design Assemble (DA) part of the tool chain, which improves on previous techniques by screening up to thousands of network topologies for robust performance using a novel robustness score derived from dynamical behavior based on circuit topology only. In addition, novel experimental support software is introduced for the assembly of genetic circuits. A complete design-through-analysis sequence is presented using several OR and NOR circuit designs, with and without structural redundancy, that are implemented in budding yeast. The execution of DART tested the predictions of the design tools, specifically with regard to robust and reproducible performance under different experimental conditions. The data analysis depended on a novel application of machine learning techniques to segment bimodal flow cytometry distributions. Evidence is presented that, in some cases, a more complex build may impart more robustness and reproducibility across experimental conditions.","",""
8,"M. Velasco, J. C. Carrasco-Jiménez, Octavio Castillo Reyes, F. Cucchietti, J. D. L. Puente","A Machine Learning Approach for Parameter Screening in Earthquake Simulation",2018,"","","","",132,"2022-07-13 09:24:54","","10.1109/CAHPC.2018.8645865","","",,,,,8,2.00,2,5,4,"Earthquakes are the result of rupture in the Earth's crust. The rupture process is difficult to model deterministically due to the number of unmeasurable parameters involved and poorly constrained physical conditions, as well as the very diverse scales involved in their nucleation (meters) and complete failure (up to hundreds of kilometers). In this research work we focus on synthetic seismic catalogs generated with a stochastic modeling technique called Fiber Bundle Model (FBM). These catalogs can be readily compared with statistical measures computed from real earthquake series, but the link between the FBM parameters and the characteristics of the obtained earthquake series is difficult to assess. Furthermore, the stochastic nature of the model requires a large amount of realizations in order to attain statistical robustness. The aim of this work is to estimate the FBM parameters that generate aftershock sequences that are similar to those generated by real seismic events. In order to estimate the optimal combination of parameters that generate such sequences, we executed a large number of simulations with different combinations of parameters using High-Performance Computing (HPC) resources to reduce compute time. Lastly, the synthetic datasets were used to train a supervised Machine Learning (ML) model that analyzes and extracts statistical patterns that reproduce the observations regarding aftershock occurrence and its spatio-temporal distribution in real seismic events.","",""
2,"Ziqiang Shi, Chaoliang Zhong, Yasuto Yokota, Wensheng Xia, Jun Sun","Robustness Evaluation of Deep Learning Models Based on Local Prediction Consistency",2019,"","","","",133,"2022-07-13 09:24:54","","10.1109/ICMLA.2019.00224","","",,,,,2,0.67,0,5,3,"It is important to estimate the performance gap of a given deep learning model on the target data set, since discrepancy or bias between source and target domains is a common and fundamental problem in the practice of machine learning techniques. Without any assumptions on data bias, such as label shift or covariate shift and without target data labels, we propose a robustness estimation method based on prediction consistency evaluation between source and target data in the neighborhood of the source samples. Considering outliers and whether the user provided model is fully trained, a variety of variant methods are also tried, including setting neighborhood threshold to average intra-class distance for each category and relative robustness. Furthermore, the time complexity of this method is O(nlogn), which is applicable for large datasets. Experiments on the handwritten digit recognition and Japanese handwriting recognition show that the proposed methods are effective.","",""
76,"Kai Fukami, Yusuke Nabae, K. Kawai, K. Fukagata","Synthetic turbulent inflow generator using machine learning",2018,"","","","",134,"2022-07-13 09:24:54","","10.1103/PhysRevFluids.4.064603","","",,,,,76,19.00,19,4,4,"We propose a methodology for generating time-dependent turbulent inflow data with the aid of machine learning (ML), which has a possibility to replace conventional driver simulations or synthetic turbulent inflow generators. As for the ML model, we use an auto-encoder type convolutional neural network (CNN) with a multi-layer perceptron (MLP). For the test case, we study a fully-developed turbulent channel flow at the friction Reynolds number of ${\rm Re}_{\tau} = 180$ for easiness of assessment. The ML models are trained using a time series of instantaneous velocity fields in a single cross-section obtained by direct numerical simulation (DNS) so as to output the cross-sectional velocity field at a specified future time instant. From the a priori test in which the output from the trained ML model are recycled to the input, the spatio-temporal evolution of cross-sectional structure is found to be reasonably well reproduced by the proposed method. The turbulence statistics obtained in the a priori test are also, in general, in reasonable agreement with the DNS data, although some deviation in the flow rate was found. It is also found that the present machine-learned inflow generator is free from the spurious periodicity, unlike the conventional driver DNS in a periodic domain. As an a posteriori test, we perform DNS of inflow-outflow turbulent channel flow with the trained ML model used as a machine-learned turbulent inflow generator (MLTG) at the inlet. It is shown that the present MLTG can maintain the turbulent channel flow for a long time period sufficient to accumulate turbulent statistics, with much lower computational cost than the corresponding driver simulation. It is also demonstrated that we can obtain accurate turbulent statistics by properly correcting the deviation in the flow rate.","",""
0,"S. Boscolo, Ilya Gukov, S. Turitsyn, C. Finot","Multi-parameter optimisation of dual-pump NALM fibre laser using machine-learning approaches",2018,"","","","",135,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,4,4,"Recently, a new design of a model-locked all-fibre Figure-8 laser employing a nonlinear amplifying loop mirror (NALM) with two active fibre segments and two independently controlled pump-power modules has been proposed and experimentally demonstrated. This laser layout combines the reliability and robustness of conventional Figure-8 lasers with the flexibility of nonlinear-polarisation-evolution (NPE) lasers, providing access to a variety of generation regimes with a relatively wide adjustment range of the pulse parameters. Moreover, it enables reliable and reproducible live electronic adjustment of the lasing regimes, which is practically impossible to do by adjusting fibre-based polarisation controllers in NPE lasers. The general issue of reaching a target mode-locked laser regime with a setup featuring many adjustable parameters can be intelligently addressed by using machine-learning techniques. Here, we apply predictive regression to find optimum operating regimes in the NALM laser that are accessible through independent control of the pump powers in the gain segments, Pp,1, Pp,2, and the laser output coupling ratio β. We use a piece-wise propagation model for generating data that characterises the laser. In the fibres, propagation follows a standard modified nonlinear-Schrodinger equation including gain saturation and spectral response for the active segments. The gain coefficient amplitude is dependent on the average signal and pump powers, the average power dynamics being described by standard rate equations. We have trained a gradient boosted tree algorithm on our dataset to identify high-energy, stable mode-locked solutions across the full variation range of the total pump level delivered to the active fibres, Pp,tot, the ratio Pp1/Pp,tot, and β (tens of thousands of points). The algorithm has quickly handled the whole parameter space. Our approach paves the way for alternative approaches to the optimisation of nonlinear cavity dynamics, and can be generalised to other complex systems and higher degrees of freedom.","",""
48,"A. Chiuso, G. Pillonetto","System Identification: A Machine Learning Perspective",2019,"","","","",136,"2022-07-13 09:24:54","","10.1146/ANNUREV-CONTROL-053018-023744","","",,,,,48,16.00,24,2,3,"Estimation of functions from sparse and noisy data is a central theme in machine learning. In the last few years, many algorithms have been developed that exploit Tikhonov regularization theory and reproducing kernel Hilbert spaces. These are the so-called kernel-based methods, which include powerful approaches like regularization networks, support vector machines, and Gaussian regression. Recently, these techniques have also gained popularity in the system identification community. In both linear and nonlinear settings, kernels that incorporate information on dynamic systems, such as the smoothness and stability of the input–output map, can challenge consolidated approaches based on parametric model structures. In the classical parametric setting, the complexity of the model (the model order) needs to be chosen, typically from a finite family of alternatives, by trading bias and variance. This (discrete) model order selection step may be critical, especially when the true model does not belong to the model class. In regularization-based approaches, model complexity is controlled by tuning (continuous) regularization parameters, making the model selection step more robust. In this article, we review these new kernel-based system identification approaches and discuss extensions based on nuclear and [Formula: see text] norms.","",""
8,"Hongyang Li, Y. Guan","Machine learning empowers phosphoproteome prediction in cancers",2020,"","","","",137,"2022-07-13 09:24:54","","10.1093/bioinformatics/btz639","","",,,,,8,4.00,4,2,2,"MOTIVATION Reversible protein phosphorylation is an essential post-translational modification regulating protein functions and signaling pathways in many cellular processes. Aberrant activation of signaling pathways often contributes to cancer development and progression. The mass spectrometry-based phosphoproteomics technique is a powerful tool to investigate the site-level phosphorylation of the proteome in a global fashion, paving the way for understanding the regulatory mechanisms underlying cancers. However, this approach is time-consuming and requires expensive instruments, specialized expertise, and a large amount of starting material. An alternative in silico approach is predicting the phosphoproteomic profiles of cancer patients from the available proteomic, transcriptomic, and genomic data.   RESULTS Here, we present a winning algorithm in the 2017 NCI-CPTAC DREAM Proteogenomics Challenge for predicting phosphorylation levels of the proteome across cancer patients. We integrate four components into our algorithm, including (1) baseline correlations between protein and phosphoprotein abundances, (2) universal protein-protein interactions, (3) shareable regulatory information across cancer tissues, and (4) associations among multi-phosphorylation sites of the same protein. When tested on a large held-out testing dataset of 108 breast and 62 ovarian cancer samples, our method ranked first in both cancer tissues, demonstrating its robustness and generalization ability.   AVAILABILITY Our code and reproducible results are freely available on GitHub: https://github.com/GuanLab/phosphoproteome_prediction.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
0,"A. Chakrabarty, K. Berntorp, S. D. Cairano","Learning-based Parameter-Adaptive Reference Governors /Author=Chakrabarty, Ankush; Berntorp, Karl; Di Cairano, Stefano /CreationDate=July 3, 2020 /Subject=Control, Machine Learning",2020,"","","","",138,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,2,"Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example. American Control Conference (ACC) This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2020 201 Broadway, Cambridge, Massachusetts 02139 Learning-based Parameter-Adaptive Reference Governors Ankush Chakrabarty†, Karl Berntorp, Stefano Di Cairano Abstract—Reference governors (RGs) provide an effective method for ensuring safety via constraint enforcement in closedloop control systems. When the parameters of the underlying systems are unknown, but constant or slowly-varying, robust formulations of RGs that consider only the worst-case effect may be overly conservative and exhibit poor performance. This paper proposes a parameter-adaptive reference governor (PARG) architecture that is capable of generating safe trajectories in spite of parameter uncertainties without being as conservative as robust RGs. The proposed approach leverages on-line data to inform algorithms for robust parameter estimation. Subsequently, confidence bounds around parameter estimates are fed to supervised machine learners for approximating robust constraint admissible sets leveraged by the PARG. While initially, due to the absence of on-line data, the PARG may be as conservative as a robust RG, as more data is gathered and the confidence bounds become tighter, such conservativeness reduces, as demonstrated in a simulation example.","",""
2,"S. Siltanen, Takanori Ide","Electrical Impedance Tomography, Enclosure Method and Machine Learning",2020,"","","","",139,"2022-07-13 09:24:54","","10.1109/MLSP49062.2020.9231717","","",,,,,2,1.00,1,2,2,"Electrical impedance tomography (EIT) is a non-destructive imaging method, where a physical body is probed with electric measurements at the boundary, and information about the internal conductivity is extracted from the data. The enclosure method of Ikehata [J. Inv. III-Posed Prob. 8(2000)] recovers the convex hull of an inclusion of unknown conductivity embedded in known background conductivity. Practical implementations of the enclosure method are based on least-squares (LS) fitting of lines to noise-robust values of the so-called indicator function. It is shown how a convolutional neural network instead of LS fitting improves the accuracy of the enclosure method significantly while retaining interpretability.","",""
2,"Moritz Lange, Henri Suominen, M. Kurppa, L. Järvi, Emilia Oikarinen, Rafael Savvides, K. Puolamäki","Machine learning models to replicate large-eddy simulations of air pollutant concentrations along boulevard-type streets",2020,"","","","",140,"2022-07-13 09:24:54","","10.5194/gmd-2020-200","","",,,,,2,1.00,0,7,2,"Abstract. Running large-eddy simulations (LES) can be burdensome and computationally too expensive from the application point-of-view for example to support urban planning. In this study, regression models are used to replicate modelled air pollutant concentrations from LES in urban boulevards. We study the performance of regression models and discuss how to detect situations where the models are applied outside their training domain and their outputs cannot be trusted. Regression models from 10 different model families are trained and a cross-validation methodology is used to evaluate their performance and to find the best set of features needed to reproduce the LES outputs. We also test the regression models on an independent testing dataset. Our results suggest that in general, log-linear regression gives the best and most robust performance on new independent data. It clearly outperforms the dummy model which would predict constant concentrations for all locations (mRMSE of 0.76 vs 1.78 of the dummy model). Furthermore, we demonstrate that it is possible to detect concept drift, i.e., situations where the model is applied outside its training domain and a new LES run may be necessary to obtain reliable results. Regression models can be used to replace LES simulations in estimating air pollutant concentrations, unless higher accuracy is needed. In order to have reliable results, it is however important to do the model and feature selection carefully to avoid over-fitting and to use methods to detect the concept drift. ","",""
20,"L. Pan, Caixia Cheng, U. Haberkorn, A. Dimitrakopoulou-Strauss","Machine learning-based kinetic modeling: a robust and reproducible solution for quantitative analysis of dynamic PET data.",2017,"","","","",141,"2022-07-13 09:24:54","","10.1088/1361-6560/aa6244","","",,,,,20,4.00,5,4,5,"A variety of compartment models are used for the quantitative analysis of dynamic positron emission tomography (PET) data. Traditionally, these models use an iterative fitting (IF) method to find the least squares between the measured and calculated values over time, which may encounter some problems such as the overfitting of model parameters and a lack of reproducibility, especially when handling noisy data or error data. In this paper, a machine learning (ML) based kinetic modeling method is introduced, which can fully utilize a historical reference database to build a moderate kinetic model directly dealing with noisy data but not trying to smooth the noise in the image. Also, due to the database, the presented method is capable of automatically adjusting the models using a multi-thread grid parameter searching technique. Furthermore, a candidate competition concept is proposed to combine the advantages of the ML and IF modeling methods, which could find a balance between fitting to historical data and to the unseen target curve. The machine learning based method provides a robust and reproducible solution that is user-independent for VOI-based and pixel-wise quantitative analysis of dynamic PET data.","",""
217,"Ian J. Goodfellow, Nicolas Papernot, P. Mcdaniel","Cleverhans V0.1: an Adversarial Machine Learning Library",2016,"","","","",142,"2022-07-13 09:24:54","","","","",,,,,217,36.17,72,3,6,"cleverhans is a software library that provides standardized reference implementations of adversarial example construction techniques and adversarial training. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models’ performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section 1 provides an overview of adversarial examples in machine learning and of the cleverhans software. Section 2 presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section 3 describes how to report benchmark results using the library. Section 4 describes the versioning system.","",""
0,"Upma Yadav, Ashok Kumar, A. Tiwari, S. Mukherjee","Machine Learning in Medical Imaging for Early Detection of Skin Diseases.",2020,"","","","",143,"2022-07-13 09:24:54","","10.35940/ijitee.e3019.049620","","",,,,,0,0.00,0,4,2,"Dermatology is a medical field that treats skin health and diseases. These skin diseases are perilous and often transmittable but can be cured or reversed with higher degree if detected at an early stage. Early detection and treatment can correct most skin disorders. Diagnosis of these diseases requires a sophisticated of proficiency due to the variety of their illustration aspects. As manual conclusion are often skewed and hardly reproducible, to achieve a more intent and undependable diagnosis, a computer aided diagnostic system should be considered. This work is to provide a comparative view of advancements the works as a robust literature of with techniques, methodology, experimented results and dataset done in medical science using medical images to predict diseases with early detection and higher accuracy .","",""
657,"Wieland Brendel, Jonas Rauber, M. Bethge","Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",2017,"","","","",144,"2022-07-13 09:24:54","","","","",,,,,657,131.40,219,3,5,"Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .","",""
22,"Y. Arai, T. Kondo, K. Fuse, Y. Shibasaki, M. Masuko, J. Sugita, T. Teshima, N. Uchida, T. Fukuda, K. Kakihana, Y. Ozawa, T. Eto, Masatsugu Tanaka, K. Ikegame, Takehiko Mori, K. Iwato, T. Ichinohe, Y. Kanda, Y. Atsuta","Using a machine learning algorithm to predict acute graft-versus-host disease following allogeneic transplantation.",2019,"","","","",145,"2022-07-13 09:24:54","","10.1182/bloodadvances.2019000934","","",,,,,22,7.33,2,19,3,"Acute graft-versus-host disease (aGVHD) is 1 of the critical complications that often occurs following allogeneic hematopoietic stem cell transplantation (HSCT). Thus far, various types of prediction scores have been created using statistical calculations. The primary objective of this study was to establish and validate the machine learning-dependent index for predicting aGVHD. This was a retrospective cohort study that involved analyzing databases of adult HSCT patients in Japan. The alternating decision tree (ADTree) machine learning algorithm was applied to develop models using the training cohort (70%). The ADTree algorithm was confirmed using the hazard model on data from the validation cohort (30%). Data from 26 695 HSCT patients transplanted from allogeneic donors between 1992 and 2016 were included in this study. The cumulative incidence of aGVHD was 42.8%. Of >40 variables considered, 15 were adapted into a model for aGVHD prediction. The model was tested in the validation cohort, and the incidence of aGVHD was clearly stratified according to the categorized ADTree scores; the cumulative incidence of aGVHD was 29.0% for low risk and 58.7% for high risk (hazard ratio, 2.57). Predicting scores for aGVHD also demonstrated the link between the risk of development aGVHD and overall survival after HSCT. The machine learning algorithms produced clinically reasonable and robust risk stratification scores. The relatively high reproducibility and low impacts from the interactions among the variables indicate that the ADTree algorithm, along with the other data-mining approaches, may provide tools for establishing risk score.","",""
21,"C. Maltecca, D. Lu, Constantino Schillebeeckx, N. McNulty, C. Schwab, C. Shull, F. Tiezzi","Predicting Growth and Carcass Traits in Swine Using Microbiome Data and Machine Learning Algorithms",2019,"","","","",146,"2022-07-13 09:24:54","","10.1038/s41598-019-43031-x","","",,,,,21,7.00,3,7,3,"","",""
28,"Jiuwen Cao, K. Zhang, Hongwei Yong, Xiaoping Lai, Badong Chen, Zhiping Lin","Extreme Learning Machine With Affine Transformation Inputs in an Activation Function",2019,"","","","",147,"2022-07-13 09:24:54","","10.1109/TNNLS.2018.2877468","","",,,,,28,9.33,5,6,3,"The extreme learning machine (ELM) has attracted much attention over the past decade due to its fast learning speed and convincing generalization performance. However, there still remains a practical issue to be approached when applying the ELM: the randomly generated hidden node parameters without tuning can lead to the hidden node outputs being nonuniformly distributed, thus giving rise to poor generalization performance. To address this deficiency, a novel activation function with an affine transformation (AT) on its input is introduced into the ELM, which leads to an improved ELM algorithm that is referred to as an AT-ELM in this paper. The scaling and translation parameters of the AT activation function are computed based on the maximum entropy principle in such a way that the hidden layer outputs approximately obey a uniform distribution. Application of the AT-ELM algorithm in nonlinear function regression shows its robustness to the range scaling of the network inputs. Experiments on nonlinear function regression, real-world data set classification, and benchmark image recognition demonstrate better performance for the AT-ELM compared with the original ELM, the regularized ELM, and the kernel ELM. Recognition results on benchmark image data sets also reveal that the AT-ELM outperforms several other state-of-the-art algorithms in general.","",""
17,"V. Lam, Thanh Nguyen, T. Phan, B. Chung, G. Nehmetallah, C. Raub","Machine Learning with Optical Phase Signatures for Phenotypic Profiling of Cell Lines",2019,"","","","",148,"2022-07-13 09:24:54","","10.1002/cyto.a.23774","","",,,,,17,5.67,3,6,3,"Robust and reproducible profiling of cell lines is essential for phenotypic screening assays. The goals of this study were to determine robust and reproducible optical phase signatures of cell lines for classification with machine learning and to correlate optical phase parameters to motile behavior. Digital holographic microscopy (DHM) reconstructed phase maps of cells from two pairs of cancer and non‐cancer cell lines. Seventeen image parameters were extracted from each cell's phase map, used for linear support vector machine learning, and correlated to scratch wound closure and Boyden chamber chemotaxis. The classification accuracy was between 90% and 100% for the six pairwise cell line comparisons. Several phase parameters correlated with wound closure rate and chemotaxis across the four cell lines. The level of cell confluence in culture affected phase parameters in all cell lines tested. Results indicate that optical phase features of cell lines are a robust set of quantitative data of potential utility for phenotypic screening and prediction of motile behavior. © 2019 International Society for Advancement of Cytometry","",""
2,"Ian Convy, W. Huggins, Haoran Liao, K. Birgitta Whaley","Mutual information scaling for tensor network machine learning",2021,"","","","",149,"2022-07-13 09:24:54","","10.1088/2632-2153/ac44a9","","",,,,,2,2.00,1,4,1,"Tensor networks have emerged as promising tools for machine learning, inspired by their widespread use as variational ansatze in quantum many-body physics. It is well known that the success of a given tensor network ansatz depends in part on how well it can reproduce the underlying entanglement structure of the target state, with different network designs favoring different scaling patterns. We demonstrate here how a related correlation analysis can be applied to tensor network machine learning, and explore whether classical data possess correlation scaling patterns similar to those found in quantum states, which might indicate the best network to use for a given dataset. We utilize mutual information (MI) as measure of correlations in classical data, and show that it can serve as a lower-bound on the entanglement needed for a probabilistic tensor network classifier. We then develop a logistic regression algorithm to estimate the MI between bipartitions of data features, and verify its accuracy on a set of Gaussian distributions designed to mimic different correlation patterns. Using this algorithm, we characterize the scaling patterns in the Modified National Institute of Standards and Technology and Tiny Images datasets, and find clear evidence of boundary-law scaling in the latter. This quantum-inspired classical analysis offers insight into the design of tensor networks that are best suited for specific learning tasks.","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",150,"2022-07-13 09:24:54","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
0,"G. M. Anand, Heitor C. Megale, Sean H. Murphy, Theresa Weis, Zuwan Lin, Yichun He, Xiao Wang, Jia Liu, S. Ramanathan","Machine learning directed organoid morphogenesis uncovers an excitable system driving human axial elongation",2022,"","","","",151,"2022-07-13 09:24:54","","10.1101/2022.05.10.491358","","",,,,,0,0.00,0,9,1,"The human embryo breaks symmetry to form the anterior-posterior axis of the body. As the embryo elongates along this axis, progenitors in the tailbud give rise to axial tissues that generate the spinal cord, skeleton, and musculature. The mechanisms underlying human axial elongation are unknown. While ethics necessitate in vitro studies, the variability of human organoid systems has hindered mechanistic insights. Here we developed a bioengineering and machine learning framework that optimizes symmetry breaking by tuning the spatial coupling between human pluripotent stem cell-derived organoids. This framework enabled the reproducible generation of hundreds of axially elongating organoids, each possessing a tailbud and an epithelial neural tube with a single lumen. We discovered that an excitable system composed of WNT and FGF signaling drives axial elongation through the induction of a signaling center in the form of neuromesodermal progenitor (NMP)-like cells. The ability of NMP-like cells to function as a signaling center and drive elongation is independent of their potency to generate mesodermal cell types. We further discovered that the instability of the underlying excitable system is suppressed by secreted WNT inhibitors of the secreted frizzled-related protein (SFRP) family. Absence of these inhibitors led to the formation of ectopic tailbuds and branches. Our results identify mechanisms governing stable human axial elongation to achieve robust morphogenesis.","",""
0,"H. Hosseiny, C. Masteller, Colin P. Phillips","Development of a machine learning model for river bedload",2022,"","","","",152,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,1,". Prediction of bedload sediment transport rates in rivers is a notoriously challenging problem due to inherent variability in river hydraulics and channel morphology. Machine learning offers a compelling approach to leverage the growing wealth of bedload transport observations towards the development of a data driven predictive model. We present an artificial neural network (ANN) model for predicting bedload transport rates informed by 8,117 measurements from 134 10 rivers. Inputs to the model were river discharge, flow width, bed slope, and four bed surface sediment sizes. A sensitivity analysis showed that all inputs to the ANN model contributed to a reasonable estimate of bedload flux. At individual sites, the ANN model was able to reproduce observed sediment rating curves with a variety of shapes and outperformed four standard bedload models. This ANN model has the potential to be broadly applied to predict bedload fluxes based on discharge and reach properties alone. This paper presented an artificial neural network (ANN) model for predicting river bedload. To do that, a large, measured bedload dataset, including 8,117 data points from 134 rivers, was gathered from the BedloadWeb, a free public online platform. The structure of the ANN included an input layer, an output layer, and five hidden layers with 600 neurons. The 255 inputs to the model included temporally variable river discharge and flow width, and static measurements of bed slope, D 16 , D 50 , D 84 , and D 90 . A sensitivity analysis was carried out to show the sensitivity of the model with the input parameters. The results showed that the ANN model was most sensitive to the river discharge and least sensitive to the largest grain size ( D 90 ). Our analysis suggests that including all available parameters in the ANN model better captures the covariations between the input and output parameters. Further, the ANN model provides robust prediction of the test (unseen) bedload 260 data ( n = 1,624) within the bounds of one order of magnitude. We highlight that an advantage of this ANN model is that it was developed on a broad range of rivers and appears to accurately capture the variation in the data, making this model a good candidate for predicting bedload fluxes at gaged sites. The proposed machine learning model in this research lays the foundations for efficient and accurate predictions of river bedload.","",""
0,"Davide Piras, B. Joachimi, F. Villaescusa-Navarro","Fast and realistic large-scale structure from machine-learning-augmented random field simulations",2022,"","","","",153,"2022-07-13 09:24:54","","10.48550/arXiv.2205.07898","","",,,,,0,0.00,0,3,1,"Producing thousands of simulations of the dark matter distribution in the Universe with increasing precision is a challenging but critical task to facilitate the exploitation of current and forthcoming cosmological surveys. Many inexpensive substitutes to full 𝑁 -body simulations have been proposed, even though they often fail to reproduce the statistics of the smaller, non-linear scales. Among these alternatives, a common approximation is represented by the lognormal distribution, which comes with its own limitations as well, while being extremely fast to compute even for high-resolution density ﬁelds. In this work, we train a machine learning model to transform projected lognormal dark matter density ﬁelds to more realistic dark matter maps, as obtained from full 𝑁 -body simulations. We detail the procedure that we follow to generate highly correlated pairs of lognormal and simulated maps, which we use as our training data, exploiting the information of the Fourier phases. We demonstrate the performance of our model comparing various statistical tests with diﬀerent ﬁeld resolutions, redshifts and cosmological parameters, proving its robustness and explaining its current limitations. The augmented lognormal random ﬁelds reproduce the power spectrum up to wavenumbers of 1 ℎ Mpc − 1 , the bispectrum and the peak counts within 10%, and always within the error bars, of the ﬁducial target simulations. Finally, we describe how we plan to integrate our proposed model with existing tools to yield more accurate spherical random ﬁelds for weak lensing analysis, going beyond the lognormal approximation.","",""
0,"K. Shimamura, Koura Akihide, F. Shimojo","Construction of Machine-Learning Interatomic Potential Under Heat Flux Regularization and Its Application to Power Spectrum Analysis for Silver Chalcogenides",2022,"","","","",154,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,1,"We propose a data-driven approach for constructing machine-learning interatomic potentials (MLIPs) trained under a regularization with the aim of avoiding nonphysical heat ﬂux. Speciﬁcally, we introduce a regularization term for the heat ﬂux into the cost function of MLIPs to be minimized. Since the treatment of heat ﬂux using MLIPs with regularization can be decomposed into elemental contributions or conducted in frequency space, this approach is expected to be useful for investigating the origin of thermal conductivity obtained from the Green-Kubo formula. However, the strength of regularization needs to be appropriately set because it may reduce not only the nonphysical part but also the intrinsic heat ﬂux one. To this end, we investigated the conditions for constructing MLIPs that can reproduce the power spectra of heat ﬂux associated with the empirical interatomic potential of Ag 2 Se, which consists of pairwise functions and do not contain a nonphysical heat ﬂux. The appropriate strength could be estimated from the variation of the magnitude of regularization term as well as root mean square errors for total potential energy, atomic force, and virial stress with respect to the strengths, without reference spectrum data. As an application example, we explored the differences in power spectra between superionic and nonsuperionic conducting phases based on the heat ﬂux regularization to MLIPs trained with the ﬁrst-principles calculation data of Ag 2 S. Furthermore, our results demonstrate that training with the regularization improves the robustness of MLIPs as well as the reduction of the nonphysical heat ﬂux.","",""
0,"Daniel C. Anderson","Comment on gmd-2022-44 Anonymous Referee # 1 Referee comment on "" A Machine Learning Methodology for the Generation of a Parameterization of the Hydroxyl Radical : a Tool to Improve Computational-Efficiency in Chemistry Climate Models",2022,"","","","",155,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,1,1,"This paper describes the application of a gradient boosted regression tree machine learning approach to derive a parameterization for tropospheric OH based on CCM simulations. The approach is shown to reproduce simulated OH well under current conditions even for cases it has not been trained on, and it behaves acceptably, albeit with increasing errors, when applied to future conditions outside the standard training set. There is substantial novelty in the approach taken, and the results offer a degree of interpretability that is very interesting. The paper is generally well structured, clearly written, and appropriately illustrated. The authors have been thorough in evaluating their approach, and it is particularly good to see robust testing of input variable choice and hyperparameter value selection. the paper approach","",""
0,"Suparna De, Harry Moss, Jon Johnson, Jenny Li, Haeron Pereira, Sanaz Jabbari","Engineering a machine learning pipeline for automating metadata extraction from longitudinal survey questionnaires",2022,"","","","",156,"2022-07-13 09:24:54","","10.29173/iq1023","","",,,,,0,0.00,0,6,1,"Data Documentation Initiative-Lifecycle (DDI-L) introduced a robust metadata model to support the capture of questionnaire content and flow, and encouraged through support for versioning and provenancing, objects such as BasedOn for the reuse of existing question items. However, the dearth of questionnaire banks including both question text and response domains has meant that an ecosystem to support the development of DDI ready Computer Assisted Interviewing (CAI) tools has been limited. Archives hold the information in PDFs associated with surveys but extracting that in an efficient manner into DDI-Lifecycle is a significant challenge.  While CLOSER Discovery has been championing the provision of high-quality questionnaire metadata in DDI-Lifecycle, this has primarily been done manually. More automated methods need to be explored to ensure scalable metadata annotation and uplift.  This paper presents initial results in engineering a machine learning (ML) pipeline to automate the extraction of questions from survey questionnaires as PDFs. Using CLOSER Discovery as a ‘training and test dataset’, a number of machine learning approaches have been explored to classify parsed text from questionnaires to be output as valid DDI items for inclusion in a DDI-L compliant repository.  The developed ML pipeline adopts a continuous build and integrate approach, with processes in place to keep track of various combinations of the structured DDI-L input metadata, ML models and model parameters against the defined evaluation metrics, thus enabling reproducibility and comparative analysis of the experiments.  Tangible outputs include a map of the various metadata and model parameters with the corresponding evaluation metrics’ values, which enable model tuning as well as transparent management of data and experiments.","",""
0,"A. Cornhill, S. Dykstra, A. Satriano, D. Labib, Y. Mikami, J. Flewitt, Easter Prosio, S. Rivest, R. Sandonato, A. Howarth, C. Lydell, C. Eastwood, H. Quan, N. Fine, Joon Lee, J. White","Machine Learning Patient-Specific Prediction of Heart Failure Hospitalization Using Cardiac MRI-Based Phenotype and Electronic Health Information",2022,"","","","",157,"2022-07-13 09:24:54","","10.3389/fcvm.2022.890904","","",,,,,0,0.00,0,16,1,"Background Heart failure (HF) hospitalization is a dominant contributor of morbidity and healthcare expenditures in patients with systolic HF. Cardiovascular magnetic resonance (CMR) imaging is increasingly employed for the evaluation of HF given capacity to provide highly reproducible phenotypic markers of disease. The combined value of CMR phenotypic markers and patient health information to deliver predictions of future HF events has not been explored. We sought to develop and validate a novel risk model for the patient-specific prediction of time to HF hospitalization using routinely reported CMR variables, patient-reported health status, and electronic health information. Methods Standardized data capture was performed for 1,775 consecutive patients with chronic systolic HF referred for CMR imaging. Patient demographics, symptoms, Health-related Quality of Life, pharmacy, and routinely reported CMR features were provided to both machine learning (ML) and competing risk Fine-Gray-based models (FGM) for the prediction of time to HF hospitalization. Results The mean age was 59 years with a mean LVEF of 36 ± 11%. The population was evenly distributed between ischemic (52%) and idiopathic non-ischemic cardiomyopathy (48%). Over a median follow-up of 2.79 years (IQR: 1.59–4.04) 333 patients (19%) experienced HF related hospitalization. Both ML and competing risk FGM based models achieved robust performance for the prediction of time to HF hospitalization. Respective 90-day, 1 and 2-year AUC values were 0.87, 0.83, and 0.80 for the ML model, and 0.89, 0.84, and 0.80 for the competing risk FGM-based model in a holdout validation cohort. Patients classified as high-risk by the ML model experienced a 34-fold higher occurrence of HF hospitalization at 90 days vs. the low-risk group. Conclusion In this study we demonstrated capacity for routinely reported CMR phenotypic markers and patient health information to be combined for the delivery of patient-specific predictions of time to HF hospitalization. This work supports an evolving migration toward multi-domain data collection for the delivery of personalized risk prediction at time of diagnostic imaging.","",""
2,"Dhruv Desai, D. Mehta","On Robustness of Mutual Funds Categorization and Distance Metric Learning",2021,"","","","",158,"2022-07-13 09:24:54","","10.3905/jfds.2021.3.4.130","","",,,,,2,2.00,1,2,1,"Identifying similar mutual funds among a given universe of funds has many applications, including competitor analysis, marketing and sales, tax loss harvesting, and so on. For a contemporary analyst, the most popular approach to finding similar funds is to look up a categorization system such as Morningstar categorization. Morningstar categorization has been heavily investigated by academic researchers from various angles, including using unsupervised clustering techniques in which clusters were found to be inconsistent with categorization. Recently, however, categorization has been studied using supervised classification techniques, with the categories being the target labels. Categorization was indeed learnable with very high accuracy using a purely data-driven approach, causing a paradox: Clustering was inconsistent with respect to categorization, whereas supervised classification was able to reproduce (near) complete categorization. Here, the authors resolve this apparent paradox by pointing out incorrect uses and interpretations of machine learning techniques in the previous academic literature. The authors demonstrate that by using an appropriate list of variables and metrics to identify the optimal number of clusters and preprocessing the data using distance metric learning, one can indeed reproduce the Morningstar categorization using a data-driven approach. The present work puts an end to the debate on this issue and establishes that the Morningstar categorization is indeed intrinsically rigorous, consistent, rule-based, and reproducible using data-driven approaches, if machine learning techniques are correctly implemented. Key Findings ▪ Academic literature has time and again questioned the consistency and robustness of mutual fund’s categorization systems, such as Morningstar categorization, by contrasting them with unsupervised clustering of funds. ▪ Here, the authors settle the debate in favor of Morningstar categorization by pointing out the use of incorrect lists of variables and interpretation of machine learning algorithms in the previous literature, while emphasizing that the main missing piece from the machine learning side in previous research was the appropriate distance metric. ▪ The authors employ a machine learning technique called distance metric learning and reproduce the Morningstar categorization completely using a data-driven approach.","",""
8,"Adedeji Olugboja, Zenghui Wang","Malaria parasite detection using different machine learning classifier",2017,"","","","",159,"2022-07-13 09:24:54","","10.1109/ICMLC.2017.8107772","","",,,,,8,1.60,4,2,5,"In the tropical and the subtropical countries, malaria has been a challenge, which really needs a quick and precise diagnosis to put a stop or control the disease. The conventional microscopy method has some shortcomings which includes time consumption and reproducibility. Many of the alternative methods are expensive and it's not readily accessible to the developing countries that need them. In this paper a fast and precise system was developed using stained blood smear images. We employed watershed segmentation technique to acquire plasmodium infected and non-infected erythrocytes and relevant feature was extracted. Six different machine learning techniques for classification are used in the experiments. Fine Gaussian SVM had a True Positive Rate (TPR) of 99.8% in the detection of the plasmodium infected erythrocyte.","",""
17,"Khimya Khetarpal, Zafarali Ahmed, Andre Cianflone, Riashat Islam, Joelle Pineau","RE-EVALUATE: Reproducibility in Evaluating Reinforcement Learning Algorithms",2018,"","","","",160,"2022-07-13 09:24:54","","","","",,,,,17,4.25,3,5,4,"Reinforcement learning (RL) has recently achieved tremendous success in solving complex tasks. Careful considerations are made towards reproducible research in machine learning. Reproducibility in RL often becomes more difficult, due to the lack of standard evaluation method and detailed methodology for algorithms and comparisons with existing work. In this work, we highlight key differences in evaluation in RL compared to supervised learning, and discuss specific issues that are often non-intuitive for newcomers. We study the importance of reproducibility in evaluation in RL, and propose an evaluation pipeline that can be decoupled from the algorithm code. We hope such an evaluation pipeline can be standardized, as a step towards robust and reproducible research in RL.","",""
14,"Hongfeng Li, Hong-Qin Zhao, Hong Li","Neural-Response-Based Extreme Learning Machine for Image Classification",2019,"","","","",161,"2022-07-13 09:24:54","","10.1109/TNNLS.2018.2845857","","",,,,,14,4.67,5,3,3,"This paper proposes a novel and simple multilayer feature learning method for image classification by employing the extreme learning machine (ELM). The proposed algorithm is composed of two stages: the multilayer ELM (ML-ELM) feature mapping stage and the ELM learning stage. The ML-ELM feature mapping stage is recursively built by alternating between feature map construction and maximum pooling operation. In particular, the input weights for constructing feature maps are randomly generated and hence need not be trained or tuned, which makes the algorithm highly efficient. Moreover, the maximum pooling operation enables the algorithm to be invariant to certain transformations. During the ELM learning stage, elastic-net regularization is proposed to learn the output weight. Elastic-net regularization helps to learn more compact and meaningful output weight. In addition, we preprocess the input data with the dense scale-invariant feature transform operation to improve both the robustness and invariance of the algorithm. To evaluate the effectiveness of the proposed method, several experiments are conducted on three challenging databases. Compared with the conventional deep learning methods and other related ones, the proposed method achieves the best classification results with high computational efficiency.","",""
456,"Amir Mosavi, Pınar Öztürk, K. Chau","Flood Prediction Using Machine Learning Models: Literature Review",2018,"","","","",162,"2022-07-13 09:24:54","","10.3390/w10111536","","",,,,,456,114.00,152,3,4,"Floods are among the most destructive natural disasters, which are highly complex to model. The research on the advancement of flood prediction models contributed to risk reduction, policy suggestion, minimization of the loss of human life, and reduction of the property damage associated with floods. To mimic the complex mathematical expressions of physical processes of floods, during the past two decades, machine learning (ML) methods contributed highly in the advancement of prediction systems providing better performance and cost-effective solutions. Due to the vast benefits and potential of ML, its popularity dramatically increased among hydrologists. Researchers through introducing novel ML methods and hybridizing of the existing ones aim at discovering more accurate and efficient prediction models. The main contribution of this paper is to demonstrate the state of the art of ML models in flood prediction and to give insight into the most suitable models. In this paper, the literature where ML models were benchmarked through a qualitative analysis of robustness, accuracy, effectiveness, and speed are particularly investigated to provide an extensive overview on the various ML algorithms used in the field. The performance comparison of ML models presents an in-depth understanding of the different techniques within the framework of a comprehensive evaluation and discussion. As a result, this paper introduces the most promising prediction methods for both long-term and short-term floods. Furthermore, the major trends in improving the quality of the flood prediction models are investigated. Among them, hybridization, data decomposition, algorithm ensemble, and model optimization are reported as the most effective strategies for the improvement of ML methods. This survey can be used as a guideline for hydrologists as well as climate scientists in choosing the proper ML method according to the prediction task.","",""
9,"R. Roelofs","Measuring Generalization and Overfitting in Machine Learning",2019,"","","","",163,"2022-07-13 09:24:54","","","","",,,,,9,3.00,9,1,3,"Author(s): Roelofs, Rebecca | Advisor(s): Recht, Benjamin; Demmel, James | Abstract: Due to the prevalence of machine learning algorithms and the potential for their decisions to profoundly impact billions of human lives, it is crucial that they are robust, reliable, and understandable. This thesis examines key theoretical pillars of machine learning surrounding generalization and overfitting, and tests the extent to which empirical behavior matches existing theory. We develop novel methods for measuring overfitting and generalization, and we characterize how reproducible observed behavior is across differences in optimization algorithm, dataset, task, evaluation metric, and domain.First, we examine how optimization algorithms bias machine learning models towards solutions with varying generalization properties. We show that adaptive gradient methods empirically find solutions with inferior generalization behavior compared to those found by stochastic gradient descent. We then construct an example using a simple overparameterized model that corroborates the algorithms’ empirical behavior on neural networks. Next, we study the extent to which machine learning models have overfit to commonly reused datasets in both academic benchmarks and machine learning competitions. We build new test sets for the CIFAR-10 and ImageNet datasets and evaluate a broad range of classification models on the new datasets. All models experience a drop in accuracy, which indicates that current accuracy numbers are susceptible to even minute natural variations in the data distribution. Surprisingly, despite several years of adaptively selecting the models to perform well on these competitive benchmarks, we find no evidence of overfitting. We then analyze data from the machine learning platform Kaggle and find little evidence of substantial overfitting in ML competitions. These findings speak to the robustness of the holdout method across different data domains, loss functions, model classes, and human analysts.Overall, our work suggests that the true concern for robust machine learning is distribution shift rather than overfitting, and designing models that still work reliably in dynamic environments is a challenging but necessary undertaking.","",""
0,"Marco Rasetto, Qingzhou Wan, Himanshu Akolkar, Bertram E. Shi, Feng Xiong, R. Benosman","The Challenges Ahead for Bio-inspired Neuromorphic Event Processors: How Memristors Dynamic Properties Could Revolutionize Machine Learning",2022,"","","","",164,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,6,1,"Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artificial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efficient approach to build novel bio-inspired processing units in silicon.","",""
0,"Daniel Castillo-Secilla, J. M. Gálvez, Francisco Carrillo-Perez, Juan Carlos Prieto- Prieto, O. Valenzuela, Luis Javier Herrera, Ignacio Rojas","Comprehensive PanCancer Gene Signature Assessment Through the Implementation of a Cascade Machine Learning System",2022,"","","","",165,"2022-07-13 09:24:54","","10.2174/1574893617666220421100512","","",,,,,0,0.00,0,7,1,"  Despite all the medical advances introduced for personalized patient treatment and the research supported in search of genetic patterns inherent to the occurrence of its different manifestations on the human being, the unequivocal and effective treatment of cancer unfortunately remains as an unresolved challenge within the scientific panorama. Until a universal solution for its control is achieved, early detection mechanisms for preventative diagnosis are increasingly avoiding therapeutic treatments which result in unreliable effectiveness. The discovery of unequivocal gene patterns allowing us to discern between multiple pathological states, could help to shed light on those patients with suspicion of oncological disease but with uncertainty in the histological and immunohistochemical results.    This study presents an approach for pancancer diagnosis based on gene expression analysis that determines a reduced set of 12 genes, which makes it possible to distinguish between the main 14 cancer diseases.    Our cascade machine learning process has been robustly designed, obtaining a mean F1-score of 92% and a mean AUC of 99.37% in the test set. Our study showed heterogeneous over-or underexpression of the analyzed genes, which are able to act as oncogenes or tumor suppressor genes. Upregulation of LPAR5 and PAX8 was demonstrated in thyroid cancer samples. KLF5 was highly expressed in the majority of cancer types.    Our model constituted a useful tool for pancancer gene expression evaluation. In addition to providing biological clues about a hypothetical common origin of cancer, the scalability of this study promises to be very useful for future studies to reinforce, confirm, and extend the biological observations presented here. Code availability and datasets are stored in the following GitHub repository to aim the research reproducibility: https://github.com/CasedUgr/PanCancerClassification. ","",""
0,"T. Giese, Jinzhe Zeng, S. Ekesan, D. York","Combined QM/MM, Machine Learning Path Integral Approach to Compute Free Energy Profiles and Kinetic Isotope Effects in RNA Cleavage Reactions.",2022,"","","","",166,"2022-07-13 09:24:54","","10.1021/acs.jctc.2c00151","","",,,,,0,0.00,0,4,1,"We present a fast, accurate, and robust approach for determination of free energy profiles and kinetic isotope effects for RNA 2'-O-transphosphorylation reactions with inclusion of nuclear quantum effects. We apply a deep potential range correction (DPRc) for combined quantum mechanical/molecular mechanical (QM/MM) simulations of reactions in the condensed phase. The method uses the second-order density-functional tight-binding method (DFTB2) as a fast, approximate base QM model. The DPRc model modifies the DFTB2 QM interactions and applies short-range corrections to the QM/MM interactions to reproduce ab initio DFT (PBE0/6-31G*) QM/MM energies and forces. The DPRc thus enables both QM and QM/MM interactions to be tuned to high accuracy, and the QM/MM corrections are designed to smoothly vanish at a specified cutoff boundary (6 Å in the present work). The computational speed-up afforded by the QM/MM+DPRc model enables free energy profiles to be calculated that include rigorous long-range QM/MM interactions under periodic boundary conditions and nuclear quantum effects through a path integral approach using a new interface between the AMBER and i-PI software. The approach is demonstrated through the calculation of free energy profiles of a native RNA cleavage model reaction and reactions involving thio-substitutions, which are important experimental probes of the mechanism. The DFTB2+DPRc QM/MM free energy surfaces agree very closely with the PBE0/6-31G* QM/MM results, and it is vastly superior to the DFTB2 QM/MM surfaces with and without weighted thermodynamic perturbation corrections. 18O and 34S primary kinetic isotope effects are compared, and the influence of nuclear quantum effects on the free energy profiles is examined.","",""
0,"Chace Lee, Angelica Willis, Christina Chen, M. Sieniek, Akib A Uddin, Jonny Wong, Rory Pilgrim, Katherine Chou, Daniel Tse, S. Shetty, Ryan G. Gomes","Enabling faster and more reliable sonographic assessment of gestational age through machine learning",2022,"","","","",167,"2022-07-13 09:24:54","","10.48550/arXiv.2203.11903","","",,,,,0,0.00,0,11,1,"Fetal ultrasounds are an essential part of prenatal care and can be used to estimate gestational age (GA). Accurate GA assessment is important for providing appropriate prenatal care throughout pregnancy and identifying complications such as fetal growth disorders. Since derivation of GA from manual fetal biometry measurements (head, abdomen, femur) are operator-dependent and time-consuming, there have been a number of research efforts focused on using artificial intelligence (AI) models to estimate GA using standard biometry images, but there is still room to improve the accuracy and reliability of these AI systems for widescale adoption. To improve GA estimates, without significant change to provider workflows, we leverage AI to interpret standard plane ultrasound images as well as “fly-to” ultrasound videos, which are 5-10s videos automatically recorded as part of the standard of care before the still image is captured. We developed and validated three AI models: an image model using standard plane images, a video model using fly-to videos, and an ensemble model (combining both image and video). All three were statistically superior to standard fetal biometry-based GA estimates derived by expert sonographers, the ensemble model has the lowest mean absolute error (MAE) compared to the clinical standard fetal biometry (mean difference: -1.51 ± 3.96 days, 95% CI [-1.9, -1.1]) on a test set that consisted of 404 participants. We showed that our models outperform standard biometry by a more substantial margin on fetuses that were small for GA. Our AI models have the potential to empower trained operators to estimate GA with higher accuracy while reducing the amount of time required and user variability in measurement acquisition. Introduction Fetal ultrasound is the cornerstone of prenatal imaging and can provide crucial information to guide maternal-fetal care, such as estimated gestational age (GA) and fetal growth disorders. Currently, the clinical standard of estimating GA and diagnosis of fetal growth disorders are determined through manual acquisition of fetal biometric measurements such as biparietal diameter, head circumference, abdominal circumference, femur length, and crown-rump length. Numerous regression formulae for GA estimation exist based on different combinations of fetal biometric measurements. Hadlock's formula is one of the most popular formulas and is included with most ultrasound equipment packages. Previous studies have suggested that while fetal biometric measurements were generally reproducible, there was increased variance later in pregnancy, which is when many key clinical decisions (such as delivery scheduling and medication administration if needed) are made.1,2 The accuracy and efficiency of biometric measurements is dependent on the skill and experience of the sonographer. Factors like fetal movement and difficult fetal positioning can make it difficult to accurately position the ultrasound probe to acquire biometry measurements. There has been extensive research on using artificial intelligence (AI) systems to assist in estimating GA, typically through automatic estimation of biometric parameters that are then used in the Hadlock formula.3–7 We have recently shown that GA model estimation that directly used ultrasound videos of pre-defined sweeps was non-inferior to standard fetal biometry estimates.8 In this study, we further extend the use of ultrasound videos by developing three end-to-end AI models: a) image model using fetal ultrasound images captured by sonographers during biometry measurements, b) video model using “fly-to” videos, or 5 to 10 seconds of video immediately before image capture, c) ensemble model using both images and fly-to videos. All data were collected retrospectively during standard biometry measurements. All three models directly estimate GA, without requiring measurement acquisition or use of regression formulae. To our knowledge, this is the first attempt on using AI on standard of care ultrasound videos to predict GA directly for all trimesters without estimating biometry measurements from standard plane images. Results Our models were developed and evaluated using datasets prospectively collected as part of the FAMLI study 9. Our evaluation was performed on a test set consisting of patients independent of those used for AI development. The primary test set consisted of 407 women with standard of care ultrasound scans performed by expert sonographers at University of North Carolina (UNC) Healthcare, Chapel Hill, NC, USA and at community clinics in Lusaka, Zambia. Complete sets of ultrasound fetal biometry images and fly-to videos data collected with the SonoSite Turbo-M or Voluson S6 ultrasound machine were available for 404 of these 407 participants, corresponding to 677 study visits. The disposition of test set study participants used in the following analysis are summarized in STARD diagrams (Extended Data Figure 1). The characteristics of study participants who are included in the test set analyses are shown in Extended Data Table 1. Among study visits conducted by sonographers, 63 (9.3%) women had at least one visit during the first trimester, 235 (34.7%) women had at least one visit during the second trimester, and 379 (56.0%) had one or more visits in the third trimester. AI gestational age estimation using ultrasound images and fly-to videos The primary analysis outcome for GA was the mean difference in absolute error between the GA model estimate and the clinical standard estimate, with the ground truth GA extrapolated from the initial GA estimated at the initial exam. The ground truth GA at each subsequent visit was calculated as: GA at initial exam plus number of days since baseline visit. Statistical estimates and comparisons were computed after randomly selecting one study visit per patient for each analysis group, to avoid combining correlated measurements from the same patient. GA analysis results are summarized in Table 1. The overall MAE for the image GA model is lower compared to the MAE for the standard fetal biometry estimates (mean difference -1.13 ± 4.18 days, 95% CI [-1.5, -0.7]), the upper limit of the 95% CI for the difference in MAE values was negative, indicating statistical superiority of the model. The overall MAE of the video model and ensemble models are significantly lower compared to the standard fetal biometry; the ensemble model has the lowest MAE (mean difference -1.51 ± 3.96 days, 95% CI [-1.9, -1.1]), followed by the video model (mean difference -1.48 ± 4.05 days, 95% CI [-1.9, -1.1]). For both models, the upper limit of the 95% CI for the difference in MAE values was negative, indicating statistical superiority. In addition, secondary subgroup analyses were performed, with subgroups including pregnancy trimester (first, second or third), by country (US and Zambia), and device manufacturers (SonoSite Turbo-M or Voluson S6). For each subgroup analysis, estimates and comparisons were computed after randomly selecting one study visit per patient for patients eligible for the subgroups, to avoid combining correlated measurements from the same patient. Subgroup analysis for trimester, countries and devices are provided in Tables 2 and 3. The result shows that our models generalize well across countries, devices and second and third trimesters, with lower MAE compared to the standard fetal biometry estimates. The upper limit of the 95% CI for the difference in MAE values was less than 0.1 day, except for the first trimester, where the smaller sample size for the first trimester dataset size broadened confidence intervals. There was a trend towards increasing error for all models and standard fetal biometry procedures with gestational week. Gestational age estimation compared with alternative formulae The formulae derived in Hadlock et al.2 are the standard of care in the United States and many other countries around the world; however, these formulae, having been derived based on a limited population of 361 middle-class Caucasian women in Texas, might not generalize as well as alternative formulae developed with broader, population-based data. For this reason, we compared the predictions on the FAMLI population with two additional formulae, INTERGROWTH-21st and NICHD, that have shown promise as potential alternatives to Hadlock.10,11 GA analysis results are summarized in Table 4, the ensemble model has the lower MAE compared to NICHD (mean difference -1.23 ± 4.04 days, 95% CI [-1.6, -0.8]), and INTERGROWTH-21st (mean difference -2.69 ± 5.54 days, 95% CI [-3.3, -2.1]), the upper limits of the 95% CI for the difference in MAE values were less negative, indicating statistical superiority. Analysis of per country performance is summarized in Extended Table 2, which shows that the accuracy of Hadlock-based GA estimates are close to Hadlock in the US (NICHD MAE: 4.79 ± 4.16, Hadlock MAE: 4.90 ± 4.32), while outperforming Hadlock significantly in the Zambia population (NICHD MAE: 4.96. ± 4.84, Hadlock MAE: 5.62 ± 5.2). The INTERGROWTH-21st formula performs significantly worse than Hadlock and NICHD across both populations. Our ensemble model estimate is compared against NICHD; the result shows the ensemble model has a lower MAE for both US (mean difference 3.58 ± 2.79 days, 95% CI [-1.9, -0.7]) and Zambia (mean difference 3.70 ± 3.57 days, 95% CI [-1.8, -0.6]), demonstrating robustness and statistical superiority on all subgroups. Performance of model on small for gestational age (SGA) and large for gestational age (LGA) cases Biometry-based methods of determining gestational age are predisposed to underestimation and overestimation of SGA and LGA fetuses, respectively. To understand if the AI model was affected, we performed an analysis of accuracy achieved on fetuses smaller or larger than expected for their GA based on fetal abdominal circumference (AC) measured for the given population and ground truth gestational week, ","",""
6,"Ismael Baira Ojeda, S. Tolu, H. Lund","A Scalable Neuro-inspired Robot Controller Integrating a Machine Learning Algorithm and a Spiking Cerebellar-Like Network",2017,"","","","",168,"2022-07-13 09:24:54","","10.1007/978-3-319-63537-8_31","","",,,,,6,1.20,2,3,5,"","",""
3,"N. Radziwill","Machine Learning with R, Third Edition (Book Review)",2019,"","","","",169,"2022-07-13 09:24:54","","10.1080/10686967.2019.1648086","","",,,,,3,1.00,3,1,3,"This book is highly recommended for anyone with previous programing experience who seeks a solid, grounded introduction to basic machine learning using the R statistical software. With nearly 100 additional pages added since the first edition in 2013, this update to Brett Lantz’s excellent text is well worth the purchase, even for those who already have an earlier copy on their shelf. Clear writing, robust explanations, and compelling examples appear throughout, and most chapters explain the math underlying the methods in as simple and easy a manner as possible. I liked the first edition so much, I used it as the primary textbook for my applied machine learning class for undergraduate juniors and seniors in science and engineering. Chapter 1 provides an overview of the main concepts associated with developing and using ML models for decision making. It includes discussions of traditional topics like overfitting and emerging issues like bias and artificial intelligence (AI) ethics. The chapter structure follows the same pattern as previous editions, so knn, Naive Bayes, decision trees, four neural networks and SVMs, association rules, k-means, and performance are all covered. Chapter 12 on specialized machine learning topics is significantly updated from previous editions and now covers tidyverse, domain-specific data, and brief examinations of performance optimization techniques like parallelization, MapReduce, Hadoop, and Spark. In most chapters, there are fully reproducible examples clearly broken down into steps. Within those steps, subtasks (for example, transformation, data preparation, model specification) are also clearly specified, making it clear how to structure different types of problems. This book is excellent for beginners and others who want to use R to learn how to skillfully address ML problems using their own data.","",""
3,"Finn Kuusisto, V. S. Costa, Zhonggang Hou, James A. Thomson, David Page, R. Stewart","Machine Learning to Predict Developmental Neurotoxicity with High-Throughput Data from 2D Bio-Engineered Tissues",2019,"","","","",170,"2022-07-13 09:24:54","","10.1109/ICMLA.2019.00055","","",,,,,3,1.00,1,6,3,"There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.","",""
1,"Ramkumar Harikrishnakumar, A. Dand, S. Nannapaneni, K. Krishnan","Supervised Machine Learning Approach for Effective Supplier Classification",2019,"","","","",171,"2022-07-13 09:24:54","","10.1109/ICMLA.2019.00045","","",,,,,1,0.33,0,4,3,"Supplier assessment plays a critical role in the supply chain management, which involves the flow of goods and services from the initial stage (raw material procurement) to the final stage (delivery). Supplier assessment is a multi-criteria decision-making (MCDM) approach that requires several criteria for the proper assessment of the suppliers. When there are several criteria involved, it makes the supplier assessment process more complicated. For a comprehensive and robust assessment process, we propose the use of supervised machine learning algorithms to classify various suppliers into four categories: excellent, good, satisfactory, and unsatisfactory. In this paper, supervised learning (classification) algorithms are applied for a supplier assessment problem where a model is trained based on the previous historical data and then tested on the new unseen data set. This method will provide an efficient way for supplier assessment that is more effective in terms of accuracy and time when compared to MCDM approach. Classification algorithms such as support vector machines (with linear, polynomial and radial basis kernels), logistic regression, k-nearest neighbors, and naïve Bayes methods are used to train the model and their performance is assessed against a test data. Finally, the performance measures from all the classification methods are used to assess the best supplier.","",""
0,"Muhammad Abdullah Hanif, R. Hafiz, M. Javed, Semeen Rehman, M. Shafique","Energy-Efficient Design of Advanced Machine Learning Hardware",2019,"","","","",172,"2022-07-13 09:24:54","","10.1007/978-3-030-04666-8_21","","",,,,,0,0.00,0,5,3,"","",""
0,"R. Murphy, Joshua D Kangas, C. Langmead","Tools Needed for Automating Science : Formalizing the use of Active Machine Learning to Drive Experimentation",2017,"","","","",173,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,3,5,"There is a need to develop and deploy advanced technologies for fully automating the execution of science and engineering projects. These technologies could dramatically decrease the costs of research and engineering, while increasing throughput and reproducibility. Existing platforms for automating research merely execute experiments selected by humans. What is needed are generalizable technologies (open source software and community standards) capable of closed-loop hypothesis generation from available data, experiment selection, and automated execution. Many biological and chemical systems are too complex for humans to understand completely, due to their scale and their nonlinear and stochastic behaviors. Traditionally, scientists and engineers choose and perform experiments to test hypotheses or to optimize designs. As the system’s complexity increases, the number of possible experiments that could be performed to study it rises exponentially, and, since resource constraints limit the number of experiments performed, we are faced with the need to select a maximally informative set of experiments from a combinatorial space of possible experiments, trying to optimize financial or other constraints. Unfortunately, the human mind is not well suited to solving this type of optimization problem, due most often to our inability to form predictive models at the scales involved. The result is that, in practice, many humanselected experiments are “wasted” on conditions where no effect is observed or, more importantly, where the effect is predictable from other experiments, given computational assistance. This waste of resources ultimately limits what scientists and engineers can accomplish. This type of problem is the realm of Active Learning [1-6], a sub-domain of Machine Learning focused on algorithms for iteratively choosing experiments expected to optimally improve an underlying computational model (Figure 1). While active learning could provide benefits for essentially all large scale screening and experimentation, such as drug development [7-8], there are significant barriers to its routine use. Perhaps the most significant is the absence of robust, readily available software to facilitate use by any group embarking on large scale experimentation. We therefore suggest the need for the development of open source tools and open access standards to enable the routine use of active learning driven experimentation. We suggest tools are needed for four connected tasks: random access experimentation; experimental data analysis; predictive model construction; and active learning experiment selection (Figure 2). The first component is the most involved, in that it may be highly specialized for particular types of experiments. However, the first step is to have the experimenter communicate to an automated system the specifics of how to perform an experiment and what experiments are allowed (e.g., which cell lines and drugs may be chosen from). The former is simply a protocol that, for example, liquid-handling robots and automated measurement systems are used to execute and open standards currently exist. The latter is simply defining the source plates/libraries. However, most current systems can only run the protocol for entire rows, columns or plates. The key to using such systems for active learning is to allow a computer to specify a particular set of experiments to perform that does not conform to these limitations (e.g., cells 1a, 4c, 9f, 2e, etc.). We suggest the need for collaboration between software developers, instrument manufacturers and contract research organizations to Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science 2 implement such systems and create open standards for a computer to communicate a desired set of experiments to an automated system without human intervention. The second component, predictive model generation, is also specialized for a particular type of data or problem, and would typically be paired with a particular protocol or instrument type. However, much work has been done on automated analysis and modeling pipelines for various data sources , the interfaces to which can be standardized. There has been significant work on the third of these components in the context of large experimental spaces. This first is on matrix completion methods that construct a predictive model for an entire space given data for some parts of that space. For example, work has been done on constructing a predictive model of drug-target interactions in the setting of drug discovery [9-11]. However, that work has focused on the task of predicting which new drugs will interact with known targets given data on the interactions of known drugs with those targets. In most settings, this has meant providing complete data for the subset of known drugs in order to train the model (i.e., values for many complete columns of the drug-target matrix); the assumption was that one was going to do no new experiments but simply try to predict their outcomes from a large body of comprehensive data. Recent results for the setting in which the training data is non-uniformly distributed over the drug-target matrix has been done [12,13]. The fourth component is active learning engines. Active learning has been studied in many contexts and for a number of different criteria for choosing experiments. However, the vast majority of this work has been retrospective: a large, complete dataset is ‘hidden’ from the active learner and individual data points are revealed upon request. This setting enables the calculation of the accuracy of the model at any point in the active learning process because all of the data is actually available. This setting does not apply to any real-world application in which the point is to avoid collecting all of the data. Additional work is needed on approaches for estimating the accuracy of an actively-learned model so that we can know when the model is good enough to stop doing acquisition Conclusion: Automation is the future of science and engineering. It will dramatically reduce the costs of discovery and development, while increasing throughput and reproducibility. More importantly, the use of automated model building and experiment selection via active learning will overcome the limits of the human mind, when it comes to reasoning about complex systems and the data they produce Figure 1. The Active Learning Cycle. The key is to iteratively select and execute experiments based on the current predictive model. Note that this is not the traditional “systems biology” approach that focuses on constructing a predictive model using data from a very large set of experiments and then trying to “prove” the model by doing selected additional Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science 3 experiments to verify high-confidence predictions. Such approaches ignore the fact that it is impossible to prove empirical models, and that the most appropriate use of new data is to improve a model! Note also that this different from trying to predict everything in silico – the active learning approach optimally combines computational prediction and experimental data acquisition. Figure 2. Components to be developed by the STC. 1) Tools for the experimenter to communicate to an automated system the specifics of what experiments are allowed (e.g., which cell lines and compounds may be chosen from) and how to perform them. 2) Tools for processing measurements (e.g., image analysis). These are specific to each type of study. 3) Tools for converting processed data into predictive models. This uses traditional machine learning methods or system identification methods, depending on the study. 4) Active learning engines. Most past work has been retrospective: a large, complete dataset is ‘hidden’ from the active learner and individual data points are revealed upon request. The STC will demonstrate the utility in real-world, prospective settings. Figure 3. Active Learning Examples. In a retrospective study of drug effects, 57% of active compounds were discovered with only 2.5% of possible experiments [13]. In a prospective study, a 92% accurate model of complex phenotypes was obtained after only 28% of possible experiments [14]. Murphy, Kangas and Langmead White Paper: Tools Needed for Automating Science","",""
227,"Naomi Zimmerman, A. Presto, Srini Kumar, J. Gu, A. Hauryliuk, E. Robinson, A. Robinson, R. Subramanian","A machine learning calibration model using random forests to improve sensor performance for lower-cost air quality monitoring",2018,"","","","",174,"2022-07-13 09:24:54","","10.5194/AMT-11-291-2018","","",,,,,227,56.75,28,8,4,"Abstract. Low-cost sensing strategies hold the promise of denser air quality monitoring networks, which could significantly improve our understanding of personal air pollution exposure. Additionally, low-cost air quality sensors could be deployed to areas where limited monitoring exists. However, low-cost sensors are frequently sensitive to environmental conditions and pollutant cross-sensitivities, which have historically been poorly addressed by laboratory calibrations, limiting their utility for monitoring. In this study, we investigated different calibration models for the Real-time Affordable Multi-Pollutant (RAMP) sensor package, which measures CO, NO2, O3, and CO2. We explored three methods: (1) laboratory univariate linear regression, (2) empirical multiple linear regression, and (3) machine-learning-based calibration models using random forests (RF). Calibration models were developed for 16–19 RAMP monitors (varied by pollutant) using training and testing windows spanning August 2016 through February 2017 in Pittsburgh, PA, US. The random forest models matched (CO) or significantly outperformed (NO2, CO2, O3) the other calibration models, and their accuracy and precision were robust over time for testing windows of up to 16 weeks. Following calibration, average mean absolute error on the testing data set from the random forest models was 38 ppb for CO (14 % relative error), 10 ppm for CO2 (2 % relative error), 3.5 ppb for NO2 (29 % relative error), and 3.4 ppb for O3 (15 % relative error), and Pearson r versus the reference monitors exceeded 0.8 for most units. Model performance is explored in detail, including a quantification of model variable importance, accuracy across different concentration ranges, and performance in a range of monitoring contexts including the National Ambient Air Quality Standards (NAAQS) and the US EPA Air Sensors Guidebook recommendations of minimum data quality for personal exposure measurement. A key strength of the RF approach is that it accounts for pollutant cross-sensitivities. This highlights the importance of developing multipollutant sensor packages (as opposed to single-pollutant monitors); we determined this is especially critical for NO2 and CO2. The evaluation reveals that only the RF-calibrated sensors meet the US EPA Air Sensors Guidebook recommendations of minimum data quality for personal exposure measurement. We also demonstrate that the RF-model-calibrated sensors could detect differences in NO2 concentrations between a near-road site and a suburban site less than 1.5 km away. From this study, we conclude that combining RF models with carefully controlled state-of-the-art multipollutant sensor packages as in the RAMP monitors appears to be a very promising approach to address the poor performance that has plagued low-cost air quality sensors.","",""
3,"Noureldin Laban, B. Abdellatif, H. M. Ebeid, H. Shedeed, M. Tolba","Machine Learning for Enhancement Land Cover and Crop Types Classification",2018,"","","","",175,"2022-07-13 09:24:54","","10.1007/978-3-030-02357-7_4","","",,,,,3,0.75,1,5,4,"","",""
34,"A. Sargolzaei, C. Crane, Alireza Abbaspour, S. Noei","A Machine Learning Approach for Fault Detection in Vehicular Cyber-Physical Systems",2016,"","","","",176,"2022-07-13 09:24:54","","10.1109/ICMLA.2016.0112","","",,,,,34,5.67,9,4,6,"A network of vehicular cyber-physical systems (VCPSs) can use wireless communications to interact with each other and the surrounding environment to improve transportation safety, mobility, and sustainability. However, cloud-oriented architectures are vulnerable to cyber attacks, which may endanger passenger and pedestrian safety and privacy, and cause severe property damage. For instance, a hacker can use message falsification attack to affect functionality of a particular application in a platoon of VCPSs. In this paper, a neural network-based fault detection technique is applied to detect and track fault data injection attacks on the cooperative adaptive cruise control layer of a platoon of connected vehicles in real time. A decision support system was developed to reduce the probability and severity of any consequent accident. A case study with its design specifications is demonstrated in detail. The simulation results show that the proposed method can improve system reliability, robustness, and safety.","",""
3,"H. Clausen, R. Flood, D. Aspinall","Traffic Generation using Containerization for Machine Learning",2019,"","","","",177,"2022-07-13 09:24:54","","10.1145/3464458.3464460","","",,,,,3,1.00,1,3,3,"The design and evaluation of data-driven network intrusion detection methods are currently held back by a lack of adequate data, both in terms of benign and attack traffic. Existing datasets are mostly gathered in isolated lab environments containing virtual machines, to both offer more control over the computer interactions and prevent any malicious code from escaping. This procedure however leads to datasets that lack four core properties: heterogeneity, ground truth traffic labels, large data size, and contemporary content. Here, we present a novel data generation framework based on Docker containers that addresses these problems systematically. For this, we arrange suitable containers into relevant traffic communication scenarios and subscenarios, which are subject to appropriate input randomization as well as WAN emulation. By relying on process isolation through containerization, we can match traffic events with individual processes, and achieve scalability and modularity of individual traffic scenarios. We perform two experiments to assess the reproducability and traffic properties of our framework, and demonstrate the usefulness of our framework on a traffic classification example.","",""
141,"F. Thabtah","Machine learning in autistic spectrum disorder behavioral research: A review and ways forward",2019,"","","","",178,"2022-07-13 09:24:54","","10.1080/17538157.2017.1399132","","",,,,,141,47.00,141,1,3,"ABSTRACT Autistic Spectrum Disorder (ASD) is a mental disorder that retards acquisition of linguistic, communication, cognitive, and social skills and abilities. Despite being diagnosed with ASD, some individuals exhibit outstanding scholastic, non-academic, and artistic capabilities, in such cases posing a challenging task for scientists to provide answers. In the last few years, ASD has been investigated by social and computational intelligence scientists utilizing advanced technologies such as machine learning to improve diagnostic timing, precision, and quality. Machine learning is a multidisciplinary research topic that employs intelligent techniques to discover useful concealed patterns, which are utilized in prediction to improve decision making. Machine learning techniques such as support vector machines, decision trees, logistic regressions, and others, have been applied to datasets related to autism in order to construct predictive models. These models claim to enhance the ability of clinicians to provide robust diagnoses and prognoses of ASD. However, studies concerning the use of machine learning in ASD diagnosis and treatment suffer from conceptual, implementation, and data issues such as the way diagnostic codes are used, the type of feature selection employed, the evaluation measures chosen, and class imbalances in data among others. A more serious claim in recent studies is the development of a new method for ASD diagnoses based on machine learning. This article critically analyses these recent investigative studies on autism, not only articulating the aforementioned issues in these studies but also recommending paths forward that enhance machine learning use in ASD with respect to conceptualization, implementation, and data. Future studies concerning machine learning in autism research are greatly benefitted by such proposals.","",""
85,"Neoklis Polyzotis, Sudip Roy, S. E. Whang, Martin A. Zinkevich","Data Lifecycle Challenges in Production Machine Learning",2018,"","","","",179,"2022-07-13 09:24:54","","10.1145/3299887.3299891","","",,,,,85,21.25,21,4,4,"Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.","",""
72,"M. Heidari, Abolfazl Zargari Khuzani, A. Hollingsworth, Gopichandh Danala, Seyedehnafiseh Mirniaharikandehei, Y. Qiu, Hong Liu, B. Zheng","Prediction of breast cancer risk using a machine learning approach embedded with a locality preserving projection algorithm.",2018,"","","","",180,"2022-07-13 09:24:54","","10.1088/1361-6560/aaa1ca","","",,,,,72,18.00,9,8,4,"In order to automatically identify a set of effective mammographic image features and build an optimal breast cancer risk stratification model, this study aims to investigate advantages of applying a machine learning approach embedded with a locally preserving projection (LPP) based feature combination and regeneration algorithm to predict short-term breast cancer risk. A dataset involving negative mammograms acquired from 500 women was assembled. This dataset was divided into two age-matched classes of 250 high risk cases in which cancer was detected in the next subsequent mammography screening and 250 low risk cases, which remained negative. First, a computer-aided image processing scheme was applied to segment fibro-glandular tissue depicted on mammograms and initially compute 44 features related to the bilateral asymmetry of mammographic tissue density distribution between left and right breasts. Next, a multi-feature fusion based machine learning classifier was built to predict the risk of cancer detection in the next mammography screening. A leave-one-case-out (LOCO) cross-validation method was applied to train and test the machine learning classifier embedded with a LLP algorithm, which generated a new operational vector with 4 features using a maximal variance approach in each LOCO process. Results showed a 9.7% increase in risk prediction accuracy when using this LPP-embedded machine learning approach. An increased trend of adjusted odds ratios was also detected in which odds ratios increased from 1.0 to 11.2. This study demonstrated that applying the LPP algorithm effectively reduced feature dimensionality, and yielded higher and potentially more robust performance in predicting short-term breast cancer risk.","",""
0,"Yuya Jeremy Ong, Tomoki Takasawa","Efficiency Characterization of the Kepler Exoplanet Discovery Pipeline Using Machine Learning",2019,"","","","",181,"2022-07-13 09:24:54","","","","",,,,,0,0.00,0,2,3,"The Kepler mission, launched by NASA has been used to discover the possibilities for the existence of exoplanets beyond our solar system, providing massive amounts of data that we can use to speculate such candidates. However, to collect the massive amounts of data to identify new and potentially interesting planet candidates, researchers have developed several different methods, heuristics, and data pipelines to facilitate the discovery of new exoplanets. In this work, we characterize the efficiency of the Kepler missionâĂŹs Transiting Planet Search (TPS) system known as Robovetter, using the Robovetter’s simulated light-curve pipeline data and provide insights towards building robust automated pipelines for detecting potentially new and interesting stellar objects and identify potential potential false positives within the samples. Furthermore, to facilitate the research and discovery process of this work, we also develop and propose a data-driven research pipeline specifically for our modeling purposes to provide an efficient workflow for researchers to easily design reproducible machine learning-based experimental workflows that both enables automation and flexibility in modeling approaches.","",""
0,"Hsiao-Chi Li, Chang-Yu Cheng, Chia Chou, Chien-Chang Hsu, Meng-Lin Chang, Y. Chiu, J. Chai","Multi-Class Brain Age Discrimination Using Machine Learning Algorithm",2019,"","","","",182,"2022-07-13 09:24:54","","10.1109/ICMLC48188.2019.8949317","","",,,,,0,0.00,0,7,3,"Resting-state functional connectivity analyses have revealed a significant effect on the inter-regional interactions in brain. The brain age prediction based on resting-state functional magnetic resonance imaging has been proved as biomarkers to characterize the typical brain development and neuropsychiatric disorders. The brain age prediction model based on functional connectivity measurements derived from resting-state functional magnetic resonance imaging has received a lots of interest in recent years due to its great success in age prediction. However, some of the recent studies rely on experienced neuroscientist experts to select appropriate connectivity features in order to build a robust model for prediction while the others just selected the features based on trial-and-error test. Besides, the subjects used in this studies omitted some subjects that can be divided into two groups with less similarity which may confused the prediction model. In this study, we proposed a multi-class age categories discrimination method with the connectivity features selected via K-means clustering with no prior knowledge provided. The experimental results show that with K-means selected features the proposed model better discriminate multi-class age categories.","",""
57,"Lal Hussain","Detecting epileptic seizure with different feature extracting strategies using robust machine learning classification techniques by applying advance parameter optimization approach",2018,"","","","",183,"2022-07-13 09:24:54","","10.1007/s11571-018-9477-1","","",,,,,57,14.25,57,1,4,"","",""
9,"Yiwen Guo, Long Chen, Yurong Chen, Changshui Zhang","On Connections Between Regularizations for Improving DNN Robustness",2020,"","","","",184,"2022-07-13 09:24:54","","10.1109/tpami.2020.3006917","","",,,,,9,4.50,2,4,2,"This paper analyzes regularization terms proposed recently for improving the adversarial robustness of deep neural networks (DNNs), from a theoretical point of view. Specifically, we study possible connections between several effective methods, including input-gradient regularization, Jacobian regularization, curvature regularization, and a cross-Lipschitz functional. We investigate them on DNNs with general rectified linear activations, which constitute one of the most prevalent families of models for image classification and a host of other machine learning applications. We shed light on essential ingredients of these regularizations and re-interpret their functionality. Through the lens of our study, more principled and efficient regularizations can possibly be invented in the near future.","",""
0,"Sannasi Chakravarthy S R, H. Rajaguru","Deep Features with Improved Extreme Learning Machine for Breast Cancer Classification",2021,"","","","",185,"2022-07-13 09:24:54","","10.1109/ISCMI53840.2021.9654814","","",,,,,0,0.00,0,2,1,"Breast cancer classification problem is receiving more attention among researchers due to its global impact on women's healthcare. There is always a demand for research analysis in the earlier diagnosis of breast cancer. The paper proposes a new computer-aided diagnosis (CAD) framework which integrates deep learning and Extreme Learning Machine (ELM) for feature extrication and classification of breast cancer. The proposed CAD tool is very much helpful for radiologists in the earlier diagnosis of breast cancer using digital mammograms. Herein, the research uses the Sine-Cosine Crow-Search Optimization Algorithm (SC-CSOA) for improving the ELM’s classification performance. And to extricate the robust features from the input mammograms, the concept of transfer learning is applied. For that, the work adopts the three most efficient Residual Network (ResNet) families of CNN, namely ResNet18, ResNet50, and ResNet101 architectures. The input database used for evaluation is the INbreast dataset which comprises Full-Field Digital Mammogram (FFDM) images. At this point, the research compares the results obtained with the existing ELM and K-NN algorithms where it is found that the performance of the proposed framework provides the supreme classification (95.811% of accuracy) over others.","",""
294,"Jaideep Pathak, Zhixin Lu, B. Hunt, M. Girvan, E. Ott","Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data.",2017,"","","","",186,"2022-07-13 09:24:54","","10.1063/1.5010300","","",,,,,294,58.80,59,5,5,"We use recent advances in the machine learning area known as ""reservoir computing"" to formulate a method for model-free estimation from data of the Lyapunov exponents of a chaotic process. The technique uses a limited time series of measurements as input to a high-dimensional dynamical system called a ""reservoir."" After the reservoir's response to the data is recorded, linear regression is used to learn a large set of parameters, called the ""output weights."" The learned output weights are then used to form a modified autonomous reservoir designed to be capable of producing an arbitrarily long time series whose ergodic properties approximate those of the input signal. When successful, we say that the autonomous reservoir reproduces the attractor's ""climate."" Since the reservoir equations and output weights are known, we can compute the derivatives needed to determine the Lyapunov exponents of the autonomous reservoir, which we then use as estimates of the Lyapunov exponents for the original input generating system. We illustrate the effectiveness of our technique with two examples, the Lorenz system and the Kuramoto-Sivashinsky (KS) equation. In the case of the KS equation, we note that the high dimensional nature of the system and the large number of Lyapunov exponents yield a challenging test of our method, which we find the method successfully passes.","",""
34,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, Semeen Rehman, M. Shafique","Robust Machine Learning Systems: Reliability and Security for Deep Neural Networks",2018,"","","","",187,"2022-07-13 09:24:54","","10.1109/IOLTS.2018.8474192","","",,,,,34,8.50,7,5,4,"Machine learning is commonly being used in almost all the areas that involve advanced data analytics and intelligent control. From applications like Natural Language Processing (NLP) to autonomous driving are based upon machine learning algorithms. An increasing trend is observed in the use of Deep Neural Networks (DNNs) for such applications. While the slight inaccuracy in applications like NLP does not have any severe consequences, it is not the same for other safety-critical applications, like autonomous driving and smart healthcare, where a small error can lead to catastrophic effects. Apart from high-accuracy DNN algorithms, there is a significant need for robust machine learning systems and hardware architectures that can generate reliable and trustworthy results in the presence of hardware-level faults while also preserving security and privacy. This paper provides an overview of the challenges being faced in ensuring reliable and secure execution of DNNs. To address the challenges, we present several techniques for analyzing and mitigating the reliability and security threats in machine learning systems.","",""
33,"Ved P. Kafle, Y. Fukushima, P. Martinez-Julia, T. Miyazawa","Consideration On Automation of 5G Network Slicing with Machine Learning",2018,"","","","",188,"2022-07-13 09:24:54","","10.23919/ITU-WT.2018.8597639","","",,,,,33,8.25,8,4,4,"Machine learning has the capability to provide simpler solutions to complex problems by analyzing a huge volume of data in a short time, learning for adapting its functionality to dynamically changing environments, and predicting near future events with reasonably good accuracy. The 5G communication networks are getting complex due to emergence of unprecedentedly huge number of new connected devices and new types of services. Moreover, the requirements of creating virtual network slices suitable to provide optimal services for diverse users and applications are posing challenges to the efficient management of network resources, processing information about a huge volume of traffic, staying robust against all potential security threats, and adaptively adjustment of network functionality for time-varying workload. In this paper, we introduce about the envisioned 5G network slicing and elaborate the necessity of automation of network functions for the design, construction, deployment, operation, control and management of network slices. We then revisit the machine learning techniques that can be applied for the automation of network functions. We also discuss the status of artificial intelligence and machine learning related activities being progressed in standards development organizations and industrial forums.","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",189,"2022-07-13 09:24:54","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
2,"Leslie Rice, Anna Bair, Huan Zhang, J. Z. Kolter","Robustness between the worst and average case",2021,"","","","",190,"2022-07-13 09:24:54","","","","",,,,,2,2.00,1,4,1,"Several recent works in machine learning have focused on evaluating the test-time robustness of a classifier: how well the classifier performs not just on the target domain it was trained upon, but upon perturbed examples. In these settings, the focus has largely been on two extremes of robustness: the robustness to perturbations drawn at random from within some distribution (i.e., robustness to random perturbations), and the robustness to the worst case perturbation in some set (i.e., adversarial robustness). In this paper, we argue that a sliding scale between these two extremes provides a valuable additional metric by which to gauge robustness. Specifically, we illustrate that each of these two extremes is naturally characterized by a (functional) q-norm over perturbation space, with q = 1 corresponding to robustness to random perturbations and q = 1 corresponding to adversarial perturbations. We then present the main technical contribution of our paper: a method for efficiently estimating the value of these norms by interpreting them as the partition function of a particular distribution, then using path sampling with MCMC methods to estimate this partition function (either traditional Metropolis-Hastings for non-differentiable perturbations, or Hamiltonian Monte Carlo for differentiable perturbations). We show that our approach provides substantially better estimates than simple random sampling of the actual “intermediate-q” robustness of standard, data-augmented, and adversarially-trained classifiers, illustrating a clear tradeoff between classifiers that optimize different metrics. Code for reproducing experiments can be found at https://github.com/locuslab/intermediate_robustness.","",""
2,"Sebastian Ziegelmayer, S. Reischl, Felix N Harder, M. Makowski, R. Braren, J. Gawlitza","Feature Robustness and Diagnostic Capabilities of Convolutional Neural Networks Against Radiomics Features in Computed Tomography Imaging.",2021,"","","","",191,"2022-07-13 09:24:54","","10.1097/RLI.0000000000000827","","",,,,,2,2.00,0,6,1,"Radiomics and deep learning algorithms such as convolutional neural networks (CNNs) are increasingly used for radiological image classification and outcome prediction. One of the main challenges is to create robustness against technical alterations. Both methods initially extract specific imaging features, which are then used as input for machine learning algorithms or in an end-to-end fashion for outcome prediction. For radiomics features, it has previously been shown that differences in image acquisition parameters can cause variability in feature values, making them irreproducible. However, it remains unclear how these technical variations influence feature values extracted by a CNN. Therefore, the aim of this study was to compare the robustness of CNN features versus radiomics features to technical variations in image acquisition parameters. An additional retrospective analysis was performed to show the in vivo capabilities of these features compared with classical radiomics features in a tumor differentiation task.   MATERIALS AND METHODS Imaging phantoms were scanned twice on 3 computed tomography scanners from 2 different manufactures with varying tube voltages and currents. Phantoms were segmented, and features were extracted using PyRadiomics and a pretrained CNN. After standardization the concordance correlation coefficient (CCC), mean feature variance, feature range, and the coefficient of variant were calculated to assess feature robustness. In addition, the cosine similarity was calculated for the vectorized activation maps for an exemplary phantom. For the in vivo comparison, the radiomics and CNN features of 30 patients with hepatocellular carcinoma (HCC) and 30 patients with hepatic colon carcinoma metastasis were compared.   RESULTS In total, 851 radiomics features and 256 CNN features were extracted for each phantom. For all phantoms, the global CCC of the CNN features was above 98%, whereas the highest CCC for the radiomics features was 36%. The mean feature variance and feature range was significantly lower for the CNN features. Using a coefficient of variant ≤0.2 as a threshold to define robust features and averaging across all phantoms 346 of 851 (41%) radiomics features and 196 of 256 (77%) CNN features were found to be robust. The cosine similarity was greater than 0.98 for all scanner and parameter variations. In the retrospective analysis, 122 of the 256 CNN (49%) features showed significant differences between HCC and hepatic colon metastasis.   DISCUSSION Convolutional neural network features were more stable compared with radiomics features against technical variations. Moreover, the possibility of tumor entity differentiation based on CNN features was shown. Combined with visualization methods, CNN features are expected to increase reproducibility of quantitative image representations. Further studies are warranted to investigate the impact of feature stability on radiological image-based prediction of clinical outcomes.","",""
24,"R. McKinley, Fan Hung, R. Wiest, D. Liebeskind, F. Scalzo","A Machine Learning Approach to Perfusion Imaging With Dynamic Susceptibility Contrast MR",2018,"","","","",192,"2022-07-13 09:24:54","","10.3389/fneur.2018.00717","","",,,,,24,6.00,5,5,4,"Background: Dynamic susceptibility contrast (DSC) MR perfusion is a frequently-used technique for neurovascular imaging. The progress of a bolus of contrast agent through the tissue of the brain is imaged via a series of T2*-weighted MRI scans. Clinically relevant parameters such as blood flow and Tmax can be calculated by deconvolving the contrast-time curves with the bolus shape (arterial input function). In acute stroke, for instance, these parameters may help distinguish between the likely salvageable tissue and irreversibly damaged infarct core. Deconvolution typically relies on singular value decomposition (SVD): however, studies have shown that these algorithms are very sensitive to noise and artifacts present in the image and therefore may introduce distortions that influence the estimated output parameters. Methods: In this work, we present a machine learning approach to the estimation of perfusion parameters in DSC-MRI. Various machine learning models using as input the raw MR source data were trained to reproduce the output of an FDA approved commercial implementation of the SVD deconvolution algorithm. Experiments were conducted to determine the effect of training set size, optimal patch size, and the effect of using different machine-learning models for regression. Results: Model performance increased with training set size, but after 5,000 samples (voxels) this effect was minimal. Models inferring perfusion maps from a 5 by 5 voxel patch outperformed models able to use the information in a single voxel, but larger patches led to worse performance. Random Forest models produced had the lowest root mean squared error, with neural networks performing second best: however, a phantom study revealed that the random forest was highly susceptible to noise levels, while the neural network was more robust. Conclusion: The machine learning-based approach produces estimates of the perfusion parameters invariant to the noise and artifacts that commonly occur as part of MR acquisition. As a result, better robustness to noise is obtained, when evaluated against the FDA approved software on acute stroke patients and simulated phantom data.","",""
37,"Bin Wang, Lihong Zheng, D. Liu, F. Ji, A. Clark, Qiang Yu","Using multi‐model ensembles of CMIP5 global climate models to reproduce observed monthly rainfall and temperature with machine learning methods in Australia",2018,"","","","",193,"2022-07-13 09:24:54","","10.1002/joc.5705","","",,,,,37,9.25,6,6,4,"Global climate models (GCMs) are useful tools for assessing climate change impacts on temperature and rainfall. Although climate data from various GCMs have been increasingly used in climate change impact studies, GCMs configurations and module characteristics vary from one to another. Therefore, it is crucial to assess different GCMs to confirm the extent to which they can reproduce the observed temperature and rainfall. Rather than assessing the interdependence of each GCM, the purpose of this study is to compare the capacity of four different multi‐model ensemble (MME) methods (random forest [RF], support vector machine [SVM], Bayesian model averaging [BMA] and the arithmetic ensemble mean [EM]) in reproducing observed monthly rainfall and temperature. Of these four methods, the RF and SVM demonstrated a significant improvement over EM and BMA in terms of performance criteria. The relative importance of each GCM based on the RF ensemble in reproducing rainfall and temperature could also be ranked. We compared the GCMs importance and Taylor skill score and found that their correlation was 0.95 for temperature and 0.54 for rainfall. Our results also demonstrated that the number of GCMs ensemble simulations could be reduced from 33 to 25 in RF model while maintaining predictive error less than 2%. Having such a representative subset of simulations could reduce computational costs for climate impact modelling and maintain the quality of ensemble at the same time. We conclude that machine learning MME could be efficient and useful with improved accuracy in reproducing historical climate variables.","",""
241,"B. Goldstein, A. Navar, R. Carter","Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges",2016,"","","","",194,"2022-07-13 09:24:54","","10.1093/eurheartj/ehw302","","",,,,,241,40.17,80,3,6,"Abstract Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning.","",""
1,"Niklas Risse, C. Gopfert, Jan Philip Göpfert","How to Compare Adversarial Robustness of Classifiers from a Global Perspective",2020,"","","","",195,"2022-07-13 09:24:54","","10.1007/978-3-030-86362-3_3","","",,,,,1,0.50,0,3,2,"","",""
101,"G. Lecu'e, M. Lerasle","Robust machine learning by median-of-means: Theory and practice",2017,"","","","",196,"2022-07-13 09:24:54","","10.1214/19-AOS1828","","",,,,,101,20.20,51,2,5,"We introduce new estimators for robust machine learning based on median-of-means (MOM) estimators of the mean of real valued random variables. These estimators achieve optimal rates of convergence under minimal assumptions on the dataset. The dataset may also have been corrupted by outliers on which no assumption is granted. We also analyze these new estimators with standard tools from robust statistics. In particular, we revisit the concept of breakdown point. We modify the original definition by studying the number of outliers that a dataset can contain without deteriorating the estimation properties of a given estimator. This new notion of breakdown number, that takes into account the statistical performances of the estimators, is non-asymptotic in nature and adapted for machine learning purposes. We proved that the breakdown number of our estimator is of the order of (number of observations)*(rate of convergence). For instance, the breakdown number of our estimators for the problem of estimation of a d-dimensional vector with a noise variance sigma^2 is sigma^2d and it becomes sigma^2 s log(d/s) when this vector has only s non-zero component. Beyond this breakdown point, we proved that the rate of convergence achieved by our estimator is (number of outliers) divided by (number of observation).  Besides these theoretical guarantees, the major improvement brought by these new estimators is that they are easily computable in practice. In fact, basically any algorithm used to approximate the standard Empirical Risk Minimizer (or its regularized versions) has a robust version approximating our estimators. As a proof of concept, we study many algorithms for the classical LASSO estimator. A byproduct of the MOM algorithms is a measure of depth of data that can be used to detect outliers.","",""
15,"S. Leighton, R. Krishnadas, K. Chung, A. Blair, Susie Brown, S. Clark, K. Sowerbutts, M. Schwannauer, J. Cavanagh, A. Gumley","Predicting one-year outcome in first episode psychosis using machine learning",2018,"","","","",197,"2022-07-13 09:24:54","","10.1101/390096","","",,,,,15,3.75,2,10,4,"Lay Summary Evidence before this study Our knowledge of factors which predict outcome in first episode psychosis (FEP) is incomplete. Poor premorbid adjustment, history of developmental disorder, symptom severity at baseline and duration of untreated psychosis are the most replicated predictors of poor clinical, functional, cognitive, and biological outcomes. Yet, such group level differences are not always replicated in individuals, nor can observational results be clearly equated with causation. Advanced machine learning techniques have potential to revolutionise medicine by looking at causation and the prediction of individual patient outcome. Within psychiatry, Koutsouleris et al employed machine learning to predict 4- and 52-week functional outcome in FEP to a 75% and 73.8% test-fold balanced accuracy on repeated nested internal cross-validation. The authors suggest that before employing a machine learning model “into real-world care, replication is needed in external first episode samples”. Added value of this study We believe our study to be the first externally validated evidence, in a temporally and geographically independent cohort, for predictive modelling in FEP at an individual patient level. Our results demonstrate the ability to predict both symptom remission and functioning (in employment, education or training (EET)) at one-year. The performance of our EET model was particularly robust, with an ability to accurately predict the one-year EET outcome in more than 85% of patients. Regularised regression results in sparse models which are uniquely interpretable and identify meaningful predictors of recovery including specific individual PANSS items, and social support. This builds on existing studies of group-level differences and the elegant work of Koutsouleris et al. Implications of all the available evidence We have demonstrated the externally validated ability to accurately predict one-year symptomatic and functional status in individual patients with FEP. External validation in a plausibly related temporally and geographically distinct population assesses model transportability to an untested situation rather than simply reproducibility alone. We propose that our results represent important and exciting progress in unlocking the potential of predictive modelling in psychiatric illness. The next step prior to implementation into routine clinical practice would be to establish whether, by the accurate identification of individuals who will have poor outcomes, we can meaningful intervene to improve their prognosis. Abstract Background Early illness course correlates with long-term outcome in psychosis. Accurate prediction could allow more focused intervention. Earlier intervention corresponds to significantly better symptomatic and functional outcomes. We use routinely collected baseline demographic and clinical characteristics to predict employment, education or training (EET) status, and symptom remission in patients with first episode psychosis (FEP) at 1 year. Methods 83 FEP patients were recruited from National Health Service (NHS) Glasgow between 2011 and 2014 to a 24-month prospective cohort study with regular assessment of demographic and psychometric measures. An external independent cohort of 79 FEP patients were recruited from NHS Glasgow and Edinburgh during a 12-month study between 2006 and 2009. Elastic net regularised logistic regression models were built to predict binary EET status, period and point remission outcomes at 1 year on 83 Glasgow patients (training dataset). Models were externally validated on an independent dataset of 79 patients from Glasgow and Edinburgh (validation dataset). Only baseline predictors shared across both cohorts were made available for model training and validation. Outcomes After excluding participants with missing outcomes, models were built on the training dataset for EET status, period and point remission outcomes and externally validated on the validation dataset. Models predicted EET status, period and point remission with ROC area under curve (AUC) performances of 0.876 (95%CI: 0.864, 0.887), 0.630 (95%CI: 0.612, 0.647) and 0.652 (95%CI: 0.635, 0.670) respectively. Positive predictors of EET included baseline EET and living with spouse/children. Negative predictors included higher PANSS suspiciousness, hostility and delusions scores. Positive predictors for symptom remission included living with spouse/children, and affective symptoms on the Positive and Negative Syndrome Scale (PANSS). Negative predictors of remission included passive social withdrawal symptoms on PANSS. Interpretation Using advanced statistical machine learning techniques, we provide the first externally validated evidence for the ability to predict 1-year EET status and symptom remission in FEP patients. Funding The authors acknowledge financial support from NHS Research Scotland, the Chief Scientist Office, the Wellcome Trust, and the Scottish Mental Health Research Network.","",""
130,"A. Subasi, Jasmin Kevric, Muhammed Abdullah Canbaz","Epileptic seizure detection using hybrid machine learning methods",2017,"","","","",198,"2022-07-13 09:24:54","","10.1007/s00521-017-3003-y","","",,,,,130,26.00,43,3,5,"","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",199,"2022-07-13 09:24:54","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
0,"P. Rasouli, Ingrid Chieh Yu","Analyzing and Improving the Robustness of Tabular Classifiers using Counterfactual Explanations",2021,"","","","",200,"2022-07-13 09:24:54","","10.1109/ICMLA52953.2021.00209","","",,,,,0,0.00,0,2,1,"Recent studies have revealed that Machine Learning (ML) models are vulnerable to adversarial perturbations. Such perturbations can be intentionally or accidentally added to the original inputs, evading the classifier’s behavior to misclassify the crafted samples. A widely-used solution is to retrain the model using data points generated by various attack strategies. However, this creates a classifier robust to some particular evasions and can not defend unknown or universal perturbations. Counterfactual explanations are a specific class of post-hoc explanation methods that provide minimal modification to the input features in order to obtain a particular outcome from the model. In addition to the resemblance of counterfactual explanations to the universal perturbations, the possibility of generating instances from specific classes makes such approaches suitable for analyzing and improving the model’s robustness. Rather than explaining the model’s decisions in the deployment phase, we utilize the distance information obtained from counterfactuals and propose novel metrics to analyze the robustness of tabular classifiers. Further, we introduce a decision boundary modification approach using customized counterfactual data points to improve the robustness of the models without compromising their accuracy. Our framework addresses the robustness of black-box classifiers in the tabular setting, which is considered an under-explored research area. Through several experiments and evaluations, we demonstrate the efficacy of our approach in analyzing and improving the robustness of black-box tabular classifiers.","",""
