Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
7,"Jonathan Fürst, Mauricio Fadel Argerich, Bin Cheng, E. Kovacs","Towards Knowledge Infusion for Robust and Transferable Machine Learning in IoT",2020,"","","","",1,"2022-07-13 09:39:36","","","","",,,,,7,3.50,2,4,2,"Machine learning (ML) applications in Internet of Things (IoT) scenarios face the issue that supervision signals, such as labeled data, are scarce and expensive to obtain. For example, it often requires a human to manually label events in a data stream by observing the same events in the real world. In addition, the performance of trained models usually depends on a specific context: (1) location, (2) time and (3) data quality. This context is not static in reality, making it hard to achieve robust and transferable machine learning for IoT systems in practice. In this paper, we address these challenges with an envisioned method that we name Knowledge Infusion. First, we present two past case studies in which we combined external knowledge with traditional data-driven machine learning in IoT scenarios to ease the supervision effort: (1) a weak-supervision approach for the IoT domain to auto-generate labels based on external knowledge (e.g., domain knowledge) encoded in simple labeling functions. Our evaluation for transport mode classification achieves a micro-F1 score of 80.2%, with only seven labeling functions, on par with a fully supervised model that relies on hand-labeled data. (2) We introduce guiding functions to Reinforcement Learning (RL) to guide the agents' decisions and experience. In initial experiments, our guided reinforcement learning achieves more than three times higher reward in the beginning of its training than an agent with no external knowledge. We use the lessons learned from these experiences to develop our vision of knowledge infusion. In knowledge infusion, we aim to automate the inclusion of knowledge from existing knowledge bases and domain experts to combine it with traditional data-driven machine learning techniques during setup/training phase, but also during the execution phase.","",""
5,"Haohan Wang, Zeyi Huang, Hanlin Zhang, Eric P. Xing","Toward Learning Human-aligned Cross-domain Robust Models by Countering Misaligned Features",2021,"","","","",2,"2022-07-13 09:39:36","","","","",,,,,5,5.00,1,4,1,"Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective as-suming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available here.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",3,"2022-07-13 09:39:36","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
12,"Atik Mahabub","A robust voting approach for diabetes prediction using traditional machine learning techniques",2019,"","","","",4,"2022-07-13 09:39:36","","10.1007/s42452-019-1759-7","","",,,,,12,4.00,12,1,3,"","",""
0,"Majwega Jackson, Ggaliwango Marvin, A. Chakrabarty","Robust Ensemble Machine Learning for Precision Agriculture",2022,"","","","",5,"2022-07-13 09:39:36","","10.1109/iciset54810.2022.9775879","","",,,,,0,0.00,0,3,1,"In agriculture, various decisions largely depend on farmers’ previous experiences, however, using simple numerical values to enumerate these decisions is hard. To attain sustainable agriculture development, new technologies in farming are slowly replacing human labor in decision making. The new innovations in agriculture have been employed to increase crop planting scale and ensure quality. One of the biggest challenges faced by farmers who are operating on a small scale is soil exhaustion caused by poor farming practices for example mono-cropping which leads to loss of plant nutrients. And due to a lack of knowledge of existing soil nutrients and crop requirements, it’s hard for farmers to plant appropriately leading to low crop productivity and hence low production and huge losses. To address this challenge, precision agriculture, a modern farming technique has been proposed by many researchers to encompass research data of soil nutrients, soil types, etc., and recommend the most appropriate crop for planting. But since it’s too hard to build a single model that works best, it has been hard to attain precision agriculture goals with the previously proposed machine learning models. Therefore, in this paper, we propose a robust ensemble machine learning model which combines data from numerous modeling approaches to produce more robust models and more accurate predictions which Technology might work better especially in developing countries. And the results of the optimized crop recommendation indicate that the LightGBM classifier is the best with 99.39%, 100%, and 99.9% accuracy, Precision, and recall, making it the most reliable","",""
37,"Efstathios D. Gennatas, J. Friedman, L. Ungar, R. Pirracchio, Eric Eaton, L. Reichman, Y. Interian, C. Simone, A. Auerbach, E. Delgado, M. J. Laan, T. Solberg, G. Valdes","Expert-augmented machine learning",2019,"","","","",6,"2022-07-13 09:39:36","","10.1073/pnas.1906831117","","",,,,,37,12.33,4,13,3,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.","",""
4,"Alexandra Renouard, A. Maggi, M. Grunberg, C. Doubre, C. Hibert","Toward False Event Detection and Quarry Blast versus Earthquake Discrimination in an Operational Setting Using Semiautomated Machine Learning",2021,"","","","",7,"2022-07-13 09:39:36","","10.1785/0220200305","","",,,,,4,4.00,1,5,1,"  Small-magnitude earthquakes shed light on the spatial and magnitude distribution of natural seismicity, as well as its rate and occurrence, especially in stable continental regions where natural seismicity remains difficult to explain under slow strain-rate conditions. However, capturing them in catalogs is strongly hindered by signal-to-noise ratio issues, resulting in high rates of false and man-made events also being detected. Accurate and robust discrimination of these events is critical for optimally detecting small earthquakes. This requires uncovering recurrent salient features that can rapidly distinguish first false events from real events, then earthquakes from man-made events (mainly quarry blasts), despite high signal variability and noise content. In this study, we combined the complementary strengths of human and interpretable rule-based machine-learning algorithms for solving this classification problem. We used human expert knowledge to co-create two reliable machine-learning classifiers through human-assisted selection of classification features and review of events with uncertain classifier predictions. The two classifiers are integrated into the SeisComP3 operational monitoring system. The first one discards false events from the set of events obtained with a low short-term average/long-term average threshold; the second one labels the remaining events as either earthquakes or quarry blasts. When run in an operational setting, the first classifier correctly detected more than 99% of false events and just over 93% of earthquakes; the second classifier correctly labeled 95% of quarry blasts and 96% of earthquakes. After a manual review of the second classifier low-confidence outputs, the final catalog contained fewer than 2% of misclassified events. These results confirm that machine learning strengthens the quality of earthquake catalogs and that the performance of machine-learning classifiers can be improved through human expertise. Our study promotes a broader implication of hybrid intelligence monitoring within seismological observatories.","",""
1,"K. Belesova, M. Callaghan, J. Minx, F. Creutzig, C. Turcu, E. Hutchinson, J. Milner, M. Crane, A. Haines, M. Davies, P. Wilkinson","Climate action for health and wellbeing in cities: a protocol for the systematic development of a database of peer-reviewed studies using machine learning methods",2021,"","","","",8,"2022-07-13 09:39:36","","10.12688/wellcomeopenres.16570.1","","",,,,,1,1.00,0,11,1,"Cities produce more than 70% of global greenhouse gas emissions. Action by cities is therefore crucial for climate change mitigation as well as for safeguarding the health and wellbeing of their populations under climate change. Many city governments have made ambitious commitments to climate change mitigation and adaptation and implemented a range of actions to address them. However, a systematic record and synthesis of the findings of evaluations of the effect of such actions on human health and wellbeing is currently lacking. This, in turn, impedes the development of robust knowledge on what constitutes high-impact climate actions of benefit to human health and wellbeing, which can inform future action plans, their implementation and scale-up. The development of a systematic record of studies reporting climate and health actions in cities is made challenging by the broad landscape of relevant literature scattered across many disciplines and sectors, which is challenging to effectively consolidate using traditional literature review methods. This protocol reports an innovative approach for the systematic development of a database of studies of climate change mitigation and adaptation actions implemented in cities, and their benefits (or disbenefits) for human health and wellbeing, derived from peer-reviewed academic literature. Our approach draws on extensive tailored search strategies and machine learning methods for article classification and tagging to generate a database for subsequent systematic reviews addressing questions of importance to urban decision-makers on climate actions in cities for human health and wellbeing.","",""
1,"Seungwoong Ha, Hawoong Jeong","Discovering conservation laws from trajectories via machine learning",2021,"","","","",9,"2022-07-13 09:39:36","","","","",,,,,1,1.00,1,2,1,"Invariants and conservation laws convey critical information about the underlying dynamics of a system, yet it is generally infeasible to find them from large-scale data without any prior knowledge or human insight. We propose ConservNet to achieve this goal, a neural network that spontaneously discovers a conserved quantity from grouped data where the members of each group share invariants, similar to a general experimental setting where trajectories from different trials are observed. As a neural network trained with a novel and intuitive loss function called noise-variance loss, ConservNet learns the hidden invariants in each group of multi-dimensional observables in a data-driven, endto-end manner. Our model successfully discovers underlying invariants from the simulated systems having invariants as well as a real-world double pendulum trajectory. Since the model is robust to various noises and data conditions compared to baseline, our approach is directly applicable to experimental data for discovering hidden conservation laws and further, general relationships between variables.","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",10,"2022-07-13 09:39:36","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
7,"Jina Suh, S. Ghorashi, Gonzalo A. Ramos, N. Chen, S. Drucker, J. Verwey, P. Simard","AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning",2019,"","","","",11,"2022-07-13 09:39:36","","10.1145/3241379","","",,,,,7,2.33,1,7,3,"When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.","",""
2,"A. Smart, Larry James, B. Hutchinson, Simone Wu, Shannon Vallor","Why Reliabilism Is not Enough: Epistemic and Moral Justification in Machine Learning",2020,"","","","",12,"2022-07-13 09:39:36","","10.1145/3375627.3375866","","",,,,,2,1.00,0,5,2,"In this paper we argue that standard calls for explainability that focus on the epistemic inscrutability of black-box machine learning models may be misplaced. If we presume, for the sake of this paper, that machine learning can be a source of knowledge, then it makes sense to wonder what kind of \em justification it involves. How do we rationalize on the one hand the seeming justificatory black box with the observed wide adoption of machine learning? We argue that, in general, people implicitly adoptreliabilism regarding machine learning. Reliabilism is an epistemological theory of epistemic justification according to which a belief is warranted if it has been produced by a reliable process or method \citegoldman2012reliabilism. We argue that, in cases where model deployments require \em moral justification, reliabilism is not sufficient, and instead justifying deployment requires establishing robust human processes as a moral ""wrapper'' around machine outputs. We then suggest that, in certain high-stakes domains with moral consequences, reliabilism does not provide another kind of necessary justification---moral justification. Finally, we offer cautions relevant to the (implicit or explicit) adoption of the reliabilist interpretation of machine learning.","",""
0,"J. Z. Pan, Nicholas Zufelt","On Intrinsic Dataset Properties for Adversarial Machine Learning",2020,"","","","",13,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,2,2,"Deep neural networks (DNNs) have played a key role in a wide range of machine learning applications. However, DNN classifiers are vulnerable to human-imperceptible adversarial perturbations, which can cause them to misclassify inputs with high confidence. Thus, creating robust DNNs which can defend against malicious examples is critical in applications where security plays a major role. In this paper, we study the effect of intrinsic dataset properties on the performance of adversarial attack and defense methods, testing on five popular image classification datasets - MNIST, Fashion-MNIST, CIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play key roles in attack and defense success. Our discoveries highlight that dataset design and data preprocessing steps are important to boost the adversarial robustness of DNNs. To our best knowledge, this is the first comprehensive work that studies the effect of intrinsic dataset properties on adversarial machine learning.","",""
0,"M. Hecht, Jaron Chen, Phanitta Chomsinsap","CLAIM: An Enhanced Machine Learning Technique for Discrepancy Report Analysis",2020,"","","","",14,"2022-07-13 09:39:36","","10.1109/RAMS48030.2020.9153691","","",,,,,0,0.00,0,3,2,"CLAIM is a tool for analyzing and classifying discrepancy reports that allows for the incorporation of domain expert knowledge into a semi-supervised machine learning (ML) process (a semi-supervised learning uses a small number of manually labeled data and a much larger amount of unlabeled for training a machine learning algorithm). By using this domain knowledge, classification accuracy is higher than conventional ML approaches. The advantages are particularly apparent with small, imbalanced data sets that are quite common in discrepancy report data sets (an imbalanced data set has an unequal distribution of documents categories within each category). The CLAIM method is robust against human bias and can tolerate misclassifications of up to 20% of the training set. The increased accuracy of the CLAIM methodology makes ML a viable tool for safety, reliability, and software development process decision making. The modest human labor requirement enables use of the method under circumstances that previously made free text discrepancy report analysis infeasible due to resource, scheduling, and cost constraints.","",""
0,"Likita J. Raikar, Sayali V. Pardeshi, Pritam Sawale","Airplane Crash Analysis and Prediction using Machine Learning",2020,"","","","",15,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,3,2,"1,2,3 Department of Information Technology, Vidyalankar Institute of Technology, Mumbai, Maharashtra, India ---------------------------------------------------------------------***--------------------------------------------------------------------Abstract Airplanes are the most frequent mode of transportation in the present world. A single airplane crash leads to tremendous loss of human life. Safety is of prime importance since a huge number of people travel across the borders and within them. Abstracting data from a large database is always a difficult task. Data mining is a robust technology in order to extract the knowledge from raw data. Aviation systems take care of the minute precautions in order to prevent aircraft crashes. Factors causing and contributing to crashes needs to be understood studied and prevented in order to further minimize any kind of mishap. It is immensely difficult to find and extract the patterns of the factors due to very less amount of accident rates. In this research work, crash analysis and prediction is done. We have conducted the analysis of airplane crash data while, co-relating it with accidental information. To carry out this we have employed machine learning techniques. Machine learning helps in extracting the relationships between the various factors either affecting or non-affecting the crash to the general information of the airplane and as a result, patterns are formed. Many researchers, in recent times, have been using several machine learning techniques to help the aviation industry and the professionals in determining the hurdles. Supervised machine learning algorithms like SVM, K-NN, ADABoost and XGBoost are used for the purpose of prediction. The work has helped in improving the accuracy to a great extent.","",""
0,"Bukhoree Sahoh, Kanjana Haruehansapong, Mallika Kliangkhlao","Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model",2022,"","","","",16,"2022-07-13 09:39:36","","10.1109/access.2022.3155118","","",,,,,0,0.00,0,3,1,"A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",17,"2022-07-13 09:39:36","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
1,"Adyasha Rath, Debahuti Mishra, G. Panda, S. Satapathy","An exhaustive review of machine and deep learning based diagnosis of heart diseases",2021,"","","","",18,"2022-07-13 09:39:36","","10.1007/s11042-021-11259-3","","",,,,,1,1.00,0,4,1,"","",""
23,"Muxin Gu, M. Buckley","Semi-supervised machine learning for automated species identification by collagen peptide mass fingerprinting",2018,"","","","",19,"2022-07-13 09:39:36","","10.1186/s12859-018-2221-3","","",,,,,23,5.75,12,2,4,"","",""
376,"Rui Zhao, Ruqiang Yan, Jinjiang Wang, K. Mao","Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks",2017,"","","","",20,"2022-07-13 09:39:36","","10.3390/s17020273","","",,,,,376,75.20,94,4,5,"In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","",""
1,"Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, M. Shafique","ISA4ML: Training Data-Unaware Imperceptible Security Attacks on Machine Learning Modules of Autonomous Vehicles",2018,"","","","",21,"2022-07-13 09:39:36","","","","",,,,,1,0.25,0,4,4,"Due to big data analysis ability, machine learning (ML) algorithms are becoming popular for several applications in autonomous vehicles. However, ML algorithms possessinherent security vulnerabilities which increase the demand for robust ML algorithms. Recently, various groups have demonstrated how vulnerabilities in ML can be exploited to perform several security attacks for confidence reduction and random/targeted misclassification, by using the data manipulation techniques. These traditional data manipulation techniques, especially during the training stage, introduce the random visual noise. However, such visual noise can be detected during the attack or testing through noise detection/filtering or human-in-the-loop. In this paper, we propose a novel methodology to automatically generate an ""imperceptible attack"" by exploiting the back-propagation property of trained deep neural networks (DNNs). Unlike state-of-the-art inference attacks, our methodology does not require any knowledge of the training data set during the attack image generation. To illustrate the effectiveness of the proposed methodology, we present a case study for traffic sign detection in an autonomous driving use case. We deploy the state-of-the-art VGGNet DNN trained for German Traffic Sign Recognition Benchmarks (GTSRB) datasets. Our experimental results show that the generated attacks are imperceptible in both subjective tests (i.e., visual perception) and objective tests (i.e., without any noticeable change in the correlation and structural similarity index) but still performs successful misclassification attacks.","",""
0,"A. Ke, Jian Huang, Jing Wang, Jiping He","Improving the Robustness of Human-Machine Interactive Control for Myoelectric Prosthetic Hand During Arm Position Changing",2022,"","","","",22,"2022-07-13 09:39:36","","10.3389/fnbot.2022.853773","","",,,,,0,0.00,0,4,1,"Robust classification of natural hand grasp type based on electromyography (EMG) still has some shortcomings in the practical prosthetic hand control, owing to the influence of dynamic arm position changing during hand actions. This study provided a framework for robust hand grasp type classification during dynamic arm position changes, improving both the “hardware” and “algorithm” components. In the hardware aspect, co-located synchronous EMG and force myography (FMG) signals are adopted as the multi-modal strategy. In the algorithm aspect, a sequential decision algorithm is proposed by combining the RNN-based deep learning model with a knowledge-based post-processing model. Experimental results showed that the classification accuracy of multi-modal EMG-FMG signals was increased by more than 10% compared with the EMG-only signal. Moreover, the classification accuracy of the proposed sequential decision algorithm improved the accuracy by more than 4% compared with other baseline models when using both EMG and FMG signals.","",""
8,"Brandon M. Booth, Tiantian Feng, Abhishek Jangalwa, Shrikanth S. Narayanan","Toward Robust Interpretable Human Movement Pattern Analysis in a Workplace Setting",2019,"","","","",23,"2022-07-13 09:39:36","","10.1109/ICASSP.2019.8683730","","",,,,,8,2.67,2,4,3,"Gaining a better understanding of how people move about and interact with their environment is an important piece of understanding human behavior. Careful analysis of individuals’ deviations or variations in movement over time can provide an awareness about changes to their physical or mental state and may be helpful in tracking performance and well-being especially in workplace settings. We propose a technique for clustering and discovering patterns in human movement data by extracting motifs from the time series of durations where participants linger at different locations. Using a data set of over 200 participants moving around a hospital for ten weeks, we show this technique intuitively captures local temporal relationships between hospital rooms and also clusters them in a fashion consistent with the room type labels (e.g. lounge, break room, etc.) without using prior knowledge. Machine learning features derived from these clusters are empirically shown to provide information similar to features attained using domain knowledge of the room type labels directly when predicting mental wellness from self-reports.","",""
0,"Mamta A. Rajnayak, Snigdha Moitra, Charu Nahata","Traditional vs. Machine Learning Techniques: Customer Propensity",2017,"","","","",24,"2022-07-13 09:39:36","","10.1007/978-3-319-54430-4_63","","",,,,,0,0.00,0,3,5,"","",""
0,"D. Ruta, Ling Cen, E. Damiani","Summarization-Guided Greedy Optimization of Machine Learning Model",2017,"","","","",25,"2022-07-13 09:39:36","","10.1007/978-3-319-62416-7_22","","",,,,,0,0.00,0,3,5,"","",""
0,"N. Katanić, K. Fertalj","Towards Physical Intrusion Detection Method Based on Machine Learning and Context-Aware Activity Recognition in Real-Time",2017,"","","","",26,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,2,5,"Sensor-based human activity recognition is getting increasingly popular in various applications. Most of the related work within dense-sensing based approaches assume that large number of different multimodal sensors are placed on the objects in the environment (which is rarely the case in today’s real life home environments), that sensor data is not processed in real-time and that activity to be classified is always performed within the same context, thus perform poorly when tested in real life scenarios. In this paper we report on the current status and future steps towards a generic context-aware method for human activity recognition, based on a real-time raw sensor data stream coming from a minimum number of sensors placed in the environment. We propose a hybrid method based on state-of-the-art data-driven and knowledge-driven approaches. Proposed method is being developed and will be validated on the example of the application for robust physical intrusion detection on home doors in real life environment. Key-Words: activity recognition, machine learning, context-aware, real-time, dense-sensing, accelerometer,","",""
1,"Donggyu Lee, Hyeongmin Park, Taesup Moon, Youngwook Kim","Continual Learning of Micro-Doppler Signature-Based Human Activity Classification",2021,"","","","",27,"2022-07-13 09:39:36","","10.1109/LGRS.2020.3046015","","",,,,,1,1.00,0,4,1,"Human activity classification based on micro-Doppler signatures measured by radar recently has been successfully applied in diverse applications due to the improvement of machine learning methods, e.g., deep convolutional neural networks (DCNNs). Despite the success, those methods encounter a common practical problem when all the radar data are not readily available before training a model but sequentially arrive as the learning continues, e.g., during surveillance or search-and-rescue operations. That is, when DCNN is naively utilized in such settings, it is well-known that catastrophic forgetting of past learned tasks occurs; hence, more robust continual learning methods should be developed. To that end, we apply several state-of-the-art methods for two practical continual learning scenarios in activity classification, i.e., when the data for a subject and an activity class arrive incrementally, respectively, and compare the competitiveness of those methods. To the best of our knowledge, this is the first comparative study of continual learning methods for the classification based on micro-Doppler signatures—we find that exemplar memory-based methods particularly become very effective for both scenarios, not only for the performance but also for the memory usage.","",""
150,"H. Rahmani, A. Mian, M. Shah","Learning a Deep Model for Human Action Recognition from Novel Viewpoints",2016,"","","","",28,"2022-07-13 09:39:36","","10.1109/TPAMI.2017.2691768","","",,,,,150,25.00,50,3,6,"Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a set of non-linear transformations that connects the views. The R-NKTM is learned from 2D projections of dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.","",""
0,"Jianfei Yang, Xinyan Chen, Han Zou, Dazhuo Wang, Lihua Xie","AutoFi: Towards Automatic WiFi Human Sensing via Geometric Self-Supervised Learning",2022,"","","","",29,"2022-07-13 09:39:36","","10.48550/arXiv.2205.01629","","",,,,,0,0.00,0,5,1,"—WiFi sensing technology has shown superiority in smart homes among various sensors for its cost-effective and privacy-preserving merits. It is empowered by Channel State Information (CSI) extracted from WiFi signals and advanced machine learning models to analyze motion patterns in CSI. Many learning-based models have been proposed for kinds of applications, but they severely suffer from environmental dependency. Though domain adaptation methods have been proposed to tackle this issue, it is not practical to collect high- quality, well-segmented and balanced CSI samples in a new environment for adaptation algorithms, but randomly-captured CSI samples can be easily collected. In this paper, we ﬁrstly explore how to learn a robust model from these low-quality CSI samples, and propose AutoFi, an automatic WiFi sensing model based on a novel geometric self-supervised learning algorithm. The AutoFi fully utilizes unlabeled low-quality CSI samples that are captured randomly, and then transfers the knowledge to speciﬁc tasks deﬁned by users, which is the ﬁrst work to achieve cross-task transfer in WiFi sensing. The AutoFi is implemented on a pair of Atheros WiFi APs for evaluation. The AutoFi transfers knowledge from randomly collected CSI samples into human gait recognition and achieves state-of-the-art performance. Furthermore, we simulate cross-task transfer using public datasets to further demonstrate its capacity for cross-task learning. For the UT-HAR and Widar datasets, the AutoFi achieves satisfactory results on activity recognition and gesture recognition without any prior training. We believe that the AutoFi takes a huge step toward automatic WiFi sensing without any developer engagement while overcoming the cross-site issue.","",""
16,"W. MacInnes, Stephanie Santosa, William Wright","Visual Classification: Expert Knowledge Guides Machine Learning",2010,"","","","",30,"2022-07-13 09:39:36","","10.1109/MCG.2010.18","","",,,,,16,1.33,5,3,12,"Humans use intuition and experience to classify everything they perceive, but only if the distinguishing patterns are visible. Machine-learning algorithms can learn class information from data sets, but the created classes' meaning isn't always clear. A proposed mixed-initiative approach combines intuitive visualizations with machine learning to tap into the strengths of human and machine classification. The use of visualizations in an expert-guided clustering technique allows the display of complex data sets in a way that allows human input into machine clustering. Test participants successfully employed this technique to classify analytic activities using behavioral observations of a creative-analysis task. The results demonstrate how visualization of the machine-learned classification can help users create more robust and intuitive categories.","",""
19,"Chi Ian Tang, I. Perez-Pozuelo, Dimitris Spathis, S. Brage, N. Wareham, C. Mascolo","SelfHAR: Improving Human Activity Recognition through Self-training with Unlabeled Data",2021,"","","","",31,"2022-07-13 09:39:36","","10.1145/3448112","","",,,,,19,19.00,3,6,1,"Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models. In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input. We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.","",""
16,"Ramyar Saeedi, S. Norgaard, A. Gebremedhin","A closed-loop deep learning architecture for robust activity recognition using wearable sensors",2017,"","","","",32,"2022-07-13 09:39:36","","10.1109/BigData.2017.8257960","","",,,,,16,3.20,5,3,5,"Human activity recognition (HAR) plays a central role in health-care, fitness and sport applications because of its potential to enable context-aware human monitoring. With the increase in popularity of wearable devices, we are witnessing a large influx in availability of human activity data. For effective analysis and interpretation of these heterogeneous and high-volume streaming data, we need powerful algorithms. In particular, there is a strong need for developing algorithms for robust classification of human activity data that specifically address challenges associated with dynamic environments (e.g. different users, signal heterogeneity). We use the term robust here in two, orthogonal senses: 1) leveraging related data in such a way that knowledge is transferred to a new context; and 2) actively reconfiguring machine learning algorithms such that they can be applied in a new context. In this paper, we propose an architecture that combines an active learning approach with a novel deep network. Our deep neural network exploits both Convolutional and Long Short-Term Memory (LSTM) layers in order to learn hierarchical representation of features and capture time dependencies from raw-data. The active learning process allows us to choose the best instances for fine-tuning the deep network to the new setting in which the system operates (i.e. a new subject). We demonstrate the efficacy of the architecture using real data of human activity. We show that the accuracy of activity recognition reaches over 90% by annotating less than 20% of unlabeled data.","",""
7,"Ayon Sen, P. Patel, Martina A. Rau, Blake Mason, R. Nowak, T. Rogers, Xiaojin Zhu","Machine Beats Human at Sequencing Visuals for Perceptual-Fluency Practice",2018,"","","","",33,"2022-07-13 09:39:36","","","","",,,,,7,1.75,1,7,4,"In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency: the ability to intuitively and rapidly see which concepts visuals show and to translate among multiple visuals. Instructional problems that engage students in nonverbal, implicit learning processes enhance perceptual fluency. Such processes are highly influenced by sequence effects. Thus far, we lack a principled approach for identifying a sequence of perceptual-fluency problems that promote robust learning. Here, we describe a novel educational data mining approach that uses machine learning to generate an optimal sequence of visuals for perceptual-fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machinegenerated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that an educational data mining approach can induce desirable difficulties for perceptual learning.","",""
9,"Syed Ashiqur Rahman, Peter Giacobbi, L. Pyles, C. Mullett, Gianfranco Doretto, D. Adjeroh","Deep learning for biological age estimation",2020,"","","","",34,"2022-07-13 09:39:36","","10.1093/bib/bbaa021","","",,,,,9,4.50,2,6,2,"Modern machine learning techniques (such as deep learning) offer immense opportunities in the field of human biological aging research. Aging is a complex process, experienced by all living organisms. While traditional machine learning and data mining approaches are still popular in aging research, they typically need feature engineering or feature extraction for robust performance. Explicit feature engineering represents a major challenge, as it requires significant domain knowledge. The latest advances in deep learning provide a paradigm shift in eliciting meaningful knowledge from complex data without performing explicit feature engineering. In this article, we review the recent literature on applying deep learning in biological age estimation. We consider the current data modalities that have been used to study aging and the deep learning architectures that have been applied. We identify four broad classes of measures to quantify the performance of algorithms for biological age estimation and based on these evaluate the current approaches. The paper concludes with a brief discussion on possible future directions in biological aging research using deep learning. This study has significant potentials for improving our understanding of the health status of individuals, for instance, based on their physical activities, blood samples and body shapes. Thus, the results of the study could have implications in different health care settings, from palliative care to public health.","",""
392,"Dingwen Zhang, Deyu Meng, Junwei Han","Co-Saliency Detection via a Self-Paced Multiple-Instance Learning Framework",2017,"","","","",35,"2022-07-13 09:39:36","","10.1109/TPAMI.2016.2567393","","",,,,,392,78.40,131,3,5,"As an interesting and emerging topic, co-saliency detection aims at simultaneously extracting common salient objects from a group of images. On one hand, traditional co-saliency detection approaches rely heavily on human knowledge for designing hand-crafted metrics to possibly reflect the faithful properties of the co-salient regions. Such strategies, however, always suffer from poor generalization capability to flexibly adapt various scenarios in real applications. On the other hand, most current methods pursue co-saliency detection in unsupervised fashions. This, however, tends to weaken their performance in real complex scenarios because they are lack of robust learning mechanism to make full use of the weak labels of each image. To alleviate these two problems, this paper proposes a new SP-MIL framework for co-saliency detection, which integrates both multiple instance learning (MIL) and self-paced learning (SPL) into a unified learning framework. Specifically, for the first problem, we formulate the co-saliency detection problem as a MIL paradigm to learn the discriminative classifiers to detect the co-saliency object in the “instance-level”. The formulated MIL component facilitates our method capable of automatically producing the proper metrics to measure the intra-image contrast and the inter-image consistency for detecting co-saliency in a purely self-learning way. For the second problem, the embedded SPL paradigm is able to alleviate the data ambiguity under the weak supervision of co-saliency detection and guide a robust learning manner in complex scenarios. Experiments on benchmark datasets together with multiple extended computer vision applications demonstrate the superiority of the proposed framework beyond the state-of-the-arts.","",""
32,"Arindam Sengupta, Feng Jin, Renyuan Zhang, Siyang Cao","mm-Pose: Real-Time Human Skeletal Posture Estimation Using mmWave Radars and CNNs",2019,"","","","",36,"2022-07-13 09:39:36","","10.1109/JSEN.2020.2991741","","",,,,,32,10.67,8,4,3,"In this paper, mm-Pose, a novel approach to detect and track human skeletons in real-time using an mmWave radar, is proposed. To the best of the authors’ knowledge, this is the first method to detect >15 distinct skeletal joints using mmWave radar reflection signals. The proposed method would find several applications in traffic monitoring systems, autonomous vehicles, patient monitoring systems and defense forces to detect and track human skeleton for effective and preventive decision making in real-time. The use of radar makes the system operationally robust to scene lighting and adverse weather conditions. The reflected radar point cloud in range, azimuth and elevation are first resolved and projected in Range-Azimuth and Range-Elevation planes. A novel low-size high-resolution radar-to-image representation is also presented, that overcomes the sparsity in traditional point cloud data and offers significant reduction in the subsequent machine learning architecture. The RGB channels were assigned with the normalized values of range, elevation/azimuth and the power level of the reflection signals for each of the points. A forked CNN architecture was used to predict the real-world position of the skeletal joints in 3-D space, using the radar-to-image representation. The proposed method was tested for a single human scenario for four primary motions, (i) Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging both arms to validate accurate predictions for motion in range, azimuth and elevation. The detailed methodology, implementation, challenges, and validation results are presented.","",""
0,"Mark A. Miller, Hayden Freedman, C. Stoeckert","A Robust, Self-Training Classifier for Medication Strings, with Quantitative and Semantic Confidence Metrics",2020,"","","","",37,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,3,2,"The TURBO Medication Mapper (TMM) identifies terms from RxNorm that best represent a list of medication strings, like one would find in a Clinical Data Warehouse (CDW). TMM has several differentiating characteristics, compared to other tools: the machine learning component does not require a human-curated gold standard for training; normalizations are applied to source-specific language in the strings (instead of just excluding them); the confidence of each mapping is represented as a relationship to the absolute truth, along with a 0.0-1.0 score; the results, along with supporting knowledge, are saved into an RDF graph and a Solr document database is generated. Queries for drug classes like “statins” are based on OBO foundry ontologies like the Drug Ontology (DrOn) and ChEBI, and they return more results than multiple SQL search strategies over the CDW, with few false positives. TMM is available for download from GitHub.","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",38,"2022-07-13 09:39:36","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
3,"Sijie Yang, Fei Zhu, Xinghong Ling, QUAN LIU, Peiyao Zhao","Intelligent Health Care: Applications of Deep Learning in Computational Medicine",2021,"","","","",39,"2022-07-13 09:39:36","","10.3389/fgene.2021.607471","","",,,,,3,3.00,1,5,1,"With the progress of medical technology, biomedical field ushered in the era of big data, based on which and driven by artificial intelligence technology, computational medicine has emerged. People need to extract the effective information contained in these big biomedical data to promote the development of precision medicine. Traditionally, the machine learning methods are used to dig out biomedical data to find the features from data, which generally rely on feature engineering and domain knowledge of experts, requiring tremendous time and human resources. Different from traditional approaches, deep learning, as a cutting-edge machine learning branch, can automatically learn complex and robust feature from raw data without the need for feature engineering. The applications of deep learning in medical image, electronic health record, genomics, and drug development are studied, where the suggestion is that deep learning has obvious advantage in making full use of biomedical data and improving medical health level. Deep learning plays an increasingly important role in the field of medical health and has a broad prospect of application. However, the problems and challenges of deep learning in computational medical health still exist, including insufficient data, interpretability, data privacy, and heterogeneity. Analysis and discussion on these problems provide a reference to improve the application of deep learning in medical health.","",""
2,"K. Yan, Adam P. Harrison","Interpretable Medical Image Classification with Self-Supervised Anatomical Embedding and Prior Knowledge",2021,"","","","",40,"2022-07-13 09:39:36","","","","",,,,,2,2.00,1,2,1,"In medical image analysis tasks, it is important to make machine learning models focus on correct anatomical locations, so as to improve interpretability and robustness of the model. We adopt a latest algorithm called self-supervised anatomical embedding (SAM) to locate point of interest (POI) on computed tomography (CT) scans. SAM can detect arbitrary POI with only one labeled sample needed. Then, we can extract targeted features from the POIs to train a simple prediction model guided by clinical prior knowledge. This approach mimics the practice of human radiologists, thus is interpretable, controllable, and robust. We illustrate our approach on the application of CT contrast phase classification and it outperforms an existing deep learning based method trained on the whole image.","",""
3,"Jihun Hamm","Machine vs Machine: Defending Classifiers Against Learning-based Adversarial Attacks",2017,"","","","",41,"2022-07-13 09:39:36","","","","",,,,,3,0.60,3,1,5,"Recently, researchers have discovered that the state-of-the-art object classifiers can be fooled easily by small perturbations in the input unnoticeable to human eyes. Several methods were proposed to craft adversarial examples, as well as methods of robustifying the classifier against such examples. An attacker with the knowledge of the classifier parameters can generate strong adversarial patterns. Conversely, a classifier with the knowledge of such patterns can be trained to be robust to them. The cat-and-mouse game nature of the attacks and the defenses raises the question of the presence of an equilibrium in the dynamic. In this paper, we propose a game framework to formulate the interaction of attacks and defenses and present the natural notion of the best worst-case defense and attack. We propose simple algorithms to numerically find those solutions motivated by sensitivity penalization. In addition, we show the potentials of learning-based attacks, and present the close relationship between the adversarial attack and the privacy attack problems. The results are demonstrated with MNIST and CIFAR-10 datasets.","",""
60,"Hang Yan, Qi Shan, Yasutaka Furukawa","RIDI: Robust IMU Double Integration",2017,"","","","",42,"2022-07-13 09:39:36","","10.1007/978-3-030-01261-8_38","","",,,,,60,12.00,20,3,5,"","",""
0,"Tomoya Koike, Kun Qian, Björn Schuller, Yoshiharu Yamamoto","Transferring Cross-Corpus Knowledge: An Investigation on Data Augmentation for Heart Sound Classification",2021,"","","","",43,"2022-07-13 09:39:36","","10.1109/EMBC46164.2021.9629714","","",,,,,0,0.00,0,4,1,"Human auscultation has been regarded as a cheap, convenient and efficient method for the diagnosis of cardiovascular diseases. Nevertheless, training professional auscultation skills needs tremendous efforts and is time-consuming. Computer audition (CA) that leverages the power of advanced machine learning and signal processing technologies has increasingly attracted contributions to the field of automatic heart sound classification. While previous studies have shown promising results in CA based heart sound classification with the ‘shuffle split’ method, machine learning for heart sound classification decreases in accuracy with a cross-corpus test dataset. We investigate this problem with a cross-corpus evaluation using the PhysioNet CinC Challenge 2016 Dataset and propose a new combination of data augmentation techniques that leads to a CNN robust for such cross-corpus evaluation. Compared with the baseline, which is given without augmentation, our data augmentation techniques combined improve by 20.0 % the sensitivity and by 7.9 % the specificity on average across 6 databases, which is a significant difference on 4 out of these (p < .05 by one-tailed z-test).","",""
0,"S. Muggleton, Wang-Zhou Dai","Human-like Computer Vision",2021,"","","","",44,"2022-07-13 09:39:36","","10.1093/oso/9780198862536.003.0010","","",,,,,0,0.00,0,2,1,"Statistical machine learning is widely used in image classification and typically 1) requires many images to achieve high accuracy and 2) does not provide support for reasoning below the level of classification.  By contrast this paper describes an approach called machine learning approach called Logical Vision (LV) which uses a) background knowledge such as light reflection that can itself be learned and used for resolving visual ambiguities, which cannot be easily modeled using statistical approaches, b) a wider class of background models representing classical 2D shapes such as circles and ellipses, c) primitive-level statistical estimators to handle noise in real images, Our results indicate that in real images the new noise-robust version of LV using a single example (ie one-shot LV) converges to an accuracy at least comparable to thirty-shot statistical machine learner on the prediction of hidden light sources.","",""
0,"Anshul, Raju Kumar","Deep Learning Techniques in Perception of Cancer Diagnosis",2021,"","","","",45,"2022-07-13 09:39:36","","10.4018/978-1-7998-7511-6.ch001","","",,,,,0,0.00,0,2,1,"In this era of technology, for effective treatment of patients, clinical experts are getting great support from automated e-healthcare systems. Nowadays, one of the leading reasons of death is cancer. Some common cancers are breast cancer, prostate cancer, lung cancer, skin cancer, brain cancer, and so on. To save human lives from cancer, an effective and timely treatment is required. Many different types of image modalities like CT scan, ultrasound, x-ray, MRI can be used to determine the disease, but traditionally, this was purely dependent on the knowledge and experience of doctors. So, the death rate was quite high and increasing day by day. Machine learning and deep learning are providing robust solutions in this field. There are many deep learning techniques like RNN, CNN, DBN, autoencoders, generative adversarial networks which are providing robust solutions in cancer diagnosis and prognosis so that many human lives can be saved. The objective of this chapter is to give an insight into deep learning techniques in the field of a cancer diagnosis.","",""
1,"Yuqiao Wu, Xiaoyi Geng, Zili Liu, Zhenwei Shi","Tropical Cyclone Forecast Using Multitask Deep Learning Framework",2022,"","","","",46,"2022-07-13 09:39:36","","10.1109/lgrs.2021.3132395","","",,,,,1,1.00,0,4,1,"A tropical cyclone is a robust weather system that affects human daily life. Accurate and rapid tropical cyclone forecast can guide human disaster prevention and mitigation work against tropical cyclones. The mainstream tropical cyclone forecasting method is numerical forecasting, which requires abundant prior knowledge and luxurious calculation. Nowadays, machine learning methods have received increasing attention for which they can overcome these disadvantages. However, existing machine learning methods usually ignored some potential factors since they mainly concentrated on one aspect of the tropical cyclone forecast. This letter proposes a multitask machine learning framework to forecast tropical cyclone path and intensity, which possesses two modules: one is the prediction module and the other is the estimate module. We use an improved generative adversarial network as the prediction module to predict the tropical cyclone spatial data at a certain moment in the future. Then, we use two different deep neural networks as the estimation module to extract the position and intensity from the generated prediction data. The method we propose is a general and relatively accurate tropical cyclone forecast method. We reach a 24-h path forecast error of 116 km and a 24-h intensity forecast error of 13.06 kt.","",""
0,"Jianwei Wang, Deyun Chen","Few-Shot Object Detection Method Based on Knowledge Reasoning",2022,"","","","",47,"2022-07-13 09:39:36","","10.3390/electronics11091327","","",,,,,0,0.00,0,2,1,"Human beings have the ability to quickly recognize novel concepts with the help of scene semantics. This kind of ability is meaningful and full of challenge for the field of machine learning. At present, object recognition methods based on deep learning have achieved excellent results with the use of large-scale labeled data. However, the data scarcity of novel objects significantly affects the performance of these recognition methods. In this work, we investigated utilizing knowledge reasoning with visual information in the training of a novel object detector. We trained a detector to project the image representations of objects into an embedding space. Knowledge subgraphs were extracted to describe the semantic relation of the specified visual scenes. The spatial relationship, function relationship, and the attribute description were defined to realize the reasoning of novel classes. The designed few-shot detector, named KR-FSD, is robust and stable to the variation of shots of novel objects, and it also has advantages when detecting objects in a complex environment due to the flexible extensibility of KGs. Experiments on VOC and COCO datasets showed that the performance of the detector was increased significantly when the novel class was strongly associated with some of the base classes, due to the better knowledge propagation between the novel class and the related groups of classes.","",""
1,"J. Wolff","The SP Theory of Intelligence as a Foundation for the Development of a General, Human-Level Thinking Machine",2016,"","","","",48,"2022-07-13 09:39:36","","","","",,,,,1,0.17,1,1,6,"This paper summarises how the ""SP theory of intelligence"" and its realisation in the ""SP computer model"" simplifies and integrates concepts across artificial intelligence and related areas, and thus provides a promising foundation for the development of a general, human-level thinking machine, in accordance with the main goal of research in artificial general intelligence.  The key to this simplification and integration is the powerful concept of ""multiple alignment"", borrowed and adapted from bioinformatics. This concept has the potential to be the ""double helix"" of intelligence, with as much significance for human-level intelligence as has DNA for biological sciences.  Strengths of the SP system include: versatility in the representation of diverse kinds of knowledge; versatility in aspects of intelligence (including: strengths in unsupervised learning; the processing of natural language; pattern recognition at multiple levels of abstraction that is robust in the face of errors in data; several kinds of reasoning (including: one-step `deductive' reasoning; chains of reasoning; abductive reasoning; reasoning with probabilistic networks and trees; reasoning with 'rules'; nonmonotonic reasoning and reasoning with default values; Bayesian reasoning with 'explaining away'; and more); planning; problem solving; and more); seamless integration of diverse kinds of knowledge and diverse aspects of intelligence in any combination; and potential for application in several areas (including: helping to solve nine problems with big data; helping to develop human-level intelligence in autonomous robots; serving as a database with intelligence and with versatility in the representation and integration of several forms of knowledge; serving as a vehicle for medical knowledge and as an aid to medical diagnosis; and several more).","",""
3,"Caroline E. Roe, Madeline J. Hayes, Sierra M. Barone, J. Irish","Training Novices in Generation and Analysis of High‐Dimensional Human Cell Phospho‐Flow Cytometry Data",2020,"","","","",49,"2022-07-13 09:39:36","","10.1002/cpcy.71","","",,,,,3,1.50,1,4,2,"This article presents a single experiment designed to introduce a trainee to multiple advanced bench and analysis techniques, including high‐dimensional cytometry, profiling cell signaling networks, functional assays with primary human tissue, and single‐cell analysis with machine learning tools. The trainee is expected to have only minimal laboratory experience and is not required to have any prior training in flow cytometry, immunology, or data science. This article aims to introduce the advanced research areas with a design that is robust enough that novice trainees will succeed, flexible enough to allow some project customization, and fundamental enough that the skills and knowledge gained will provide a template for future experiments. For advanced users, the updated phospho‐flow protocol and the established controls, best practices, and expected outcomes presented here also provide a framework for adapting these tools in new areas with unexplored biology. © 2020 by John Wiley & Sons, Inc.","",""
0,"Mahmudul Hassan, A. Dharmaratne","Labeling abnormalities in video based complex Human-Object Interactions by robust affordance modelling",2015,"","","","",50,"2022-07-13 09:39:36","","10.1109/ICCVIA.2015.7351886","","",,,,,0,0.00,0,2,7,"Identifying abnormalities in complex Human Object Interaction (HOI) based videos and labeling their possible categories is a novel and ambitious research problem, which requires an optimal blend of the state of the art computer vision and machine learning algorithms. For classifying a HOI event normal or abnormal and subsequently classifying the potential abnormal categories requires the knowledge of the mutual relations between the Human, object and the ambient environment. Researchers have been using various contexts like spatial, temporal, sequential etc. to classify the abnormal actions. In this paper, we have introduced a novel context of object's affordance (which is a semantic map of the human, object and the ambient environment) to identify abnormalities in Human Object Interactions. Furthermore, the sub-classification of the abnormalities is also realized. In order to achieve our goal, we have introduced a set of novel attributes associated with the Human and the Objects and mapped them in a Bayesian network framework. The inference capabilities of the system depict the successful identification of abnormal events. We have also initiated a novel dataset of abnormal Human-Object Interactions in domestic settings. This research work also made a valiant effort to capitalize the abundant statistical data sources currently available, related to the domestic accidents and use them to nourish a practical classifier.","",""
0,"Andreas Holzinger","From Explainable AI to Human-Centered AI",2020,"","","","",51,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,2,"The problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. Their weakness was in dealing with non-linearities and the intrinsic uncertainties of medical data. Advances in data-driven statistical machine learning have led to the current renaissance of AI, but the solutions are becoming increasingly complex and opaque. Due to increasing social, ethical, and legal aspects of AI in medicine, explainable AI (xAI) is attracting much interest within the international research community. While xAI deals with the implementation of transparency and traceability of statistical blackbox machine learning methods, there is a pressing need to go beyond xAI, e.g. to extent explainability with causability. The integrative backbone for this approach is in interactive machine learning with the human-inthe-loop because a human domain expert complements AI with implicit knowledge. Humans are robust, can generalize from few examples, understand relevant representations and concepts and are able to explain causal links between them. Consequently, more research is needed on how human experts explain their decisions by examining their strategies, as they are (but not always) able to describe the underlying explanatory factors. Formalized, these can be used to build structural causal models of human decision making and characteristics can be mapped back to train AI. Finally, such an AI-ecosystem needs advanced Human-AI interfaces, that allow to ask questions of why, but also to ask for counterfactuals, i.e. what-if. This interactivity between human and AI will contribute to enhance robustness, reliability, accountability, fairness and trust in AI and foster ethical responsible machine learning with the human-in-control.","",""
7,"Sebastian Berisha","IMAGE CLASSIFICATION USING GABOR FILTERS AND MACHINE LEARNING",2009,"","","","",52,"2022-07-13 09:39:36","","","","",,,,,7,0.54,7,1,13,"Feature extraction and classification are important areas of research in image processing and computer vision with a myriad of applications in science and industry. The focus of this work is on the robust classification of tree and non-tree areas in aerial imagery of the eastern Andes mountains in Peru. Knowledge of this type of information has strong implications in the study of the effect of climate change on the environment and its conservation. Drawing from recent work on human iris pattern identification, we propose a classification methodology based on Gabor feature space representation of aerial imagery, where the two object classes may be well separated. We evaluate two different distance metrics to discern class separation and use the receiver operating characteristic curve to determine an optimum classification threshold. We then build upon our Gabor representation technique by proposing two additional classification methods based on naive Bayes’ and support vector machine classifiers. Mutual information is used for reducing redundant Gabor features not carrying sufficient object information. Extensive experimentation using real aerial imagery of the Peruvian Andes shows that our approach can provide highly accurate classification, even in the presence of variable illumination, different land features and changing topology. The issue of finding an optimal Gabor feature space where object classes are optimally represented is still a challenging problem to be resolved.","",""
176,"Li Liu, L. Shao, Xuelong Li, K. Lu","Learning Spatio-Temporal Representations for Action Recognition: A Genetic Programming Approach",2016,"","","","",53,"2022-07-13 09:39:36","","10.1109/TCYB.2015.2399172","","",,,,,176,29.33,44,4,6,"Extracting discriminative and robust features from video sequences is the first and most critical step in human action recognition. In this paper, instead of using handcrafted features, we automatically learn spatio-temporal motion features for action recognition. This is achieved via an evolutionary method, i.e., genetic programming (GP), which evolves the motion feature descriptor on a population of primitive 3D operators (e.g., 3D-Gabor and wavelet). In this way, the scale and shift invariant features can be effectively extracted from both color and optical flow sequences. We intend to learn data adaptive descriptors for different datasets with multiple layers, which makes fully use of the knowledge to mimic the physical structure of the human visual cortex for action recognition and simultaneously reduce the GP searching space to effectively accelerate the convergence of optimal solutions. In our evolutionary architecture, the average cross-validation classification error, which is calculated by an support-vector-machine classifier on the training set, is adopted as the evaluation criterion for the GP fitness function. After the entire evolution procedure finishes, the best-so-far solution selected by GP is regarded as the (near-)optimal action descriptor obtained. The GP-evolving feature extraction method is evaluated on four popular action datasets, namely KTH, HMDB51, UCF YouTube, and Hollywood2. Experimental results show that our method significantly outperforms other types of features, either hand-designed or machine-learned.","",""
0,"Z. Bashir","University Admission System using Machine Learning",2009,"","","","",54,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,13,"This work examines the entrance procedure for a student seeking admission to a college institute. The system ASD (Artificial Student Decision) is a simple classifier system, which learns from the performance of the previous batches. This experience coupled with information about his aptitude enables the expert to guide the student towards the branch best suited for him. Genetics Based Machine Learning (GBML) forms our choice, as it is more human like, speculative, seeking better alternatives through the juxtaposition of hunches, inductive, using deductive procedures. Apportionment of credits involved in the evaluation of aptitude is carried out using the famous Bucket Brigade Algorithm. The tripartite process of Genetic Algorithm has been applied to make the system robust. This work addressed an important issue in student education requirement, compares and contrasts what is involved in human learning with what is involved in machine learning. The results shows In the long run for big knowledge based systems, learning will turn out to be more efficient than programming. Development the LCS by using two wildcards this increase the performance of the system.","",""
73,"Yueting Zhuang, Fei Wu, Chun Chen, Yunhe Pan","Challenges and opportunities: from big data to knowledge in AI 2.0",2017,"","","","",55,"2022-07-13 09:39:36","","10.1631/FITEE.1601883","","",,,,,73,14.60,18,4,5,"In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.","",""
4,"V. Kniaz","Deep learning for dense labeling of hydrographic regions in very high resolution imagery",2019,"","","","",56,"2022-07-13 09:39:36","","10.1117/12.2533161","","",,,,,4,1.33,4,1,3,"Automatic dense labeling of multispectral satellite images facilitates faster map update process. Water objects are essential elements of a geographic map. While modern dense labeling methods perform robust segmentation of such objects like roads, buildings, and vegetation, dense labeling of hydrographic regions remains a challenging problem. Water objects change their surface albedo, color, and reflection in different weather and different seasons. Moreover, rivers and lakes can change their boundaries after floods or droughts. Robust documentation of such seasonal changes is an essential task in the field of analysis of satellite imagery. Due to the high variance in water object appearance, their segmentation is usually performed manually by a human operator. Recent advances in machine learning have made possible robust segmentation of static objects such as buildings and roads. To the best of our knowledge, there is little research in the modern literature regarding dense labeling of water regions. This paper is focused on the development of a deep-learning-based method for dense labeling of hydrographic in aerial and satellite imagery. We use the GeoGAN framework and MobileNetV2 as the starting point for our research. The GeoGAN framework uses an aerial image as an input to generate pixel-level annotations of five object classes: building, low vegetation, high vegetation, road, and car. The GeoGAN framework leverages two deep learning approaches to ensure robust labeling: a generator with skip connections and Generative Adversarial Networks. A generator with skip connections performs image→label translation using feed-forward connections between convolutional and deconvolutional layers of the same depth. A GAN framework consists of two competing networks: a generator and a discriminator. The adversarial loss improves the quality of the resulting dense labeling. We made the following contributions to the GeoGAN framework: (1) new MobileNetV2-based generator, (2) adversarial loss function. We term the resulting framework as HydroGAN. We evaluate our HydroGAN model using a new HydroViews dataset focused on dense labeling of areas that are subject to severe flooding during the spring season. The evaluation results are encouraging and demonstrate that our HydroGAN model competes with the state-of-the-art models for dense labeling of aerial and satellite imagery. The evaluation demonstrates that our model can generalize from the training data to previously unseen samples. The developed HydroGAN model is capable of performing dense labeling of water objects in different seasons. We made our model publicly available.","",""
20,"Claire Cardie","Embedded machine learning systems for natural language processing: a general framework",1995,"","","","",57,"2022-07-13 09:39:36","","10.1007/3-540-60925-3_56","","",,,,,20,0.74,20,1,27,"","",""
3,"Erin Grant, Joshua C. Peterson, Tom Griffiths","Learning deep taxonomic priors for concept learning from few positive examples",2019,"","","","",58,"2022-07-13 09:39:36","","","","",,,,,3,1.00,1,3,3,"Human concept learning is surprisingly robust, allowing for precise generalizations given only a few positive examples. Bayesian formulations that account for this behavior require elaborate, pre-specified priors, leaving much of the learning process unexplained. More recent models of concept learning bootstrap from deep representations, but the deep neural networks are themselves trained using millions of positive and negative examples. In machine learning, recent progress in metalearning has provided large-scale learning algorithms that can learn new concepts from a few examples, but these approaches still assume access to implicit negative evidence. In this paper, we formulate a training paradigm that allows a meta-learning algorithm to solve the problem of concept learning from few positive examples. The algorithm discovers a taxonomic prior useful for learning novel concepts even from held-out supercategories and mimics human generalization behavior—the first to do so without hand-specified domain knowledge or negative examples of a novel concept.","",""
0,"R. Klinkenberg, Simon Fischer, Ingo Mierswa, A. Felske","Yale: yet Another Learning Environment Motivation and Introduction 1.1 Data Pre-processing and Data Mining 1.2 Usefulness and Desired Properties of Machine Learning Environments",2001,"","","","",59,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,4,21,"In many data mining and knowledge discovery applications, the problem at hand cannot be solved satisfactorily by just taking the raw data as it is and simply applying a single one-step machine learning method. Instead, some data pre-processing and maybe representation changes are necessary to provide the data in a form suitable for the learning task and the chosen learning method and to improve the performance of the learned model. One example is the task of predicting certain properties of a chemical given its chromatogram curve, i.e. a time series with concentrations of the chemical measured at diierent points of time at the end of a column the chemical is sent through. The sensor readings may be noisy and perhaps slightly shifted along the time axis between diierent measurements, so that chromatograms looking very similar to a human expert, may seem very diierent for a learning method depending on the chosen representation. The extraction or construction of characteristic, robust features may signiicantly improve the result obtained by a learning method. Hence in many data mining applications, like the one just mentioned, one rather considers chains of pre-processing and learning steps rather than just a single one-step method. This paper proposes Yale, yet another learning environment, which allows to easily specify and execute such data mining operator chains for pre-processing, especially feature generation and selection, and multistrategy learning. This modular, non-commercial environment supports nested operator chains and the exchange of individual operators and thereby the systematic evaluation and comparison of diierent operators and operator chains for the same (sub)task. This paper describes the basic concepts underlying Yale, demonstrates how to describe data mining operator chains in Yale, and provides an example application of Yale for feature generation and selection on chromatography time series data comparing diierent data pre-processing approaches. In many real-world data mining applications, the data has to be pre-processed to be usable by the chosen machine learning method and/or to achieve an acceptable level of performance in prediction. A central problem is the representation of the examples by a good set of attributes, i.e. a set of attributes that allows the chosen learner to nd a candidate hypothesis solving the learning task at hand within its hypothesis search space. Without meaningful attributes that together convey suucient information to make learning tractable, no machine learning technique will be successful. Hence nding a suitable set of attributes may be far more …","",""
6,"Chi Ian Tang, I. Perez-Pozuelo, Dimitris Spathis, S. Brage, N. Wareham, C. Mascolo","SelfHAR",2021,"","","","",60,"2022-07-13 09:39:36","","10.1145/3448112","","",,,,,6,6.00,1,6,1,"Machine learning and deep learning have shown great promise in mobile sensing applications, including Human Activity Recognition. However, the performance of such models in real-world settings largely depends on the availability of large datasets that captures diverse behaviors. Recently, studies in computer vision and natural language processing have shown that leveraging massive amounts of unlabeled data enables performance on par with state-of-the-art supervised models. In this work, we present SelfHAR, a semi-supervised model that effectively learns to leverage unlabeled mobile sensing datasets to complement small labeled datasets. Our approach combines teacher-student self-training, which distills the knowledge of unlabeled and labeled datasets while allowing for data augmentation, and multi-task self-supervision, which learns robust signal-level representations by predicting distorted versions of the input. We evaluated SelfHAR on various HAR datasets and showed state-of-the-art performance over supervised and previous semi-supervised approaches, with up to 12% increase in F1 score using the same number of model parameters at inference. Furthermore, SelfHAR is data-efficient, reaching similar performance using up to 10 times less labeled data compared to supervised approaches. Our work not only achieves state-of-the-art performance in a diverse set of HAR datasets, but also sheds light on how pre-training tasks may affect downstream performance.","",""
1,"A. Bontempelli, Marcelo Rodas Britez, Xiaoyue Li, Haonan Zhao, L. Erculiani, Stefano Teso, Andrea Passerini, Fausto Giunchiglia","Lifelong Personal Context Recognition",2022,"","","","",61,"2022-07-13 09:39:36","","10.48550/arXiv.2205.10123","","",,,,,1,1.00,0,8,1,". We focus on the development of AIs which live in lifelong symbiosis with a human. The key prerequisite for this task is that the AI understands - at any moment in time - the personal situational context that the human is in. We out- line the key challenges that this task brings forth, namely (i) handling the human-like and ego-centric nature of the the user’s context, necessary for understanding and providing useful suggestions, (ii) performing lifelong context recognition using machine learning in a way that is robust to change, and (iii) maintaining align- ment between the AI’s and human’s representations of the world through continual bidirectional interaction. In this short paper, we summarize our recent attempts at tackling these challenges, discuss the lessons learned, and highlight directions of future research. The main take-away message is that pursuing this project requires research which lies at the intersection of knowledge representation and machine learning. Neither technology can achieve this goal without the other.","",""
1,"Farida Mustafazade, Peter F. Ebbinghaus","Evaluation of Semantic Answer Similarity Metrics",2022,"","","","",62,"2022-07-13 09:39:36","","10.5121/ijnlc.2022.11305","","",,,,,1,1.00,1,2,1,"There are several issues with the existing general machine translation or natural language generation evaluation metrics, and question-answering (QA) systems are indifferent in that context. To build robust QA systems, we need the ability to have equivalently robust evaluation systems to verify whether model predictions to questions are similar to ground-truth annotations. The ability to compare similarity based on semantics as opposed to pure string overlap is important to compare models fairly and to indicate more realistic acceptance criteria in real-life applications. We build upon the first to our knowledge paper that uses transformer-based model metrics to assess semantic answer similarity and achieve higher correlations to human judgement in the case of no lexical overlap. We propose cross-encoder augmented bi-encoder and BERTScore models for semantic answer similarity, trained on a new dataset consisting of name pairs of US-American public figures. As far as we are concerned, we provide the first dataset of co-referent name string pairs along with their similarities, which can be used both for training and as a benchmark.","",""
1,"Yuxin Hou, Ari Heljakka, A. Solin","Gaussian Process Priors for View-Aware Inference",2019,"","","","",63,"2022-07-13 09:39:36","","","","",,,,,1,0.33,0,3,3,"We derive a principled framework for encoding prior knowledge of information coupling between views or camera poses (translation and orientation) of a single scene. While deep neural networks have become the prominent solution to many tasks in computer vision, some important problems not so well suited for deep models have received less attention. These include uncertainty quantification, auxiliary data fusion, and real-time processing, which are instrumental for delivering practical methods with robust inference. While these are central goals in probabilistic machine learning, there is a tangible gap between the theory and practice of applying probabilistic methods to many modern vision problems. For this, we derive a novel parametric kernel (covariance function) in the pose space, $\mathrm{SE}(3)$, that encodes information about input pose relationships into larger models. We show how this soft-prior knowledge can be applied to improve performance on several real vision tasks, such as feature tracking, human face encoding, and view synthesis.","",""
0,"Chris Yang","Explainable Artificial Intelligence for Predictive Modeling in Healthcare",2022,"","","","",64,"2022-07-13 09:39:36","","10.1007/s41666-022-00114-1","","",,,,,0,0.00,0,1,1,"","",""
0,"Sonam Sharma, I. Alsmadi, Rami Suleiman Alkhawaldeh, B. Al-Ahmad","Analytical and Predictive Model for the impact of social distancing on COVID-19 pandemic",2022,"","","","",65,"2022-07-13 09:39:36","","10.1109/ICICS55353.2022.9811168","","",,,,,0,0.00,0,4,1,"The coronavirus (COVID-19) as in the study of which had a starting point in China in 2019, has spread rapidly in every single country and has spread in millions of cases. The pandemic attracts lots of attentions due to major impacts not only on human health but on many other aspects including, social and political ones. This paper presents a robust data-driven machine learning analysis of COVID19 starting from data collection to the final step of knowledge extraction based on the selected research topics. The proposed approach evaluates the impact of social distancing on COVID19. Several machine learning and ensemble models have been used and compared to obtain the best accuracy. Experiments have been demonstrated on large public datasets. The motivation of this study is to propose an analytical machine learning based model to explore the social distancing aspects of COVID-19 pandemic. The proposed analytical model includes classic classifiers, distinctive ensemble methods such as bagging, feature based ensemble, voting and stacking. Also, it uses different Python libraries, Rattle, RStudio, Anaconda, and Jupyter Notebook. This study shows superior prediction performance comparing with the related approaches and the classical machine learning approaches.","",""
0,"Frederick Appoh, Akilu Yunusa-Kaltungo","Dynamic Hybrid Model for Comprehensive Risk Assessment: A Case Study of Train Derailment Due to Coupler Failure",2022,"","","","",66,"2022-07-13 09:39:36","","10.1109/access.2022.3155494","","",,,,,0,0.00,0,2,1,"Comprehensive risk assessment plays a significant role in railway rolling stock safety planning to prevent accidents, including rail derailment and collision. Several methods of evaluating individual sources of railway system risk, ranging from human factors to inherent system failure and environmental hazards, exist in the literature. However, the lack of a hybrid technique to integrate these multiple sources of risk holistically, including their interdependent effects, as a single framework for robust, accurate, and comprehensive risk assessment can limit risk perception and risk mitigation actions. This report proposes a dynamic hybrid model (DHM) that incorporates the Bayesian convolutional factorization and elimination method as a compound aggregation of frequency and severity distributions. The DHM validates predicted risk using Bayesian expectation–maximization machine learning with evidenced-based propagation from expert knowledge and learned data. It also incorporates sensitivity analysis to improve the predicted risk further by prioritizing the hazards with the maximum impact on the estimated risk due to organization resource constraints. A railway case study in the UK revealed that risk prediction using the DHM provided a holistic view of the risk. The results showed that the quantitative risk prediction using the DHM was significantly more robust, accurate, and holistic than that of the conventional risk-assessment method based on the inherent failure rate. This research will facilitate the comprehensive development of risk-mitigation strategies, such as improvements in staff training and wiring insulation, to decrease the likelihood of train derailment caused by semi-permanent coupler failure.","",""
0,"Royi Ronen, Hilik Berezin, Rotem Preizler, Gopal Kasturi, A. J. Ezzour, Sayalee Bhanavase, Edan Hauon, O. Nir","Generic Automated Lead Ranking in Dynamics CRM",2021,"","","","",67,"2022-07-13 09:39:36","","10.1145/3460231.3478880","","",,,,,0,0.00,0,8,1,"We developed a generic framework which enables Customer Relationship Management (CRM) organizations to deploy an automated ranking system for leads (commonly known as ‘lead scoring’). Leads are records that represent non-customers who might become customers. Lead ranking is a fundamental CRM problem with many flavors. Ranking serves as a prioritization management tool for CRM organizations, with many characteristics similar to those of recommender systems. We present the system with its most recent developments, emphasizing challenges that go beyond the core of the learning algorithm, and that have played an instrumental role in maturing the system into a trustable feature, robust to different types of organizations and datasets. Particularly, we present features which enable Human in the Loop [1], a dominant concept in both configuration and result consumption. Another type of features demonstrates the addition of domain knowledge into the machine learning based process. We present the concepts of feature selection, with and without human help, prediction explanations, insights on model inputs, data quality issues, training for UX consistency, and actionability for each individual prediction.","",""
0,"Ayon Sen, P. Patel, Martina A. Rau, Blake Mason, R. Nowak, T. Rogers, Jerry Zhu","For Teaching Perceptual Fluency, Machines Beat Human Experts",2018,"","","","",68,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,7,4,"In STEM domains, students are expected to acquire domain knowledge from visual representations that they may not yet be able to interpret. Such learning requires perceptual fluency, or the ability to intuitively and rapidly see the underlying concepts in visuals and to translate between them. Perceptual fluency is acquired via nonverbal, implicit learning processes. Thus far, we have lacked a principled approach for identifying a sequence of perceptual fluency problems that promote robust learning. Here, we describe how a novel machine learning technique can generate an optimal sequence of perceptual fluency problems. In a human experiment, we show that a machine-generated sequence outperforms both a random sequence and a sequence generated by a human domain expert. Interestingly, the machine-generated sequence resulted in significantly lower accuracy during training, but higher posttest accuracy. This suggests that the machine-generated sequence induced desirable difficulties. To our knowledge, our study is the first to show that machine learning can yield desirable difficulties for perceptual learning.","",""
12,"Lei Chen, C. Chu, Yu-Hang Zhang, Changming Zhu, Xiangyin Kong, Tao Huang, Yuanyuan Cai","Analysis of Gene Expression Profiles in the Human Brain Stem, Cerebellum and Cerebral Cortex",2016,"","","","",69,"2022-07-13 09:39:36","","10.1371/journal.pone.0159395","","",,,,,12,2.00,2,7,6,"The human brain is one of the most mysterious tissues in the body. Our knowledge of the human brain is limited due to the complexity of its structure and the microscopic nature of connections between brain regions and other tissues in the body. In this study, we analyzed the gene expression profiles of three brain regions—the brain stem, cerebellum and cerebral cortex—to identify genes that are differentially expressed among these different brain regions in humans and to obtain a list of robust, region-specific, differentially expressed genes by comparing the expression signatures from different individuals. Feature selection methods, specifically minimum redundancy maximum relevance and incremental feature selection, were employed to analyze the gene expression profiles. Sequential minimal optimization, a machine-learning algorithm, was employed to examine the utility of selected genes. We also performed a literature search, and we discuss the experimental evidence for the important physiological functions of several highly ranked genes, including NR2E1, DAO, and LRRC7, and we give our analyses on a gene (TFAP2B) that have not been investigated or experimentally validated. As a whole, the results of our study will improve our ability to predict and understand genes related to brain regionalization and function.","",""
4,"Jina Suh, S. Ghorashi, Gonzalo A. Ramos, N. Chen, S. Drucker, J. Verwey, P. Simard","AnchorViz",2019,"","","","",70,"2022-07-13 09:39:36","","10.1145/3241379","","",,,,,4,1.33,1,7,3,"When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.","",""
24,"D. Miller","The medical AI insurgency: what physicians must know about data to practice with intelligent machines",2019,"","","","",71,"2022-07-13 09:39:36","","10.1038/s41746-019-0138-5","","",,,,,24,8.00,24,1,3,"","",""
22,"Jonathan Peck, Claire Nie, R. Sivaguru, Charles Grumer, Femi G. Olumofin, Bin Yu, A. Nascimento, Martine De Cock","CharBot: A Simple and Effective Method for Evading DGA Classifiers",2019,"","","","",72,"2022-07-13 09:39:36","","10.1109/ACCESS.2019.2927075","","",,,,,22,7.33,3,8,3,"Domain generation algorithms (DGAs) are commonly leveraged by malware to create lists of domain names, which can be used for command and control (C&C) purposes. Approaches based on machine learning have recently been developed to automatically detect generated domain names in real-time. In this paper, we present a novel DGA called CharBot, which is capable of producing large numbers of unregistered domain names that are not detected by state-of-the-art classifiers for real-time detection of the DGAs, including the recently published methods FANCI (a random forest based on human-engineered features) and LSTM.MI (a deep learning approach). The CharBot is very simple, effective, and requires no knowledge of the targeted DGA classifiers. We show that retraining the classifiers on CharBot samples is not a viable defense strategy. We believe these findings show that DGA classifiers are inherently vulnerable to adversarial attacks if they rely only on the domain name string to make a decision. Designing a robust DGA classifier may, therefore, necessitate the use of additional information besides the domain name alone. To the best of our knowledge, the CharBot is the simplest and most efficient black-box adversarial attack against DGA classifiers proposed to date.","",""
2,"Kshitij Tayal, Rahul Ghosh, Vipin Kumar","Model-agnostic Methods for Text Classification with Inherent Noise",2020,"","","","",73,"2022-07-13 09:39:36","","10.18653/V1/2020.COLING-INDUSTRY.19","","",,,,,2,1.00,1,3,2,"Text classification is a fundamental problem, and recently, deep neural networks (DNN) have shown promising results in many natural language tasks. However, their human-level performance relies on high-quality annotations, which are time-consuming and expensive to collect. As we move towards large inexpensive datasets, the inherent label noise degrades the generalization of DNN. While most machine learning literature focuses on building complex networks to handle noise, in this work, we evaluate model-agnostic methods to handle inherent noise in large scale text classification that can be easily incorporated into existing machine learning workflows with minimal interruption. Specifically, we conduct a point-by-point comparative study between several noise-robust methods on three datasets encompassing three popular classification models. To our knowledge, this is the first time such a comprehensive study in text classification encircling popular models and model-agnostic loss methods has been conducted. In this study, we describe our learning and demonstrate the application of our approach, which outperformed baselines by up to 10 % in classification accuracy while requiring no network modifications.","",""
2,"Miguel Altamirano Cabrera, Juan Heredia, D. Tsetserukou","Tactile Perception of Objects by the User's Palm for the Development of Multi-contact Wearable Tactile Displays",2020,"","","","",74,"2022-07-13 09:39:36","","10.1007/978-3-030-58147-3_6","","",,,,,2,1.00,1,3,2,"","",""
2,"M. Shimosaka, Taketoshi Mori, T. Harada, Tomomasa Sato","Action recognition based on kernel machine encoding qualitative prior knowledge",2004,"","","","",75,"2022-07-13 09:39:36","","10.1109/ICSMC.2004.1399855","","",,,,,2,0.11,1,4,18,"This paper proposes a recognition algorithm based on kernel classifier for human daily life action such as walking or lying down. The advantage of the proposed algorithm is to realize implant of qualitative human knowledge and robust recognition accuracy at the same time. The main features of the presented method are: (1)utilizing Gaussian process with latent variables for relation between recognized labels and input human motion, (2) in order to embed prior knowledge for proper recognition of novel motion dissimilar to the learned motion data, assigning probabilistic labels to virtual human motions generated in ""sparse"" area of input motion feature space, (3) learning parameters of classifier by real human motion with labels and the virtual motions in Bayesian perspective. The result of cross-validation like experiment shows that the accuracy of the proposed method is as good as support vector classification based recognition methods. It is also shown that the proposed method can recognize some novel motion fit into human common sense even when the classifiers without embedded knowledge fails to recognize it.","",""
0,"Dimitris Spathis, A. Tefas","Learning to interact with high-dimensional data",2017,"","","","",76,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,2,5,"Artificial intelligence techniques and humans have skills that complement each other; the first being good in computation at lowest level (e.g. matrix multiplications) whereas people are better at abstracting and transferring knowledge from their experience. This thesis examines how we can combine the two aforementioned strengths in order to create robust, efficient, visual and interpretable machine learning. In particular, we research on dimensionality reduction techniques, which provide ways of projecting high-dimensional data in 2D. While dimensionality reduction is used for many reasons such as to reduce storage space and processing time, we focus on its usage for visualization. By visualizing the features in a two dimensional (2D) or three dimensional (3D) space, we make it easier for the human perception to understand the structure of data in a manner that feels natural. In layman terms, we examine what happens when a user interacts (moves, drags etc.) with some data points in 2D, which correspond to high-dimensional data. Most modern dimensionality reduction techniques are based in distance metrics, which are prone to outliers and crowding issues. By extending a recently proposed generic framework called Similarity Embedding Framework (SEF) which minimizes the objective function of the difference between the projection and a target, we define that target similarity matrix as the outcome of user interaction. Then, the framework learns iteratively the optimal projection with gradient descent. In essence, we just optimize two similarity matrices. Fast linear and kernel versions are proposed. The experimental procedure covers two interaction scenarios. The first one is a quite common in multi-dimensional projection literature, so that users are provided with a subset of data points (also known as control points) and they are free to rearrange it as they wish, usually to cluster them better. Based, on that interaction, techniques have been proposed that perform interpolation so that they are able to project the rest of unseen dataset, in a kind of semi-supervised learning. While most techniques of this kind rely on feeding coordinates to least-squares, bayesian modeling, eigendecomposition, or other kinds of solvers, this thesis suggests an end-toend optimization algorithm that models user interaction as a target similarity matrix. Extensive evaluations are performed where we report results that outperform competitive baselines in a wide range of datasets (numerical, image, text). The second interaction scenario involves questions like ""what happens if I move that class away?"". This scenario involves a modification of SEF in which the target matrix of user interaction is enriched with the information of high-dimensional neighbors. In essence, when a whole dataset is projected, we drag a class away and we set the target matrix so as that the points we moved to be similar with their high-dimensional neighbors. This procedure results in some surprising observations. Apart from improving classification precision and clustering, the new emerging structure of the projection unveils semantic manifolds. For example, on a Head Pose dataset, by just dragging the faces looking far left to the left and those looking far right to the right, all faces are re-arranged on a continuum even on the vertical axis (face up and down). This methodology could be used in domain adaptation of dense embeddings and transfer learning. Αριστοτέλειο Πανεπιστήμιο Θεσσαλονίκης","",""
1,"F. Fabiano, A. D. Palù","An ASP Approach for Arteries Classification in CT-scans",2020,"","","","",77,"2022-07-13 09:39:36","","10.1093/logcom/exab087","","",,,,,1,0.50,1,2,2,"Automated segmentation of CT scans is the first step in the pipeline for the interpretation and identification of potential pathologies in human organs. Several methods based on Machine Learning are currently available, even if their precision is still outperformed by medical doctors. In this field there are some intrinsic limitations to ML approaches, such as the cost and time to acquire high quality annotated scans for training; a considerably high variability of organs morphology due to age, health conditions, genetics; acquisition noise. This paper outlines a new methodology based on Answer Set Programming, which returns reliable, easy-to-program and explainable interpretations. In particular, we focus on the CT scan analysis and retrieval of tree-like structure, corresponding to main blood vessels (arteries) arrangement. The structure is compared to the knowledge base of vessels contained in anatomy text-books. The mapping of vessels names is computed by an ASP program. This preliminary step produces a robust input to a reasoner for the multi-organ labeling and localization problem.","",""
1,"Jianbo Jiao, Linchao Bao, Yunchao Wei, Shengfeng He, Humphrey Shi, Rynson W. H. Lau, Thomas S. Huang","Laplacian Denoising Autoencoder",2020,"","","","",78,"2022-07-13 09:39:36","","","","",,,,,1,0.50,0,7,2,"While deep neural networks have been shown to perform remarkably well in many machine learning tasks, labeling a large amount of ground truth data for supervised training is usually very costly to scale. Therefore, learning robust representations with unlabeled data is critical in relieving human effort and vital for many downstream tasks. Recent advances in unsupervised and self-supervised learning approaches for visual data have benefited greatly from domain knowledge. Here we are interested in a more generic unsupervised learning framework that can be easily generalized to other domains. In this paper, we propose to learn data representations with a novel type of denoising autoencoder, where the noisy input data is generated by corrupting latent clean data in the gradient domain. This can be naturally generalized to span multiple scales with a Laplacian pyramid representation of the input data. In this way, the agent learns more robust representations that exploit the underlying data structures across multiple scales. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach, compared to its counterpart with single-scale corruption and other approaches. Furthermore, we also demonstrate that the learned representations perform well when transferring to other downstream vision tasks.","",""
28,"N. Chen, Jina Suh, J. Verwey, Gonzalo A. Ramos, S. Drucker, P. Simard","AnchorViz: Facilitating Classifier Error Discovery through Interactive Semantic Data Exploration",2018,"","","","",79,"2022-07-13 09:39:36","","10.1145/3172944.3172950","","",,,,,28,7.00,5,6,4,"When building a classifier in interactive machine learning, human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This paper presents AnchorViz, an interactive visualization that facilitates error discovery through semantic data exploration. By creating example-based anchors, users create a topology to spread data based on their similarity to the anchors and examine the inconsistencies between data points that are semantically related. The results from our user study show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods.","",""
0,"Ricelli M. S. Ramos, D. Monteiro, Ivandré Paraboni","Personality-dependent content selection in natural language generation systems",2020,"","","","",80,"2022-07-13 09:39:36","","10.1186/s13173-020-00096-1","","",,,,,0,0.00,0,3,2,"","",""
0,"Fábio M. Miranda, V. Azevedo, B. Renard, V. Piro, R. Ramos","HiTaC: Hierarchical Taxonomic Classification of Fungal ITS Sequences",2020,"","","","",81,"2022-07-13 09:39:36","","10.1101/2020.04.24.014852","","",,,,,0,0.00,0,5,2,"Motivation Fungi are key elements in several important ecological functions, ranging from organic matter decomposition to symbiotic associations with plants. Moreover, fungi naturally inhabit the human microbiome and can be causative agents of human infections. An accurate and robust method for fungal ITS classification is not only desired for the purpose of better diversity estimation, but it can also help us gain a deeper insight of the dynamics of environmental communities and ultimately comprehend whether the abundance of certain species correlate with health and disease. Although many methods have been proposed for taxonomic classification, to the best of our knowledge, none of them consider the taxonomic tree hierarchy when building their models. This in turn, leads to lower generalization power and higher risk of committing classification errors. Results In this work, we developed a robust, hierarchical machine learning model for accurate ITS classification, which requires a small amount of data for training and is able to handle imbalanced datasets. We show that our hierarchical model, HiTaC, outperforms state-of-the-art methods when trained over noisy data, consistently achieving higher accuracy and sensitivity across different taxonomic ranks. Availability HiTaC is an open-source software, with documentation and source code available at https://gitlab.com/dacs-hpi/hitac. Contact vitor.cedranpiro@hpi.de Supplementary information Supplementary data are available at bioRxiv online.","",""
6,"K. Noda, Naoya Hashimoto, K. Nakadai, T. Ogata","Sound source separation for robot audition using deep learning",2015,"","","","",82,"2022-07-13 09:39:36","","10.1109/HUMANOIDS.2015.7363579","","",,,,,6,0.86,2,4,7,"Noise robust speech recognition is crucial for effective human-machine interaction in real-world environments. Sound source separation (SSS) is one of the most widely used approaches for addressing noise robust speech recognition by extracting a target speaker's speech signal while suppressing simultaneous unintended signals. However, conventional SSS algorithms, such as independent component analysis or nonlinear principal component analysis, are limited in modeling complex projections with scalability. Moreover, conventional systems required designing an independent subsystem for noise reduction (NR) in addition to the SSS. To overcome these issues, we propose a deep neural network (DNN) framework for modeling the separation function (SF) of an SSS system. By training a DNN to predict clean sound features of a target sound from corresponding multichannel deteriorated sound feature inputs, we enable the DNN to model the SF for extracting the target sound without prior knowledge regarding the acoustic properties of the surrounding environment. Moreover, the same DNN is trained to function simultaneously as a NR filter. Our proposed SSS system is evaluated using an isolated word recognition task and a large vocabulary continuous speech recognition task when either nondirectional or directional noise is accumulated in the target speech. Our evaluation results demonstrate that DNN performs noticeably better than the baseline approach, especially when directional noise is accumulated with a low signal-to-noise ratio.","",""
5,"Taketoshi Mori, M. Shimosaka, T. Harada","Recognition of Human Daily Life Action and Its Performance Adjustment based on Support Vector Learning",2003,"","","","",83,"2022-07-13 09:39:36","","","","",,,,,5,0.26,2,3,19,"This paper presents a recognition method of human daily life action. The system deals with actions related to regular human activity such as walking or lying down. The main features of the proposed method are: 1)simultaneous recognition, 2)expressing unclarity in humans’ recognition, 3) defining similarity between two motions by utilizing kernel functions, which is derived from expressions of action based on human knowledge, 4)robust learning capability based on Support Vector Machine. The comparison with neural networks optimized by back propagation algorithm and decision trees generated by C4.5 proves that the accuracy of recognition in the proposed method is superior to the others. Recognition of daily life action is expected to ensure smooth communication between humans and robots and to enhance support functionality in intelligent systems.","",""
2,"Dongjin Choi, Myunggwon Hwang, Byeongkyu Ko, Sicheon You, Pankoo Kim","Low Ambiguity First Algorithm: A New Approach to Knowledge-Based Word Sense Disambiguation",2015,"","","","",84,"2022-07-13 09:39:36","","10.1007/978-3-319-20895-4_52","","",,,,,2,0.29,0,5,7,"","",""
1,"Phillip Odom, Raksha Kumaraswamy, K. Kersting, Sriraam Natarajan","Learning Through Advice-Seeking via Transfer",2016,"","","","",85,"2022-07-13 09:39:36","","10.1007/978-3-319-63342-8_4","","",,,,,1,0.17,0,4,6,"","",""
7,"D. Ramík","Contribution to complex visual information processing and autonomous knowledge extraction : application to autonomous robotics. (Contribution au traitement d'informations visuelles complexes et à l'extraction autonome des connaissances : application à la robotique autonome)",2012,"","","","",86,"2022-07-13 09:39:36","","","","",,,,,7,0.70,7,1,10,"The work accomplished in this thesis concerns development of an autonomous machine cognition system. The proposed solution reposes on the assumption that it is the curiosity which motivates a cognitive system to acquire new knowledge. Further, two distinct kinds of curiosity are identified in conformity to human cognitive system. On this I build a two level cognitive architecture. I identify its lower level with the perceptual saliency mechanism, while the higher level performs knowledge acquisition from observation and interaction with the environment. This thesis brings the following contribution: A) Investigation of the state of the art in autonomous knowledge acquisition. B) Realization of a lower cognitive level in the ensemble of the mentioned system, which is realizing the perceptual curiosity mechanism through a novel fast, real-world robust algorithm for salient object detection and learning. C) Realization of a higher cognitive level through a general framework for knowledge acquisition from observation and interaction with the environment including humans. Based on the epistemic curiosity, the high-level cognitive system enables a machine (e.g. a robot) to be itself the actor of its learning. An important consequence of this system is the possibility to confer high level multimodal cognitive capabilities to robots to increase their autonomy in real-world environment (human environment). D) Realization of the strategy proposed in the context of autonomous robotics. The studies and experimental validations done had confirmed notably that our approach allows increasing the autonomy of robots in real-world environment","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",87,"2022-07-13 09:39:36","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
3,"Neda Nasiriani, A. Squicciarini, Zara Saldanha, Sanchit Goel, Nicola Zannone","Hierarchical Clustering for Discrimination Discovery: A Top-Down Approach",2019,"","","","",88,"2022-07-13 09:39:36","","10.1109/AIKE.2019.00041","","",,,,,3,1.00,1,5,3,"Today, data is an essential part of many decision-making processes in businesses and social life through the use of various machine learning techniques. These methods can easily perpetuate human bias in the data and result in discrimination. Despite a growing interest in data discrimination discovery and removal, to date there is a lack of a general and robust framework to distinguish discriminatory decision-making processes from non-discriminatory ones. In this work, we present a generic framework that helps detect possible discrimination by analyzing historical data and associated decisions using a top-down unsupervised approach, which we refer to as hierarchical clustering. Our approach is highly adaptive as it gradually ""learns"" users' inherent groups, and clusters their records using cohesiveness and density of points in the dataset. Moreover, we propose a progressive attribute-selection method to choose statistically relevant attributes, thus reducing the effect of noise. Finally, we adopt a recursive notion of cluster profile that is homogeneous w.r.t. decision labels. This allows for deeper insights on the data and on the decision-making underlying the final user classification. Our framework is able to identify both positive and negative bias resulting in discrimination. We also highlight patterns of discrimination revealed by the homogeneous cluster centroids, which otherwise could not be captured.","",""
50,"Simon Harding, J. Leitner, J. Schmidhuber","Cartesian Genetic Programming for Image Processing",2013,"","","","",89,"2022-07-13 09:39:36","","10.1007/978-1-4614-6846-2_3","","",,,,,50,5.56,17,3,9,"","",""
46,"Reinhold Scherer, J. Faller, David Balderas, E. Friedrich, M. Pröll, B. Allison, G. Müller-Putz","Brain–computer interfacing: more than the sum of its parts",2013,"","","","",90,"2022-07-13 09:39:36","","10.1007/s00500-012-0895-4","","",,,,,46,5.11,7,7,9,"","",""
0,"","Robot Learning Using Structured Policies",,"","","","",91,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,0,,"We will explore learning using structured policies as a way to achieve robust intelligence. There are several components to our approach to learning using structured policies. Humans use domain knowledge to create a library of local policies or local behavioral primitives. Machines use statistical approaches to propose local policies. Machines learn to select the appropriate local policy at each instant in time, and learn to provide the selected policy with appropriate sub-goals. From a machine learning point of view, a structured policy is being learned. One hypothesis we will explore is that policy structure, which restricts what the machine can do, can actually accelerate learning. The goals of this work are to understand which kinds of policy structure are most beneficial, and develop learning algorithms that can take advantage of policy structure. We will explore both learning from observation, where the machine learns by watching the task being executed either by a human or another machine, and learning from practice. We will explore learning both parametric and non-parametric structured policies, and model-free and model-based learning approaches. We will also develop planning algorithms that can plan and reason in terms of these local policies. Robot learning goals: To test our learning and planning methods, we will implement them on robots performing difficult dynamic tasks. Up to now, we have focused on tasks that are repeatable (deterministic) and where it is reasonable to expect to be able to learn about all aspects of the task (closed world) (Figure 1). In this work we intend to push those limits with more complexity. We will focus on manipulating deformable objects and clearing rubble and debris in simulated disaster sites. Our robots will learn by storing actual experiences, creating and updating models, improving system parameters, and directly adjusting stored policies. Our robots will reason and plan by rapidly finding usable plans, and then refining those plans with further thought and experience. Our robots will generalize within a task and across similar tasks by transforming experience and knowledge into appropriate local representations. Our robots will organize knowledge by creating behavioral primitives that can be used as building blocks in learning and reasoning. In manipulating deformable objects, such as putting on clothes, the task is quite complex, but simple actions such as pushing an arm through a sleeve or using gravity to orient the clothing are useful local policies to select from. In moving debris and rescuing victims in search and rescue robotics, much more than “pick-andplace” actions are useful. Tipping and pivoting large objects, cutting or deforming wreckage, and shoveling small rubble are among the local policies that should be in the repertoire. We also believe everyday tasks such as cooking, cleaning, and repair can be performed by robots using a library of policies for specific behaviors and a learned policy selection algorithm and sub-goal generator. We will be exploring these types of tasks in our NSF funded work on humanoid robotics. Funding this proposal will enable students to develop learning algorithms and implement and evaluate them on state of the art humanoid robots. Testbeds and Japanese collaboration: Funded by an NSF CISE Collaborative Research Resources grant (ANI-0224419), CMU and Sarcos are creating a state of the art humanoid robot for this research (Figure 2). In addition, existing humanoid robots at ATR Laboratories in Japan, Figures 1, 2, and 4, will be used for some of the experimental work described in this proposal. The PI has been collaborating with ATR since 1993, and has been working with DB since 1999. Funds provided in this grant will be used to support student tuitions, stipends, and associated costs in the US. Work done in Japan and travel to Japan will be supported by ATR. The PI has undertaken two visits to ATR, each approximately a month long, during each of the last few years. The significant Japanese interest in this project is demonstrated by their willingness to pay the costs of the PI and students to work in Japan. The opportunity to collaborate with Japanese in Japan is an exciting educational opportunity for the students involved, in addition to its scientific benefit. Fit to Robust Intelligence program: The proposed research makes progress towards the general goal of robust intelligence by exploring innovative ideas, theories, and experiments that move beyond incremental advances to enable fundamentally different intelligent systems approaches and paradigms based on structured policies. The proposed research will advance the understanding and development of the foundations of robust intelligent systems, and is fundamental to the development of computer systems capable of controlling robots performing intelligent tasks robustly and flexibly. Our approach will enable robots to address multiple problems and contexts, respond intelligently in novel situations, handle gaps, conflicts, and ambiguities","",""
98,"R. Battiti, Andrea Passerini","Brain–Computer Evolutionary Multiobjective Optimization: A Genetic Algorithm Adapting to the Decision Maker",2010,"","","","",92,"2022-07-13 09:39:36","","10.1109/TEVC.2010.2058118","","",,,,,98,8.17,49,2,12,"The centrality of the decision maker (DM) is widely recognized in the multiple criteria decision-making community. This translates into emphasis on seamless human-computer interaction, and adaptation of the solution technique to the knowledge which is progressively acquired from the DM. This paper adopts the methodology of reactive search optimization (RSO) for evolutionary interactive multiobjective optimization. RSO follows to the paradigm of “learning while optimizing,” through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. User judgments of couples of solutions are used to build robust incremental models of the user utility function, with the objective to reduce the cognitive burden required from the DM to identify a satisficing solution. The technique of support vector ranking is used together with a k-fold cross-validation procedure to select the best kernel for the problem at hand, during the utility function training procedure. Experimental results are presented for a series of benchmark problems.","",""
0,"Yaxin Peng, S. Du, T. Zeng","Preface: Special Issue on Optimization Models and Algorithms in Artificial Intelligence",2019,"","","","",93,"2022-07-13 09:39:36","","10.1007/s40305-019-00278-5","","",,,,,0,0.00,0,3,3,"","",""
4,"Yan Tong, Jixu Chen, Q. Ji","Modeling and exploiting the spatio-temporal facial action dependencies for robust spontaneous facial expression recognition",2009,"","","","",94,"2022-07-13 09:39:36","","10.1109/CVPRW.2009.5204263","","",,,,,4,0.31,1,3,13,"Facial action provides various types of messages for human communications. Recognizing spontaneous facial actions, however, is very challenging due to subtle facial deformation, frequent head movements, and ambiguous and uncertain facial motion measurements. As a result, current research in facial action recognition is limited to posed facial actions and often in frontal view.Spontaneous facial action is characterized by rigid head movements and nonrigid facial muscular movements. More importantly, it is the spatiotemporal interactions among the rigid and nonrigid facial motions that produce a meaningful and natural facial display. Recognizing this fact, we introduce a probabilistic facial action model based on a dynamic Bayesian network (DBN) to simultaneously and coherently capture rigid and nonrigid facial motions, their spatiotemporal dependencies, and their image measurements. Advanced machine learning methods are introduced to learn the probabilistic facial action model based on both training data and prior knowledge. Facial action recognition is accomplished through probabilistic inference by systemically integrating measurements official motions with the facial action model. Experiments show that the proposed system yields significant improvements in recognizing spontaneous facial actions.","",""
15,"Yun-he Pan","Special issue on artificial intelligence 2.0",2017,"","","","",95,"2022-07-13 09:39:36","","10.1631/FITEE.1710000","","",,,,,15,3.00,15,1,5,"With the ever-growing popularization of the Internet, universal existence of sensors, emergence of big data, development of e-commerce, rise of the information community, and interconnection and fusion of data and knowledge in human society, physical space, and cyberspace, the information environment surrounding artificial intelligence (AI) development has changed profoundly, leading to a new evolutionary stage: AI 2.0. The emergence of new technologies also promotes AI to a new stage (Pan, 2016). The next-generation AI, namely AI 2.0, is a more explainable, robust, open, and general AI with the following attractive merits: It effectively integrates data-driven machine learning approaches (bottom-up) with knowledge-guided methods (top-down). In addition, it can employ data with different modalities (e.g., visual, auditory, and natural language processing) to perform cross-media learning and inference. Furthermore, there will be a step from the pursuit of an intelligent machine to the hybridaugmented intelligence (i.e., high-level man-machine collaboration and fusion). AI 2.0 will also promote crowd-based intelligence and autonomous-intelligent systems. In the next decades, AI2.0 will probably achieve remarkable progress in aforementioned trends, and therefore significantly change our cities, products, services, economics, environments, even how we advance our society. This special issue aims at reporting recent re-thinking of AI 2.0 from aforementioned aspects as well as practical methodologies, efficient implementations, and applications of AI 2.0. The papers in this special issue can be categorized into two groups. The first group consists of six review papers and the second group five research papers. In the first group, Zhuang et al. (2017) reviewed recent emerging theoretical and technological advances of AI in big data settings. The authors concluded that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI. Li W et al. (2017) described the concepts of crowd intelligence, and explained its relationship to the existing related concepts, e.g., crowdsourcing and human computation. In addition, the authors introduced four categories of representative crowd intelligence platforms. Peng et al. (2017) presented approaches, advances, and future directions in cross-media analysis and reasoning. This paper covers cross-media representation, mining, reasoning, and cross-media knowledge evolution. Tian et al. (2017) reviewed the state-of-the-art research of the perception in terms of visual perception, auditory perception, and speech perception. It also covered perceptual information processing and learning engines. Zhang et al. (2017) introduced the trends in the development of intelligent unmanned autonomous systems. It covered unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned Editorial: Frontiers of Information Technology & Electronic Engineering www.zju.edu.cn/jzus; engineering.cae.cn; www.springerlink.com ISSN 2095-9184 (print); ISSN 2095-9230 (online) E-mail: jzus@zju.edu.cn","",""
5,"T. Callahan, W. Baumgartner, M. Bada, Adrianne L. Stefanski, Ignacio J. Tripodi, Elizabeth K. White, L. Hunter","OWL-NETS: Transforming OWL representations for improved network inference",2018,"","","","",96,"2022-07-13 09:39:36","","10.1142/9789813235533_0013","","",,,,,5,1.25,1,7,4,"Our knowledge of the biological mechanisms underlying complex human disease is largely incomplete. While Semantic Web technologies, such as the Web Ontology Language (OWL), provide powerful techniques for representing existing knowledge, well-established OWL reasoners are unable to account for missing or uncertain knowledge. The application of inductive inference methods, like machine learning and network inference are vital for extending our current knowledge. Therefore, robust methods which facilitate inductive inference on rich OWL-encoded knowledge are needed. Here, we propose OWL-NETS (NEtwork Transformation for Statistical learning), a novel computational method that reversibly abstracts OWL-encoded biomedical knowledge into a network representation tailored for network inference. Using several examples built with the Open Biomedical Ontologies, we show that OWL-NETS can leverage existing ontology-based knowledge representations and network inference methods to generate novel, biologically-relevant hypotheses. Further, the lossless transformation of OWL-NETS allows for seamless integration of inferred edges back into the original knowledge base, extending its coverage and completeness.","",""
2,"Qianqian Wu, Jianzhi Lang, Songjie Wei, Mi-lin Ren, E. Seidel","A Novel Construction of Correlation-Based Image CAPTCHA with Random Walk",2018,"","","","",97,"2022-07-13 09:39:36","","10.1007/978-981-10-8971-8_31","","",,,,,2,0.50,0,5,4,"","",""
9,"A. Ramanathan, L. Pullum, Zubir Husein, Sunny Raj, N. Torosdagli, S. Pattanaik, Sumit Kumar Jha","Adversarial attacks on computer vision algorithms using natural perturbations",2017,"","","","",98,"2022-07-13 09:39:36","","10.1109/IC3.2017.8284294","","",,,,,9,1.80,1,7,5,"Verifying the correctness of intelligent embedded systems is notoriously difficult due to the use of machine learning algorithms that cannot provide guarantees of deterministic correctness. In this paper, our validation efforts demonstrate that the OpenCV Histogram of Oriented Gradients (HOG) implementation for human detection is susceptible to errors due to both malicious perturbations and naturally occurring fog phenomena. To the best of our knowledge, we are the first to explicitly employ a natural perturbation (like fog) as an adversarial attack using methods from computer graphics. Our experimental results show that computer vision algorithms are susceptible to errors under a small set of naturally occurring perturbations even if they are robust to a majority of such perturbations. Our methods and results may be of interest to the designers, developers and validation teams of intelligent cyber-physical systems such as autonomous cars.","",""
16,"Franco Ronchetti, F. Quiroga, César Estrebou, L. Lanzarini","Handshape recognition for Argentinian Sign Language using ProbSom",2016,"","","","",99,"2022-07-13 09:39:36","","","","",,,,,16,2.67,4,4,6,"Automatic sign language recognition is an important topic within the areas of human-computer interaction and machine learning. On the one hand, it poses a complex challenge that requires the intervention of various knowledge areas, such as video processing, image processing, intelligent systems and linguistics. On the other hand, robust recognition of sign language could assist in the translation process and the integration of hearingimpaired people. This paper offers two main contributions: first, the creation of a database of handshapes for the Argentinian Sign Language (LSA), which is a topic that has barely been discussed so far. Secondly, a technique for image processing, descriptor extraction and subsequent handshape classification using a supervised adaptation of self-organizing maps that is called ProbSom. This technique is compared to others in the state of the art, such as Support Vector Machines (SVM), Random Forests, and Neural Networks. The database that was built contains 800 images with 16 LSA conjurations, and is a first step towards building a comprehensive database of Argentinian signs. The ProbSom-based neural classifier, using the proposed descriptor, achieved an accuracy rate above 90%.","",""
3,"Natraj Raman, Jochen L. Leidner","Municipal Bond Pricing: A Data Driven Method",2018,"","","","",100,"2022-07-13 09:39:36","","10.3390/IJFS6030080","","",,,,,3,0.75,2,2,4,"Price evaluations of municipal bonds have traditionally been performed by human experts based on their market knowledge and trading experience. Automated evaluation is an attractive alternative providing the advantage of an objective estimation that is transparent, consistent, and scalable. In this paper, we present a statistical model to automatically estimate U.S municipal bond yields based on trade transactions and study the agreement between human evaluations and machine generated estimates. The model uses piecewise polynomials constructed using basis functions. This provides immense flexibility in capturing the wide dispersion of yields. A novel transfer learning based approach that exploits the latent hierarchical relationship of the bonds is applied to enable robust yield estimation even in the absence of adequate trade data. The Bayesian nature of our model offers a principled framework to account for uncertainty in the estimates. Our inference procedure scales well even for large data sets. We demonstrate the empirical effectiveness of our model by assessing over 100,000 active bonds and find that our estimates are in line with hand priced evaluations for a large number of bonds.","",""
13,"Franco Ronchetti, F. Quiroga, César Estrebou, L. Lanzarini, A. Rosete","Sign Languague Recognition Without Frame-Sequencing Constraints: A Proof of Concept on the Argentinian Sign Language",2016,"","","","",101,"2022-07-13 09:39:36","","10.1007/978-3-319-47955-2_28","","",,,,,13,2.17,3,5,6,"","",""
1,"B. Vatashsky, S. Ullman","Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures",2018,"","","","",102,"2022-07-13 09:39:36","","","","",,,,,1,0.25,1,2,4,"An image related question defines a specific visual task that is required in order to produce an appropriate answer. The answer may depend on a minor detail in the image and require complex reasoning and use of prior knowledge. When humans perform this task, they are able to do it in a flexible and robust manner, integrating modularly any novel visual capability with diverse options for various elaborations of the task. In contrast, current approaches to solve this problem by a machine are based on casting the problem as an end-to-end learning problem, which lacks such abilities.  We present a different approach, inspired by the aforementioned human capabilities. The approach is based on the compositional structure of the question. The underlying idea is that a question has an abstract representation based on its structure, which is compositional in nature. The question can consequently be answered by a composition of procedures corresponding to its substructures. The basic elements of the representation are logical patterns, which are put together to represent the question. These patterns include a parametric representation for object classes, properties and relations. Each basic pattern is mapped into a basic procedure that includes meaningful visual tasks, and the patterns are composed to produce the overall answering procedure.  The UnCoRd (Understand Compose and Respond) system, based on this approach, integrates existing detection and classification schemes for a set of object classes, properties and relations. These schemes are incorporated in a modular manner, providing elaborated answers and corrections for negative answers. In addition, an external knowledge base is queried for required common-knowledge. We performed a qualitative analysis of the system, which demonstrates its representation capabilities and provide suggestions for future developments.","",""
15,"B. Menze, E. Geremia, N. Ayache, G. Székely","Segmenting Glioma in Multi-Modal Images using a Generative-Discriminative Model for Brain Lesion Segmentation",2012,"","","","",103,"2022-07-13 09:39:36","","","","",,,,,15,1.50,4,4,10,"In this paper, we evaluate a generative-discriminative approach for multi-modal tumor segmentation that builds – in its generative part – on a generative statistical model for tumor appearance in multi-dimensional images [1] by using a “latent” tumor class [2, 3], and – in its discriminative part – on a machine learning approach based on a random forest using long-range features that is capable of learning the local appearance of brain lesions in multi-dimensional images [4, 5]. The approach combines advantageous properties from both types of learning algorithms: First, it extracts tumor related image features in a robust fashion that is invariant to relative intensity changes by relying on a generative model encoding prior knowledge on expected physiology and pathophysiological changes. Second, it transforms image features extracted from the generative model – representing tumor probabilities in the different image channels – to an arbitrary image representation desired by the human interpreter through an efficient classification method that is capable of dealing with high-dimensional input data and that returns the desired class probabilities. In the following, we shortly describe the generative model from [1], and input features and additional regularization methods used similar to our earlier discriminative model from [4].","",""
1,"Zornitsa Kozareva","Resolving named entity problems: from recognition and discrimination to semantic class learning",2009,"","","","",104,"2022-07-13 09:39:36","","","","",,,,,1,0.08,1,1,13,"Contributions 1, Named Entity Recognition Among the first NER are the rule-based systems which use a set of hand-crafted rules and grammars to identify and to classify the NEs in the text. These systems have robust performance, but they are tedious to create and maintain. Their performance is dependent on the knowledge of their human creator and many times the utilized set of rules does not capture all possible cases and representations of the NEs in the texts, hence many times they miss firing. To surmount these problems, researches focused towards the development of data-driven NER systems. Most such approaches study the type of machine-learning classifier suitable for the task or the set of features that can be encoded. Over the years data driven systems also showed that they can reach high and robust performance as the rule-based system. However, the biggest bottleneck for such systems is the availability of labeled training data from which the systems can learn when ported to new domain or language. The creation of labeled data requires experts who can perform the annotation, and the labeling processes become time consuming. In this thesis, we propose a data-driven NER system which can function with labeled training data, but at the same time is capable to start the learning process from few annotated seeds which during the learning process convert large quantities of unlabeled data into labeled. For the purpose we use semi-supervised machine learning techniques such as self-training and co-training. Meanwhile most NER system use manually created gazetteer lists2, we have proposed an automatic pattern validation and graph exploration algorithm which harvests unstructured and unlabeled texts to generate person and location gazetteer entries. Our final contribution in NER is the development of a feature set which is easy to generate and adapt to a new language. The feature set does not depend on any language specific resources and uses morphological, contextual, orthographic, gazetteer and trigger word information. The main objectives and contributions are supported with comparative study and evaluation with Spanish and Italian NE data sets.  2. Named Entity Discrimination Named entity discrimination system aims at finding the number of underlying entities given a name. Current systems group the snippets of ambiguous names or map the content of the documents to the disambiguated pages in Wikipedia. Our contribution in this NE subtask is the development of a system which groups snippets into clusters and also assigns to each cluster category labels. The category labels represent the sense or the topic of the cluster. For instance, ""Jerry Hobbs"" the series killer is mapped to the category label ""CRIME"", while ""Jerry Hobbs"" the professor is mapped to ""SCIENCE"". The system also generates descriptive and discriminative labels. The descriptive labels are words which are typical for given sense, but they can be also shared by other clusters. For instance, the two senses of ""Jerry Hobbs"" the taekwondo teacher and the computational linguistics professor share words like lecture, class, pupils, students, homework and exercise. While the discriminative labels are words which are specific to given sense and are not shared by other individuals. For instance, though the two ""Jerry Hobbs"" are related to science, they live on specific address, they are married to different wives and have different children. These characteristics provide more thorough representation and explanation of the formed clusters. Our approach is evaluated according to different criterion like the number of conflated names, the size of the examples that have to be disambiguated, disparity factor which estimates the difficulty level for the disambiguation of names which share similar properties among other criterion. Since our approach is based on the similarity of context, the approach was adapted to different languages. We have conducted experiments in Spanish, English, Romanian and Bulgarian languages. We have evaluated the approach with different named entity categories such as rivers, organizations, capitals, racers among others. We have carried out comparative study with other disambiguation approaches and the obtained results show that the proposed disambiguation approach achieves high results.  3. Semantic Class Learning  According to Artiles et al. (2005) 30% of the web queries are related to named entities. To improve the performance of search engines fine-grained NER is necessary. The creation of such systems is impeded by number of factors like the creation of annotated data, the type of categories that have to be learned, handling dynamic information as NEs change categories over time. Rather than learning such classifiers researchers focused towards the development of automatic, web-based knowledge extractors and relation harvesters. For instance, Pasca (2004) and Etzioni et al. (2005) proposed instance-based harvesting algorithms, later on Pasca (2007b), Pasca & Durme (2007) continued the work towards attribute generation for each NE class, while Etzioni et al. continued the work towards web based machine reading Etzioni (2008) and open information extraction Banko et al. (2007). Our contribution in this NE subtask is the development of a doubly-anchored pattern (DAP) of the type ""superordinate such as subordinate1 and subordinate2"" which when instantiated with two of the three instances is able to learn new instances, categories and the relations among them. To steer the learning process, the algorithm is incorporated in a bootstrapping fashion which learns on alternating cycles these three kinds of information. To guide bootstrapping, we have proposed the usage of hyponym pattern linkage graphs. They use different graph algorithms to rank the extracted information and separate relevant from irrelevant concepts. We have shown that the DAP pattern can be used not only as knowledge harvester but also as a validation mechanism which positions a category as super- or subordinate concept given another category. This concept positioning test selects the category which should be incorporated in the bootstrapping process and thus expands the search space. To validate the correctness of the harvested categories, we introduced a criterion according to which people separate and organize the concepts in the domain people. This is also our first approximation at taxonomizing the acquired information. The proposed approach is evaluated on open and closed semantic classes. We have presented comparative study with other knowledge miners such as Etzioni et al. (2005) and Pasca (2007a).","",""
3,"Z. Ye","Improved Mumford-Shah Active Contour Image Segmentation Based on Support Vector Machine Energy Representation",2006,"","","","",105,"2022-07-13 09:39:36","","","","",,,,,3,0.19,3,1,16,"We propose a image segmentation method which couples support vector machine and mumford-shah active contour model,where the advantages of supervised learning classification and the global region distribution information can be exploited to enhance the performance.A new region-based image energy term in curve evolution based on the output of support vector machine classifier is presented.It is more robust than classical active contour because it takes into account the image segmentation knowledge of human being and interactive operation as well.In order to improve the segmentation speed,support vector machine also be used to obtain initial contour firstly.Experimental results have demonstrated the flexibility and better performance of this new image segmentation method.","",""
1,"B. Liu, L. Yao, Junfeng Wu, Zheyuan Ding","Ontology Development for Classification: Spirals - A Case Study in Space Object Classification",2017,"","","","",106,"2022-07-13 09:39:36","","10.5220/0006240002250234","","",,,,,1,0.20,0,4,5,"Ontology-based classification (OBC) has been used extensively. The classification ontologies (COs) are the grounds of the OBC systems. It is an urgent call for a method to guide the development of CO, to get better performances for OBC. A method for developing CO named Spirals is proposed, taking the development of the ontology for space object classification named OntoStar as an example. First, soft sensing data and hard sensing data are collected. Then, various kinds of human knowledge and knowledge obtained by machine learning are combined to build a CO. Finally, data-driven evaluation and promotion assesses and promotes CO. Classification of space object based on OntoStar show that data-driven evaluation and promotion increases the accuracy by 4.1%. Meanwhile, OBC is more robust than baseline classifiers with respect to a missing feature in the test data. When classifying space objects with “size” missing in the test data, OBC keeps its FP rate, while the baseline classifiers’ FP rates increase between 3.9% and 35.5%; the losing accuracy of OBC is 0.2%, while that of baseline classifiers ranges from 1.1% to 69.5%.","",""
1,"Yueting Zhuang, R. Jain, W. Gao, Liu Ren, K. Aizawa","Panel: Cross-media Intelligence",2017,"","","","",107,"2022-07-13 09:39:36","","10.1145/3123266.3133336","","",,,,,1,0.20,0,5,5,"In this panel, we attempt to review and discuss the recent emerging theoretical and technological advances and trends of cross-media. Integrating data-driven machine learning with human knowledge can effectively lead to explainable, robust, and general models. Thus, the effective employment of the interaction between cross-media data during inference and reasoning becomes a challenge to populate the cross-media knowledge graph. Some other fundamental and controversial issues such as leveraging the auxiliary information to boost the cross-media understanding, the existence of unified framework to bridge the gap between multi-modality will also be discussed in this panel.","",""
1,"I. Zitouni, Hui Jiang, Qiru Zhou","Discriminative training and support vector machine for natural language call routing",2005,"","","","",108,"2022-07-13 09:39:36","","","","",,,,,1,0.06,0,3,17,"In natural language call routing, callers are routed to desired departments based on natural spoken responses to an open-ended “How may I direct your call?” prompt. Natural language call classification can be performed using support vector machines (SVMs) or the popular vector-based model used in information retrieval. We recently demonstrate how discriminative training is powerful to improve any parameterized vector-based classifier to achieve minimum classification error. Discriminative training minimizes the classification error by increasing the score separation of the correct from competing documents. It makes the classifier robust to feature selection, enabling fully automated training without the injection of human expert knowledge. Support vector machines received also a lot of attention in the machine learning community. They have often achieved better performance than customized neuronal network and state-of-the-art baseline classifiers. We investigate in this paper the classification power of SVMs and discriminative training approaches on natural language call routing. Experiments are reported for a banking call routing and for Switchboard topic identification task. Results show that the application of discriminative training on vector-based model outperforms SVMs by on spoken data.","",""
1,"M. P. Sharma, N. Chopde","Face Recognition using Discriminant Face Features Extraction method",2017,"","","","",109,"2022-07-13 09:39:36","","10.23883/ijrter.2017.3061.shhl1","","",,,,,1,0.20,1,2,5,"Face recognition has been one of the most interesting and important research fields in the past two decades. The reasons come from the need of automatic recognitions and surveillance systems, the interest in human visual system on face recognition, and the design of human-computer interface, etc. These researches involve knowledge and researchers from disciplines such as neuroscience, psychology, computer vision, pattern recognition, image processing, and machine learning, etc. A bunch of papers have been published to overcome difference factors (such as illumination, expression, scale, pose, etc) and achieve better recognition rate, while there is still no robust technique against uncontrolled practical cases which may involve kinds of factors simultaneously. Most of the current face recognition systems presume that faces are readily available for processing. However, in reality, we do not get images with just faces. We need a system, which will detect the face in image, so that this detected face can be given as input to face recognition systems. The goal of a face detection algorithm is to identify the location and scale of all the faces in image. The task of face detection is so trivial for the human brain, yet it still remains a challenging and difficult problem to enable a computer to do face detection. This is because the human face changes with respect to internal factors like facial expression, beard and mustache, glasses etc and it is also affected by external factors like scale, lightning conditions, contrast between face and background and orientation of the face.","",""
10,"Taketoshi Mori, M. Shimosaka, T. Harada, Tomomasa Sato","Recognition of Actions in Daily Life and its Performance Adjustment Based on Support Vector Learning",2004,"","","","",110,"2022-07-13 09:39:36","","10.1142/S0219843604000368","","",,,,,10,0.56,3,4,18,"This paper presents a recognition method for human actions in daily life. The system deals with actions related to regular human activity such as walking or lying down. The main features of the proposed method are: (i) simultaneous recognition, (ii) expressing lack of clarity in human recognition, (iii) defining similarities between two motions by utilizing kernel functions derived from expressions of actions based on human knowledge, (iv) robust learning capability based on support vector machine. Comparison with neural networks optimized by a back propagation algorithm and decision trees generated by C4.5 proves that the accuracy of recognition in the proposed method is superior to others. Recognizing actions in daily life robustly is expected to ensure smooth communication between humans and robots and to enhance support functionality in intelligent systems.","",""
29,"Xudong Jiang","Feature extraction for image recognition and computer vision",2009,"","","","",111,"2022-07-13 09:39:36","","10.1109/ICCSIT.2009.5235014","","",,,,,29,2.23,29,1,13,"Feature extraction and classifier design are two main processing blocks in all pattern recognition and computer vision systems. For visual patterns, extracting robust and discriminative features from image is the most difficult yet the most critical step. Several typical and advanced approaches of feature extraction from image are explored, some of which are analyzed in depth. Various techniques of feature extraction from image are organized in four categories: human expert knowledge based methods, image local structure based approaches, image global structure based techniques and machine learning based statistical approaches. We will show examples of applying these feature extraction approaches to solve problems of the image based biometrics, including fingerprint verification/identification and face detection/recognition. These illustrative application examples unveil the ideas, principles and advancements of feature extraction techniques and demonstrate their effectiveness and limitations in solving real-world problems.","",""
18,"P. Bock","The Emergence of Artificial Intelligence: Learning to Learn",1985,"","","","",112,"2022-07-13 09:39:36","","10.1609/AIMAG.V6I3.498","","",,,,,18,0.49,18,1,37,"The classical approach to the acquisition of knowledge and reason in artificial intelligence is to program the facts and rules into the machine. Unfortunately, the amount of time required to program the equivalent of human intelligence is prohibitively large. An alternative approach allows an automaton to learn to solve problems through iterative trial-and-error interaction with its environment, much as humans do. To solve a problem posed by the environment, the automaton generates a sequence or collection of responses based on its experience. The environment evaluates the effectiveness of this collection, and reports its evaluation to the automaton. The automaton modifies its strategy accordingly, and then generates a new collection of responses. This process is repeated until the automaton converges to the correct collection of responses. The principles underlying this paradigm, known as collective learning systems theory, are explained and applied to a simple game, demonstrating robust learning and dynamic adaptivity.","",""
11,"C. Liu, H. Wechsler","Learning the face space-representation and recognition",2000,"","","","",113,"2022-07-13 09:39:36","","10.1109/ICPR.2000.905313","","",,,,,11,0.50,6,2,22,"This paper advances an integrated learning and evolutionary computation methodology for approaching the task of learning the face space. The methodology is geared to provide a framework whereby enhanced and robust face coding and classification schemes can be derived and evaluated using both machine and human benchmark studies. In particular we take an interdisciplinary approach, drawing from the accumulated and vast knowledge of both the computer vision and psychology communities, and describe how evolutionary computation and statistical learning can engage in mutually beneficial relationships in order to define an exemplar (absolute)-based coding of multidimensional face space representation for successfully coping with changing population (face) types, and to leverage past experience for incremental face space definition.","",""
37,"D. Sculley, G. Cormack","Filtering Email Spam in the Presence of Noisy User Feedback",2008,"","","","",114,"2022-07-13 09:39:36","","","","",,,,,37,2.64,19,2,14,"Recent email spam filtering evaluations, such as those conducted at TREC, have shown that near-perfect filtering results are attained with a variety of machine learning methods when filters are given perfectly accurate labeling feedback for training. Yet in realworld settings, labeling feedback may be far from perfect. Real users give feedback that is often mistaken, inconsistent, or even maliciously inaccurate. To our knowledge, the impact of this noisy labeling feedback on current spam filtering methods has not been previously explored in the literature. In this paper, we show that noisy feedback may harm or even break state-of-the-art spam filters, including recent TREC winners. We then propose and evaluate several approaches to make such filters robust to label noise. We find that although such modifications are effective for uniform random label noise, more realistic “natural” label noise from human users remains a difficult challenge.","",""
21,"Marco Dinarelli, Alessandro Moschitti, G. Riccardi","Re-Ranking Models for Spoken Language Understanding",2009,"","","","",115,"2022-07-13 09:39:36","","10.3115/1609067.1609089","","",,,,,21,1.62,7,3,13,"Spoken Language Understanding aims at mapping a natural language spoken sentence into a semantic representation. In the last decade two main approaches have been pursued: generative and discriminative models. The former is more robust to overfitting whereas the latter is more robust to many irrelevant features. Additionally, the way in which these approaches encode prior knowledge is very different and their relative performance changes based on the task. In this paper we describe a machine learning framework where both models are used: a generative model produces a list of ranked hypotheses whereas a discriminative model based on structure kernels and Support Vector Machines, re-ranks such list. We tested our approach on the MEDIA corpus (human-machine dialogs) and on a new corpus (human-machine and human-human dialogs) produced in the European LUNA project. The results show a large improvement on the state-of-the-art in concept segmentation and labeling.","",""
7,"T. Lau, Daniel Oblinger, L. Bergman, V. Castelli","Learning Procedures for Autonomic Computing",2003,"","","","",116,"2022-07-13 09:39:36","","","","",,,,,7,0.37,2,4,19,"Today’s skilled IT professionals bring to bear an enormous amount of knowledge about how systems are configured, how they function on a day-to-day basis, and how to repair them when they break. However, there are not enough skilled IT professionals to meet the ever-growing demand. Autonomic computing offers a way out of this dilemma: offload the responsibility of managing complex systems onto the systems themselves, rather than relying on limited human resources. This problem raises a large challenge: how will we transfer the knowledge about systems management and configuration from the human experts to the software managing the systems? We believe this problem is fundamentally a knowledge acquisition problem. Our approach to solving this problem draws on machine learning and knowledge representation. Our core idea is based on programming by demonstration: by observing several human experts each solve a similar problem on different systems, we generalize from traces of their activity to create a robust procedure that is capable of automatically performing the same task in future instances. What will make it work is the observation that solutions to similar problems share similar sub-procedures. By capturing these nuggets of problem-solving knowledge from multiple experts, we form a robust procedure that captures the important parts of the procedures executed by all of the experts. We are currently employing this approach to acquire deskside technical support procedures, such as upgrading a network card, troubleshooting email problems, and installing a new printer. Our system captures traces of multiple desk-side support representatives as they perform one task, such as diagnosing a dysfunctional network adapter, under a variety of operational conditions. From these traces, our system generalizes and aligns the traces into a single general procedure for repairing network adapters. An important feature of our approach is that it works across applications, by instrumenting at the Windows operating system level. This paper describes our formulation of this problem as a machine learning problem. First we the problem and describes how various problem characteristics affect the difficulty of the learning problem. We then outline the subproblems we have identified, and describe our approach to each one. Finally, we conclude with a summary of current results and directions for future work. 2 Procedural knowledge acquisition","",""
11,"Varun Khanna, S. Ranganathan","In silico approach to screen compounds active against parasitic nematodes of major socio-economic importance",2011,"","","","",117,"2022-07-13 09:39:36","","10.1186/1471-2105-12-S13-S25","","",,,,,11,1.00,6,2,11,"","",""
6,"Taketoshi Mori, M. Shimosaka, Tomomasa Sato","SVM-Based Human Action Recognition and Its Remarkable Motion Features Discovery Algorithm",2004,"","","","",118,"2022-07-13 09:39:36","","10.1007/11552246_2","","",,,,,6,0.33,2,3,18,"","",""
7,"S. Rahman, I. Drezga, J. Rajagopalan","Knowledge enhanced connectionist models for short-term electric load forecasting",1993,"","","","",119,"2022-07-13 09:39:36","","10.1109/ANN.1993.264314","","",,,,,7,0.24,2,3,29,"This paper addresses short-term load forecasting using machine learning and neural network techniques. Neural networks, though accurate in weekday load forecasting, are poor at forecasting maximum daily load, weekend and holiday loads. This necessitates development of a robust forecasting technique to complement the neural networks for enhanced reliability of forecast and improved overall accuracy. The statistical decision tree method produces robust forecasts and human intelligible rules. These rules provide understanding of factors driving load demand. Decision trees when combined with neural network forecasts, produce robust and accurate forecasts. Simulations are performed on a service area susceptible to large and sudden changes in weather and load. Forecasts obtained by the proposed method are accurate under diverse conditions.<<ETX>>","",""
0,"A. Larson, R. Voyles","Programming Robot Behavior Primitives through Human Demonstration",2000,"","","","",120,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,2,22,"Robotic systems are capable of complex behavior by sequencing simpler skills called primitives (Voyles, Morrow, & Khosla 1997). A primitive is a sensor/actuator mapping robust enough to perform appropriately in various situations. Programming one primitive can be tedious and requires an accurate translation of human knowledge to machine code. Once a sufficient set of primitives is coded, the user must write code to sequence the primitives ‐ also tedious and difficult. Programming by human demonstration addresses these problems of acquiring and combining primitives. To create primitives, programming by demonstration can be implemented with a supervised learning technique such as artificial neural networks (ANN) to learn a sensor/actuator mapping. Problems exist with such techniques, however, including creating a training set which is comprehensive (for robustness) and concise (for efficienttraining). Here, we present a method for nonexpert users to collect “good” training data from an intuitive understanding of task behavior, not from knowledge of the underlying learning mechanism.","",""
2,"K. Hjelmervik, H. Berg","Automatic target classification for low-frequency anti-submarine warfare sonars",2013,"","","","",121,"2022-07-13 09:39:36","","10.1109/OCEANS-BERGEN.2013.6608190","","",,,,,2,0.22,1,2,9,"Autonomous anti-submarine warfare (ASW) sonars require robust automatic target classification algorithms. In conventional systems with human operators, the main role of such algorithms is to simplify the work of the sonar operator, while in autonomous systems, automatic target classification is crucial for the operative value of the systems. The emergence of the autonomous underwater vehicle (AUV), coupled with ongoing increase in computational power allowing more advanced real-time processing, has increased the interest in automatic target classification in the naval community. Detailed knowledge of the environment and an acoustic model may be used to estimate the probability that contacts are generated due to the signal processing induced phenomenon called false alarm rate inflation (FARI). This is a phenomenon often encountered in the littorals in presence of bathymetric features such as sea mounts and ridges. In this paper, we propose combining FARI information with track information, using two different machine learning techniques, k-Nearest neighbours and ID3.","",""
2,"C. Lim, C. Abeynayake, M. Sato-Ilic, L. Jain","Special issue: Computational intelligence models for image processing and information reasoning",2013,"","","","",122,"2022-07-13 09:39:36","","10.3233/IFS-2012-0546","","",,,,,2,0.22,1,4,9,"Computational Intelligence CI models comprise robust computing methodologies with a high level of machine learning quotient. CI models, in general, are useful for designing computerized intelligent systems/machines that possess useful characteristics mimicking human behaviors and capabilities in solving complex tasks, e.g., learning, adaptation, and evolution. Examples of some popular CI models include fuzzy systems, artificial neural networks, evolutionary algorithms, multi-agent systems, decision trees, rough set theory, knowledge-based systems, and hybrid of these models. This special issue highlights how different computational intelligence models, coupled with other complementary techniques, can be used to handle problems encountered in image processing and information reasoning.","",""
36,"Richard Tzong-Han Tsai, Shih-Hung Wu, Cheng-Wei Lee, Cheng-Wei Shih, W. Hsu","Mencius: A Chinese Named Entity Recognizer Using the Maximum Entropy-based Hybrid Model",2004,"","","","",123,"2022-07-13 09:39:36","","10.30019/IJCLCLP.200402.0004","","",,,,,36,2.00,7,5,18,"This paper presents a Chinese named entity recognizer (NER): Mencius. It aims to address Chinese NER problems by combining the advantages of rule-based and machine learning (ML) based NER systems. Rule-based NER systems can explicitly encode human comprehension and can be tuned conveniently, while ML-based systems are robust, portable and inexpensive to develop. Our hybrid system incorporates a rule-based knowledge representation and template-matching tool, called InfoMap [Wu et al. 2002], into a maximum entropy (ME) framework. Named entities are represented in InfoMap as templates, which serve as ME features in Mencius. These features are edited manually, and their weights are estimated by the ME framework according to the training data. To understand how word segmentation might influence Chinese NER and the differences between a pure template-based method and our hybrid method, we configure Mencius using four distinct settings. The F-Measures of person names (PER), location names (LOC) and organization names (ORO) of the best configuration in our experiment were respectively 94.3%, 77.8% and 75.3%. From comparing the experiment results obtained using these configurations reveals that hybrid NER Systems always perform better performance in identifying person names. On the other hand, they have a little difficulty identifying location and organization names. Furthermore, using a word segmentation module improves the performance of pure Template-based NER Systems, but, it has little effect on hybrid NER systems.","",""
15,"R. Battiti, Andrea Passerini","Brain-Computer Evolutionary Multi-Objective Optimization ( BC-EMO ) : a genetic algorithm adapting to the decision maker",2009,"","","","",124,"2022-07-13 09:39:36","","","","",,,,,15,1.15,8,2,13,"The centrality of the decision maker (DM) is widely recognized in the Multiple Criteria Decision Making community. This translates into emphasis on seamless human-computer interaction, and adaptation of the solution technique to the knowledge which is progressively acquired from the DM. This paper adopts the methodology of Reactive Search Optimization (RSO) for evolutionary interactive multi-objective optimization. RSO follows to the paradigm of “learning while optimizing”, through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. User judgments of couples of solutions are used to build robust incremental models of the user utility function, with the objective to reduce the cognitive burden required from the DM to identify a satisficing solution. The technique of support vector ranking is used together with a k-fold cross-validation procedure to select the best kernel for the problem at hand, during the utility function training procedure. Experimental results are presented for a series of benchmark problems.","",""
0,"","Edinburgh Research Explorer Why reliabilism is not enough",,"","","","",125,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,0,,"In this paper we argue that standard calls for explainability that focus on the epistemic inscrutability of black-box machine learning models may be misplaced. If we presume, for the sake of this paper, that machine learning can be a source of knowledge, then it makes sense to wonder what kind of justification it involves. How do we rationalize on the one hand the seeming justificatory black box with the observed widespread adoption of machine learning? We argue that, in general, people implicitly adopt reliabilism regard-ing machine learning. Reliabilism is an epistemological theory of epistemic justification according to which a belief is warranted if it has been produced by a reliable process or method [18]. We argue that, in cases where model deployments require moral justification, reliabilism is not sufficient, and instead justifying deployment requires establishing robust human processes as a moral “wrap-per” around machine outputs. We then suggest that, in certain high-stakes domains with moral consequences, reliabilism does not provide another kind of necessary justification—moral justification. Finally, we offer cautions relevant to the (implicit or explicit) adoption of the reliabilist interpretation of machine learning.","",""
0,"Thin Nguyen, Dinh Q. Phung, Wei Luo, T. Tran, S. Venkatesh","iPoll: Automatic Polling Using Online Search",2014,"","","","",126,"2022-07-13 09:39:36","","10.1007/978-3-319-11749-2_21","","",,,,,0,0.00,0,5,8,"","",""
1,"J. Moore","GENETIC PROGRAMMING THEORY AND PRACTICE X GENETIC PROGRAMMING THEORY AND PRACTICE X",2012,"","","","",127,"2022-07-13 09:39:36","","","","",,,,,1,0.10,1,1,10,"Combining domain knowledge about both imaging processing and machine learning techniques can expand the abilities of Genetic Programming when used for image processing. We successfully demonstrate our new approach on several different problem domains. We show that the approach is fast, scalable and robust. In addition, by virtue of using off-the-shelf image processing libraries we can generate human readable programs that incorporate sophisticated domain","",""
5,"R. Battiti, Andrea Passerini","Evolutionary Multiobjective Optimization ( BC-EMO ) : A Genetic Algorithm Adapting to the Decision Maker",2010,"","","","",128,"2022-07-13 09:39:36","","","","",,,,,5,0.42,3,2,12,"The centrality of the decision maker (DM) is widely recognized in the multiple criteria decision-making community. This translates into emphasis on seamless human–computer interaction, and adaptation of the solution technique to the knowledge which is progressively acquired from the DM. This paper adopts the methodology of reactive search optimization (RSO) for evolutionary interactive multiobjective optimization. RSO follows to the paradigm of “learning while optimizing,” through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. User judgments of couples of solutions are used to build robust incremental models of the user utility function, with the objective to reduce the cognitive burden required from the DM to identify a satisficing solution. The technique of support vector ranking is used together with a k-fold cross-validation procedure to select the best kernel for the problem at hand, during the utility function training procedure. Experimental results are presented for a series of benchmark problems.","",""
9,"A. W. Example","Belief Propagation in Fuzzy Bayesian Networks",2008,"","","","",129,"2022-07-13 09:39:36","","","","",,,,,9,0.64,9,1,14,"Fuzzy Bayesian networks (FBN) are a graphical machine learning model representation with variables which are simultaneously fuzzy and uncertain[2]. Bayesian networks (BN) are commonly used in machine learning. This is due to their statistical rationality, capacity for rigorous causal inference, and robustness in the face of noisy, partially missing and realistic data. They are also more easily human-interpretable than other machine learning representations such as neural networks, and experts can specify prior knowledge in a principled manner to guide the machine learning search. A wide range of search algorithms have been developed for structural and parameter inference, including structural EM [3] and MCMC. Classically, Bayesian networks use continuous (Gaussian) or multinomial variables. Similarly, a fuzzy model has a wide range of advantages. Fuzzy models are also robust in the face of noise-corrupted data. The use of linguistic terms aids human comprehension of the learnt model, and they are particularly useful when the data is insufficient to formulate a precise model. The need to specify membership functions also forces the designer to consider the semantic interpretation of the model parameterisation and construction more explicitly. For these reasons, FBN (which combine these advantages) may be useful. Theoretical analysis in current research[1] indicates that fuzzy variables can be more expressive than multinomial or continuous variables. FBN may also be used as part of an integrated sequence of machine learning techniques that include reversible dimensionality reduction techniques such as fuzzy cover clustering algorithms. This may allow larger problems to be addressed with FBN than with classic BN.","",""
0,"Haoming Huang","Coevolutionary synthesis of fuzzy decision support systems.",2009,"","","","",130,"2022-07-13 09:39:36","","10.32657/10356/19087","","",,,,,0,0.00,0,1,13,"Many essential applications in finance, medicine, engineering, and science require increasingly complex decision-making capabilities. There is accordingly a growing demand for decision support systems (DSSs) to assist humans in their tasks. To provide accurate and reliable decision support, a DSS needs not only to be robust in the face of the uncertainty but also to model the decision-making logic in a form that is understandable. Compared with other machine learning methods, fuzzy rule-based systems possess the merits of providing strong approximate reasoning in the presence of imprecise data while representing domain knowledge as a set of interpretable semantic rules. Using them to realize DSSs is thus a most suitable approach yielding powerful fuzzy decision support systems (FDSSs). However, the synthesis of an optimal FDSS with well-balanced accuracy and interpretability is an arduous task. Experience shows that it is very difficult for human experts to manually design its two most important components, the fuzzy membership functions and fuzzy rule base, which directly affect system performance. Ad-hoc architectures, which must be redesigned anew for every application, and improperly chosen parameters typically introduce unwanted biases and unavoidably result in suboptimal systems. Ideally, the decision-making logic should therefore be induced automatically from example and further optimized for the problem at hand. To achieve this goal, a generic approach is needed that can automatically synthesize an accurate and interpretable FDSS, while requiring minimal or no human effort. NTU-School of Computer Engineering (SCE) vii ATTENTION: The Singapore Copyright Act applies to the use of this document. Nanyang Technological University Library","",""
2,"V. Ayala-Ramírez, R. E. Sánchez-Yáñez, C. H. García-Capulín, F. Montecillo-Puente","Soft Computing Applications in Robotic Vision Systems",2007,"","","","",131,"2022-07-13 09:39:36","","10.5772/4928","","",,,,,2,0.13,1,4,15,"1.1 Soft Computing Soft computing is a collection of intelligent techniques working in a complementary way to build robust systems at low cost. Soft computing includes techniques such as neural networks, fuzzy logic, evolutionary computation (including genetic algorithms) and probabilistic reasoning (Wang and Tang, 1997). These techniques are capable of dealing with imprecision, uncertainty, ambiguity, partial truth, machine learning and optimization issues we usually face in real world problems. Soft computing addresses problem solving tasks in a complementary approach more than in a competitive one. Main advantages of soft computing are: i) its rich knowledge representation (both at signal and pattern level), ii) its flexible knowledge acquisition process (including machine learning and learning from human experts) and iii) its flexible knowledge processing. These advantages let us to build intelligent systems with a high machine intelligence quotient at low cost. Soft computing systems have already been applied in industrial sectors like aerospace, communications systems, robotics and automation and transport systems (Dote and Ovaska, 2001).","",""
8,"Michele Bariani, R. Cucchiara, P. Mello, M. Piccardi","Data Mining for Automated Visual Inspection",1997,"","","","",132,"2022-07-13 09:39:36","","","","",,,,,8,0.32,2,4,25,"This paper addresses an automatic knowledge discovery process from a database of images in a context of Automated Visual Inspection (AVI). AVI is the field of computer vision addressing quality inspection of industrial products, even under informal quality models. When modelling informal knowledge, one of the most critical point turns out to be the correct and efficient translation of human experience into a set of rules. The paper focuses on the use of machine learning in inspection of industrial workpieces. It shows how machine learning can be exploited for data mining purposes and more specifically for selecting a minimal set of visual primitives, in order to perform reliable and robust classification of the inspected components. Eventually, the industrial application and the inspection system are presented in details.","",""
3,"Richard Tzong-Han Tsai, Shih-Hung Wu, W. Hsu","Mencius: A Chinese Named Entity Recognizer Using Hybrid Model",2003,"","","","",133,"2022-07-13 09:39:36","","","","",,,,,3,0.16,1,3,19,"This paper presents a maximum entropy based Chinese named entity recognizer (NER): Mencius. It aims to address Chinese NER problems by combining the advantages of rule-based and machine learning (ML) based NER systems. Rule-based NER systems can explicitly encode human comprehension and can be tuned conveniently, while ML-based systems are robust, portable and inexpensive to develop. Our hybrid system incorporates a rule-based knowledge representation and template-matching tool, InfoMap [1], into a maximum entropy (ME) framework. Named entities are represented in InfoMap as templates, which serve as ME features in Mencius. These features are edited manually and their weights are estimated by the ME framework according to the training data. To avoid the errors caused by word segmentation, we model the NER problem as a character-based tagging problem. In our experiments, Mencius outperforms both pure rule-based and pure ME-based NER systems. The F-Measures of person names (PER), location names (LOC) and organization names (ORG) in the experiment are respectively 92.4%, 73.7% and 75.3%.","",""
0,"D. Kalamatianos, Panos Liatis, P. Wellstead","Classification of urea data from a novel near-infrared spectrometer",2005,"","","","",134,"2022-07-13 09:39:36","","10.1117/12.629890","","",,,,,0,0.00,0,3,17,"Near-infrared (NIR) spectroscopy is being applied to the solution of problems in many areas of biomedical and pharmaceutical research. The need for modern medical diagnostics to develop small portable instruments that enable fast and effective monitoring of the biological properties of the human body is apparent. We have developed a portable and robust spectrometer that consists of a two beam interferometer operating in the near-infrared wavelength range for real-time measurements. The device has limited spectral resolution and so methods of computational intelligence and advanced signal processing have been applied to the NIR data to produce more precise and informative diagnostic information. Our target application concerns blood and tissue status in a form that can be interpreted directly by the user, without special knowledge of spectral analysis. More specifically, theories and methods from the field of machine intelligence (learning algorithms, neural networks, etc.) were first applied to classify in vitro urea samples of different concentrations. The results are encouraging, with overall mean squared prediction errors of less than 10-4, and in vivo trials will follow to further develop the device. Non-intrusive diagnostics of this kind are suitable for point-of-care screening.","",""
1,"Y. Xiang, B. Chaib-draa","Advances in artificial intelligence : 16th Conference of the Canadian Society for Computational Studies of Intelligence, AI 2003, Halifax, Canada, June 11-13, 2003 : proceedings",2003,"","","","",135,"2022-07-13 09:39:36","","","","",,,,,1,0.05,1,2,19,"Experiences Building a Distributed Sensor Network.- Artificial Intelligence and Human Brain Imaging.- Machine Learning Methods for Computational Proteomics and Beyond.- The Structure Model Interpretation of Wright's NESS Test.- Answer Formulation for Question-Answering.- Patttern-Based AI Scripting Using ScriptEase.- Enumerating the Preconditions of Agent Message Types.- Monadic Memoization towards Correctness-Preserving Reduction of Search.- Searching Solutions in the Crypto-arithmetic Problems: An Adaptive Parallel Genetic Algorithm Approach.- Stochastic Local Search for Multiprocessor Scheduling for Minimum Total Tardiness.- A Graph Based Backtracking Algorithm for Solving General CSPs.- Iterated Robust Tabu Search for MAX-SAT.- Scaling and Probabilistic Smoothing: Dynamic Local Search for Unweighted MAX-SAT.- A Comparison of Consistency Propagation Algorithms in Constraint Optimization.- Discovering Temporal/Causal Rules: A Comparison of Methods.- Selective Transfer of Task Knowledge Using Stochastic Noise.- Efficient Mining of Indirect Associations Using HI-Mine.- Case Authoring from Text and Historical Experiences.- Session Boundary Detection for Association Rule Learning Using n-Gram Language Models.- Negotiating Exchanges of Private Information for Web Service Eligibility.- Post-supervised Template Induction for Dynamic Web Sources.- Summarizing Web Sites Automatically.- Cycle-Cutset Sampling for Bayesian Networks.- Learning First-Order Bayesian Networks.- AUC: A Better Measure than Accuracy in Comparing Learning Algorithms.- Model-Based Least-Squares Policy Evaluation.- DIAGAL: A Tool for Analyzing and Modelling Commitment-Based Dialogues between Agents.- Situation Event Logic for Early Validation of Multi-Agent Systems.- Understanding ""Not-Understood"": Towards an Ontology of Error Conditions for Agent Communication.- An Improved Ant Colony Optimisation Algorithm for the 2D HP Protein Folding Problem.- Hybrid Randomised Neighbourhoods Improve Stochastic Local Search for DNA Code Design.- A Strategy for Improved Satisfaction of Selling Software Agents in E-Commerce.- Pre-negotiations over Services - A Framework for Evaluation.- Formal Theory for Describing Action Concepts in Terminological Knowledge Bases.- Improving User-Perceived QoS in Mobile Ad Hoc Networks Using Decision Rules Induction.- Risk Neutral Calibration of Classifiers.- Search Bound Strategies for Rule Mining by Iterative Deepening.- Methods for Mining Frequent Sequential Patterns.- Learning by Discovering Conflicts.- Enhancing Caching in Distributed Databases Using Intelligent Polytree Representations.- Feature Selection Strategies for Text Categorization.- Learning General Graphplan Memos through Static Domain Analysis.- Classification Automaton and Its Construction Using Learning.- A Genetic K-means Clustering Algorithm Applied to Gene Expression Data.- Explanation-Oriented Association Mining Using a Combination of Unsupervised and Supervised Learning Algorithms.- Motion Recognition from Video Sequences.- Noun Sense Disambiguation with WordNet for Software Design Retrieval.- Not as Easy as It Seems: Automating the Construction of Lexical Chains Using Roget's Thesaurus.- The Importance of Fine-Grained Cue Phrases in Scientific Citations.- Fuzzy C-Means Clustering of Web Users for Educational Sites.- Re-using Web Information for Building Flexible Domain Knowledge.- A New Inference Axiom for Probabilistic Conditional Independence.- Probabilistic Reasoning for Meal Planning in Intelligent Fridges.- Probabilistic Reasoning in Bayesian Networks: A Relational Database Approach.- Fundamental Issue of Naive Bayes.- The Virtual Driving Instructor Creating Awareness in a Multiagent System.- Multi-attribute Exchange Market: Theory and Experiments.- Agent-Based Online Trading System.- On the Applicability of L-systems and Iterated Function Systems for Grammatical Synthesis of 3D Models.- An Unsupervised Clustering Algorithm for Intrusion Detection.- Dueling CSP Representations: Local Search in the Primal versus Dual Constraint Graph.- A Quick Look at Methods for Mining Long Subsequences.- Back to the Future: Changing the Direction of Time to Discover Causality.- Learning Coordination in RoboCupRescue.- Accent Classification Using Support Vector Machine and Hidden Markov Model.- A Neural Network Based Approach to the Artificial Aging of Facial Images.- Adaptive Negotiation for Agent Based Distributed Manufacturing Scheduling.- Multi-agent System Architecture for Tracking Moving Objects.","",""
0,"","Ido Dagan – Research Statement",2002,"","","","",136,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,0,20,"The research field of Natural Language Processing (NLP, also known as Computational Linguistics) deals with two fundamental goals. The first is developing generic algorithms and computational models for analyzing the full range of human language behavior. The second goal, which relies largely on the first, is developing the needed algorithms for robust text-based applications, such as machine translation, information extraction, text categorization, question answering and many others. In many areas, achieving high performance in real-world applications drives research motivations and serves as a touchstone for the performance of the field as a whole – what can NLP algorithms actually do? The empirical NLP area, in which I focus my research, aims to make robust language processing feasible based on automated learning of knowledge and inferences from corpora (text collections). This is a great challenge, since language exhibits many unique characteristics, such as ambiguity, large variations and sparse data, that are difficult to represent and analyze in a regular manner, let alone learn them in automated ways. A recurrent theme in my own research has been to advance the "" realistic "" feasibility of NLP methods, by introducing empirical algorithms for novel tasks and through reducing and simplifying the requirements for manual supervision in learning. Empirical NLP has strong ties to machine learning and related areas, such as information theory and statistical inference, and many algorithms developed for NLP tasks (including some of mine) were published in machine learning journals and conferences. At the same time, researchers are gradually integrating learning with linguistic models, so that empirical analysis refers to deeper language phenomena. The remainder of this document illustrates major lines of my research and its current focus and plans. Semantic Disambiguation and Distributional Similarity Human language is ambiguous, so that many utterances can be interpreted in more than one way. Semantic criteria, which refer to the meaning of words and their combinations, help to select the most likely interpretation in many disambiguation problems. For example, consider the pronoun reference ambiguity (anaphora) in the sentence "" The program displays the file on the monitor and prints it "". From a syntactic perspective "" it "" can refer to both "" monitor "" and "" file "" , but from a semantic perspective the word combination <verb-object: print-file> is much more likely than <verb-object: print-monitor>, indicating that interpreting "" it "" as "" file "" should be preferred. Early approaches for semantic …","",""
0,"Myung-Mook Han","Using Genetic Rule-Based Classifier System for Data Mining",2000,"","","","",137,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,22,"Data mining means a process of nontrivial extraction of hidden knowledge or potentially useful information from data in large databases. Data mining algorithm is a multi-disciplinary field of research; machine learning, statistics, and computer science all make a contribution. Different classification schemes can be used to categorize data mining methods based on the kinds of tasks to be implemented and the kinds of application classes to be utilized, and classification has been identified as an important task in the emerging field of data mining. Since classification is the basic element of human's way of thinking, it is a well-studied problem in a wide varietyof application. In this paper, we propose a classifier system based on genetic algorithm with robust property, and the proposed system is evaluated by applying it to nDmC problem related to classification task in data mining.","",""
0,"G. McCalla","Artificial Intelligence and Educational Technology: A Natural Synergy. Extended Abstract.",1994,"","","","",138,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,28,"Educational technology and artificial intelligence (AI) are natural partners in the development of environments to support human learning. Designing systems with the characteristics of a rich learning environment is the long term goal of research in intelligent tutoring systems (ITS). Building these characteristics into a system is extremely difficult: each requires the use of techniques from AI, including knowledge representation, diagnosis and user modeling, planning, machine learning, and natural language understanding. Artificial intelligence techniques are usable now in practical systems. To illustrate this, several working systems that use artificial intelligence and that have been developed in the ARIES Laboratory (University of Saskatchewan, Canada) are discussed. The SCENT advisor can be used to provide robust diagnosis in a wide variety of problem solving domains. The learning by teaching system inverts the usual instructional paradigm: the system acts as an inquisitive learner, thus stimulating the human learner to refine and extend his/her knowledge. G.E.N.I.U.S. takes advantage of the credibility invested in a programming advisor by human learners in order to provide ""ignorance-based"" advice on programming errors. Finally, the VCR Tutor provides help to learners on how to program a video cassette recorder. The general lesson is that AI and educational technology can interact in a natural synergy to the mutual benefit of both. (Contains 11 references.) (MAS) *********************************************************************** Reproductions supplied by EDRS are the best that can be made from the original document. *********************************************************************** Artificial Intelligence and Educational Technology: A Natural Synergy","",""
39,"Changyu Deng, Xunbi A. Ji, Colton Rainey, Jian-yu Zhang, Wei Lu","Integrating Machine Learning with Human Knowledge",2020,"","","","",139,"2022-07-13 09:39:36","","10.1016/j.isci.2020.101656","","",,,,,39,19.50,8,5,2,"","",""
1,"A. Mehta, Y. Jain, Anirudha Kemtur, Jugoslav Stojcheski, Saksham Consul, Mateo Tošić, Falk Lieder","Leveraging Machine Learning to Automatically Derive Robust Decision Strategies from Imperfect Knowledge of the Real World",2022,"","","","",140,"2022-07-13 09:39:36","","10.1007/s42113-022-00141-6","","",,,,,1,1.00,0,7,1,"","",""
27,"Masahiro Mitsuhara, Hiroshi Fukui, Yusuke Sakashita, Takanori Ogata, Tsubasa Hirakawa, Takayoshi Yamashita, H. Fujiyoshi","Embedding Human Knowledge in Deep Neural Network via Attention Map",2019,"","","","",141,"2022-07-13 09:39:36","","10.5220/0010335806260636","","",,,,,27,9.00,4,7,3,"In this work, we aim to realize a method for embedding human knowledge into deep neural networks. While the conventional method to embed human knowledge has been applied for non-deep machine learning, it is challenging to apply it for deep learning models due to the enormous number of model parameters. To tackle this problem, we focus on the attention mechanism of an attention branch network (ABN). In this paper, we propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert. Our fine-tuning method can train a network so that the output attention map corresponds to the edited ones. As a result, the fine-tuned network can output an attention map that takes into account human knowledge. Experimental results with ImageNet, CUB-200-2010, and IDRiD demonstrate that it is possible to obtain a clear attention map for a visual explanation and improve the classification performance. Our findings can be a novel framework for optimizing networks through human intuitive editing via a visual interface and suggest new possibilities for human-machine cooperation in addition to the improvement of visual explanations.","",""
2,"Xiawu Zheng, Yang Zhang, Sirui Hong, Huixia Li, Lang Tang, Youcheng Xiong, Jin Zhou, Yan Wang, Xiaoshuai Sun, P. Zhu, Chenglin Wu, Rongrong Ji","Evolving Fully Automated Machine Learning via Life-Long Knowledge Anchors",2021,"","","","",142,"2022-07-13 09:39:36","","10.1109/TPAMI.2021.3069250","","",,,,,2,2.00,0,12,1,"Automated machine learning (AutoML) has achieved remarkable progress on various tasks, which is attributed to its minimal involvement of manual feature and model designs. However, most of existing AutoML pipelines only touch parts of the full machine learning pipeline, e.g., neural architecture search or optimizer selection. This leaves potentially important components such as data cleaning and model ensemble out of the optimization, and still results in considerable human involvement and suboptimal performance. The main challenges lie in the huge search space assembling all possibilities over all components, as well as the generalization ability over different tasks like image, text, and tabular etc. In this paper, we present a first-of-its-kind fully AutoML pipeline, to comprehensively automate data preprocessing, feature engineering, model generation/selection/training and ensemble for an arbitrary dataset and evaluation metric. Our innovation lies in the comprehensive scope of a learning pipeline, with a novel “life-long” knowledge anchor design to fundamentally accelerate the search over the full search space. Such knowledge anchors record detailed information of pipelines and integrates them with an evolutionary algorithm for joint optimization across components. Experiments demonstrate that the result pipeline achieves state-of-the-art performance on multiple datasets and modalities. Specifically, the proposed framework was extensively evaluated in the NeurIPS 2019 AutoDL challenge, and won the only champion with a significant gap against other approaches, on all the image, video, speech, text and tabular tracks.","",""
0,"Ahmed Reda Ali, M. Jaya, E. A. Jones","Machine Learning Strategies for Accurate Log Prediction in Reservoir Characterization: Self-Calibrating Versus Domain-Knowledge",2021,"","","","",143,"2022-07-13 09:39:36","","10.2118/205602-ms","","",,,,,0,0.00,0,3,1,"  Petrophysical evaluation is a crucial task for reservoir characterization but it is often complicated, time-consuming and associated with uncertainties. Moreover, this job is subjective and ambiguous depending on the petrophysicist's experience. Utilizing the flourishing Artificial Intelligence (AI)/Machine Learning (ML) is a way to build an automating process with minimal human intervention, improving consistency and efficiency of well log prediction and interpretation. Nowadays, the argument is whether AI-ML should base on a statistically self-calibrating or knowledge-based prediction framework! In this study, we develop a petrophysically knowledge-based AI-ML workflow that upscale sparsely-sampled core porosity and permeability into continuous curves along the entire well interval.  AI-ML focuses on making predictions from analyzing data by learning and identifying patterns. The accuracy of the self-calibrating statistical models is heavily dependent on the volume of training data. The proposed AI-ML workflow uses raw well logs (gamma-ray, neutron and density) to predict porosity and permeability over the well interval using sparsely core data. The challenge in building the AI-ML model is the number of data points used for training showed an imbalance in the relative sampling of plugs, i.e. the number of core data (used as target variable) is less than 10%. Ensemble learning and stacking ML approaches are used to obtain maximum predictive performance of self-calibrating learning strategy.  Alternatively, a new petrophysical workflow is established to debrief the domain experience in the feature selection that is used as an important weight in the regression problem. This helps ML model to learn more accurately by discovering hidden relationships between independent and target variables. This workflow is the inference engine of the AI-ML model to extract relevant domain-knowledge within the system that leads to more accurate predictions.  The proposed knowledge-driven ML strategy achieved a prediction accuracy of R2 score = 87% (Correlation Coefficient (CC) of 96%). This is a significant improvement by R2 = 57% (CC = 62%) compared to the best performing self-calibrating ML models. The predicted properties are upscaled automatically to predict uncored intervals, improving data coverage and property population in reservoir models leading to the improvement of the model robustness. The high prediction accuracy demonstrates the potential of knowledge-driven AI-ML strategy in predicting rock properties under data sparsity and limitations and saving significant cost and time.  This paper describes an AI-ML workflow that predicts high-resolution continuous porosity and permeability logs from imbalanced and sparse core plug data. The method successfully incorporates new type petrophysical facies weight as a feature augmentation engine for ML domain-knowledge framework. The workflow consisted of petrophysical treatment of raw data includes log quality control, preconditioning, processing, features augmentation and labelling, followed by feature selection to impersonate domain experience.","",""
0,"S. Chujfi, C. Meinel","Machine Learning and Human Cognition Combined to Enhance Knowledge Discovery Fidelity",2019,"","","","",144,"2022-07-13 09:39:36","","10.1109/CogMI48466.2019.00010","","",,,,,0,0.00,0,2,3,"The objective of this work is knowledge discovery in large-scale audio files by performing a Cognitive Analysis – CA –, where the knowledge is extracted from transcribed customer service conversations taking into consideration individual cognitive styles to mimic the human cognitive process and maximize the correct meaning interpretation information in a given context. We make the following three contributions: (i) integrate a Cyber Cognitive Identity model – CCI – that states the cognitive profile an individual has for interacting in cyberspace, which yields superior fidelity to identify the meaning of spoken sentences following Sternberg's Thinking Style Inventory (TSI). In particular it guides an analysis grounded in peers' cognitive styles to index words by dimension; (ii) a novel method that extends the Latent Dirichlet Allocation (LDA) approach to a multidimensional partially supervised machine learning model with the help of the psychological activation theory Adaptive Control of Thought – ACT; (iii) an improvement of the Exploratory Data Analysis – EDA–suggested by De Mast and Trip, envisioned as an extended approach to obtain high-fidelity data where topics of a three-dimensional corpus are clustered according to cognitive categorizations. Using speech-to-text software, we transcribed and evaluated 27 500 calls from 206 German-speaking teleworkers combining these three complementary methods and achieved significant fidelity to generate a hypothesis based on individuals' cognitive affinities.","",""
0,"H. Anh, Cao Van Kien","Robust extreme learning machine neural approach for uncertain nonlinear hyper‐chaotic system identification",2021,"","","","",145,"2022-07-13 09:39:36","","10.1002/rnc.5756","","",,,,,0,0.00,0,2,1,"This paper proposes a novel nonlinearly parameterized advanced single‐hidden layer neural extreme learning machine (ASHLN‐ELM) model in which the hidden and output weighting values are simultaneously updated using adaptively robust rules that are implemented based on Lyapunov stability principle. The proposed scheme guarantees the fast convergence speed of the state‐estimation residual errors bounded to null regarding to the influence of time‐varied disturbances. Additionally, proposed method needs no any knowledge related to desired weighting values or required approximating error. Typical uncertain hyper‐chaotic benchmark systems are used as to verify the new ASHLN‐ELM approach and to demonstrate the efficiency and the robustness of proposed method.","",""
2,"T. Schmid","Using Learning Algorithms to Create, Exploit and Maintain Knowledge Bases: Principles of Constructivist Machine Learning",2020,"","","","",146,"2022-07-13 09:39:36","","","","",,,,,2,1.00,2,1,2,"Recently, interest has grown in connecting modern machine learning approaches with traditional expert systems. This can mean, e.g, to identify patterns with neural networks and integrate them with knowledge graphs. While such combined systems offer a variety of advantages, few domainindependent approaches are known to make a hybrid artificial intelligence applicable without human interaction. To this end, we present the implementation of a constructivist machine learning framework (conML). This novel paradigm uses machine learning to manage a knowledge base and thereby allows for both raw data-based and symbolic information processing on the same internal knowledge representation. Based on axioms for a constructivist machine learning, we describe which operations are required to create, exploit and maintain a knowledge base and how these operations may be implemented with machine learning techniques. The major practical obstacle in this approach is to implement an automated deconstruction process that avoids ambiguity, handles continuous learning and allows knowledge abstraction. As we demonstrate, however, these obstacles can be overcome and constructivist machine learning can be put into practice. Combining machine learning and knowledge engineering is currently considered a potential game changing advancement in artificial intelligence. Neural networks and other machine learning techniques have proven strength in adapting to highly complex patterns and relationships, but are unable to represent existing knowledge explicitly and in an abstract fashion as expert systems can. Expert systems, on the other hand, operate on human-understandable knowledge representations but are highly domain-specific and, moreover, unable to process real-world data directly as machine learning can. Therefore, it is expected that joining both fields will produce a hybrid artificial intelligence that is “explainable, compliant and grounded in domain knowledge” (Martin et al. 2019). Such systems may, e.g., be able to identify patterns with neural networks and integrate them with knowledge graphs (Subasic, Yin, and Lin 2019). Copyright 2020 held by the author(s). In A. Martin, K. Hinkelmann, H.-G. Fill, A. Gerber, D. Lenat, R. Stolle, F. van Harmelen (Eds.), Proceedings of the AAAI 2020 Spring Symposium on Combining Machine Learning and Knowledge Engineering in Practice (AAAI-MAKE 2020). Stanford University, Palo Alto, California, USA, March 23-25, 2020. In fact, the idea of a hybrid artificial intelligence has been discussed for more than 30 years (Gallant 1988; Hendler 1989; Skeirik 1990; Levey 1991; Morik et al. 1993). So far, however, most research in this field focuses on specific knowledge or application domains like medical diagnosis (Hudson, Cohen, and Anderson 1991; Karabatak and Ince 2009; Herrmann 1995). This is to a large extent due to the fact that knowledge bases are typically created manually, which is a highly time-consuming task that requires detailled knowledge of the domain (Kidd 2012). No less timeconsuming are exploitation and maintenance of knowledge bases, which are typical follow-up phases within the life cycle of a knowledge base. While some progress has been made in employing algorithms for these tasks, several major challenges for an automated management of knowledge bases are still considered unresolved (Martinez-Gil 2015). Considering recent performance advancements in machine learning, manually managed knowledge bases obviously constitute a serious bottleneck in creating efficient hybrid systems. For truely automated systems, however, an implementable semantic interface between inductive machine learning and deductive expert systems is required. To this end, we have introduced a constructivist machine learning paradigm (Schmid 2019) based on the concept of learnable models and their storage in a knowledge base. While machine learning is currently dominated by neuro-inspired approaches, constructivist theories root in educational research (Fox 2001) and, so far, few actual implementations have been proposed for a constructivist machine learning (Drescher 1989; Quartz 1993). Central challenge for putting this into practice is the implementation of an automated deconstruction process, which to the best of our knowledge has only once been addressed successfully (Schmid 2018). Based on this paradigm, we designed a prototype for a constructivist machine learning that employs a meta databased knowledge base. Here, we present the underlying operationalizations and concepts required to put constructivist machine learning into practice. The rest of the paper is organized as follows: In section I, we lay out guidelines for automated knowledge base management. In section II, we define Stachowiak-like models as building blocks for knowledge representations. In section III, we introduce principles for constructivist machine learning processes. In section IV, we summarize our approach and point out future goals. Data Set or Stream Representation Knowledge Base select learn integrate","",""
3,"M. Halgamuge","Supervised Machine Learning Algorithms for Bioelectromagnetics: Prediction Models and Feature Selection Techniques Using Data from Weak Radiofrequency Radiation Effect on Human and Animals Cells",2020,"","","","",147,"2022-07-13 09:39:36","","10.3390/ijerph17124595","","",,,,,3,1.50,3,1,2,"The emergence of new technologies to incorporate and analyze data with high-performance computing has expanded our capability to accurately predict any incident. Supervised Machine learning (ML) can be utilized for a fast and consistent prediction, and to obtain the underlying pattern of the data better. We develop a prediction strategy, for the first time, using supervised ML to observe the possible impact of weak radiofrequency electromagnetic field (RF-EMF) on human and animal cells without performing in-vitro laboratory experiments. We extracted laboratory experimental data from 300 peer-reviewed scientific publications (1990–2015) describing 1127 experimental case studies of human and animal cells response to RF-EMF. We used domain knowledge, Principal Component Analysis (PCA), and the Chi-squared feature selection techniques to select six optimal features for computation and cost-efficiency. We then develop grouping or clustering strategies to allocate these selected features into five different laboratory experiment scenarios. The dataset has been tested with ten different classifiers, and the outputs are estimated using the k-fold cross-validation method. The assessment of a classifier’s prediction performance is critical for assessing its suitability. Hence, a detailed comparison of the percentage of the model accuracy (PCC), Root Mean Squared Error (RMSE), precision, sensitivity (recall), 1 − specificity, Area under the ROC Curve (AUC), and precision-recall (PRC Area) for each classification method were observed. Our findings suggest that the Random Forest algorithm exceeds in all groups in terms of all performance measures and shows AUC = 0.903 where k-fold = 60. A robust correlation was observed in the specific absorption rate (SAR) with frequency and cumulative effect or exposure time with SAR×time (impact of accumulated SAR within the exposure time) of RF-EMF. In contrast, the relationship between frequency and exposure time was not significant. In future, with more experimental data, the sample size can be increased, leading to more accurate work.","",""
29,"Violeta Mirchevska, M. Luštrek, M. Gams","Combining domain knowledge and machine learning for robust fall detection",2014,"","","","",148,"2022-07-13 09:39:36","","10.1111/exsy.12019","","",,,,,29,3.63,10,3,8,"This paper presents a method for combining domain knowledge and machine learning (CDKML) for classifier generation and online adaptation. The method exploits advantages in domain knowledge and machine learning as complementary information sources. Whereas machine learning may discover patterns in interest domains that are too subtle for humans to detect, domain knowledge may contain information on a domain not present in the available domain dataset. CDKML has three steps. First, prior domain knowledge is enriched with relevant patterns obtained by machine learning to create an initial classifier. Second, genetic algorithms refine the classifier. Third, the classifier is adapted online on the basis of user feedback using the Markov decision process. CDKML was applied in fall detection. Tests showed that the classifiers developed by CDKML have better performance than machine‐learning classifiers generated on a training dataset that does not adequately represent all real‐life cases of the learned concept. The accuracy of the initial classifier was 10 percentage points higher than the best machine‐learning classifier and the refinement added 3 percentage points. The online adaptation improved the accuracy of the refined classifier by an additional 15 percentage points.","",""
1,"Andrew McCarthy, Essam Ghadafi, Panagiotis Andriotis, Phil Legg","Functionality-Preserving Adversarial Machine Learning for Robust Classification in Cybersecurity and Intrusion Detection Domains: A Survey",2022,"","","","",149,"2022-07-13 09:39:36","","10.3390/jcp2010010","","",,,,,1,1.00,0,4,1,"Machine learning has become widely adopted as a strategy for dealing with a variety of cybersecurity issues, ranging from insider threat detection to intrusion and malware detection. However, by their very nature, machine learning systems can introduce vulnerabilities to a security defence whereby a learnt model is unaware of so-called adversarial examples that may intentionally result in mis-classification and therefore bypass a system. Adversarial machine learning has been a research topic for over a decade and is now an accepted but open problem. Much of the early research on adversarial examples has addressed issues related to computer vision, yet as machine learning continues to be adopted in other domains, then likewise it is important to assess the potential vulnerabilities that may occur. A key part of transferring to new domains relates to functionality-preservation, such that any crafted attack can still execute the original intended functionality when inspected by a human and/or a machine. In this literature survey, our main objective is to address the domain of adversarial machine learning attacks and examine the robustness of machine learning models in the cybersecurity and intrusion detection domains. We identify the key trends in current work observed in the literature, and explore how these relate to the research challenges that remain open for future works. Inclusion criteria were: articles related to functionality-preservation in adversarial machine learning for cybersecurity or intrusion detection with insight into robust classification. Generally, we excluded works that are not yet peer-reviewed; however, we included some significant papers that make a clear contribution to the domain. There is a risk of subjective bias in the selection of non-peer reviewed articles; however, this was mitigated by co-author review. We selected the following databases with a sizeable computer science element to search and retrieve literature: IEEE Xplore, ACM Digital Library, ScienceDirect, Scopus, SpringerLink, and Google Scholar. The literature search was conducted up to January 2022. We have striven to ensure a comprehensive coverage of the domain to the best of our knowledge. We have performed systematic searches of the literature, noting our search terms and results, and following up on all materials that appear relevant and fit within the topic domains of this review. This research was funded by the Partnership PhD scheme at the University of the West of England in collaboration with Techmodal Ltd.","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",150,"2022-07-13 09:39:36","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
0,"Ying Zhao, Lauren Jones","Integrating Human Reasoning and Machine Learning to Classify Cyber Attacks",2020,"","","","",151,"2022-07-13 09:39:36","","10.1007/978-3-030-55692-1_8","","",,,,,0,0.00,0,2,2,"","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",152,"2022-07-13 09:39:36","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
0,"Houpu Yao","Robust and Generalizable Machine Learning through Generative Models,Adversarial Training, and Physics Priors",2019,"","","","",153,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,3,"Machine learning has demonstrated great potential across a wide range of applications such as computer vision, robotics, speech recognition, drug discovery, material science, and physics simulation. Despite its current success, there are two major challenges for machine learning algorithms: limited robustness and generalizability. The robustness of a neural network is defined as the influence that input perturbations have on its final prediction. It has been shown that neural networks are very sensitive to input perturbations. For convolutional neural networks, its prediction can be totally different for input images that are visually indistinguishable to human eyes. Based on such property, hackers can reversely engineer the input to trick machine learning systems in targeted ways. These adversarial attacks have shown to be surprisingly effective, which has raised serious concerns over safety-critical applications like autonomous driving. In the meantime, how to improve the robustness of neural networks is still an open question. The generalizability of a neural network refers to its ability to be effective across a range of different inputs. On one hand, machine learning algorithms require a large number of samples from the data distribution in order to generalize well. It brings a big need for labeled data to perform supervised learning, and over-fitting on training data needs to be avoided for better generalization. On the other hand, machine learning models often fail to carry out reliable generalizations whenever there is a scarcity of supervised data. Many techniques have been proposed to improve the model generalizability; however, generalization with a few samples is still a challenging task. In this dissertation, we are thus motivated to improve the robustness and generalizability of neural networks. Firstly, unlike traditional bottom-up classifiers, we use a pre-trained generative model to perform top-down reasoning and infer the label information. The proposed generative classifier has shown to be promising in handling challenging classification tasks like adversarial attacks and input distribution shifts. Secondly, we focus on improving the network robustness and propose an extension to adversarial training by considering the transformation invariance. Proposed method improves the robustness over state-of-the-art methods by 2.5\% on MNIST, 3.7\% on CIFAR-10, and 1.1\% on restricted ImageNet. Thirdly, we focus on designing networks that generalize well at predicting physics response. Our physics prior knowledge is used to guide the designing of the network architecture, which enables efficient learning and inference. Proposed network is able to generalize well even when it is trained with a single image pair. Aerospace Engineering Doctoral Defense Robust and Generalizable Machine Learning through Generative Models, Adversarial Training, and Physics Prior Houpu Yao Advisor: Yi Ren July 12, 2019; 2:00 PM; ECG 237 School for Engineering of Matter, Transport and Energy","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",154,"2022-07-13 09:39:36","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
2,"Gareth Simons","Prediction of 'artificial' urban archetypes at the pedestrian-scale through a synthesis of domain expertise with machine learning methods",2021,"","","","",155,"2022-07-13 09:39:36","","","","",,,,,2,2.00,2,1,1,"The vitality of urban spaces has been steadily undermined by the pervasive adoption of car-centric forms of urban development as characterised by lower densities, street networks offering poor connectivity for pedestrians, and a lack of accessible land-uses; yet, even if these issues have been clearly framed for some time, the problem persists in new forms of planning. It is here posited that a synthesis of domain knowledge and machine learning methods allows for the creation of robust toolsets against which newly proposed developments can be benchmarked in a more rigorous manner in the interest of greater accountability and better-evidenced decision-making. A worked example develops a sequence of machine learning models that distinguishing ‘artificial’ towns from their more walkable and mixed-use ‘historical’ equivalents. The dataset is developed from network centrality, mixed-use, land-use accessibility, and population density measures as proxies for spatial complexity, which are computed at the pedestrian-scale for 931 towns and cities in Great Britain. Using officially designated ‘New Towns’ as a departure point, a series of clues is then developed. First, using an iterative human-in-the-loop procedure, a supervised classifier (Extra-Trees) is cultivated from which 185 ‘artificial’ locations are identified based on data aggregated to respective town or city boundaries. This information is then used to train supervised and semi-supervised (M2) deep neural network classifiers against the higher resolution dataset. The models broadly align with intuitions expressed by urbanists and show potential for continued development to broach ensuing challenges pertaining to: selection of curated training exemplars; further development of techniques to accentuate localised scales of analysis; and methods for the calibration of model probabilities to align with the intuitions of domain experts.","",""
0,"G. Truda","Quantified Sleep: Machine learning techniques for observational n-of-1 studies",2021,"","","","",156,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,1,"This paper applies statistical learning techniques to an observational Quantified-Self (QS) study to build a descriptive model of sleep quality. A total of 472 days of my sleep data was collected with an Oura ring. This was combined with a variety of lifestyle, environmental, and psychological data, harvested from multiple sensors and manual logs. Such n-of-1 QS projects pose a number of specific challenges: heterogeneous data sources with many missing values; few observations and many features; dynamic feedback loops; and human biases. This paper directly addresses these challenges with an end-to-end QS pipeline for observational studies that combines techniques from statistics and machine learning to produce robust descriptive models. Sleep quality is one of the most difficult modelling targets in QS research, due to high noise and a large number of weakly-contributing factors. Sleep quality was selected so that approaches from this paper would generalise to most other n-of-1 QS projects. Techniques are presented for combining and engineering features for the different classes of data types, sample frequencies, and schema. This includes manually-tracked event logs and automatically-sampled weather and geo-spatial data. Relevant statistical analyses for outliers, normality, (auto)correlation, stationarity, and missing data are detailed, along with a proposed method for hierarchical clustering to identify correlated groups of features. The missing data was overcome using a combination of knowledge-based and statistical techniques, including several multivariate imputation algorithms. “Markov unfolding” is presented for collapsing the time series into a collection of independent observations, whilst incorporating historical information. The final model was interpreted in two key ways: by inspecting the internal β-parameters, and using the SHAP framework, which can explain any “black box” model. These two interpretation techniques were combined to produce a list of the 16 most-predictive features, demonstrating that an observational study can greatly narrow down the number of features that need to be considered when designing interventional QS studies.","",""
0,"A. Martin, K. Hinkelmann","AAAI-MAKE 2021: Combining Machine Learning and Knowledge Engineering",2021,"","","","",157,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,2,1,"The AAAI 2021 Spring Symposium on Combining Machine Learning and Knowledge Engineering (AAAI-MAKE 2021) brought together researchers and practitioners from the machine learning and knowledge engineering fields to reflect two years later the progress on the combination of machine learning and knowledge engineering after it has been raised in the 2019 AAAI spring symposium series for the first time. With great success, many current AI solutions rely on machine/deep learning approaches, which help to solve complex tasks based on real-world data. It is most suitable for building AI systems when knowledge is not known or is tacit. While machine learning is now able to master data-intensive learning tasks, there are still some challenges. Many tasks require large amounts of training data, especially tasks where events to be predicted are rare. Often, machine output serves merely as a basis for decisions, which humans finally make. Knowledge engineering and knowledge-based systems, which make expert knowledge explicit and accessible, are often based on logic and explain their conclusions. These systems typically require a higher initial effort during development than systems that use machine learning approaches. However, symbolic machine learning and ontology learning approaches are promising for reducing the effort of knowledge engineering. Because of machine learning and knowledge engineering’s complementary strengths and weaknesses, there is a demand in business to integrate and combine both AI methods for complex business scenarios. Focusing on only one aspect will not exploit the full potential of AI. Two years after the first AAAI-MAKE symposium held in 2019 at Stanford University, the 2021 edition was held as a virtual event. The remarkable number of submissions showed a tremendous demand for combined/hybrid AI approaches. These proceedings are a collection of presented papers contributing to the symposium’s aim of combining machine learning and knowledge engineering as well as other hybrid AI and neuro-symbolic approaches/methods.","",""
0,"S. Pande, Bineet Kumar Jha","Character Recognition System for Devanagari Script Using Machine Learning Approach",2021,"","","","",158,"2022-07-13 09:39:36","","10.1109/ICCMC51019.2021.9418028","","",,,,,0,0.00,0,2,1,"It is a very difficult task to manually process the handwritten documents due to varieties of handwritten scripts and lack of associated language dictionary to interpret documents. Most of the large companies as well as small-scale industries want to automate the process of script recognition. The big challenge is to make machines recognize the hand-printed scripts. Humans can recognize handwritten or hand-printed words after gaining knowledge of a specific language. In the same way, machines should be trained to recognize the handwritten scripts. This process of transferring human knowledge to computers should be automated. The proposed research work attempts to automate the character recognition system for Devanagari script using various machine learning classifiers like Decision Tree classifier, Nearest Centroid classifier, K Nearest Neighbors classifier, Extra Trees classifiers and Random Forest classifier. The performance of all the classifiers is evaluated using accuracy parameter as success criteria. The Extra Trees classifiers and Random Forest classifier is proved to better than other classifiers with 78% and 77% of accuracy respectively. The robustness to picture quality, writing style, font size is the novelty of the OCR system which makes it ideal to use.","",""
1,"Michael Walch","Knowledge Engineering and Machine Learning for Design and Use in Cyber-Physical Environments",2019,"","","","",159,"2022-07-13 09:39:36","","","","",,,,,1,0.33,1,1,3,"A required task for developing cyber-physical systems (CPS) with people and business aspects in the loop is to capture human knowledge & design in an explicit manner. Knowledge engineering can be applied to tackle this task. Thereby, the idea is to utilize human knowledge & design in an automated manner throughout the life-cycle of CPS. In particular, one challenge is to connect conceptual models and operation environments. The former focuses on capturing and decomposing human knowledge & design about people, businesses, and CPS using semi-formal concepts that can be executed through procedures for sequential semantics, while the latter focuses on continuous-time models and CPS that operate in the physical world at run-time. By connecting conceptual models and operation environments in an intelligent manner, the s*IoT conceptual modeling approach is able to align two levels of iterpretability: one for people concerned with feasible, desirable, and viable designs and one for efficient, automated, and reliable use of CPSs. Therby, s*IoT supersedes the approach of developing application-specific interfaces between conceptual models and operation environments. Rather, s*IoT employs the semantic web stack to reduce the human effort for developing application-specific interfaces. While this is a promising approach, the question is if the integration of machine-learning approaches offers additional benefits for s*IoT, as machine-learning approaches can presumably further eliminate human effort associated with technologies from the semantic web stack. This paper presents an arguable opinion about the issue.","",""
1,"J. Ani, Mirajul Islam, Nushrat Jahan Ria, Sharmin Akter, Abu Kaisar Mohammad Masum","Estimating Gender Based On Bengali Conventional Full Name With Various Machine Learning Techniques",2021,"","","","",160,"2022-07-13 09:39:36","","10.1109/ICCCNT51525.2021.9579927","","",,,,,1,1.00,0,5,1,"For finding patterns in data, machine learning models are being trained. Gender relations psychology looks for social norms like inter dimensionality, beliefs, social experience and self-perception, and self-respect. Training on gender based text NLP models unknowingly become acquainted with unusual patterns. In this paper, we represent gender recognition by using Bengali conventional full names. We present a review and interpretation of gender classification based on individual names in this correspondence. These days, NLP has demonstrated excellent execution in identifying human gender. In the field of knowledge, gender classification is a demonstrative binary classification phenomenon. We've used a total of seven algorithms in this research. We were added to the dataset with details regarding which features are currently used for prediction along with that it determines how these features are affected by data preprocessing model initialization and architecture selection. Our research compares those classifiers, examines the impact of pretraining moreover, assesses the robustness of the alignment preprocessing through the confusion matrix.. The proposed Neural Network outperforms most approaches and is much more reliable than other models. This model has the best weighted precision of all the models, with such a 73.04 % accuracy score.","",""
1,"Yew Kee Wong","Machine Learning and Deep Learning Technologies",2021,"","","","",161,"2022-07-13 09:39:36","","10.5121/csit.2021.111214","","",,,,,1,1.00,1,1,1,"In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studied and provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using machine learning, which is the application of advanced deep learning techniques on big data. This paper aims to analyse some of the different machine learning and deep learning algorithms and methods, aswell as the opportunities provided by the AI applications in various decision making domains.","",""
1,"Samuel Manoharan J","Flawless Detection of Herbal Plant Leaf by Machine Learning Classifier Through Two Stage Authentication Procedure",2021,"","","","",162,"2022-07-13 09:39:36","","10.36548/jaicn.2021.2.005","","",,,,,1,1.00,1,1,1,"Herbal plants are crucial to human existence for medical reasons, and they can also provide free oxygen to the environment. Many herbal plants are rich in therapeutic goods and also it includes the active elements that will benefit future generations. Many valuable plant species are being extinguished and destroyed as a result of factors such as global warming, population growth, occupational secrecy, a lack of government support for research, and a lack of knowledge about therapeutic plants. Due to the lag of dimensional factors such as length and width, many existing algorithms fail to recognize herbal leaf in all seasons with the maximum accuracy. Henceforth, the proposed algorithm focuses on the incomplete problems in the datasets in order to improve the detection rate for herbal leaf identification. The inclusions of dimension factors in the datasets are performing good results in the image segmentation process. The obtained result has been validated with a machine learning classifier when combined with ex-or gate operation is called deep knowledge-based identification. This two-stage authentication (TSA) procedure is improving the recognition rate required for the detection of herbal leaf. This fusion of image segmentation with machine learning is providing good robustness for the proposed architecture. Besides, intelligent selection of image segmentation techniques to segment the leaf from the image is improving the detection accuracy. This procedure is addressing and answering the drawbacks associated with the detection of the herbal leaf by using many Machine Learning (ML) approaches. Also, it improves the rate of detection and minimizes the classification error. From the results, it is evident that the proposed method has obtained better accuracy and other performance measures.","",""
3,"J. Nuamah, Younho Seong","A Machine Learning Approach to Predict Human Judgments in Compensatory and Noncompensatory Judgment Tasks",2019,"","","","",163,"2022-07-13 09:39:36","","10.1109/THMS.2019.2892436","","",,,,,3,1.00,2,2,3,"Traditionally, in judgment analysis, multiple linear regression based lens model, which assumes decision makers assess every cue, weigh, and combine them to make overall judgments, has been used to model and analyze human judgments. However, linear regression assumptions are limited in situations where logical rules for making decisions are not consistent with a weighting and summing formula. In this study, we sought to extend the body of knowledge in the judgment analysis research by adopting the rule-based lens model and using machine learning models to predict human judgments in compensatory and noncompensatory judgment tasks. Overall, the selected machine learning models outperformed the linear logistic regression (LgR) model in both compensatory and noncompensatory tasks. Our own results suggest that, at least for the present application, machine learning models may be better at predicting human judgments in compensatory and noncompensatory judgment tasks than linear multiple LgR models. We conclude that machine learning algorithms can yield useful models for training and decision support applications.","",""
0,"J. Manoharan","Flawless Detection of Herbal Plant Leaf by Machine Learning Classifier Through Two Stage Authentication Procedure",2021,"","","","",164,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,1,"Herbal plants are crucial to human existence for medical reasons, and they can also provide free oxygen to the environment. Many herbal plants are rich in therapeutic goods and also it includes the active elements that will benefit future generations. Many valuable plant species are being extinguished and destroyed as a result of factors such as global warming, population growth, occupational secrecy, a lack of government support for research, and a lack of knowledge about therapeutic plants. Due to the lag of dimensional factors such as length and width, many existing algorithms fail to recognize herbal leaf in all seasons with the maximum accuracy. Henceforth, the proposed algorithm focuses on the incomplete problems in the datasets in order to improve the detection rate for herbal leaf identification. The inclusions of dimension factors in the datasets are performing good results in the image segmentation process. The obtained result has been validated with a machine learning classifier when combined with ex-or gate operation is called deep knowledge-based identification. This two-stage authentication (TSA) procedure is improving the recognition rate required for the detection of herbal leaf. This fusion of image segmentation with machine learning is providing good robustness for the proposed architecture. Besides, intelligent selection of image segmentation techniques to segment the leaf from the image is improving the detection accuracy. This procedure is addressing and answering the drawbacks associated with the detection of the herbal leaf by using many Machine Learning (ML) approaches. Also, it improves the rate of detection and minimizes Journal of Artificial Intelligence and Capsule Networks (2021) Vol.03/ No.02 Pages: 125-139 http://irojournals.com/aicn/ DOI: https://doi.org/10.36548/jaicn.2021.2.005 126 ISSN: 2582-2012 (online) Submitted: 11.05.2021 Revised: 30.05.2021 Accepted: 16.06.2021 Published: 22.06.2021 the classification error. From the results, it is evident that the proposed method has obtained better accuracy and other performance measures.","",""
0,"Yew Kee Wong","The Difference of Machine Learning and Deep Learning Algorithms",2021,"","","","",165,"2022-07-13 09:39:36","","10.5121/csit.2021.111519","","",,,,,0,0.00,0,1,1,"In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studiedand provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using big data analytics, which is the application of advanced analytics techniques on big data. This paper aims to analyse some of the different machine learning algorithms and methods which can be applied to big data analysis, as well as the opportunities provided by the application of big data analytics in various decision making domains.","",""
0,"Muhao Chen","Knowledge Acquisition with Transferable and Robust Representation Learning",2020,"","","","",166,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,1,2,"My research focuses on promoting the advancement of intelligent computational systems with better awareness of commonsense and expert knowledge, which leads to more efficient information exchange of the system with people and the world. My goal, in the long term, is to leverage unified methodologies to help machines understand the relations of lexemes, entities and concepts in human languages as well as the interactions of objects in nature (such as molecules and biomolecules). In the near term, I am motivated by the objective of developing new technologies in representation learning and information extraction, and extending their use in various tasks for knowledge base construction, natural language understanding, computational biology and medicine. The challenges span over a range of fields, from the fundamental questions in the acquisition, representation and inference of knowledge, to systematic paradigms for scalable data management, mining and retrieval. In this decade, AI systems in various application domains are empowered by representation learning technologies for automatically discovering and acquiring relations, patterns and properties of objects from large-scale data. In particular, such technologies involve relational embedding, language modeling and constrained learning. My work seeks to trigger the advancement of these technologies, with focus on knowledge acquisition from data in different modalities, and in scenarios with or without plausible supervision signals. My investigation in these research directions has led to over 30 published papers, and have benefited real-world applications in various computational and interdisciplinary areas. The following of this statement presents parts of my investigation into these directions, followed by some exciting future directions that I am planning to explore.","",""
1,"Parthasarathi Pattnayak, Amiya Ranjan Panda","Innovation on Machine Learning in Healthcare Services—An Introduction",2021,"","","","",167,"2022-07-13 09:39:36","","10.1007/978-981-33-4698-7_1","","",,,,,1,1.00,1,2,1,"","",""
1,"Anay Raj","Malaria Disease Diagnosis using Machine Learning Techniques",2020,"","","","",168,"2022-07-13 09:39:36","","","","",,,,,1,0.50,1,1,2,"Malaria is a major infectious disease of humans, with roughly 200 million cases worldwide and more than 400,000 deaths per year. Malaria could be prevented, controlled, and cured more effectively if a more accurate and efficient diagnostic method was available. The standard diagnostic method for malaria is the microscopic examination of blood smears for infected erythrocytes by qualified microscopists. However, this method is inefficient and the quality of the diagnosis depends on the experience and knowledge of the microscopists. This study proposes a new and robust machine learning model based on a Convolutional neural network (CNN) to automatically classify single cells in thin blood smears on standard microscope slides as either infected or uninfected. This will help in the faster diagnosis of malaria and save valuable time for beginning the treatment.","",""
0,"Nofe Alganmi","Machine learning for the exploitation of high throughput omics data: a case study on identifying circadian disruption from human blood transcriptomic data",2019,"","","","",169,"2022-07-13 09:39:36","","10.15126/THESIS.00850560","","",,,,,0,0.00,0,1,3,"The DNA microarray is a high throughput technology that is able to scan thousands of genes simultaneously and read their expression level. However, there are many challenges associated with data. One of the main opportunities is the curse of dimensionality which makes it difficult to learn without overfitting. Therefore, we proposed an unsupervised nonlinear machine learning framework to explore the circadian rhythmic features as a case study. Auto-encoder is capable of automatically learn the microarray data features and reveal knowledge that can help in designing the complex relations between the features for a circadian disorder in the future. Features derived from unsupervised algorithms can serve as input features to supervised learning, used to build discriminative markers, and directly used as functional modules. The constructed features are typically compressed representation of input data in a lower dimension. They maintain essential information in the input but are better organized than the input with less noise or artifacts. Therefore, it is easier to build classifiers on the summarized features than raw input data, and the success of a classifier heavily depends on the choice of data representation We proved our finding using machine learning classification framework. With our representation, we could enhance simple linear SVM accuracy from 63% to 75%    We also proposed a novel machine learning approach to evaluating the circadian disruption using robust regression as a contextual anomaly detection method. The main aspect of novelty in this work is coming from applying a point anomaly detection technique with respect to a circadian rhythmicity context. To the best of our knowledge, this work is the first which introduced the use of NR1D1/NR1D2 clock genes as prior knowledge to detect genes pathways involved in response to sleep disruption. In the Circadian Disruption Detection (CDD) model, we implemented and validated a model that successfully model the normal samples. While in anomalies samples i.e. samples with significant transcription effect under the circadian disruption, the model was acting poorly. Results of the analysis of variance (ANOVA) and t-test show the benefits of using our robust multi-regression errors as a biological biomarker to detect sleep deprivation using genes microarray data. we found that there was a significant difference between the error distribution for the normal sleep and the anomalies samples at the p<0.05 level. The model used to identify a quantitative measurement for sleep disruption in human regardless of the time of the day.","",""
0,"Swagatam Biswas, Sheikh Rafiul Islam","Machine Learning-Enabled Human Activity Recognition System for Humanoid Robot",2021,"","","","",170,"2022-07-13 09:39:36","","10.1007/978-981-16-0598-7_2","","",,,,,0,0.00,0,2,1,"","",""
230,"Quanming Yao, Mengshuo Wang, H. Escalante, I. Guyon, Yi-Qi Hu, Yu-Feng Li, Wei-Wei Tu, Qiang Yang, Yang Yu","Taking Human out of Learning Applications: A Survey on Automated Machine Learning",2018,"","","","",171,"2022-07-13 09:39:36","","","","",,,,,230,57.50,26,9,4,"Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, human experts are heavily involved in every aspect of machine learning. In order to make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date but also can guide the design for new methods. Subsequently, we categorize and review the existing works from two aspects, i.e., the problem setup and the employed techniques. Finally, we provide a detailed analysis of AutoML approaches and explain the reasons underneath their successful applications. We hope this survey can serve as not only an insightful guideline for AutoML beginners but also an inspiration for future research.","",""
550,"F. Hutter, Lars Kotthoff, J. Vanschoren","Automated Machine Learning: Methods, Systems, Challenges",2019,"","","","",172,"2022-07-13 09:39:36","","10.1007/978-3-030-05318-5","","",,,,,550,183.33,183,3,3,"","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",173,"2022-07-13 09:39:36","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
2328,"Nicolas Papernot, P. Mcdaniel, Ian J. Goodfellow, S. Jha, Z. B. Celik, A. Swami","Practical Black-Box Attacks against Machine Learning",2016,"","","","",174,"2022-07-13 09:39:36","","10.1145/3052973.3053009","","",,,,,2328,388.00,388,6,6,"Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.","",""
12,"Lixiang Hong, Jinjian Lin, Shuya Li, Fangping Wan, Hui Yang, Tao Jiang, Dan Zhao, Jianyang Zeng","A novel machine learning framework for automated biomedical relation extraction from large-scale literature repositories",2020,"","","","",175,"2022-07-13 09:39:36","","10.1038/s42256-020-0189-y","","",,,,,12,6.00,2,8,2,"","",""
166,"M. Alber, A. Buganza Tepole, W. R. Cannon, S. De, S. Dura-Bernal, K. Garikipati, G. Karniadakis, W. Lytton, P. Perdikaris, L. Petzold, E. Kuhl","Integrating machine learning and multiscale modeling—perspectives, challenges, and opportunities in the biological, biomedical, and behavioral sciences",2019,"","","","",176,"2022-07-13 09:39:36","","10.1038/s41746-019-0193-y","","",,,,,166,55.33,17,11,3,"","",""
1,"K. Kalaiselvi, D. Karthika","Identifying Diseases and Diagnosis Using Machine Learning",2020,"","","","",177,"2022-07-13 09:39:36","","10.1007/978-3-030-40850-3_16","","",,,,,1,0.50,1,2,2,"","",""
1,"L. Zaadnoordijk, Tarek R. Besold, R. Cusack","The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons from Infant Learning",2020,"","","","",178,"2022-07-13 09:39:36","","","","",,,,,1,0.50,0,3,2,"After a surge in popularity of supervised Deep Learning, the desire to reduce the dependence on curated, labelled data sets and to leverage the vast quantities of unlabelled data available recently triggered renewed interest in unsupervised learning algorithms. Despite a significantly improved performance due to approaches such as the identification of disentangled latent representations, contrastive learning, and clustering optimisations, the performance of unsupervised machine learning still falls short of its hypothesised potential. Machine learning has previously taken inspiration from neuroscience and cognitive science with great success. However, this has mostly been based on adult learners with access to labels and a vast amount of prior knowledge. In order to push unsupervised machine learning forward, we argue that developmental science of infant cognition might hold the key to unlocking the next generation of unsupervised learning approaches. Conceptually, human infant learning is the closest biological parallel to artificial unsupervised learning, as infants too must learn useful representations from unlabelled data. In contrast to machine learning, these new representations are learned rapidly and from relatively few examples. Moreover, infants learn robust representations that can be used flexibly and efficiently in a number of different tasks and contexts. We identify five crucial factors enabling infants' quality and speed of learning, assess the extent to which these have already been exploited in machine learning, and propose how further adoption of these factors can give rise to previously unseen performance levels in unsupervised learning.","",""
0,"Yanning Cai, Qian Dong, Anlan Li","Application and research progress of machine learning in Bioinformatics",2020,"","","","",179,"2022-07-13 09:39:36","","10.1109/CVIDL51233.2020.00-69","","",,,,,0,0.00,0,3,2,"Artificial intelligence is an important branch of computer science, and machine learning is an important component of artificial intelligence. Machine learning enables computers to simulate human learning behavior, acquire knowledge and life skills spontaneously through learning, and constantly improve their performance in the process of learning, so as to achieve self-improvement. Bioinformatics is an interdisciplinary subject that applies mathematics and computer science to the index, classification and analysis of biomolecular information. Due to the characteristics and requirements of data in bioinformatics, many algorithms of artificial intelligence, especially machine learning, have been widely used in this field, which has greatly promoted the development of bioinformatics. This paper reviews the application and research progress of machine learning technology in bioinformatics.","",""
1,"Shengping Zhang, Huiyu Zhou, Dong Xu, M. E. Celebi, T. Bouwmans","Introduction to the Special Issue on Multimodal Machine Learning for Human Behavior Analysis",2020,"","","","",180,"2022-07-13 09:39:36","","10.1145/3381917","","",,,,,1,0.50,0,5,2,"Analyzing human behaviors in multimedia data has become one of the most interesting topics in intelligent multimedia perception. Recently, with the widespread availability of advanced visual and nonvisual sensors and a growing need for a user-friendly interface, integrating multimodality data for human behavior analysis, has received a great deal of research interests from the community of multimedia analysis. Compared to the traditional single-modality human behavior analysis, multimodality human behavior analysis provides deeper-level understanding of human identification and event detection, and a more comprehensive perspective for understanding the intrinsic interaction and connections of humans. Although the studies of human behavior analysis in multimodality data are invaluable for both academia and industry, there are many fundamental problems unsolved so far, such as learning representation of human appearance and behaviors from multiple modalities, mapping data from one modality to another to achieve cross-modality human behavior analysis, identifying and utilizing relations between elements from two or more different modalities for comprehensive behavior analysis, fusing information from two or more modalities to perform a more accurate prediction, transferring knowledge between modalities and their representations, and recovering missing modality data given the observed ones. This special issue accepted nine articles that address the challenging issues of multimodal machine learning for human behavior analysis. The first three articles focus on modeling multiple features using sparse coding. In particular, “Robust Visual Tracking Using Kernel Sparse Coding on Multiple Covariance Descriptors” proposes to use covariance matrices as descriptors to represent multiple features and then performs tracking in a sparse representation framework. “CovLets: A Second Order Descriptor for Modeling Multiple Features” proposes to aggregate local descriptors in the form of covariance descriptors into a rich descriptor by using sparse coding to learn second-order statistics of the covariance descriptors. “Action Recognition Using Form and Motion Modalities” uses hierarchal sparse coding to learn the underlying features from videos. The learned features characterize the form and motion simultaneously and therefore provide more accurate and complete feature representation. Beside sparse coding, six deep learning–based methods have also been proposed to address some issues of multimodal feature learning. “AMIL: Adversarial Multi-Instance Learning for Human Pose Estimation” proposes generative adversarial networks as the learning model, which has two residual multiple instance learning models with identical architecture. One is used as the generator, and the other is used as the discriminator. In addition to generative adversarial networks, “Multichannel Attention Refinement for Video Question Answering” proposes to tackle the Video Question Answering task—that is, the extension of image question answering in the video—from","",""
1,"Nikola Bakaric, Davor Nikolić","Automated phonetic transcription of Croatian folklore genres using supervised machine learning",2020,"","","","",181,"2022-07-13 09:39:36","","10.17234/INFUTURE.2019.16","","",,,,,1,0.50,1,2,2,"This paper aims to detect the possibilities of automatic text transcription for the purpose of preparing a corpus for further natural language processing analysis. The corpus contains various Croatian folklore genres. The transcription goal is to have one character represent one phoneme and remove spaces between accentuated and non-accentuated words. This knowledge independent system is trained using supervised learning methods and applied to the rest of the corpus using classifiers such as the naïve Bayes, k-nearest neighbour, support vector machine and others. The results are compared to a human-annotated sample to determine accuracy.","",""
4,"R. R. Batcha, M. Geetha","A Survey on IOT Based on Renewable Energy for Efficient Energy Conservation Using Machine Learning Approaches",2020,"","","","",182,"2022-07-13 09:39:36","","10.1109/ICETCE48199.2020.9091737","","",,,,,4,2.00,2,2,2,"The Internet of Things has a vision in which the web extends into this present reality which is followed by daily posts. The IoT allows articles to be detected or remotely controlled over existing system frameworks, opening doors for the unadulterated incorporation of the physical world into PC-based frameworks and providing improved efficiency, accuracy, and monetary advantage despite reduced human mediation. This breakthrough has various applications, such as urban communities focused on solar power, smart cities, micro matrices, and lights on Solar Road, etc. AI is when calculations decode gigantic knowledge arrangements to the PCs so that they can function without specific programming. This, for the most part, focuses on the development of different PC programs which may change when exposed to new information. During this period renewable vitality developed at a rate faster than some other time in history. These days people groups confronting the issue of confinement of non-sustainable power sources, so to take care of this issue the best arrangement is to utilize sustainable power sources like solar oriented vitality. Solar dependence is the planet's fastest-growing sustainable power source, steadily increasing by a standard of 40 percent in the overall limit. AI can be utilized in Probabilistic Energy Forecasting. The fundamental reason behind this is to gauge the likelihood appropriation of solar oriented power age from more than one solar-based ranch all the while. In this paper, we examined -the study on how IOT assumes a significant job in solar-powered vitality and how AI approaches are utilized in solar oriented vitality.","",""
1,"N. Howard, Naima Chouikhi, Ahsan Adeel, Katelyn Dial, Adam Howard, A. Hussain","BrainOS: A Novel Artificial Brain-Alike Automatic Machine Learning Framework",2020,"","","","",183,"2022-07-13 09:39:36","","10.3389/fncom.2020.00016","","",,,,,1,0.50,0,6,2,"Human intelligence is constituted by a multitude of cognitive functions activated either directly or indirectly by external stimuli of various kinds. Computational approaches to the cognitive sciences and to neuroscience are partly premised on the idea that computational simulations of such cognitive functions and brain operations suspected to correspond to them can help to further uncover knowledge about those functions and operations, specifically, how they might work together. These approaches are also partly premised on the idea that empirical neuroscience research, whether following on from such a simulation (as indeed simulation and empirical research are complementary) or otherwise, could help us build better artificially intelligent systems. This is based on the assumption that principles by which the brain seemingly operate, to the extent that it can be understood as computational, should at least be tested as principles for the operation of artificial systems. This paper explores some of the principles of the brain that seem to be responsible for its autonomous, problem-adaptive nature. The brain operating system (BrainOS) explicated here is an introduction to ongoing work aiming to create a robust, integrated model, combining the connectionist paradigm underlying neural networks and the symbolic paradigm underlying much else of AI. BrainOS is an automatic approach that selects the most appropriate model based on the (a) input at hand, (b) prior experience (a history of results of prior problem solving attempts), and (c) world knowledge (represented in the symbolic way and used as a means to explain its approach). It is able to accept diverse and mixed input data types, process histories and objectives, extract knowledge and infer a situational context. BrainOS is designed to be efficient through its ability to not only choose the most suitable learning model but to effectively calibrate it based on the task at hand.","",""
2,"Robert Z. Zheng, Kevin Greenberg","Effective Design in Human and Machine Learning: A Cognitive Perspective",2018,"","","","",184,"2022-07-13 09:39:36","","10.1007/978-3-319-90403-0_4","","",,,,,2,0.50,1,2,4,"","",""
3,"Patrick C. Shih","Beyond Human-in-the-Loop: Empowering End-Users with Transparent Machine Learning",2018,"","","","",185,"2022-07-13 09:39:36","","10.1007/978-3-319-90403-0_3","","",,,,,3,0.75,3,1,4,"","",""
1,"Yuntian Chen, Dongxiao Zhang","Integration of knowledge and data in machine learning",2022,"","","","",186,"2022-07-13 09:39:36","","","","",,,,,1,1.00,1,2,1,"Scientiﬁc research’s mandate is to comprehend and explore the world, as well as to improve it based on experience and knowledge. Knowledge embedding and knowledge discovery are two signif-icant methods of integrating knowledge and data. Through knowledge embedding, the barriers between knowledge and data can be eliminated, and machine learning models with physical common sense can be established. Meanwhile, humans’ understanding of the world is always limited, and knowledge discovery takes advantage of machine learning to extract new knowledge from observations. Knowledge discovery can not only assist researchers to better grasp the nature of physics, but it can also support them in conducting knowledge embedding research. A closed loop of knowledge generation and usage are formed by combining knowledge embedding with knowledge discovery, which can improve the robustness and accuracy of models and uncover previously unknown scientiﬁc principles. This study summarizes and ana-lyzes extant literature, as well as identiﬁes research gaps and future opportunities.","",""
16,"Matthew E. Taylor","Assisting Transfer-Enabled Machine Learning Algorithms: Leveraging Human Knowledge for Curriculum Design",2009,"","","","",187,"2022-07-13 09:39:36","","","","",,,,,16,1.23,16,1,13,"Transfer learning is a successful technique that significantly improves machine learning algorithms by training on a sequence of tasks rather than a single task in isolation. However, there is currently no systematic method for deciding how to construct such a sequence of tasks. In this paper, I propose that while humans are well-suited for the task of curriculum development, significant research is still necessary to better understand how to create effective curricula for machine learning algorithms.","",""
1,"S. Dankwa, Lu Yang","Securing IoT Devices: A Robust and Efficient Deep Learning with a Mixed Batch Adversarial Generation Process for CAPTCHA Security Verification",2021,"","","","",188,"2022-07-13 09:39:36","","10.3390/electronics10151798","","",,,,,1,1.00,1,2,1,"The Internet of Things environment (e.g., smart phones, smart televisions, and smart watches) ensures that the end user experience is easy, by connecting lives on web services via the internet. Integrating Internet of Things devices poses ethical risks related to data security, privacy, reliability and management, data mining, and knowledge exchange. An adversarial machine learning attack is a good practice to adopt, to strengthen the security of text-based CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), to withstand against malicious attacks from computer hackers, to protect Internet of Things devices and the end user’s privacy. The goal of this current study is to perform security vulnerability verification on adversarial text-based CAPTCHA, based on attacker–defender scenarios. Therefore, this study proposed computation-efficient deep learning with a mixed batch adversarial generation process model, which attempted to break the transferability attack, and mitigate the problem of catastrophic forgetting in the context of adversarial attack defense. After performing K-fold cross-validation, experimental results showed that the proposed defense model achieved mean accuracies in the range of 82–84% among three gradient-based adversarial attack datasets.","",""
3,"Wenxing Chen, Shuyang Dai, B. Zheng, Hao Lin","An Efficient Evaluation Method for Automobile Shells Design Based on Semi-supervised Machine Learning Strategy",2022,"","","","",189,"2022-07-13 09:39:36","","10.1088/1742-6596/2171/1/012026","","",,,,,3,3.00,1,4,1,"Automobile is one of the important modes of transportation for human travel in today’s society. Batch production in various countries in the world has also promoted the transformation of production concepts. At present, the development of the automobile industry is developing towards the trend of intelligence, personalizat-ion and sharing. Car appearance in a variety of ways, not every design is reasonable. Therefore, the main purpose of this article is to establish a scientific evaluation standard in order to large-scale test the quality of a variety of car shells design. The scientific nature is mainly reflected in combination the fluid-solid coupling knowledge and machine learning in this article, which can analyze the force of different shells in the flow field, and put out the cloud map information such as the stress, pressure and velocity of the shell. At last, analyze the best test samples and store them in the database, and then using semi-supervised heuristic algorithm to perform the sample training, the ultimate goal is to make the evaluation system more robust. The trained model can correctly evaluate each personalized car shape and give a reasonable score, which is convenient for car manufacturers to make best decision with personalized demand and scientific production.","",""
0,"M. Barandas, Duarte Folgado, Ricardo Santos, Raquel Simão, Hugo Gamboa","Uncertainty-Based Rejection in Machine Learning: Implications for Model Development and Interpretability",2022,"","","","",190,"2022-07-13 09:39:36","","10.3390/electronics11030396","","",,,,,0,0.00,0,5,1,"Uncertainty is present in every single prediction of Machine Learning (ML) models. Uncertainty Quantification (UQ) is arguably relevant, in particular for safety-critical applications. Prior research focused on the development of methods to quantify uncertainty; however, less attention has been given to how to leverage the knowledge of uncertainty in the process of model development. This work focused on applying UQ into practice, closing the gap of its utility in the ML pipeline and giving insights into how UQ is used to improve model development and its interpretability. We identified three main research questions: (1) How can UQ contribute to choosing the most suitable model for a given classification task? (2) Can UQ be used to combine different models in a principled manner? (3) Can visualization techniques improve UQ’s interpretability? These questions are answered by applying several methods to quantify uncertainty in both a simulated dataset and a real-world dataset of Human Activity Recognition (HAR). Our results showed that uncertainty quantification can increase model robustness and interpretability.","",""
0,"Lihong Peng, Jialiang Yang, Minxian Wang, Liqian Zhou","Editorial: Machine Learning-Based Methods for RNA Data Analysis",2022,"","","","",191,"2022-07-13 09:39:36","","10.3389/fgene.2022.828575","","",,,,,0,0.00,0,4,1,"RNA is a type of extremely important biological macromolecules, which play key roles in all aspects of life activities and biological processes through its interactions with other biological entities Wang et al. (2021); Zhang et al. (2021). Thus, it is critical to identify complex biological associations between RNA and other biological entities Mu et al. (2020); Deng et al. (2018). Although experimental methods have been applied to analyze RNA data, especially identify various associations between RNA molecules and complex diseases, they are usually timeconsuming and resource demanding. Machine learning aims to simulate human learning ways in real time and divide the existing content into knowledge structures to advance learning efficiency. It can effectively use available electronic data to boost learning performance or implement accurate prediction Mohri et al. (2018). Furthermore, it still improves more evidence-based decision-making in the area of life science Jordan and Mitchell (2015). With the advancement of next generation sequencing techniques, machine learning-based methods discovered a large number of useful information from abundant RNA data and thus provide an effective way for the analysis of RNA data. Consequently, through machine learning techniques, we can design powerful models and algorithms to discovery diverse associations between RNA molecules themselves (such as microRNAs, mRNA, circular RNAs, and long noncoding RNAs) and between RNA molecules and complex diseases. We can further infer novel molecular markers for diagnosis and prognosis of corresponding diseases based on the identified associations. Based on the assumption of “guilt-by-association” and machine learning technologies, accumulated computational methods have been developed to analyze RNA data Liu et al. (2020); Chu et al. (2021). However, the performance of most methods remains unsatisfying due to data complexity and heterogeneity. Therefore, this research topic serves as a forum to develop new machine learning algorithms to improve RNA data analyses. MicroRNAs (miRNAs) are a class of short and endogenous noncoding RNAs Wang et al. (2020); Chen et al. (2019a). miRNAs can control gene expression based on translational repression or messenger RNA (mRNA) degradation and exhibit strong associations with a variety of disease including neurodegenerative diseases and cancers Saliminejad et al. (2019). Chen et al. designed a few representative machine learning-based algorithms to identify potential microRNA-disease associations Chen et al. (2018, 2019b). To find robust biomarkers associated with prostate cancer, Ning et al. designed amulti-omics data fusion method by integrating directed random walk and Support Vector Machine (SVM). They compared their proposed pathway-based method with five other methods including the Median method, Mean method, component analysis method, pathway activity inference method based on Edited by: William C. Cho, QEH, Hong Kong SAR, China","",""
3,"F. Lécué, B. Abeloos, Jonathan Anctil, Manuel Bergeron, Damien Dalla-Rosa, Simon Corbeil-Letourneau, Florian Martet, Tanguy Pommellet, L. Salvan, Simon Veilleux, M. Ziaeefard","Thales XAI Platform: Adaptable Explanation of Machine Learning Systems - A Knowledge Graphs Perspective",2019,"","","","",192,"2022-07-13 09:39:36","","","","",,,,,3,1.00,0,11,3,"Explanation in Machine Learning systems has been identified to be the main asset to have for large scale deployment of Artificial Intelligence (AI) in critical systems. Explanations could be example-, features-, semantics-based or even counterfactual to potentially action on an AI system; they could be represented in many different ways e.g., textual, graphical, or visual. All representations serve different means, purpose and operators. We built the first-of-its-kind XAI (eXplainable AI) platform for critical systems i.e., Thales XAI Platform which aims at serving explanations through various forms. This paper emphasizes on the semantics-based explanations for Machine Learning systems. 1 Explainable AI in Critical Systems Motivation: The current hype of Artificial Intelligence (AI) mostly refers to the success of Machine Learning (ML) and its sub-domain of deep learning. However industries operating with critical systems are either highly regulated, or require high level of certification and robustness. Therefore, such industry constraints do limit the adoption of non deterministic and ML systems. Answers to the question of explainability will be intrinsically connected to the adoption of AI in industry at scale. Indeed explanation, which could be used for debugging intelligent systems or deciding to follow a recommendation in real-time, will increase acceptance and (business) user trust. Explainable AI (XAI) is now referring to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. Focus: Thales XAI Platform is designed to provide explanation for a ML task (classification, regression, object detection, segmentation). Although Thales XAI Platform does provide different levels of explanation e.g., example-based, featuresbased, counterfactual using textual and visual representations, we emphasis only on the semantics-based explanation through knowledge graphs. ? Copyright c © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Critical Applications: From adapting a plane trajectory, stopping a train, refitting a boat to reconfiguring a satellite, all are examples of critical situations where explanation is a must-to-have to follow an AI system decision. 2 Why Knowledge Graphs for Explainable AI? State-of-the-Art Limitations: Most approaches limits explanation of ML systems to features involved in the data and model, or at best to examples, prototypes or counterfactuals. Explanation should go beyond correlation (features importance) and numerical similarity (local explanation). Opportunity: By expanding and linking initial (training, validation and test) data with entities in knowledge graphs, (i) context is encoded, (ii) connections and relations are exposed, and (iii) inference and causation are natively supported. Knowledge graphs are used for encoding better representation of data, structuring a ML model in a more interpretable way, and adopt a semantic similarity for local (instance-based) and global (model-based) explanation. 3 Thales XAI Platform: A Knowledge Graph Perspective (Semantic) Perspective: The platform is combining ML and reasoning functionalities to expose a human-like rational as explanation when (i) recognizing an object (in a raw image) of any class in a knowledge graph, (ii) predicting a link in a knowledge graph. Thales XAI Platform is using state-of-the-art Semantic Web tools for enriching input, output (class) data with DBpedia (4, 233, 000 resources) and domain-specific knowledge graphs, usually enterprise knowledge graphs. This is a crucial step for contextualizing training, validation, test data. Explainable ML Classifications: Starting from raw images, as unstructured data, but with class labels augmented with a domain knowledge graph, Thales XAI Platform relies on existing neural network architectures to build the most appropriate models. All confidence scores of output classes on any input image are updated based on the semantic description of the output classes. For instance, an input classified as a car will have a higher overall confidence score in case some properties of car in the knowledge graph are retrieved e.g., having wheels, being on a road. In addition the platform is embedding naturally explanation i.e., properties of the objects retrieved in both the raw data and knowledge graph. Explainable Relational Learning: Starting from relational data, structured as graph, and augmented with a domain knowledge graph, Thales XAI Platform relies on existing knowledge graph embeddings frameworks to build the most appropriate models. Explanation of any link prediction is retrieved by identifying representative hotspots in the knowledge graph i.e., connected parts of the graphs that negatively impact prediction accuracy when removed.","",""
3,"H. Vardhan, P. Völgyesi, J. Sztipanovits","Machine learning assisted propeller design",2021,"","","","",193,"2022-07-13 09:39:36","","10.1145/3450267.3452001","","",,,,,3,3.00,1,3,1,"Propellers are one of the most widely used propulsive devices for generating thrust from rotational engine motion both in marine vehicles and subsonic air-crafts. Due to their simplicity, robustness and high efficiency, propellers remained the mainstream design choice over the last hundred years. On the other hand, finding the optimal application-specific geometry is still challenging. This work in progress report describes application of modern and rapidly developing Machine Learning (ML) techniques to gain novel designs. We rely on a rich set of preexisting parametric design patterns and accumulated engineering knowledge supplemented by high-fidelity simulation models to formulate the design process as a supervised learning problem. The aim of our work is to develop and evaluate machine learning models for the parametric design of propellers based on application-specific constraints. While the application of ML techniques in optimal propeller design is at a very nascent level, we believe that our early results are promising with a potentially significant impact on the overall design process. The ML-assisted design flow allows for a more automated design space exploration process with less dependency on human intuition and engineering guidance.","",""
1,"Anupam Datta, Matt Fredrikson, Klas Leino, Kaiji Lu, S. Sen, Zifan Wang","Machine Learning Explainability and Robustness: Connected at the Hip",2021,"","","","",194,"2022-07-13 09:39:36","","10.1145/3447548.3470806","","",,,,,1,1.00,0,6,1,"This tutorial examines the synergistic relationship between explainability methods for machine learning and a significant problem related to model quality: robustness against adversarial perturbations. We begin with a broad overview of approaches to explainable AI, before narrowing our focus to post-hoc explanation methods for predictive models. We discuss perspectives on what constitutes a ""good'' explanation in various settings, with an emphasis on axiomatic justifications for various explanation methods. In doing so, we will highlight the importance of an explanation method's faithfulness to the target model, as this property allows one to distinguish between explanations that are unintelligible because of the method used to produce them, and cases where a seemingly poor explanation points to model quality issues. Next, we introduce concepts surrounding adversarial robustness, including adversarial attacks as well as a range of corresponding state-of-the-art defenses. Finally, building on the knowledge presented thus far, we present key insights from the recent literature on the connections between explainability and robustness, showing that many commonly-perceived explainability issues may be caused by non-robust model behavior. Accordingly, a careful study of adversarial examples and robustness can lead to models whose explanations better appeal to human intuition and domain knowledge.","",""
0,"T. Inamura, Hiroki Yokoyama, Emre Ugur, Xavier Hinaut, M. Beetz, T. Taniguchi","Section focused on machine learning methods for high-level cognitive capabilities in robotics",2019,"","","","",195,"2022-07-13 09:39:36","","10.1080/01691864.2019.1625183","","",,,,,0,0.00,0,6,3,"Integrating highand low-level cognitive capabilities is essential for developing robotic systems that can adaptively act in our daily environment in active collaboration with humans. Recent advances in machine learning techniques, including deep learning and hierarchical Bayesian modeling, are providing us with new possibilities to integrate highand low-level cognitive capabilities in robotics. It became clear that such learning methods are indispensable to create robots that can effectively address uncertaintieswhile acting smart in the realworld. We had organized workshops, named ‘Machine Learning Methods for High-Level Cognitive Capabilities in Robotics,’ in IROS 2016 and 2017. In the workshops, we solicited excellent papers related to the demand for accelerating the synergies of lowand high-level cognitive capabilities. It would enable us to develop methods that address real-world problems in a more robust manner. Hence, we aim to share knowledge regarding stateof-the-art machine learning methods that contribute to modeling sensory-motor and cognitive capabilities in robotics and to exchange views among cutting-edge robotics researchers with a special emphasis on adaptive high-level cognition. Through the workshops, researchers from cognitive robotics, speech processing, artificial intelligence, machine learning, computer vision, natural language processing, and so on were gathered to discuss the current challenges in machine learning methods for highlevel cognitive capabilities in robotics. Typical keywords discussed in the workshop were as follows: multimodal communication, learning motor skills and segmentation of time-series information, concept formation, probabilisticmodels, language acquisition, human–robot communication and collaboration, deep learning, the theory of mind and model of others, skill transfer, Bayesian modeling, application in communicable service robots, and so on. These keywords should be organized using Figure 1, which was used in the workshop discussion in 2017. Our daily environment is full of uncertainties, with complex objects and challenging tasks. A robot is not only required to deal with things appropriately in a physical manner, but also perform logical and linguistic tasks in the real world. Consider a scenario where a human user tells a robot, ‘pleasemove it into the blue box.’ In addition to solving a manipulation task, the robot must move the target object to a particular blue box and estimatewhat ‘it’ represents. In addition to solving the manipulation task, the robot should estimate the meaning of ‘into,’ representing the relationship between ‘it’ and ‘the blue box’ in a real-world environment. When a robot attempts to communicate and collaborate with human users in a realworld environment, bridging highand low-level cognitive capabilities is critical. Low-level cognitive capabilities include physical control, behavioral motion generation, and sensory perception (node (i) in Figure 1). In contrast, high-level cognitive capabilities include logical inference, planning, and language (node (ii) in Figure 1). Conventionally, symbol-based and/or rule-based approaches have been employed to model high-level cognitive capabilities in robotics. However, it has been reported that such conventional methods could not create a robot that could address inevitable uncertainties in the physical environment and natural human–robot communications. In other words, the difficulty of direct transformation between nodes (i) and (ii) was the major cause of the low performance of natural human–robot communications. However, recent advances in machine learning techniques have provided a bridge betweennode (i) and the top node, and between node (ii) and the top node, as shown in Figure 1. It has become increasingly clear that machine learning methods are indispensable for creating robots that address uncertainties. In addition to machine learning techniques, big data in human–robot interactions through a virtual reality environment can be applied to accelerate the learning process to connect the highand low-level cognitive capabilities. We organized a new type of submission strategy at the second workshop in 2017. Authors could choose from two submission categories:","",""
0,"C. Carpenter","Machine-Learning Approach Optimizes Well Spacing",2021,"","","","",196,"2022-07-13 09:39:36","","10.2118/0921-0044-jpt","","",,,,,0,0.00,0,1,1,"This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 201698, “Finding a Trend Out of Chaos: A Machine-Learning Approach for Well-Spacing Optimization,” by Zheren Ma, Ehsan Davani, SPE, and Xiaodan Ma, SPE, Quantum Reservoir Impact, et al., prepared for the 2020 SPE Annual Technical Conference and Exhibition, originally scheduled to be held in Denver, Colorado, 5–7 October. The paper has not been peer reviewed.  Data-driven decisions powered by machine-learning (ML) methods are increasing in popularity when optimizing field development in unconventional reservoirs. However, because well performance is affected by many factors, the challenge is to uncover trends within all the noise. By leveraging basin-level knowledge captured by big data sculpting, integrating private and public data with the use of uncertainty quantification, a process the authors describe as augmented artificial intelligence (AI) can provide quick, science-based answers for well spacing and fracturing optimization and can assess the full potential of an asset in unconventional reservoirs. A case study in the Midland Basin is detailed in the complete paper.      Augmented AI is a process wherein ML and human expertise are coupled to improve solutions. The augmented AI work flow (Fig. 1) starts with data sculpting, which includes information retrieval; data cleaning and standardization; and smart, deep, and systematic data quality control (QC). Feature engineering generates all relevant parameters entering the ML model. More than 50 features have been generated for this work and categorized. The final step is to perform model tuning and ensemble, evaluating model robustness and generating model explanation and uncertainty quantification.        The complete paper provides a detailed geological background of the Permian Basin and its Wolfcamp unconventional layer, an organic-rich shale formation with tight reservoir properties.  To find a solution for the multidimensional well-spacing problem in the Permian Basin, multiple sources and types of data were gathered using publicly available sources. The detailed geological attributes, including structure, petrophysics, geochemistry, basin-level features, and cultural information (such as counties or lease boundaries) have been combined in an integrated database to extract and generate features for the ML algorithm. Most attributes are available either in a limited number of wells, mostly vertical, or through the low number of available cored wells across the basin. Therefore, a significant amount of data imputation has been processed with mapping exercises using geostatistical modeling techniques.  The mapping process augmented the ML attribute-generation step because these features were distributed in both vertical and lateral dimensions. All horizontal wells within the area of interest across the Permian Basin have been resampled with the logged and mapped information.  The geological features also are reengineered into multiple indices to reduce the number of labeled features to include in the ML process. This feature-reduction process also has helped in ranking and selecting the most-important parameters relevant to the well-spacing problem. Here, a key attribute called the shale-oil index was introduced, which is generated for the ML-driven process and is used in understanding the level of contribution of geological sweet spots to well-spacing optimization. In addition, the initial well, reservoir, or laboratory data, including logs, have been normalized before mapping and modeling to eliminate potential bias. This study has focused on Wolfcamp layers; however, both geological and engineering attribute generation work flows used for this practical ML methodology to find optimization solutions for common problems are highly applicable to other unconventional layers, such as Bone Spring or Spraberry. ","",""
0,"Janghwan Lee, Shuhui Qu, Yan Kang, Wonhyouk Jang","Multimodal Machine Learning for Display Panel Defect Layer Identification",2021,"","","","",197,"2022-07-13 09:39:36","","10.1109/ASMC51741.2021.9435664","","",,,,,0,0.00,0,4,1,"Process control in display mass production needs defect layer identification to estimate the process that causes fault conditions, which is crucial for quality fault prediction and monitoring. Defect layer identification is a labor-intensive task that requires domain knowledge of experts to make consistent decisions over multiple datasets. Sometimes, it also requires examining multiple sources of inspection images to make the final identification. In this paper, we propose a multimodal machine learning model for defect layer identification as a classification problem from multiple sources of input images. After training two single modal models from each input source, we develop a final joint fusion model to achieve the best classification performance. This work also demonstrates how to estimate the final fusion model performance without exhaustively trying all possible combinations of single modal models. In order to integrate the approach into an industrial display manufacturing defect data analytic, we propose the data coverage model, which guarantees human-level classification performance within a certain portion of data. The data coverage model improves the robustness of the multimodal model, utilizing confident learning to make a high-confidence predictions for the particle defect layer identification and adding a filter to assess whether data samples are within the coverage based on the model’s latent space density estimation. This work uses particle defects data samples in 8 different layers as a combination of TEM and STEM images from display manufacturing fabrication lines. Our experimental results show that the classification accuracy improves substantially by deploying the proposed multimodal model. The results also show that it is possible to implement the data coverage model to achieve the human expert level of defect layer classification for a portion of data to automate the task.","",""
0,"Eike Petersen, Yannik Potdevin, Esfandiar Mohammadi, S. Zidowitz, Sabrina Breyer, Dirk Nowotka, Sandra Henn, Ludwig Pechmann, M. Leucker, P. Rostalski, C. Herzog","Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Technical Challenges and Solutions",2021,"","","","",198,"2022-07-13 09:39:36","","","","",,,,,0,0.00,0,11,1,"Machine learning is expected to fuel significant improvements in medical care. To ensure that fundamental principles such as beneficence, respect for human autonomy, prevention of harm, justice, privacy, and transparency are respected, medical machine learning applications must be developed responsibly. A large number of high-level declarations of ethical principles have been put forth for this purpose, but there is a severe lack of technical guidelines explicating the practical consequences for medical machine learning. Similarly, there is currently considerable uncertainty regarding the exact regulatory requirements placed upon medical machine learning systems. In this paper, we survey the technical challenges involved in creating medical machine learning systems responsibly and in conformity with existing regulations, as well as possible solutions to address these challenges. We begin by providing a brief overview of existing regulations affecting medical machine learning, showing that properties such as safety, robustness, reliability, privacy, security, transparency, explainability, and nondiscrimination are all demanded already by existing law and regulations — albeit, in many cases, to an uncertain degree. Next, we discuss the key technical obstacles to achieving these desirable properties, and important techniques to overcome those barriers in the medical context. Since most of the technical challenges are very young and new problems frequently emerge, the scientific discourse is rapidly evolving and has not yet converged on clear best-practice solutions. Nevertheless, we aim to illuminate the underlying technical challenges, possible ways for addressing them, and their respective merits and drawbacks. In particular, we notice that distribution shift, spurious correlations, model underspecification, and data scarcity represent severe challenges in the medical context (and others) that are very difficult to solve with classical black-box deep neural networks. Important measures that may help to address these challenges include the use of large and representative datasets and federated learning as a means to that end, the careful exploitation of domain knowledge wherever feasible, the use of inherently transparent models, comprehensive model testing and verification, as well as stakeholder inclusion. ar X iv :2 10 7. 09 54 6v 1 [ cs .L G ] 2 0 Ju l 2 02 1","",""
0,"Julius Polz, Lennart Schmidt, Luca Glawion, Maximilian Graf, Christian Werner, C. Chwala, H. Mollenhauer, C. Rebmann, H. Kunstmann, J. Bumberger","Supervised and unsupervised machine-learning for automated quality control of environmental sensor data",2021,"","","","",199,"2022-07-13 09:39:36","","10.5194/EGUSPHERE-EGU21-14485","","",,,,,0,0.00,0,10,1,"<p>We can observe a global decrease of well maintained weather stations by meteorological services and governmental institutes. At the same time, environmental sensor data is increasing through the use of opportunistic or remote sensing approaches. Overall, the trend for environmental sensor networks is strongly going towards automated routines, especially for quality-control (QC) to provide usable data in near real-time. A common QC scenario is that data is being flagged manually using expert knowledge and visual inspection by humans. To reduce this tedious process and to enable near-real time data provision, machine-learning (ML) algorithms exhibit a high potential as they can be designed to imitate the experts actions.&#160;</p><p>Here we address these three common challenges when applying ML for QC: 1) Robustness to missing values in the input data. 2) Availability of training data, i.e. manual quality flags that mark erroneous data points. And 3) Generalization of the model regarding non-stationary behavior of one&#160; experimental system or changes in the experimental setup when applied to a different study area. We approach the QC problem and the related issues both as a supervised and an unsupervised learning problem using deep neural networks on the one hand and dimensionality reduction combined with clustering algorithms on the other.</p><p>We compare the different ML algorithms on two time-series datasets to test their applicability across scales and domains. One dataset consists of signal levels of 4000 commercial microwave links distributed all over Germany that can be used to monitor precipitation. The second dataset contains time-series of soil moisture and temperature from 120 sensors deployed at a small-scale measurement plot at the TERENO site &#8220;Hohes Holz&#8221;.</p><p>First results show that supervised ML provides an optimized performance for QC for an experimental system not subject to change and at the cost of a laborious preparation of the training data. The unsupervised approach is also able to separate valid from erroneous data at reasonable accuracy. However, it provides the additional benefit that it does not require manual flags and can thus be retrained more easily in case the system is subject to significant changes.&#160;</p><p>In this presentation, we discuss the performance, advantages and drawbacks of the proposed ML routines to tackle the aforementioned challenges. Thus, we aim to provide a starting point for researchers in the promising field of ML application for automated QC of environmental sensor data.</p>","",""
1,"C. He, M. Mahfouf, Luis A. Torres-Salomao","An Adaptive General Type-2 Fuzzy Logic Approach for Psychophysiological State Modeling in Real-Time Human–Machine Interfaces",2021,"","","","",200,"2022-07-13 09:39:36","","10.1109/THMS.2020.3027531","","",,,,,1,1.00,0,3,1,"In this article, a new type-2 fuzzy-based modeling approach is proposed to assess human operators’ psychophysiological states for both safety and reliability of human–machine interface systems. Such a new modeling technique combines type-2 fuzzy sets with state tracking to update the rule base through a Bayesian process. These new configurations successfully lead to an adaptive, robust, and transparent computational framework that can be utilized to identify dynamic (i.e., real time) features without prior training. The proposed framework is validated on mental arithmetic cognitive real-time experiments with ten participants. It is found that the proposed framework outperforms other paradigms (i.e., an adaptive neuro-fuzzy inference system and an adaptive general type-2 fuzzy c-means modeling approach) in terms of disturbance rejection and learning capabilities. The proposed framework achieved the best performance compared to other models that have been presented in the related literature. Therefore, the new framework can be a promising development in human–machine interface systems. It can be further utilized to develop advanced control mechanisms, investigate the origins of human compromised task performance, and identify and remedy psychophysiological breakdown in the early stages.","",""
