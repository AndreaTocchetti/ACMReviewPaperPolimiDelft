Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
1,"Sandhya Aneja, Nagender Aneja, Pg Emeroylariffion Abas, A. G. Naim","IAES International Journal of Artificial Intelligence (IJ-AI)",2021,"","","","",1,"2022-07-13 09:20:28","","","","",,,,,1,1.00,0,4,1,"Received Aug 22, 2021 Revised May 20, 2022 Accepted Jun 6, 2022 Despite substantial advances in network architecture performance, the susceptibility of adversarial attacks makes deep learning challenging to implement in safety-critical applications. This paper proposes a data-centric approach to addressing this problem. A nonlocal denoising method with different luminance values has been used to generate adversarial examples from the Modified National Institute of Standards and Technology database (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) data sets. Under perturbation, the method provided absolute accuracy improvements of up to 9.3% in the MNIST data set and 13% in the CIFAR10 data set. Training using transformed images with higher luminance values increases the robustness of the classifier. We have shown that transfer learning is disadvantageous for adversarial machine learning. The results indicate that simple adversarial examples can improve resilience and make deep learning easier to apply in various applications.","",""
0,"N. Komendantova, L. Ekenberg, W. Amann, M. Danielson, V. Koulolias","Chapter 10 The Adequacy of Artificial Intelligence Tools to Combat Misinformation",2021,"","","","",2,"2022-07-13 09:20:28","","10.1007/978-3-030-70370-7_10","","",,,,,0,0.00,0,5,1,"","",""
2,"Nistha Tandiya, E. Colbert, V. Marojevic, Jeffrey H. Reed","Biologically Inspired Artificial Intelligence Techniques",2018,"","","","",3,"2022-07-13 09:20:28","","10.1007/978-3-319-77492-3_13","","",,,,,2,0.50,1,4,4,"","",""
1,"Wenzheng Li, Wei Zhu, Jianchun Zheng","Research on Resilience Urban under the Background of New Generation Information and Communication Technology",2021,"","","","",4,"2022-07-13 09:20:28","","10.1109/ICEIEC51955.2021.9463811","","",,,,,1,1.00,0,3,1,"In view of the threats and uncertainties faced by cities and the problems that traditional urban emergency management is difficult to solve, this paper starts from the development of new generation information and communication technology, and explores the feasibility of intelligent operation and maintenance and scientific disaster prevention of urban infrastructure system supported by Internet of things, big data, artificial intelligence technology, 5G, digital twin technology to improve the robustness of cities to external disturbances Visual management and enabling the dynamic management of urban security risk are new ways to improve the robustness and adaptability of the urban, and build a security and resilience urban system of risk emergency monitoring, early warning and rescue based on the integration of perception, communication and computing.","",""
0,"Mingu Kang, HyeungKyeom Kim, Suchul Lee, Seokmin Han","Resilience against Adversarial Examples: Data-Augmentation Exploiting Generative Adversarial Networks",2021,"","","","",5,"2022-07-13 09:20:28","","10.3837/tiis.2021.11.013","","",,,,,0,0.00,0,4,1,"Recently, malware classification based on Deep Neural Networks (DNN) has gained significant attention due to the rise in popularity of artificial intelligence (AI). DNN-based malware classifiers are a novel solution to combat never-before-seen malware families because this approach is able to classify malwares based on structural characteristics rather than requiring particular signatures like traditional malware classifiers. However, these DNNbased classifiers have been found to lack robustness against malwares that are carefully crafted to evade detection. These specially crafted pieces of malware are referred to as adversarial examples. We consider a clever adversary who has a thorough knowledge of DNN-based malware classifiers and will exploit it to generate a crafty malware to fool DNN-based classifiers. In this paper, we propose a DNN-based malware classifier that becomes resilient to these kinds of attacks by exploiting Generative Adversarial Network (GAN) based data augmentation. The experimental results show that the proposed scheme classifies malware, including AEs, with a false positive rate (FPR) of 3.0% and a balanced accuracy of 70.16%. These are respective 26.1% and 18.5% enhancements when compared to a traditional DNNbased classifier that does not exploit GAN.","",""
0,"Marie Alban, Desnos Karol, Morin Luce, Zhang Lu","Expert training: Enhancing AI resilience to image coding artifacts",2022,"","","","",6,"2022-07-13 09:20:28","","10.2352/ei.2022.34.10.ipas-392","","",,,,,0,0.00,0,4,1,"—In the Machine-to-Machine (M2M) transmission context, there is a great need to reduce the amount of transmitted information using lossy compression. However, commonly used image compression methods are designed for human perception, not for Artificial Intelligence (AI) algorithms performances. It is known that these compression distortions affect many deep learning based architectures on several computer vision tasks. In this paper, we focus on the classification task and propose a new approach, named expert training, to enhance Convolutional Neural Networks (CNNs) resilience to compression distortions. We validated our approach using MnasNet and ResNet50 ar- chitectures, against image compression distortions introduced by three commonly used methods (JPEG, J2K and BPG), on the ImageNet dataset. The results showed a better robustness of these two architectures against the tested coding artifacts using the proposed expert training approach. Our code is publicly available at https://github.com/albmarie/expert training.","",""
1,"Muhammad Abdullah Hanif, M. Shafique","Dependable Deep Learning: Towards Cost-Efficient Resilience of Deep Neural Network Accelerators against Soft Errors and Permanent Faults",2020,"","","","",7,"2022-07-13 09:20:28","","10.1109/IOLTS50870.2020.9159734","","",,,,,1,0.50,1,2,2,"Deep Learning has enabled machines to learn computational models (i.e., Deep Neural Networks – DNNs) that can perform certain complex tasks with claims to be close to human-level precision. This state-of-the-art performance offered by DNNs in many Artificial Intelligence (AI) applications has paved their way to being used in several safety-critical applications where even a single failure can lead to catastrophic results. Therefore, improving the robustness of these models to hardware-induced faults (such as soft errors, aging, and manufacturing defects) is of significant importance to avoid any disastrous event. Traditional redundancy-based fault mitigation techniques cannot be employed in a wide of applications due to their high overheads, which, when coupled with the compute-intensive nature of DNNs, lead to undesirable resource consumption. In this article, we present an overview of different low-cost fault-mitigation techniques that exploit the intrinsic characteristics of DNNs to limit their overheads. We discuss how each technique can contribute to the overall resilience of a DNN-based system, and how they can be integrated together to offer resilience against multiple diverse hardware-induced reliability threats. Towards the end, we highlight several key future directions that are envisioned to help in achieving highly dependable DL-based systems.","",""
6,"Xueyuan She, Yun Long, S. Mukhopadhyay","Improving Robustness of ReRAM-based Spiking Neural Network Accelerator with Stochastic Spike-timing-dependent-plasticity",2019,"","","","",8,"2022-07-13 09:20:28","","10.1109/IJCNN.2019.8851825","","",,,,,6,2.00,2,3,3,"Spike-timing-dependent-plasticity (STDP) is an unsupervised learning algorithm for spiking neural network (SNN), which promises to achieve deeper understanding of human brain and more powerful artificial intelligence. While conventional computing system fails to simulate SNN efficiently, process-inmemory (PIM) based on devices such as ReRAM can be used in designing fast and efficient STDP based SNN accelerators, as it operates in high resemblance with biological neural network. However, the real-life implementation of such design still suffers from impact of input noise and device variation. In this work, we present a novel stochastic STDP algorithm that uses spiking frequency information to dynamically adjust synaptic behavior. The algorithm is tested in pattern recognition task with noisy input and shows accuracy improvement over deterministic STDP. In addition, we show that the new algorithm can be used for designing a robust ReRAM based SNN accelerator that has strong resilience to device variation.","",""
5,"A. Hussein, A. Chehab, A. Kayssi, I. Elhajj","Machine learning for network resilience: The start of a journey",2018,"","","","",9,"2022-07-13 09:20:28","","10.1109/SDS.2018.8370423","","",,,,,5,1.25,1,4,4,"Security is one of the main concerns facing the development of new projects in networking and communications. Another challenge is to verify that a system is working exactly as specified. On the other hand, advances in Artificial Intelligence (AI) technology have opened up new markets and opportunities for progress in critical areas such as network resiliency, health, education, energy, economic inclusion, social welfare, and the environment. AI is expected to play an increasing role in defensive and offensive measures to provide a rapid response to react to the landscape of evolving threats. Software Defined Networking (SDN), being centralized by nature, provides a global view of the network. It is the flexibility and robustness offered by programmable networking that lead us to consider the integration of these two concepts, SDN and AI. Inspired by the fascinating tactics of the human immunity system, we aim to design a general hybrid Artificial Intelligence Resiliency System (ARS) that strikes a good balance between centralized and distributed security systems that may be applicable to different network environments. In addition, we aim to investigate and leverage the latest AI techniques to improve network performance in general and resiliency in particular.","",""
3,"M. G. Sánchez-Escribano","Engineering Computational Emotion - A Reference Model for Emotion in Artificial Systems",2017,"","","","",10,"2022-07-13 09:20:28","","10.1007/978-3-319-59430-9","","",,,,,3,0.60,3,1,5,"","",""
5,"J. Varughese, R. Thenius, T. Schmickl, F. Wotawa","Quantification and Analysis of the Resilience of Two Swarm Intelligent Algorithms",2017,"","","","",11,"2022-07-13 09:20:28","","10.29007/5fhn","","",,,,,5,1.00,1,4,5,"Nature showcases swarms of animals performing various complex tasks efficiently where capabilities of individuals alone in the swarm are often quite limited. Swarm intelligence is observed when agents in the swarm follow simple rules which enable the swarm to perform certain complex tasks. This decentralized approach of nature has inspired the artificial intelligence community to apply this approach to engineered systems. Such systems are said to have no single point of failure and thus tend be more resilient. The aim of this paper is to put this notion of resilience to the test and quantify the robustness of two swarm algorithms, namely “swarmtaxis” and “FSTaxis”. The first simulation results of the effects of introducing an impairment in agent-to-agent interactions in these two swarm algorithms are presented in this paper. While the FSTaxis algorithm shows a much higher resilience to agent-to-agent communication failure, both the FSTaxis and swarmtaxis algorithms are found to have a non-zero tolerance towards such failures.","",""
1,"Danilo R. B. Araújo, Gustavo H. P. S. de Barros, C. J. A. B. Filho, J. Martins-Filho","Surrogate models assisted by neural networks to assess the resilience of networks",2017,"","","","",12,"2022-07-13 09:20:28","","10.1109/LA-CCI.2017.8285704","","",,,,,1,0.20,0,4,5,"The assessment of networks is frequently accomplished by using time-consuming analysis tools based on simulations. For example, the blocking probability of networks can be estimated by Monte Carlo simulations and the network resilience can be assessed by link or node failure simulations. We propose in this paper to use Artificial Neural Networks (ANN) to predict the robustness of networks based on simple topological metrics to avoid time-consuming failure simulations. We accomplish the training process using supervised learning based on a historical database of networks. We compare the results of our proposal with the outcome provided by targeted and random failures simulations. We show that our approach is faster than failure simulators and the ANN can mimic the same robustness evaluation provide by these simulators. We obtained an average speedup of 300 times.","",""
0,"Anas Al-Tirawi, R. Reynolds","How to Design a Trustable Cultural Algorithm Using Common Value Auctions",2021,"","","","",13,"2022-07-13 09:20:28","","10.1109/TransAI51903.2021.00022","","",,,,,0,0.00,0,2,1,"One of the major challenges facing Artificial Intelligence in the future is the design of trustworthy algorithms. In this paper four basic features of trustworthy algorithms are presented. A Cultural Algorithm based upon Common Value Auctions is presented. It is demonstrated that this framework is able to support each of these fundamental principles. The basic principles are: fairness, explainability, responsibility, and sustainability. The first three are features that are part of the Cultural Algorithm configuration used here. The fourth properties was established experimentally. It was shown that the CVA based Cultural Algorithm exhibited improved sustainability in terms of both resilience and robustness over the of a Cultural Algorithm based upon a Wisdom of the Crowds or voting approach..","",""
0,"Zhe Liu, M. Yang, W. Yan","A Framework for Image Encryption on Frequency Domain",2021,"","","","",14,"2022-07-13 09:20:28","","10.4018/978-1-5225-6313-6.CH010","","",,,,,0,0.00,0,3,1,"In this chapter, the authors propose an improved image encryption algorithm based on digital watermarking. The algorithm combines discrete wavelet transform (DWT), discrete cosine transform (DCT), and singular value decomposition (SVD) together in a DWT-DCT-SVD framework to improve the robust watermarking technique. The secret image is embedded into both high-frequency and low-frequency sub-bands of the host image; this makes it difficult to be attacked in all the sub-bands. To reduce the size of a secret key, the authors use a logistic map to generate random images so as to replace the host images. They tested the algorithm by using five types of attacks and the results indicate that the proposed algorithm has higher robustness than traditional chaotic scrambling method and the DRPE method. It shows strong resilience against the five types of attacks as well as statistical attacks.","",""
0,"F. Marulli, S. Marrone, Laura Verde","Sensitivity of Machine Learning Approaches to Fake and Untrusted Data in Healthcare Domain",2022,"","","","",15,"2022-07-13 09:20:28","","10.3390/jsan11020021","","",,,,,0,0.00,0,3,1,"Machine Learning models are susceptible to attacks, such as noise, privacy invasion, replay, false data injection, and evasion attacks, which affect their reliability and trustworthiness. Evasion attacks, performed to probe and identify potential ML-trained models’ vulnerabilities, and poisoning attacks, performed to obtain skewed models whose behavior could be driven when specific inputs are submitted, represent a severe and open issue to face in order to assure security and reliability to critical domains and systems that rely on ML-based or other AI solutions, such as healthcare and justice, for example. In this study, we aimed to perform a comprehensive analysis of the sensitivity of Artificial Intelligence approaches to corrupted data in order to evaluate their reliability and resilience. These systems need to be able to understand what is wrong, figure out how to overcome the resulting problems, and then leverage what they have learned to overcome those challenges and improve their robustness. The main research goal pursued was the evaluation of the sensitivity and responsiveness of Artificial Intelligence algorithms to poisoned signals by comparing several models solicited with both trusted and corrupted data. A case study from the healthcare domain was provided to support the pursued analyses. The results achieved with the experimental campaign were evaluated in terms of accuracy, specificity, sensitivity, F1-score, and ROC area.","",""
0,"Naiara Escudero, P. Costas, Michael W. Hardt, G. Inalhan","Machine Learning Based Visual Navigation System Architecture for Aam Operations with A Discussion on its Certifiability",2022,"","","","",16,"2022-07-13 09:20:28","","10.1109/ICNS54818.2022.9771519","","",,,,,0,0.00,0,4,1,"Advanced Air Mobility (AAM) is expected to revolutionize the future of general transportation expanding the conventional notion of air traffic to include several services carried out by autonomous aerial platforms. However, the significant challenges associated with such complex scenarios require the introduction of sophisticated technologies able to deliver the resilience, robustness, and accuracy needed to achieve safe, autonomous operations [39]. In this context, solutions based on Artificial Intelligence (AI), able to overcome some limitations found in traditional approaches, are becoming a major opportunity for the aviation industry, but, at the same time, a significant challenge with respect to the certification standards.With the focal point on further proposing a certifiable architecture for AI-enhanced vision navigation in AAM operations, this paper first, summarizes the current technologies and fusion methods applied to date to navigation purposes, to later address the certification problem. Regarding certification, it explores three specific points: 1) traditional certification procedures; 2) current status of AI homologation recommendations; and 3) other certification factors to be considered for future discussion.","",""
0,"Sandhya Aneja, Nagender Aneja, Pg Emeroylariffion Abas, A. G. Naim","Defense against adversarial attacks on deep convolutional neural networks through nonlocal denoising",2022,"","","","",17,"2022-07-13 09:20:28","","10.11591/ijai.v11.i3.pp961-968","","",,,,,0,0.00,0,4,1,"Despite substantial advances in network architecture performance, the susceptibility of adversarial attacks makes deep learning challenging to implement in safety-critical applications. This paper proposes a data-centric approach to addressing this problem. A nonlocal denoising method with different luminance values has been used to generate adversarial examples from the Modified National Institute of Standards and Technology database (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) data sets. Under perturbation, the method provided absolute accuracy improvements of up to 9.3% in the MNIST data set and 13% in the CIFAR-10 data set. Training using transformed images with higher luminance values increases the robustness of the classifier. We have shown that transfer learning is disadvantageous for adversarial machine learning. The results indicate that simple adversarial examples can improve resilience and make deep learning easier to apply in various applications.","",""
0,"Md. Saber Hossen, M. Islam, M. Shafiullah, Mir Fahim-Ul-Haque, Amjad Ali","Tunicate Swarm Algorithm for Power System Stability Enhancement in a SMIB-UPFC Network",2022,"","","","",18,"2022-07-13 09:20:28","","10.1109/ICAIS53314.2022.9743091","","",,,,,0,0.00,0,5,1,"In this paper tunicate swarm algorithm is employed to tune the power system stabilizer’s (PSS) parameters in a single machine infinite bus (SMIB) network incorporated with a unified power flow controller (UPFC). To enhance the damping of the system, the objective function based on the minimization of the damping ratio is addressed, and a widely utilized lead-lag compensator-type PSS structure is adopted. The algorithm’s ability to lead the PSS’s model regardless of the initial guess illustrates its robustness. The approach’s performance is investigated under three-phase faults, and the simulation findings verify the effectiveness of the proposed technique. The simulation results are compared to the backtracking search algorithm (BSA), a well-known population-based approach, in this sector that provides resilience in the suggested technique.","",""
0,"Anas Al-Tirawi, R. Reynolds","Using Cultural Algorithms with Common Value Auctions to Provide Sustainability in Complex Dynamic Environments",2020,"","","","",19,"2022-07-13 09:20:28","","10.1109/AIKE48582.2020.00042","","",,,,,0,0.00,0,2,2,"In Computation intelligence algorithm performance is crucial especially when the complexity of the system increases and becomes chaotic (un-predictable). In Cultural Systems many algorithms are able to predict the system performance as the complexity is linear, or non-linear. However, when it is chaotic the prediction quality decreases dramatically. In this paper, we are show that Common Value Auctions are able to distribute sufficient information through the system in order to sustain the prediction rate even on the edge of chaos. This sustainability is expressed here in terms of increased resilience and robustness. Systems that rely on wisdom of the crowd based approaches are shown not to do as well when environmental change goes from linear to non-linear, and finally to chaotic.","",""
1,"S. Mileiko, R. Shafik, A. Yakovlev, J. Edwards","A Pulse Width Modulation based Power-elastic and Robust Mixed-signal Perceptron Design",2019,"","","","",20,"2022-07-13 09:20:28","","10.23919/DATE.2019.8714806","","",,,,,1,0.33,0,4,3,"Neural networks are exerting burgeoning influence in emerging artificial intelligence applications at the micro-edge, such as sensing systems and image processing. As many of these systems are typically self-powered, their circuits are expected to be resilient and efficient in the presence of continuous power variations caused by the harvesters. In this paper, we propose a novel mixed-signal (i.e. analogue/digital) approach of designing a power-elastic perceptron using the principle of pulse width modulation (PWM). Fundamental to the design are a number of parallel inverters that transcode the input-weight pairs based on the principle of PWM duty cycle. Since PWM-based inverters are typically agnostic to amplitude and frequency variations, the perceptron shows a high degree of power elasticity and robustness under these variations. We show extensive design analysis in Cadence Analog Design Environment tool using a 3 x 3 perceptron circuit as a case study to demonstrate the resilience in the presence of parameric variations.","",""
1,"K. Thórisson","Achieving AGI within My Lifetime: Some Progress and Some Observations",2012,"","","","",21,"2022-07-13 09:20:28","","10.1007/978-3-642-34274-5_14","","",,,,,1,0.10,1,1,10,"","",""
2,"R. Azevedo, Gautam Biswas, D. Bohus, Ted Carmichael, Mark A. Finlayson, M. Hadzikadic, Catherine Havasi, E. Horvitz, T. Kanda, O. Koyejo, W. Lawless, D. Lenat, Felipe Meneguzzi, Bilge Mutlu, Jean Oh, R. Pirrone, Antoine Raux, D. Sofge, G. Sukthankar, Benjamin Van Durme","Reports of the AAAI 2010 Fall Symposia",2011,"","","","",22,"2022-07-13 09:20:28","","10.1609/aimag.v32i1.2338","","",,,,,2,0.18,0,20,11,"The Association for the Advancement of Artificial Intelligence was pleased to present the 2010 Fall Symposium Series, held Thursday through Saturday, November 11-13, at the Westin Arlington Gateway in Arlington, Virginia. The titles of the eight symposia are as follows: (1) Cognitive and Metacognitive Educational Systems; (2) Commonsense Knowledge; (3) Complex Adaptive Systems: Resilience, Robustness, and Evolvability; (4) Computational Models of Narrative; (5) Dialog with Robots; (6) Manifold Learning and Its Applications; (7) Proactive Assistant Agents ; and (8) Quantum Informatics for Cognitive, Social, and Semantic Processes. The highlights of each symposium are presented in this report.","",""
27,"Amine Belhadi, Venkatesh Mani, Sachin S. Kamble, S. A. R. Khan, Surabhi Verma","Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism: an empirical investigation",2021,"","","","",23,"2022-07-13 09:20:28","","10.1007/s10479-021-03956-x","","",,,,,27,27.00,5,5,1,"","",""
14,"S. Modgil, R. Singh, C. Hannibal","Artificial intelligence for supply chain resilience: learning from Covid-19",2021,"","","","",24,"2022-07-13 09:20:28","","10.1108/ijlm-02-2021-0094","","",,,,,14,14.00,5,3,1,"PurposeMany supply chains have faced disruption during Covid-19. Artificial intelligence (AI) is one mechanism that can be used to improve supply chain resilience by developing business continuity capabilities. This study examines how firms employ AI and consider the opportunities for AI to enhance supply chain resilience by developing visibility, risk, sourcing and distribution capabilities.Design/methodology/approachThe authors have gathered rich data by conducting semistructured interviews with 35 experts from the e-commerce supply chain. The authors have adopted a systematic approach of coding using open, axial and selective methods to map and identify the themes that represent the critical elements of AI-enabled supply chain resilience.FindingsThe results of the study highlight the emergence of five critical areas where AI can contribute to enhanced supply chain resilience; (1) transparency, (2) ensuring last-mile delivery, (3) offering personalized solutions to both upstream and downstream supply chain stakeholders, (4) minimizing the impact of disruption and (5) facilitating an agile procurement strategy.Research limitations/implicationsThe study offers interesting implications for bridging the theory–practice gap by drawing on contemporary empirical data to demonstrate how enhancing dynamic capabilities via AI technologies further strengthens supply chain resilience. The study also offers suggestions for utilizing the findings and proposes a framework to strengthen supply chain resilience through AI.Originality/valueThe study presents the dynamic capabilities for supply chain resilience through the employment of AI. AI can contribute to readying supply chains to reduce their risk of disruption through enhanced resilience.","",""
13,"Amine Belhadi, Sachin S. Kamble, S. Fosso Wamba, M. Queiroz","Building supply-chain resilience: an artificial intelligence-based technique and decision-making framework",2021,"","","","",25,"2022-07-13 09:20:28","","10.1080/00207543.2021.1950935","","",,,,,13,13.00,3,4,1,"Artificial Intelligence (AI) offers a promising solution for building and promoting more resilient supply chains. However, the literature is highly dispersed regarding the application of AI in supp...","",""
7,"F. Morales-Rodríguez, Juan Pedro Martínez-Ramón, Inmaculada Méndez, C. Ruiz-Esteban","Stress, Coping, and Resilience Before and After COVID-19: A Predictive Model Based on Artificial Intelligence in the University Environment",2021,"","","","",26,"2022-07-13 09:20:28","","10.3389/fpsyg.2021.647964","","",,,,,7,7.00,2,4,1,"The COVID-19 global health emergency has greatly impacted the educational field. Faced with unprecedented stress situations, professors, students, and families have employed various coping and resilience strategies throughout the confinement period. High and persistent stress levels are associated with other pathologies; hence, their detection and prevention are needed. Consequently, this study aimed to design a predictive model of stress in the educational field based on artificial intelligence that included certain sociodemographic variables, coping strategies, and resilience capacity, and to study the relationship between them. The non-probabilistic snowball sampling method was used, involving 337 people (73% women) from the university education community in south-eastern Spain. The Perceived Stress Scale, Stress Management Questionnaire, and Brief Resilience Scale were administered. The Statistical Package for the Social Sciences (version 24) was used to design the architecture of artificial neural networks. The results found that stress levels could be predicted by the synaptic weights of coping strategies and timing of the epidemic (before and after the implementation of isolation measures), with a predictive capacity of over 80% found in the neural network model. Additionally, direct and significant associations were identified between the use of certain coping strategies, stress levels, and resilience. The conclusions of this research are essential for effective stress detection, and therefore, early intervention in the field of educational psychology, by discussing the influence of resilience or lack thereof on the prediction of stress levels. Identifying the variables that maintain a greater predictive power in stress levels is an effective strategy to design more adjusted prevention programs and to anticipate the needs of the community.","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",27,"2022-07-13 09:20:28","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
7,"M. Hosseini, M. Parvania","Artificial intelligence for resilience enhancement of power distribution systems",2021,"","","","",28,"2022-07-13 09:20:28","","10.1016/j.tej.2020.106880","","",,,,,7,7.00,4,2,1,"","",""
59,"Jinha Jung, M. Maeda, Anjin Chang, Mahendra Bhandari, Akash Ashapure, Juan Landivar-Bowles","The potential of remote sensing and artificial intelligence as tools to improve the resilience of agriculture production systems.",2020,"","","","",29,"2022-07-13 09:20:28","","10.1016/j.copbio.2020.09.003","","",,,,,59,29.50,10,6,2,"","",""
3,"Vijay Singh, P. Chaudhary, Jyoti Taunk, C. Singh, Deepti Singh, R. S. Tomar, M. Aski, N. Konjengbam, Ranjeet Sharan Raje, Sanjay Singh, R. S. Sengar, R. Yadav, M. Pal","Fab Advances in Fabaceae for Abiotic Stress Resilience: From ‘Omics’ to Artificial Intelligence",2021,"","","","",30,"2022-07-13 09:20:28","","10.3390/ijms221910535","","",,,,,3,3.00,0,13,1,"Legumes are a better source of proteins and are richer in diverse micronutrients over the nutritional profile of widely consumed cereals. However, when exposed to a diverse range of abiotic stresses, their overall productivity and quality are hugely impacted. Our limited understanding of genetic determinants and novel variants associated with the abiotic stress response in food legume crops restricts its amelioration. Therefore, it is imperative to understand different molecular approaches in food legume crops that can be utilized in crop improvement programs to minimize the economic loss. ‘Omics’-based molecular breeding provides better opportunities over conventional breeding for diversifying the natural germplasm together with improving yield and quality parameters. Due to molecular advancements, the technique is now equipped with novel ‘omics’ approaches such as ionomics, epigenomics, fluxomics, RNomics, glycomics, glycoproteomics, phosphoproteomics, lipidomics, regulomics, and secretomics. Pan-omics—which utilizes the molecular bases of the stress response to identify genes (genomics), mRNAs (transcriptomics), proteins (proteomics), and biomolecules (metabolomics) associated with stress regulation—has been widely used for abiotic stress amelioration in food legume crops. Integration of pan-omics with novel omics approaches will fast-track legume breeding programs. Moreover, artificial intelligence (AI)-based algorithms can be utilized for simulating crop yield under changing environments, which can help in predicting the genetic gain beforehand. Application of machine learning (ML) in quantitative trait loci (QTL) mining will further help in determining the genetic determinants of abiotic stress tolerance in pulses.","",""
12,"S. Abir, S. Islam, A. Anwar, A. Mahmood, A. Oo","Building Resilience against COVID-19 Pandemic Using Artificial Intelligence, Machine Learning, and IoT: A Survey of Recent Progress",2020,"","","","",31,"2022-07-13 09:20:28","","10.3390/iot1020028","","",,,,,12,6.00,2,5,2,"Coronavirus disease 2019 (COVID-19) has significantly impacted the entire world today and stalled off regular human activities in such an unprecedented way that it will have an unforgettable footprint on the history of mankind. Different countries have adopted numerous measures to build resilience against this life-threatening disease. However, the highly contagious nature of this pandemic has challenged the traditional healthcare and treatment practices. Thus, artificial intelligence (AI) and machine learning (ML) open up new mechanisms for effective healthcare during this pandemic. AI and ML can be useful for medicine development, designing efficient diagnosis strategies and producing predictions of the disease spread. These applications are highly dependent on real-time monitoring of the patients and effective coordination of the information, where the Internet of Things (IoT) plays a key role. IoT can also help with applications such as automated drug delivery, responding to patient queries, and tracking the causes of disease spread. This paper represents a comprehensive analysis of the potential AI, ML, and IoT technologies for defending against the COVID-19 pandemic. The existing and potential applications of AI, ML, and IoT, along with a detailed analysis of the enabling tools and techniques are outlined. A critical discussion on the risks and limitations of the aforementioned technologies are also included.","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",32,"2022-07-13 09:20:28","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
7,"Meng-Leong How, Y. Chan, S. Cheah","Predictive Insights for Improving the Resilience of Global Food Security Using Artificial Intelligence",2020,"","","","",33,"2022-07-13 09:20:28","","10.3390/su12156272","","",,,,,7,3.50,2,3,2,"Unabated pressures on food systems affect food security on a global scale. A human-centric artificial intelligence-based probabilistic approach is used in this paper to perform a unified analysis of data from the Global Food Security Index (GFSI). The significance of this intuitive probabilistic reasoning approach for predictive forecasting lies in its simplicity and user-friendliness to people who may not be trained in classical computer science or in software programming. In this approach, predictive modeling using a counterfactual probabilistic reasoning analysis of the GFSI dataset can be utilized to reveal the interplay and tensions between the variables that underlie food affordability, food availability, food quality and safety, and the resilience of natural resources. Exemplars are provided in this paper to illustrate how computational simulations can be used to produce forecasts of good and bad conditions in food security using multi-variant optimizations. The forecast of these future scenarios is useful for informing policy makers and stakeholders across domain verticals, so they can make decisions that are favorable to global food security.","",""
0,"Oleksandr V Lemeshko, M. Yevdokymenko, Oleksandra Yeremenko, I. Kuzminykh","Cyber Resilience and Fault Tolerance of Artificial Intelligence Systems: EU Standards, Guidelines, and Reports",2020,"","","","",34,"2022-07-13 09:20:28","","","","",,,,,0,0.00,0,4,2,"The problem of ensuring cyber resilience and fault tolerance of artificial intelligence systems is urgent. The paper proposes methods for ensuring cyber resilience and fault tolerance of an artificial intelligence system based on existing European standards, recommendations, and reports. Collectively, the use of these methods and recommendations will make it possible to ensure complex cyber resilience and fault tolerance of the artificial intelligence system, namely databases (knowledge bases), the functionality of the system itself as a whole. The considered methods are based on the aspects of ensuring cyber resilience and fault tolerance of data centers or clouds as platforms for the deployment and implementation of artificial intelligence systems. Using the proposed solutions will increase the trust of artificial intelligence systems and will allow them to be implemented more intensively in many industries.","",""
12,"Ahmed Imteaj, M. Amini, J. Mohammadi","Leveraging Decentralized Artificial Intelligence to Enhance Resilience of Energy Networks",2019,"","","","",35,"2022-07-13 09:20:28","","10.1109/PESGM41954.2020.9281763","","",,,,,12,4.00,4,3,3,"This paper reintroduces the notion of resilience in the context of recent issues originated from climate change triggered events including severe hurricanes and wildfires. A recent example is PG&E’s forced power outage to contain wildfire risk which led to widespread power disruption. This paper focuses on answering two questions: who is responsible for resilience? and how to quantify the monetary value of resilience? To this end, we first provide preliminary definitions of resilience for power systems. We then investigate the role of natural hazards, especially wildfire, on power system resilience. Finally, we will propose a decentralized strategy for a resilient management system using distributed storage and demand response resources. Our proposed high fidelity model provides utilities, operators, and policymakers with a clearer picture for strategic decision making and preventive decisions.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",36,"2022-07-13 09:20:28","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
35,"S. Saravi, R. Kalawsky, D. Joannou, M. Rivas Casado, G. Fu, F. Meng","Use of Artificial Intelligence to Improve Resilience and Preparedness Against Adverse Flood Events",2019,"","","","",37,"2022-07-13 09:20:28","","10.3390/W11050973","","",,,,,35,11.67,6,6,3,"The main focus of this paper is the novel use of Artificial Intelligence (AI) in natural disaster, more specifically flooding, to improve flood resilience and preparedness. Different types of flood have varying consequences and are followed by a specific pattern. For example, a flash flood can be a result of snow or ice melt and can occur in specific geographic places and certain season. The motivation behind this research has been raised from the Building Resilience into Risk Management (BRIM) project, looking at resilience in water systems. This research uses the application of the state-of-the-art techniques i.e., AI, more specifically Machin Learning (ML) approaches on big data, collected from previous flood events to learn from the past to extract patterns and information and understand flood behaviours in order to improve resilience, prevent damage, and save lives. In this paper, various ML models have been developed and evaluated for classifying floods, i.e., flash flood, lakeshore flood, etc. using current information i.e., weather forecast in different locations. The analytical results show that the Random Forest technique provides the highest accuracy of classification, followed by J48 decision tree and Lazy methods. The classification results can lead to better decision-making on what measures can be taken for prevention and preparedness and thus improve flood resilience.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",38,"2022-07-13 09:20:28","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
3,"Y. Maruyama","The Conditions of Artificial General Intelligence: Logic, Autonomy, Resilience, Integrity, Morality, Emotion, Embodiment, and Embeddedness",2020,"","","","",39,"2022-07-13 09:20:28","","10.1007/978-3-030-52152-3_25","","",,,,,3,1.50,3,1,2,"","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",40,"2022-07-13 09:20:28","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
26,"P. Radanliev, D. D. Roure, M. V. Kleek, Omar Santos, U. Ani","Artificial intelligence in cyber physical systems",2019,"","","","",41,"2022-07-13 09:20:28","","10.1007/s00146-020-01049-0","","",,,,,26,8.67,5,5,3,"","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",42,"2022-07-13 09:20:28","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",43,"2022-07-13 09:20:28","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
0,"Bahman Zohuri, Masoud Moghaddam, Farhang Mossavar-Rahmani","Business Resilience System Integrated Artificial Intelligence System",2022,"","","","",44,"2022-07-13 09:20:28","","10.47485/2767-3901.1019","","",,,,,0,0.00,0,3,1,"By definition, “Business Resilience” is the ability for an organization to quickly adapt to an unexpected disruption(s) and prevent any ongoing workflow(s) to come to a halt and yet maintaining continuous business operations and safeguarding people, resources, assets, and overall barns equity. By the same talking, a Business Resilience System (BRS) is a combination of intelligent software and hardware combined in an integrated system. Such an integrated combination of Business Resilience System goes a step beyond Disaster Recovery (DR) by offering post-disaster strategies to avoid costly downtime, shore up vulnerability and maintain business operations in the face of additional, unexpected breaches of the daily operation of workflow in any enterprise or organization. With recent technical progress in Artificial Intelligence (AI) augmented with Machine Learning (ML) and Deep Learning sub-systems, they present an Artificial Intelligence System (AIS) and now integrating these two systems of BRS and AIS, one can offer the most intelligent system that an organization or an enterprise can own, in order to have the best possible solution in place to have the best possible technique of predication and consequently prevention and adverse events based on collective historical data within Deep Learning of Artificial Intelligence. In this paper we are present and introduce each of these systems i.e., BRS and AIS and how they can be beneficial to each other by their integration as a holistic system along with their sub-stems of Software, Hardware, Machine Learning and Deep Learning.","",""
0,"Zhong Zheng, G. Zhang, Yun Lin, Yanfang Pan, Yandong He","The Role of Artificial Intelligence Technology in Improving the Resilience of Supply Chain During COVID-19",2022,"","","","",45,"2022-07-13 09:20:28","","10.1007/978-3-030-92537-6_21","","",,,,,0,0.00,0,5,1,"","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",46,"2022-07-13 09:20:28","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
10,"O. Omitaomu, Haoran Niu","Artificial Intelligence Techniques in Smart Grid: A Survey",2021,"","","","",47,"2022-07-13 09:20:28","","10.3390/SMARTCITIES4020029","","",,,,,10,10.00,5,2,1,"The smart grid is enabling the collection of massive amounts of high-dimensional and multi-type data about the electric power grid operations, by integrating advanced metering infrastructure, control technologies, and communication technologies. However, the traditional modeling, optimization, and control technologies have many limitations in processing the data; thus, the applications of artificial intelligence (AI) techniques in the smart grid are becoming more apparent. This survey presents a structured review of the existing research into some common AI techniques applied to load forecasting, power grid stability assessment, faults detection, and security problems in the smart grid and power systems. It also provides further research challenges for applying AI technologies to realize truly smart grid systems. Finally, this survey presents opportunities of applying AI to smart grid problems. The paper concludes that the applications of AI techniques can enhance and improve the reliability and resilience of smart grid systems.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",48,"2022-07-13 09:20:28","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
2,"Francesco Ciampi, Giacomo Marzi, Riccardo Rialti","Artificial Intelligence, Big Data, Strategic Flexibility, Agility, And Organizational Resilience: A Conceptual Framework Based On Existing Literature",2018,"","","","",49,"2022-07-13 09:20:28","","","","",,,,,2,0.50,1,3,4,"In today’s economically turbulent times, it is imperative that organizations remain flexible and resilient in order to adapt themselves to an ever-changing environment. To facilitate this, organizations should rely upon pliant structures of information, whilst simultaneously continuing to incorporate more rigid infrastructures in order to allow for the collection and analysis of large amounts of both internal and external data. This juxtaposition gives rise to the need for a trade-off. While academic literature has stressed that information systems may represent a burden for organizations pursuing strategic agility, flexibility, and organizational resilience, this paper highlights the ways in which Analytical, Automatic, Adaptive, and Agile information systems - or Big Data Analytics (BDA) capable information systems - may be helpful. In particular, this paper proposes BDA capable information systems, tied with artificial intelligence capabilities, as a trade-off solution. Alongside this, it also proposes some further implications of the topic for scholars and practitioners.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",50,"2022-07-13 09:20:28","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",51,"2022-07-13 09:20:28","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",52,"2022-07-13 09:20:28","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",53,"2022-07-13 09:20:28","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
7,"Arwin Datumaya Wahyudi Sumari, A. S. Ahmad, Cognitive Artificial","The application of cognitive artificial intelligence within C4ISR framework for national resilience",2017,"","","","",54,"2022-07-13 09:20:28","","10.1109/ACDTJ.2017.8259600","","",,,,,7,1.40,2,3,5,"Cognitive Artificial Intelligence (CAI) is a new perspective in Artificial Intelligence (AI) which is aimed to emulate how human brain works in generating knowledge. Human becomes intelligent because of knowledge which grows over time in his brain. With comprehensive knowledge, he can understand the world (environment) and is able to make decision and or action on it. On the other hand, strategic decision which impacts to the continuance of having a nation and having state is a critical and crucial matter, and it should be done in precise and quick manner especially in the case of contingency and faced to mutiple-data multiple-decision-alternative problems. The most precise decision has to be based on the knowledge from extracted comprehensive information. In this paper we show you the application of CAI for National Security with Knowledge-Growing System (KGS) as the engine of decision making system. We apply the CAI to a framework called Cognitive Command, Control, Communications, Computers, Intelligence, Surveillance and Reconnaissance (C4ISR) with examples taken from a simulated of real-life case in the Defense-Security domain.","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",55,"2022-07-13 09:20:28","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
1,"Oliver Eigner, Sebastian Eresheim, Peter Kieseberg, Lukas Daniel Klausner, Martin Pirker, Torsten Priebe, S. Tjoa, F. Marulli, F. Mercaldo","Towards Resilient Artificial Intelligence: Survey and Research Issues",2021,"","","","",56,"2022-07-13 09:20:28","","10.1109/CSR51186.2021.9527986","","",,,,,1,1.00,0,9,1,"Artificial intelligence (AI) systems are becoming critical components of today’s IT landscapes. Their resilience against attacks and other environmental influences needs to be ensured just like for other IT assets. Considering the particular nature of AI, and machine learning (ML) in particular, this paper provides an overview of the emerging field of resilient AI and presents research issues the authors identify as potential future work.","",""
2,"D. Silvestro, S. Goria, T. Sterner, A. Antonelli","Optimising biodiversity protection through artificial intelligence",2021,"","","","",57,"2022-07-13 09:20:28","","10.1101/2021.04.13.439752","","",,,,,2,2.00,1,4,1,"Over a million species face extinction, carrying with them untold options for food, medicine, fibre, shelter, ecological resilience, aesthetic and cultural values. There is therefore an urgent need to design conservation policies that maximise the protection of biodiversity and its contributions to people, within the constraints of limited budgets. Here we present a novel framework for spatial conservation prioritisation that combines simulation models, reinforcement learning and ground validation to identify optimal policies. Our methodology, CAPTAIN (Conservation Area Prioritisation Through Artificial Intelligence Networks), quantifies the trade-off between the costs and benefits of area and biodiversity protection, allowing the exploration of multiple biodiversity metrics. Under a fixed budget, our model protects substantially more species from extinction than the random or naively targeted protection of areas. CAPTAIN also outperforms the most widely used software for spatial conservation prioritisation (Marxan) in 97% of cases and reduces species loss by an average of 40% under simulations, besides yielding prioritisation maps at substantially higher spatial resolution using empirical data. We find that regular biodiversity monitoring, even if simple and with a degree of inaccuracy – characteristic of citizen science surveys – substantially improves biodiversity outcomes. Given the complexity of people–nature interactions and wealth of associated data, artificial intelligence holds great promise for improving the conservation of biological and ecosystem values in a rapidly changing and resource-limited world.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",58,"2022-07-13 09:20:28","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",59,"2022-07-13 09:20:28","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
23,"A. Șerban, M. Lytras","Artificial Intelligence for Smart Renewable Energy Sector in Europe—Smart Energy Infrastructures for Next Generation Smart Cities",2020,"","","","",60,"2022-07-13 09:20:28","","10.1109/ACCESS.2020.2990123","","",,,,,23,11.50,12,2,2,"One of the most challenging areas of Future Smart Cities Research is the Smart Energy domain. Critical issues related to optimization, provision of smart customizable networks and sophisticated computational techniques and methods enabled by artificial intelligence and machine learning need further investigation. The renewable energy (RE) is a powerful resource for the future global development in the context of climate change and resources depletion. Artificial intelligence (AI) implies new rules of organizing the activities in order to respond to these new requirements. It is necessary to improve the design of the energy infrastructure, the deployment and production of RE in order to face the multiple challenges that will affect the sector’s growth and resilience.. In this research work we exploit the recent developments on the AI adoption for RE sector in European Union (EU). In this respect, we analysed (i) the efficiency of the transformation processes of the RE within the energy chain from Gross Inland Consumption to Final Energy Consumption, (ii) its implications on the structure of renewable energy by source (solar, wind, biomass etc.), (iii) the labour productivity in RE sector compared to the economy as a whole and its correlation with investments level, (iv) the implication of the adoption of AI for RE towards Future Smart Cities Research. The main contribution of this research is the development of a framework for understanding the contribution of AI in the RE sector in Europe. Another bold contribution of this work is the discussion of the implications for Future Smart Cities Research and future research directions.","",""
23,"P. Radanliev, D. de Roure, Rob Walton, M. Van Kleek, Rafael Mantilla Montalvo, L. Maddox, Omar Santos, P. Burnap, Eirini Anthi","Artificial intelligence and machine learning in dynamic cyber risk analytics at the edge",2020,"","","","",61,"2022-07-13 09:20:28","","10.1007/s42452-020-03559-4","","",,,,,23,11.50,3,9,2,"","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",62,"2022-07-13 09:20:28","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
20,"Dimitra Samara, Ioannis Magnisalis, Vassilios Peristeras","Artificial intelligence and big data in tourism: a systematic literature review",2020,"","","","",63,"2022-07-13 09:20:28","","10.1108/jhtt-12-2018-0118","","",,,,,20,10.00,7,3,2,"This paper aims to research, identify and discuss the benefits and overall role of big data and artificial intelligence (BDAI) in the tourism sector, as this is depicted in recent literature.,A systematic literature review was conducted under the McKinsey’s Global Institute (Talwar and Koury, 2017) methodological perspective that identifies the four ways (i.e. project, produce, promote and provide) in which BDAI creates value. The authors enhanced this analysis methodology by depicting relevant challenges as well.,The findings imply that BDAI create value for the tourism sector through appropriately identified disseminations. The benefits of adopting BDAI strategies include increased efficiency, productivity and profitability for tourism suppliers combined with an extremely rich and personalized experience for travellers. The authors conclude that challenges can be bypassed by adopting a BDAI strategy. Such an adoption will stand critical for the competitiveness and resilience of existing established and new players in the tourism sector.,Besides identifying the benefits that BDAI brings in the tourism sector, the research proposes a guidebook to overcome challenges when introducing such new technologies. The exploration of the BDAI literature brings important implication for managers, academicians and consumers. This is the first systematic review in an area and contributes to the broader e-commerce marketing, retailing and e-tourism research.,本论文旨在研究、指出、和讨论大数据和人工智能（BDAI）在旅游业中的优势和整体作用。这些方面也在近文献中有所提到。,本论文采用系统综述方式, 在McKinsey’s Global Institute方法论的指导下, 确认BDAI可以在四种方面（预测、产出、提高、以及提供）创造价值。我们也通过阐述相关挑战来增强这个分析方法。,本论文结果显示BDAI通过适当的传播方式来为旅游业中创造价值。采用BDAI战略的好处包括：对旅游提供商带来高效、多产、盈利, 以及对旅游者们带来极度丰富和个性化的旅游体验。我们还总结了采取BDAI战略带来的诸多挑战。采用BDAI战略对旅游业中现有和新参与者的竞争力和弹性起到至关重要的作用。,除了指出了旅游业中BDAI带来的优势, 本论文还提出了一个指南, 来指导当新科技被引进时如何克服挑战。本论文通过对BDAI文献的梳理, 其文献综述结果对经理、学者、和消费者都有重要的启示作用。本论文是首篇在BDAI领域的系统综述, 对拓展电子商务营销、零售、和电子旅游科研有着重大贡献。","",""
0,"Joe Hays, S. Ramamoorthy, Christian Tetzlaff","Editorial: Robust Artificial Intelligence for Neurorobotics",2021,"","","","",64,"2022-07-13 09:20:28","","10.3389/fnbot.2021.809903","","",,,,,0,0.00,0,3,1,"Neural computing is a powerful paradigm that has revolutionized machine learning. Building from early roots in the study of adaptive behavior and attempts to understand information processing in parallel and distributed neural architectures, modern neural networks have convincingly demonstrated successes in numerous areas—transforming the practice of computer vision, natural language processing, and even computational biology. Applications in robotics bring stringent constraints on size, weight and power constraints (SWaP), which challenge the developers of these technologies in new ways. Indeed, these requirements take us back to the roots of the field of neural computing, forcing us to ask how it could be that the human brain achieves with as little as 12 watts of power what seems to require entire server farms with state of the art computational and numerical methods. Likewise, even lowly insects demonstrate a degree of adaptivity and resilience that still defy easy explanation or computational replication. In this Research Topic, we have compiled the latest research addressing several aspects of these broadly defined challenge questions. As illustrated in Figure 1, the articles are organized into four prevailing themes: Sense, Think, Act, and Tools.","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",65,"2022-07-13 09:20:28","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",66,"2022-07-13 09:20:28","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",67,"2022-07-13 09:20:28","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",68,"2022-07-13 09:20:28","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
6,"E. Loukis, M. Maragoudakis, Niki Kyriakou","Artificial intelligence-based public sector data analytics for economic crisis policymaking",2020,"","","","",69,"2022-07-13 09:20:28","","10.1108/tg-11-2019-0113","","",,,,,6,3.00,2,3,2," Purpose Public sector has started exploiting artificial intelligence (AI) techniques, however, mainly for operational but much less for tactical or level tasks. The purpose of this study is to exploit AI for the highest strategic-level task of government: to develop an AI-based public sector data analytics methodology for supporting policymaking for one of the most serious and large-scale challenges that governments repeatedly face, the economic crises that lead to economic recessions (though the proposed methodology is of much more general applicability).   Design/methodology/approach A public sector data analytics methodology has been developed, which enables the exploitation of existing public and private sector data, through advanced processing of them using a big data-oriented AI technique, “all-relevant” feature selection, to identify characteristics of firms as well as their external environment that affect (positively or negatively) their resilience to economic crisis.   Findings A first application of the proposed public sector data analytics methodology has been conducted, using Greek firms’ data concerning the economic crisis period 2009–2014, which has led to interesting conclusions and insights, revealing factors affecting the extent of sales revenue decrease in Greek firms during the above crisis period and providing a first validation of the methodology used in this study.   Research limitations/implications This paper contributes to the advancement of two emerging highly important, for the society, but minimally researched, digital government research domains: public sector data analytics (and especially policy analytics) and government exploitation of AI. It exploits an AI feature selection algorithm, the Boruta “all-relevant” variables identification algorithm, which has been minimally exploited in the past for public sector data analytics, to support the design of public policies for addressing one of the most serious and large-scale economic challenges that governments repeatedly face: the economic crises.   Practical implications The proposed methodology allows the identification of characteristics of firms as well as their external environment that affect positively or negatively their resilience to economic crisis. This enables a better understanding of the kinds of firms that are more strongly hit by the crisis, which is quite useful for the design of public policies for supporting them; and at the same time reveals firms’ practices, resources, capabilities, etc. that enhance their ability to cope with economic crisis, to design policies for promoting them through educational and support activities.   Social implications This methodology can be very useful for the design of more effective public policies for reducing the negative impacts of economic crises on firms, and therefore mitigating their negative consequences for the society, such as unemployment, poverty and social exclusion.   Originality/value This study develops a novel approach to the exploitation of public and private sector data, based on a minimally exploited, for such purposes, AI technique (“all-relevant” feature selection), to support the design of public policies for addressing one of the most threatening disruptions that modern economies and societies repeatedly face, the economic crises. ","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",70,"2022-07-13 09:20:28","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
3,"B. Unhelkar, T. Gonsalves","Enhancing Artificial Intelligence Decision Making Frameworks to Support Leadership During Business Disruptions",2020,"","","","",71,"2022-07-13 09:20:28","","10.1109/MITP.2020.3031312","","",,,,,3,1.50,2,2,2,"Resilience is an organization's end-to-end capability to handle disruptions and recover postdisruption. This resilience depends on an organization's ability to predict disruptions and the preparedness of the leadership to handle them. Predictability and preparedness are functions of data science in the data-driven world of today's digital business. Artificial Intelligence (AI) within data science is poised to play a crucial role in making sense of data, predicting disruptions, and assisting the leaders with business continuity. AI's deep learning engine (DLE) is a tool that learns from past decisions and subsequent consequences. This article discusses enhancing the DLE with human experience resulting in a business disruption prediction framework.","",""
5,"C. Kyrkou, A. Papachristodoulou, A. Kloukiniotis, A. Papandreou, A. Lalos, K. Moustakas, T. Theocharides","Towards Artificial-Intelligence-Based Cybersecurity for Robustifying Automated Driving Systems Against Camera Sensor Attacks",2020,"","","","",72,"2022-07-13 09:20:28","","10.1109/isvlsi49217.2020.00-11","","",,,,,5,2.50,1,7,2,"CARAMEL is a European project that aims amongst others to improve and extend cyberthreat detection and mitigation techniques for automotive driving systems. This paper highlights the important role that advanced artificial intelligence and machine learning techniques can have in proactively addressing modern autonomous vehicle cybersecurity challenges and on mitigating associated safety risks when dealing with targetted attacks on a vehicle's camera sensors. The cybersecurity solutions developed by CARAMEL are based on powerful AI tools and algorithms to combat security risks in automated driving systems and will be hosted on embedded processors and platforms. As such, it will be possible to have a specialized anti-hacking device that addresses newly introduced technological dimensions for increased robustness and cybersecurity in addition to industry needs for high speed, low latency, functional safety, light weight, low power consumption.","",""
5,"David Abele, Sara D’Onofrio","Artificial Intelligence – The Big Picture",2020,"","","","",73,"2022-07-13 09:20:28","","10.1007/978-3-658-27941-7_2","","",,,,,5,2.50,3,2,2,"","",""
1,"P. Cook, Felicity O'Neill","Artificial Intelligence in Agribusiness is Growing in Emerging Markets",2020,"","","","",74,"2022-07-13 09:20:28","","10.1596/34304","","",,,,,1,0.50,1,2,2,"Business models utilizing artificial intelligence can help meet rising global demand for food and support a more inclusive and sustainable food system by: (1) enhancing the resilience of farming methods; (2) reducing the cost of quality inputs and services to underserved farmers; and (3) improving market access to facilitate smallholder farmer integration into regional and global supply chains. Although nascent in emerging economies, applications for artificial intelligence in agribusiness will proliferate as farmers’ access to the Internet and adoption of smart devices increases across low-income countries.","",""
1,"L. Goldberg, Emma Quail","Leverage Utility Management and Artificial Intelligence in Today's COVID‐19 World",2020,"","","","",75,"2022-07-13 09:20:28","","10.1002/opfl.1425","","",,,,,1,0.50,1,2,2,"An Illinois water utility's ability to optimize water distribution network monitoring through artificial intelligence and automation gives it operational resilience to meet current and future challenges","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",76,"2022-07-13 09:20:28","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
0,"Rih-Teng Wu","Development and Application of Big Data Analytics and Artificial Intelligence for Structural Health Monitoring and Metamaterial Design",2020,"","","","",77,"2022-07-13 09:20:28","","10.25394/PGS.12858245.V1","","",,,,,0,0.00,0,1,2,"Recent advances in sensor technologies and data acquisition platforms have led to the era of Big Data. The rapid growth of artificial intelligence (AI), computing power and machine learning (ML) algorithms allow Big Data to be processed within affordable time constraints. This opens abundant opportunities to develop novel and efficient approaches to enhance the sustainability and resilience of Smart Cities. This work, by starting with a review of the state-of-the-art data fusion and ML techniques, focuses on the development of advanced solutions to structural health monitoring (SHM) and metamaterial design and discovery strategies. A deep convolutional neural network (CNN) based approach that is more robust against noisy data is proposed to perform structural response estimation and system identification. To efficiently detect surface defects using mobile devices with limited training data, an approach that incorporates network pruning into transfer learning is introduced for crack and corrosion detection. For metamaterial design, a reinforcement learning (RL) and a neural network based approach are proposed to reduce the computation efforts for the design of periodic and non-periodic metamaterials, respectively. Lastly, a physics-constrained deep auto-encoder (DAE) based approach is proposed to design the geometry of wave scatterers that satisfy user-defined downstream acoustic 2D wave fields. The robustness of the proposed approaches as well as their limitations are demonstrated and discussed through experimental data or/and numerical simulations. A roadmap for future works that may benefit the SHM and material design research communities is presented at the end of this dissertation.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",78,"2022-07-13 09:20:28","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",79,"2022-07-13 09:20:28","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",80,"2022-07-13 09:20:28","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",81,"2022-07-13 09:20:28","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
17,"Mosleh Hmoud Al-Adhaileh, Fawaz Waselallah Alsaade","Modelling and Prediction of Water Quality by Using Artificial Intelligence",2021,"","","","",82,"2022-07-13 09:20:28","","10.3390/SU13084259","","",,,,,17,17.00,9,2,1,"Artificial intelligence methods can remarkably reduce costs for water supply and sanitation systems and help ensure compliance with the quality of drinking and wastewater treatment. Therefore, modelling and predicting water quality to control water pollution has been widely researched. The novelty of the proposed system is presented to develop an efficient operation of monitoring drinking water to ensure a sustainable and friendly green environment. In this work, the adaptive neuro-fuzzy inference system (ANFIS) algorithm was developed to predict the water quality index (WQI). Feed-forward neural network (FFNN) and K-nearest neighbors were applied to classify water quality. The dataset has eight significant parameters, but seven parameters were considered to show significant values. The proposed methodology was developed based on these statistical parameters. Prediction results demonstrated that the ANFIS model was superior for the prediction of WQI values. Nevertheless, the FFNN algorithm achieved the highest accuracy (100%) for water quality classification (WQC). Furthermore, the ANFIS model accurately predicted WQI, and the FFNN model showed superior robustness in classifying the WQC. In addition, the ANFIS model showed accuracy during the testing phase, with a regression coefficient of 96.17% for predicting WQI, and the FFNN model achieved the highest accuracy (100%) for WQC. This proposed method, using advanced artificial intelligence, can aid in water treatment and management.","",""
5,"Ali Taghi-Molla, M. Rabbani, M. Gavareshki, E. Dehghani","Safety improvement in a gas refinery based on resilience engineering and macro-ergonomics indicators: a Bayesian network–artificial neural network approach",2020,"","","","",83,"2022-07-13 09:20:28","","10.1007/s13198-020-00968-x","","",,,,,5,2.50,1,4,2,"","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",84,"2022-07-13 09:20:28","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",85,"2022-07-13 09:20:28","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",86,"2022-07-13 09:20:28","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
48,"Liang Tan, Keping Yu, Fang Ming, Xiaofan Cheng, Gautam Srivastava","Secure and Resilient Artificial Intelligence of Things: A HoneyNet Approach for Threat Detection and Situational Awareness",2022,"","","","",87,"2022-07-13 09:20:28","","10.1109/MCE.2021.3081874","","",,,,,48,48.00,10,5,1,"Artificial Intelligence of Things (AIoT) is emerging as the future of Industry 4.0 and will be widely applied in consumer, commercial, and industrial fields. In AIoT, intelligent objects (smart devices), smart gateways, and edge/cloud nodes are subject to a large number of security threats and attacks. However, the traditional network security approaches are not fully suitable for AIoT. To address this issue, this article proposes a HoneyNet approach that includes both threat detection and situational awareness to enhance the security and resilience of AIoT. We first design a HoneyNet based on Docker technology that collects data to detect adversaries and monitor their attack behaviors. The collected data are then converted into images and used as samples to train a deep learning model. Finally, the trained model is deployed in AIoT to perform threat detection and provide situational awareness. To validate our scheme, we conduct HoneyNet deployment and model training on the SiteWhere AIoT platform and construct a simulation environment on this platform for threat detection and situational awareness. The experimental results demonstrate the feasibility and effectiveness of our solution.","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",88,"2022-07-13 09:20:28","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",89,"2022-07-13 09:20:28","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
6,"Dina M. El-Sherif, Mohamed Abouzid, Mohamed Tarek Elzarif, Alhassan Ali Ahmed, Ashwag Albakri, Mohammed M. Alshehri","Telehealth and Artificial Intelligence Insights into Healthcare during the COVID-19 Pandemic",2022,"","","","",90,"2022-07-13 09:20:28","","10.3390/healthcare10020385","","",,,,,6,6.00,1,6,1,"Soon after the coronavirus disease 2019 pandemic was proclaimed, digital health services were widely adopted to respond to this public health emergency, including comprehensive monitoring technologies, telehealth, creative diagnostic, and therapeutic decision-making methods. The World Health Organization suggested that artificial intelligence might be a valuable way of dealing with the crisis. Artificial intelligence is an essential technology of the fourth industrial revolution that is a critical nonmedical intervention for overcoming the present global health crisis, developing next-generation pandemic preparation, and regaining resilience. While artificial intelligence has much potential, it raises fundamental privacy, transparency, and safety concerns. This study seeks to address these issues and looks forward to an intelligent healthcare future based on best practices and lessons learned by employing telehealth and artificial intelligence during the COVID-19 pandemic.","",""
5,"P. Radanliev, D. D. Roure, R. Nicolescu, M. Huth, Omar Santos","Digital twins: artificial intelligence and the IoT cyber-physical systems in Industry 4.0",2021,"","","","",91,"2022-07-13 09:20:28","","10.1007/S41315-021-00180-5","","",,,,,5,5.00,1,5,1,"","",""
12,"M. Yoosefzadeh-Najafabadi, D. Tulpan, M. Eskandari","Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices",2021,"","","","",92,"2022-07-13 09:20:28","","10.3390/rs13132555","","",,,,,12,12.00,4,3,1,"Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.","",""
19,"Y. Ong, Abhishek Gupta","AIR5: Five Pillars of Artificial Intelligence Research",2018,"","","","",93,"2022-07-13 09:20:28","","10.1109/TETCI.2019.2928344","","",,,,,19,4.75,10,2,4,"In this paper, we provide an overview of what we consider to be some of the most pressing research questions currently facing the fields of <italic>artificial and computational intelligence</italic> (AI and CI). While AI spans a range of methods that enable machines to learn from data and operate autonomously, CI serves as a means to this end by finding its niche in algorithms that are inspired by complex natural phenomena (including the working of the brain). In this paper, we demarcate the key issues surrounding these fields using five unique <italic>Rs</italic>, namely, <italic>rationalizability</italic>, <italic>resilience</italic>, <italic>reproducibility</italic>, <italic>realism</italic>, and <italic>responsibility</italic>. Notably, just as <italic>air</italic> serves as the basic element of biological life, the term AIR<sub>5</sub>—cumulatively referring to the five aforementioned <italic>Rs</italic>—is introduced herein to mark some of the basic elements of artificial life, <italic>for sustainable AI and CI</italic>. A brief summary of each of the <italic>Rs</italic> is presented, highlighting their relevance as pillars of future research in this arena.","",""
0,"You Lv","Application of 3D Animation Cluster System Based on Artificial Intelligence and Machine Learning",2022,"","","","",94,"2022-07-13 09:20:28","","10.1155/2022/2904607","","",,,,,0,0.00,0,1,1,"In many living phenomena, the behavior of social animals (such as ants, fish stocks, and birds) has attracted great attention, and many theories and models have emerged to simulate the behavior of biological communities. These studies are important in theory and practice and have wide application potential in optimization methods and product design, which leads to the so-called cluster intelligence. Development of the 3D animation system can be closely combined with cluster intelligence, and the full application of cluster intelligence is conducive to continuously improve the stability of animation system design, for animation system design to bring continuous design inspiration. The purpose of the development platform is to promote the development of enterprise projects, record each stage of the animation process in 3D, form a complete industrial chain, ensure the traceability and resilience of the whole process, and provide a comprehensive and effective solution for 3D animation production.","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",95,"2022-07-13 09:20:28","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",96,"2022-07-13 09:20:28","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",97,"2022-07-13 09:20:28","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
0,"R. W. Albuquerque, D. L. M. Vieira, M. E. Ferreira, L. P. Soares, S. Olsen, L. S. Araujo, L. E. Vicente, J. R. Tymus, C. Balieiro, M. Matsumoto, C. Grohmann","Mapping Key Indicators of Forest Restoration in the Amazon Using a Low-Cost Drone and Artificial Intelligence",2022,"","","","",98,"2022-07-13 09:20:28","","10.3390/rs14040830","","",,,,,0,0.00,0,11,1,"Monitoring the vegetation structure and species composition of forest restoration (FR) in the Brazilian Amazon is critical to ensuring its long-term benefits. Since remotely piloted aircrafts (RPAs) associated with deep learning (DL) are becoming powerful tools for vegetation monitoring, this study aims to use DL to automatically map individual crowns of Vismia (low resilience recovery indicator), Cecropia (fast recovery indicator), and trees in general (this study refers to individual crowns of all trees regardless of species as All Trees). Since All Trees can be accurately mapped, this study also aims to propose a tree crown heterogeneity index (TCHI), which estimates species diversity based on: the heterogeneity attributes/parameters of the RPA image inside the All Trees results; and the Shannon index measured by traditional fieldwork. Regarding the DL methods, this work evaluated the accuracy of the detection of individual objects, the quality of the delineation outlines and the area distribution. Except for Vismia delineation (IoU = 0.2), DL results presented accurate values in general, as F1 and IoU were always greater than 0.7 and 0.55, respectively, while Cecropia presented the most accurate results: F1 = 0.85 and IoU = 0.77. Since All Trees results were accurate, the TCHI was obtained through regression analysis between the canopy height model (CHM) heterogeneity attributes and the field plot data. Although TCHI presented robust parameters, such as p-value < 0.05, its results are considered preliminary because more data are needed to include different FR situations. Thus, the results of this work show that low-cost RPA has great potential for monitoring FR quality in the Amazon, because Vismia, Cecropia, and All Trees can be automatically mapped. Moreover, the TCHI preliminary results showed high potential in estimating species diversity. Future studies must assess domain adaptation methods for the DL results and different FR situations to improve the TCHI range of action.","",""
17,"M. Mrówczyńska, M. Sztubecka, M. Skiba, A. Bazan-Krzywoszanska, P. Bejga","The Use of Artificial Intelligence as a Tool Supporting Sustainable Development Local Policy",2019,"","","","",99,"2022-07-13 09:20:28","","10.3390/SU11154199","","",,,,,17,5.67,3,5,3,"This paper addresses the problem of noise in spa protection areas. Its aim is to determine the delimitation of the areas that exceed a permissible noise level around the sanatorium on the example of a health resort in Inowrocław. The determination of the exceedance of permissible noise levels allows us to develop directly effective local policy tools to be included in planning documents. In order to reduce noise infiltration, it is important to define environmental priorities. Taking into account their impact on the health of users in the protection area, environmental priorities enable us to introduce additional elements to street architecture. In order to properly manage space, in accordance with the idea of sustainable development, zones of environmental sensitivity—and their socio-environmental vulnerability—have been designated for assessing damage (exceeding permissible noise in health facilities) and defining methods of building resilience (proper management). This has provided the basis for a natural balance optimized for the people living in these areas. To achieve the goal above, non-linear support vector machine (SVM) networks were used. This technique allows us to classify the linearly inseparable data and to determine the optimal separation margin. The boundaries of the areas which exceeded permissible noise levels (separation margin) were estimated on the basis of noise pollution maps, created by means of the SVM technique. Thus, the study results in establishing buffer zones where it is possible to use varied land utilization in terms of form and function, as described in the planning documents. Such an activity would limit the spread of noise.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",100,"2022-07-13 09:20:28","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",101,"2022-07-13 09:20:28","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",102,"2022-07-13 09:20:28","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",103,"2022-07-13 09:20:28","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
9,"Seunghyeon Kim, Yeon-Hee Lee, Yung-kyun Noh, F. Park, Q-Schick Auh","Age-group determination of living individuals using first molar images based on artificial intelligence",2021,"","","","",104,"2022-07-13 09:20:28","","10.1038/s41598-020-80182-8","","",,,,,9,9.00,2,5,1,"","",""
9,"Farheen Naz, Anil . Kumar, A. Majumdar, R. Agrawal","Is artificial intelligence an enabler of supply chain resiliency post COVID-19? An exploratory state-of-the-art review for future research",2021,"","","","",105,"2022-07-13 09:20:28","","10.1007/s12063-021-00208-w","","",,,,,9,9.00,2,4,1,"","",""
0,"Alessio Carpegna, S. Carlo, A. Savino","Artificial Resilience in neuromorphic systems",2022,"","","","",106,"2022-07-13 09:20:28","","10.1145/3535044.3535062","","",,,,,0,0.00,0,3,1,"Biological beings are intrinsically resilient. This means that they are able to continue to perform a task even if they are partially damaged or if some parts of them don’t work as expected. This is true also for the human brain. The research in these last years, however, has been concentrated on Artificial Intelligence (AI), to try to emulate the capabilities of the brain to improve itself, learning from experience. Artificial Resilience (AR) is something not explored in detail yet. This four pages abstract present a Ph.D. path dedicated to the extensive study of Artificial Resilience in all its aspects. The study will target neuromorphic systems, in particular Spiking Neural Networks, an emerging type of neural network models that try to mimic the behavior of a biological brain in a faithful way. In addition to this they are in general more suitable for an hardware acceleration. The goal of the Ph.D. is to realize a complete neuromorphic accelerator, configurable and resilient, and to apply it to improve the resilience of other electronic systems. Such an accelerator will be able to target area- and power-constrained applications in mission-critical environments, providing a more efficient alternative to classical techniques like Error Correction Codes (ECC) or redundancy to improve the robustness of a complex electronic system.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",107,"2022-07-13 09:20:28","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",108,"2022-07-13 09:20:28","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",109,"2022-07-13 09:20:28","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
4,"J. Braun, Jochen Hausler, Wolfgang Schäfers","Artificial intelligence, news sentiment, and property market liquidity",2019,"","","","",110,"2022-07-13 09:20:28","","10.1108/jpif-08-2019-0100","","",,,,,4,1.33,1,3,3,"The purpose of this paper is to use a text-based sentiment indicator to explain variations in direct property market liquidity in the USA.,By means of an artificial neural network, market sentiment is extracted from 66,070 US real estate market news articles from the S&P Global Market Intelligence database. For training of the network, a distant supervision approach utilizing 17,822 labeled investment ideas from the crowd-sourced investment advisory platform Seeking Alpha is applied.,According to the results of autoregressive distributed lag models including contemporary and lagged sentiment as independent variables, the derived textual sentiment indicator is not only significantly linked to the depth and resilience dimensions of market liquidity (proxied by Amihud’s (2002) price impact measure), but also to the breadth dimension (proxied by transaction volume).,These results suggest an intertemporal effect of sentiment on liquidity for the direct property market. Market participants should account for this effect in terms of their investment decisions, and also when assessing and pricing liquidity risk.,This paper not only extends the literature on text-based sentiment indicators in real estate, but is also the first to apply artificial intelligence for sentiment extraction from news articles in a market liquidity setting.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",111,"2022-07-13 09:20:28","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
6,"A. Allam, S. Feuerriegel, M. Rebhan, M. Krauthammer","Analyzing Patient Trajectories With Artificial Intelligence.",2021,"","","","",112,"2022-07-13 09:20:28","","10.2196/29812","","",,,,,6,6.00,2,4,1,"In digital medicine, patient data typically record health events over time (eg, through electronic health records, wearables, or other sensing technologies) and thus form unique patient trajectories. Patient trajectories are highly predictive of the future course of diseases and therefore facilitate effective care. However, digital medicine often uses only limited patient data, consisting of health events from only a single or small number of time points while ignoring additional information encoded in patient trajectories. To analyze such rich longitudinal data, new artificial intelligence (AI) solutions are needed. In this paper, we provide an overview of the recent efforts to develop trajectory-aware AI solutions and provide suggestions for future directions. Specifically, we examine the implications for developing disease models from patient trajectories along the typical workflow in AI: problem definition, data processing, modeling, evaluation, and interpretation. We conclude with a discussion of how such AI solutions will allow the field to build robust models for personalized risk scoring, subtyping, and disease pathway discovery.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",113,"2022-07-13 09:20:28","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
7,"F. Arama, Slimane Laribi, T. Ghaitaoui","A Control Method using Artificial Intelligence in Wind Energy Conversion System",2019,"","","","",114,"2022-07-13 09:20:28","","10.46657/ajresd.2019.1.1.6","","",,,,,7,2.33,2,3,3,"This work presents a field-oriented control (FOC) of active and reactive power applied on Doubly Fed Induction Machine (DFIM) integrated in wind energy conversion system (WECS). The main objective of this work is to compare the performances of energy produced by the use of two types of controllers ( PI regulator and the neural network regulator (NN)) in order to control the wind power conversion system to compare their precision & robustness against the wind fluctuation and the impact on the quality of produced energy. A field oriented control of DEFIG stator is also presented to control the active and reactive power. To show the efficiency of the performances and the robustness of the two control methods those were analyzed and compared by simulation using Matlab/Simulink software. The results described the favoured method.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",115,"2022-07-13 09:20:28","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",116,"2022-07-13 09:20:28","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",117,"2022-07-13 09:20:28","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",118,"2022-07-13 09:20:28","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",119,"2022-07-13 09:20:28","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",120,"2022-07-13 09:20:28","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",121,"2022-07-13 09:20:28","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",122,"2022-07-13 09:20:28","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
4,"Z. Akkus, Yousof H. Aly, Itzhak Z. Attia, F. Lopez‐Jimenez, A. Arruda-Olson, P. Pellikka, S. Pislaru, G. Kane, P. Friedman, J. Oh","Artificial Intelligence (AI)-Empowered Echocardiography Interpretation: A State-of-the-Art Review",2021,"","","","",123,"2022-07-13 09:20:28","","10.3390/jcm10071391","","",,,,,4,4.00,0,10,1,"Echocardiography (Echo), a widely available, noninvasive, and portable bedside imaging tool, is the most frequently used imaging modality in assessing cardiac anatomy and function in clinical practice. On the other hand, its operator dependability introduces variability in image acquisition, measurements, and interpretation. To reduce these variabilities, there is an increasing demand for an operator- and interpreter-independent Echo system empowered with artificial intelligence (AI), which has been incorporated into diverse areas of clinical medicine. Recent advances in AI applications in computer vision have enabled us to identify conceptual and complex imaging features with the self-learning ability of AI models and efficient parallel computing power. This has resulted in vast opportunities such as providing AI models that are robust to variations with generalizability for instantaneous image quality control, aiding in the acquisition of optimal images and diagnosis of complex diseases, and improving the clinical workflow of cardiac ultrasound. In this review, we provide a state-of-the art overview of AI-empowered Echo applications in cardiology and future trends for AI-powered Echo technology that standardize measurements, aid physicians in diagnosing cardiac diseases, optimize Echo workflow in clinics, and ultimately, reduce healthcare costs.","",""
4,"O. L. Saldanha, P. Quirke, N. West, J. James, M. Loughrey, H. Grabsch, M. Salto‐Tellez, E. Alwers, Didem Cifci, Narmin Ghaffari Laleh, T. Seibel, Richard Gray, G. Hutchins, H. Brenner, T. Yuan, T. Brinker, J. Chang-Claude, Firas Khader, A. Schuppert, T. Luedde, S. Foersch, H. Muti, C. Trautwein, M. Hoffmeister, D. Truhn, J. Kather","Swarm learning for decentralized artificial intelligence in cancer histopathology",2021,"","","","",124,"2022-07-13 09:20:28","","10.1038/s41591-022-01768-5","","",,,,,4,4.00,0,26,1,"","",""
3,"Feng Xiao, Jintao Ke","Pricing, management and decision-making of financial markets with artificial intelligence: introduction to the issue",2021,"","","","",125,"2022-07-13 09:20:28","","10.1186/s40854-021-00302-9","","",,,,,3,3.00,2,2,1,"","",""
3,"M. Padmaja, S. Shitharth, K. Prasuna, Abhay Chaturvedi, P. Kshirsagar, A. Vani","Grow of Artificial Intelligence to Challenge Security in IoT Application",2021,"","","","",126,"2022-07-13 09:20:28","","10.1007/s11277-021-08725-4","","",,,,,3,3.00,1,6,1,"","",""
2,"P. W. Grimm, Maura R. Grossman, G. Cormack","Artificial Intelligence as Evidence",2021,"","","","",127,"2022-07-13 09:20:28","","","","",,,,,2,2.00,1,3,1,"This article explores issues that govern the admissibility of Artificial Intelligence (“AI”) applications in civil and criminal cases, from the perspective of a federal trial judge and two computer scientists, one of whom also is an experienced attorney. It provides a detailed yet intelligible discussion of what AI is and how it works, a history of its development, and a description of the wide variety of functions that it is designed to accomplish, stressing that AI applications are ubiquitous, both in the private and public sectors. Applications today include: health care, education, employment-related decision-making, finance, law enforcement, and the legal profession. The article underscores the importance of determining the validity of an AI application (i.e., how accurately the AI measures, classifies, or predicts what it is designed to), as well as its reliability (i.e., the consistency with which the AI produces accurate results when applied to the same or substantially similar circumstances), in deciding whether it should be admitted into evidence in civil and criminal cases. The article further discusses factors that can affect the validity and reliability of AI evidence, including bias of various types, “function creep,” lack of transparency and explainability, and the sufficiency of the objective testing of AI applications before they are released for public use. The article next provides an in-depth discussion of the evidentiary principles that govern whether AI evidence should be admitted in court cases, a topic which, at present, is not the subject of comprehensive analysis in decisional law. The focus of this discussion is on providing a step-by-step analysis of the most important issues, and the factors that affect decisions on whether to admit AI evidence. Finally, the article concludes with a discussion of practical suggestions intended to assist lawyers and judges as they are called upon to introduce, object to, or decide on whether to admit AI evidence. 1 Hon. Paul W. Grimm is a United States District Judge for the District of Maryland, and an adjunct professor at both the University of Maryland Carey School of Law and the University of Baltimore School of Law. Maura R. Grossman, J.D., Ph.D., is a Research Professor, and Gordon V. Cormack, Ph.D., is a Professor, in the David R. Cheriton School of Computer Science at the University of Waterloo. Professor Grossman is also an affiliate faculty member at the Vector Institute for Artificial Intelligence. Her work is funded, in part, by the National Sciences and Engineering Council of Canada (“NESERC”). The opinions expressed in this article are the authors’ own, and do not necessarily reflect the views of the institutions or organizations with which they are affiliated. NORTHWESTERN JOURNAL OF TECHNOLOGY AND INTELLECTUAL PROPERTY 10 INTRODUCTION .............................................................................................................. 10 I. WHAT IS “ARTIFICIAL INTELLIGENCE”? .................................................................... 14 II. WHY AI HAS COME TO THE FOREFRONT TODAY ...................................................... 17 III. THE AI TECHNOLOGY LANDSCAPE .......................................................................... 24 IV. USES OF AI IN BUSINESS AND LAW TODAY .............................................................. 32 V. ISSUES RAISED BY THE USE OF AI IN BUSINESS AND LAW TODAY ............................ 41 A. Bias ............................................................................................................... 42 B. Lack of Robust Testing for Validity and Reliability ....................................... 48 C. Failure to Monitor for Function Creep ......................................................... 51 D. Failure to Ensure Data Privacy and Data Protection .................................. 53 E. Lack of Transparency and Explainabilty ....................................................... 60 F. Lack of Accountability ................................................................................... 65 G. Lack of Resilience ......................................................................................... 72 VI. ESTABLISHING VALIDITY AND RELIABILITY ........................................................... 79 A. Testimony, Expert Testimony, or Technology? .............................................. 79 B. Benchmarks and Goodhart’s Law ................................................................. 82 VII. EVIDENTIARY PRINCIPLES THAT SHOULD BE CONSIDERED IN EVALUATING THE ADMISSIBILITY OF AI EVIDENCE IN CIVIL AND CRIMINAL TRIALS .................... 84 A. Adequacy of the Federal Rules of Evidence in Addressing the Admissibility of AI Evidence ......................................................................... 84 B. Relevance ...................................................................................................... 86 C. Authentication of AI Evidence ....................................................................... 90 D. Usefulness of the Daubert Factors in Determining Whether to Admit AI Evidence ....................................................................................................... 95 E. Practice Pointers for Lawyers and Judges .................................................... 97 CONCLUSION ............................................................................................................... 105","",""
1,"Sara R. Jordan","Challenges of Artificial Intelligence Review in a Soft Law Environment",2021,"","","","",128,"2022-07-13 09:20:28","","10.1109/MTS.2021.3123743","","",,,,,1,1.00,1,1,1,"<bold>If artificial intelligence (AI)</bold> lives up to the claims of journalists, futurists, and tech companies, then AI stands to disrupt the landscape of human cognition, social order, and political power. Within a week’s span, AI can be discussed in both positive and utopian terms as well as in negative, even apocalyptic, terms. On the positive side, AI is described as an extraordinarily confident and capable F-16 pilot <xref ref-type=""bibr"" rid=""ref2"">[2]</xref>, a panoptic gastroenterologist who misses no part of a colonoscopy <xref ref-type=""bibr"" rid=""ref3"">[3]</xref>, the all-seeing solution to mapping climate change affected regions <xref ref-type=""bibr"" rid=""ref4"">[4]</xref>, and a smartphone application able to show your body with 12% less fat and give dieting advice to achieve that goal <xref ref-type=""bibr"" rid=""ref5"">[5]</xref>. Conversely, in a similar one-week period, AI is described as a tool for the surveillance of a minority population <xref ref-type=""bibr"" rid=""ref6"">[6]</xref>, a technique for identifying the whereabouts of political protestors or dissidents <xref ref-type=""bibr"" rid=""ref7"">[7]</xref>, a rogue system that delivers arbitrary scores on high-stakes examinations <xref ref-type=""bibr"" rid=""ref8"">[8]</xref>, and a harbinger of decline for reasoning, resilience, and emotional intelligence <xref ref-type=""bibr"" rid=""ref9"">[9]</xref>. Each of these assertions rests on the interpretation of both basic and applied AI research that may or may not be deployed into the production environment of normal human lives.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",129,"2022-07-13 09:20:28","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",130,"2022-07-13 09:20:28","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",131,"2022-07-13 09:20:28","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",132,"2022-07-13 09:20:28","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",133,"2022-07-13 09:20:28","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",134,"2022-07-13 09:20:28","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",135,"2022-07-13 09:20:28","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",136,"2022-07-13 09:20:28","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",137,"2022-07-13 09:20:28","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",138,"2022-07-13 09:20:28","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",139,"2022-07-13 09:20:28","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
9,"J. Chen, Jen-Ting Chang","Route Choice Behaviour Modeling using IoT Integrated Artificial Intelligence",2021,"","","","",140,"2022-07-13 09:20:28","","10.36548/JAICN.2020.4.006","","",,,,,9,9.00,5,2,1,"Automatic Vehicle Identification (AVI) data is used to identify the location of a particular vehicle in and can also be used for route choice behaviour modelling. But the use of AVI doesn’t provide accurate information on OD pair and the particular route that is chosen. This problem is addressed in this paper using a semi-supervised learning method which can be used to identify the route on prior training. As the first step, the AVI trace is segregated into observation pairs using the Maximum Likelihood Estimation and then it is further joined with GPS co-ordinates to tackle the sparse issues. As the next step, the heterogeneity and correlation between the various pairs are determined using Mixed Logit model. As the final step, a relationship between the likelihood function and route choice model is established using Maximum to log-likelihood function. Based on the observations, the results are recorded and the proposed work shows significant improvement in the accuracy in route determination. The evaluation scenario shows that the proposed work could be expanded to a larger area. Moreover, the robustness of the system is illustrated using sensitivity analysis. This work uses AVI data with respect to its behaviour in routes through high penetration.","",""
4,"F. Negrello, M. Garabini, G. Grioli, N. Tsagarakis, A. Bicchi, M. Catalano","Benchmarking Resilience of Artificial Hands",2019,"","","","",141,"2022-07-13 09:20:28","","10.1109/ICRA.2019.8793793","","",,,,,4,1.33,1,6,3,"The deployment of robotics in real-world scenarios, which may involve harsh and irregular physical interactions with the environment, such as those when robots operating in a disaster scenario, or the interactions that prosthetic devices may experience, demands hardware, which is physically resilient. The end-effectors, as the main media of interaction, are probably the parts at the highest risk. The capability of robotic hands to survive severe impacts is thus a necessity for the effective deployment of reliable robotic solutions in real-world tasks. Although, this robustness capability has been noted and discussed in the robotics community for long time, the literature does not provide a systematic study nor there is any proposal of standardized test or metric to evaluate hand resilience. In this work, inspired by the works of Charpy and Izod for the systematic definition of resilience and toughness of materials through impact tests, we consider extending the standard test to robot hands. We introduce a resilience evaluation framework, including a precisely defined experimental set-up and test procedure. As an example of application of the procedure, we apply it to experimentally characterize two robot hands, with a similar conceptual architecture but different size and material. From these tests we obtain several insights, including the observation that the dominant factor in hand resilience is their compliance and actuation principle, and that the use, under certain design conditions, of lightweight materials, such as plastic instead of aluminum, may not necessarily reduce the mechanical strength of the overall system.","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",142,"2022-07-13 09:20:28","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
7,"O. H. Maghsoudi, A. Gastounioti, Christopher Scott, L. Pantalone, Fang-Fang Wu, E. Cohen, S. Winham, E. Conant, C. Vachon, D. Kontos","Deep-LIBRA: Artificial intelligence method for robust quantification of breast density with independent validation in breast cancer risk assessment",2020,"","","","",143,"2022-07-13 09:20:28","","10.1016/j.media.2021.102138","","",,,,,7,3.50,1,10,2,"","",""
6,"B. Mahboub, M. Bataineh, H. Alshraideh, R. Hamoudi, Laila Salameh, A. Shamayleh","Prediction of COVID-19 Hospital Length of Stay and Risk of Death Using Artificial Intelligence-Based Modeling",2021,"","","","",144,"2022-07-13 09:20:28","","10.3389/fmed.2021.592336","","",,,,,6,6.00,1,6,1,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a highly infectious virus with overwhelming demand on healthcare systems, which require advanced predictive analytics to strategize COVID-19 management in a more effective and efficient manner. We analyzed clinical data of 2017 COVID-19 cases reported in the Dubai health authority and developed predictive models to predict the patient's length of hospital stay and risk of death. A decision tree (DT) model to predict COVID-19 length of stay was developed based on patient clinical information. The model showed very good performance with a coefficient of determination R2 of 49.8% and a median absolute deviation of 2.85 days. Furthermore, another DT-based model was constructed to predict COVID-19 risk of death. The model showed excellent performance with sensitivity and specificity of 96.5 and 87.8%, respectively, and overall prediction accuracy of 96%. Further validation using unsupervised learning methods showed similar separation patterns, and a receiver operator characteristic approach suggested stable and robust DT model performance. The results show that a high risk of death of 78.2% is indicated for intubated COVID-19 patients who have not used anticoagulant medications. Fortunately, intubated patients who are using anticoagulant and dexamethasone medications with an international normalized ratio of <1.69 have zero risk of death from COVID-19. In conclusion, we constructed artificial intelligence–based models to accurately predict the length of hospital stay and risk of death in COVID-19 cases. These smart models will arm physicians on the front line to enhance management strategies to save lives.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",145,"2022-07-13 09:20:28","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",146,"2022-07-13 09:20:28","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
4,"D. Cabrera, R. Rubilar, Claudio Cubillos","Resilience in the Decision-Making of an Artificial Autonomous System on the Stock Market",2019,"","","","",147,"2022-07-13 09:20:28","","10.1109/ACCESS.2019.2945471","","",,,,,4,1.33,1,3,3,"This paper presents the design of a resilience mechanism for supporting investment decision-making processes performed by artificial autonomous systems. In the field of Psychology, resilience is understood as the capacity of people to overcome adversity. Resilience has been determined to be a permanent necessary element for the life of an individual. In addition, different levels of intelligence, analysis capacities, and degrees of autonomy have been progressively incorporated within information systems that are oriented to support decision-making processes, such as those for stock markets. Particularly, the inclusion of affective criteria or variables within decision-making systems represents a promising line of action. However, to the best of our knowledge, there are no proposals that suggest the inclusion of a psychological approach to resilience within an autonomous decision-making system for stock markets. Specifically, the incorporation of a psychological approach to resilience allows the autonomous system to face special difficult investment scenarios (e.g., an economic shock) and prevent the system from achieving a permanent negative performance. Thus, psychological resilience can enable an artificial autonomous system to adapt its decision-making processes according to uncertain investment environments. Our proposal conducts experiments using official data from the Standard & Poor’s 500 Index. The results are promising and are based on a second-order autoregressive model. The test results suggest that the use of a resilience mechanism within an artificial autonomous system can contain and recover the affective dimensions of the system when it faces adverse decision scenarios.","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",148,"2022-07-13 09:20:28","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",149,"2022-07-13 09:20:28","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",150,"2022-07-13 09:20:28","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
3,"Juan Pedro Martínez-Ramón, F. Morales-Rodríguez, S. Pérez-López","Burnout, Resilience, and COVID-19 among Teachers: Predictive Capacity of an Artificial Neural Network",2021,"","","","",151,"2022-07-13 09:20:28","","10.3390/app11178206","","",,,,,3,3.00,1,3,1,"Emotional exhaustion, cynicism, and work inefficiency are three dimensions that define burnout syndrome among teachers. On another note, resilience can be understood as the ability to adapt to the environment and overcome adverse situations. In addition, COVID-19 has provided a threatening environment that has led to the implementation of resilience strategies to struggle with burnout and cope with the virus. The aim of this study was to analyze the relationship between resilience, burnout dimensions, and variables associated with COVID-19 through the design of an artificial neural network architecture. For this purpose, the Maslach Burnout Inventory-General Survey (MBI-GS), the Brief Resilience Coping Scale (BRCS), and a questionnaire on stress towards COVID-19 were administered to 419 teachers from secondary schools in southeastern Spain (292 females; 69.7%). The results showed that 30.8% suffered from burnout (high emotional exhaustion, high cynicism, and low professional efficacy) and that 38.7% had a high level of resilience, with an inverse relationship between both constructs. Likewise, we modelled an ANN able to predict burnout syndrome among 97.4% of teachers based on its dimensions, resilience, sociodemographic variables, and the stress generated by COVID-19. Our conclusions shed some light on the efficacy of relying on artificial intelligence in the educational field to predict the psychological situation of teachers and take early action.","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",152,"2022-07-13 09:20:28","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
3,"Pu Yanan, Yan Jilong, Zhang Heng","Using Artificial Intelligence to Achieve Auxiliary Training of Table Tennis Based on Inertial Perception Data",2021,"","","","",153,"2022-07-13 09:20:28","","10.3390/s21196685","","",,,,,3,3.00,1,3,1,"Compared with optical sensors, wearable inertial sensors have many advantages such as low cost, small size, more comprehensive application range, no space restrictions and occlusion, better protection of user privacy, and more suitable for sports applications. This article aims to solve irregular actions that table tennis enthusiasts do not know in actual situations. We use wearable inertial sensors to obtain human table tennis action data of professional table tennis players and non-professional table tennis players, and extract the features from them. Finally, we propose a new method based on multi-dimensional feature fusion convolutional neural network and fine-grained evaluation of human table tennis actions. Realize ping-pong action recognition and evaluation, and then achieve the purpose of auxiliary training. The experimental results prove that our proposed multi-dimensional feature fusion convolutional neural network has an average recognition rate that is 0.17 and 0.16 higher than that of CNN and Inception-CNN on the nine-axis non-professional test set, which proves that we can better distinguish different human table tennis actions and have a more robust generalization performance. Therefore, on this basis, we have better realized the enthusiast of table tennis the purpose of the action for auxiliary training.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",154,"2022-07-13 09:20:28","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",155,"2022-07-13 09:20:28","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",156,"2022-07-13 09:20:28","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",157,"2022-07-13 09:20:28","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
0,"Maria Cecilia Anggraeni, Chrysanti Anastasya Silaban, Maria Susan Anggreainy, Ervan Cahyadi","Role of Artificial Intelligence in the Management of Food Waste",2021,"","","","",158,"2022-07-13 09:20:28","","10.1109/AiDAS53897.2021.9574167","","",,,,,0,0.00,0,4,1,"Food waste is caused by a complex collection of interconnected behavior at both the supplier and customer levels. Computational and mathematical models provide various methods for simulating, diagnosing, and predicting various aspects of the dynamic food waste generation and prevention system. This paper describes three modeling methods that have been used to analyze food waste in the past. Bayesian networks and machine learning algorithms are applied to help determine how much food is discarded at the household level. Agent-Based Simulation was used to gain insight into how innovation and adoption of a particular technology can help minimize retail food waste. The first BN-ABM integrated model assesses consumer food waste levels affected by particular features and aspects, resulting in the model reaching equilibrium. Proofing that there is a need for policy interventions, including training, economic incentives, and campaigns, to obtain the resulting model transformation. These interventions are ready to be assessed by the model, but further study is needed to understand the effects of enforcing these structures on the accuracy of the BN-ABM predictive model. The second ABM model aims to determine the factors that establish the adoption of food waste reduction technology at the retail level, which is influenced by particular but not limited to economic factors, including a strong network between retailers and consumer's awareness regarding food waste reduction technology. These findings can study the effects of policy intervention regarding food waste reduction at the retail and consumer level. The third ABM model employed a general food chain network model consisting of consumers, traders, and producers to simulate the dynamic change of product flow between agents and to be able to assess the effect of agent's behavioral contrast. Resilience is measured by the ability to deal with shocks, and efficiency is the share of total food manages to be dispatched to consumers. At first glance, the simulation results seem to show a system trade-off between efficiency and resilience. Network chain structures with higher efficiency displayed more sensitivity to shocks, while networks with less efficiency show more resilience. However, there seem to be modifications in the results when applying several trading interactions and shock types. Resiliency and efficiency are affected by social aspects (trust and preference) in trading interaction between agents. An essential aspect of resilience is the agent's ability to switch links (trading partners) which shows the capability of reorganization. Insights regarding the research can be applicable when considering real-life food chain and structural reorganization to increase resilience and efficiency in meeting national food security goals.","",""
14,"E. Kotter, E. Ranschaert","Challenges and solutions for introducing artificial intelligence (AI) in daily clinical workflow",2020,"","","","",159,"2022-07-13 09:20:28","","10.1007/s00330-020-07148-2","","",,,,,14,7.00,7,2,2,"","",""
14,"M. Yazdani-Asrami, Mehran Taghipour-Gorjikolaie, Wenjuan Song, Min Zhang, W. Yuan","Prediction of Nonsinusoidal AC Loss of Superconducting Tapes Using Artificial Intelligence-Based Models",2020,"","","","",160,"2022-07-13 09:20:28","","10.1109/ACCESS.2020.3037685","","",,,,,14,7.00,3,5,2,"Current is no longer sinusoidal in modern electric networks because of widespread use of power electronic-based equipments and nonlinear loads. Usually AC loss is calculated for pure sinusoidal current, while it is no longer accurate when current is nonsinusoidal. On the other hand, efficiency of cooling system in large scale power devices is dependent on accurate estimation and prediction of the heat load caused by AC loss in design stage. Therefore, estimation of nonsinusoidal AC loss of high temperature superconducting (HTS) material would be of great interest for designers of large-scale superconducting devices. In this paper, at first nonsinusoidal AC loss of a typical HTS tape was calculated under distorted currents using H-formulation finite element method. Then, a range of artificial intelligence (AI) models were implemented to predict AC loss of a typical HTS tape. In order to find the best and more adaptive AI model for nonsinusoidal AC loss prediction, different regression models are evaluated using Support Vector Machine regression model, Generalized Linear regression model, Decision Tree regression model, Feed Forward Neural Network based model, Adaptive Neuro Fuzzy Inference System based model, and Radial Basis Function Neural Network (RBFNN) based model. In order to evaluate robustness of developed models cross-validation technique is implemented on experimental data. To compare the performance of different AI models, four prediction measures were used: Theil’s U coefficients (U_Accuracy and U_Quality), Root Mean Square Error (RMSE) and Regression value (R-value). Obtained results show that best performance belongs to RBFNN based model and then ANFIS based model. U coefficients and RMSE values are obtained less than 0.005 and R-Value is become close to one by using RBFNN based model for testing data, which indicates high accuracy prediction performance.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",161,"2022-07-13 09:20:28","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
14,"Claudia Gonzalez Viejo, S. Fuentes","Beer Aroma and Quality Traits Assessment Using Artificial Intelligence",2020,"","","","",162,"2022-07-13 09:20:28","","10.3390/fermentation6020056","","",,,,,14,7.00,7,2,2,"Increasing beer quality demands from consumers have put pressure on brewers to target specific steps within the beer-making process to modify beer styles and quality traits. However, this demands more robust methodologies to assess the final aroma profiles and physicochemical characteristics of beers. This research shows the construction of artificial intelligence (AI) models based on aroma profiles, chemometrics, and chemical fingerprinting using near-infrared spectroscopy (NIR) obtained from 20 commercial beers used as targets. Results showed that machine learning models obtained using NIR from beers as inputs were accurate and robust in the prediction of six important aromas for beer (Model 1; R = 0.91; b = 0.87) and chemometrics (Model 2; R = 0.93; b = 0.90). Additionally, two more accurate models were obtained from robotics (RoboBEER) to obtain the same aroma profiles (Model 3; R = 0.99; b = 1.00) and chemometrics (Model 4; R = 0.98; b = 1.00). Low-cost robotics and sensors coupled with computer vision and machine learning modeling could help brewers in the decision-making process to target specific consumer preferences and to secure higher consumer demands.","",""
14,"I. Tyukin, D. Higham, A. Gorban","On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems",2020,"","","","",163,"2022-07-13 09:20:28","","10.1109/IJCNN48605.2020.9207472","","",,,,,14,7.00,5,3,2,"In this work we present a formal theoretical framework for assessing and analyzing two classes of malevolent action towards generic Artificial Intelligence (AI) systems. Our results apply to general multi-class classifiers that map from an input space into a decision space, including artificial neural networks used in deep learning applications. Two classes of attacks are considered. The first class involves adversarial examples and concerns the introduction of small perturbations of the input data that cause misclassification. The second class, introduced here for the first time and named stealth attacks, involves small perturbations to the AI system itself. Here the perturbed system produces whatever output is desired by the attacker on a specific small data set, perhaps even a single input, but performs as normal on a validation set (which is unknown to the attacker).We show that in both cases, i.e., in the case of an attack based on adversarial examples and in the case of a stealth attack, the dimensionality of the AI’s decision-making space is a major contributor to the AI’s susceptibility. For attacks based on adversarial examples, a second crucial parameter is the absence of local concentrations in the data probability distribution, a property known as Smeared Absolute Continuity. According to our findings, robustness to adversarial examples requires either (a) the data distributions in the AI’s feature space to have concentrated probability density functions or (b) the dimensionality of the AI’s decision variables to be sufficiently small. We also show how to construct stealth attacks on high-dimensional AI systems that are hard to spot unless the validation set is made exponentially large.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",164,"2022-07-13 09:20:28","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",165,"2022-07-13 09:20:28","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
13,"Mohammad Rasheed Khan, Zeeshan Tariq, A. Abdulraheem","Application of Artificial Intelligence to Estimate Oil Flow Rate in Gas-Lift Wells",2020,"","","","",166,"2022-07-13 09:20:28","","10.1007/s11053-020-09675-7","","",,,,,13,6.50,4,3,2,"","",""
12,"M. Pedersen, K. Verspoor, M. Jenkinson, M. Law, D. Abbott, G. Jackson","Artificial intelligence for clinical decision support in neurology",2020,"","","","",167,"2022-07-13 09:20:28","","10.1093/braincomms/fcaa096","","",,,,,12,6.00,2,6,2,"Abstract Artificial intelligence is one of the most exciting methodological shifts in our era. It holds the potential to transform healthcare as we know it, to a system where humans and machines work together to provide better treatment for our patients. It is now clear that cutting edge artificial intelligence models in conjunction with high-quality clinical data will lead to improved prognostic and diagnostic models in neurological disease, facilitating expert-level clinical decision tools across healthcare settings. Despite the clinical promise of artificial intelligence, machine and deep-learning algorithms are not a one-size-fits-all solution for all types of clinical data and questions. In this article, we provide an overview of the core concepts of artificial intelligence, particularly contemporary deep-learning methods, to give clinician and neuroscience researchers an appreciation of how artificial intelligence can be harnessed to support clinical decisions. We clarify and emphasize the data quality and the human expertise needed to build robust clinical artificial intelligence models in neurology. As artificial intelligence is a rapidly evolving field, we take the opportunity to iterate important ethical principles to guide the field of medicine is it moves into an artificial intelligence enhanced future.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",168,"2022-07-13 09:20:28","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",169,"2022-07-13 09:20:28","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",170,"2022-07-13 09:20:28","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",171,"2022-07-13 09:20:28","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
11,"S. Goto, K. Mahara, L. Beussink-Nelson, H. Ikura, Y. Katsumata, J. Endo, H. Gaggin, S. J. Shah, Y. Itabashi, C. Macrae, R. Deo","Artificial Intelligence-Enabled, Fully Automated Detection of Cardiac Amyloidosis Using Electrocardiograms and Echocardiograms.",2020,"","","","",172,"2022-07-13 09:20:28","","10.1101/2020.07.02.20141028","","",,,,,11,5.50,1,11,2,"Although individually uncommon, rare diseases collectively affect over 350 million patients worldwide and are increasingly the target of therapeutic development efforts. Unfortunately, the pursuit and use of such therapies have been hindered by a common challenge: patients with specific rare diseases are difficult to identify, especially if the conditions resemble more prevalent disorders. Cardiac amyloidosis is one such rare disease, which is characterized by deposition of misfolded proteins within the heart muscle resulting in heart failure and death. In recent years, specific therapies have emerged for cardiac amyloidosis and several more are under investigation, but because cardiac amyloidosis is mistaken for common forms of heart failure, it is typically diagnosed late in its course. As a possible solution, artificial intelligence methods could enable automated detection of rare diseases, but model performance must address low disease prevalence. Here we present an automated multi-modality pipeline for cardiac amyloidosis detection using two neural-network models; one using electrocardiograms (ECG) and the second using echocardiographic videos as input. These models were trained and validated on 3 and 5 academic medical centers (AMC), respectively, in the United States and Japan. Both models had excellent accuracy for detecting cardiac amyloidosis with C-statistics of 0.85-0.92 and 0.91-1.00 for the ECG and echocardiography models, respectively, with the latter outperforming expert diagnosis. Simulating deployment on 13,906 and 7775 patients with ECG-echocardiography paired data for AMC2 and AMC3 indicated a positive predictive value (PPV) for the ECG model of 4% and 3% at 61% and 54% recall, respectively. Pre-screening with ECG enhanced the echocardiography model performance from PPV 23% and 20% to PPV 58% and 53% at 64% recall, respectively for AMC2 and AMC3. In conclusion, we have developed a robust pipeline to augment detection of cardiac amyloidosis, which should serve as a generalizable strategy for other rare and intermediate frequency cardiac diseases with established or emerging therapies.","",""
9,"R. Haneef, M. Delnord, M. Vernay, E. Bauchet, R. Gaidelytė, H. Van Oyen, Z. Or, B. Pérez-Gómez, L. Palmieri, P. Achterberg, M. Tijhuis, M. Zaletel, S. Mathis-Edenhofer, O. Májek, H. Haaheim, H. Tolonen, A. Gallay","Innovative use of data sources: a cross-sectional study of data linkage and artificial intelligence practices across European countries",2020,"","","","",173,"2022-07-13 09:20:28","","10.1186/s13690-020-00436-9","","",,,,,9,4.50,1,17,2,"","",""
8,"J. Kwon, Kyung-Hee Kim, K. Jeon, Soo Youn Lee, Jinsik Park, B. Oh","Artificial intelligence algorithm for predicting cardiac arrest using electrocardiography",2020,"","","","",174,"2022-07-13 09:20:28","","10.1186/s13049-020-00791-0","","",,,,,8,4.00,1,6,2,"","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",175,"2022-07-13 09:20:28","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
8,"R. Deo, Z. Yaseen, N. Al‐Ansari, Thong Nguyen-Huy, Trevor Ashley Mcpherson Langlands, Linda Galligan","Modern Artificial Intelligence Model Development for Undergraduate Student Performance Prediction: An Investigation on Engineering Mathematics Courses",2020,"","","","",176,"2022-07-13 09:20:28","","10.1109/access.2020.3010938","","",,,,,8,4.00,1,6,2,"A computationally efficient artificial intelligence (AI) model called Extreme Learning Machines (ELM) is adopted to analyze patterns embedded in continuous assessment to model the weighted score (WS) and the examination (EX) score in engineering mathematics courses at an Australian regional university. The student performance data taken over a six-year period in multiple courses ranging from the mid- to the advanced level and a diverse course offering mode (i.e., on-campus, ONC, and online, ONL) are modelled by ELM and further benchmarked against competing models: random forest (RF) and Volterra. With the assessments and examination marks as key predictors of WS (leading to a grade in the mid-level course), ELM (with respect to RF and Volterra) outperformed its counterpart models both for the ONC and the ONL offer. This generated relative prediction error in the testing phase, of only 0.74%, compared to about 3.12% and 1.06%, respectively, while for the ONL offer, the prediction errors were only 0.51% compared to about 3.05% and 0.70%. In modelling the student performance in advanced engineering mathematics course, ELM registered slightly larger errors: 0.77% (vs. 22.23% and 1.87%) for ONC and 0.54% (vs. 4.08% and 1.31%) for the ONL offer. This study advocates a pioneer implementation of a robust AI methodology to uncover relationships among student learning variables, developing teaching and learning intervention and course health checks to address issues related to graduate outcomes, and student learning attributes in the higher education sector.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",177,"2022-07-13 09:20:28","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",178,"2022-07-13 09:20:28","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"Dimitri Grün, F. Rudolph, Nils Gumpfer, J. Hannig, L. Elsner, B. Jeinsen, C. Hamm, A. Rieth, Michael Guckert, T. Keller","Identifying Heart Failure in ECG Data With Artificial Intelligence—A Meta-Analysis",2021,"","","","",179,"2022-07-13 09:20:28","","10.3389/fdgth.2020.584555","","",,,,,8,8.00,1,10,1,"Introduction: Electrocardiography (ECG) is a quick and easily accessible method for diagnosis and screening of cardiovascular diseases including heart failure (HF). Artificial intelligence (AI) can be used for semi-automated ECG analysis. The aim of this evaluation was to provide an overview of AI use in HF detection from ECG signals and to perform a meta-analysis of available studies. Methods and Results: An independent comprehensive search of the PubMed and Google Scholar database was conducted for articles dealing with the ability of AI to predict HF based on ECG signals. Only original articles published in peer-reviewed journals were considered. A total of five reports including 57,027 patients and 579,134 ECG datasets were identified including two sets of patient-level data and three with ECG-based datasets. The AI-processed ECG data yielded areas under the receiver operator characteristics curves between 0.92 and 0.99 to identify HF with higher values in ECG-based datasets. Applying a random-effects model, an sROC of 0.987 was calculated. Using the contingency tables led to diagnostic odds ratios ranging from 3.44 [95% confidence interval (CI) = 3.12–3.76] to 13.61 (95% CI = 13.14–14.08) also with lower values in patient-level datasets. The meta-analysis diagnostic odds ratio was 7.59 (95% CI = 5.85–9.34). Conclusions: The present meta-analysis confirms the ability of AI to predict HF from standard 12-lead ECG signals underlining the potential of such an approach. The observed overestimation of the diagnostic ability in artificial ECG databases compared to patient-level data stipulate the need for robust prospective studies.","",""
7,"S. Harmon, Palak G Patel, T. Sanford, Isabelle Caven, Rachael Iseman, T. Vidotto, C. Picanço, J. Squire, Samira Masoudi, Sherif Mehralivand, P. Choyke, D. Berman, B. Turkbey, T. Jamaspishvili","High throughput assessment of biomarkers in tissue microarrays using artificial intelligence: PTEN loss as a proof-of-principle in multi-center prostate cancer cohorts",2020,"","","","",180,"2022-07-13 09:20:28","","10.1038/s41379-020-00674-w","","",,,,,7,3.50,1,14,2,"","",""
6,"S. Gulati, A. Emmanuel, Mehul V. Patel, Sophie Williams, A. Haji, B. Hayee, H. Neumann","Artificial intelligence in luminal endoscopy",2020,"","","","",181,"2022-07-13 09:20:28","","10.1177/2631774520935220","","",,,,,6,3.00,1,7,2,"Artificial intelligence is a strong focus of interest for global health development. Diagnostic endoscopy is an attractive substrate for artificial intelligence with a real potential to improve patient care through standardisation of endoscopic diagnosis and to serve as an adjunct to enhanced imaging diagnosis. The possibility to amass large data to refine algorithms makes adoption of artificial intelligence into global practice a potential reality. Initial studies in luminal endoscopy involve machine learning and are retrospective. Improvement in diagnostic performance is appreciable through the adoption of deep learning. Research foci in the upper gastrointestinal tract include the diagnosis of neoplasia, including Barrett’s, squamous cell and gastric where prospective and real-time artificial intelligence studies have been completed demonstrating a benefit of artificial intelligence–augmented endoscopy. Deep learning applied to small bowel capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. Prospective evaluation including the first randomised trial has been performed in the colon, demonstrating improved polyp and adenoma detection rates; however, these appear to be relevant to small polyps. There are potential additional roles of artificial intelligence relevant to improving the quality of endoscopic examinations, training and triaging of referrals. Further large-scale, multicentre and cross-platform validation studies are required for the robust incorporation of artificial intelligence–augmented diagnostic luminal endoscopy into our routine clinical practice.","",""
2,"Sara Aqab, Muhammad Usman","Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing",2020,"","","","",182,"2022-07-13 09:20:28","","10.14569/ijacsa.2020.0110719","","",,,,,2,1.00,1,2,2,"Due to increased usage of digital technologies in all sectors and in almost all day to day activities to store and pass information, Handwriting character recognition has become a popular subject of research. Handwriting remains relevant, but people still want to have Handwriting copies converted into electronic copies that can be communicated and stored electronically. Handwriting character recognition refers to the computer's ability to detect and interpret intelligible Handwriting input from Handwriting sources such as touch screens, photographs, paper documents, and other sources. Handwriting characters remain complex since different individuals have different handwriting styles. This paper aims to report the development of a Handwriting character recognition system that will be used to read students and lectures Handwriting notes. The development is based on an artificial neural network, which is a field of study in artificial intelligence. Different techniques and methods are used to develop a Handwriting character recognition system. However, few of them focus on neural networks. The use of neural networks for recognizing Handwriting characters is more efficient and robust compared with other computing techniques. The paper also outlines the methodology, design, and architecture of the Handwriting character recognition system and testing and results of the system development. The aim is to demonstrate the effectiveness of neural networks for Handwriting character recognition.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",183,"2022-07-13 09:20:28","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
5,"M. Iqbal, Md. Faiz Iqbal Faiz","Active Surveillance for COVID-19 Through Artificial Intelligence Using Real-Time Speech-Recognition Mobile Application",2020,"","","","",184,"2022-07-13 09:20:28","","10.1109/ICCE-Taiwan49838.2020.9258276","","",,,,,5,2.50,3,2,2,"We propose a novel model of active surveillance for COVID-19 through artificial intelligence. Both past and recent events of viral disease outbreaks have shown us that we do not have effective methods to screen the whole population, and efforts are failing to stop the pandemics. Moreover, at this stage, social distancing and home quarantine are only measures to prevent the spread of COVID-19 infection. The purpose of our project is to introduce a robust method of using speech-recognition techniques through a mobile application in analyzing cough sounds of suspected people who previously were healthy, suffering from a respiratory ailment, and actively monitor the progress of their symptoms in real-time.","",""
4,"S. Hoffman, Andy Podgurski","Artificial Intelligence and Discrimination in Health Care",2020,"","","","",185,"2022-07-13 09:20:28","","","","",,,,,4,2.00,2,2,2,"Artificial intelligence (AI) holds great promise for improved health-care outcomes. It has been used to analyze tumor images, to help doctors choose among different treatment options, and to combat the COVID-19 pandemic. But AI also poses new hazards. This Article focuses on a particular type of health-care harm that has thus far evaded significant legal scrutiny. The harm is algorithmic discrimination.    Algorithmic discrimination in healthcare occurs with surprising frequency. A well-known example is an algorithm used to identify candidates for “high risk care management” programs that routinely failed to refer racial minorities for these beneficial services. Some algorithms deliberately adjust for race in ways that hurt minority patients. For example, such algorithms have regularly underestimated African Americans’ risks of kidney stones, death from heart failure, and other medical problems.    The Article argues that algorithmic discrimination in medicine can violate civil rights laws such as Title VI and Section 1557 of the Affordable Care Act when it exacerbates health disparities or perpetuates inequities. It urges that algorithmic fairness constitute a key element in designing, validating, and implementing AI and that both legal and technical tools be deployed to promote fairness. To that end, we call for the reintroduction of the disparate impact theory as a robust litigation tool in the health-care arena and for the passage of an algorithmic accountability act. We also detail technical measures that AI developers and users should implement.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",186,"2022-07-13 09:20:28","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",187,"2022-07-13 09:20:28","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",188,"2022-07-13 09:20:28","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",189,"2022-07-13 09:20:28","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",190,"2022-07-13 09:20:28","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",191,"2022-07-13 09:20:28","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
16,"A. Arabameri, S. Saha, Kaustuv Mukherjee, T. Blaschke, Wei Chen, P. T. Ngo, S. Band","Modeling Spatial Flood using Novel Ensemble Artificial Intelligence Approaches in Northern Iran",2020,"","","","",192,"2022-07-13 09:20:28","","10.3390/rs12203423","","",,,,,16,8.00,2,7,2,"The uncertainty of flash flood makes them highly difficult to predict through conventional models. The physical hydrologic models of flash flood prediction of any large area is very difficult to compute as it requires lot of data and time. Therefore remote sensing data based models (from statistical to machine learning) have become highly popular due to open data access and lesser prediction times. There is a continuous effort to improve the prediction accuracy of these models through introducing new methods. This study is focused on flash flood modeling through novel hybrid machine learning models, which can improve the prediction accuracy. The hybrid machine learning ensemble approaches that combine the three meta-classifiers (Real AdaBoost, Random Subspace, and MultiBoosting) with J48 (a tree-based algorithm that can be used to evaluate the behavior of the attribute vector for any defined number of instances) were used in the Gorganroud River Basin of Iran to assess flood susceptibility (FS). A total of 426 flood positions as dependent variables and a total of 14 flood conditioning factors (FCFs) as independent variables were used to model the FS. Several threshold-dependent and independent statistical tests were applied to verify the performance and predictive capability of these machine learning models, such as the receiver operating characteristic (ROC) curve of the success rate curve (SRC) and prediction rate curve (PRC), efficiency (E), root-mean square-error (RMSE), and true skill statistics (TSS). The valuation of the FCFs was done using AdaBoost, frequency ratio (FR), and Boosted Regression Tree (BRT) models. In the flooding of the study area, altitude, land use/land cover (LU/LC), distance to stream, normalized differential vegetation index (NDVI), and rainfall played important roles. The Random Subspace J48 (RSJ48) ensemble method with an area under the curve (AUC) of 0.931 (SRC), 0.951 (PRC), E of 0.89, sensitivity of 0.87, and TSS of 0.78, has become the most effective ensemble in predicting the FS. The FR technique also showed good performance and reliability for all models. Map removal sensitivity analysis (MRSA) revealed that the FS maps have the highest sensitivity to elevation. Based on the findings of the validation methods, the FS maps prepared using the machine learning ensemble techniques have high robustness and can be used to advise flood management initiatives in flood-prone areas.","",""
66,"Keping Yu, Zhiwei Guo, Yulian Shen, Wei Wang, Jerry Chun‐wei Lin, Takuro Sato","Secure Artificial Intelligence of Things for Implicit Group Recommendations",2021,"","","","",193,"2022-07-13 09:20:28","","10.1109/JIOT.2021.3079574","","",,,,,66,66.00,11,6,1,"The emergence of Artificial Intelligence of Things (AIoT) has provided novel insights for many social computing applications, such as group recommender systems. As the distances between people have been greatly shortened, there has been more general demand for the provision of personalized services aimed at groups instead of individuals. The existing methods for capturing group-level preference features from individuals have mostly been established via aggregation and face two challenges: 1) secure data management workflows are absent and 2) implicit preference feedback is ignored. To tackle these current difficulties, this article proposes secure AIoT for implicit group recommendations (SAIoT-GRs). For the hardware module, a secure Internet of Things structure is developed as the bottom support platform. For the software module, a collaborative Bayesian network model and noncooperative game are introduced as algorithms. This secure AIoT architecture is able to maximize the advantages of the two modules. In addition, a large number of experiments are carried out to evaluate the performance of SAIoT-GR in terms of efficiency and robustness.","",""
199,"Dong Wook Kim, H. Jang, K. Kim, Youngbin Shin, S. Park","Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers",2019,"","","","",194,"2022-07-13 09:20:28","","10.3348/kjr.2019.0025","","",,,,,199,66.33,40,5,3,"Objective To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images. Materials and Methods PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals. Results Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals. Conclusion Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms.","",""
9,"E. Natsheh","Hybrid Power Systems Energy Management Based on Artificial Intelligence",2020,"","","","",195,"2022-07-13 09:20:28","","","","",,,,,9,4.50,9,1,2,"This thesis presents a novel adaptive scheme for energy management in stand-alone hybrid power systems. The proposed management system is designed to manage the power flow between the hybrid power system and energy storage elements in order to satisfy the load requirements based on artificial neural network (ANN) and fuzzy logic controllers.   The neural network controller is employed to achieve the maximum power point (MPP) for different types of photovoltaic (PV) panels, based on Levenberg Marquardt learning algorithm. The statistical analysis of the results indicates that the R2 value for the testing set was 0.99.   The advance fuzzy logic controller is developed to distribute the power among the hybrid system and to manage the charge and discharge current flow for performance optimization.  The developed management system performance was assessed using a hybrid system comprises PV panels, wind turbine, battery storage, and proton exchange membrane fuel cell (PEMFC). To improve the generating performance of the PEMFC and prolong its life, stack temperature is controlled by a fuzzy logic controller.  Moreover, perturb and observe (P&O) algorithm with two different controller techniques - the linear PI and the non-linear passivity-based controller (PBC) - are provided for a comparison with the proposed MPPT controller system. The comparison revealed the robustness of the proposed PV control system for solar irradiance and load resistance changes.  Real-time measured parameters and practical load profiles are used as inputs for the developed management system. The proposed model and its control strategy offer a proper tool for optimizing the hybrid power system performance, such as the one used in smart-house applications.  The research work also led to a new approach in monitoring PV power stations. The monitoring system enables system degradation early detection by calculating the residual difference between the model predicted and the actual measured power parameters. Measurements were taken over 21 month’s period; using hourly average irradiance and cell temperature. Good agreement was achieved between the theoretical simulation and the real time measurement taken the online grid connected solar power plant.","",""
6,"Tanya Tiwari, Tanuj Tiwari, Sanjay Tiwari","How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?",2018,"","","","",196,"2022-07-13 09:20:28","","10.23956/IJARCSSE.V8I2.569","","",,,,,6,1.50,2,3,4,"There is a lot of confusion these days about Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL). A computer system able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. Artificial Intelligence has made it possible. Deep learning is a subset of machine learning, and machine learning is a subset of AI, which is an umbrella term for any computer program that does something smart. In other words, all machine learning is AI, but not all AI is machine learning, and so forth. Machine Learning represents a key evolution in the fields of computer science, data analysis, software engineering, and artificial intelligence. Machine learning (ML)is a vibrant field of research, with a range of exciting areas for further development across different methods and applications. These areas include algorithmic interpretability, robustness, privacy, fairness, inference of causality, human-machine interaction, and security. The goal of ML is never to make “perfect” guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful. Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones. This paper gives an overview of artificial intelligence, machine learning & deep learning techniques and compare these techniques.","",""
7,"K. Kertysova","Artificial Intelligence and Disinformation",2018,"","","","",197,"2022-07-13 09:20:28","","10.1163/18750230-02901005","","",,,,,7,1.75,7,1,4,"This article explores the challenges and opportunities presented by advances in artificial intelligence (AI) in the context of information operations. The article first examines the ways in which AI can be used to counter disinformation online. It then dives into some of the limitations of AI solutions and threats associated with AI techniques, namely user profiling, micro-targeting, and deep fakes. Finally, the paper reviews a number of solutions that could help address the spread of AI-powered disinformation and improve the online environment. The article recognises that in the fight against disinformation, there is no single fix. The next wave of disinformation calls first and foremost for societal resilience.","",""
187,"M. Frank, David Autor, James Bessen, E. Brynjolfsson, M. Cebrián, D. Deming, M. Feldman, Matt Groh, J. Lobo, E. Moro, Dashun Wang, Hyejin Youn, I. Rahwan","Toward understanding the impact of artificial intelligence on labor",2019,"","","","",198,"2022-07-13 09:20:28","","10.1073/pnas.1900949116","","",,,,,187,62.33,19,13,3,"Rapid advances in artificial intelligence (AI) and automation technologies have the potential to significantly disrupt labor markets. While AI and automation can augment the productivity of some workers, they can replace the work done by others and will likely transform almost all occupations at least to some degree. Rising automation is happening in a period of growing economic inequality, raising fears of mass technological unemployment and a renewed call for policy efforts to address the consequences of technological change. In this paper we discuss the barriers that inhibit scientists from measuring the effects of AI and automation on the future of work. These barriers include the lack of high-quality data about the nature of work (e.g., the dynamic requirements of occupations), lack of empirically informed models of key microlevel processes (e.g., skill substitution and human–machine complementarity), and insufficient understanding of how cognitive technologies interact with broader economic dynamics and institutional mechanisms (e.g., urban migration and international trade policy). Overcoming these barriers requires improvements in the longitudinal and spatial resolution of data, as well as refinements to data on workplace skills. These improvements will enable multidisciplinary research to quantitatively monitor and predict the complex evolution of work in tandem with technological progress. Finally, given the fundamental uncertainty in predicting technological change, we recommend developing a decision framework that focuses on resilience to unexpected scenarios in addition to general equilibrium behavior.","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",199,"2022-07-13 09:20:28","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
2,"Rozhin Eskandarpour, A. Khodaei, Aleksi Paaso, N. M. Abdullah","Artificial Intelligence Assisted Power Grid Hardening in Response to Extreme Weather Events",2018,"","","","",200,"2022-07-13 09:20:28","","","","",,,,,2,0.50,1,4,4,"In this paper, an artificial intelligence based grid hardening model is proposed with the objective of improving power grid resilience in response to extreme weather events. At first, a machine learning model is proposed to predict the component states (either operational or outage) in response to the extreme event. Then, these predictions are fed into a hardening model, which determines strategic locations for placement of distributed generation (DG) units. In contrast to existing literature in hardening and resilience enhancement, this paper co-optimizes grid economic and resilience objectives by considering the intricate dependencies of the two. The numerical simulations on the standard IEEE 118-bus test system illustrate the merits and applicability of the proposed hardening model. The results indicate that the proposed hardening model through decentralized and distributed local energy resources can produce a more robust solution that can protect the system significantly against multiple component outages due to an extreme event.","",""
