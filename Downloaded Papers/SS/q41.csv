Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
6,"Tusar Kanti Hembram, S. Saha, B. Pradhan, K. A. Abdul Maulud, A. Alamri","Robustness analysis of machine learning classifiers in predicting spatial gully erosion susceptibility with altered training samples",2021,"","","","",1,"2022-07-13 09:24:21","","10.1080/19475705.2021.1890644","","",,,,,6,6.00,1,5,1,"Abstract The present research intended to assess the robustness of three popular machine learning models, i.e. random forest (RF), boosted regression tree (BRT) and naïve bayes (NB) in spatial gully erosion susceptibility modelling in Jainti River basin, India. A gully inventory map of 208 gullies was prepared through field survey and Google earth imageries. Following the 70/30 ratio, three randomly sampled groups of altered training and validation gully sets G1, G2 and G3 were prepared for modelling gully erosion susceptibility. Using information gain ratio and multi-collinearity analysis, 14 gully conditioning factors (GCF) were selected. The discrimination ability and reliability of the models were measured through Kappa coefficient, efficiency, receiver operating characteristic curve, root-mean-square-error (RMSE) and mean-absolute-error (MAE). The stability of the machine learning models was estimated by comparing the accuracy statistics and the departure in areal outcomes among intra-model and inter-model. RF model was found as the most consistent. With the highest mean AUC (0.903), efficiency (91.17), Kappa coefficient (0.835) and lowest RMSE (0.192) and MAE (0.081), RF was found to be more consistent when the training and validation data sets were altered. The effectiveness of each input GCFs was determined using map removal sensitivity analysis technique. This study could be supportive in ascertaining model deployment for mapping gully erosion and managing the land resource.","",""
1,"Nicolas Jourdan, S. Sen, E. J. Husom, Enrique Garcia-Ceja, Tobias Biegel, J. Metternich","On The Reliability Of Machine Learning Applications In Manufacturing Environments",2021,"","","","",2,"2022-07-13 09:24:21","","","","",,,,,1,1.00,0,6,1,"The increasing deployment of advanced digital technologies such as Internet of Things (IoT) devices and Cyber-Physical Systems (CPS) in industrial environments is enabling the productive use of machine learning (ML) algorithms in the manufacturing domain. As ML applications transcend from research to productive use in real-world industrial environments, the question of reliability arises. Since the majority of ML models are trained and evaluated on static datasets, continuous online monitoring of their performance is required to build reliable systems. Furthermore, concept and sensor drift can lead to degrading accuracy of the algorithm over time, thus compromising safety, acceptance and economics if undetected and not properly addressed. In this work, we exemplarily highlight the severity of the issue on a publicly available industrial dataset which was recorded over the course of 36 months and explain possible sources of drift. We assess the robustness of ML algorithms commonly used in manufacturing and show, that the accuracy strongly declines with increasing drift for all tested algorithms. We further investigate how uncertainty estimation may be leveraged for online performance estimation as well as drift detection as a first step towards continually learning applications. The results indicate, that ensemble algorithms like random forests show the least decay of confidence calibration under drift.","",""
0,"Eric J. Wyers, Weiyi Qi, P. Franzon","A robust calibration and supervised machine learning reliability framework for digitally-assisted self-healing RFICs",2017,"","","","",3,"2022-07-13 09:24:21","","10.1109/MWSCAS.2017.8053129","","",,,,,0,0.00,0,3,5,"A robust calibration and supervised machine learning reliability framework has been developed to aid the circuit designer in the design and implementation of reliable digitally-reconfigurable self-healing RFICs. For calibration algorithm performance and reliability validation, we advocate the use of surrogate modeling, a supervised machine learning technique, which offers a significant reduction in the required computational complexity relative to relying solely on the execution of expensive circuit simulations. An RF phase rotator test case is used to show the robustness and utility of the developed self-healing reliability framework.","",""
0,"Hossein Nourkhiz Mahjoub","Reliability and Robustness Enhancement of Cooperative Vehicular Systems: A Bayesian Machine Learning Perspective",2019,"","","","",4,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,1,3,"","",""
17,"F. Kriebel, Semeen Rehman, Muhammad Abdullah Hanif, Faiq Khalid, M. Shafique","Robustness for Smart Cyber Physical Systems and Internet-of-Things: From Adaptive Robustness Methods to Reliability and Security for Machine Learning",2018,"","","","",5,"2022-07-13 09:24:21","","10.1109/ISVLSI.2018.00111","","",,,,,17,4.25,3,5,4,"In recent years, the exponential growth of internet of things (IoT) and cyber physical systems (CPS) in safety critical applications has imposed severe reliability and security challenges. This is due to the heterogeneity and complex connectivity of the CPS components as well as error-prone and vulnerable nature of the underlying devices, harsh operating environments, and escalating security attacks. Different reliability threats (like soft errors, process variation and the temperature-induced dark silicon problem) have posed diverse challenges, which led to the development of various mitigation techniques on different layers of the CPS/IoT stack. Similarly, security threats (like manipulation of communication channels, hardware components and associated software) led to the development of different detection and protection techniques on different layers of the CPS/IoT stack, e.g., cross-layer and intra-layer connectivity. Towards this, the associated costs and overhead as well as potentially conflicting goals are important to be considered, e.g., most of the soft error mitigation techniques are based on redundancy and most of the security-related techniques require continuous runtime monitoring, obfuscation, attestation, and trusted execution environments. This paper first discusses different existing options for approaching this problem at different system layers, i.e., adaptive reliability and security management. These different solutions will provide a wide variety of options to choose from, as a basis for selection and adaptation, to solve reliability-related problems at design-time and run-time. Due to the exponential increase in the complexity and functional requirements, there is a trend towards employing Machine Learning in CPSs and IoT systems. Therefore, we will show how systems can be protected against different security and reliability threats when Machine Learning sub-systems are employed in CPS/IoT.","",""
0,"Boyu Ao, Jiachang Ren, Chen Guo","Impact of Image Corruptions on the Reliability of Traffic Sign Recognition Using Machine Learning Technique",2019,"","","","",6,"2022-07-13 09:24:21","","10.1145/3314545.3314547","","",,,,,0,0.00,0,3,3,"As autonomous driving gets closer to be widely applied, it is important to guarantee that traffic signs are recognized correctly. Due to change of light conditions and blockage by some other objects, traffic signs can sometimes be partially corrupted. In this paper, we evaluated how machine learning would respond to different types of image corruption by various degrees. Removing a higher percentage of pixels will gradually harm the recognition accuracy, and removal by blocks causes the biggest harm, which is consistent with human observation. Changing to various colors or a single color doesn't seem to cause significant differences. This study, by building a model for traffic sign recognition and evaluating its robustness to various types of image corruptions, provides insights into corruptions of datasets for machine learning in general, and provide potential concern for applying the well-trained model to a new test set with corruptions, which could be a concern for applying autonomous driving in certain areas.","",""
0,"George J. Siedel, S. Vock, A. Morozov, Stefan Voss","Utilizing Class Separation Distance for the Evaluation of Corruption Robustness of Machine Learning Classifiers",2022,"","","","",7,"2022-07-13 09:24:21","","10.48550/arXiv.2206.13405","","",,,,,0,0.00,0,4,1,"Robustness is a fundamental pillar of Machine Learning (ML) classifiers, substantially determining their reliability. Methods for assessing classifier robustness are therefore essential. In this work, we address the challenge of evaluating corruption robustness in a way that allows comparability and interpretability on a given dataset. We propose a test data augmentation method that uses a robustness distance 𝜖 derived from the datasets minimal class separation distance. The resulting MSCR (mean statistical corruption robustness) metric allows a dataset-specific comparison of different classifiers with respect to their corruption robustness. The MSCR value is interpretable, as it represents the classifiers avoidable loss of accuracy due to statistical corruptions. On 2D and image data, we show that the metric reflects different levels of classifier robustness. Furthermore, we observe unexpected optima in classifiers robust accuracy through training and testing classifiers with different levels of noise. While researchers have frequently reported on a significant tradeoff on accuracy when training robust models, we strengthen the view that a tradeoff between accuracy and corruption robustness is not inherent. Our results indicate that robustness training through simple data augmentation can already slightly improve accuracy.","",""
0,"Anne-Laure Wozniak, S. Segura, Raúl Mazo, Sarah Leroy","Robustness Testing of a Machine Learning-based Road Object Detection System: An Industrial Case",2022,"","","","",8,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,4,1,"With the increasing development of critical systems based on artificial intelligence (AI), methods have been proposed and evaluated in academia to assess the reliability of these systems. In the context of computer vision, some approaches use the generation of images altered by common perturbations and realistic transformations to assess the robustness of systems. To better understand the strengths and limitations of these approaches, we report the results obtained on an industrial case of a road object detection system. By comparing these results with those of reference models, we identify areas for improvement regarding the robustness of the system and the metrics used for this evaluation.CCS CONCEPTS • Computing methodologies → Machine learning.","",""
11,"S. Tripathi, David Muhr, Manuel Brunner, F. Emmert‐Streib, H. Jodlbauer, M. Dehmer","Ensuring the Robustness and Reliability of Data-Driven Knowledge Discovery Models in Production and Manufacturing",2020,"","","","",9,"2022-07-13 09:24:21","","10.3389/frai.2021.576892","","",,,,,11,5.50,2,6,2,"The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.","",""
40,"Jianwen Fang","A critical review of five machine learning-based algorithms for predicting protein stability changes upon mutation",2020,"","","","",10,"2022-07-13 09:24:21","","10.1093/bib/bbz071","","",,,,,40,20.00,40,1,2,"A number of machine learning (ML)-based algorithms have been proposed for predicting mutation-induced stability changes in proteins. In this critical review, we used hypothetical reverse mutations to evaluate the performance of five representative algorithms and found all of them suffer from the problem of overfitting. This approach is based on the fact that if a wild-type protein is more stable than a mutant protein, then the same mutant is less stable than the wild-type protein. We analyzed the underlying issues and suggest that the main causes of the overfitting problem include that the numbers of training cases were too small, and the features used in the models were not sufficiently informative for the task. We make recommendations on how to avoid overfitting in this important research area and improve the reliability and robustness of ML-based algorithms in general.","",""
4,"I. Scott","Demystifying machine learning: a primer for physicians",2021,"","","","",11,"2022-07-13 09:24:21","","10.1111/imj.15200","","",,,,,4,4.00,4,1,1,"Machine learning is a tool for analysing digitised data sets and formulating predictions that can optimise clinical decision‐making. It aims to identify complex patterns in large data sets and encode them into models that can then classify new unseen cases or make predictions on new data. Machine learning methods take several forms and individual models can be of many different types. More than 50 models have been approved for use in routine healthcare, and the numbers continue to grow exponentially. The reliability and robustness of any model depends on multiple factors, including the quality and quantity of the data used to develop the models, and the selection of features in the data considered most important to maximising accuracy. In ensuring models are safe, effective and reproducible in routine care, physicians need to have some understanding of how these models are developed and evaluated, and to collaborate with data and computer scientists in their design and validation. This narrative review introduces principles, methods and examples of machine learning in a way that does not require mastery of highly complex statistical and computational concepts.","",""
3,"Sanjida Ferdousi, Qiyi Chen, Mehrzad Soltani, Jiadeng Zhu, P. Cao, W. Choi, R. Advíncula, Yijie Jiang","Characterize traction–separation relation and interfacial imperfections by data-driven machine learning models",2021,"","","","",12,"2022-07-13 09:24:21","","10.1038/s41598-021-93852-y","","",,,,,3,3.00,0,8,1,"","",""
2,"David Gonzalez-Jimenez, Jon del-Olmo, J. Poza, Fernando Garramiola, Izaskun Sarasola","Machine Learning-Based Fault Detection and Diagnosis of Faulty Power Connections of Induction Machines",2021,"","","","",13,"2022-07-13 09:24:21","","10.3390/en14164886","","",,,,,2,2.00,0,5,1,"Induction machines have been key components in the industrial sector for decades, owing to different characteristics such as their simplicity, robustness, high energy efficiency and reliability. However, due to the stress and harsh working conditions they are subjected to in many applications, they are prone to suffering different breakdowns. Among the most common failure modes, bearing failures and stator winding failures can be found. To a lesser extent, High Resistance Connections (HRC) have also been investigated. Motor power connection failure mechanisms may be due to human errors while assembling the different parts of the system. Moreover, they are not only limited to HRC, there may also be cases of opposite wiring connections or open-phase faults in motor power terminals. Because of that, companies in industry are interested in diagnosing these failure modes in order to overcome human errors. This article presents a machine learning (ML) based fault diagnosis strategy to help maintenance assistants on identifying faults in the power connections of induction machines. Specifically, a strategy for failure modes such as high resistance connections, single phasing faults and opposite wiring connections has been designed. In this case, as field data under the aforementioned faulty events are scarce in industry, a simulation-driven ML-based fault diagnosis strategy has been implemented. Hence, training data for the ML algorithm has been generated via Software-in-the-Loop simulations, to train the machine learning models.","",""
1,"M. Staron, Helena Odenstedt Herg'es, S. Naredi, L. Block, Ali El-Merhi, Richard Vithal, M. Elam","Robust Machine Learning in Critical Care — Software Engineering and Medical Perspectives",2021,"","","","",14,"2022-07-13 09:24:21","","10.1109/WAIN52551.2021.00016","","",,,,,1,1.00,0,7,1,"Using machine learning in clinical practice poses hard requirements on explainability, reliability, replicability and robustness of these systems. Therefore, developing reliable software for monitoring critically ill patients requires close collaboration between physicians and software engineers. However, these two different disciplines need to find own research perspectives in order to contribute to both the medical and the software engineering domain. In this paper, we address the problem of how to establish a collaboration where software engineering and medicine meets to design robust machine learning systems to be used in patient care. We describe how we designed software systems for monitoring patients under carotid endarterectomy, in particular focusing on the process of knowledge building in the research team. Our results show what to consider when setting up such a collaboration, how it develops over time and what kind of systems can be constructed based on it. We conclude that the main challenge is to find a good research team, where different competences are committed to a common goal.","",""
1,"Yinghan Liu","Intelligent analysis platform of agricultural sustainable development based on the Internet of Things and machine learning",2021,"","","","",15,"2022-07-13 09:24:21","","10.1080/09064710.2021.1943513","","",,,,,1,1.00,1,1,1,"ABSTRACT In order to improve the management effect of agricultural sustainable development, this paper uses the Internet of Things technology and machine learning technology as the basis to study the agricultural sustainable development platform. Simultaneously, this paper studies the architecture of wireless sensor nodes and networks oriented to complex agricultural habitat conditions. Moreover, in view of the harsh environment of data collection in agricultural production sites and the higher requirements for network robustness, this paper designs a new type of intelligent sensor network equipment. It is used to effectively reduce the number of tasks undertaken by routing and the completeness of data in a large covered agricultural base area, and to ensure the efficiency and reliability of network data. In addition, this paper combines the needs of sustainable development of smart agriculture to build a smart agriculture platform based on Internet of Things technology and machine learning, and design experiments to verify the performance of the system platform constructed in this paper. From the experimental research, it can be seen that the system constructed in this paper basically meets actual needs.","",""
5,"Zafer Al-makhadmeh, A. Tolba","SRAF: Scalable Resource Allocation Framework using Machine Learning in user-Centric Internet of Things",2020,"","","","",16,"2022-07-13 09:24:21","","10.1007/s12083-020-00924-3","","",,,,,5,2.50,3,2,2,"","",""
0,"Vedpal, N. Chauhan","Role of Machine Learning in Software Testing",2021,"","","","",17,"2022-07-13 09:24:21","","10.1109/ISCON52037.2021.9702427","","",,,,,0,0.00,0,2,1,"Software reliability and robustness is the main objective to perform testing of the software. Now the machine learning approaches are used to develop applications in almost every area like health care, business prediction, etc. The testing of such type of software by using the conventional testing techniques does not give promising results. The testing techniques based on machine learning helps to produce reliable and robust software within time and allocated budget. In this paper the role of the machine learning algorithms in the design of testing approaches for testing the software has been presented. The machine learning-based testing techniques are used in the generation and execution order of the test cases. The outcomes of the machine learning based techniques showing the efficacy as compared to the other techniques.","",""
0,"Rashid Ali, Haoyuan Ma, Zhengyi Hou, Deming Zhang, E. Deng, You Wang","A Reconfigurable Arbiter MPUF With High Resistance Against Machine Learning Attack",2021,"","","","",18,"2022-07-13 09:24:21","","10.1109/tmag.2021.3102838","","",,,,,0,0.00,0,6,1,"Physical unclonable function (PUF) is an emerging hardware security primitive which is increasingly used to authenticate and identify Internet of Things (IoT) devices. Spin-transfer torque magnetoresistive random access memory (STT-MRAM) provides new opportunities for novel PUFs due to inherent randomness sources, such as process variations, stochastic switching, and chaotic magnetization. In this article, we propose a hybrid STT-MRAM/complementary metal-oxide semiconductor (CMOS)-based reconfigurable arbiter PUF (MPUF) with enhanced performance metrics in terms of reliability, uniqueness, and uniformity. This design has a mean intra-hamming distance (HD) of 0.147%, a mean inter-HD of 50.21%, and passes the National Institute of Standards and Technology (NIST) statistical tests. The proposed arbiter MPUF features distinct advantages, such as reconfigurable architecture, challenge-dependent stage delays, and huge challenge-response pair (CRP) space. Moreover, the robustness of the proposed MPUF against machine learning (ML)-based modeling attacks is tested using three ML algorithms, namely support vector machine (SVM), linear regression (LR), and multilayer perceptron (MLP). Results show that the proposed reconfigurable arbiter MPUF is resistant to ML attacks and minimizes the ML attack prediction accuracy to less than 65.12% without XOR and less than 44.34% with XOR. Meanwhile, the correlation power analysis demonstrates that the proposed MPUF is also resilient to side-channel attacks.","",""
1,"Q. Gao, X. Wu, Junhui Guo, Hongqing Zhou, Wei Ruan","Machine-Learning-Based Intelligent Mechanical Fault Detection and Diagnosis of Wind Turbines",2021,"","","","",19,"2022-07-13 09:24:21","","10.1155/2021/9915084","","",,,,,1,1.00,0,5,1,"Wind power has gained wide popularity due to the increasingly serious energy and environmental crisis. However, the severe operational conditions often bring faults and failures in the wind turbines, which may significantly degrade the security and reliability of large-scale wind farms. In practice, accurate and efficient fault detection and diagnosis are crucial for safe and reliable system operation. This work develops an effective deep learning solution using a convolutional neural network to address the said problem. In addition, the linear discriminant criterion-based metric learning technique is adopted in the model training process of the proposed solution to improve the algorithmic robustness under noisy conditions. The proposed solution can efficiently extract the features of the mechanical faults. The proposed algorithmic solution is implemented and assessed through a range of experiments for different scenarios of faults. The numerical results demonstrated that the proposed solution can well detect and diagnose the multiple coexisting faults of the operating wind turbine gearbox.","",""
10,"M. Campi, S. Garatti","Scenario optimization with relaxation: a new tool for design and application to machine learning problems",2020,"","","","",20,"2022-07-13 09:24:21","","10.1109/CDC42340.2020.9303914","","",,,,,10,5.00,5,2,2,"Scenario optimization is by now a well established technique to perform designs in the presence of uncertainty. It relies on domain knowledge integrated with first-hand information that comes from data and generates solutions that are also accompanied by precise statements of reliability. In this paper, following recent developments in [22], we venture beyond the traditional set-up of scenario optimization by analyzing the concept of constraints relaxation. By a solid theoretical underpinning, this new paradigm furnishes fundamental tools to perform designs that meet a proper compromise between robustness and performance. After suitably expanding the scope of constraints relaxation as proposed in [22], we focus on various classical Support Vector methods in machine learning – including SVM (Support Vector Machine), SVR (Support Vector Regression) and SVDD (Support Vector Data Description) – and derive new results that attest the ability of these methods to generalize.","",""
18,"Li Fu, Lu Liu, Zhi-Jiang Yang, Pan Li, Jun-Jie Ding, Yong-Huan Yun, Aiping Lu, Tingjun Hou, Dongsheng Cao","Systematic Modeling of log D7.4 Based on Ensemble Machine Learning, Group Contribution, and Matched Molecular Pair Analysis",2019,"","","","",21,"2022-07-13 09:24:21","","10.1021/acs.jcim.9b00718","","",,,,,18,6.00,2,9,3,"Lipophilicity, as evaluated by the n-octanol/buffer solution distribution coefficient at pH = 7.4 (logD7.4), is a major determinant of various absorption, distribution, metabolism, elimination and toxicology (ADMET) parameters of drug candidates. In this study, we developed several quantitative structure-property relationship (QSPR) models to predict logD7.4 based on a large and structurally diverse data set. Eight popular machine learning algorithms were employed to build the prediction models with 43 molecular descriptors selected by a wrapper feature selection method. The results demonstrated XGBoost yielded better prediction performance than any other single model (RT2 = 0.906 and RMSET = 0.395). However, the consensus model from the top three models could continue to improve the prediction performance (RT2 = 0.922 and RMSET=0.359). The robustness, reliability, and generalization ability of the models were strictly evaluated by the Y-randomization test and applicability domain analysis. Moreover, the group contribution model based on 110 atom types and the local models for different ionization states were also established and compared with the global models. The results demonstrated that the descriptor-based consensus model is superior to the group contribution method, and the local models have no advantage over the global models. Finally, matched molecular pair (MMP) analysis and descriptor importance analysis were performed to extract transformation rules and give some explanations related to logD7.4. In conclusion, we believe that the consensus model developed in this study can be used as a reliable and promising tool to evaluate logD7.4 in drug discovery.","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",22,"2022-07-13 09:24:21","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
17,"Jaskaran Singh, M. Azamfar, Fei Li, Jay Lee","A systematic review of machine learning algorithms for prognostics and health management of rolling element bearings: fundamentals, concepts and applications",2020,"","","","",23,"2022-07-13 09:24:21","","10.1088/1361-6501/ab8df9","","",,,,,17,8.50,4,4,2,"This article aims to present a comprehensive review of the recent efforts and advances in applying machine learning (ML) techniques in the area of diagnostics and prognostics of rolling element bearings. The significant goal of this study is to review, recognize and evaluate the performance of various ML techniques and compare them on criteria's such as reliability, accuracy, robustness to noise, data volume requirements and implementation aspects. The merits and demerits of the reviewed ML techniques have been comprehensively analyzed and discussed. A comparative benchmarking of the performance of the reviewed ML algorithms is provided both from the viewpoint of theoretical aspects and industrial applicability. Finally, the potential challenges that come along with the implementation of ML technology are discussed in detail that will likely play a major role in prognostics and health management of rolling element bearings. It is expected that this review would serve as a reference point for researchers to explore the opportunities for further improvement in the field of ML-based fault diagnosis and prognosis of rolling element bearings.","",""
6,"N. Sepulveda, J. Sinha","Parameter Optimisation in the Vibration-Based Machine Learning Model for Accurate and Reliable Faults Diagnosis in Rotating Machines",2020,"","","","",24,"2022-07-13 09:24:21","","10.3390/machines8040066","","",,,,,6,3.00,3,2,2,"Artificial intelligence (AI)-based machine learning (ML) models seem to be the future for most of the applications. Recent research effort has also been made on the application of these AI and ML methods in the vibration-based faults diagnosis (VFD) in rotating machines. Several research studies have been published over the last decade on this topic. However, most of the studies are data driven, and the vibration-based ML (VML) model is generally developed on a typical machine. The developed VML model may not predict faults accurately if applied on other identical machines or a machine with different operation conditions or both. Therefore, the current research is on the development of a VML model by optimising the vibration parameters based on the dynamics of the machine. The developed model is then blindly tested at different machine operation conditions to show the robustness and reliability of the proposed VML model.","",""
6,"Farzin Piltan, Jong-Myon Kim","Bearing Fault Identification Using Machine Learning and Adaptive Cascade Fault Observer",2020,"","","","",25,"2022-07-13 09:24:21","","10.3390/app10175827","","",,,,,6,3.00,3,2,2,"In this work, a hybrid procedure for bearing fault identification using a machine learning and adaptive cascade observer is explained. To design an adaptive cascade observer, the normal signal approximation is the first step. Therefore, the fuzzy orthonormal regressive (FOR) technique was developed to approximate the acoustic emission (AE) and vibration (non-stationary and nonlinear) bearing signals in normal conditions. After approximating the normal signal of bearing using the FOR technique, the adaptive cascade observer is modeled in four steps. First, the linear observation technique using a FOR proportional-integral (PI) observer (FOR-PIO) is developed. In the second step, to increase the power of uncertaintie rejection (robustness) of the FOR-PIO, the structure procedure is used serially. Next, the fuzzy like observer is selected to increase the accuracy of FOR structure PI observer (FOR-SPIO). Moreover, the adaptive technique is used to develop the reliability of the cascade (fuzzy-structure PI) observer. Additionally to fault identification, the machine-learning algorithm using a support vector machine (SVM) is recommended. The effectiveness of the adaptive cascade observer with the SVM fault identifier was validated by a vibration and AE datasets. Based on the results, the average vibration and AE fault diagnosis using the adaptive cascade observer with the SVM fault identifier are 97.8% and 97.65%, respectively.","",""
6,"Liwei Song, Vikash Sehwag, A. Bhagoji, Prateek Mittal","A Critical Evaluation of Open-World Machine Learning",2020,"","","","",26,"2022-07-13 09:24:21","","","","",,,,,6,3.00,2,4,2,"Open-world machine learning (ML) combines closed-world models trained on in-distribution data with out-of-distribution (OOD) detectors, which aim to detect and reject OOD inputs. Previous works on open-world ML systems usually fail to test their reliability under diverse, and possibly adversarial conditions. Therefore, in this paper, we seek to understand how resilient are state-of-the-art open-world ML systems to changes in system components? With our evaluation across 6 OOD detectors, we find that the choice of in-distribution data, model architecture and OOD data have a strong impact on OOD detection performance, inducing false positive rates in excess of $70\%$. We further show that OOD inputs with 22 unintentional corruptions or adversarial perturbations render open-world ML systems unusable with false positive rates of up to $100\%$. To increase the resilience of open-world ML, we combine robust classifiers with OOD detection techniques and uncover a new trade-off between OOD detection and robustness.","",""
5,"P. Santhanam","Quality Management of Machine Learning Systems",2020,"","","","",27,"2022-07-13 09:24:21","","10.1007/978-3-030-62144-5_1","","",,,,,5,2.50,5,1,2,"","",""
2,"H. Khorshidi, M. Kirley, U. Aickelin","Machine learning with incomplete datasets using multi-objective optimization models",2020,"","","","",28,"2022-07-13 09:24:21","","10.1109/IJCNN48605.2020.9206742","","",,,,,2,1.00,1,3,2,"Machine learning techniques have been developed to learn from complete data. When missing values exist in a dataset, the incomplete data should be preprocessed separately by removing data points with missing values or imputation. In this paper, we propose an online approach to handle missing values while a classification model is learnt. To reach this goal, we develop a multi-objective optimization model with two objective functions for imputation and model selection. We also propose three formulations for imputation objective function. We use an evolutionary algorithm based on NSGA II to find the optimal solutions as the Pareto solutions. We investigate the reliability and robustness of the proposed model using experiments by defining several scenarios in dealing with missing values and classification. We also describe how the proposed model can contribute to medical informatics. We compare the performance of three different formulations via experimental results. The proposed model results get validated by comparing with a comparable literature.","",""
1,"Elif Ceren Gok, Murat Onur Yildirim, E. Eren, A. Oksuz","Comparison of Machine Learning Models on Performance of Single- and Dual-Type Electrochromic Devices",2020,"","","","",29,"2022-07-13 09:24:21","","10.1021/acsomega.0c03048","","",,,,,1,0.50,0,4,2,"This study shows that the model fitting based on machine learning (ML) from experimental data can successfully predict the electrochromic characteristics of single- and dual-type flexible electrochromic devices (ECDs) by using tungsten trioxide (WO3) and WO3/vanadium pentoxide (V2O5), respectively. Seven different regression methods were used for experimental observations, which belong to single and dual ECDs where 80% percent was used as training data and the remaining was taken as testing data. Among the seven different regression methods, K-nearest neighbor (KNN) achieves the best results with higher coefficient of determination (R2) score and lower root-mean-squared error (RMSE) for the bleaching state of ECDs. Furthermore, higher R2 score and lower RMSE for the coloration state of ECDs were achieved with Gaussian process regressor. The robustness result of the ML modeling demonstrates the reliability of prediction outcomes. These results can be proposed as promising models for different energy-saving flexible electronic systems.","",""
1,"Shirin Haji Amin Shirazi, Hoda Naghibijouybari, N. Abu-Ghazaleh","Securing Machine Learning Architectures and Systems",2020,"","","","",30,"2022-07-13 09:24:21","","10.1145/3386263.3409104","","",,,,,1,0.50,0,3,2,"Machine learning (ML), and deep learning in particular, have become a critical workload as they are becoming increasingly applied at the core of a wide range of application spaces. Computer systems, from the architecture up, have been impacted by ML in two primary directions: (1) ML is an increasingly important computing workload, with new accelerators and systems targeted to support both training and inference at scale; and (2) ML supporting computer system decisions, both during design and run times, with new machine learning based algorithms controlling systems to optimize their performance, reliability and robustness. In this paper, we will explore the intersection of security, ML and computing systems, identifying both security challenges and opportunities. Machine learning systems are vulnerable to new attacks including adversarial attacks crafted to fool a classifier to the attacker's advantage, membership inference attacks attempting to compromise the privacy of the training data, and model extraction attacks seeking to recover the hyperparameters of a (secret) model. Architecture can be a target of these attacks when supporting ML (or is supported by ML), but also provides an opportunity to develop defenses against them, which we will illustrate with three examples from our recent work. First, we show how ML based hardware malware detectors can be attacked with adversarial perturbations to the Malware and how we can develop detectors that resist these attacks. Second, we show an example of microarchitectural side channel attacks that can be used to extract the secret parameters of a neural network and potential defenses against it. Finally, we discuss how hardware and systems can be used to make ML more robust against adversarial and other attacks.","",""
1,"Korn Sooksatra, Pablo Rivas","A Review of Machine Learning and Cryptography Applications",2020,"","","","",31,"2022-07-13 09:24:21","","10.1109/CSCI51800.2020.00105","","",,,,,1,0.50,1,2,2,"Adversarially robust neural cryptography deals with the training of a neural-based model using an adversary to leverage the learning process in favor of reliability and trustworthiness. The adversary can be a neural network or a strategy guided by a neural network. These mechanisms are proving successful in finding secure means of data protection. Similarly, machine learning benefits significantly from the cryptography area by protecting models from being accessible to malicious users. This paper is a literature review on the symbiotic relationship between machine learning and cryptography. We explain cryptographic algorithms that have been successfully applied in machine learning problems and, also, deep learning algorithms that have been used in cryptography. We pay special attention to the exciting and relatively new area of adversarial robustness.","",""
1,"Huda Aldosari, Raafat S. Elfouly, Reda Ammar","Evaluation of Machine Learning-Based Regression Techniques for Prediction of Oil and Gas Pipelines Defect",2020,"","","","",32,"2022-07-13 09:24:21","","10.1109/CSCI51800.2020.00271","","",,,,,1,0.50,0,3,2,"Magnetic flux leakage (MFL) signals allow the scale of metal failure defects present on a pipeline to be observed, located, and measured. An advanced and reliable intelligent pipeline monitoring system is needed to protect the local ecosystem from disastrous effects due to malfunctioning pipelines. MFL plays a vital role in gas pipeline examination; various studies have explored smart MFL based defect prediction systems. Machine learning-based defect prediction systems allow predicting the characteristics of the oil and gas defects in real-time. As fault detection control is applied to low-performance embedded systems, prediction algorithms' reliability is of utmost importance. The intention was to extend the work of previous researchers and provide insight into the behavior of the selected classifiers with time as a robustness factor, an experimental design that constitutes the novelty of this study. For the said purpose, a prerecorded dataset comprised of MFL signals has been utilized. Prediction of defect length has been performed with several approaches, including linear regression (LR), linear regression with stochastic gradient descent (LRSGD), support vector machine (SVM), Gaussian process regression (GPR), boosting regression tree ensemble (BSTE), binary decision tree (BDT), stepwise (SW), and artificial neural network (ANN). The results indicated that ANN yields the best prediction results for MFL based defect predictions, followed by GRP regression analysis. The presented results can be utilized to design and implement a defect length prediction model to be deployed underwater, providing real-time prediction results.","",""
0,"Qi Wu, Weiqi Chen, Haiming Wang, W. Hong","Machine Learning-Assisted Tolerance Analysis and Its Application to Antennas",2020,"","","","",33,"2022-07-13 09:24:21","","10.1109/IEEECONF35879.2020.9330387","","",,,,,0,0.00,0,4,2,"An efficient machine learning-assisted tolerance analysis (MLATA) method is proposed by applying machine learning (ML) methods into multiple layers of the antenna tolerance analysis. The computational time for operations including worst case performance searching, maximum input tolerance hypervolume searching and robust optimization is greatly reduced while maintaining high reliability due to the introduction of the ML methods. The surrogate models which are built using ML methods have been introduced to predict both antenna performance and tolerance of parameters at given design points. The Pareto front combining antenna performance, robustness and size has been obtained to guide trade-offs for antenna robust design. A planar inverted-L antenna for mobile terminals is simulated to validate the proposed MLATA method.","",""
0,"J. Filipe, Ashish Ghosh, R. Prates, O. Shehory, E. Farchi, Guy Barash","Engineering Dependable and Secure Machine Learning Systems: Third International Workshop, EDSMLS 2020, New York City, NY, USA, February 7, 2020, Revised Selected Papers",2020,"","","","",34,"2022-07-13 09:24:21","","10.1007/978-3-030-62144-5","","",,,,,0,0.00,0,6,2,"","",""
0,"Simone Bexten, José Saenz, Christoph Walter, Juliana Scholle, N. Elkmann","Discussion of using Machine Learning for Safety Purposes in Human Detection",2020,"","","","",35,"2022-07-13 09:24:21","","10.1109/ETFA46521.2020.9212028","","",,,,,0,0.00,0,5,2,"The reliability and robustness of systems using machine learning to detect humans is of high importance for the safety of workers in a shared workspace. Developments such as deep learning are advancing rapidly, supporting the field of robotics through increased perception capabilities. An early detection of humans will support robot behavior to reduce downtime or system stoppages due to unsafe proximity between humans and robots. In this work, we present an industry-oriented experimental setup, in which humans and robots share the same workplace. We have created our own dataset to detect humans wearing different clothing. We evaluate Faster R-CNN and SSD which are state-of-the-art detectors on two different camera viewpoints. In addition, this paper elaborates on the requirements for validating the safety of such a system to be used in industrial safety applications.","",""
0,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, M. Teimoori, F. Kriebel, Jeff Zhang, Kang Liu, Semeen Rehman, T. Theocharides, A. Artusi, S. Garg, M. Shafique","Robust Computing for Machine Learning-Based Systems",2020,"","","","",36,"2022-07-13 09:24:21","","10.1007/978-3-030-52017-5_20","","",,,,,0,0.00,0,12,2,"","",""
0,"E. Kondrateva, Polina Belozerova, M. Sharaev, Evgeny Burnaev, A. Bernstein, I. Samotaeva","Machine learning models reproducibility and validation for MR images recognition",2020,"","","","",37,"2022-07-13 09:24:21","","10.1117/12.2559525","","",,,,,0,0.00,0,6,2,"In the present work, we introduce a data processing and analysis pipeline, which ensures the reproducibility of machine learning models chosen for MR image recognition. The proposed pipeline is applied to solve the binary classification problems: epilepsy and depression diagnostics based on vectorized features from MR images. This model is then assessed in terms of classification performance, robustness and reliability of the results, including predictive accuracy on unseen data. The classification performance achieved with our approach compares favorably to ones reported in the literature, where usually no thorough model evaluation is performed.","",""
0,"S. V. Palmov","Studying the capabilities of the analytical system based on the machine learning method",2020,"","","","",38,"2022-07-13 09:24:21","","10.21778/2413-9599-2020-30-3-112-126","","",,,,,0,0.00,0,1,2,"Data analysis carried out by machine learning tools has covered almost all areas of human activity. This is due to a large amount of data that needs to be processed in order, for example, to predict the occurrence of specific events (an emergency, a customer contacting the organization’s technical support, a natural disaster, etc.) or to formulate recommendations regarding interaction with a certain group of people (personalized offers for the customer, a person’s reaction to advertising, etc.). The paper deals with the possibilities of the Multitool analytical system, created based on the machine learning method «decision tree», in terms of building predictive models that are suitable for solving data analysis problems in practical use. For this purpose, a series of ten experiments was conducted, in which the results generated by the system were evaluated in terms of their reliability and robustness using five criteria: arithmetic mean, standard deviation, variance, probability, and F-measure. As a result, it was found that Multitool, despite its limited functionality, allows creating predictive models of sufficient quality and suitable for practical use.","",""
1,"Khadija Attouri, M. Hajji, M. Mansouri, M. Harkat, A. Kouadri, H. Nounou, M. Nounou","Fault detection in photovoltaic systems using machine learning technique",2020,"","","","",39,"2022-07-13 09:24:21","","10.1109/SSD49366.2020.9364094","","",,,,,1,0.50,0,7,2,"To ensure high reliability of the Grid-Connected Photovoltaic (GCPV) systems, promptly faults detection, diagnosis and automatic process monitoring are essential tools to keep the PV and the grid network under optimal functioning. Regardless of fault types, incipient faults are usually more difficult to detect and accurately isolate. As an alternative and effective method, the principal components analysis (PCA) is proposed to extract and select more relevant features and support vector machines (SVM) technique is applied to quickly detect the faults that occur in a GCPV system. The T2 and squared weighted errors (SWE) statistics, generally used as fault detection indices, are appropriately extracted and selected within the PCA framework. Both of these features are fed to a SVM classifier handling the incipient fault detection. This task is carried out on a simulated GCPV operating under maximum power point trackers (MPPT) and matching realistic outdoor to demonstrate the effectiveness and robustness of the proposed technique.","",""
34,"Sai Gokul Subraveti, Zukui Li, V. Prasad, A. Rajendran","Machine Learning-Based Multiobjective Optimization of Pressure Swing Adsorption",2019,"","","","",40,"2022-07-13 09:24:21","","10.1021/acs.iecr.9b04173","","",,,,,34,11.33,9,4,3,"The transient, cyclic nature and the flexibility in process design makes the optimization of pressure-swing adsorption (PSA) computationally intensive. Two hybrid approaches incorporating machine learning methods into the optimization routines are described. The first optimization approach uses artificial neural networks as surrogate models for function evaluations. The surrogates are constructed in the course of the initial optimization and utilized for function evaluations in subsequent optimization. In the second optimization approach, important design variables are identified to reduce the high dimensional search space to a lower dimension based on partial least squares regression. The accuracy, robustness and reliability of these approaches are demonstrated by considering a complex 8-step PSA process for pre-combustion CO2 capture as a case study. The machine learning-based optimization ∼10x reduction in computational efforts while achieving the same performance as that of the detailed models.","",""
5,"Andrew Hines, P. Kendrick, A. Barri, Manish Narwaria, J. Redi","Robustness and prediction accuracy of Machine Learning for objective visual quality assessment",2014,"","","","",41,"2022-07-13 09:24:21","","","","",,,,,5,0.63,1,5,8,"Machine Learning (ML) is a powerful tool to support the development of objective visual quality assessment metrics, serving as a substitute model for the perceptual mechanisms acting in visual quality appreciation. Nevertheless, the reliability of ML-based techniques within objective quality assessment metrics is often questioned. In this study, the robustness of ML in supporting objective quality assessment is investigated, specifically when the feature set adopted for prediction is suboptimal. A Principal Component Regression based algorithm and a Feed Forward Neural Network are compared when pooling the Structural Similarity Index (SSIM) features perturbed with noise. The neural network adapts better with noise and intrinsically favours features according to their salient content.","",""
0,"Horacio L. França, Cesar Teixeira, N. Laranjeiro","Techniques for Evaluating the Robustness of Deep Learning Systems: A Preliminary Review",2021,"","","","",42,"2022-07-13 09:24:21","","10.1109/ladc53747.2021.9672592","","",,,,,0,0.00,0,3,1,"Machine Learning algorithms are currently being applied to a huge diversity of systems in various domains, including control systems in the industry, medical instruments, and autonomous vehicles, just to name a few. Systems based on deep learning models have become extremely popular in this context, and, like regular machine learning algorithms, are susceptible to errors caused by noisy data, outliers, or adversarial attacks. An error of a deep learning model in a safety-critical context can lead to a system failure, which can have disastrous consequences, including safety violations. In this paper we review the state of the art in techniques for evaluating the reliability (in lato sensu) of deep learning models, identify the main characteristics of the methods used and discuss research trends and open challenges.","",""
4,"Xingli Qin, Jie Yang, Pingxiang Li, Weidong Sun","Research on Water Body Extraction from Gaofen-3 Imagery Based on Polarimetric Decomposition and Machine Learning",2019,"","","","",43,"2022-07-13 09:24:21","","10.1109/IGARSS.2019.8898204","","",,,,,4,1.33,1,4,3,"The quick and accurate extraction of water bodies from images is imperative for land resources management, ecological protection, and flood disaster prevention. However, the prevalent methods for water body extraction of SAR imagery have the major issues of depending on expert experience, the poor retention of water-land boundaries, and a high false alarm rate. In this paper, focusing on these issues, we study the effectiveness of water body extraction using only simple polarimetric decomposition components and commonly used machine learning classifiers for Gaofen-3(GF-3) image. We test it using different sizes of training samples and compare it with the previous methods. The experimental results showed that the combination of polarimetric decomposition components and machine learning classifiers can achieve satisfactory accuracies in water body extraction of GF-3 image, and has strong robustness, reliability and high application value.","",""
4,"Tim Tiedemann, Jonas Fuhrmann, Se Paulsen, Thorben Schnirpel, Nils Schönherr, B. Buth, Stephan Pareigis","Miniature Autonomy as One Important Testing Means in the Development of Machine Learning Methods for Autonomous Driving: How ML-based Autonomous Driving could be Realized on a 1: 87 Scale",2019,"","","","",44,"2022-07-13 09:24:21","","10.5220/0007955704830488","","",,,,,4,1.33,1,7,3,"In the current state of autonomous driving machine learning methods are dominating, especially for the environment recognition. For such solutions, the reliability and the robustness is a critical question. A “miniature autonomy” with model vehicles at a small scale could be beneficial for different reasons. Examples are (1) the testability of dangerous and close-to-crash edge cases, (2) the possibility to test potentially dangerous concepts as end-to-end learning or combined inference and learning phases, (3) the need to optimize algorithms thoroughly, and (4) a potential reduction of test mile counts. Presented is the motivation for miniature autonomy and a discussion of testing of machine learning methods. Finally, two currently set up platforms including one with an FPGA-based TPU for ML acceleration are described.","",""
1,"Tianzhe Bao, Shengquan Xie, Pengfei Yang, P. Zhou, Zhiqiang Zhang","Towards Robust, Adaptive and Reliable Upper-limb Motion Estimation Using Machine Learning and Deep Learning--A Survey in Myoelectric Control.",2022,"","","","",45,"2022-07-13 09:24:21","","10.1109/JBHI.2022.3159792","","",,,,,1,1.00,0,5,1,"To develop multi-functional human-machine interfaces that can help disabled people reconstruct lost functions of upper-limbs, machine learning (ML) and deep learning (DL) techniques have been widely implemented to decode human movement intentions from surface electromyography (sEMG) signals. However, due to the high complexity of upper-limb movements and the inherent non-stable characteristics of sEMG, the usability of ML/DL based control schemes is still greatly limited in practical scenarios. To this end, tremendous efforts have been made to improve model robustness, adaptation, and reliability. In this article, we provide a systematic review on recent achievements, mainly from three categories: multi-modal sensing fusion to gain additional information of the user, transfer learning (TL) methods to eliminate domain shift impacts on estimation models, and post-processing approaches to obtain more reliable outcomes. Special attention is given to fusion strategies, deep TL frameworks, and confidence estimation. \textcolor{red}{Research challenges and emerging opportunities, with respect to hardware development, public resources, and decoding strategies, are also analysed to provide perspectives for future developments.","",""
2,"J. Sarkar, Cory Peterson","Operational Workload Impact on Robust Solid-State Storage Analyzed with Interpretable Machine Learning",2019,"","","","",46,"2022-07-13 09:24:21","","10.1109/IRPS.2019.8720510","","",,,,,2,0.67,1,2,3,"Solid-state storage technology is finding increasing adoption in enterprise and data center environments due to their high reliability and reducing cost. With high performance solid-state storage devices (SSDs) internally designed as distributed resilient systems, their operational behavior under materially different workloads is described in this research. Application of interpretable machine learning on internal parametric data of SSDs enables insights on workloads' interaction with the resilient system design. After prior research demonstrated significantly different accelerated workload stress, the analysis on resilience of the SSDs under random vs. pseudo-sequential workloads emphasize the efficacy and importance of their distributed resilience schemes. As such, these results provide causational insights on the mechanism of differential stress of the workloads impacting the resilience design principles. Moreover, the results elucidate guidelines strongly relevant from design robustness perspective for research on novel SSD architectures such as the proposed Open Channel SSD, towards deployment in hyperscale and virtualization environments.","",""
1,"J. M. Mutunga, J. Kimotho, P. Muchiri","Health-Index Based Prognostics for a Turbofan Engine using Ensemble of Machine Learning Algorithms",2019,"","","","",47,"2022-07-13 09:24:21","","","","",,,,,1,0.33,0,3,3,"A turbofan engine is a critical component of the aircraft, and monitoring its performance is important to avoid catastrophic failures and expensive downtime. Technologies in condition monitoring have made this possible by using sensors to collect data regarding fault propagation in systems. Machine Learning Algorithms (MLA) are useful tools for data analytics modeling. They use features from datasets to detect patterns and build predictive models. The predictive models are then used with new data, to determine the future reliability of a system by assessing the extent of degradation from its expected normal operating conditions. This in turn facilitating determination of the system's Remaining Useful Life (RUL). Several prognostics approaches have been proposed to predict RUL for complex systems. There is a need to further increase their accuracy and robustness, with the aim of increasing reliability. This can be achieved by use of ensemble techniques. Ensemble of predicting models developed using different MLAs or models developed using similar datasets are some of the ensemble techniques used in RUL modeling. Their results have demonstrated to achieve better performance compared to single modeling. This work aims at further increasing the prediction accuracy and robustness by combining these two ensemble techniques. A case study based on the National Aeronautics and Space Administration (NASA) turbofan engine degradation simulation dataset FD001 is presented. Evaluation results demonstrate that the developed ensemble model had better performance having a score value of 115. This is in comparison to the best approach in literature using similar dataset, where modeling was done using a single MLA and a score value of 231 was achieved. This illustrates the superiority of the developed prognostics approach having a diverse strategy in developing the RUL predicting model.","",""
6,"Manjari Pradhan, B. Bhattacharya, K. Chakrabarty, B. Bhattacharya","Predicting ${X}$ -Sensitivity of Circuit-Inputs on Test-Coverage: A Machine-Learning Approach",2019,"","","","",48,"2022-07-13 09:24:21","","10.1109/TCAD.2018.2878169","","",,,,,6,2.00,2,4,3,"Digital circuits are often prone to suffer from uncertain timing, inadequate sensor feedback, limited controllability of past states or inability of initializing memory-banks, and erroneous behavior of analog-to-digital converters, which may produce an unknown (<inline-formula> <tex-math notation=""LaTeX"">${X}$ </tex-math></inline-formula>) logic value at various circuit nodes. Additionally, many design bugs that are identified during the post-silicon validation phase manifest themselves as <inline-formula> <tex-math notation=""LaTeX"">${X}$ </tex-math></inline-formula>-values. The presence of such <inline-formula> <tex-math notation=""LaTeX"">${X}$ </tex-math></inline-formula>-sources on certain primary or secondary inputs of a logic circuit may cause loss of fault-coverage of a test set, which, in turn, may impact its reliability and robustness. In this paper, we provide a mechanism for predicting the sensitivity of <inline-formula> <tex-math notation=""LaTeX"">${X}$ </tex-math></inline-formula>-sources in terms of loss of fault-coverage, on the basis of learning only a few structural features of the circuit that are easy to extract from the netlist. We show that the <inline-formula> <tex-math notation=""LaTeX"">${X}$ </tex-math></inline-formula>-sources can be graded satisfactorily according to their sensitivity using support vector regression, thereby obviating the need for costly explicit simulation. Experimental results on several benchmark circuits demonstrate the efficacy, speed, and accuracy of prediction.","",""
0,"Marc Schmitt","Automated machine learning: AI-driven decision making in business analytics",2022,"","","","",49,"2022-07-13 09:24:21","","10.48550/arXiv.2205.10538","","",,,,,0,0.00,0,1,1,"The realization that AI-driven decision-making is indispensable in today’s fast-paced and ultra-competitive marketplace has raised interest in industrial machine learning (ML) applications significantly. The current demand for analytics experts vastly exceeds the supply. One solution to this problem is to increase the user-friendliness of ML frameworks to make them more accessible for the non-expert. Automated machine learning (AutoML) is an attempt to solve the problem of expertise by providing fully automated off-the-shelf solutions for model choice and hyperparameter tuning. This paper analyzed the potential of AutoML for applications within business analytics, which could help to increase the adoption rate of ML across all industries. The H2O AutoML framework was benchmarked against a manually tuned stacked ML model on three real-world datasets to test its performance, robustness, and reliability. The manually tuned ML model could reach a performance advantage in all three case studies used in the experiment. Nevertheless, the H2O AutoML package proved to be quite potent. It is fast, easy to use, and delivers reliable results, which come close to a professionally tuned ML model. The H2O AutoML framework in its current capacity is a valuable tool to support fast prototyping with the potential to shorten development and deployment cycles. It can also bridge the existing gap between supply and demand for ML experts and is a big step towards fully automated decisions in business analytics.","",""
0,"Tianyu Hu, Guibing Li","Machine Learning-Based Model in Predicting the Plate-End Debonding of FRP-Strengthened RC Beams in Flexure",2022,"","","","",50,"2022-07-13 09:24:21","","10.1155/2022/6069871","","",,,,,0,0.00,0,2,1,"Reinforced concrete (RC) beams strengthened with fiber reinforced polymers (FRPs) are structurally complex and prone to plate-end (PE) debonding. In this study, considering the extremely complicated nonlinear relationship between the PE debonding and the parameters, machine learning algorithms, namely, linear regression, ridge regression, decision tree, random forest, and neural network improved by sparrow search algorithm, are established to predict the PE debonding of RC beams strengthened with FRP. The results of reliability evaluation and parameter analysis reveal that ACI, CNR, fib-1, fib-2, and TR55-2 are a little conservative; AS and TR55-1 have the problem of overestimating the shear force; the accuracy and robustness of the SSA-BP model developed in this paper are good; the stirrup reinforcement has the greatest effect on PE debonding; and each parameter shows a complex nonlinear relationship with the shear force when PE debonding occurs.","",""
0,"M. Christakis, Hasan Ferit Eniser, J. Hoffmann, A. Singla, Valentin Wüstholz","Specifying and Testing k-Safety Properties for Machine-Learning Models",2022,"","","","",51,"2022-07-13 09:24:21","","10.48550/arXiv.2206.06054","","",,,,,0,0.00,0,5,1,"Machine-learning models are becoming increasingly prevalent in our lives, for instance assisting in image-classification or decision-making tasks. Consequently, the reliability of these models is of critical importance and has resulted in the development of numerous approaches for validating and verifying their robustness and fairness. However, beyond such specific properties, it is challenging to specify, let alone check, general functional-correctness expectations from models. In this paper, we take inspiration from specifications used in formal methods, expressing functional-correctness properties by reasoning about k different executions—socalled k-safety properties. Considering a credit-screening model of a bank, the expected property that ""if a person is denied a loan and their income decreases, they should still be denied the loan"" is a 2-safety property. Here, we show the wide applicability of k-safety properties for machine-learning models and present the first specification language for expressing them. We also operationalize the language in a framework for automatically validating such properties using metamorphic testing. Our experiments show that our framework is effective in identifying property violations, and that detected bugs could be used to train better models.","",""
0,"Rashid Ali, Deming Zhang, H. Cai, Weisheng Zhao, You Wang","A Machine Learning Attack-Resilient Strong PUF Leveraging the Process Variation of MRAM",2022,"","","","",52,"2022-07-13 09:24:21","","10.1109/tcsii.2022.3144497","","",,,,,0,0.00,0,5,1,"This brief presents a parallel magnetoresistive random access memory (MRAM)-based strong physical unclonable function (MPUF). The proposed MPUF leverages fabrication-induced process variations of magnetic tunnel junction (MTJ) and compares the resistance of MRAM cells to obtain a 1-bit response value. Contrary to arbiter PUF, the proposed MPUF achieves maximum security by satisfying strict avalanche criterion (SAC) property, and its secrecy capacity increases linearly with CRPs. Moreover, an array selection circuit (ASC) is proposed, which injects strong non-linearity into the PUF response and improves the robustness against machine learning (ML)- based modeling attacks. The proposed MPUF demonstrates high reliability, uniqueness, and uniformity with mean intra and inter-hamming distance (HD) of 0.447% and 49.76%, respectively. The robustness evaluation of the proposed MPUF against ML attacks, such as multilayer perceptron (MLP), linear regression (LR), and support vector machine (SVM), shows that it is resistant to these attacks, with ML-attack prediction accuracy of less than 79.7% for the basic two-array MPUF and less than 53.8% for the four-array MPUF with ASC. Moreover, compared to existing PUFs, the proposed MPUF has a large CRP space, high energy efficiency, and low area occupancy.","",""
0,"Tyler Cody, Justin Kauffman, J. Krometis, Daniel Sobien, Laura J. Freeman","Combinatorial coverage framework for machine learning in multi-domain operations",2022,"","","","",53,"2022-07-13 09:24:21","","10.1117/12.2617117","","",,,,,0,0.00,0,5,1,"Multi-domain operations (MDO) are characterized by simultaneous and sequential operations; rapid and continuous integration; and surprise. Machine learning (ML) for MDO is no different. Translated into ML, MDO requires highly assured yet rapid data and model fusion. Assurance demands robustness, reliability, and explain-ability, while speed demands computational efficiency and sample efficiency. Combinatorial interaction testing offers explainable and rigorous techniques to ML for fusing data and models with runtime guarantees. But such methods are underexplored in the literature. Combinatorial coverage has been applied to neuron- and layer-levels of neural networks, but only recently to ML in general. There are also ongoing debates of efficacy in the literature, but these debates are scoped to explainable deep learning. This work presents a framework for using combinatorial coverage for multi-domain operations. We discuss how coverage metrics can incorporate multi-modal meta-data and mission context into fusion processes, how coverage is oriented towards identifying gaps in and between sets of data, and how coverage can identify cases where performance is expected to be difficult. We conclude that combinatorial coverage should be considered a core capability for supporting ML in MDO.","",""
0,"M. Sedighkia, B. Datta","Detecting land use changes using hybrid machine learning methods in the Australian tropical regions",2022,"","","","",54,"2022-07-13 09:24:21","","10.1007/s10708-022-10678-5","","",,,,,0,0.00,0,2,1,"","",""
0,"Yiyang Chen, Wei Jiang, Themistoklis Charalambous","Machine learning based iterative learning control for non-repetitive time-varying systems",2021,"","","","",55,"2022-07-13 09:24:21","","10.1002/rnc.6272","","",,,,,0,0.00,0,3,1,"The repetitive tracking task for time-varying systems (TVSs) with non-repetitive time-varying parameters, which is also called non-repetitive TVSs, is realized in this paper using iterative learning control (ILC). A machine learning (ML) based nominal model update mechanism, which utilizes the linear regression technique to update the nominal model at each ILC trial only using the current trial information, is proposed for non-repetitive TVSs in order to enhance the ILC performance. Given that the ML mechanism forces the model uncertainties to remain within the ILC robust tolerance, an ILC update law is proposed to deal with non-repetitive TVSs. How to tune parameters inside ML and ILC algorithms to achieve the desired aggregate performance is also provided. The robustness and reliability of the proposed method are verified by simulations. Comparison with current state-of-the-art demonstrates its superior control performance in terms of controlling precision. This paper broadens ILC applications from time-invariant systems to non-repetitive TVSs, adopts ML regression technique to estimate non-repetitive time-varying parameters between two ILC trials and proposes a detailed parameter tuning mechanism to achieve desired performance, which are the main contributions.","",""
0,"F. Marulli, S. Marrone, Laura Verde","Sensitivity of Machine Learning Approaches to Fake and Untrusted Data in Healthcare Domain",2022,"","","","",56,"2022-07-13 09:24:21","","10.3390/jsan11020021","","",,,,,0,0.00,0,3,1,"Machine Learning models are susceptible to attacks, such as noise, privacy invasion, replay, false data injection, and evasion attacks, which affect their reliability and trustworthiness. Evasion attacks, performed to probe and identify potential ML-trained models’ vulnerabilities, and poisoning attacks, performed to obtain skewed models whose behavior could be driven when specific inputs are submitted, represent a severe and open issue to face in order to assure security and reliability to critical domains and systems that rely on ML-based or other AI solutions, such as healthcare and justice, for example. In this study, we aimed to perform a comprehensive analysis of the sensitivity of Artificial Intelligence approaches to corrupted data in order to evaluate their reliability and resilience. These systems need to be able to understand what is wrong, figure out how to overcome the resulting problems, and then leverage what they have learned to overcome those challenges and improve their robustness. The main research goal pursued was the evaluation of the sensitivity and responsiveness of Artificial Intelligence algorithms to poisoned signals by comparing several models solicited with both trusted and corrupted data. A case study from the healthcare domain was provided to support the pursued analyses. The results achieved with the experimental campaign were evaluated in terms of accuracy, specificity, sensitivity, F1-score, and ROC area.","",""
1,"M. Bansal, U. Dinesh, Remica Aggarwal, V. K.","On an attempt to explore challenges for Artificial Intelligence and Machine Learning in Indian Military and Defence Sector and Studying the Possible Inter-relationship amongst them using ISM Methodology",2019,"","","","",57,"2022-07-13 09:24:21","","10.5120/ijca2019919695","","",,,,,1,0.33,0,4,3,"Recent developments in Artificial Intelligence (AI) have resulted in breakthroughs in applications such as computer vision, natural language processing, robotics, and data mining. These breakthroughs have been optimally utilized in various military applications such as surveillance, reconnaissance , threat evaluation, underwater mine warfare, cyber security, intelligence analysis, command and control as well as military education and training . However, it is not easy to achieve these breakthroughs . They are subject to the package of challenges of being prone to high risks ; robustness and reliability crunch or absence of the required training to name a few. Present research work tries to explore such challenges and further attempts to study the possible interrelationships using ISM methodology.","",""
0,"A. Tahat, Azmi Al-Zaben, Lubna Saad El-Deen, Sara Abbad, C. Talhi","An Evaluation of Machine Learning Algorithms in an Experimental Structural Health Monitoring System Incorporating LoRa IoT Connectivity",2022,"","","","",58,"2022-07-13 09:24:21","","10.1109/I2MTC48687.2022.9806560","","",,,,,0,0.00,0,5,1,"The Internet of Things (IoT) offers dynamic mechanisms and methodologies for a broad number of practical applications by virtue of its integrated powerful advantages encompassing immense reliability, and superb robustness. This will expedite and simplify the deployment of IoT devices in civil structures and building settings for structural health monitoring (SHM) applications, including early warning systems (EWS). A SHM system extracts and provides information about variations in an individual component or in the complete structure. In this paper, an experimental SHM system incorporating the LoRa wireless IoT connectivity is presented, which includes assortment of sensor devices to acquire measurements of commonly monitored physical variables in typical SHM systems. The acquired concurrent measurements performed on the structure are aggregated at a designated cloud server, where they are analyzed, to predict the health status of the monitored structure. To that end, we conduct a comparative performance analysis of a collection of machine learning (ML) classification algorithms to evaluate their detection capacities in determining faults or variations in a monitored structure state. Numerical analysis results demonstrated that in our SHM system, the presence of a fault could be effectively predicted by means of a subset of the collection of considered ML classification algorithms. Computed evaluation metrics to characterize performance of our SHM system served to identify an optimum ML algorithm based on attained results, in addition to a training methodology for employment in SHM systems, to accurately detect the presence of a fault or damage in the monitored structure.","",""
0,"J. M. Mutunga, J. Kimotho, P. Muchiri","Estimating the Remaining Useful Lifetime of a Turbofan Engine using Ensemble of Machine Learning Algorithms",2019,"","","","",59,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,3,3,"Predicting the Remaining Useful Lifetime (RUL) of a component or system is important for effective and efficient maintenance. Prognostics approaches, used in predicting the future reliability of a system by assessing the extent of degradation of the product from its expected normal operating conditions, can be classified into physics-based and data driven. The later has received huge attention from researchers as it does not require expertise knowledge of the system at hand. Ensemble technique, associated with aggregation of predictions produced by multiple learning algorithms to improve predictive performance, robustness and accuracy in prognostics is the area of interest for this research that ensembles various selected regression Machine Learning Algorithms (MLA). The effect of ensembling various MLAs and MLAs models built using similar data is presented and a comparative study done with using only a single model. A case study of a NASA turbofan engine degradation simulation data set is presented. Simple averaging approach is proposed in combining the output of different sub models both at the training and predictive stages. Of the selected MLAs, ensemble regression, the best performing, had a Mean Absolute Error (MAE) of 39.63 for a single model compared to 22.91 for an ensemble of various sub models. The numerical results indicate that the ensemble approach outperforms use of individual machine learning models.","",""
0,"Sasmitha Dasanayaka, S. Silva, V. Shantha, D. Meedeniya, Thanuja D. Ambegoda","Interpretable Machine Learning for Brain Tumor Analysis Using MRI",2022,"","","","",60,"2022-07-13 09:24:21","","10.1109/ICARC54489.2022.9754131","","",,,,,0,0.00,0,5,1,"A brain tumor is a potentially fatal growth of cells in the central nervous system that can be categorized as benign or malignant. Advancements in deep learning in the recent past and the availability of high computational power have been influencing the automation of diagnosing brain tumors. DenseNet and U-Net are considered state of the art deep learning models for classification and segmentation of MRIs respectively. Despite the progress of deep learning in diagnosing using medical images, generic convolutional neural networks are still not fully adopted in clinical settings as they lack robustness and reliability. Moreover, such black-box models don’t offer a human interpretable justification as to why certain classification decisions are made, which makes them less preferable for medical diagnostics. Brain tumor segmentation and classification using deep learning techniques has been a popular research area in the last few decades but still, there are only a few models that are interpretable. In this paper, we have proposed an interpretable deep learning model which is more human understandable than existing black-box models, designed based on U-Net and DenseNet to segment and classify brain tumors using MRI. In our proposed model, we generate a heat map highlighting the contribution of each region of the input to the classification output and have validated the system using the MICCAI 2020 Brain Tumor dataset.","",""
0,"Mohammed Naveed Akram, Akshatha Ambekar, Ioannis Sorokos, Koorosh Aslansefat, Daniel Schneider","StaDRe and StaDRo: Reliability and Robustness Estimation of ML-based Forecasting using Statistical Distance Measures",2022,"","","","",61,"2022-07-13 09:24:21","","10.48550/arXiv.2206.11116","","",,,,,0,0.00,0,5,1,"Reliability estimation of Machine Learning (ML) models is becoming a crucial subject. This is particularly the case when such models are deployed in safety-critical applications, as the decisions based on model predictions can result in hazardous situations. As such, recent research has proposed methods to achieve safe, dependable and reliable ML systems. One such method is to detect and analyze distributional shift, and then measuring how such systems respond to these shifts. This was proposed in earlier work in SafeML. This work focuses on the use of SafeML for time series data, and on reliability and robustness estimation of ML-forecasting methods using statistical distance measures. To this end, distance measures based on the Empirical Cumulative Distribution Function (ECDF), proposed in SafeML, are explored to measure Statistical-Distance Dissimilarity (SDD) across time series. We then propose SDD-based Reliability Estimate (StaDRe) and SDDbased Robustness (StaDRo) measures. With the help of clustering technique, identification of similarity between statistical properties of data seen during training, and the forecasts is done. The proposed method is capable of providing a link between dataset SDD and Key Performance Indices (KPIs) of the ML models.","",""
103,"F. Granata, S. Papirio, G. Esposito, R. Gargano, G. D. Marinis","Machine Learning Algorithms for the Forecasting of Wastewater Quality Indicators",2017,"","","","",62,"2022-07-13 09:24:21","","10.3390/W9020105","","",,,,,103,20.60,21,5,5,"Stormwater runoff is often contaminated by human activities. Stormwater discharge into water bodies significantly contributes to environmental pollution. The choice of suitable treatment technologies is dependent on the pollutant concentrations. Wastewater quality indicators such as biochemical oxygen demand (BOD5), chemical oxygen demand (COD), total suspended solids (TSS), and total dissolved solids (TDS) give a measure of the main pollutants. The aim of this study is to provide an indirect methodology for the estimation of the main wastewater quality indicators, based on some characteristics of the drainage basin. The catchment is seen as a black box: the physical processes of accumulation, washing, and transport of pollutants are not mathematically described. Two models deriving from studies on artificial intelligence have been used in this research: Support Vector Regression (SVR) and Regression Trees (RT). Both the models showed robustness, reliability, and high generalization capability. However, with reference to coefficient of determination R2 and root‐mean square error, Support Vector Regression showed a better performance than Regression Tree in predicting TSS, TDS, and COD. As regards BOD5, the two models showed a comparable performance. Therefore, the considered machine learning algorithms may be useful for providing an estimation of the values to be considered for the sizing of the treatment units in absence of direct measures.","",""
0,"Yiyang Chen, Wei Jiang, Themistoklis Charalambous","Machine learningbased iterative learning control for non-repetitive time-varying systems",2021,"","","","",63,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,3,1,"The repetitive tracking task for time-varying systems (TVSs) with non-repetitive time-varying parameters, which is also called non-repetitive TVSs, is realized in this paper using iterative learning control (ILC). A machine learning (ML) based nominal model update mechanism, which utilizes the linear regression technique to update the nominal model at each ILC trial only using the current trial information, is proposed for non-repetitive TVSs in order to enhance the ILC performance. Given that the ML mechanism forces the model uncertainties to remain within the ILC robust tolerance, an ILC update law is proposed to deal with non-repetitive TVSs. How to tune parameters inside ML and ILC algorithms to achieve the desired aggregate performance is also provided. The robustness and reliability of the proposed method are verified by simulations. Comparison with current state-of-the-art demonstrates its superior control performance in terms of controlling precision. This paper broadens ILC applications from time-invariant systems to non-repetitive TVSs, adopts ML regression technique to estimate non-repetitive time-varying parameters between two ILC trials and proposes a detailed parameter tuning mechanism to achieve desired performance, which are the main contributions.","",""
9,"Song Huang, Erhu Liu, Zhan-wei Hui, Shi-Qi Tang, Suo-Juan Zhang","Challenges of Testing Machine Learning Applications",2018,"","","","",64,"2022-07-13 09:24:21","","10.23940/IJPE.18.06.P18.12751282","","",,,,,9,2.25,2,5,4,"Machine learning applications have achieved impressive results in many areas and provided effective solution to deal with image recognition, automatic driven, voice processing etc. problems. As these applications are adopted by multiple critical areas, their reliability and robustness becomes more and more important. Software testing is a typical way to ensure the quality of applications. Approaches for testing machine learning applications are needed. This paper analyzes the characteristics of several machine learning algorithms and concludes the main challenges of testing machine learning applications. Then, multiple preliminary techniques are presented according to the challenges. Moreover, the paper demonstrates how these techniques can be used to solve the problems during the testing of machine learning applications.","",""
0,"Uche Onyema, Mahmoud Shafik, T. Dobrev, James Hardy","A Tracking Platform Solution for Autonomous Vehicles Localization in Future Smart Cities Using Machine and Deep Learning",2021,"","","","",65,"2022-07-13 09:24:21","","10.3233/atde210022","","",,,,,0,0.00,0,4,1,"The localization of autonomous vehicles requires, accurate tracking of its position and orientation in all conditions. As modern cities evolve localization would require a more precise accuracy that up to the level of centimetre and decimetre. One of the most crucial struggles in global positioning system and inertial navigation fusion is that the accuracy of the algorithm is reduced during GPS interruptions. In recent days bigdata, machine and deep learning offer great opportunities, especially for future smart and industrial 4.0 autonomous applications. This research programme is aiming to investigate and deploy machine and deep learning approach to improve and reach the level of reliability, accuracy and robustness required at low-cost GPS/IMU unit. The programme will also present a tracking platform solution that would compensates the issues of lack of accuracy in existing localization methods. The initial result of this ongoing programme is presented and reported in this paper. The paper also covers the research programme future development plans and milestones.","",""
1,"Pin-Yu Chen, Sijia Liu","Holistic Adversarial Robustness of Deep Learning Models",2022,"","","","",66,"2022-07-13 09:24:21","","","","",,,,,1,1.00,1,2,1,"Adversarial robustness studies the worst-case performance of a machine learning model to ensure safety and reliability. With the proliferation of deep-learning based technology, the potential risks associated with model development and deployment can be amplified and become dreadful vulnerabilities. This paper provides a comprehensive overview of research topics and foundational principles of research methods for adversarial robustness of deep learning models, including attacks, defenses, verification, and novel applications.","",""
0,"Harshad Purani","A machine learning based performance enhancement mechanism for reliable link in cognitive radio for wireless networks",2018,"","","","",67,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,1,4,"Cognitive radio is an efficient technology to avail the benefit of next generation wireless network by utilizing the available spectrum in a dynamic manner. Cognitive radio is used to enhance spectrum utilization and efficiency. Most researches in cognitive radio is done to improve spectrum efficiency and its utilization in dynamic manner. However least is done to improve the link reliability of cognitive radio for wireless networks link reliability is one of the major factor to enhance the network robustness. The main objective of our work is to show the application of machine learning algorithm to improve the network failures and thereby improving the reliability of wireless networks which are using cognitive radio in order to achieve next generation customer expectations.","",""
3,"Kriti Kohli, M. Jobes, Ioana Graur","Automated detection and classification of printing sub-resolution assist features using machine learning algorithms",2017,"","","","",68,"2022-07-13 09:24:21","","10.1117/12.2261417","","",,,,,3,0.60,1,3,5,"Sub-Resolution Assist Feature (SRAF) printing is a critical yield detractor and known issue in OPC technology. SRAF print avoidance models can be used to determine where undesirable printing is likely to occur, but such models lack the necessary robustness and reliability for the detection of all SRAF printing cases. Classification of printing SRAFs is a subjective and manual task where many engineering hours are spent. In this work we demonstrate a reliable way to accurately classify images according to SRAF printing risk. Testing multiple sets of data, across multiple processes, yielded a prediction success rate of 97% wherein only a single image was under-predicted. Under-prediction is when a model fails to predict printing SRAFs; a key defect generator, as it means the model will not be able to remove the SRAF shape in the OPC iteration before mask build. We propose a new methodology as to accurately auto-classify and filter images with SRAF printing on wafer. This scalable solution will improve the quality and reliability of SRAF print avoidance models and reduce the risk of printing SRAF by removing the manual, highly subjective, image classification step.","",""
34,"A. Sargolzaei, C. Crane, Alireza Abbaspour, S. Noei","A Machine Learning Approach for Fault Detection in Vehicular Cyber-Physical Systems",2016,"","","","",69,"2022-07-13 09:24:21","","10.1109/ICMLA.2016.0112","","",,,,,34,5.67,9,4,6,"A network of vehicular cyber-physical systems (VCPSs) can use wireless communications to interact with each other and the surrounding environment to improve transportation safety, mobility, and sustainability. However, cloud-oriented architectures are vulnerable to cyber attacks, which may endanger passenger and pedestrian safety and privacy, and cause severe property damage. For instance, a hacker can use message falsification attack to affect functionality of a particular application in a platoon of VCPSs. In this paper, a neural network-based fault detection technique is applied to detect and track fault data injection attacks on the cooperative adaptive cruise control layer of a platoon of connected vehicles in real time. A decision support system was developed to reduce the probability and severity of any consequent accident. A case study with its design specifications is demonstrated in detail. The simulation results show that the proposed method can improve system reliability, robustness, and safety.","",""
1,"Lin Chen, Yunhui Ding, Huimin Wang, Yijue Wang, Bohao Liu, Shuxiao Wu, Hao Li, H. Pan","Online Estimating State of Health of Lithium-Ion Batteries Using Hierarchical Extreme Learning Machine",2022,"","","","",70,"2022-07-13 09:24:21","","10.1109/tte.2021.3107727","","",,,,,1,1.00,0,8,1,"Battery state-of-health (SoH) monitoring is of great importance to ensure the safety and reliability of battery systems. This study proposed an innovative SoH estimation method using hierarchical extreme learning machine (HELM) to improve the estimation robustness and accuracy without the complex parameter model was directly applied to establish the HELM-oriented online SoH estimation framework. First, the increase in mean ohmic resistance was constructed as a novel health indicator (HI) to characterize battery aging. Then, the HI was adopted for offline training to build an HELM model, which captures the underlying correlation between the extracted HI and capacity degradation. Finally, the datasets of four batteries at three different temperatures with dynamic loading profiles were used for validation. The results show that the SoH estimation errors are no more than 1.5%, while the training and estimation datasets are from the same temperature; when the SoH estimation is conducted at different temperatures, the maximum error is only 3.36%. The results indicate that the proposed method had good generalization and reliability for SoH estimation, which is applicable for dynamic scenarios with different temperatures.","",""
33,"Martin Genzel, Jan MacDonald, Maximilian März","Solving Inverse Problems With Deep Neural Networks - Robustness Included?",2020,"","","","",71,"2022-07-13 09:24:21","","10.1109/TPAMI.2022.3148324","","",,,,,33,16.50,11,3,2,"In the past five years, deep learning methods have become state-of-the-art in solving various inverse problems. Before such approaches can find application in safety-critical fields, a verification of their reliability appears mandatory. Recent works have pointed out instabilities of deep neural networks for several image reconstruction tasks. In analogy to adversarial attacks in classification, it was shown that slight distortions in the input domain may cause severe artifacts. The present article sheds new light on this concern, by conducting an extensive study of the robustness of deep-learning-based algorithms for solving underdetermined inverse problems. This covers compressed sensing with Gaussian measurements as well as image recovery from Fourier and Radon measurements, including a real-world scenario for magnetic resonance imaging (using the NYU-fastMRI dataset). Our main focus is on computing adversarial perturbations of the measurements that maximize the reconstruction error. A distinctive feature of our approach is the quantitative and qualitative comparison with total-variation minimization, which serves as a provably robust reference method. In contrast to previous findings, our results reveal that standard end-to-end network architectures are not only resilient against statistical noise, but also against adversarial perturbations. All considered networks are trained by common deep learning techniques, without sophisticated defense strategies.","",""
13,"Shamik Kundu, K. Basu, Mehdi Sadi, Twisha Titirsha, Shihao Song, Anup Das, Ujjwal Guin","Special Session: Reliability Analysis for ML/AI Hardware",2021,"","","","",72,"2022-07-13 09:24:21","","","","",,,,,13,13.00,2,7,1,"Artificial intelligence (AI) and Machine Learning (ML) are becoming pervasive in today’s applications, such as autonomous vehicles, healthcare, aerospace, cybersecurity, and many critical applications. Ensuring the reliability and robustness of the underlying AI/ML hardware becomes our paramount importance. In this paper, we explore and evaluate the reliability of different AI/ML hardware. The first section outlines the reliability issues in a commercial systolic array-based ML accelerator in the presence of faults engendering from devicelevel non-idealities in the DRAM. Next, we quantified the impact of circuit-level faults in the MSB and LSB logic cones of the Multiply and Accumulate (MAC) block of the AI accelerator on the AI/ML accuracy. Finally, we present two key reliability issues – circuit aging and endurance in emerging neuromorphic hardware platforms and present our system-level approach to mitigate them.","",""
33,"Megha Srivastava, Tatsunori B. Hashimoto, Percy Liang","Robustness to Spurious Correlations via Human Annotations",2020,"","","","",73,"2022-07-13 09:24:21","","","","",,,,,33,16.50,11,3,2,"The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption---useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible test-time shifts. Empirically, we show improvements of 5-10% on a digit recognition task confounded by rotation, and 1.5-5% on the task of analyzing NYPD Police Stops confounded by location.","",""
4,"Maurice Weber, Nana Liu, Bo Li, Ce Zhang, Zhikuan Zhao","Optimal provable robustness of quantum classification via quantum hypothesis testing",2020,"","","","",74,"2022-07-13 09:24:21","","10.1038/s41534-021-00410-5","","",,,,,4,2.00,1,5,2,"","",""
58,"M. Hansen, M. Haugland, T. Sinkjaer","Evaluating robustness of gait event detection based on machine learning and natural sensors",2004,"","","","",75,"2022-07-13 09:24:21","","10.1109/TNSRE.2003.819890","","",,,,,58,3.22,19,3,18,"A real-time system for deriving timing control for functional electrical stimulation for foot-drop correction, using peripheral nerve activity as a sensor input, was tested for reliability to investigate the potential for clinical use. The system, which was previously reported on, was tested on a hemiplegic subject instrumented with a recording cuff electrode on the Sural nerve, and a stimulation cuff electrode on the Peroneal cuff. Implanted devices enabled recording and stimulation through telelinks. An input domain was derived from the recorded electroneurogram and fed to a detection algorithm based on an adaptive logic network for controlling the stimulation timing. The reliability was tested by letting the subject wear different foot wear and walk on different surfaces than when the training data was recorded. The detection system was also evaluated several months after training. The detection system proved able to successfully detect when walking with different footwear on varying surfaces up to 374 days after training, and thereby showed great potential for being clinically useful.","",""
47,"A. Joseph, P. Laskov, F. Roli, J. Tygar, Blaine Nelson","Machine Learning Methods for Computer Security (Dagstuhl Perspectives Workshop 12371)",2012,"","","","",76,"2022-07-13 09:24:21","","10.4230/DagMan.3.1.1","","",,,,,47,4.70,9,5,10,"The study of learning in adversarial environments is an emerging discipline at the juncture between machine learning and computer security that raises new questions within both fields.    The interest in learning-based methods for security and system design applications comes from the high degree of complexity of phenomena underlying the security and reliability of computer systems. As it becomes increasingly difficult to reach the desired properties by design alone, learning methods are being used to obtain a better understanding of various data collected from these complex systems.    However, learning approaches can be co-opted or evaded by adversaries, who change to counter them. To-date, there has been limited research into learning techniques that are resilient to attacks with provable robustness guarantees making the task of designing secure learning-based systems a lucrative open  research area with many challenges.    The Perspectives Workshop, ``Machine Learning Methods for Computer Security'' was convened to bring together interested researchers from both the computer security and machine learning communities to discuss techniques, challenges, and future research directions for secure learning and learning-based security applications.    This workshop featured twenty-two invited talks from leading researchers within the secure learning community covering topics in adversarial learning, game-theoretic learning, collective classification, privacy-preserving learning, security evaluation metrics, digital forensics, authorship identification, adversarial advertisement detection, learning for offensive security, and data sanitization. The workshop also featured workgroup sessions  organized into three topic: machine learning for computer security, secure learning, and future applications of secure learning.","",""
1,"Niklas Risse, C. Gopfert, Jan Philip Göpfert","How to Compare Adversarial Robustness of Classifiers from a Global Perspective",2020,"","","","",77,"2022-07-13 09:24:21","","10.1007/978-3-030-86362-3_3","","",,,,,1,0.50,0,3,2,"","",""
0,"Madeleine Schneider, D. Aspinall, Nathaniel D. Bastian","Evaluating Model Robustness to Adversarial Samples in Network Intrusion Detection",2021,"","","","",78,"2022-07-13 09:24:21","","10.1109/BigData52589.2021.9671580","","",,,,,0,0.00,0,3,1,"Adversarial machine learning, a technique which seeks to deceive machine learning (ML) models, threatens the utility and reliability of ML systems. This is particularly relevant in critical ML implementations such as those found in Network Intrusion Detection Systems (NIDS). This paper considers the impact of adversarial influence on NIDS and proposes ways to improve ML based systems. Specifically, we consider five feature robustness metrics to determine which features in a model are most vulnerable, and four defense methods. These methods are tested on six ML models with four adversarial sample generation techniques. Our results show that across different models and adversarial generation techniques, there is limited consistency in vulnerable features or in effectiveness of defense method.","",""
0,"Mohamed Abdelhack, Jiaming Zhang, Sandhya Tripathi, B. Fritz, M. Avidan, Yixin Chen, C. King","A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues",2021,"","","","",79,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,7,1,"Data quality is a common problem in machine learning, especially in high-stakes settings such as healthcare. Missing data affects accuracy, calibration, and feature attribution in complex patterns. Developers often train models on carefully curated datasets to minimize missing data bias; however, this reduces the usability of such models in production environments, such as real-time healthcare records. Making machine learning models robust to missing data is therefore crucial for practical application. While some classifiers naturally handle missing data, others, such as deep neural networks, are not designed for unknown values. We propose a novel neural network modification to mitigate the impacts of missing data. The approach is inspired by neuromodulation that is performed by biological neural networks. Our proposal replaces the fixed weights of a fully-connected layer with a function of an additional input (reliability score) at each input, mimicking the ability of cortex to upand down-weight inputs based on the presence of other data. The modulation function is jointly learned with the main task using a multi-layer perceptron. We tested our modulating fully connected layer on multiple classification, regression, and imputation problems, and it either improved performance or generated comparable performance to conventional neural network architectures concatenating reliability to the inputs. Models with modulating layers were more robust against degradation of data quality by introducing additional missingness at evaluation time. These results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time settings. ∗Author has since moved to the Krembil Center for Neuroinformatics, Toronto, ON, Canada Preprint. Under review. ar X iv :2 10 7. 08 57 4v 1 [ cs .L G ] 1 9 Ju l 2 02 1","",""
7,"A. Joseph, P. Laskov, F. Roli, J. Tygar, Blaine Nelson","2 Machine Learning Methods for Computer Security 1 Executive Summary",2013,"","","","",80,"2022-07-13 09:24:21","","","","",,,,,7,0.78,1,5,9,"The study of learning in adversarial environments is an emerging discipline at the juncture between machine learning and computer security. The interest in learning-based methods for securityand system-design applications comes from the high degree of complexity of phenomena underlying the security and reliability of computer systems. As it becomes increasingly difficult to reach the desired properties solely using statically designed mechanisms, learning methods are being used more and more to obtain a better understanding of various data collected from these complex systems. However, learning approaches can be evaded by adversaries, who change their behavior in response to the learning methods. To-date, there has been limited research into learning techniques that are resilient to attacks with provable robustness guarantees The Perspectives Workshop, “Machine Learning Methods for Computer Security” was convened to bring together interested researchers from both the computer security and machine learning communities to discuss techniques, challenges, and future research directions for secure learning and learning-based security applications. As a result of the twenty-two invited presentations, workgroup sessions and informal discussion, several priority areas of research were identified. The open problems identified in the field ranged from traditional applications of machine learning in security, such as attack detection and analysis of malicious software, to methodological issues related to secure learning, especially the development of new formal approaches with provable security guarantees. Finally a number of other potential applications were pinpointed outside of the traditional scope of computer security in which security issues may also arise in connection with data-driven methods. Examples of such applications are social media spam, plagiarism detection, authorship identification, copyright enforcement, computer vision (particularly in the context of biometrics), and sentiment analysis. Perspectives Workshop 09.–14. September, 2012 – www.dagstuhl.de/12371 1998 ACM Subject Classification C.2.0 Computer-Communication Networks (General): Security and Protection (e.g., firewalls), D.4.6 Operating Systems (Security and Protection), I.2.6 Artificial Intelligence (Learning), I.2.7 Artificial Intelligence (Natural Language Processing), I.2.8 Artificial Intelligence (Problem Solving, Control Methods, and Search), K.4.1 Computers and Society (Public Policy Issues): Privacy, K.6.5 Management of Computing and Information Systems (Security and Protection)","",""
0,"A. Joseph, P. Laskov, F. Roli, J. Tygar, Blaine Nelson","Machine Learning Methods for Computer Security (dagstuhl Perspectives Workshop 12371) Machine Learning Methods for Computer Security Machine Learning Methods for Computer Security 1 Executive Summary Table of Contents",2014,"","","","",81,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,5,8,"The study of learning in adversarial environments is an emerging discipline at the juncture between machine learning and computer security. The interest in learning-based methods for securityand system-design applications comes from the high degree of complexity of phenomena underlying the security and reliability of computer systems. As it becomes increasingly difficult to reach the desired properties solely using statically designed mechanisms, learning methods are being used more and more to obtain a better understanding of various data collected from these complex systems. However, learning approaches can be evaded by adversaries, who change their behavior in response to the learning methods. To-date, there has been limited research into learning techniques that are resilient to attacks with provable robustness guarantees The Perspectives Workshop, “Machine Learning Methods for Computer Security” was convened to bring together interested researchers from both the computer security and machine learning communities to discuss techniques, challenges, and future research directions for secure learning and learning-based security applications. As a result of the twenty-two invited presentations, workgroup sessions and informal discussion, several priority areas of research were identified. The open problems identified in the field ranged from traditional applications of machine learning in security, such as attack detection and analysis of malicious software, to methodological issues related to secure learning, especially the development of new formal approaches with provable security guarantees. Finally a number of other potential applications were pinpointed outside of the traditional scope of computer security in which security issues may also arise in connection with data-driven methods. Examples of such applications are social media spam, plagiarism detection, authorship identification, copyright enforcement, computer vision (particularly in the context of biometrics), and sentiment analysis. Perspectives Workshop 09.–14. September, 2012 – www.dagstuhl.de/12371 1998 ACM Subject Classification C.2.0 Computer-Communication Networks (General): Security and Protection (e.g., firewalls), D.4.6 Operating Systems (Security and Protection), I.2.6 Artificial Intelligence (Learning), I.2.7 Artificial Intelligence (Natural Language Processing), I.2.8 Artificial Intelligence (Problem Solving, Control Methods, and Search), K.4.1 Computers and Society (Public Policy Issues): Privacy, K.6.5 Management of Computing and Information Systems (Security and Protection)","",""
0,"A. Hu, Rong Zhang, Dong Yin, Wenlong Hu","Machine learning-based multi-channel evaluation pooling strategy for image quality assessment",2013,"","","","",82,"2022-07-13 09:24:21","","10.1109/ICIP.2013.6738088","","",,,,,0,0.00,0,4,9,"Multi-channel peculiarity is one of the most widely accepted human visual system (HVS) models for perceptual image quality assessment (IQA). Otherwise than extensive studies of channel decomposition and intra-channel distortion measure, relatively scant research effort has been devoted to develop efficient multichannel evaluation pooling strategies. In this paper, we review and address the limitations of the conventional pooling models based on HVS sensitivities-weighted average. Instead, we explore the utilization of machine learning for this pooling problem, since machine learning can establish an optimal and generalized mapping that models the highly complex relationship between the multi-channel distortion evaluations and the perceived image quality. Experiments based on available subjective IQA databases demonstrate the rationality, reliability and robustness of our proposed scheme.","",""
0,"A. Joseph, P. Laskov, F. Roli, J. Tygar, Blaine Nelson","128 12371 – Machine Learning Methods for Computer Security 6 . 2 Secure Learning : Theory and Methods",2013,"","","","",83,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,5,9,"The study of learning in adversarial environments is an emerging discipline at the juncture between machine learning and computer security that raises new questions within both fields. The interest in learning-based methods for security and system design applications comes from the high degree of complexity of phenomena underlying the security and reliability of computer systems. As it becomes increasingly difficult to reach the desired properties by design alone, learning methods are being used to obtain a better understanding of various data collected from these complex systems. However, learning approaches can be co-opted or evaded by adversaries, who change to counter them. To-date, there has been limited research into learning techniques that are resilient to attacks with provable robustness guarantees making the task of designing secure learning-based systems a lucrative open research area with many challenges. The Perspectives Workshop, “Machine Learning Methods for Computer Security” was convened to bring together interested researchers from both the computer security and machine learning communities to discuss techniques, challenges, and future research directions for secure learning and learning-based security applications. This workshop featured twenty-two invited talks from leading researchers within the secure learning community covering topics in adversarial learning, game-theoretic learning, collective classification, privacy-preserving learning, security evaluation metrics, digital forensics, authorship identification, adversarial advertisement detection, learning for offensive security, and data sanitization. The workshop also featured workgroup sessions organized into three topic: machine learning for computer security, secure learning, and future applications of secure learning. Seminar 09.–14. September, 2012 – www.dagstuhl.de/12371 1998 ACM Subject Classification C.2.0 Computer-Communication Networks (General): Security and Protection (e.g., firewalls); D.4.6 Operating Systems (Security and Protection); I.2.6 Artificial Intelligence (Learning); I.2.7 Artificial Intelligence (Natural Language Processing); I.2.8 Artificial Intelligence (Problem Solving, Control Methods, and Search); K.4.1 Computers and Society (Public Policy Issues): Privacy; K.6.5 Management of Computing and Information Systems (Security and Protection)","",""
1,"Shamik Kundu, K. Basu, Mehdi Sadi, Twisha Titirsha, Shihao Song, Anup Das, Ujjwal Guin","Special Session: Reliability Analysis for AI/ML Hardware",2021,"","","","",84,"2022-07-13 09:24:21","","10.1109/VTS50974.2021.9441050","","",,,,,1,1.00,0,7,1,"Artificial intelligence (AI) and Machine Learning (ML) are becoming pervasive in today’s applications, such as autonomous vehicles, healthcare, aerospace, cybersecurity, and many critical applications. Ensuring the reliability and robustness of the underlying AI/ML hardware becomes our paramount importance. In this paper, we explore and evaluate the reliability of different AI/ML hardware. The first section outlines the reliability issues in a commercial systolic array-based ML accelerator in the presence of faults engendering from device-level non-idealities in the DRAM. Next, we quantified the impact of circuit-level faults in the MSB and LSB logic cones of the Multiply and Accumulate (MAC) block of the AI accelerator on the AI/ML accuracy. Finally, we present two key reliability issues- circuit aging and endurance in emerging neuromorphic hardware platforms and present our system-level approach to mitigate them.","",""
0,"Saranyu Chattopadhyay, Pranesh Santikellur, R. Chakraborty, J. Mathew, M. Ottavi","A Conditionally Chaotic Physically Unclonable Function Design Framework with High Reliability",2021,"","","","",85,"2022-07-13 09:24:21","","10.1145/3460004","","",,,,,0,0.00,0,5,1,"  Physically Unclonable Function (PUF) circuits are promising low-overhead hardware security primitives, but are often gravely susceptible to machine learning–based modeling attacks. Recently, chaotic PUF circuits have been proposed that show greater robustness to modeling attacks. However, they often suffer from unacceptable overhead, and their analog components are susceptible to low reliability. In this article, we propose the concept of a  conditionally chaotic PUF  that enhances the reliability of the analog components of a chaotic PUF circuit to a level at par with their digital counterparts. A conditionally chaotic PUF has two modes of operation:  bistable  and  chaotic  , and switching between these two modes is conveniently achieved by setting a mode-control bit (at a secret position) in an applied input challenge. We exemplify our PUF design framework for two different PUF variants—the CMOS Arbiter PUF and a previously proposed hybrid CMOS-memristor PUF, combined with a hardware realization of the  Lorenz system  as the chaotic component. Through detailed circuit simulation and modeling attack experiments, we demonstrate that the proposed PUF circuits are highly robust to modeling and cryptanalytic attacks, without degrading the reliability of the original PUF that was combined with the chaotic circuit, and incurs acceptable hardware footprint. ","",""
1,"Simone Bexten, Johann Schmidt, Christoph Walter, N. Elkmann","Human Action Recognition as part of a Natural Machine Operation Framework",2021,"","","","",86,"2022-07-13 09:24:21","","10.1109/ETFA45728.2021.9613331","","",,,,,1,1.00,0,4,1,"The reliability of systems that use machine learning to recognize the human working in an industrial environment is of high importance for the employee safety. we present a framework which is capable of recognizing the person's natural interaction with an industrial machine. We focus on the application of human action recognition in the context of machine operation by skilled workers in industrial or commercial environments. We propose a framework that includes action recognition as part of a software component for understanding behavior. For our use case, we defined an exemplary machine operation workflow which we use to compare five different neural networks in terms of prediction accuracy and real-time capabilities. Moreover, we compare different input shapes as the resolution of input images and the size of the possible 3D-volume in order to study the robustness of the models. For our evaluation, we created our own custom dataset containing six action classes. Our analysis shows that the best model is the I3D with color images, a resolution of 112 × 112 pixels and 16 consecutive frames. The I3D also exhibited the best run-time performance for real-time applications.","",""
4,"Ahsan Morshed, R. Dutta","Machine Learning based Vocabulary Management Tool Assessment for the Linked Open Data",2012,"","","","",87,"2022-07-13 09:24:21","","10.5120/9724-4197","","",,,,,4,0.40,2,2,10,"domain vocabularies in the context of developing the knowledge based Linked Open data system is the most important discipline on the web. Many editors are available for developing and managing the vocabularies or Ontologies. However, selecting the most relevant editor is very difficult since each vocabulary construction initiative requires its own budget, time, resources. In this paper a novel unsupervised machine learning based comparative assessment mechanism has been proposed for selecting the most relevant editor. Defined evaluation criterions were functionality, reusability, data storage, complexity, association, maintainability, resilience, reliability, robustness, learnability, availability, flexibility, and visibility. Principal component analysis (PCA) was applied on the feedback data set collected from a survey involving sixty users. Focus was to identify the least correlated features carrying the most independent information variance to optimize the tool selection process. An automatic evaluation method based on Bagging Decision Trees has been used to identify the most suitable editor. Three tools namely Vocbench, TopBraid EVN and Pool Party Thesaurus Manager have been evaluated. Decision tree based analysis recommended the Vocbench and the Pool Party Thesaurus Manager are the better performer than the TopBraid EVN tool with very similar recommendation scores.","",""
4,"T. Fromm, B. Staehle, W. Ertel","Robust multi-algorithm object recognition using Machine Learning methods",2012,"","","","",88,"2022-07-13 09:24:21","","10.1109/MFI.2012.6343014","","",,,,,4,0.40,1,3,10,"Robust object recognition is a crucial requirement for many robotic applications. We propose a method towards increasing reliability and flexibility of object recognition for robotics. This is achieved by the fusion of diverse recognition frameworks and algorithms on score level which use characteristics like shape, texture and color of the objects. Machine Learning allows for the automatic combination of the respective recognition methods' outputs instead of having to adapt their hypothesis metrics to a common basis. We show the applicability of our approach through several real-world experiments in a service robotics environment. Great importance is attached to robustness, especially in varying environments.","",""
0,"Luyu Qiu, Yi Yang, Caleb Chen Cao, Yueyuan Zheng, H. Ngai, Janet Hsiao, Lei Chen","Generating Perturbation-based Explanations with Robustness to Out-of-Distribution Data",2022,"","","","",89,"2022-07-13 09:24:21","","10.1145/3485447.3512254","","",,,,,0,0.00,0,7,1,"Perturbation-based techniques are promising for explaining black-box machine learning models due to their effectiveness and ease of implementation. However, prior works have faced the problem of Out-of-Distribution (OoD) — an artifact of randomly perturbed data becoming inconsistent with the original dataset, degrading the reliability of generated explanations, which is still under-explored according to our best knowledge. This work addresses the OoD issue by designing a simple yet effective module that can quantify the affinity between the perturbed data and the original dataset distribution. Specifically, we penalize the influences of unreliable OoD data for the perturbed samples by integrating the inlier scores and prediction results of the target models, thereby making the final explanations more robust. Our solution is shown to be compatible with the most popular perturbation-based XAI algorithms: RISE, OCCLUSION, and LIME. Extensive experiments confirmed that our methods exhibit superior performance in most cases with computational and cognitive metrics. In particular, we point out the degradation problem of RISE algorithm for the first time. With our design, the performance of RISE can be boosted significantly. Besides, our solution also resolves a fundamental problem with a faithfulness indicator, a commonly used evaluation metric of XAI algorithms that appears sensitive to the OoD issue.","",""
0,"Mark H. Meng, Guangdong Bai, S. Teo, Zhe Hou, Yan Xiao, Yun Lin, Jin Song Dong","Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective",2022,"","","","",90,"2022-07-13 09:24:21","","10.1109/TDSC.2022.3179131","","",,,,,0,0.00,0,7,1,"—Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which concerns the reliability of a neural network when dealing with maliciously manipulated inputs, is one of the hottest topics in security and machine learning. In this work, we survey existing literature in adversarial robustness veriﬁcation for neural networks and collect 39 diversiﬁed research works across machine learning, security, and software engineering domains. We systematically analyze their approaches, including how robustness is formulated, what veriﬁcation techniques are used, and the strengths and limitations of each technique. We provide a taxonomy from a formal veriﬁcation perspective for a comprehensive understanding of this topic. We classify the existing techniques based on property speciﬁcation, problem reduction, and reasoning strategies. We also demonstrate representative techniques that have been applied in existing studies with a sample model. Finally, we discuss open questions for future research.","",""
0,"P. Vaishnavi, Kevin Eykholt, Amir Rahmati","Transferring Adversarial Robustness Through Robust Representation Matching",2022,"","","","",91,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,3,1,"With the widespread use of machine learning, concerns over its security and reliability have become prevalent. As such, many have developed defenses to harden neural networks against adversarial examples, imperceptibly perturbed inputs that are reliably misclassiﬁed. Adversarial training in which adversarial examples are generated and used during training is one of the few known defenses able to reliably withstand such attacks against neural networks. However, adversarial training imposes a signiﬁcant training overhead and scales poorly with model complexity and input dimension. In this paper, we propose Robust Representation Matching (RRM) , a low-cost method to transfer the robustness of an adversarially trained model to a new model being trained for the same task irrespective of architectural differences. Inspired by student-teacher learning, our method introduces a novel training loss that encourages the student to learn the teacher’s robust representations. Compared to prior works, RRM is superior with respect to both model performance and adversarial training time. On CIFAR-10, RRM trains a robust model ∼ 1 . 8 × faster than the state-of-the-art. Furthermore, RRM remains effective on higher-dimensional datasets. On Restricted-ImageNet, RRM trains a ResNet50 model ∼ 18 × faster than standard adversarial training.","",""
0,"Lu Yu, Verena Rieser","Adversarial Robustness of Visual Dialog",2022,"","","","",92,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,2,1,"—Adversarial robustness evaluates the worst-case per- formance scenario of a machine learning model to ensure its safety and reliability. This study is the ﬁrst to investigate the robustness of visually grounded dialog models towards textual attacks. These attacks represent a worst-case scenario where the input question contains a synonym which causes the previously correct model to return a wrong answer. Using this scenario, we ﬁrst aim to understand how multimodal input components contribute to model robustness. Our results show that models which encode dialog history are more robust, and when launching an attack on history, model prediction becomes more uncertain. This is in contrast to prior work which ﬁnds that dialog history is negligible for model performance on this task. We also evaluate how to generate adversarial test examples which successfully fool the model but remain undetected by the user/software designer. We ﬁnd that the textual, as well as the visual context are important to generate plausible worst-case scenarios.","",""
0,"K. Kavitha, M. Singh","Design of efficient classifier integration and performance evaluation in machine learning",2012,"","","","",93,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,2,10,"Characteristics of any classifier heavily depend upon the nature of data set taken for training and verification. Area of app lications like health care suffered from having the large and suitable dataset. Classifier designed for health care should show a better generalization and robustness characteristics so that end results presented by classifier can consider with high reliability and confidence. In this paper consistency problem associated with classifier has presented, which is a big issue from practical point of view. Defining committee of experts is one of natural way to increase the reliability in classifier design but at the same time, way of integration rules the end performance. To overcome problem of generalization and consistency of classifier, two methods for developing the mixture of classifier namely TMQD and MVFD are presented. Estimation of quality associated with a classifier is very challenging task for researcher, because there is no single parameter which could alone represents the absolute performance .To measure the quality of classifier rather than having the conventional parameters like sensitivity and specificity, receiver operating characteristics is always a better choice. But in practical environment of health care use of ROC hardly has seen. In this paper detail understanding of ROC and estimation of area under curve has also presented. Selection of threshold value is one of the most important factor to determine the performance of classifier. Dependency of threshold value with population and geographical area making difficult to decide a optimal value. A graphical approach has presented to select the best threshold value as according to environment and need.","",""
0,"Vibhorpandhare, Xiaodong Jia, Jay Lee","Collaborative Prognostics for Machine Fleets Using a Novel Federated Baseline Learner",2021,"","","","",94,"2022-07-13 09:24:21","","10.36001/phmconf.2021.v13i1.2989","","",,,,,0,0.00,0,3,1,"     Difficulty in obtaining enough run-to-fail datasets is a major barrier that impedes the widespread acceptance of Prognostic and Health Management (PHM) technology in many applications. Recent progress in federated learning demonstrates great potential to overcome such difficulty because it allows one to train PHM models based on distributed databases without direct data sharing. Therefore, this technology can overcome local data scarcity challenges by training the PHM model based on multi-party databases. To demonstrate the ability of federated learning to enhance the robustness and reliability of PHM models, this paper proposes a novel federated Gaussian Mixture Model (GMM) algorithm to build universal baseline models based on distributed databases. A systematic methodology to perform collaborative prognostics is further presented using the proposed federated GMM algorithm. The usefulness and performance are validated through a simulated dataset and the NASA Turbofan Engine Dataset. The proposed federated approach with parameter sharing is shown to perform at par with the traditional approach with data sharing. The proposed model further demonstrates improved robustness of predictions made collaboratively keeping the data private compared to local predictions. Federated collaborative learning can serve as a catalyst for the adaptation of business models based on the servitization of assets in the era of Industry 4.0. The methodology facilitates effective learning of asset health conditions for data-scarce organizations by collaborating with other organizations preserving data privacy. This is most suitable for a servitization model for Overall Equipment Manufacturers who sell to multiple organizations.      ","",""
7,"Yulei Wu","Robust Learning-Enabled Intelligence for the Internet of Things: A Survey From the Perspectives of Noisy Data and Adversarial Examples",2021,"","","","",95,"2022-07-13 09:24:21","","10.1109/JIOT.2020.3018691","","",,,,,7,7.00,7,1,1,"The Internet of Things (IoT) has been widely adopted in a range of verticals, e.g., automation, health, energy, and manufacturing. Many of the applications in these sectors, such as self-driving cars and remote surgery, are critical and high stakes applications, calling for advanced machine learning (ML) models for data analytics. Essentially, the training and testing data that are collected by massive IoT devices may contain noise (e.g., abnormal data, incorrect labels, and incomplete information) and adversarial examples. This requires high robustness of ML models to make reliable decisions for IoT applications. The research of robust ML has received tremendous attention from both academia and industry in recent years. This article will investigate the state of the art and representative works of robust ML models that can enable high resilience and reliability of IoT intelligence. Two aspects of robustness will be focused on, i.e., when the training data of ML models contain noises and adversarial examples, which may typically happen in many real-world IoT scenarios. In addition, the reliability of both neural networks and reinforcement learning framework will be investigated. Both of these two ML paradigms have been widely used in handling data in IoT scenarios. The potential research challenges and open issues will be discussed to provide future research directions.","",""
1,"Adhishree Srivastava, S. K. Parida","A Robust Fault Detection and Location Prediction Module Using Support Vector Machine and Gaussian Process Regression for AC Microgrid",2022,"","","","",96,"2022-07-13 09:24:21","","10.1109/tia.2021.3129982","","",,,,,1,1.00,1,2,1,"Better reliability of power supply is assured with the inculcation of distributed generators (DGs) in a distribution network. Smart sensors and latest grid communication protocols have played a crucial role in the development of intelligent microgrids (MGs). Conventional protection schemes do not provide reliable performance when implemented in MGs. This article proposes an approach which requires root mean square value of one cycle three -phase voltage and current measurements during fault. These data are treated as inputs for developing a fault isolation and locator module. This module is supposed to be available at central protection system, and is designed using machine learning (ML) based techniques viz. Gaussian process regression for fault location prediction and support vector machine for fault identification. Effectiveness of the proposed methodology is evaluated by considering practical grid scenarios with load variation and different DG penetration level. Furthermore, the robustness of the proposed model is assessed by performing sensitivity analysis with consideration of variation in line parameters and load as well as effect of DG correlation. A 7-bus meshed ac MG test system consisting of three DGs and two grid sources is modeled in SIMULINK platform, and is used to demonstrate the proposed module. Data analytics tools of MATLAB 2020a has been explored to develop an ML-based fault isolation and location module for MGs. The proposed scheme has also been validated with real-time MG data obtained from OPAL Real time (OPAL-RT) real-time simulator OP-4510. The accuracy in predicted results proves that the proposed scheme is pertinent for real-time practical applications.","",""
0,"Zhiqiang Huo, Miguel Martínez-García, Yu Zhang, Lei Shu","A Multisensor Information Fusion Method for High-Reliability Fault Diagnosis of Rotating Machinery",2022,"","","","",97,"2022-07-13 09:24:21","","10.1109/tim.2021.3132051","","",,,,,0,0.00,0,4,1,"Recent advancements in smart sensors and deep learning facilitate the use of intelligent systems for machine health monitoring and diagnostics. While data-driven diagnosis methods can extract meaningful fault patterns automatically from sensor measurements, the reliability of such a bottom-up built system largely relies on the assumption—sensor readings are normal, without outliers, and spurious readings. However, complex industrial environments or hardware malfunction is likely to cause noisy or corrupted sensor readings, resulting in degraded diagnosis performance. This article proposes a multisensor-based framework for fault diagnosis of rotating machinery based on deep learning and data fusion techniques, integrating thermal imaging with vibration measurements. In contrast to the single-sensor method, the proposed method offers two advantages: improved robustness to background noise and diagnostic performance in analyzing corrupted sensor readings. Three case studies are carried out to validate the effectiveness of the proposed method for multifault diagnosis of rotating machinery. The performance and trustworthiness of the system are studied and compared via analyzing normal sensor data, data with different noise levels, and data with sensor anomaly (bias fault and stuck fault). The results demonstrate that the proposed data fusion method presents a high diagnostic performance in identifying machine health conditions in a complex working environment.","",""
5,"S. S. Rodríguez, C. Mascolo, Young D. Kwon","Knowing when we do not know: Bayesian continual learning for sensing-based analysis tasks",2021,"","","","",98,"2022-07-13 09:24:21","","","","",,,,,5,5.00,2,3,1,"Despite much research targeted at enabling conventional machine learning models to continually learn tasks and data distributions sequentially without forgetting the knowledge acquired, little effort has been devoted to account for more realistic situations where learning some tasks accurately might be more critical than forgetting previous ones. In this paper we propose a Bayesian inference based framework to continually learn a set of real-world, sensing-based analysis tasks that can be tuned to prioritize the remembering of previously learned tasks or the learning of new ones. Our experiments prove the robustness and reliability of the learned models to adapt to the changing sensing environment, and show the suitability of using uncertainty of the predictions to assess their reliability.","",""
2,"Ziyi Huang, H. Lam, Haofeng Zhang","Quantifying Epistemic Uncertainty in Deep Learning",2021,"","","","",99,"2022-07-13 09:24:21","","","","",,,,,2,2.00,1,3,1,"Uncertainty quantification is at the core of the reliability and robustness of machine learning. In this paper, we provide a theoretical framework to dissect the uncertainty, especially the epistemic component, in deep learning into procedural variability (from the training procedure) and data variability (from the training data), which is the first such attempt in the literature to our best knowledge. We then propose two approaches to estimate these uncertainties, one based on influence function and one on batching. We demonstrate how our approaches overcome the computational difficulties in applying classical statistical methods. Experimental evaluations on multiple problem settings corroborate our theory and illustrate how our framework and estimation can provide direct guidance on modeling and data collection effort to improve deep learning performance.","",""
9,"F. Gao, Wenchao Lv, Yaotian Zhang, Jinping Sun, Jun Wang, Erfu Yang","A novel semisupervised support vector machine classifier based on active learning and context information",2016,"","","","",100,"2022-07-13 09:24:21","","10.1007/S11045-016-0396-1","","",,,,,9,1.50,2,6,6,"","",""
0,"Amina Guettas, Soheyb Ayad, O. Kazar","Real time driver's eye state recognition based on deep mobile learning",2021,"","","","",101,"2022-07-13 09:24:21","","10.1145/3454127.3456625","","",,,,,0,0.00,0,3,1,"Abstract. Eye state recognition has been the subject of many studies due to its importance in many fields especially drowsy driver detection, which is crucial task that must be done in real time and mostly using limited hardware. These restrictions make resource consuming learning techniques such as deep learning difficult to use. Deep mobile learning seems to be a viable solution to solving this issue. In this paper, we propose a real time system based on deep mobile learning to classify the eye state, and compare its performance with classical machine learning methods. The experimental results on the Closed Eyes in the Wild (CEW) and MRL Eye Datasets show that the proposed approach outperformed the other machine learning techniques in terms of accuracy and execution time. In addition, we evaluated our system on a video dataset to demonstrate its reliability and robustness.","",""
59,"Durga Prasad Sahoo, Debdeep Mukhopadhyay, R. Chakraborty, Phuong Ha Nguyen","A Multiplexer-Based Arbiter PUF Composition with Enhanced Reliability and Security",2018,"","","","",102,"2022-07-13 09:24:21","","10.1109/TC.2017.2749226","","",,,,,59,14.75,15,4,4,"Arbiter Physically Unclonable Functions (APUFs), while being relatively lightweight, are extremely vulnerable to modeling attacks. Hence, various compositions of APUFs such as XOR APUF and Lightweight Secure PUF have been proposed to be secure alternatives. Previous research has demonstrated that PUF compositions have two major challenges to overcome: vulnerability against modeling and statistical attacks, and lack of reliability. In this paper, we introduce a multiplexer-based composition of APUFs, denoted as MPUF, to simultaneously overcome these challenges. In addition to the basic MPUF design, we propose two MPUF variants namely cMPUF and rMPUF to improve the robustness against cryptanalysis and reliability-based modeling attack, respectively. An rMPUF demonstrates enhanced robustness against the reliability-based modeling attack, while even the well-known XOR APUF, otherwise robust to machine learning based modeling attacks, has been modeled using the same technique with linear data and time complexities. The rMPUF can provide a good trade-off between security and hardware overhead while maintaining a significantly higher reliability level than any practical XOR APUF instance. Moreover, MPUF variants are the first APUF compositions, to the best of our knowledge, that can achieve Strict Avalanche Criterion without using any additional input network (or hardware) for challenge transformation. Finally, we validate our theoretical findings using Matlab-based simulations of MPUFs.","",""
28,"K. Javed, R. Gouriveau, N. Zerhouni, R. Zemouri, Xiang Li","Robust, reliable and applicable tool wear monitoring and prognostic: Approach based on an improved-extreme learning machine",2012,"","","","",103,"2022-07-13 09:24:21","","10.1109/ICPHM.2012.6299516","","",,,,,28,2.80,6,5,10,"Although efforts in this field are significant around the world, real prognostics systems are still scarce in industry. Indeed, it is hard to provide efficient approaches that are able to handle with the inherent uncertainty of prognostics and nobody is able to a priori ensure that an accurate prognostic model can be built. As for an example of remaining problems, consider data-driven prognostics approaches: how to ensure that a model will be able to face with inputs variation with respect to those ones that have been learned, how to ensure that a learned-model will face with unknown data, how to ensure convergence of algorithms, etc. In other words, robustness, reliability and applicability of a prognostic approach are still open areas. Following that, the aim of this paper is to address these challenges by proposing a new neural network (structure and algorithm) that enhances reliability of RUL estimates while improving applicability of the approach. Robustness, reliability and applicability aspects are first discussed and defined according to literature. On this basis, a new connexionist system is proposed for prognostics: the Improved-Extreme Learning machine (Imp-ELM). This neural network, based on complex activation functions, enables to reduce the influence of human choices and initial parameterization, while improving accuracy of estimates and speeding the learning phase. The whole proposition is illustrated by performing tests on a real industrial case of cutting tools from a Computer Numerical Control (CNC) machine. This is achieved by predicting tool condition (wear) in terms of remaining cuts successfully made. Thorough comparisons with adaptive neuro fuzzy inference system (ANFIS) and existing ELM algorithm are also given. Results show improved robustness, reliability and applicability performances.","",""
1,"G. Vouros","Explainable Deep Reinforcement Learning: State of the Art and Challenges",2022,"","","","",104,"2022-07-13 09:24:21","","10.1145/3527448","","",,,,,1,1.00,1,1,1,"Interpretability, explainability and transparency are key issues to introducing Artificial Intelligence methods in many critical domains: This is important due to ethical concerns and trust issues strongly connected to reliability, robustness, auditability and fairness, and has important consequences towards keeping the human in the loop in high levels of automation, especially in critical cases for decision making, where both (human and the machine) play important roles. While the research community has given much attention to explainability of closed (or black) prediction boxes, there are tremendous needs for explainability of closed-box methods that support agents to act autonomously in the real world. Reinforcement learning methods, and especially their deep versions, are such closed-box methods. In this article we aim to provide a review of state of the art methods for explainable deep reinforcement learning methods, taking also into account the needs of human operators - i.e., of those that take the actual and critical decisions in solving real-world problems. We provide a formal specification of the deep reinforcement learning explainability problems, and we identify the necessary components of a general explainable reinforcement learning framework. Based on these, we provide a comprehensive review of state of the art methods, categorizing them in classes according to the paradigm they follow, the interpretable models they use, and the surface representation of explanations provided. The article concludes identifying open questions and important challenges.","",""
55,"He Fang, Xianbin Wang, L. Hanzo","Learning-Aided Physical Layer Authentication as an Intelligent Process",2018,"","","","",105,"2022-07-13 09:24:21","","10.1109/TCOMM.2018.2881117","","",,,,,55,13.75,18,3,4,"Performance of the existing physical layer authentication schemes could be severely affected by the imperfect estimates and variations of the communication link attributes used. The commonly adopted static hypothesis testing for physical layer authentication faces significant challenges in time-varying communication channels due to the changing propagation and interference conditions, which are typically unknown at the design stage. To circumvent this impediment, we propose an adaptive physical layer authentication scheme based on machine-learning as an intelligent process to learn and utilize the complex time-varying environment, and hence to improve the reliability and robustness of physical layer authentication. Explicitly, a physical layer attribute fusion model based on a kernel machine is designed for dealing with multiple attributes without requiring the knowledge of their statistical properties. By modeling the physical layer authentication as a linear system, the proposed technique directly reduces the authentication scope from a combined  $N$ -dimensional feature space to a single-dimensional (scalar) space, hence leading to reduced authentication complexity. By formulating the learning (training) objective of the physical layer authentication as a convex problem, an adaptive algorithm based on kernel least mean square is then proposed as an intelligent process to learn and track the variations of multiple attributes, and therefore to enhance the authentication performance. Both the convergence and the authentication performance of the proposed intelligent authentication process are theoretically analyzed. Our simulations demonstrate that our solution significantly improves the authentication performance in time-varying environments.","",""
53,"N. Matni, A. Proutière, A. Rantzer, Stephen Tu","From self-tuning regulators to reinforcement learning and back again",2019,"","","","",106,"2022-07-13 09:24:21","","10.1109/CDC40024.2019.9029916","","",,,,,53,17.67,13,4,3,"Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.","",""
0,"Yuanyi Zhong, Haoran Tang, Junkun Chen, Jian Peng, Yu-Xiong Wang","Is Self-Supervised Learning More Robust Than Supervised Learning?",2022,"","","","",107,"2022-07-13 09:24:21","","10.48550/arXiv.2206.05259","","",,,,,0,0.00,0,5,1,"Self-supervised contrastive learning is a powerful tool to learn visual representation without labels. Prior work has primarily focused on evaluating the recognition accuracy of various pre-training algorithms, but has overlooked other behavioral aspects. In addition to accuracy, distributional robustness plays a critical role in the reliability of machine learning models. We design and conduct a series of robustness tests to quantify the behavioral differences between contrastive learning and supervised learning to downstream or pretraining data distribution changes. These tests leverage data corruptions at multiple levels, ranging from pixellevel gamma distortion to patch-level shuffling and to dataset-level distribution shift. Our tests unveil intriguing robustness behaviors of contrastive and supervised learning. On the one hand, under downstream corruptions, we generally observe that contrastive learning is surprisingly more robust than supervised learning. On * Equal contribution the other hand, under pre-training corruptions, we find contrastive learning vulnerable to patch shuffling and pixel intensity change, yet less sensitive to dataset-level distribution change. We attempt to explain these results through the role of data augmentation and feature space properties. Our insight has implications in improving the downstream robustness of supervised learning.","",""
0,"Daniel Fusaro, Emilio Olivastri, D. Evangelista, Marco Imperoli, E. Menegatti, A. Pretto","Pushing the Limits of Learning-based Traversability Analysis for Autonomous Driving on CPU",2022,"","","","",108,"2022-07-13 09:24:21","","10.48550/arXiv.2206.03083","","",,,,,0,0.00,0,6,1,". Self-driving vehicles and autonomous ground robots require a reliable and accurate method to analyze the traversability of the sur-rounding environment for safe navigation. This paper proposes and eval-uates a real-time machine learning-based Traversability Analysis method that combines geometric features with appearance-based features in a hybrid approach based on a SVM classiﬁer. In particular, we show that integrating a new set of geometric and visual features and focusing on important implementation details enables a noticeable boost in performance and reliability. The proposed approach has been compared with state-of-the-art Deep Learning approaches on a public dataset of outdoor driving scenarios. It reaches an accuracy of 89.2% in scenarios of varying complexity, demonstrating its eﬀectiveness and robustness. The method runs fully on CPU and reaches comparable results with respect to the other methods, operates faster, and requires fewer hardware resources.","",""
0,"Matteo Zecchin, Sangwoo Park, O. Simeone, M. Kountouris, D. Gesbert","Robust Bayesian Learning for Reliable Wireless AI: Framework and Applications",2022,"","","","",109,"2022-07-13 09:24:21","","10.48550/arXiv.2207.00300","","",,,,,0,0.00,0,5,1,"—This work takes a critical look at the application of conventional machine learning methods to wireless communication problems through the lens of reliability and robustness. Deep learning techniques adopt a frequentist framework, and are known to provide poorly calibrated decisions that do not reproduce the true uncertainty caused by limitations in the size of the training data. Bayesian learning, while in principle capable of addressing this shortcoming, is in practice impaired by model misspeciﬁcation and by the presence of outliers. Both problems are pervasive in wireless communication settings, in which the capacity of machine learning models is subject to resource constraints and training data is affected by noise and interference. In this context, we explore the application of the framework of robust Bayesian learning. After a tutorial-style introduction to robust Bayesian learning, we showcase the merits of robust Bayesian learning on several important wireless communication problems in terms of accuracy, calibration, and robustness to outliers and misspeciﬁcation.","",""
0,"Juanjuan Tian, Li Li","Digital Universal Financial Credit Risk Analysis Using Particle Swarm Optimization Algorithm with Structure Decision Tree Learning-Based Evaluation Model",2022,"","","","",110,"2022-07-13 09:24:21","","10.1155/2022/4060256","","",,,,,0,0.00,0,2,1,"Predictions of credit risk, model reliability, monitoring, and efficient loan processing are all important factors in decision-making and transparency. Machine learning method is providing these people new hope. However, it is up to banking or nonbanking institutions to determine how they will implement this advanced method in order to decrease human biases in loan decision-making. Objective. This paper proposed the novel machine learning-based credit risk analysis in the digital banking evaluation model. The purpose of this research is to compare various ML algorithms in order to develop an accurate model for credit risk assessment utilising data from a genuine credit registry dataset. Aim is to design the classification-based model using particle swarm optimization (PSO) algorithm with structure decision tree learning (SDTL) in predicting credit risk. This system has the potential to improve quality criteria such as dependability, robustness, extensibility, and scalability. Features have been extracted and classified by the proposed PSO_SL model. Experimental Results. The data have been collected based on real time for credit analysis. Simulation is carried out in Python and optimal results are obtained in comparative analysis with existing techniques. The accuracy obtained by proposed technique is enhanced and the error rate of the design is minimized.","",""
0,"K. Saurabh, Saksham Sood, P. A. Kumar, Uphar Singh, Ranjana Vyas, O. P. Vyas, M. M. Khondoker","LBDMIDS: LSTM Based Deep Learning Model for Intrusion Detection Systems for IoT Networks",2022,"","","","",111,"2022-07-13 09:24:21","","10.48550/arXiv.2207.00424","","",,,,,0,0.00,0,7,1,"—In the recent years, we have witnessed a huge growth in the number of Internet of Things (IoT) and edge devices being used in our everyday activities. This demands the security of these devices from cyber attacks to be improved to protect its users. For years, Machine Learning (ML) techniques have been used to develop Network Intrusion Detection Systems (NIDS) with the aim of increasing their reliability/robustness. Among the earlier ML techniques DT performed well. In the recent years, Deep Learning (DL) techniques have been used in an attempt to build more reliable systems. In this paper, a Deep Learning enabled Long Short Term Memory (LSTM) Autoencoder and a 13-feature Deep Neural Network (DNN) models were developed which performed a lot better in terms of accuracy on UNSW- NB15 and Bot-IoT datsets. Hence we proposed LBDMIDS, where we developed NIDS models based on variants of LSTMs namely, stacked LSTM and bidirectional LSTM and validated their performance on the UNSW NB15 and BoTIoT datasets. This paper concludes that these variants in LBDMIDS outperform classic ML techniques and perform similarly to the DNN models that have been suggested in the past.","",""
0,"K. M. Collins, Umang Bhatt, Adrian Weller","Eliciting and Learning with Soft Labels from Every Annotator",2022,"","","","",112,"2022-07-13 09:24:21","","10.48550/arXiv.2207.00810","","",,,,,0,0.00,0,3,1,"The labels used to train machine learning (ML) models are of paramount importance. Typically for ML classiﬁcation tasks, datasets contain hard labels, yet learning using soft labels has been shown to yield beneﬁts for model generalization, robustness, and calibration. Earlier work found success in forming soft labels from multiple annotators’ hard labels; however, this approach may not converge to the best labels and neces- sitates many annotators, which can be expensive and inefﬁ-cient. We focus on efﬁciently eliciting soft labels from in- dividual annotators. We collect and release a dataset of soft labels for CIFAR-10 via a crowdsourcing study ( N = 242 ). We demonstrate that learning with our labels achieves com- parable model performance to prior approaches while requir-ing far fewer annotators. Our elicitation methodology there- fore shows promise towards enabling practitioners to enjoy the beneﬁts of improved model performance and reliability with fewer annotators, and serves as a guide for future dataset curators on the beneﬁts of leveraging richer information, such as categorical uncertainty, from individual annotators.","",""
5,"Klaus Neumann","Reliability of Extreme Learning Machines",2014,"","","","",113,"2022-07-13 09:24:21","","","","",,,,,5,0.63,5,1,8,"The reliable application of machine learning methods becomes increasingly important in challenging engineering domains. In particular, the application of extreme  learning machines (ELM) seems promising because of their apparent simplicity and the capability of very efficient processing of large and high-dimensional data sets.  However, the ELM paradigm is based on the concept of single hidden-layer neural networks with randomly initialized and fixed input weights and is thus inherently  unreliable. This black-box character usually repels engineers from application in potentially safety critical tasks. The problem becomes even more severe since, in  principle, only sparse and noisy data sets can be provided in such domains. The goal of this thesis is therefore to equip the ELM approach with the abilities to perform in a reliable manner.  This goal is approached in three aspects by enhancing the robustness of ELMs to initializations, make ELMs able to handle slow changes in the environment (i.e. input drifts), and allow the incorporation of continuous constraints derived from prior knowledge. It is shown in several diverse scenarios that the novel ELM approach proposed in this thesis ensures a safe and reliable application while simultaneously sustaining the full modeling power of data-driven methods.","",""
85,"J. Hahne, M. Marković, D. Farina","User adaptation in Myoelectric Man-Machine Interfaces",2017,"","","","",114,"2022-07-13 09:24:21","","10.1038/s41598-017-04255-x","","",,,,,85,17.00,28,3,5,"","",""
0,"孙哲南, 张慧, 谭铁牛","Method for distinguishing false iris images based on robust texture features and machine learning",2010,"","","","",115,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,3,12,"The invention relates to a method for distinguishing false iris images based on robust texture features and machine learning, which comprises the following steps: preprocessing true iris images or false iris images; extracting the partitioned statistical features of a robust weighted partial binary pattern; and carrying out training and sorting of a support vector machine, and judging whether thetest images are false iris images or not according to the output result of a sorter. The method of the invention combines SIFT descriptors and partial binary pattern features to extract the robust texture features, the description of textures is more stable because of the robustness of the SIFT to brightness, translation, rotation and scale change, and the support vector machine enables the method to have better universality. The invention can be used for effectively distinguishing the false iris images, has the advantages of high precision, high robustness and high reliability, can be used for distinguishing false irises such as paper printing irises, color printing contact lenses, synthetic eyes and the like, and can improve the safety of the system when being applied to the applicationsystem in which iris recognition is used for carrying out identification.","",""
0,"Wu Haiyang, Xiao Lu, Dawei Su, Miao Weiwei, Zhang Li, Qi Sun","Dynamic Routing Programming for Power Communication Networks by Recurrent Neural Networks based Reliability Prediction and Particle Swarm Optimization",2019,"","","","",116,"2022-07-13 09:24:21","","10.33969/EECS.V3.003","","",,,,,0,0.00,0,6,3,"The coupling Power Communication Network (PCN) has been proven as an effective supplement to modern power grid for carrying various auxiliary services. Conventional fault processing methods for PCN implement short term recovery of services from interruption caused by external risks. However, such methods normally optimize topological structure of routing according to direct communication states. In this paper, we propose a machine learning based method to predict the reliability of nodes as well as links on PCN and dynamically program routing strategy alongside with the variation of external environment. The method comprehensively takes various factors into account as input to a Recurrent Neural Network to predict the reliability of hardware in incoming days. Based on the predicted reliability, a Particle Swarm Optimization method is exploited to optimize the routing to prompt the robustness of services by avoiding path with potential risk. Our experimental analysis on both simulation cases as well as realistic records demonstrates that the proposed dynamic routing programming method can be applied as a medium and long term supplement to existing fault processing methods.","",""
3,"Maoguo Gong, Yingying Duan, Hao Li","Group Self-Paced Learning With a Time-Varying Regularizer for Unsupervised Change Detection",2020,"","","","",117,"2022-07-13 09:24:21","","10.1109/TGRS.2019.2951441","","",,,,,3,1.50,1,3,2,"Unsupervised change detection based on supervised or semisupervised classifiers has achieved strong adaptability and robustness to obtain satisfactory change detection results. However, these methods suffer from an issue that it is hard to collect reliable training samples in an unsupervised manner. In this article, a group self-paced learning (GSPL) framework is proposed to mine the reliable training samples. In the proposed method, each sample is assigned a weight to indicate its reliability. The proposed scheme is able to learn the weighted samples and update the weights iteratively in a self-paced manner to identify the reliable training samples. In the phase of updating weights, a grouping strategy is designed to avoid selecting training samples from homogeneous regions. Furthermore, a novel time-varying self-paced regularizer is proposed to automatically determine the learning scheme of self-paced learning. Finally, three classifiers, including SoftMax, backpropagation neural network, and support vector machine, are investigated under this proposed framework. Experiments on five change detection data sets demonstrate that the proposed framework can significantly outperform those state-of-art methods for change detection in terms of accuracy and robustness.","",""
0,"Maurice Poot, D. Kostic, Roel Vromans, George Maleas, J. Portegies, T. Oomen","Learning for motion control in bonding machines: Bridging data-driven learning and physical modelling",2020,"","","","",118,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,6,2,"Semiconductor back-end machines require high position accuracy, throughput, and reliability in a variety of industrial environments. Motion control is essential to meet future challenges. Systems have to perform varying motion tasks with (sub-)micrometer precision. The high demands on throughput require movements with high velocity and accelerations. Robustness and reliability for changing industrial environments is needed to minimize machine-to-machine differences and obtain uniform system performance. The use of data-driven learning in conjunction with model-based control approaches is envisaged to overcome these challenges. Regarding the challenge, and safe is while maintaining flexibility under varying high performance with fast and safe learning for repeating motion ILC algorithms for operation for motion tasks. parameterized functions that model Traditionally, the basis functions are chosen using typical motion profiles, i.e., velocity, acceleration, and snap. For semiconductor back-end machines, substantial non-linear dynamics non-linear terms are in the basis functions, which are from first principle modelling of the system. tests a XYZ-motion stage of a commercial wirebonder significant performance improvement despite varying motion tasks. performance multipe aspacts. the reduce the error up to the reproducible part using a data-driven approach. is between and position- and time-dependent system performance evaluation at the bonding location is for and applying model-free learning using reinforcement learning techniques to enhance performance under changing environments. To conclude, these techniques combined bridge data-driven learning with physical modelling.","",""
14,"Ruofeng Wei, Y. Bi","Research on Recognition Technology of Aluminum Profile Surface Defects Based on Deep Learning",2019,"","","","",119,"2022-07-13 09:24:21","","10.3390/ma12101681","","",,,,,14,4.67,7,2,3,"Aluminum profile surface defects can greatly affect the performance, safety, and reliability of products. Traditional human-based visual inspection has low accuracy and is time consuming, and machine vision-based methods depend on hand-crafted features that need to be carefully designed and lack robustness. To recognize the multiple types of defects with various size on aluminum profiles, a multiscale defect-detection network based on deep learning is proposed. Then, the network is trained and evaluated using aluminum profile surface defects images. Results show 84.6%, 48.5%, 96.9%, 97.9%, 96.9%, 42.5%, 47.2%, 100%, 100%, and 43.3% average precision (AP) for the 10 defect categories, respectively, with a mean AP of 75.8%, which illustrate the effectiveness of the network in aluminum profile surface defects detection. In addition, saliency maps also show the feasibility of the proposed network.","",""
23,"J. Hahne, D. Farina, N. Jiang, D. Liebetanz","A Novel Percutaneous Electrode Implant for Improving Robustness in Advanced Myoelectric Control",2016,"","","","",120,"2022-07-13 09:24:21","","10.3389/fnins.2016.00114","","",,,,,23,3.83,6,4,6,"Despite several decades of research, electrically powered hand and arm prostheses are still controlled with very simple algorithms that process the surface electromyogram (EMG) of remnant muscles to achieve control of one prosthetic function at a time. More advanced machine learning methods have shown promising results under laboratory conditions. However, limited robustness has largely prevented the transfer of these laboratory advances to clinical applications. In this paper, we introduce a novel percutaneous EMG electrode to be implanted chronically with the aim of improving the reliability of EMG detection in myoelectric control. The proposed electrode requires a minimally invasive procedure for its implantation, similar to a cosmetic micro-dermal implant. Moreover, being percutaneous, it does not require power and data telemetry modules. Four of these electrodes were chronically implanted in the forearm of an able-bodied human volunteer for testing their characteristics. The implants showed significantly lower impedance and greater robustness against mechanical interference than traditional surface EMG electrodes used for myoelectric control. Moreover, the EMG signals detected by the proposed systems allowed more stable control performance across sessions in different days than that achieved with classic EMG electrodes. In conclusion, the proposed implants may be a promising interface for clinically available prostheses.","",""
10,"Gauravkumar K. Patel, J. Hahne, Claudio Castellini, D. Farina, S. Došen","Context-dependent adaptation improves robustness of myoelectric control for upper-limb prostheses.",2017,"","","","",121,"2022-07-13 09:24:21","","10.1088/1741-2552/aa7e82","","",,,,,10,2.00,2,5,5,"OBJECTIVE Dexterous upper-limb prostheses are available today to restore grasping, but an effective and reliable feed-forward control is still missing. The aim of this work was to improve the robustness and reliability of myoelectric control by using context information from sensors embedded within the prosthesis.   APPROACH We developed a context-driven myoelectric control scheme (cxMYO) that incorporates the inference of context information from proprioception (inertial measurement unit) and exteroception (force and grip aperture) sensors to modulate the outputs of myoelectric control. Further, a realistic evaluation of the cxMYO was performed online in able-bodied subjects using three functional tasks, during which the cxMYO was compared to a purely machine-learning-based myoelectric control (MYO).   MAIN RESULTS The results demonstrated that utilizing context information decreased the number of unwanted commands, improving the performance (success rate and dropped objects) in all three functional tasks. Specifically, the median number of objects dropped per round with cxMYO was zero in all three tasks and a significant increase in the number of successful transfers was seen in two out of three functional tasks. Additionally, the subjects reported better user experience.   SIGNIFICANCE This is the first online evaluation of a method integrating information from multiple on-board prosthesis sensors to modulate the output of a machine-learning-based myoelectric controller. The proposed scheme is general and presents a simple, non-invasive and cost-effective approach for improving the robustness of myoelectric control.","",""
1,"Thomas G. Dietterich, Brandon T. Harvey, Drake Miller, David T Jones, Aaron F. Gray, Alan Fern, Prasad Tadepalli","Machine Learning for the Knowledge Plane",2006,"","","","",122,"2022-07-13 09:24:21","","10.21236/ada454287","","",,,,,1,0.06,0,7,16,"The field of machine learning has made major strides over the last 20 years. This document summarizes the major problem formulations that the discipline has studied, then reviews three tasks in cognitive networking and briefly discusses how aspects of those tasks fit these formulations. After this, it discusses challenges for machine learning research raised by Knowledge Plane applications and closes with proposals for the evaluation of learning systems developed for these problems. B1. Background and Motivation Recently, Clark (2002) and Partridge (2003) have proposed a new vision for computer network management—the Knowledge Plane—that would augment the current paradigm of low-level data collection and decision making with higher-level processes. One key idea is that the Knowledge Plane would learn about its own behavior over time, making it better able to analyze problems, tune its operation, and generally increase its reliability and robustness. This suggests the incorporation of concepts and methods from machine learning (Langley, 1995; Mitchell, 1997), an established field that is concerned with such issues. Machine learning aims to understand computational mechanisms by which experience can lead to improved performance. In everyday language, we say that a person has `learned' something from an experience when he can do something he could not, or could not do as well, before that experience. The field of machine learning attempts to characterize how such changes can occur by designing, implementing, running, and analyzing algorithms that can be run on computers. The discipline draws on ideas from many other fields, including statistics, cognitive psychology, information theory, logic, complexity theory, and operations research, but always with the goal of understanding the computational character of learning.","",""
0,"Jasminder Kaur Sandhu, Anil Kumar Verma, P. Rana","RCDR: Reliability Control Framework for Data Rate Prediction in Wireless Sensor Networks",2018,"","","","",123,"2022-07-13 09:24:21","","10.1109/GUCON.2018.8674978","","",,,,,0,0.00,0,3,4,"Machine learning or popularly known as prediction technique is an application of Artificial Intelligence. It provides network the ability to learn from past experience and make them more efficient. This technique of prediction is being used in diverse fields due to its adaptive nature. In particular, the prediction technique has been proven very useful in the design of reliable Wireless Sensor Networks. This paper proposes a reliability control framework with date rate prediction in Wireless Sensor Network, and provides the community a general view of this vibrant research area. Various, simulations are carried out to generate a primary networking dataset with many performance parameters including the data rate. The data rate is predicted using different prediction techniques. Lastly, to check the robustness of best predictive model, N-fold cross-validation technique is used.","",""
0,"W. You, S. Alexandre, M. Ichchou, Zine Abdelmalek, Xiaoping Zhong, M. Belhaq","Reliability modeling and prediction of passive controlled structures through Random Forest",2018,"","","","",124,"2022-07-13 09:24:21","","10.1051/MATECCONF/201824101023","","",,,,,0,0.00,0,6,4,"Reliability prediction plays a significant role in risk assessment of engineering structures. Mathematically, the prediction task can be seen as a classification (regression) procedure. In this aspect, machine learning methods have recently shown their superior performance over others in various research domains. Random forest (RF) is distinguished for its robustness and high accuracy in modeling and prediction work. However, its application in the area of structural reliability has not been widely explored. This study aims to explore the feasibility of RF as well as examine its performance in modeling and prediction of structure reliability in passive control mode. A numerical example is introduced in the simulation part to evaluate performance of the proposed method in different perspectives.","",""
117,"J. Serrà, David Álvarez, V. Gómez, Olga Slizovskaia, José F. Núñez, J. Luque","Input complexity and out-of-distribution detection with likelihood-based generative models",2019,"","","","",125,"2022-07-13 09:24:21","","","","",,,,,117,39.00,20,6,3,"Likelihood-based generative models are a promising resource to detect out-of-distribution (OOD) inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models have been shown to be problematic for detecting certain types of inputs that significantly differ from training data. In this paper, we pose that this problem is due to the excessive influence that input complexity has in generative models' likelihoods. We report a set of experiments supporting this hypothesis, and use an estimate of input complexity to derive an efficient and parameter-free OOD score, which can be seen as a likelihood-ratio, akin to Bayesian model comparison. We find such score to perform comparably to, or even better than, existing OOD detection approaches under a wide range of data sets, models, model sizes, and complexity estimates.","",""
9,"Charalampos Orfanidis","Ph.D. Forum Abstract: Increasing Robustness in WSN Using Software Defined Network Architecture",2016,"","","","",126,"2022-07-13 09:24:21","","10.1109/IPSN.2016.7460687","","",,,,,9,1.50,9,1,6,"With the advent of Internet of Things (IoT) Wireless Sensor Networks (WSN) seem to play key a role in the connectivity of smart objects. The limited resources of WSN devices and the increased demand for new and more sophisticated services call for new and more efficient architectures. The new architectures should ensure energy-efficiency, flexibility, reliability and robustness. We believe that using SDN principles in WSN will improve many important features, such as routing, robustness and reconfiguration of the networking as well as the applications. In this research, We will find ways to increase the robustness of WSN using an SDN inspired architecture and a statistical model. The initial plan is to use statistical machine learning to look for periodic interference and other periodic behaviour in typical WSN networks.","",""
2,"S. Pasricha, Janardhan Rao Doppa, K. Chakrabarty, Saideep Tiku, D. Dauwe, Shi Jin, P. Pande","Special session paper: data analytics enables energy- efficiency and robustness: from mobile to manycores, datacenters, and networks",2017,"","","","",127,"2022-07-13 09:24:21","","","","",,,,,2,0.40,0,7,5,"The amount of data generated and collected across computing platforms every day is not only enormous, but growing at an exponential rate. Advanced data analytics and machinelearning techniques have become increasingly essential to analyze and extract meaning from such “Big Data”. These techniques can be very useful to detect patterns and trends to improve the operational behavior of computing platforms, but they also introduce a number of outstanding challenges: (1) How can we design and deploy data analytics and learning mechanisms to improve energy-efficiency in IoT and mobile devices, without introducing significant software overheads? (2) How to use machine learning and analytics techniques for effective designspace exploration during manycore chip design? (3) How can data analytics and learning improve the reliability and energyefficiency of large-scale cloud datacenters, to cost-effectively support connected embedded and IoT platforms? (4) How can data analytics detect anomalies and increase robustness in the network backbone of emerging cloud datacenter networks? In this paper, we discuss these outstanding problems and describe far-reaching solutions applicable across the interconnected ecosystem of IoT and mobile devices, manycore chips, datacenters, and networks.","",""
1,"S. Pasricha, Janardhan Rao Doppa, K. Chakrabarty, Saideep Tiku, D. Dauwe, Shi Jin, P. Pande","Data analytics enables energy-efficiency and robustness: from mobile to manycores, datacenters, and networks (special session paper)",2017,"","","","",128,"2022-07-13 09:24:21","","10.1145/3125502.3125560","","",,,,,1,0.20,0,7,5,"The amount of data generated and collected across computing platforms every day is not only enormous, but growing at an exponential rate. Advanced data analytics and machine-learning techniques have become increasingly essential to analyze and extract meaning from such ""Big Data"". These techniques can be very useful to detect patterns and trends to improve the operational behavior of computing platforms, but they also introduce a number of outstanding challenges: (1) How can we design and deploy data analytics and learning mechanisms to improve energy-efficiency in IoT and mobile devices, without introducing significant software overheads? (2) How to use machine learning and analytics techniques for effective designspace exploration during manycore chip design? (3) How can data analytics and learning improve the reliability and energy-efficiency of large-scale cloud datacenters, to cost-effectively support connected embedded and IoT platforms? (4) How can data analytics detect anomalies and increase robustness in the network backbone of emerging cloud datacenter networks? In this paper, we discuss these outstanding problems and describe far-reaching solutions applicable across the interconnected ecosystem of IoT and mobile devices, manycore chips, datacenters, and networks.","",""
20,"Sheeba Lal, S. Rehman, J. H. Shah, Talha Meraj, Hafiz Tayyab Rauf, Robertas Damaševičius, M. Mohammed, Karrar Hameed Abdulkareem","Adversarial Attack and Defence through Adversarial Training and Feature Fusion for Diabetic Retinopathy Recognition",2021,"","","","",129,"2022-07-13 09:24:21","","10.3390/s21113922","","",,,,,20,20.00,3,8,1,"Due to the rapid growth in artificial intelligence (AI) and deep learning (DL) approaches, the security and robustness of the deployed algorithms need to be guaranteed. The security susceptibility of the DL algorithms to adversarial examples has been widely acknowledged. The artificially created examples will lead to different instances negatively identified by the DL models that are humanly considered benign. Practical application in actual physical scenarios with adversarial threats shows their features. Thus, adversarial attacks and defense, including machine learning and its reliability, have drawn growing interest and, in recent years, has been a hot topic of research. We introduce a framework that provides a defensive model against the adversarial speckle-noise attack, the adversarial training, and a feature fusion strategy, which preserves the classification with correct labelling. We evaluate and analyze the adversarial attacks and defenses on the retinal fundus images for the Diabetic Retinopathy recognition problem, which is considered a state-of-the-art endeavor. Results obtained on the retinal fundus images, which are prone to adversarial attacks, are 99% accurate and prove that the proposed defensive model is robust.","",""
269,"Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, S. Khurshid","DeepRoad: GAN-Based Metamorphic Testing and Input Validation Framework for Autonomous Driving Systems",2018,"","","","",130,"2022-07-13 09:24:21","","10.1145/3238147.3238187","","",,,,,269,67.25,54,5,4,"While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well.","",""
1,"Fu Yangzhen, Zhang Hong, Zeng Chenchen, Feng Chao","A Software Reliability Prediction Model: Using Improved Long Short Term Memory Network",2017,"","","","",131,"2022-07-13 09:24:21","","10.1109/QRS-C.2017.115","","",,,,,1,0.20,0,4,5,"With the development of software reliability research and machine learning, many machine learning models have been used in software reliability prediction. A long short term memory network (LSTM) modeling approach for software reliability prediction is proposed. Profit from its particular data flow control structure, the model overcomes the vanishing and exploding sensitivity of simple recursive neural network for software reliability prediction. Proposed approach also combines with layer normalization and truncate back propagation. To some extent, these two methods promote the effect of the proposed model. Compared with the simple recursive neural network, numerical results show that our proposed approach has a better performance and robustness with respect to software reliability prediction.","",""
8,"Zuoyi Chen, Yanzhi Wang, Jun Wu, C. Deng, Kui Hu","Sensor data-driven structural damage detection based on deep convolutional neural networks and continuous wavelet transform",2021,"","","","",132,"2022-07-13 09:24:21","","10.1007/S10489-020-02092-6","","",,,,,8,8.00,2,5,1,"","",""
1,"Wichai Pawgasame","A Survey of Deep Learning for Tactical Wireless Networks",2018,"","","","",133,"2022-07-13 09:24:21","","10.1109/ACDT.2018.8593210","","",,,,,1,0.25,1,1,4,"A tactical wireless network is a military radio communication network supporting mission-critical applications. Hence, a tactical wireless network demands more reliability, availability, robustness, and security than a commercial wireless network. The tactical wireless network must operate in hostile environment, where the environment changes rapidly and is prone to attack. To maintain the required quality of services (QoS), the network must intelligently adapt to the hostile environment. The concept of cognitive radio (CR), in which a radio can sense and adapt to radio environment, could be a solution for modern tactical wireless networks. Machine learning plays an important role in CR to provide sensing and adapting functions. Irrational decision made by a machine learning can lead to flaws in the CR. The introduction of Deep Learning models machine learning on the basis of human brain process; and hence, could make the CR more rational. This paper explores the challenges of tactical wireless networks, the CR functions as the solution for tactical wireless networks and Deep Learning techniques for improving CR functions. The survey presented in this paper should contribute to the development of modern tactical wireless networks by providing the possible applications, benefits and drawbacks of deep learning in CR.","",""
0,"Charalampos Orfanidis","Increasing robustness in WSN using software defined network architecture: Ph.D. forum abstract",2016,"","","","",134,"2022-07-13 09:24:21","","10.5555/2959355.2959410","","",,,,,0,0.00,0,1,6,"With the advent of Internet of Things (IoT) Wireless Sensor Networks (WSN) seem to play key a role in the connectivity of smart objects. The limited resources of WSN devices and the increased demand for new and more sophisticated services call for new and more efficient architectures. The new architectures should ensure energy-efficiency, flexibility, reliability and robustness. We believe that using SDN principles in WSN will improve many important features, such as routing, robustness and reconfiguration of the networking as well as the applications. In this research, We will find ways to increase the robustness of WSN using an SDN inspired architecture and a statistical model. The initial plan is to use statistical machine learning to look for periodic interference and other periodic behaviour in typical WSN networks.","",""
5,"Dongning Ma, Jianmin Guo, Yu Jiang, Xun Jiao","HDTest: Differential Fuzz Testing of Brain-Inspired Hyperdimensional Computing",2021,"","","","",135,"2022-07-13 09:24:21","","10.1109/dac18074.2021.9586169","","",,,,,5,5.00,1,4,1,"Brain-inspired hyperdimensional computing (HDC) is an emerging computational paradigm that mimics brain cognition and leverages hyperdimensional vectors with fully distributed holographic representation and (pseudo)randomness. Compared to other machine learning (ML) methods such as deep neural networks (DNNs), HDC offers several advantages including high energy efficiency, low latency, and one-shot learning, making it a promising alternative candidate on a wide range of applications. However, the reliability and robustness of HDC models have not been explored yet. In this paper, we design, implement, and evaluate HDTest to test HDC model by automatically exposing unexpected or incorrect behaviors under rare inputs. The core idea of HDTest is based on guided differential fuzz testing. Guided by the distance between query hypervector and reference hypervector in HDC, HDTest continuously mutates original inputs to generate new inputs that can trigger incorrect behaviors of HDC model. Compared to traditional ML testing methods, HDTest does not need to manually label the original input. Using handwritten digit classification as an example, we show that HDTest can generate thousands of adversarial inputs with negligible perturbations that can successfully fool HDC models. On average, HDTest can generate around 400 adversarial inputs within one minute running on a commodity computer. Finally, by using the HDTest-generated inputs to retrain HDC models, we can strengthen the robustness of HDC models. To the best of our knowledge, this paper presents the first effort in systematically testing this emerging brain-inspired computational model.","",""
4,"S. Cruz, B. Taetz, Thomas Stifter, D. Stricker","Illumination Normalization by Partially Impossible Encoder-Decoder Cost Function",2020,"","","","",136,"2022-07-13 09:24:21","","10.1109/WACV48630.2021.00150","","",,,,,4,2.00,1,4,2,"Images recorded during the lifetime of computer vision based systems undergo a wide range of illumination and environmental conditions affecting the reliability of previously trained machine learning models. Image normalization is hence a valuable preprocessing component to enhance the models' robustness. To this end, we introduce a new strategy for the cost function formulation of encoder-decoder networks to average out all the unimportant information in the input images (e.g. environmental features and illumination changes) to focus on the reconstruction of the salient features (e.g. class instances). Our method exploits the availability of identical sceneries under different illumination and environmental conditions for which we formulate a partially impossible reconstruction target: the input image will not convey enough information to reconstruct the target in its entirety. Its applicability is assessed on three publicly available datasets. We combine the triplet loss as a regular- izer in the latent space representation and a nearest neighbour search to improve the generalization to unseen illuminations and class instances. The importance of the aforementioned post-processing is highlighted on an automotive application. To this end, we release a synthetic dataset of sceneries from three different passenger compartments where each scenery is rendered under ten different illumination and environmental conditions: https://sviro.kl.dfki.de","",""
2,"Xiaolong Guo, Song Han, X. S. Hu, Xun Jiao, Yier Jin, Fanxin Kong, M. Lemmon","Towards Scalable, Secure, and Smart Mission-Critical IoT Systems: Review and Vision : (Special Session Paper)",2021,"","","","",137,"2022-07-13 09:24:21","","10.1145/3477244.3477624","","",,,,,2,2.00,0,7,1,"Recent emerging technologies such as artificial intelligence and machine learning have been promising enormous economic and societal benefits. While it is desirable to deploy these technologies to Internet-of-Things (IoT) infrastructures in many applications such as medical, energy, transportation, and industrial automation systems, such deployments present daunting challenges in performance, efficiency, and dependability of scaling-up IoT infrastructure, due to the ever-increasing number of edge devices, ever-increasing levels of device and system heterogeneity, and more stringent requirements of reliability, robustness, and security in mission-critical settings. This position paper elaborates the needs for a cross-layer and full hardware/software stack solution for the design and deployment of scalable, secure, and smart mission-critical IoT systems from four different perspectives and research fields. We present a review of recent studies on such issues and identify the potential challenges and gaps, based on which we highlight some important research directions and future works that can be conducted to tackle such challenges.","",""
2,"Tianle Mai, S. Garg, Haipeng Yao, Jiangtian Nie, G. Kaddoum, Zehui Xiong","In-Network Intelligence Control: Toward a Self-Driving Networking Architecture",2021,"","","","",138,"2022-07-13 09:24:21","","10.1109/MNET.011.2000412","","",,,,,2,2.00,0,6,1,"The past few years have witnessed the compelling applications of the Internet of Things (IoT) in our daily life. Meanwhile, with the explosion of IoT devices and various applications, the expectations for the performance, reliability, and security of networks are greater than ever. The current end-host-based or centralized control framework incurs too much communication and computation overhead, therefore exhibiting tardiness and clumsiness in responding to network dynamics. Recently, with the advancement of programmable network hardware, it is possible to implement network functions inside the network. However, current in-network schemes are largely dependent on the manual process, which presents poor scalability and robustness. Therefore, in this article, we present a new intelligent network control architecture, in-network intelligence control. We design intelligent in-network devices that can automatically adapt to network dynamics by leveraging powerful machine learning adaptive abilities. In addition, to enhance the collaboration among distributed in-network devices, a centralized management plane is introduced to ease the training process of distributed switches. To demonstrate the technical feasibility and performance advantage of our architecture, we present three use cases: in-network load balance, in-network congestion control, and in-network DDoS detection.","",""
2,"R. Soklaski, Justin A. Goodwin, Olivia M. Brown, Michael Yee, J. Matterer","Tools and Practices for Responsible AI Engineering",2022,"","","","",139,"2022-07-13 09:24:21","","","","",,,,,2,2.00,0,5,1,"Responsible Artificial Intelligence (AI)—the practice of developing, evaluating, and maintaining accurate AI systems that also exhibit essential properties such as robustness and explainability—represents a multifaceted challenge that often stretches standard machine learning tooling, frameworks, and testing methods beyond their limits. In this paper, we present two new software libraries—hydra-zen and the rAI-toolbox—that address critical needs for responsible AI engineering. hydra-zen dramatically simplifies the process of making complex AI applications configurable, and their behaviors reproducible. The rAI-toolbox is designed to enable methods for evaluating and enhancing the robustness of AI-models in a way that is scalable and that composes naturally with other popular ML frameworks. We describe the design principles and methodologies that make these tools effective, including the use of property-based testing to bolster the reliability of the tools themselves. Finally, we demonstrate the composability and flexibility of the tools by showing how various use cases from adversarial robustness and explainable AI can be concisely implemented with familiar APIs.","",""
1,"M. Wischow, Guillermo Gallego, I. Ernst, Anko Borner","Camera Condition Monitoring and Readjustment by means of Noise and Blur",2021,"","","","",140,"2022-07-13 09:24:21","","","","",,,,,1,1.00,0,4,1,"Autonomous vehicles and robots require increasingly more robustness and reliability to meet the demands of modern tasks. These requirements specially apply to cameras because they are the predominant sensors to acquire information about the environment and support actions. A camera must maintain proper functionality and take automatic countermeasures if necessary. However, there is little work that examines the practical use of a general condition monitoring approach for cameras and designs countermeasures in the context of an envisaged high-level application. We propose a generic and interpretable self-health-maintenance framework for cameras based on dataand physically-grounded models. To this end, we determine two reliable, real-time capable estimators for typical image effects of a camera in poor condition (defocus blur, motion blur, different noise phenomena and most common combinations) by comparing traditional and retrained machine learning-based approaches in extensive experiments. Furthermore, we demonstrate how one can adjust the camera parameters (e.g., exposure time and ISO gain) to achieve optimal whole-system capability based on experimental (non-linear and non-monotonic) input-output performance curves, using object detection, motion blur and sensor noise as examples. Our framework not only provides a practical ready-to-use solution to evaluate and maintain the health of cameras, but can also serve as a basis for extensions to tackle more sophisticated problems that combine additional data sources (e.g., sensor or environment parameters) empirically in order to attain fully reliable and robust machines.","",""
1,"Pranesh Santikellur, R. Chakraborty","A Computationally Efficient Tensor Regression Network-Based Modeling Attack on XOR Arbiter PUF and Its Variants",2021,"","","","",141,"2022-07-13 09:24:21","","10.1109/TCAD.2020.3032624","","",,,,,1,1.00,1,2,1,"XOR arbiter PUF (XOR APUF), where the outputs of multiple arbiter PUF (APUFs) are XOR-ed, has proven to be more robust to machine learning-based modeling attacks. The reported successful modeling attacks for XOR APUF either employ auxiliary side-channel or reliability information, or require enormous computational effort. This robustness is primarily due to the difficulty in learning the unknown internal delay parameter terms in the mathematical model of a XOR APUF, and the robustness increases as the number of APUFs being XOR-ed increases. In this article, we employ a novel machine learning-based modeling technique called efficient CANDECOMP/PARAFAC-tensor regression network (CP-TRN), a variant of CP-decomposition-based tensor regression network, to reduce the computational resource requirement of model building attacks on XOR APUF. We theoretically prove the reduction in computational complexity, as well as give supporting experimental results. In addition, our proposed technique does not require any auxiliary information, and is robust to noisy training data. The proposed technique allowed us to successfully model 64-bit 8-XOR APUF and 128-bit 7-XOR APUF on a single desktop workstation, with high prediction accuracy. Further, we extend the proposed modeling attack technique to XOR APUF variants, e.g., lightweight secure PUF (LSPUF), which rely on input challenge transformation. The modeling accuracy results obtained by us for the LSPUF are comparable with those obtained by applying other state-of-the-art techniques, while requiring less training data.","",""
0,"P. Icer","Bioinformatics Methods For Studying Intra-Host and Inter-Host Evolution Of Highly Mutable Viruses",2021,"","","","",142,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,1,1,"Understanding viral disease progression is vital to the detection of outbreaks and subsequent planning for public health actions. Bioinformatics methods are extremely useful for this purpose through a range of applications among which the analysis of viral next-generation sequencing (NGS) data, tracing virus evolution and reconstruction of transmission networks have been explored in this research. The first part of this research focuses on the processing of NGS data where quantification methods are proposed to describe the robustness and reproducibility of the output of bioinformatics tools. This research shows the importance of assessing the reliability of genomic tools. The second part of this study is the application of processed NGS data to investigate the intra-host evolution of Hepatitis C Virus (HCV) to diagnose and detect new and incident HCV cases. A computational method based on Machine Learning algorithms is proposed to solve this problem. This genomic multi feature-based model not only aims to predict the stage of infection but also aims to understand the evolution of HCV and its underlying complex mechanism. The third part of this research aims to reconstruct transmission networks for new cases which were identified during the aforementioned research. In this part the inter-host evolution of highly mutable viruses is studied. A Maximum Likelihood approach consisting of Uncapacitated Facility Location Algorithm is proposed to solve this problem. Finally, the last part of this dissertation focuses on the inference of the global transmission network of SARS-CoV-2 prior to the pandemic state. INDEX WORDS: Robustness, Quasispecies, Transmission Network, Machine Learning, Hepatitis C Virus, SARS-CoV-2 BIONFORMATICS METHODS FOR STUDYING INTRA-HOST AND INTER-HOST EVOLUTION OF HIGHLY MUTABLE VIRUSES","",""
0,"M. S. Hossain Lipu, M. Hannan, A. Hussain, Shaheer Ansari, A. Ayob, M. Saad, K. Muttaqi","Differential Search Optimized Random Forest Regression Algorithm for State of Charge Estimation in Electric Vehicle Batteries",2021,"","","","",143,"2022-07-13 09:24:21","","10.1109/ias48185.2021.9677106","","",,,,,0,0.00,0,7,1,"This paper presents an improved machine learning approach for the accurate and robust state of charge (SOC) in electric vehicle (EV) batteries using differential search optimized random forest regression (RFR) algorithm. The precise SOC estimation confirms the safety and reliability of EV. Nevertheless, SOC is influenced by numerous factors which cannot be measured directly. RFR is suitable for SOC estimation due to its robustness to noise, overfitting issues and capacity to work with huge datasets. However, proper selection of RFR architecture and hyper-parameters combination remains a key issue to be explored. Hence, a differential search algorithm (DSA) is employed to search for the optimal values of trees and leaves in RFR algorithm. DSA optimized RFR eliminates the utilization of the filter in data pre-processing steps and does not require a detailed understanding and knowledge about battery chemistry, rather only needs sensors to monitor battery voltage and current. The developed approach is validated at room temperature using two types of lithium-ion batteries under a pulse discharge test. In addition, the proposed model is verified under varying temperature settings under EV drive cycles. The experimental results demonstrate that the DSA optimized RFR algorithm is superior to other optimized machine learning approaches in achieving a lower error rate which illustrates the suitability of the proposed model in the online battery management system.","",""
0,"Simon Kamm, K. Sharma, N. Jazdi, M. Weyrich","A Hybrid Modelling Approach for Parameter Estimation of Analytical Reflection Models in the Failure Analysis Process of Semiconductors",2021,"","","","",144,"2022-07-13 09:24:21","","10.1109/CASE49439.2021.9551454","","",,,,,0,0.00,0,4,1,"Electronic devices are one of the key factors for recent advances in smart production systems or automotive. Reliability and robustness are key issues. To further increase this reliability, occurring failures in an electronic device has to be investigated in post-production failure analysis processes. One recent technique to detect and locate failures in electronic components is Time-Domain Reflectometry. This method offers the chance to detect several kinds of failures (e.g. a hard or soft failure) and localize the failure nondestructively. In theory, this can be determined following defined physical formulas. Nevertheless, the received signals are not perfect and mixed with noise from the measurement device or disturbed by nonoptimal material properties. In addition, complex architectures of devices are hard to model based on analytical models. Thus, these models solely are not sufficient for the failure analysis process. For this reason, a hybrid modeling approach is proposed, using a Machine Learning model in combination with physical models to detect and characterize the failure and its exact position. The Machine Learning model will be trained with simulated Time-Domain Reflectometry data.","",""
0,"Xiuyu Huang, Mark Latt, Matloob Khushi, P. Pelicioni, M. Brodie, S. Lord, C. Loy, S. Poon","A Multi-view Classification Framework for Falls Prediction: Multiple-domain Assessments in Parkinson's Disease",2021,"","","","",145,"2022-07-13 09:24:21","","10.24251/HICSS.2021.413","","",,,,,0,0.00,0,8,1,"Falls are one of the most common causes of injury and disability in people with Parkinson’s disease (PD). This study developed an augmented machine learning framework for screening the risk of falling in people with PD using multiple domain assessments. A sample of 109 people with PD (50 fallers and 59 non-fallers) undertook four domains of assessment: disease-specific rating scales, clinical examination measures, physiological assessments, and gait analysis. A multiview classifying framework was developed from a sequence of procedures and achieved 77.50% average predicting accuracy. The robustness of the multi-view framework was tested by comparing outcomes of three different view selection methods. The developed framework may have implications for clinical decision making, as some of the PD fall risk variables/features may be amenable to treatment. Our results showed that external reliability can be achieved by a simple voting mechanism from multiple, perhaps diverse, perspective","",""
0,"Shawqi Al-Maliki, Faissal El Bouanani, Kashif Ahmad, Mohamed Abdallah, D. Hoang, D. Niyato, A. Al-Fuqaha","Opportunistic Use of Crowdsourced Workers for Online Relabeling of Potential Adversarial Examples",2021,"","","","",146,"2022-07-13 09:24:21","","10.36227/techrxiv.17088941.v1","","",,,,,0,0.00,0,7,1,"Deep Neural Networks (DDNs) have achieved tremendous success in handling various Machine Learning (ML) tasks, such as speech recognition, Natural Language Processing, and image classification. However, they have shown vulnerability to well-designed inputs called adversarial examples. Researchers in industry and academia have proposed many adversarial example defense techniques. However, none can provide complete robustness. The cutting-edge defense techniques offer partial reliability. Thus, complementing them with another layer of protection is a must, especially for mission-critical applications. This paper proposes a novel Online Selection and Relabeling Algorithm (OSRA) that opportunistically utilizes a limited number of crowdsourced workers (budget-constraint crowdsourcing) to maximize the ML system’s robustness. OSRA strives to use crowdsourced workers effectively by selecting the most suspicious inputs (the potential adversarial examples) and moving them to the crowdsourced workers to be validated and corrected (relabeled). As a result, the impact of adversarial examples gets reduced, and accordingly, the ML system becomes more robust. We also proposed a heuristic threshold selection method that contributes to enhancing the prediction system’s reliability. We empirically validated our proposed algorithm and found that it can efficiently and optimally utilize the allocated budget for crowdsourcing. It is also effectively integrated with a state-ofthe- art black-box (transfer-based) defense technique, resulting in a more robust system. Simulation results show that OSRA can outperform a random selection algorithm by 60% and achieve comparable performance to an optimal offline selection benchmark. They also show that OSRA’s performance has a positive correlation with system robustness.","",""
0,"A. K. Akash, Sean Chung, Shri Shruthi Shridhar, Wissam Kontar","Robustifying Out-of-Distribution Detection: A Self-Supervision and Energy Based Approach",2021,"","","","",147,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,4,1,"Out-of-distribution (OOD) detection is essential to deploying machine learning systems in the real world. However, the reliability of the existing OOD detectors is severely hampered when used in an environment with adversarial/natural perturbations. Being such a critical component, this necessitates the study of techniques to robustify it. In this work, we propose using the representation learning power of self-supervision methods with better OOD scoring mechanism based on energy to improve the robustness of OOD detectors. Speciﬁcally, we propose a blend of ﬂexible loss function formulations that can effectively learn robust features. Our ﬁndings merit the use of a new methodological perspective that focuses on robustifying OOD detection.","",""
0,"P. Jardine, S. Givigi, S. Yousefi","Leveraging Data Engineering to Improve Unmanned Aerial Vehicle Control Design",2020,"","","","",148,"2022-07-13 09:24:21","","10.1109/JSYST.2020.3003203","","",,,,,0,0.00,0,3,2,"The potential benefits of big data and machine learning techniques are yet to be fully realized in real-time, safety-critical applications like unmanned aerial vehicle control. This is because of challenges related to interpretation, error susceptibility, and resources requirements. Due to their robustness and reliability, traditional model-based design techniques still dominate this landscape. However, a growing body of research in adaptive control has demonstrated the potential benefits of merging these two distinct design philosophies. This article investigates the benefits of using a combination of machine learning techniques to automatically tune parameters within a strictly defined model predictive control architecture. Fast orthogonal search and finite action-set learning automata are used to tune model coefficients and objective function weights, respectively. The strategy is validated experimentally on an actual Quanser Qball2 quadcopter and through several simulations of a Parrot AR.drone. Results demonstrate that the proposed approach improves performance while reducing design effort.","",""
0,"Lin Sun, Bingxin Xu, Xinyu Fan, Jiangbing Du, Zuyuan He, Chao Lu","Real-time channel conditional distribution tracking for intelligent decoding of optical IMDD signals.",2021,"","","","",149,"2022-07-13 09:24:21","","10.1364/OL.437740","","",,,,,0,0.00,0,6,1,"In this Letter, we propose a real-time machine learning scheme of a tracking optical intensity-modulation and direct-detection (IMDD) system's conditional distribution using linear optical sampling and inline Gaussian mixer modeling (GMM) programming. End-to-end conditional distribution tracking enables an adaptive decoding of optical IMDD signals, with robustness to the bias point shift of the optical intensity modulator. Experimental demonstration is conducted over a 20-Gbits/s optical pulse amplitude modulation-4 (PAM-4) modulation system. Optical PAM-4 signals are optically down-sampled by short pulses to 250 Msa/s. Then, statistical characters of signal distribution can be estimated using inline GMM processing. Due to the real-time learned distribution, intelligent decoding of received signals exhibits a perfect adaptation to the changing bias point of a Mach-Zendner intensity modulator, enhancing the communication reliability with bit error rate (BER) below 3.8⋅10-3. In addition, the proposed scheme also provides the possibility of practical implementation to other machine learning signal decoding methods.","",""
0,"Junwei Ma, D. Xia, Hai-Li Guo, Yankun Wang, Xiaoxu Niu, Zhiyang Liu, Sheng Jiang","Metaheuristic-based support vector regression for landslide displacement prediction: a comparative study",2022,"","","","",150,"2022-07-13 09:24:21","","10.1007/s10346-022-01923-6","","",,,,,0,0.00,0,7,1,"","",""
0,"Giuseppe Castiglione, G. Ding, M. Hashemi, C. Srinivasa, Ga Wu","Scalable Whitebox Attacks on Tree-based Models",2022,"","","","",151,"2022-07-13 09:24:21","","10.48550/arXiv.2204.00103","","",,,,,0,0.00,0,5,1,"Adversarial robustness is one of the essential safety criteria for guaranteeing the reliability of machine learning models. While various adversarial robustness testing approaches were introduced in the last decade, we note that most of them are incompatible with non-differentiable models such as tree ensembles. Since tree ensembles are widely used in industry, this reveals a crucial gap between adversarial robustness research and practical applications. This paper proposes a novel whitebox adversarial robustness testing approach for tree ensemble models. Concretely, the proposed approach smooths the tree ensembles through temperature-controlled sigmoid functions, which enables gradient descent-based adversarial attacks. By leveraging sampling and the log-derivative trick, the proposed approach can scale up to testing tasks that were previously unmanageable. We compare the approach against both random perturbations and blackbox approaches on multiple public datasets (and corresponding models). Our results show that the proposed method can 1) successfully reveal the adversarial vulnerability of tree ensemble models without causing computational pressure for testing and 2) ﬂexibly balance the search performance and time complexity to meet various testing criteria.","",""
0,"Ziyi Huang, H. Lam, Haofeng Zhang","Evaluating Aleatoric Uncertainty via Conditional Generative Models",2022,"","","","",152,"2022-07-13 09:24:21","","10.48550/arXiv.2206.04287","","",,,,,0,0.00,0,3,1,"Aleatoric uncertainty quantification seeks for distributional knowledge of random responses, which is important for reliability analysis and robustness improvement in machine learning applications. Previous research on aleatoric uncertainty estimation mainly targets closed-formed conditional densities or variances, which requires strong restrictions on the data distribution or dimensionality. To overcome these restrictions, we study conditional generative models for aleatoric uncertainty estimation. We introduce two metrics to measure the discrepancy between two conditional distributions that suit these models. Both metrics can be easily and unbiasedly computed via Monte Carlo simulation of the conditional generative models, thus facilitating their evaluation and training. We demonstrate numerically how our metrics provide correct measurements of conditional distributional discrepancies and can be used to train conditional models competitive against existing benchmarks.","",""
0,"Pegah Golchin, Ralf Kundel, Tim Steuer, Rhaban Hark, R. Steinmetz","Improving DDoS Attack Detection Leveraging a Multi-aspect Ensemble Feature Selection",2022,"","","","",153,"2022-07-13 09:24:21","","10.1109/NOMS54207.2022.9789763","","",,,,,0,0.00,0,5,1,"DDoS attack detection is crucial in computer networks to meet the reliability and accessibility requirements of online services. The ability of machine learning to discriminate between DDoS attacks and benign flows makes it a promising candidate for DDoS detection. Correctly classifying the flows with high performance in near real-time is a critical issue for an ML-based DDoS detector to reduce the damages of DDoS attacks. In order to improve the performance of classification and reduce the prediction time, we propose a multi-aspect Ensemble Feature Selection (EFS) for DDoS attack detection in this work. The presented EFS selects the most relevant features of each attack separately, leveraging a combination of statistical filtering approaches and machine learning methods. We evaluate our method on two different datasets to demonstrate the EFS robustness toward model-specific biases. Last, we demonstrate that the prediction time is reduced leveraging the proposed EFS.","",""
0,"W. Harris, A. Gu, M. Terada","Putting AI to Work: A Practical and Simple Application to Improve 3D X-ray FA",2022,"","","","",154,"2022-07-13 09:24:21","","10.1109/IRPS48227.2022.9764574","","",,,,,0,0.00,0,3,1,"This paper presents the demonstration of a deep learning-based reconstruction approach for working with 3D X-ray tomography/microscopy data, focusing on improving workflows in microelectronics failure analysis and reliability applications. Whereas the industry-standard filtered back projection (known as FDK) method of X-ray tomography reconstruction has been used for many years due to its simplicity and robustness, it has constrained the results of 3D X-ray scanning in terms of both image quality and scan speed. Powered by artificial intelligence technologies, the new deep learning high resolution reconstruction (DLHRR) approach discussed here offers broad improvements across diverse sample types including microelectronics, increases scan speed by a factor of 4X or more, is as easy to use as FDK without requirement for a machine learning expert, and is implemented on a desktop workstation PC. Results will be shown on IC packages and commercial battery devices.","",""
0,"A. R., T. Rajeev","LSTM Based Approach for Timely Detection of Gradual Development of Electrical Fault in Power System",2022,"","","","",155,"2022-07-13 09:24:21","","10.1109/ICAECT54875.2022.9807893","","",,,,,0,0.00,0,2,1,"Power system reliability and efficiency are becoming a primary concern with the increase in load and expansion of power grids. Electrical faults in the power system should be detected and cleared immediately due to their critical impact on the reliability and stability of the system. This paper proposes an approach to predict the faults in the power system using machine learning techniques like Long Short-Term Memory (LSTM). The LSTM model is used to predict gradual faults in the system before their actual occurrence. Three-phase measurements of voltages, currents, and active power during faults and normal operating conditions are taken as data inputs to train the models. The robustness of the method is verified by simulating the fault with different parameters. The proposed method can be expanded to the distribution network of the power system. A modified IEEE 9 bus system is modelled in MATLAB/Simulink and is used to get the data for the experiment. The results from the experiment prove the feasibility of using LSTM networks for predicting the faults in the power system.","",""
0,"Maximilian Busch, M. Zaeh","Multi-Fidelity Information Fusion to Model the Position-Dependent Modal Properties of Milling Robots",2022,"","","","",156,"2022-07-13 09:24:21","","10.3390/robotics11010017","","",,,,,0,0.00,0,2,1,"Robotic machining is a promising technology for post-processing large additively manufactured parts. However, the applicability and efficiency of robot-based machining processes are restricted by dynamic instabilities (e.g., due to external excitation or regenerative chatter). To prevent such instabilities, the pose-dependent structural dynamics of the robot must be accurately modeled. To do so, a novel data-driven information fusion approach is proposed: the spatial behavior of the robot’s modal parameters is modeled in a horizontal plane using probabilistic machine learning techniques. A probabilistic formulation allows an estimation of the model uncertainties as well, which increases the model reliability and robustness. To increase the predictive performance, an information fusion scheme is leveraged: information from a rigid body model of the fundamental behavior of the robot’s structural dynamics is fused with a limited number of estimated modal properties from experimental modal analysis. The results indicate that such an approach enables a user-friendly and efficient modeling method and provides reliable predictions of the directional robot dynamics within a large modeling domain.","",""
0,"S. Shariff","Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) Network Models for Forecasting Energy Consumptions",2022,"","","","",157,"2022-07-13 09:24:21","","10.24018/ejece.2022.6.3.435","","",,,,,0,0.00,0,1,1,"Unlike other sources of energy, electricity can't be stored. Therefore, an estimation of Energy Consumption (EC) with good accuracy is required to manage demand and supply in the smart grid. Not only good accuracy, but reliability is also on-demand in the prediction model to optimize resource allocation. Therefore, in this study we have implemented and examine two different models: a machine learning model, Autoregressive Integrated Moving Average (ARIMA), and a deep learning-based model Long Short-Term Memory (LSTM). Although ARIMA showed powerful statistical analysis and less robustness, LSTM demonstrated highly accurate results which may stop us to lead false alarming of over-demand and low consumption of energy. In last, we have concluded our result by presenting significant improvement in forecasting energy by LSTM using various evaluation criteria e.g., Mean Square Error (MSE), Root Mean Square Error (RMSE), and other normalized matrices.","",""
0,"Zheao Li, Zhongjin Jiang, Jie Huang","Automatic Modulation Classification Based on the Improved AlexNet",2021,"","","","",158,"2022-07-13 09:24:21","","10.1109/IWCMC51323.2021.9498686","","",,,,,0,0.00,0,3,1,"In the military and civilian domains, the modulation classification in the communication system is an extremely important technology that needs to be constantly updated and improved. In this paper, we present an automatic modulation classification (AMC) model to do modulation classification in 5 typical types of signal modulation BPSK, QPSK, 8PSK, 16QAM, and 64QAM. The proposed algorithm uses an improved AlexNet with deep residual learning, regularization, global pooling, and PReLU activation function to extract features from constellation diagrams for better recognition performance. Compared with the original AlexNet, support vector machine (SVM), and the traditional maximum likelihood-based cumulant technique, experiment results indicate that the proposed AMC model with the improved AlexNet has achieved very good recognition results, with its robustness, generalization, and high efficiency. We also explore the identifiability and reliability of signal transmission under different SNR conditions for different modulation types.","",""
1,"Cariño Corrales, J. Adolfo","Fault detection and identification methodology under an incremental learning framework applied to industrial electromechanical systems",2017,"","","","",159,"2022-07-13 09:24:21","","","","",,,,,1,0.20,1,2,5,"Condition Based Maintenance is a program that recommends actions based on the information collected and interpreted through condition monitoring and has become accepted since a decade ago by the industry as a key factor to avoiding expensive unplanned machine stoppages and reaching high production ratios. Among the condition based maintenance strategies, data-driven fault diagnosis methodologies have gained increased attention because of the high performance and widen range of applicability due to less restrictive constrains in comparison to other approaches. Therefore, an increased effort is been made to develop reliable methodologies that could diagnose multiple known faults on a machine with initial applications in controlled environments like laboratory test benches.    However, applying those methods to industry applications still represent an ongoing challenge due to the multiple limitations involved and the high reliability and robustness required. One of the most important challenges in the industrial sector refers to the management of unexpected events, in respect of how to detect new faults or anomalies in the machine. In addition, the information initially available of the monitored industrial machine is usually limited to the healthy condition, therefore is not only necessary to detect these new scenarios but also incorporate this information to the initial base knowledge.    In this regard, this thesis present a series of complementary methodologies that leads to the implementation of a fault detection and identification system capable to detect multiple faults and new scenarios of industrial electromechanical machines under an incremental learning framework to include the new scenarios detected to the initial base knowledge while achieving a high performance and generalization capabilities. Initially, a methodology to increase the performance of novelty detection models to detect unexpected events in electromechanical system is proposed. Then, a methodology to implement a sequential fault detection and identification system composed by a novelty detection and a fault diagnosis stages with high accuracy is proposed. Finally, two different methodologies are proposed to provide the sequential fault detection and identification system the capacity to include new scenarios to the base knowledge. The proposed methodologies have been validated by means of experimental data of laboratory test benches and industrial electromechanical systems.","",""
15,"S. Anvar, A. Tucker, V. Vinciotti, A. Venema, G. V. Ommen, S. V. D. Maarel, V. Raz, P. Hoen","Interspecies Translation of Disease Networks Increases Robustness and Predictive Accuracy",2011,"","","","",160,"2022-07-13 09:24:21","","10.1371/journal.pcbi.1002258","","",,,,,15,1.36,2,8,11,"Gene regulatory networks give important insights into the mechanisms underlying physiology and pathophysiology. The derivation of gene regulatory networks from high-throughput expression data via machine learning strategies is problematic as the reliability of these models is often compromised by limited and highly variable samples, heterogeneity in transcript isoforms, noise, and other artifacts. Here, we develop a novel algorithm, dubbed Dandelion, in which we construct and train intraspecies Bayesian networks that are translated and assessed on independent test sets from other species in a reiterative procedure. The interspecies disease networks are subjected to multi-layers of analysis and evaluation, leading to the identification of the most consistent relationships within the network structure. In this study, we demonstrate the performance of our algorithms on datasets from animal models of oculopharyngeal muscular dystrophy (OPMD) and patient materials. We show that the interspecies network of genes coding for the proteasome provide highly accurate predictions on gene expression levels and disease phenotype. Moreover, the cross-species translation increases the stability and robustness of these networks. Unlike existing modeling approaches, our algorithms do not require assumptions on notoriously difficult one-to-one mapping of protein orthologues or alternative transcripts and can deal with missing data. We show that the identified key components of the OPMD disease network can be confirmed in an unseen and independent disease model. This study presents a state-of-the-art strategy in constructing interspecies disease networks that provide crucial information on regulatory relationships among genes, leading to better understanding of the disease molecular mechanisms.","",""
8,"R. Sahu, Juliane Müller, Jangho Park, C. Varadharajan, B. Arora, B. Faybishenko, D. Agarwal","Impact of Input Feature Selection on Groundwater Level Prediction From a Multi-Layer Perceptron Neural Network",2020,"","","","",161,"2022-07-13 09:24:21","","10.3389/frwa.2020.573034","","",,,,,8,4.00,1,7,2,"With the growing use of machine learning (ML) techniques in hydrological applications, there is a need to analyze the robustness, performance, and reliability of predictions made with these ML models. In this paper we analyze the accuracy and variability of groundwater level predictions obtained from a Multilayer Perceptron (MLP) model with optimized hyperparameters for different amounts and types of available training data. The MLP model is trained on point observations of features like groundwater levels, temperature, precipitation, and river flow in various combinations, for different periods and temporal resolutions. We analyze the sensitivity of the MLP predictions at three different test locations in California, United States and derive recommendations for training features to obtain accurate predictions. We show that the use of all available features and data for training the MLP does not necessarily ensure the best predictive performance at all locations. More specifically, river flow and precipitation data are important training features for some, but not all locations. However, we find that predictions made with MLPs that are trained solely on temperature and historical groundwater level measurements as features, without additional hydrological information, are unreliable at all locations.","",""
25,"Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, A. Buduru","A Survey of Black-Box Adversarial Attacks on Computer Vision Models",2019,"","","","",162,"2022-07-13 09:24:21","","","","",,,,,25,8.33,6,4,3,"Machine learning has seen tremendous advances in the past few years, which has lead to deep learning models being deployed in varied applications of day-to-day life. Attacks on such models using perturbations, particularly in real-life scenarios, pose a severe challenge to their applicability, pushing research into the direction which aims to enhance the robustness of these models. After the introduction of these perturbations by Szegedy et al. [1], significant amount of research has focused on the reliability of such models, primarily in two aspects - white-box, where the adversary has access to the targeted model and related parameters; and the black-box, which resembles a real-life scenario with the adversary having almost no knowledge of the model to be attacked. To provide a comprehensive security cover, it is essential to identify, study, and build defenses against such attacks. Hence, in this paper, we propose to present a comprehensive comparative study of various black-box adversarial attacks and defense techniques.","",""
4,"J. Peguero, O. Mendoza-Montoya, J. Antelis","Single-Option P300-BCI Performance Is Affected by Visual Stimulation Conditions",2020,"","","","",163,"2022-07-13 09:24:21","","10.3390/s20247198","","",,,,,4,2.00,1,3,2,"The P300 paradigm is one of the most promising techniques for its robustness and reliability in Brain-Computer Interface (BCI) applications, but it is not exempt from shortcomings. The present work studied single-trial classification effectiveness in distinguishing between target and non-target responses considering two conditions of visual stimulation and the variation of the number of symbols presented to the user in a single-option visual frame. In addition, we also investigated the relationship between the classification results of target and non-target events when training and testing the machine-learning model with datasets containing different stimulation conditions and different number of symbols. To this end, we designed a P300 experimental protocol considering, as conditions of stimulation: the color highlighting or the superimposing of a cartoon face and from four to nine options. These experiments were carried out with 19 healthy subjects in 3 sessions. The results showed that the Event-Related Potentials (ERP) responses and the classification accuracy are stronger with cartoon faces as stimulus type and similar irrespective of the amount of options. In addition, the classification performance is reduced when using datasets with different type of stimulus, but it is similar when using datasets with different the number of symbols. These results have a special connotation for the design of systems, in which it is intended to elicit higher levels of evoked potentials and, at the same time, optimize training time.","",""
2,"Pavel Mašek, P. Sedlácek, A. Ometov, J. Mekyska, P. Mlynek, Jiri Hosek, Mikhail M. Komarov","Improving the Precision of Wireless Localization Algorithms: ML Techniques for Indoor Positioning",2020,"","","","",164,"2022-07-13 09:24:21","","10.1109/tsp49548.2020.9163551","","",,,,,2,1.00,0,7,2,"Due to the tremendous increase in the number of wearable devices and proximity-based services, the need for improved indoor localization techniques becomes more significant. The evolution of the positioning from a hardware perspective is pacing its way along with various software-based approaches also powered by Machine Learning (ML). In this paper, we apply ML algorithms to the real-life collected signal parameters in an indoor localization system based on Ultra-Wideband (UWB) technology to make an analysis of the signal and classify it accordingly. The contribution aims to answer the question of whether an indoor positioning system could benefit from utilizing ML for signal parameter analysis in order to increase its location accuracy, reliability, and robustness across various environments. To this end, we compare different applications of ML approaches and detail the trade-off between computational speed and accuracy.","",""
2,"Tuan-Duy H. Nguyen, Huu-Nghia H. Nguyen","Towards a Robust WiFi-based Fall Detection with Adversarial Data Augmentation",2020,"","","","",165,"2022-07-13 09:24:21","","10.1109/CISS48834.2020.1570617398","","",,,,,2,1.00,1,2,2,"Recent WiFi-based fall detection systems have drawn much attention due to their advantages over other sensory systems. Various implementations have achieved impressive progress in performance, thanks to machine learning and deep learning techniques. However, many of such high accuracy systems have low reliability as they fail to achieve robustness in unseen environments. To address that, this paper investigates a method of generalization through adversarial data augmentation. Our results show a slight improvement in deep learning-systems in unseen domains, though the performance is not significant.","",""
3,"Chong Shen, Xindong Wu, Donghua Zhao, Shan Li, Huiliang Cao, Huijun Zhao, Jun Tang, Jun Liu, Chenguang Wang","Comprehensive Heading Error Processing Technique Using Image Denoising and Tilt-Induced Error Compensation for Polarization Compass",2020,"","","","",166,"2022-07-13 09:24:21","","10.1109/ACCESS.2020.3028418","","",,,,,3,1.50,0,9,2,"Bionic polarization navigation has a broad variety of application in diverse fields for high reliability and strong robustness to interference, fundamental to which is the use of a polarization compass based on polarized light cues. Nevertheless, dramatical reduction of the orientation accuracy resulted from the noise in a measured angle of polarization (AoP) and the tilted angles of a polarization compass during operation gives imperative influence on navigation precision. Herein, we investigate how to improve the navigation accuracy effectively by the proposed comprehensive heading error processing technique for a polarization compass, where a novel denoising scheme is designed to eliminate the noise in AoP images directly by integrating the strength of iterative variance-stabilizing transformation (IVST) and adaptive soft interval thresholding (SIT) so as to compensate the following tilt-induced error accurately. Subsequently, a promising compensation approach inspired by efficient extreme learning machine (EELM) is introduced to correct the tilt-induced error caused by realistic execution. The AoP image denoising advance and the tilt-induced error modeling advance combine to produce remarkable performance gains on the heading error. Experimental results and comparisons with prior arts reveal that the proposed comprehensive heading error processing technique is highly appealing in terms of improving the orientation accuracy for a polarization compass with superiority to state-of-the-art alternatives.","",""
1,"Qiwu Luo, Jian Zhou, Yichuang Sun, Oluyomi Simpson","Jointly optimized echo state network for short-term channel state information prediction of fading channel",2020,"","","","",167,"2022-07-13 09:24:21","","10.1109/IWCMC48107.2020.9148072","","",,,,,1,0.50,0,4,2,"Accurately obtaining channel state information (CSI) in wireless systems is significant but challenging. This paper focuses the technique of machine-learning-based channel estimation. In particular, a jointly optimized echo state network (JOESN) is proposed to form a concept of the CSI prediction which is made up of two interacting aspects of output weight regularization and initial parameter optimization. First, in order to enhance noise robustness, a sparse regression based on L2 regularization is employed to finely learn the output weights of ESN. Second, vital reservoir parameters (i.e., global scaling factor, reservoir size, scaling coefficient and sparsity degree) are learned by a linear-weighted particle swarm optimization (LW-PSO) for further improve the prediction accuracy and reliability. The experiments about computational complexity and three evaluating metrics are carried out on two chaotic benchmarks and one real-world dataset. The analyzed results indicate that the JOESN performs promisingly on multivariate chaotic time series prediction.","",""
15,"Ke Li, Jingjing Xiao, Jiali Yang, Meng Li, Xuanqi Xiong, Y. Nian, Linbo Qiao, Huaizhi Wang, A. Eresen, Zhuoli Zhang, Xianling Hu, Jian Wang, Wei Chen","Association of radiomic imaging features and gene expression profile as prognostic factors in pancreatic ductal adenocarcinoma.",2019,"","","","",168,"2022-07-13 09:24:21","","","","",,,,,15,5.00,2,13,3,"In this study, we investigated whether radiomic features of CT image data can accurately predict HMGA2 and C-MYC gene expression status and identify the patient survival time using a machine learning approach in pancreatic ductal adenocarcinoma (PDAC). A cohort of 111 patients with PDAC was enrolled in our study. Radiomic features were extracted using conventional (shape and texture analysis) and deep learning approaches following to segmentation of preoperative CT data. To predict patient survival time, significant radiomic features were identified using a log-rank test. After surgical resection, level of HMGA2 and C-MYC gene expressions of PDAC tumor regions were classified using a support vector machines method. The model was evaluated in terms of accuracy, sensitivity, specificity, and area under the curve (AUC). Besides, inter-reader reliability analysis was used to demonstrate the robustness of the proposed features. The identified features consistently achieved good performance in survival prediction and classification of gene expression status, on images segmented by different radiologists. Using CT data from 111 patients, six features in the segmented region of images were highly correlated with survival time. Using extracted deep features of excised lesions from 47 patients, we observed an average AUC score of 0.90 with an accuracy of 95% in C-MYC prediction (sensitivity: 92% and specificity: 98%). In HGMA2 group, using shape features, the average AUC score was measured as 0.91 with an accuracy of 88% (sensitivity: 89% and specificity: 88%). In conclusion, the radiomic features of CT image can accurately predict the expression status of HMGA2 and C-MYC genes and identify the survival time of PDAC patients.","",""
2,"Huamei Zhang, S. Zhou, Cheng Xu, J. Zhang","A ROBUST APPROACH FOR THREE-DIMENSIONAL REAL-TIME TARGET LOCALIZATION UNDER AMBIGUOUS WALL PARAMETERS",2020,"","","","",169,"2022-07-13 09:24:21","","10.2528/pierm20060701","","",,,,,2,1.00,1,4,2,"To obtain three-dimensional (3-D) high-precision and real-time through-wall location under ambiguous wall parameters, an approach based on the extreme learning machine (ELM) which is a neural network is proposed. The wall’s ambiguity and propagation effects are both included in the hidden layer feedforward network, and then the through-wall location problem is converted to a regression problem. The relationship between the scattered signals and the target properties are determined after the training process. Then the target properties are estimated using the ELM approach. Numerical results demonstrate good performance in terms of effectiveness, generalization, and robustness, especially for the kernel extreme learning machine (KELM) approach. Noiseless and noisy measurements are performed to further demonstrate that the approach can provide good performance in terms of stability and reliability. The location time, including the training time and test time, is also discussed, and the results show that the KELM approach is very suitable for real-time location problems. Compared to the machine learning approach, the KELM approach is better not only in the aspect of accuracy but also in location time.","",""
0,"С. В. Пальмов","Исследование возможностей аналитической системы на основе метода машинного обучения",2020,"","","","",170,"2022-07-13 09:24:21","","10.21778/2413-9599-2020-30-3-112-126","","",,,,,0,0.00,0,1,2,"Data analysis carried out by machine learning tools has covered almost all areas of human activity. This is due to a large amount of data that needs to be processed in order, for example, to predict the occurrence of specific events (an emergency, a customer contacting the organization’s technical support, a natural disaster, etc.) or to formulate recommendations regarding interaction with a certain group of people (personalized offers for the customer, a person’s reaction to advertising, etc.). The paper deals with the possibilities of the Multitool analytical system, created based on the machine learning method «decision tree», in terms of building predictive models that are suitable for solving data analysis problems in practical use. For this purpose, a series of ten experiments was conducted, in which the results generated by the system were evaluated in terms of their reliability and robustness using five criteria: arithmetic mean, standard deviation, variance, probability, and F-measure. As a result, it was found that Multitool, despite its limited functionality, allows creating predictive models of sufficient quality and suitable for practical use.","",""
0,"J. Serrà, David Álvarez, V. Gómez, Olga Slizovskaia, José F. Núñez, J. Luque","GENERATIVE MODELS",2020,"","","","",171,"2022-07-13 09:24:21","","10.1007/springerreference_64974","","",,,,,0,0.00,0,6,2,"","",""
0,"Kimia Vahdat, Sara Shashaani","Simulation Optimization Based Feature Selection, a Study on Data-Driven Optimization with Input Uncertainty",2020,"","","","",172,"2022-07-13 09:24:21","","10.1109/WSC48552.2020.9383862","","",,,,,0,0.00,0,2,2,"In machine learning, removing uninformative or redundant features from a dataset can significantly improve the construction, analysis, and interpretation of the prediction models, especially when the set of collected features is extensive. We approach this challenge with simulation optimization over a high dimensional binary space in place of the classic greedy search in forward or backward selection or regularization methods. We use genetic algorithms to generate scenarios, bootstrapping to estimate the contribution of the intrinsic and extrinsic noise and sampling strategies to expedite the procedure. By including the uncertainty from the input data in the measurement of the estimators’ variability, the new framework obtains robustness and efficiency. Our results on a simulated dataset exhibit improvement over state-of-the-art accuracy, interpretability, and reliability. Our proposed framework provides insight for leveraging Monte Carlo methodology in probabilistic data-driven modeling and analysis.","",""
0,"Qing-xian Gao","Exploring the Interaction between Trip Purpose and Mode Choice using GPS-based Trip Data",2020,"","","","",173,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,1,2,"This study aims to improve the trip purpose and mode imputation performance and investigate their interaction. The random forest method is used to conduct supervised machine learning for labeled trip purpose and mode, and its robustness is examined through multiple experiments. Principal component analysis (PCA) is applied to reduce the dimension of numerical features, which deteriorates the model performance and suggests robustness of random forest in extracting feature information. Modification of the random forest through multistage classification and its combination with the Adaptive Synthetic Sampling Approach (ADASYN) brings benefits by selecting relevant features for each category and balancing class distribution on a reasonable scale, whereas reduced performance and reliability do not justify its intuitive benefits. The dependence of classification performance on the number of participants and duration of the survey is studied to provide a guide for future data collection. Possibility of accuracy improvement through point of interest (POI) information from Google places API and support vector machine (SVM) are tested. The results do not support their high monetary and computational cost for large data sets. Overall we get satisfactory model performance using random forests, i.e. 85.3% for trip purpose imputation and 86.3% for trip mode. Complicated characteristics of the activity type ’Leisure’ and the mode ’Car’ and the problem of imbalanced class distribution require further research.","",""
0,"S. F. Sultan, Lilianne R. Mujica Parodi, S. Skiena","Neuropredictome: a data-driven predictome for cognitive, psychiatric, medical, and lifestyle factors on the brain",2020,"","","","",174,"2022-07-13 09:24:21","","10.1101/2020.12.07.415091","","",,,,,0,0.00,0,3,2,"Most neuroimaging studies individually provide evidence on a narrow aspect of the human brain function, on distinct data sets that often suffer from small sample sizes. More generally, the high technical and cost demands of neuroimaging studies (combined with the statistical unreliability of neuroimaging pilot studies) may lead to observational bias, discouraging discovery of less obvious associations that nonetheless have important neurological implications. To address these problems, we built a machine-learning based classification framework, NeuroPredictome, optimized for the reliability and robustness of its associations. NeuroPredictome is grounded in a large-scale dataset, UK-Biobank (N=19,831), which includes resting and task functional MRI as well as structural T1-weighted and diffusion tensor imaging. Participants were assessed with respect to a comprehensive set of 5,034 phenotypes, including the physical and lifestyle factors most relevant to general medicine. Results generated by data-driven classifiers were then cross-validated, using deep-learning textual analyses, against 14,371 peer-reviewed research articles, providing an unbiased hypothesis-generator of linkages between diverse phenotypes and the brain. Our results show that neuroimaging reveals as many neurological links to physical and lifestyle factors as to cognitive factors, supporting a more integrative approach to medicine that considers disease interactions between multiple organs and systems.","",""
0,"Sajal K. Das, H. Yamana, M. Conti, A. Dubey, K. Yasumoto","Message from General Chairs and TPC Chairs",2020,"","","","",175,"2022-07-13 09:24:21","","10.1109/smartcomp50058.2020.00019","","",,,,,0,0.00,0,5,2,"Smart computing aiming to at improve human quality of life and experience represents the next wave of computing. Key technologies contributing to the realization of smart and connected communities include sensing, IoT, mobile and pervasive computing, cyber-physical-social systems, big data, machine learning, data analytics, social and cognitive computing. Smart computing helps solve a wide variety of societal challenges related to transportation, energy, healthcare, finance, disaster management, and so on. At the core of these systems, critical issues are security, privacy, reliability, resiliency, and robustness.","",""
163,"Yan Xu, Z. Dong, Junhua Zhao, Pei Zhang, K. Wong","A Reliable Intelligent System for Real-Time Dynamic Security Assessment of Power Systems",2012,"","","","",176,"2022-07-13 09:24:21","","10.1109/TPWRS.2012.2183899","","",,,,,163,16.30,33,5,10,"A new intelligent system (IS) is developed for real-time dynamic security assessment (DSA) of power systems. Taking an ensemble learning scheme, the IS structures a series of extreme learning machines (ELMs) and generalizes the randomness of single ELMs during the training. Benefiting from the unique properties of ELM and the strategically designed decision-making rules, the IS learns and works very fast and can estimate the credibility of its DSA results, allowing an accurate and reliable pre-fault DSA mechanism: credible results can be directly adopted while incredible results are decided by alternative tools such as time-domain simulation. This makes the IS promising for practical application since the potential unreliable results can be eliminated for use. Case studies considering classification and prediction are, respectively, conducted on an IEEE 50-machine system and a dynamic equivalent system of a real-world large power grid. The efficiency, robustness, accuracy, and reliability of the IS are demonstrated. In particular, it is observed that the IS could provide 100% classification accuracy and very low prediction error on its decided instances.","",""
35,"Dorjan Hitaj, L. Mancini","Have You Stolen My Model? Evasion Attacks Against Deep Neural Network Watermarking Techniques",2018,"","","","",177,"2022-07-13 09:24:21","","","","",,,,,35,8.75,18,2,4,"Deep neural networks have had enormous impact on various domains of computer science, considerably outperforming previous state of the art machine learning techniques. To achieve this performance, neural networks need large quantities of data and huge computational resources, which heavily increases their construction costs. The increased cost of building a good deep neural network model gives rise to a need for protecting this investment from potential copyright infringements. Legitimate owners of a machine learning model want to be able to reliably track and detect a malicious adversary that tries to steal the intellectual property related to the model. Recently, this problem was tackled by introducing in deep neural networks the concept of watermarking, which allows a legitimate owner to embed some secret information(watermark) in a given model. The watermark allows the legitimate owner to detect copyright infringements of his model. This paper focuses on verifying the robustness and reliability of state-of- the-art deep neural network watermarking schemes. We show that, a malicious adversary, even in scenarios where the watermark is difficult to remove, can still evade the verification by the legitimate owners, thus avoiding the detection of model theft.","",""
4,"Owen Derby","FlexGP: a Scalable System for Factored Learning in the Cloud",2013,"","","","",178,"2022-07-13 09:24:21","","","","",,,,,4,0.44,4,1,9,"This work presents FlexGP, a new system designed for scalable machine learning in the cloud. FlexGP presents a learner-agnostic, data-parallel approach to cloud-based distributed learning using existing single-machine algorithms, without any dependence on distributed file systems or shared memory between instances. We design and implement asynchronous and decentralized launch and peer discovery protocols to start and configure a distributed network of learners. Through a unique process of factoring the data and parameters across the learners, FlexGP ensures this network consists of heterogeneous learners producing diverse models. These models are then filtered and fused to produce a meta-model for prediction. Using a thoughtfully designed test framework, FlexGP is run on a real-world regression problem from a large database. The results demonstrate the reliability and robustness of the system, even when learning from very little training data and multiple factorings, and demonstrate FlexGP as a vital tool to effectively leverage the cloud for machine learning tasks. Thesis Supervisor: Kalyan Veeramachaneni Title: Research Scientist Thesis Supervisor: Una-May O’Reilly Title: Principal Research Scientist","",""
12,"Dai, Tang, Shao, Huang, Wang","Fault Diagnosis of Rolling Bearing Based on Multiscale Intrinsic Mode Function Permutation Entropy and a Stacked Sparse Denoising Autoencoder",2019,"","","","",179,"2022-07-13 09:24:21","","10.3390/APP9132743","","",,,,,12,4.00,2,5,3,"Effective intelligent fault diagnosis of bearings is important for improving safety and reliability of machine. Benefiting from the training advantages, deep learning method can automatically and adaptively learn more abstract and high-level features without much priori knowledge. To realize representative features mining and automatic recognition of bearing health condition, a diagnostic model of stacked sparse denoising autoencoder (SSDAE) which combines sparse autoencoder (SAE) and denoising autoencoder (DAE) is proposed in this paper. The sparse criterion in SAE, corrupting operation in DAE and reasonable designing of the stack order of autoencoders help to mine essential information of the input and improve fault pattern classification robustness. In order to provide better input features for the constructed network, the raw non-stationary and nonlinear vibration signals are processed with ensemble empirical mode decomposition (EEMD) and multiscale permutation entropy (MPE). MPE features which are extracted based on both the selected characteristic frequency-related intrinsic mode function components (IMFs) and the raw signal, are used as low-level feature for the input of the proposed diagnostic model for health condition recognition and classification. Two experiments based on the Case Western Reserve University (CWRU) dataset and the measurement dataset from laboratory were conducted, and results demonstrate the effectiveness of the proposed method and highlight its excellent performance relative to existing methods.","",""
0,"F. Gao, Wenchao Lv, Yaotian Zhang, Jinping Sun, J. Wang, Erfu Yang","A novel semisupervised SVM classifier based on active learning and 1 context information 2",2016,"","","","",180,"2022-07-13 09:24:21","","","","",,,,,0,0.00,0,6,6,"Fei Gao · Wenchao Lv · Yaotian Zhang · Jinping Sun · Jun Wang · Erfu Yang 3 4 5 Abstract This paper proposes a novel semisupervised support vector machine classifier (SVM) based 6 on active learning (AL) and context information to solve the problem where the number of labeled 7 samples is insufficient. Firstly, a new semisupervised learning (SSL) method is designed using AL to 8 select unlabeled samples as the semilabled samples, then the context information is exploited to further 9 expand the selected samples and relabel them, along with the labeled samples train SVM classifier. 10 Next, a new query function is designed to enhance the reliability of the classification results by using 11 the Euclidean distance between the samples. Finally, in order to enhance the robustness of the proposed 12 algorithm, a fusion method is designed. Several experiments on change detection are performed by 13 considering some real remote sensing images. The results show that the proposed algorithm in 14 comparison with other algorithms can significantly improve the detection accuracy and achieve a fast 15 convergence in addition to verify the effectiveness of the fusion method developed in this paper. 16","",""
0,"Qihang Fang, Gang Xiong, Xiuqin Shang, Sheng Liu, Bin Hu, Zhen Shen","An Enhanced Fault Diagnosis Method with Uncertainty Quantification Using Bayesian Convolutional Neural Network",2020,"","","","",181,"2022-07-13 09:24:21","","10.1109/CASE48305.2020.9216773","","",,,,,0,0.00,0,6,2,"Fault diagnosis is a vital technique to pinpoint the machine malfunctions in manufacturing systems. In recent years, the deep learning techniques greatly improve the fault detection accuracy, but there still remain some problems. If one fault is absent in the training data or the fault signal is disturbed by severe noise interference, the fault classifier may misjudge the health state. This problem limits the reliability of the fault diagnosis in real applications. In this paper, we enhance the fault diagnosis method by using Bayesian Convolutional Neural Network (BCNN). A Shannon entropy-based method is presented to quantify the prediction uncertainty. The BCNN turns the deterministic predictions to probabilistic distributions and enhances the robustness of the fault diagnosis. The uncertainty quantification method helps to indicate the wrong predictions, detect unknown faults, and discover the strong disturbances. Then, a fine-tuning strategy is applied to enhance the model performance further. The potential usability of the proposed method in monitoring the motors of 3D printers is studied. And the experiment is conducted on a motor bearing dataset provided by Case Western Reserve University. The proposed BCNN achieves 99.82% fault classification accuracy over nine health conditions. Its robustness is verified by comparing the testing accuracy with three other methods on the noisy datasets. And the uncertainty quantification method successfully detects the outlier inputs.","",""
11,"Nacer Eddine Benzebouchi, Nabiha Azizi, A. Ashour, N. Dey, R. Sherratt","Multi-modal classifier fusion with feature cooperation for glaucoma diagnosis",2019,"","","","",182,"2022-07-13 09:24:21","","10.1080/0952813X.2019.1653383","","",,,,,11,3.67,2,5,3,"ABSTRACT Glaucoma is a major public health problem that can lead to an optic nerve lesion, requiring systematic screening in the population over 45 years of age. The diagnosis and classification of this disease have had a marked and excellent development in recent years, particularly in the machine learning domain. Multimodal data have been shown to be a significant aid to the machine learning domain, especially by its contribution to improving data driven decision-making. Solving classification problems by combinations of classifiers has made it possible to increase the robustness as well as the classification reliability by using the complementarity that may exist between the classifiers. Complementarity is considered a key property of multimodality. A Convolutional Neural Network (CNN) works very well in pattern recognition and has been shown to exhibit superior performance, especially for image classification which can learn by themselves useful features from raw data. This article proposes a multimodal classification approach based on deep Convolutional Neural Network and Support Vector Machine (SVM) classifiers using multimodal data and multimodal feature for glaucoma diagnosis from retinal fundus images from RIM-ONE dataset. We make use of handcrafted feature descriptors such as the Gray Level Co-Occurrence Matrix, Central Moments and Hu Moments to co-operate with features automatically generated by the CNN in order to properly detect the optic nerve and consequently obtain a better classification rate, allowing a more reliable diagnosis of glaucoma. The experimental results confirm that the combination of classifiers using a new hybrid fusion approach and the BWWV technique is better than learning classifiers separately. The proposed method provides a computerized diagnosis system for glaucoma disease with impressive results comparing them to the main related studies that allow us to continue in this research path.","",""
0,"S. Bazi, M. Said","Extreme Learning Machines and Particle Swarm Optimization for Induction Motor Faults Detection and Classification",2015,"","","","",183,"2022-07-13 09:24:21","","10.15866/iree.v10i4.7048","","",,,,,0,0.00,0,2,7,"The Induction motors (IM) are the most common electrical machines used in industrial applications due to their versatility and their reliability. Despite their robustness, they are subjected to many types of faults during their lifetime. This could lead to a sudden damage resulting in the shutting down of the whole production line. To this end, fault monitoring and diagnosis is essential for safe operation and production quality. The aim of this paper is twofold; first we propose a pattern recognition approach for fault detection in IM based on the extreme learning machine (ELM) classifier and the discrete wavelet transform (DWT). Then in a second stage, we propose to optimize the performances of this approach using particle swarm optimization (PSO) by automatically: 1) detecting the most suitable mother wavelet and the decomposition level for modeling the fault signatures and 2) estimating the parameters of ELM (i.e., the regularization as well as the width of the Radial basis function [RBF] kernel). For this purpose, the PSO algorithm uses the cross-validation accuracy as a fitness function for guiding the search process. Experimental results on real and simulated stator and rotor faults are reported and discussed.","",""
259,"N. Syed, Huan Liu, K. Sung","Handling concept drifts in incremental learning with support vector machines",1999,"","","","",184,"2022-07-13 09:24:21","","10.1145/312129.312267","","",,,,,259,11.26,86,3,23,"With the increase in the size of real-world databases, there is an ever-increasing need to scale up inductive learning algorithms. Incremental learning techniques are one possible solution to the scalability problem. In this paper, we propose three ctiteria to evaluate the robustness and reliability of incremental learning methods, and use them to study the robustness of an incremental training method for Support Vector Machines. We provide empirical results using benchmark machine learning datasets to show that support vectors form a svccdnct and suficient set for block-by-block incremental learning.","",""
9,"Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, A. Buduru","A Study of Black Box Adversarial Attacks in Computer Vision",2019,"","","","",185,"2022-07-13 09:24:21","","","","",,,,,9,3.00,2,4,3,"Machine learning has seen tremendous advances in the past few years which has lead to deep learning models being deployed in varied applications of day-to-day life. Attacks on such models using perturbations, particularly in real-life scenarios, pose a serious challenge to their applicability, pushing research into the direction which aims to enhance the robustness of these models. After the introduction of these perturbations by Szegedy et al., significant amount of research has focused on the reliability of such models, primarily in two aspects - white-box, where the adversary has access to the targeted model and related parameters; and the black-box, which resembles a real-life scenario with the adversary having almost no knowledge of the model to be attacked. We propose to attract attention on the latter scenario and thus, present a comprehensive comparative study among the different adversarial black-box attack approaches proposed till date. The second half of this literature survey focuses on the defense techniques. This is the first study, to the best of our knowledge, that specifically focuses on the black-box setting to motivate future work on the same.","",""
9,"Xuetong Wu, H. Khorshidi, U. Aickelin, Z. Edib, M. Peate","Imputation techniques on missing values in breast cancer treatment and fertility data",2019,"","","","",186,"2022-07-13 09:24:21","","10.1007/s13755-019-0082-4","","",,,,,9,3.00,2,5,3,"","",""
8,"Tanmoy Bhattacharya, T. Brettin, J. Doroshow, Yvonne A. Evrard, E. Greenspan, A. Gryshuk, T. Hoang, Carolyn B. Lauzon, D. Nissley, Lynne Penberthy, E. Stahlberg, R. Stevens, F. Streitz, G. Tourassi, Fangfang Xia, George F. Zaki","AI Meets Exascale Computing: Advancing Cancer Research With Large-Scale High Performance Computing",2019,"","","","",187,"2022-07-13 09:24:21","","10.3389/fonc.2019.00984","","",,,,,8,2.67,1,16,3,"The application of data science in cancer research has been boosted by major advances in three primary areas: (1) Data: diversity, amount, and availability of biomedical data; (2) Advances in Artificial Intelligence (AI) and Machine Learning (ML) algorithms that enable learning from complex, large-scale data; and (3) Advances in computer architectures allowing unprecedented acceleration of simulation and machine learning algorithms. These advances help build in silico ML models that can provide transformative insights from data including: molecular dynamics simulations, next-generation sequencing, omics, imaging, and unstructured clinical text documents. Unique challenges persist, however, in building ML models related to cancer, including: (1) access, sharing, labeling, and integration of multimodal and multi-institutional data across different cancer types; (2) developing AI models for cancer research capable of scaling on next generation high performance computers; and (3) assessing robustness and reliability in the AI models. In this paper, we review the National Cancer Institute (NCI) -Department of Energy (DOE) collaboration, Joint Design of Advanced Computing Solutions for Cancer (JDACS4C), a multi-institution collaborative effort focused on advancing computing and data technologies to accelerate cancer research on three levels: molecular, cellular, and population. This collaboration integrates various types of generated data, pre-exascale compute resources, and advances in ML models to increase understanding of basic cancer biology, identify promising new treatment options, predict outcomes, and eventually prescribe specialized treatments for patients with cancer.","",""
7,"I. L. Ruiz, M. A. Gómez-Nieto","Building of Robust and Interpretable QSAR Classification Models by Means of the Rivality Index",2019,"","","","",188,"2022-07-13 09:24:21","","10.1021/acs.jcim.9b00264","","",,,,,7,2.33,4,2,3,"An unambiguous algorithm, added to the study of the applicability domain and appropriate measures of the goodness of fit and robustness, represent the key characteristics that should be ideally fulfilled for a QSAR model to be considered for regulatory purposes. In this paper, we propose a new algorithm (RINH) based on the rivality index for the construction of QSAR classification models. This index is capable of predicting the activity of the data set molecules by means of a measurement of the rivality between their nearest neighbors belonging to different classes, contributing with a robust measurement of the reliability of the predictions. In order to demonstrate the goodness of the proposed algorithm we have selected four independent and orthogonally different benchmark data sets (balanced/unbalanced and high/low modelable) and we have compared the results with those obtained using 12 different machine learning algorithms. These results have been validated using 20 data sets of different balancing and sizes, corroborating that the proposed algorithm is able to generate highly accurate classification models and contribute with valuable measurements of the reliability of the predictions and the applicability domain of the built models.","",""
6,"O. Akinsete, Adebayo Oshingbesan","Leak Detection in Natural Gas Pipelines Using Intelligent Models",2019,"","","","",189,"2022-07-13 09:24:21","","10.2118/198738-MS","","",,,,,6,2.00,3,2,3,"  Detection of small leaks in gas pipelines is an important and persistent problem in the oil and gas industry. However, the industry is beginning to investigate how tools of Machine Learning, Artificial Intelligence, Big Data, etc. can be used to improve current industry processes.  This work aims to study the ability of intelligent models to detect small leaks in a natural gas pipeline using operational parameters such as pressure, temperature and flowrate through existing industry performance metrics (sensitivity, reliability, robustness and accuracy). Observer design technique was applied to detect leaks in a gas pipeline using a regresso-classification hierarchical model where an intelligent model acts as a regressor and a leak detection algorithm acts as a classifier. Five intelligent models (Gradient Boosting, Decision Trees, Random Forest, Support Vector Machine and Artificial Neural Network) were used in this present work.  Results showed that the Random Forest and Decision Tree models are the most sensitive as they can detect a leak of 0.1% of nominal flow in about 2 hours. All the intelligent models had high reliability with zero false alarm rate in testing phase. However, due to this level of reliability, the models had low accuracy with the Artificial Neural Network and Support Vector Machine performing best and better regressors than the others. All the intelligent models are robust. The average time to leak detection for different leak sizes for all the intelligent models were compared to a real time transient model in literature. The intelligent models had a time savings of 25% to 48%.  Results in this present work further suggest that intelligent models could be used alongside a real time transient model to improve leak detection. Also, that the tools of big data, data analytics, artificial intelligence can be harnessed to improving leak detection results.","",""
5,"Alvaro H. C. Correia, Cassio P. de Campos","Towards Scalable and Robust Sum-Product Networks",2019,"","","","",190,"2022-07-13 09:24:21","","10.1007/978-3-030-35514-2_31","","",,,,,5,1.67,3,2,3,"","",""
3,"Pranesh Santikellur, Lakshya, Shashi Prakash, R. Chakraborty","A Computationally Efficient Tensor Regression Network based Modeling Attack on XOR APUF",2019,"","","","",191,"2022-07-13 09:24:21","","10.1109/AsianHOST47458.2019.9006692","","",,,,,3,1.00,1,4,3,"XOR-arbiter PUF (XOR APUF), where the outputs of multiple APUFs are XOR-ed, has proven to be robust to machine learning based modeling attacks. The reported successful modeling attacks for XOR APUF either employ auxiliary side-channel or reliability information, or require enormous computational effort. This robustness is primarily due to the difficulty in learning the unknown internal delay parameter terms in the mathematical model of a XOR APUF, and the robustness increases as the number of APUFs being XOR-ed increases. In this paper, we employ a novel machine learning based modeling technique called efficient CANDECOMP/PARAFAC-Tensor Regression Network (CP-TRN), a variant of CP-decomposition based tensor regression network, to reduce the computational resource requirement of model building attacks on XOR APUF. In addition, our proposed technique does not require any auxiliary information, and is robust to noisy training data. The proposed technique allowed us to successfully model 64-bit 8-XOR APUF and 128-bit 7-XOR APUF on a single desktop workstation, with high prediction accuracy.","",""
3,"Xiaoying Qiu, Ting Jiang, Sheng Wu, Chunxiao Jiang, Haipeng Yao, M. Hayes, A. Benslimane","Wireless User Authentication Based on KLT and Gaussian Mixture Model",2019,"","","","",192,"2022-07-13 09:24:21","","10.1109/WCNC.2019.8885922","","",,,,,3,1.00,0,7,3,"Physical (PHY)-layer security has received considerable interest as a way to safeguard data confidentiality and achieve security and privacy in wireless networks. Authentication between two devices is a challenging problem. In this paper, a machine learning algorithm is proposed to detect and identify rogue transmitters relying on a low-dimensional channel feature vector that is obtained by the Karhunen-Loeve transform (KLT). Specifically, a Linde-Buzo-Gray algorithm is designed for improving the reliability and robustness of the proposed scheme, where a Gaussian Mixture Model (GMM) is employed to learn and track the changes of physical layer properties. Simulation results demonstrate that the proposed authentication scheme achieves a higher spoofing detection rate compared to other existing methods.","",""
18,"F. Lotte, C. Jeunet, J. Mladenović, B. N'Kaoua, L. Pillette","A BCI challenge for the signal processing community: considering the user in the loop",2018,"","","","",193,"2022-07-13 09:24:21","","10.1049/PBCE114E_CH8","","",,,,,18,4.50,4,5,4,"Electroencephalography (EEG)-based brain-computer interfaces (BCIs) have proven promising for a wide range of applications, from communication and control for motor impaired users to gaming targeted at the general public, real-time mental state monitoring and stroke rehabilitation, to name a few. Despite this promising potential, BCIs are still scarcely used outside laboratories for practical applications. The main reason preventing EEG-based BCIs from being widely used is arguably their poor usability, which is notably due to their low robustness and reliability. To operate a BCI, the user has to encode commands in his/her EEG signals, typically using mental imagery tasks, such as imagining hand movement or mental calculation. The execution of these tasks leads to specific EEG patterns, which the machine has to decode by using signal processing and machine learning. So far, to address the reliability issue of BCI, most research efforts have been focused on command decoding only. However, if the user is unable to encode commands in her EEG patterns, no signal-processing algorithm would be able to decode them. Therefore, we argue in this chapter that BCI design is not only a decoding challenge (i.e., translating EEG signals into control commands) but also a human-computer interaction challenge, which aims at ensuring the user can control the BCI. Interestingly enough, there are a number of open challenges to take the user into account, for which signal-processing and machine-learning methods could provide solutions. These challenges notably concerns (1) the modeling of the user and (2) understanding and improving how and what the user is learning. More precisely, the BCI community should first work on user modeling, i.e., modeling and updating the user's states and skills overtime from his/herEEG signals, behavior, BCI performances and possibly other sensors. The community should also identify new performance metrics-beyond classification accuracy-that could better describe users' skills at BCI control. Second, the BCI community has to understand how and what the user learns to control the BCI. This includes thoroughly identifying the features to be extracted and the classifier to be used to ensure the user's understanding of the feedback resulting from them, as well as how to present this feedback. Being able to update machine-learning parameters in a specific manner and a precise moment to favor learning without confusing the user with the ever-changeable feedback is another challenge. Finally, it is necessary to gain a clearer understanding of the reasons why mental commands are sometimes correctly decoded and sometimes not; what makes people sometimes fail at BCI control, in order to be able to guide them to do better. Overall, this chapter identifies a number of open and important challenges for the BCI community, at the user level, to which experts in machine learning and signal processing could contribute.","",""
124,"P. Somol, J. Novovicová","Evaluating Stability and Comparing Output of Feature Selectors that Optimize Feature Subset Cardinality",2010,"","","","",194,"2022-07-13 09:24:21","","10.1109/TPAMI.2010.34","","",,,,,124,10.33,62,2,12,"Stability (robustness) of feature selection methods is a topic of recent interest, yet often neglected importance, with direct impact on the reliability of machine learning systems. We investigate the problem of evaluating the stability of feature selection processes yielding subsets of varying size. We introduce several novel feature selection stability measures and adjust some existing measures in a unifying framework that offers broad insight into the stability problem. We study in detail the properties of considered measures and demonstrate on various examples what information about the feature selection process can be gained. We also introduce an alternative approach to feature selection evaluation in the form of measures that enable comparing the similarity of two feature selection processes. These measures enable comparing, e.g., the output of two feature selection methods or two runs of one method with different parameters. The information obtained using the considered stability and similarity measures is shown to be usable for assessing feature selection methods (or criteria) as such.","",""
0,"","Smart Classifiers Based Classification and Condition Monitoring of Induction Motor Faults",2019,"","","","",195,"2022-07-13 09:24:21","","10.35940/ijitee.l2887.1081219","","",,,,,0,0.00,0,0,3,"With the advancements in the field of automation in the industries the use of machines is very high and if the machine which require some rotatory action for the load, the Induction motor comes in to play because of the advantages such as robustness, low maintenance, low cost etc. But with the increase in the dependency over the motors it becomes highly recommended to have machines with reliability because break in the work can lead to huge amount of loss. In order to increase the reliability of the motors predictive maintenance comes into play which requires fault classification or detection which is easily and accurately possible using the Machine Learning algorithms. With the requirements of the present scenario for predictive maintenance, this paper presents the fault classification of induction motor using Support Vector Machine SVM) and K- Nearest Neighbour (KNN) technique of classification. Here in this paper the bearing fault (BF) and broken rotor bar (BRB) fault is considered. The results collected are on the basis of validation and Principle Component Analysis (PCA) technique. And it is found that the SVM technique is better than the KNN for fault classification of Induction motor.","",""
24,"Nan Tian, Matthew Matl, Jeffrey Mahler, Y. Zhou, Sam Staszak, Christopher Correa, Steven Zheng, Qiang Li, Robert Zhang, Ken Goldberg","A cloud robot system using the dexterity network and berkeley robotics and automation as a service (Brass)",2017,"","","","",196,"2022-07-13 09:24:21","","10.1109/ICRA.2017.7989192","","",,,,,24,4.80,2,10,5,"In support of Cloud Robotics, Robotics and Automation as a Service (RAaaS) frameworks have the potential to reduce the complexity of software development, simplify software installation and maintenance, and facilitate data sharing for machine learning. In this proof-of-concept paper, we describe Berkeley Robotics and Automation as a Service (Brass), a RAaaS prototype that allows robots to access a remote server that hosts a robust grasp-planning system (Dex-Net 1.0) that maintains data on hundreds of candidate grasps on thousands of 3D object meshes and uses perturbation sampling to estimate and update a stochastic robustness metric for each grasp. Results suggest that such a system can increase grasp reliability over naive locally-computed grasping strategies with network latencies of 30 and 200 msec for servers 500 and 6000 miles away, respectively. We also study how the system can use execution reports from robots in the field to update grasp recommendations over time.","",""
2,"Ines Garcia, Fernando Gonçalves, T. Ribeiro, P. Fernandes, Cesar Rocha, Ricardo Boucinha, G. Lopes, A. F. Ribeiro","Autonomous 4DOF Robotic Manipulator Prototype for Industrial Environment and Human Cooperation",2019,"","","","",197,"2022-07-13 09:24:21","","10.1109/ICARSC.2019.8733639","","",,,,,2,0.67,0,8,3,"This paper describes the design and development of an autonomous robotic manipulator with four degrees of freedom. The manipulator is named RACHIE - “Robotic Arm for Collaboration with Humans in Industrial Environment”. The idea was to create a smaller version of the industrial manipulators available on the market. The mechanical and electronic components are presented as well as the software algorithms implemented on the robot. The manipulator has as its primary goal the detection and organization of cans by color and defects. The robot can detect a human operator so it can deliver defective cans by collaborating with him/her on an industrial environment. To be able to perform such task, the robot has implemented a machine learning algorithm, a Haar feature-based cascade classifier, on its vision system to detect cans and humans. On the handler motion, direct and inverse kinematics were calculated and implemented, and its equations are described in this paper. This robot presents high reliability and robustness in the task assigned. It is low-cost as it is a small version of commercial ones, making it optimized for smaller tasks.","",""
1,"Maximilian Pöpperl, Raghavendra Gulagundi, S. Yogamani, Stefan Milz","Realistic Ultrasonic Environment Simulation Using Conditional Generative Adversarial Networks",2019,"","","","",198,"2022-07-13 09:24:21","","10.1109/IVS.2019.8814091","","",,,,,1,0.33,0,4,3,"Generative Adversarial Networks (GANs) have achieved outstanding results in generation of realistic data, particularly for image data. Autonomous driving systems are equipped with a large suite of sensors to obtain robustness and redundancy. Ultrasonic sensors are commonly used because of their low-cost and reliability of near-field distance estimation. However, machine learning algorithms are not commonly used for ultrasonic data, as it requires extensive datasets whose creation is time-consuming, expensive and inflexible to hardware and environmental changes. On the other hand, there exists no method to simulate these signals deterministically. Thus, we present a novel approach for synthetic ultrasonic signal simulation using conditional GANs (cGANs). To the best of our knowledge, we present the first realistic data augmentation for automotive ultrasonics sensors. The performance of cGANs allows us to bring the environment simulation to a high quality close to realistic data. By using our setup and environmental parameters as condition, the proposed approach is flexible to external influences. Due to its low complexity and smaller time effort needed for data generation, the proposed method outperforms other simulation algorithms such as finite element method. We verify the outstanding accuracy and realism of our method by applying a detailed statistical analysis and comparing the generated data to an extensive amount of measured signals.","",""
26,"Yi Tang, Feng Li, Qi Wang, Yan Xu","Hybrid method for power system transient stability prediction based on two-stage computing resources",2017,"","","","",199,"2022-07-13 09:24:21","","10.1049/IET-GTD.2017.1168","","",,,,,26,5.20,7,4,5,"Accurate and prompt transient stability prediction is one of the effective ways to reduce the risk of blackout or cascading failures. In an effort to achieve improvements in time efficiency and prediction accuracy, a new transient stability prediction method combining trajectory fitting (TF) and extreme learning machine (ELM) based on two-stage process, named hybrid method, is proposed here. ELM-based method is implemented in central station to ensure the time efficiency, while TF-based method is adopted in local station to guarantee the accuracy. Furthermore, data corruption is taken into consideration to assure the robustness of the proposed algorithm. The hybrid method is validated with the New England 39-bus test system and the simulation results indicate its effectiveness and reliability.","",""
10,"Yuhang Li, Shi Ying, Xiangyang Jia, Yisen Xu, Lily Zhao, Guoli Cheng, Bingming Wang, J. Xuan","EH-Recommender: Recommending Exception Handling Strategies Based on Program Context",2018,"","","","",200,"2022-07-13 09:24:21","","10.1109/ICECCS2018.2018.00019","","",,,,,10,2.50,1,8,4,"Exception handling is widely used in software development to guarantee code robustness and system reliability. Developers are expected to choose appropriate handling strategies to ensure exceptions are handled properly without causing program crashes or unintended behaviors. However, making such choices is challenging especially for the novices due to lack of experience on exceptional flow design. To assist developers in deciding how to handle exceptions, we propose a method to automatically recommend exception handling strategies based on program context. This method learns practices of exception handling from existing high-quality projects and code by well-skilled developers. We extracted three type of program context (exceptional context, architectural context, and functional context) as features and applied machine learning techniques to recommend an optimized strategy of exception handling. We conducted the evaluation on 10 open source Java projects. Experimental results show that our approach reaches high prediction accuracy in choosing exception handling strategies.","",""
