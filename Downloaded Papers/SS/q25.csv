Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
5,"U. Gadiraju, Jie Yang","What Can Crowd Computing Do for the Next Generation of AI Systems?",2020,"","","","",1,"2022-07-13 09:22:08","","","","",,,,,5,2.50,3,2,2,"The unprecedented rise in the adoption of artificial intelligence techniques and automation in many contexts is concomitant with shortcomings of such technology with respect to robustness, interpretability, usability, and trustworthiness. Crowd computing offers a viable means to leverage human intelligence at scale for data creation, enrichment, and interpretation, demonstrating a great potential to improve the performance of AI systems and increase the adoption of AI in general. Existing research and practice has mainly focused on leveraging crowd computing for training data creation. However, this perspective is rather limiting in terms of how AI can fully benefit from crowd computing. In this vision paper, we identify opportunities in crowd computing to propel better AI technology, and argue that to make such progress, fundamental problems need to be tackled from both computation and interaction standpoints. We discuss important research questions in both these themes, with an aim to shed light on the research needed to pave a future where humans and AI can work together seamlessly, while benefiting from each other.","",""
3,"Dorsa Ziaei, Weizhe Li, Samuel Lam, W. Cheng, Weijie Chen","Characterization of color normalization methods in digital pathology whole slide images",2020,"","","","",2,"2022-07-13 09:22:08","","10.1117/12.2550585","","",,,,,3,1.50,1,5,2,"The color rendering of whole-slide images (WSIs) depends on factors involving the sample, such as tissue type, preparation methods, staining type and staining protocol, as well as equipment, such as the WSI scanner, WSI viewer, and WSI display. Variations in any of these steps may change the color rendering and therefore affect the performance of pathologists in the interpretation of WSIs and the robustness of artificial intelligence algorithms. In the literature, color normalization techniques have been proposed to reduce the color variations. The purpose of this work is to develop an objective approach to characterizing color normalization methods used in digital pathology. We employed color normalization methods to normalize the color rendered by a WSI scanner and then compared the normalized color with the actual scan by that scanner. The normalization errors were evaluated on the pixel level using the CIE color difference ΔE metric that have been shown to correlate with visually perceived differences in human vision. A selected set of 310 patch images of breast tissues scanned by two scanners from the ICPR 2014 MITOS & ATYPIA contest was used. Images from one scanner were color normalized to match the color rendering of the other scanner. Four color normalization methods were compared – Macenko, Reinhard, Vahadane, and StainGAN. Experimental results show that average color differences between two scanners in terms of ΔE were reduced from 16.2 before normalization to the range of [13.7,16.9] after normalization for the Macenko, Reinhard, Vahadane methods, and to 8.3 for the StainGAN method. Apparently the StainGAN method is significantly superior to the other three methods in terms of the ΔE metric. As such, we demonstrated a quantitative method for objectively evaluating color normalization techniques. Future work is needed to explore the relationship of the color fidelity measure and the impact of color normalization on pathologist and AI performance in clinical tasks.","",""
0,"F. D. Libera","Humanoid robot motion creation based on touch interpretation: A new programming paradigm",2011,"","","","",3,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,1,11,"Generating motions for humanoid robots is to this day a very challenging problem. These robots often features a high number of degrees of freedom, 20 or more, even for small-sized ones. This strongly limits the applicability of classical artificial intelligence approaches, and requires the design of specialized solutions.    Some specific tasks, like locomotion or grasping, have been deeply studied, and important concepts like the Zero Moment Point (ZMP) for stable walking or the Grasping Shape Primitives were introduced. Previous relevant work also explored planning strategies for these two important tasks and ongoing research keeps improving the algorithms in terms of speed, robustness and applicability.    When dealing with more generic tasks, a demonstration from a human can be used to derive an initial movement, which is then often optimized by the robot itself. In particular, one of the most common approaches is to directly acquire the movement of a human performer and adapt it to the robot. Ideally, this technique can yield very natural looking motions. This is a strong advantage, since human likeness of motions is very important for communication between human and robots, but no general mathematical formulation has been provided to date.    The retargeting of human motions to robot motions presents indeed several inconveniences. First of all, the instrumentation for acquiring motion data is expensive, requires a careful setup and may not be accessible to most of the users. Second, a human actor who is able to perform the desired movement may not be available. Finally, the differences in the shape, degrees of freedom, power and weight distribution between humans and robots may require an intensive modification of the human motion in order to adapt it to the robot. During this adaptation process, the quality of movement appearance can end up to be significantly reduced.    An alternative approach that does not suffer from these issues is the direct physical interaction between the robot and a human teacher. In a typical setup the instructor moves the humanoid's limbs, showing the robot how the task needs to be accomplished. The idea behind this technique, called ``kinesthetic demonstration'', actually appeared very early in robotics. Although under different names like ``teach-in'', ``guiding'', ``play back'', ``direct teaching'' or ``walk-through programming'', it constitutes one of the most effective methodologies for programming industrial robot arms.    When teaching a robot using this technique the joints are usually let free to move. This approach has the disadvantage that the joints move  under the force of gravity, so some setups include gravity compensation or workarounds to make the joints passive only when the teacher touches the robot. Apart from applying forces that compensate for gravity, when kinesthetic demonstration is used the robot usually just responds passively to the forces applied.    In order to ease the teaching process, this thesis proposes a new paradigm, termed ``teaching by touching''. This approach consists in having the robot interpret the meaning of the tactile instructions it receives and move based on its own understanding of the user's will, instead of limiting its behavior to a mere passive movement.    For instance, if the robot is  squatting, and the user pushes the sensors on both sides of the robot, the robot will guess that the user wants it to stand up and will apply by itself forces on its knees. Using the classical approach, instead, the robot would not move when touched on both sides, and would require the user to actually lift up the robot's body.    In other terms, the proposed methodology changes the way of interacting between humans and robots: with the classical, kinesthetic demonstration approach, the robot moves passively under the user forces like a puppet, while within the teaching by touching approach, touch is considered a way of communication between humans and robots that allows the robot to take an active role in the teaching process.    Among the many ways of communication between humans, touch is actually one of the least studied but  most powerful. Touch is often used by instructors in sport or dance classes to adjust the student's posture in a very intuitive way. Tactile instructions thus appear to be a very appealing modality for developing humanoid robot motions as well.     Interpretation of tactile instructions spontaneously given by human teachers reveals to be a complex task for artificial systems.  In fact, the way users employ touch to communicate their intention is still completely unexplored even in the interaction between humans, and models are not available. This thesis reports the first results obtained in the realization of a system for robot motion creation based on tactile interaction.    In particular, it will be shown that the meaning of tactile instructions is both context dependent and user dependent. An example of context dependence of tactile instructions can be readily provided. If a user presses the upper part of the leg when the robot is standing he or she could imply that the robot should bend the leg backwards. However, when the robot is squatting, the same touch on the leg could mean that the robot should bend its knees further.    In regard to user dependence, experiments showed that when asked to interact freely with the robot, different people tend to give different meaning to similar tactile instructions. In detail, preliminary results seem to suggest that the differences in the way of teaching could be partially explained by the diverse abstraction level at which teachers provide their instructions. For instance, some subjects decided to use a nearly direct mapping from a small set of sensors to the joints. Other users adopted a mapping between sensors and joints that appears to be derived from physical considerations. Expressly, the relationship between the pressed part and the way the robot should move according to the user can be estimated by imagining each joint to have a spring inside and to move according to the applied force. Finally, other people employed a mapping between a single touch and a complete movement. Using this approach, for instance, a step with one leg is symbolized by a tap on the knee of that leg.    The experiments were conducted initially with simulated touch sensors. A technique that permits the interaction with virtual sensors displayed on a touch screen while making the real robot execute the motion will be introduced. The strongest advantage of this setup is that it allows applying teaching by touching even to cheap humanoids on the market that are usually lacking tactile sensors.    A second set of experiments was then conducted with M3-Neony, a new humanoid robot equipped with touch sensors over the whole body, that will be shortly introduced. Data analysis confirmed the complexity of the mapping between touch instructions and the movement to be executed. On the other hand, it will be shown that experimental data suggest that the way in which the robot should respond to touch instructions can be described by using a low-dimensional subspace of the complete joint space.    Interestingly, this subspace seems to be highly correlated to the subspace where the motion being developed lies. This fact suggests that the postures assumed by the robot during the movement could be used to improve the interpretation of tactile instructions.    The final part of the thesis will briefly deal with very simple techniques used to improve the robustness of the motions taught to the robot. In detail, two approaches that use sensory information to automatically make small modification to the movement during its execution will be introduced. The first, graph based one, simply tries to make the robot return to a known state as soon as possible when a perturbation brings the robot state far from the expected one. The second approach, inspired from the chemotaxis of bacteria like Escherichia Coli, works by the addition of random noise of intensity that depends on whether the robot state evolves as expected or not.","",""
19,"I. Levner, V. Bulitko, Lihong Li, Greg Lee, R. Greiner","Towards Automated Creation of Image Interpretation Systems",2003,"","","","",4,"2022-07-13 09:22:08","","10.1007/978-3-540-24581-0_56","","",,,,,19,1.00,4,5,19,"","",""
1,"Nikita Mokhashi, Julia Grachevskaya, Lorrie Cheng, Daohai Yu, Xiaoning Lu, Yi Zhang, J. Henderer","A Comparison of Artificial Intelligence and Human Diabetic Retinal Image Interpretation in an Urban Health System",2021,"","","","",5,"2022-07-13 09:22:08","","10.1177/1932296821999370","","",,,,,1,1.00,0,7,1,"Introduction: Artificial intelligence (AI) diabetic retinopathy (DR) software has the potential to decrease time spent by clinicians on image interpretation and expand the scope of DR screening. We performed a retrospective review to compare Eyenuk’s EyeArt software (Woodland Hills, CA) to Temple Ophthalmology optometry grading using the International Classification of Diabetic Retinopathy scale. Methods: Two hundred and sixty consecutive diabetic patients from the Temple Faculty Practice Internal Medicine clinic underwent 2-field retinal imaging. Classifications of the images by the software and optometrist were analyzed using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and McNemar’s test. Ungradable images were analyzed to identify relationships with HbA1c, age, and ethnicity. Disagreements and a sample of 20% of agreements were adjudicated by a retina specialist. Results: On patient level comparison, sensitivity for the software was 100%, while specificity was 77.78%. PPV was 19.15%, and NPV was 100%. The 38 disagreements between software and optometrist occurred when the optometrist classified a patient’s images as non-referable while the software classified them as referable. Of these disagreements, a retina specialist agreed with the optometrist 57.9% the time (22/38). Of the agreements, the retina specialist agreed with both the program and the optometrist 96.7% of the time (28/29). There was a significant difference in numbers of ungradable photos in older patients (≥60) vs younger patients (<60) (p=0.003). Conclusions: The AI program showed high sensitivity with acceptable specificity for a screening algorithm. The high NPV indicates that the software is unlikely to miss DR but may refer patients unnecessarily.","",""
1793,"E. Topol","High-performance medicine: the convergence of human and artificial intelligence",2019,"","","","",6,"2022-07-13 09:22:08","","10.1038/s41591-018-0300-7","","",,,,,1793,597.67,1793,1,3,"","",""
3,"Fatemeh Homayounieh, S. Digumarthy, S. Ebrahimian, J. Rueckel, B. Hoppe, B. Sabel, Sailesh Conjeti, Karsten Ridder, Markus Sistermanns, Lei Wang, Alexander Preuhs, Florin C. Ghesu, Awais Mansoor, M. Moghbel, Ariel Botwin, Ramandeep Singh, Samuel Cartmell, J. Patti, Christian Huemmer, A. Fieselmann, Clemens Joerger, Negar Mirshahzadeh, V. Muse, M. Kalra","An Artificial Intelligence–Based Chest X-ray Model on Human Nodule Detection Accuracy From a Multicenter Study",2021,"","","","",7,"2022-07-13 09:22:08","","10.1001/jamanetworkopen.2021.41096","","",,,,,3,3.00,0,24,1,"Key Points Question Can artificial intelligence (AI) improve detection of pulmonary nodules on chest radiographs at different levels of detection difficulty? Findings In this diagnostic study, AI-aided interpretation was associated with significantly improved detection of pulmonary nodules on chest x-rays as compared with unaided interpretation of chest x-rays. Meaning These results suggest that an AI algorithm may improve diagnostic performance of radiologists with different levels of experience for detecting pulmonary nodules on chest radiographs compared with unaided interpretation.","",""
2,"E. Veitch, O. Alsos","Human-Centered Explainable Artificial Intelligence for Marine Autonomous Surface Vehicles",2021,"","","","",8,"2022-07-13 09:22:08","","10.3390/jmse9111227","","",,,,,2,2.00,1,2,1,"Explainable Artificial Intelligence (XAI) for Autonomous Surface Vehicles (ASVs) addresses developers’ needs for model interpretation, understandability, and trust. As ASVs approach wide-scale deployment, these needs are expanded to include end user interactions in real-world contexts. Despite recent successes of technology-centered XAI for enhancing the explainability of AI techniques to expert users, these approaches do not necessarily carry over to non-expert end users. Passengers, other vessels, and remote operators will have XAI needs distinct from those of expert users targeted in a traditional technology-centered approach. We formulate a concept called ‘human-centered XAI’ to address emerging end user interaction needs for ASVs. To structure the concept, we adopt a model-based reasoning method for concept formation consisting of three processes: analogy, visualization, and mental simulation, drawing from examples of recent ASV research at the Norwegian University of Science and Technology (NTNU). The examples show how current research activities point to novel ways of addressing XAI needs for distinct end user interactions and underpin the human-centered XAI approach. Findings show how representations of (1) usability, (2) trust, and (3) safety make up the main processes in human-centered XAI. The contribution is the formation of human-centered XAI to help advance the research community’s efforts to expand the agenda of interpretability, understandability, and trust to include end user ASV interactions.","",""
0,"Roberto Rodriguez, R. Perroy, J. Leary, D. Jenkins, Max Panoff, Travis Mandel, Patricia Perez","Comparing Interpretation of High-Resolution Aerial Imagery by Humans and Artificial Intelligence to Detect an Invasive Tree Species",2021,"","","","",9,"2022-07-13 09:22:08","","10.3390/rs13173503","","",,,,,0,0.00,0,7,1,"Timely, accurate maps of invasive plant species are critical for making appropriate management decisions to eliminate emerging target populations or contain infestations. High-resolution aerial imagery is routinely used to map, monitor, and detect invasive plant populations. While conventional image interpretation involving human analysts is straightforward, it can require high demands for time and resources to produce useful intelligence. We compared the performance of human analysts with a custom Retinanet-based deep convolutional neural network (DNN) for detecting individual miconia (Miconia calvescens DC) plants, using high-resolution unmanned aerial system (UAS) imagery collected over lowland tropical forests in Hawai’i. Human analysts (n = 38) examined imagery at three linear scrolling speeds (100, 200 and 300 px/s), achieving miconia detection recalls of 74 ± 3%, 60 ± 3%, and 50 ± 3%, respectively. The DNN achieved 83 ± 3% recall and completed the image analysis in 1% of the time of the fastest scrolling speed tested. Human analysts could discriminate large miconia leaf clusters better than isolated individual leaves, while the DNN detection efficacy was independent of leaf cluster size. Optically, the contrast in the red and green color channels and all three (i.e., red, green, and blue) signal to clutter ratios (SCR) were significant factors for human detection, while only the red channel contrast, and the red and green SCRs were significant factors for the DNN. A linear cost analysis estimated the operational use of a DNN to be more cost effective than human photo interpretation when the cumulative search area exceeds a minimum area. For invasive species like miconia, which can stochastically spread propagules across thousands of ha, the DNN provides a more efficient option for detecting incipient, immature miconia across large expanses of forested canopy. Increasing operational capacity for large-scale surveillance with a DNN-based image analysis workflow can provide more rapid comprehension of invasive plant abundance and distribution in forested watersheds and may become strategically vital to containing these invasions.","",""
2,"S. Rahman, Oly Katari, D. Pawde, Gopi Sumanth Bhaskar Boddeda, A. Goswami, S. Mutheneni, T. Shunmugaperumal","Application of Design of Experiments® Approach-Driven Artificial Intelligence and Machine Learning for Systematic Optimization of Reverse Phase High Performance Liquid Chromatography Method to Analyze Simultaneously Two Drugs (Cyclosporin A and Etodolac) in Solution, Human Plasma, Nanocapsules, and ",2021,"","","","",10,"2022-07-13 09:22:08","","10.1208/s12249-021-02026-6","","",,,,,2,2.00,0,7,1,"The objectives of current investigation are (1) to find out wavelength of maximum absorbance (λmax) for combined cyclosporin A and etodolac solution followed by selection of mobile phase suitable for the RP-HPLC method, (2) to define analytical target profile and critical analytical attributes (CAAs) for the analytical quality by design, (3) to screen critical method parameters with the help of full factorial design followed by optimization with face-centered central composite design (CCD) approach-driven artificial neural network (ANN)-linked with the Levenberg-Marquardt (LM) algorithm for finding the RP-HPLC conditions, (4) to perform validation of analytical procedures (trueness, linearity, precision, robustness, specificity and sensitivity) using combined drug solution, and (5) to determine drug entrapment efficiency value in dual drug-loaded nanocapsules/emulsions, percentage recovery value in human plasma spiked with two drugs and solution state stability analysis at different stress conditions for substantiating the double-stage systematically optimized RP-HPLC method conditions. Through isobestic point and scouting step, 205 nm and ACN:H2O mixture (74:26) were selected respectively as the λmax and mobile phase. The ANN topology (3:10:4) indicating the input, hidden and output layers were generated by taking the 20 trials produced from the face-centered CCD model. The ANN-linked LM model produced minimal differences between predicted and observed values of output parameters (or CAAs), low mean squared error and higher correlation coefficient values in comparison to the respective values produced by face-centered CCD model. The optimized RP-HPLC method could be applied to analyze two drugs concurrently in different formulations, human plasma and solution state stability checking.","",""
179,"S. Michie, James Thomas, M. Johnston, Pol Mac Aonghusa, J. Shawe-Taylor, M. Kelly, L. Deleris, Ailbhe N. Finnerty, M. Marques, E. Norris, A. O'Mara-Eves, R. West","The Human Behaviour-Change Project: harnessing the power of artificial intelligence and machine learning for evidence synthesis and interpretation",2017,"","","","",11,"2022-07-13 09:22:08","","10.1186/s13012-017-0641-5","","",,,,,179,35.80,18,12,5,"","",""
56,"Konstantinos C. Siontis, P. Noseworthy, Z. Attia, P. Friedman","Artificial intelligence-enhanced electrocardiography in cardiovascular disease management",2021,"","","","",12,"2022-07-13 09:22:08","","10.1038/s41569-020-00503-2","","",,,,,56,56.00,14,4,1,"","",""
2,"Avishek Choudhury, Onur Asan","Human factors: bridging artificial intelligence and patient safety",2020,"","","","",13,"2022-07-13 09:22:08","","10.1177/2327857920091007","","",,,,,2,1.00,1,2,2,"The recent launch of complex artificial intelligence (AI) in the domain of healthcare has embedded perplexities within patients, clinicians, and policymakers. The opaque and complex nature of artificial intelligence makes it challenging for clinicians to interpret its outcome. Incorrect interpretation and poor utilization of AI might hamper patient safety. The principles of human factors and ergonomics (HFE) can assist in simplifying AI design and consecutively optimize human performance ensuring better understanding of AI outcome, their interaction with the clinical workflow. In this paper, we discuss the interactions of providers with AI and how HFE can influence these interacting components to patient safety.","",""
1,"Bráulio Nascimento Lima, Pietro Balducci, Ricardo Pablo Passos, C. Novelli, Carlos Henrique Prevital Fileni, Fábio Vieira, L. B. Camargo, Guanis de Barros Vilela Junior","Artificial intelligence based on fuzzy logic for the analysis of human movement in healthy people: a systematic review",2020,"","","","",14,"2022-07-13 09:22:08","","10.1007/s10462-020-09885-8","","",,,,,1,0.50,0,8,2,"","",""
195,"Jessica Fjeld, Nele Achten, Hannah Hilligoss, Ádám Nagy, Madhulika Srikumar","Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI",2020,"","","","",15,"2022-07-13 09:22:08","","10.2139/ssrn.3518482","","",,,,,195,97.50,39,5,2,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.    To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.","",""
10,"Da-Wei Chang, Chin Lin, T. Tsao, Chia-Cheng Lee, Jiann-Torng Chen, Chien-Sung Tsai, Wei-Shiang Lin, Chin Lin","Detecting Digoxin Toxicity by Artificial Intelligence-Assisted Electrocardiography",2021,"","","","",16,"2022-07-13 09:22:08","","10.3390/ijerph18073839","","",,,,,10,10.00,1,8,1,"Although digoxin is important in heart rate control, the utilization of digoxin is declining due to its narrow therapeutic window. Misdiagnosis or delayed diagnosis of digoxin toxicity is common due to the lack of awareness and the time-consuming laboratory work that is involved. Electrocardiography (ECG) may be able to detect potential digoxin toxicity based on characteristic presentations. Our study attempted to develop a deep learning model to detect digoxin toxicity based on ECG manifestations. This study included 61 ECGs from patients with digoxin toxicity and 177,066 ECGs from patients in the emergency room from November 2011 to February 2019. The deep learning algorithm was trained using approximately 80% of ECGs. The other 20% of ECGs were used to validate the performance of the Artificial Intelligence (AI) system and to conduct a human-machine competition. Area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were used to evaluate the performance of ECG interpretation between humans and our deep learning system. The AUCs of our deep learning system for identifying digoxin toxicity were 0.912 and 0.929 in the validation cohort and the human-machine competition, respectively, which reached 84.6% of sensitivity and 94.6% of specificity. Interestingly, the deep learning system using only lead I (AUC = 0.960) was not worse than using complete 12 leads (0.912). Stratified analysis showed that our deep learning system was more applicable to patients with heart failure (HF) and without atrial fibrillation (AF) than those without HF and with AF. Our ECG-based deep learning system provides a high-accuracy, economical, rapid, and accessible way to detect digoxin toxicity, which can be applied as a promising decision supportive system for diagnosing digoxin toxicity in clinical practice.","",""
148,"Jos'e Jim'enez-Luna, F. Grisoni, G. Schneider","Drug discovery with explainable artificial intelligence",2020,"","","","",17,"2022-07-13 09:22:08","","10.1038/s42256-020-00236-4","","",,,,,148,74.00,49,3,2,"","",""
4,"Anshuman Darbari, K. Kumar, Shubhankar Darbari, Prashant L. Patil","Requirement of artificial intelligence technology awareness for thoracic surgeons",2021,"","","","",18,"2022-07-13 09:22:08","","10.1186/s43057-021-00053-4","","",,,,,4,4.00,1,4,1,"","",""
28,"J. Balayla, Guy Shrem","Use of artificial intelligence (AI) in the interpretation of intrapartum fetal heart rate (FHR) tracings: a systematic review and meta-analysis",2019,"","","","",19,"2022-07-13 09:22:08","","10.1007/s00404-019-05151-7","","",,,,,28,9.33,14,2,3,"","",""
5,"M. E. Laino, Angela Ammirabile, A. Posa, Pierandrea Cancian, Sherif Shalaby, V. Savevski, E. Neri","The Applications of Artificial Intelligence in Chest Imaging of COVID-19 Patients: A Literature Review",2021,"","","","",20,"2022-07-13 09:22:08","","10.3390/diagnostics11081317","","",,,,,5,5.00,1,7,1,"Diagnostic imaging is regarded as fundamental in the clinical work-up of patients with a suspected or confirmed COVID-19 infection. Recent progress has been made in diagnostic imaging with the integration of artificial intelligence (AI) and machine learning (ML) algorisms leading to an increase in the accuracy of exam interpretation and to the extraction of prognostic information useful in the decision-making process. Considering the ever expanding imaging data generated amid this pandemic, COVID-19 has catalyzed the rapid expansion in the application of AI to combat disease. In this context, many recent studies have explored the role of AI in each of the presumed applications for COVID-19 infection chest imaging, suggesting that implementing AI applications for chest imaging can be a great asset for fast and precise disease screening, identification and characterization. However, various biases should be overcome in the development of further ML-based algorithms to give them sufficient robustness and reproducibility for their integration into clinical practice. As a result, in this literature review, we will focus on the application of AI in chest imaging, in particular, deep learning, radiomics and advanced imaging as quantitative CT.","",""
10,"Miao Chu, H. Jia, J. Gutiérrez-Chico, A. Maehara, Z. Ali, Xiaoling Zeng, L. He, Chen Zhao, M. Matsumura, Peng Wu, M. Zeng, T. Kubo, Bo Xu, Lianglong Chen, Bo Yu, G. Mintz, W. Wijns, N. Holm, S. Tu","Automatic Characterisation of Human Atherosclerotic Plaque Composition from Intravascular Optical Coherence Tomography Using Artificial Intelligence.",2021,"","","","",21,"2022-07-13 09:22:08","","10.4244/EIJ-D-20-01355","","",,,,,10,10.00,1,19,1,"BACKGROUND Intravascular optical coherence tomography (IVOCT) enables detailed plaque characterisation in-vivo, but visual assessment is time-consuming and subjective.   AIMS This study aims to develop and validate an automatic framework for IVOCT plaque characterisation using artificial intelligence (AI).   METHODS IVOCT pullbacks from 5 international centres were analysed in a corelab, annotating basic plaque components, inflammatory markers and other structures. A deep convolutional network with encoding-decoding architecture and pseudo-3D input was developed and trained using hybrid loss. The proposed network was integrated into commercial software to be externally validated on additional IVOCT pullbacks from three international corelabs, taking the consensus among corelabs as reference.   RESULTS Annotated images from 509 pullbacks (391 patients) were divided into 10,517 and 1,156 cross-sections for the training and testing datasets, respectively. Dice coefficient of the model was 0.906 for fibrous plaque, 0.848 for calcium and 0.772 for lipid in the testing dataset. Excellent agreement in plaque burden quantification was observed between the model and manual measurements (R2=0.98). In the external validation, the software correctly identified 518 out of 598 plaque regions from 300 IVOCT cross-sections, with a diagnostic accuracy of 97.6%[95%CI:93.4%-99.3%] in fibrous plaque, 90.5%[95%CI:85.2%-94.1%] in lipid and 88.5%[95%CI:82.4%-92.7%] in calcium. The median time required for analysis was 21.4 (18.6-25.0) seconds per pullback.   CONCLUSIONS A novel AI framework for automatic plaque characterisation in IVOCT was developed, providing excellent diagnostic accuracy in both internal and external validation. This model might reduce subjectivity in image interpretation and facilitate IVOCT quantification of plaque composition, with potential applications in research and IVOCT-guided PCI.","",""
4,"Z. Akkus, Yousof H. Aly, Itzhak Z. Attia, F. Lopez‐Jimenez, A. Arruda-Olson, P. Pellikka, S. Pislaru, G. Kane, P. Friedman, J. Oh","Artificial Intelligence (AI)-Empowered Echocardiography Interpretation: A State-of-the-Art Review",2021,"","","","",22,"2022-07-13 09:22:08","","10.3390/jcm10071391","","",,,,,4,4.00,0,10,1,"Echocardiography (Echo), a widely available, noninvasive, and portable bedside imaging tool, is the most frequently used imaging modality in assessing cardiac anatomy and function in clinical practice. On the other hand, its operator dependability introduces variability in image acquisition, measurements, and interpretation. To reduce these variabilities, there is an increasing demand for an operator- and interpreter-independent Echo system empowered with artificial intelligence (AI), which has been incorporated into diverse areas of clinical medicine. Recent advances in AI applications in computer vision have enabled us to identify conceptual and complex imaging features with the self-learning ability of AI models and efficient parallel computing power. This has resulted in vast opportunities such as providing AI models that are robust to variations with generalizability for instantaneous image quality control, aiding in the acquisition of optimal images and diagnosis of complex diseases, and improving the clinical workflow of cardiac ultrasound. In this review, we provide a state-of-the art overview of AI-empowered Echo applications in cardiology and future trends for AI-powered Echo technology that standardize measurements, aid physicians in diagnosing cardiac diseases, optimize Echo workflow in clinics, and ultimately, reduce healthcare costs.","",""
0,"A. Hamed, Ibrahim Ibrahim, S. Abdelwahab, M. Elfayoumi","Using artificial intelligence in the interpretation of corneal topography for laser vision correction",2021,"","","","",23,"2022-07-13 09:22:08","","10.21608/ejomos.2021.102949.1036","","",,,,,0,0.00,0,4,1,"PURPOSE: Development and validation of an artificial intelligence program for interpretation of corneal tomography. SETTING: Ebsar eye center, Benha, Qalyopia, Egypt. METHODS: In this retrospective cohort study, we analyzed the tomography of 611 eyes of 4 groups of patients using manual interpretation and Hamed’s Interpreter as well. RESULTS: There is a statistically significant difference between group 2 and group 1 regarding the inter eye differences in thinnest location (P-value 0.021) and also manifest refraction spherical equivalent (P-value 0.011). The mean of both was significantly high in group 1 (patients with postoperative ectasia) 17.0 ± 7.87 and -5.56 ± 2.16 respectively. There is a statistically significant difference between group 3 and group 1 regarding percent tissue altered (P-value <0.001) and residual stromal thickness (P-value <0.001). The mean of percent tissue altered was significantly higher among patients who had post-laser keratorefractive surgery ectasia group (37.23 ± 5.18) while the mean of residual stromal thickness was significantly low among this group (328.25 ± 41.6). In respect to group 4, the mean of the Inter eye score was 3.38 ± 1.04, and the mean of relative thickness map was -9.2 ± 0.596. The shape of the thickness profile map curve was a quick slope in 61.5% of eyes and normal in 38.5% of eyes in group 4. Some ectasia risk factors were missed during manual interpretation of topography that led to post LVC ectasia. CONCLUSIONS: Developing an artificial intelligence system that can interpret corneal tomography will alleviate the human errors of manual interpretation.","",""
121,"T. Schaffter, D. Buist, Christoph I. Lee, Yaroslav Nikulin, D. Ribli, Y. Guan, William Lotter, Zequn Jie, Hao Du, Sijia Wang, Jiashi Feng, Mengling Feng, Hyo-Eun Kim, F. Albiol, A. Albiol, Stephen Morrell, Z. Wojna, M. Ahsen, U. Asif, Antonio José Jimeno Yepes, Shivanthan A. C. Yohanandan, S. Rabinovici-Cohen, Darvin Yi, B. Hoff, Thomas Yu, E. Chaibub Neto, D. Rubin, Peter Lindholm, L. Margolies, R. McBride, J. Rothstein, W. Sieh, Rami Ben-Ari, S. Harrer, A. Trister, S. Friend, Thea C. Norman, B. Sahiner, Fredrik Strand, J. Guinney, G. Stolovitzky, Lester W. Mackey, Joyce Cahoon, Li Shen, J. H. Sohn, H. Trivedi, Yiqiu Shen, L. Buturovic, J. C. Pereira, Jaime S. Cardoso","Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms",2020,"","","","",24,"2022-07-13 09:22:08","","10.1001/jamanetworkopen.2020.0265","","",,,,,121,60.50,12,50,2,"This diagnostic accuracy study evaluates whether artificial intelligence can overcome human mammography interpretation limits with a rigorous, unbiased evaluation of machine learning algorithms.","",""
6,"Anton Schreuder, E. Scholten, B. Ginneken, C. Jacobs","Artificial intelligence for detection and characterization of pulmonary nodules in lung cancer CT screening: ready for practice?",2020,"","","","",25,"2022-07-13 09:22:08","","10.21037/TLCR-2020-LCS-06","","",,,,,6,3.00,2,4,2,"Lung cancer computed tomography (CT) screening trials using low-dose CT have repeatedly demonstrated a reduction in the number of lung cancer deaths in the screening group compared to a control group. With various countries currently considering the implementation of lung cancer screening, recurring discussion points are, among others, the potentially high false positive rates, cost-effectiveness, and the availability of radiologists for scan interpretation. Artificial intelligence (AI) has the potential to increase the efficiency of lung cancer screening. We discuss the performance levels of AI algorithms for various tasks related to the interpretation of lung screening CT scans, how they compare to human experts, and how AI and humans may complement each other. We discuss how AI may be used in the lung cancer CT screening workflow according to the current evidence and describe the additional research that will be required before AI can take a more prominent role in the analysis of lung screening CT scans.","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",26,"2022-07-13 09:22:08","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
4,"José Daniel López-Cabrera, R. Orozco-Morales, Jorge Armando Portal-Díaz, Orlando Lovelle-Enríquez, M. Pérez-Díaz","Current limitations to identify covid-19 using artificial intelligence with chest x-ray imaging (part ii). The shortcut learning problem",2021,"","","","",27,"2022-07-13 09:22:08","","10.1007/s12553-021-00609-8","","",,,,,4,4.00,1,5,1,"","",""
0,"Evander van Wolfswinkel, Jette Wielaard, J. Lavalaye, J. Hoff, J. Booij, T. D. de Wit, J. Habraken","Artificial Intelligence-Based Assistance in Clinical 123I-FP-CIT SPECT Scan Interpretation",2021,"","","","",28,"2022-07-13 09:22:08","","10.21203/rs.3.rs-721186/v1","","",,,,,0,0.00,0,7,1,"  Purpose: Dopamine transporter (DAT) imaging with 123I-FP-CIT SPECT is used to support the diagnosis of Parkinson’s disease (PD) in clinically uncertain cases. Previous studies showed that automatic classification of 123I‑FP‑CIT SPECT images (marketed as DaTSCAN) is feasible by using machine learning algorithms. However, these studies lacked sizable use of data from routine clinical practice. This study aims to contribute to the discussion whether artificial intelligence (AI) can be applied in clinical practice. Moreover, we investigated the need for hospital specific training data.Methods: A convolutional neural network (CNN) named DaTNet-3 was designed and trained to classify DaTSCAN images as either normal or supportive of a dopaminergic deficit. Both a multi-site data set (n = 2412) from the Parkinson’s Progression Marker Initiative (PPMI) and an in-house data set containing clinical images (n = 932) obtained in routine practice at the St Antonius hospital (STA) were used for training and testing. STA images were labeled based on interpretation by nuclear medicine physicians. To investigate whether indeterminate scans effects classification accuracy, a threshold was applied on the output probability.Results: DaTNet-3 trained with STA data reached an accuracy of 89.0% in correctly identifying images of the clinical STA test set as either normal or with decreased striatal DAT binding (98.5% on the PPMI test set). When thresholded, accuracy increased to 95.7%. This increase was not observed when trained with PPMI data, indicating the incorrect images were confidently classified as the incorrect class.Conclusion: Based on results of DaTNet-3 we conclude that automatic interpretation of DaTSCAN images with AI is feasible and robust. Further, we conclude DaTNet-3 performs slightly better when it is trained with hospital specific data. This difference increased when output probability was thresholded. Therefore we conclude that the usability of a data set increases if it contains indeterminate images.","",""
2,"Neha Gupta, S. Gupta, Rajesh K. Pathak, Vanita Jain, P. Rashidi, J. Suri","Human activity recognition in artificial intelligence framework: a narrative review",2022,"","","","",29,"2022-07-13 09:22:08","","10.1007/s10462-021-10116-x","","",,,,,2,2.00,0,6,1,"","",""
9,"J. Harrison, J. Gilbertson, M. Hanna, N. Olson, J. Seheult, James M. Sorace, M. Stram","Introduction to Artificial Intelligence and Machine Learning for Pathology.",2021,"","","","",30,"2022-07-13 09:22:08","","10.5858/arpa.2020-0541-CP","","",,,,,9,9.00,1,7,1,"CONTEXT.— Recent developments in machine learning have stimulated intense interest in software that may augment or replace human experts. Machine learning may impact pathology practice by offering new capabilities in analysis, interpretation, and outcomes prediction using images and other data. The principles of operation and management of machine learning systems are unfamiliar to pathologists, who anticipate a need for additional education to be effective as expert users and managers of the new tools.   OBJECTIVE.— To provide a background on machine learning for practicing pathologists, including an overview of algorithms, model development, and performance evaluation; to examine the current status of machine learning in pathology and consider possible roles and requirements for pathologists in local deployment and management of machine learning systems; and to highlight existing challenges and gaps in deployment methodology and regulation.   DATA SOURCES.— Sources include the biomedical and engineering literature, white papers from professional organizations, government reports, electronic resources, and authors' experience in machine learning. References were chosen when possible for accessibility to practicing pathologists without specialized training in mathematics, statistics, or software development.   CONCLUSIONS.— Machine learning offers an array of techniques that in recent published results show substantial promise. Data suggest that human experts working with machine learning tools outperform humans or machines separately, but the optimal form for this combination in pathology has not been established. Significant questions related to the generalizability of machine learning systems, local site verification, and performance monitoring remain to be resolved before a consensus on best practices and a regulatory environment can be established.","",""
45,"Tom Kamiel Magda Vercauteren, M. Unberath, N. Padoy, N. Navab","CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer-Assisted Interventions",2019,"","","","",31,"2022-07-13 09:22:08","","10.1109/JPROC.2019.2946993","","",,,,,45,15.00,11,4,3,"Data-driven computational approaches have evolved to enable extraction of information from medical images with reliability, accuracy, and speed, which is already transforming their interpretation and exploitation in clinical practice. While similar benefits are longed for in the field of interventional imaging, this ambition is challenged by a much higher heterogeneity. Clinical workflows within interventional suites and operating theaters are extremely complex and typically rely on poorly integrated intraoperative devices, sensors, and support infrastructures. Taking stock of some of the most exciting developments in machine learning and artificial intelligence for computer-assisted interventions, we highlight the crucial need to take the context and human factors into account in order to address these challenges. Contextual artificial intelligence for computer-assisted intervention (CAI4CAI) arises as an emerging opportunity feeding into the broader field of surgical data science. Central challenges being addressed in CAI4CAI include how to integrate the ensemble of prior knowledge and instantaneous sensory information from experts, sensors, and actuators; how to create and communicate a faithful and actionable shared representation of the surgery among a mixed human–AI actor team; and how to design interventional systems and associated cognitive shared control schemes for online uncertainty-aware collaborative decision-making ultimately producing more precise and reliable interventions.","",""
0,"I. Sivanarayana, J. Chandra, A. Rani","NEURAL COMPUTING IN ARTIFICIAL INTELLIGENCE – A REVIEW",2021,"","","","",32,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,3,1,"This paper presents a new perspective of Artificial Intelligence (AI). Although, number of attempts has been made to make an artifact intelligent, including evolution theory, neural network etc and a number of problems have been solved using these concepts but each of this theory covers only some aspect of human intelligence. Still there is a large gap between artificial intelligence agent and human being. In this paper, we outline the technical issues that need to be addressed in order to meet this challenge, including usability, robustness, and scale. At the same time it adds the power of two well knows Artificial Intelligence techniques viz. Neural Computing .The paper gives an idea of an artifact which is supposed to match the intelligence and behavior of a human being. Paper also discusses some natural phenomenon and how they can be confirmed by the revised definition of artificial intelligence. The paper does not claim that existing definition of artificial intelligence has some faults. The paper just augments the existing definition by some other features that can make it more close to natural intelligence. The features augmented are naturally inspired similarly as AI, Neural Network and genetics all are naturally inspired. Index Terms Neural Computing, Intelligence.","",""
0,"R. Hariharan, P. He, C. Hickman, J. Chambost, C. Jacques, M. Hentschke, B. Cunegatto, C. Dutra, A. Drakeley, Q. Zhan, R. Miller, G. Verheyen, M. Rosselot, S. Loubersac, K. Kelley","P–165 Using Artificial Intelligence to Classify Embryo Shape: An International Perspective",2021,"","","","",33,"2022-07-13 09:22:08","","10.1093/humrep/deab130.164","","",,,,,0,0.00,0,15,1,"      Is a pre-trained machine learning algorithm able to accurately detect cellular arrangement in 4-cell embryos from a different continent?        Artificial Intelligence (AI) analysis of 4-cell embryo classification is transferable across clinics globally with 79% accuracy.        Previous studies observing four-cell human embryo configurations have demonstrated that non-tetrahedral embryos (embryos in which cells make contact with fewer than 3 other cells) are associated with compromised blastulation and implantation potential. Previous research by this study group has indicated the efficacy of AI models in classification of tetrahedral and non-tetrahedral embryos with 87% accuracy, with a database comprising 2 clinics both from the same country (Brazil). This study aims to evaluate the transferability and robustness of this model on blind test data from a different country (France).        The study was a retrospective cohort analysis in which 909 4-cell embryo images (“tetrahedral”, n = 749; “non-tetrahedral”, n = 160) were collected from 3 clinics (2 Brazilian, 1 French). All embryos were captured at the central focal plane using Embryoscope™ time-lapse incubators. The training data consisted solely of embryo images captured in Brazil (586 tetrahedral; 87 non-tetrahedral) and the test data consisted exclusively of embryo images captured in France (163 tetrahedral; 72 non-tetrahedral).        The embryo images were labelled as either “tetrahedral” or “non-tetrahedral” at their respective clinics. Annotations were then validated by three operators. A ResNet–50 neural network model pretrained on ImageNet was fine-tuned on the training dataset to predict the correct annotation for each image. We used the cross entropy loss function and the RMSprop optimiser (lr = 1e–5). Simple data augmentations (flips and rotations) were used during the training process to help counteract class imbalances.        Our model was capable of classifying embryos in the blind French test set with 79% accuracy when trained with the Brazilian data. The model had sensitivity of 91% and 51% for tetrahedral and non-tetrahedral embryos respectively; precision was 81% and 73%; F1 score was 86% and 60%; and AUC was 0.61 and 0.64. This represents a 10% decrease in accuracy compared to when the model both trained and tested on different data from the same clinics.        Although strict inclusion and exclusion criteria were used, inter-operator variability may affect the pre-processing stage of the algorithm. Moreover, as only one focal plane was used, ambiguous cases were interpoloated and further annotated. Analysing embryos at multiple focal planes may prove crucial in improving the accuracy of the model.  Wider implications of the findings: Though the use of machine learning models in the analysis of embryo imagery has grown in recent years, there has been concern over their robustness and transferability. While previous results have demonstrated the utility of locally-trained models, our results highlight the potential for models to be implemented across different clinics.        Not applicable ","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",34,"2022-07-13 09:22:08","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
2,"A. Koeppe, F. Bamer, M. Selzer, B. Nestler, B. Markert","Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models",2021,"","","","",35,"2022-07-13 09:22:08","","","","",,,,,2,2.00,0,5,1,"(Artificial) neural networks have become increasingly popular in mechanics as means to accelerate computations with model order reduction techniques and as universal models for a wide variety of materials. However, the major disadvantage of neural networks remains: their numerous parameters are challenging to interpret and explain. Thus, neural networks are often labeled as black boxes, and their results often elude human interpretation. In mechanics, the new and active field of physicsinformed neural networks attempts to mitigate this disadvantage by designing deep neural networks on the basis of mechanical knowledge. By using this a priori knowledge, deeper and more complex neural networks became feasible, since the mechanical assumptions could be explained. However, the internal reasoning and explanation of neural network parameters remain mysterious. Complementary to the physics-informed approach, we propose a first step towards a physicsinforming approach, which explains neural networks trained on mechanical data a posteriori. This novel explainable artificial intelligence approach aims at elucidating the black box of neural networks and their high-dimensional representations. Therein, the principal component analysis decorrelates the distributed representations in cell states of RNNs and allows the comparison to known and fundamental functions. The novel approach is supported by a systematic hyperparameter search strategy that identifies the best neural network architectures and training parameters. The findings of three case studies on fundamental constitutive models (hyperelasticity, elastoplasticity, and viscoelasticity) imply that the proposed strategy can help identify numerical and analytical closed-form solutions to characterize new materials.","",""
0,"W. Hanif, Ythan H. Goldberg, C. Taub, D. Vorchheimer, L. Slipczuk, Edwin Ho, Carlos J Rodriguez, Muhammad Farooq, Mario J. Garcia, Lili Zhang","Abstract 11383: Automated Measurement of Global Longitudinal Strain by Speckle-Tracking Echocardiography in Cardio-Oncology Patients Using Artificial Intelligence",2021,"","","","",36,"2022-07-13 09:22:08","","10.1161/circ.144.suppl_1.11383","","",,,,,0,0.00,0,10,1,"  Introduction:  Left ventricular (LV) global longitudinal strain (GLS) is a robust LV systolic function measure used to detect subtle chemotherapy cardiotoxicity. However, inter-reader and inter-vendor variabilities compromise the clinical value of longitudinal follow-up of GLS. Artificial intelligence (AI)-based, fully automated measurement of longitudinal strain may be more reliable compared with human interpretation.      Methods:  We studied 52 transthoracic echocardiographic examinations randomly selected from a Cardio-oncology registry. All subjects received anthracycline-based chemotherapy in 2016-2019. AI-based longitudinal strain was assessed by EchoGo Core using standard 2- and 4-chamber apical views. Two readers verified the myocardium tracing by AI and found no errors. Longitudinal strain results by EchoGo were compared to GLS measured by conventional software (TomTec and Philips QLAB) using standard 3-, 2- and 4-chamber apical views.      Results:  AI-based longitudinal strain analysis was feasible in 51/52 (98%) transthoracic echocardiographic studies. The mean longitudinal strain was -17.3±3.3% for EchoGo, -16.9±2.4% for TomTec and -17.5±3.1% for QLAB. Bland-Altman analysis showed a bias of -0.4 ± 2.7% and 95% limits of -5.7 to 4.9% between EchoGo longitudinal strain and TomTec GLS (Figure 1A). A bias of 0.2 ± 3.3% and 95% limits of -6.2 to 6.6% between EchoGo longitudinal strain and QLAB GLS (Figure 1B) were seen. The bias between TomTec GLS and QLAB GLS was 0.6 ±2.2% (Figure 1C). The inter-reader correlation coefficients of TomTec GLS and QLAB GLS were 0.57 and 0.71, respectively.      Conclusions:  This novel AI-based longitudinal strain analysis was feasible in the majority of echocardiograms without any operator input. The bias between EchoGo longitudinal strain and conventional software appears small. AI-based myocardial strain analysis may reduce variabilities and facilitate longitudinal follow-up of GLS in Cardio-oncology patients.       ","",""
3,"T. Kaur, Anirudra Diwakar, Kirandeep, Pranav Mirpuri, M. Tripathi, P. Chandra, T. Gandhi","Artificial Intelligence in Epilepsy",2021,"","","","",37,"2022-07-13 09:22:08","","10.4103/0028-3886.317233","","",,,,,3,3.00,0,7,1,"Background: The study of seizure patterns in electroencephalography (EEG) requires several years of intensive training. In addition, inadequate training and human error may lead to misinterpretation and incorrect diagnosis. Artificial intelligence (AI)-based automated seizure detection systems hold an exciting potential to create paradigms for proper diagnosis and interpretation. AI holds the promise to transform healthcare into a system where machines and humans can work together to provide an accurate, timely diagnosis, and treatment to the patients. Objective: This article presents a brief overview of research on the use of AI systems for pattern recognition in EEG for clinical diagnosis. Material and Methods: The article begins with the need for understanding nonstationary signals such as EEG and simplifying their complexity for accurate pattern recognition in medical diagnosis. It also explains the core concepts of AI, machine learning (ML), and deep learning (DL) methods. Results and Conclusions: In this present context of epilepsy diagnosis, AI may work in two ways; first by creating visual representations (e.g., color-coded paradigms), which allow persons with limited training to make a diagnosis. The second is by directly explaining a complete automated analysis, which of course requires more complex paradigms than the previous one. We also clarify that AI is not about replacing doctors and strongly emphasize the need for domain knowledge in building robust AI models that can work in real-time scenarios rendering good detection accuracy in a minimum amount of time.","",""
2,"Lamija Hafizović, Aldijana Čaušević, Amar Deumic, Lemana Spahic Becirovic, L. G. Pokvic, A. Badnjević","The Use of Artificial Intelligence in Diagnostic Medical Imaging: Systematic Literature Review",2021,"","","","",38,"2022-07-13 09:22:08","","10.1109/BIBE52308.2021.9635307","","",,,,,2,2.00,0,6,1,"Diagnostic medical imaging and the interpretation of the imaging results pose a great challenge for the medical profession as the final conclusions are highly susceptible to human error and subjectivity. The necessity for standardization of interpretation of medical images is very necessary to bypass these problems. The only way of achieving this is using a methodology which excludes the human eye and employs artificial intelligence. However, another challenge is selecting the most suitable AI algorithm fit for the challenging task of imaging results interpretation. This study was conducted following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines published in 2020. Research was done using PubMed, ScienceDirect and Google Scholar databases where the key inclusion criteria were language, journal credibility, open access to full-text publications and the most recent papers. In order to focus on only the most recent research, only the papers published in the last 5 years were evaluated. The search through PubMed, ScienceDirect and Google Scholar has yielded 81, 205, and 520 papers respectively. Out of this number of papers, 26 of them have met all of the inclusion criteria and were included in the research. The observed accuracies of the models and the overall rising interest in the topic denote that this field is rapidly growing and has a great potential to be applied in daily medical practice in the future.","",""
1,"V. Pai, R. Pai","Artificial intelligence in dermatology and healthcare: An overview.",2021,"","","","",39,"2022-07-13 09:22:08","","10.25259/IJDVL_518_19","","",,,,,1,1.00,1,2,1,"Many aspects of our life are affected by technology. One of the most discussed advancements of modern technologies is artificial intelligence. It involves computational methods which in some way mimic the human thought process. Just like other branches, the medical field also has come under the ambit of artificial intelligence. Almost every field in medicine has been touched by its effect in one way or the other. Prominent among them are medical diagnosis, medical statistics, robotics, and human biology. Medical imaging is one of the foremost specialties with artificial intelligence applications, wherein deep learning methods like artificial neural networks are commonly used. artificial intelligence application in dermatology was initially restricted to the analysis of melanoma and pigmentary skin lesions, has now expanded and covers many dermatoses. Though the applications of artificial intelligenceare ever increasing, large data requirements, interpretation of data and ethical concerns are some of its limitations in the present day.","",""
2,"S. Haymond, C. McCudden","Rise of the Machines: Artificial Intelligence and the Clinical Laboratory.",2021,"","","","",40,"2022-07-13 09:22:08","","10.1093/jalm/jfab075","","",,,,,2,2.00,1,2,1,"BACKGROUND Artificial intelligence (AI) is rapidly being developed and implemented to augment and automate decision-making across healthcare systems. Being an essential part of these systems, laboratories will see significant growth in AI applications for the foreseeable future.   CONTENT In laboratory medicine, AI can be used for operational decision-making and automating or augmenting human-based workflows. Specific applications include instrument automation, error detection, forecasting, result interpretation, test utilization, genomics, and image analysis. If not doing so today, clinical laboratories will be using AI routinely in the future, therefore, laboratory experts should understand their potential role in this new area and the opportunities for AI technologies. The roles of laboratorians range from passive provision of data to fuel algorithms to developing entirely new algorithms, with subject matter expertise as a perfect fit in the middle. The technical development of algorithms is only a part of the overall picture, where the type, availability, and quality of data are at least as important. Implementation of AI algorithms also offers technical and usability challenges that need to be understood to be successful. Finally, as AI algorithms continue to become available, it is important to understand how to evaluate their validity and utility in the real world.   SUMMARY This review provides an overview of what AI is, examples of how it is currently being used in laboratory medicine, different ways for laboratorians to get involved in algorithm development, and key considerations for AI algorithm implementation and critical evaluation.","",""
1,"H. Whitney, M. Giger","Artificial Intelligence in Medical Imaging",2021,"","","","",41,"2022-07-13 09:22:08","","10.1063/9780735423473_007","","",,,,,1,1.00,1,2,1,"Artificial intelligence (AI) in cancer image interpretation continues to evolve with complementary advances in image acquisition systems, imaging protocols, and machine learning tools, as well as expanding clinical tasks. AI can be defined as having computers simulate the conduction of human intelligence tasks. Advances in computers, in terms of both computing power and memory capacity, have led to a rapid increase in assessing the potential use of AI in various tasks in medical imaging, going beyond the initial use in computer-aided detection (CADe) to include diagnosis, prognosis, response to therapy, and risk assessment, as well as in cancer discovery. AI methods are being developed for CADe and computer-aided diagnosis (CADx), for computer-aided triaging (CADt), and sometimes for use as autonomous readers, often with the need for consideration for effect on radiologists’ perception/cognitive performance and workflow. While the prospects of AI in medical image interpretation are abundant and promising, they bring along challenges and limitations. This chapter focuses on the role of AI in medical image interpretation.","",""
1,"B. Hameed, Gayathri Prerepa, Vathsala Patil, Pranav Shekhar, Syed Zahid Raza, Hadis Karimi, R. Paul, Nithesh Naik, S. Modi, G. Vigneswaran, Bhavan Prasad Rai, P. Chłosta, B. Somani","Engineering and clinical use of artificial intelligence (AI) with machine learning and data science advancements: radiology leading the way for future",2021,"","","","",42,"2022-07-13 09:22:08","","10.1177/17562872211044880","","",,,,,1,1.00,0,13,1,"Over the years, many clinical and engineering methods have been adapted for testing and screening for the presence of diseases. The most commonly used methods for diagnosis and analysis are computed tomography (CT) and X-ray imaging. Manual interpretation of these images is the current gold standard but can be subject to human error, is tedious, and is time-consuming. To improve efficiency and productivity, incorporating machine learning (ML) and deep learning (DL) algorithms could expedite the process. This article aims to review the role of artificial intelligence (AI) and its contribution to data science as well as various learning algorithms in radiology. We will analyze and explore the potential applications in image interpretation and radiological advances for AI. Furthermore, we will discuss the usage, methodology implemented, future of these concepts in radiology, and their limitations and challenges.","",""
1,"M. Dorobantu","Cognitive Vulnerability, Artificial Intelligence, and the Image of God in Humans",2021,"","","","",43,"2022-07-13 09:22:08","","10.1080/23312521.2020.1867025","","",,,,,1,1.00,1,1,1,"Abstract Recent progress in artificial intelligence (AI) opens up the possibility that one day machines could do anything that a human being can do, raising thus serious questions regarding human distinctiveness. For theological anthropology, the prospect of human-level AI brings a fresh opportunity to clarify the definition of the image of God. Comparing human and artificial intelligence leads to replacing the Aristotelian-like interpretation of the image of God as rationality with a relational model. Instead of regarding our cognitive biases as vulnerabilities, they should be seen as instrumental in bringing about our unique type of intelligence, one marked by relationality.","",""
0,"Kai Jiang, Xi Lu","The Influence of Speech Translation Technology on Interpreter’s Career Prospects in the Era of Artificial Intelligence",2021,"","","","",44,"2022-07-13 09:22:08","","10.1088/1742-6596/1802/4/042074","","",,,,,0,0.00,0,2,1,"As the advancements in artificial intelligence, discussions on whether machine translation will replace human translation are found in the media and the public, but scholars have rarely explored this in research. This paper first reviews the history and recent progress in speech translation technology, and analyzes its merits and limitations. Then, in view of the history and features of the interpreting profession, the paper discusses the influence of speech translation technology on interpreter’s career prospects. The author holds that even if future speech translation technology is highly sophisticated, it still cannot completely replace human interpreters. Artificial intelligence is considered as both a challenge and an opportunity for the translation industry. The future trends in interpretation will be mainly human-led and machine-aided. After analyzing the trends and challenges to the interpreting profession, the paper proposes suggestions to interpretation teaching, hoping to give reference to interpretation teachers, learners and researchers.","",""
0,"I. Zenin","Convergence of Artificial Intelligence and Intellectual Property Rights",2021,"","","","",45,"2022-07-13 09:22:08","","10.18572/2072-4322-2021-1-4-8","","",,,,,0,0.00,0,1,1,"The purpose is to identify and evaluate the doctrinal definitions of the concept and recommendations on ensuring the protection of the results created by AI as products of the functioning of its technologies using the norms of the current copyright, patent and other legislation. At the same time, the goal of scientific evaluation of the existing legal definitions of the concept of AI and its accompanying categories is pursued. The methodology includes methods of logical, historical, systematic and comparative legal analysis of legal definitions, methods of translation (implementation) of doctrinal categories in normative legal acts, interpretation of differences in copyright and patent protection of the results of human creative activity and the need to take them into account when deciding on the possibility of legal protection of products generated by artificial intelligence. Result. As part of the assessment of the existing doctrinal and legal definitions of the concept of AI, its technologies and the possibilities of protecting the protective results created in the course of their operation, conclusions are drawn in favor of legal structures. In the sense of the latter: artificial intelligence is recognized as a human-created “complex of technological solutions”; operations performed by this complex are not identified with human actions, but are recognized only as their similarity (“imitation»); the results of these operations are not equated with the creative achievements of the natural (human) mind, but are recognized as their visibility, which can only be compared (“compared”) with the products of the cognitive functions of the human brain as the results of its “intellectual activity”.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",46,"2022-07-13 09:22:08","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
1,"C. Bormann, M. Kanakasabapathy, Prudhvi Thirumalaraju, I. Dimitriadis, I. Souter, K. Hammer, H. Shafiee","O-125 Development of an artificial intelligence embryo witnessing system to accurately track and identify patient specific embryos in a human IVF laboratory",2021,"","","","",47,"2022-07-13 09:22:08","","10.1093/humrep/deab126.050","","",,,,,1,1.00,0,7,1,"      Can convolutional neural networks (CNN) be used as a witnessing system to accurately track and identify patient specific embryos at the cleavage stage of development?        We developed the first artificial intelligence driven witnessing system to accurately track cleavage and blastocyst stage embryos in a human ART laboratory.        There are reports of human errors in embryo tracking that have led to the births of children with different genetic makeup than their birth parents. Clinical practices rely on manual identification, barcodes or radio-frequency identification technology to track embryos. These systems are designed to track culture dishes but are unable to monitor developing embryos within the dish to help ensure an error-free patient match. Previously, we developed an AI witnessing system to track blastocysts with 100% accuracy. The goal of this study was to determine whether an AI witnessing system could be developed that accurately tracks cleavage stage embryos.        A pre-developed deep neural network technology was first trained and tested on 4944 embryos images. The algorithm processed embryo images for each patient and produced a unique key that was associated with the patient ID at 60 hpi, which formed our library. When the algorithm evaluated embryos at 64 hpi it generated another key that was matched with the patient’s unique key available in the library.        A total of 3068 embryos from 412 patients were examined by the CNN at both 60 hpi and 64 hpi. These timepoints were chosen as they reflect the time our laboratory evaluates Day 3 embryos (60 hpi) and the time we move them to another dish and prepare them for transfer (64 hpi). The patient cohorts ranged from 3-12 embryos per patient.        The accuracy of the CNN in correctly matching the patient identification with the patient embryo cohort was 100% (CI: 99.1% to 100.0%, n = 412).        Limitations of this study include that all embryos were imaged under identical conditions and within the same EmbryoScope. Additionally, this study only examined fresh Day 3 embryos cultured over a span of 4 hours. Future studies should include images of fresh and frozen/thawed embryos captured using different imaging systems.        This study describes the first artificial intelligence-based approach for cleavage stage embryo tracking and patient specimen identification in the IVF laboratory. This technology offers a robust witnessing step based on unique morphological features that are specific to each individual embryo.        This work was partially supported by the Brigham Precision Medicine Developmental Award (Brigham Precision Medicine Program, Brigham and Women’s Hospital), Partners Innovation Discovery Grant (Partners Healthcare), and R01AI118502, and R01AI138800. ","",""
2,"Morteza Esmaeili, R. Vettukattil, H. Banitalebi, Nina R. Krogh, J. Geitung","Explainable Artificial Intelligence for Human-Machine Interaction in Brain Tumor Localization",2021,"","","","",48,"2022-07-13 09:22:08","","10.3390/jpm11111213","","",,,,,2,2.00,0,5,1,"Primary malignancies in adult brains are globally fatal. Computer vision, especially recent developments in artificial intelligence (AI), have created opportunities to automatically characterize and diagnose tumor lesions in the brain. AI approaches have provided scores of unprecedented accuracy in different image analysis tasks, including differentiating tumor-containing brains from healthy brains. AI models, however, perform as a black box, concealing the rational interpretations that are an essential step towards translating AI imaging tools into clinical routine. An explainable AI approach aims to visualize the high-level features of trained models or integrate into the training process. This study aims to evaluate the performance of selected deep-learning algorithms on localizing tumor lesions and distinguishing the lesion from healthy regions in magnetic resonance imaging contrasts. Despite a significant correlation between classification and lesion localization accuracy (R = 0.46, p = 0.005), the known AI algorithms, examined in this study, classify some tumor brains based on other non-relevant features. The results suggest that explainable AI approaches can develop an intuition for model interpretability and may play an important role in the performance evaluation of deep learning models. Developing explainable AI approaches will be an essential tool to improve human–machine interactions and assist in the selection of optimal training methods.","",""
0,"Canan Tiftik","Investigation of Human Resources Dimension in Management and Organization Structure of the Effects of Artificial Intelligence",2021,"","","","",49,"2022-07-13 09:22:08","","10.21733/IBAD.833256","","",,,,,0,0.00,0,1,1,"In the competitive time, there has been a great deal of progress in the industry. It is one of the most serious obstacles to the industry in many industries that adopt contemporary technologies to manage continuous development and faster than ordinary jobs. Many of the scientists and researchers recommend using AI tools and digital technologies for industries. Machine language and artificial intelligence are used by many organizations in the human resources unit, where it undertakes an integrated task in recruiting, performance analysis, personnel selection, data collection for employees, providing real-time information and obtaining the right information. Artificial intelligence-based Human Resources (HR) applications have a solid potential to increase employee productivity and support HR experts to become knowledge and trained consultants that increase the success of the employee. HR applications authorized by artificial intelligence have the ability to analyze, predict, diagnose and seek and find more robust and capable resources.","",""
21,"B. Stoel","Use of artificial intelligence in imaging in rheumatology – current status and future perspectives",2020,"","","","",50,"2022-07-13 09:22:08","","10.1136/rmdopen-2019-001063","","",,,,,21,10.50,21,1,2,"After decades of basic research with many setbacks, artificial intelligence (AI) has recently obtained significant breakthroughs, enabling computer programs to outperform human interpretation of medical images in very specific areas. After this shock wave that probably exceeds the impact of the first AI victory of defeating the world chess champion in 1997, some reflection may be appropriate on the consequences for clinical imaging in rheumatology. In this narrative review, a short explanation is given about the various AI techniques, including ‘deep learning’, and how these have been applied to rheumatological imaging, focussing on rheumatoid arthritis and systemic sclerosis as examples. By discussing the principle limitations of AI and deep learning, this review aims to give insight into possible future perspectives of AI applications in rheumatology.","",""
3,"B. Schneider, P. Asprion, F. Grimberg","Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence",2019,"","","","",51,"2022-07-13 09:22:08","","10.5220/0007715503810390","","",,,,,3,1.00,1,3,3,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.","",""
21,"Shantani Kannan, K. Subbaram, Sheeza Ali, H. Kannan","The Role of Artificial Intelligence and Machine Learning Techniques: Race for COVID-19 Vaccine",2020,"","","","",52,"2022-07-13 09:22:08","","10.5812/archcid.103232","","",,,,,21,10.50,5,4,2,"Context: In the healthcare system, Artificial Intelligence (AI) is emerging as a productive tool. There are instances where AI has done marvels in the diagnosis of various health conditions and the interpretation of complex medical disorders. Although AI is far from human intelligence, it can be used as an effective tool to study the SARS-CoV-2 and its capabilities, virulence, and genome. The progress of the pandemic can be tracked, and the patients can be monitored, thereby speeding up the research for the treatment of COVID-19. In this review article, we highlighted the importance of AI and Machine learning (ML) techniques that can speed up the path to the discovery of a possible cure for COVID-19. We also deal with the interactions between viromics and AI, which can hopefully find a solution to this pandemic. Evidence Acquisition: A review of different articles was conducted using the following databases: MEDLINE/PubMed, SCOPUS, Web of Science, ScienceDirect, and Google Scholar for recent studies regarding the use of AI, seeking the spread of different infectious diseases using relevant MeSH subheadings. Results: After a thorough screening of different articles, 30 articles were considered, and key information was obtained from them. Finally, the scope was broadened to obtain more information. Our findings indicated that AI/ML is a promising approach to drug development. Conclusions: The field of AI has enormous potential to predict the changes that may take place in the environment. If this technology is applied to situations of a pandemic such as COVID-19, breakthroughs could potentially pave the way for new vaccines and antiviral drugs.","",""
18,"Zhen Zhao, Y. Pi, Lisha Jiang, Yongzhao Xiang, Jianan Wei, Pei Yang, Wenjie Zhang, Xiao Zhong, K. Zhou, Yuhao Li, Lin Li, Yi Zhang, H. Cai","Deep neural network based artificial intelligence assisted diagnosis of bone scintigraphy for cancer bone metastasis",2020,"","","","",53,"2022-07-13 09:22:08","","10.1038/s41598-020-74135-4","","",,,,,18,9.00,2,13,2,"","",""
15,"M. Jiménez Pérez, R. Grande","Application of artificial intelligence in the diagnosis and treatment of hepatocellular carcinoma: A review",2020,"","","","",54,"2022-07-13 09:22:08","","10.3748/wjg.v26.i37.5617","","",,,,,15,7.50,8,2,2,"Although artificial intelligence (AI) was initially developed many years ago, it has experienced spectacular advances over the last 10 years for application in the field of medicine, and is now used for diagnostic, therapeutic and prognostic purposes in almost all fields. Its application in the area of hepatology is especially relevant for the study of hepatocellular carcinoma (HCC), as this is a very common tumor, with particular radiological characteristics that allow its diagnosis without the need for a histological study. However, the interpretation and analysis of the resulting images is not always easy, in addition to which the images vary during the course of the disease, and prognosis and treatment response can be conditioned by multiple factors. The vast amount of data available lend themselves to study and analysis by AI in its various branches, such as deep-learning (DL) and machine learning (ML), which play a fundamental role in decision-making as well as overcoming the constraints involved in human evaluation. ML is a form of AI based on automated learning from a set of previously provided data and training in algorithms to organize and recognize patterns. DL is a more extensive form of learning that attempts to simulate the working of the human brain, using a lot more data and more complex algorithms. This review specifies the type of AI used by the various authors. However, well-designed prospective studies are needed in order to avoid as far as possible any bias that may later affect the interpretability of the images and thereby limit the acceptance and application of these models in clinical practice. In addition, professionals now need to understand the true usefulness of these techniques, as well as their associated strengths and limitations.","",""
47,"L. Faes, B. Geerts, Xiaoxuan Liu, L. Morgan, P. Watkinson, P. McCulloch","DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in clinical artificial intelligence.",2021,"","","","",55,"2022-07-13 09:22:08","","10.1038/s41591-021-01229-5","","",,,,,47,47.00,8,6,1,"","",""
0,"R. Porcher","CORR Insights®: Does Artificial Intelligence Outperform Natural Intelligence in Interpretation of Musculoskeletal Radiological Studies? A Systematic Review.",2020,"","","","",56,"2022-07-13 09:22:08","","10.1097/CORR.0000000000001415","","",,,,,0,0.00,0,1,2,"Machine learning, and artificial intelligence more generally, are quickly growing areas of applied medical decisionmaking research. Compared with what are now considered moretraditional analytical approaches, such as statistical prediction models, machine learning is seen as providing unique advantages; in particular, it may improve healthcare delivery because it can learn from millions of digitized patient charts or images, and so provide robust, reproducible, and rapid decision-support tools [8, 14]. Artificial intelligence has already transformed many aspects of daily life outside health care; machine-learning algorithms allow us to translate large pieces of text into any language, recognize speech, drive a car, make a plane take off or land, or detect banking fraud. The advantages of machine learning include the ability to analyze enormous amounts of data, capture complex nonlinear relationships among these data, and consider a wide range of data. It can handle structured data, similar to other statistical prediction methods, but machine learning can also analyze free text and images, as well as high-frequency sampled data streams such as those produced by wearable devices. In this respect, no approach other than artificial intelligence and machine learning has enabled the analysis of such data so far. These approaches have begun to show promise in orthopaedic surgery, specifically. For example, one recent study used machine learning to predict whether patients would achieve clinically important improvements in validated outcome scores 2 years after joint arthroplasty [5, 10], which is important in light of the fact that even experienced surgeons’ abilities in this sort of prediction for patients undergoing TKA are no better than a coin toss [6]. However, despite the hype and hopes about artificial intelligence, more-nuanced opinions have emerged [1, 13]. Identifying associations among data does not prevent confounding, and this may prevent us from translating modifiable factors flagged by algorithms into real targets for interventions. Additionally, despite the underlying idea that the more data we have to train an algorithm, the more accurate they are, the greed for more data does not always translate into more-accurate predictions [1]. Predicting what will occur in 1, 5, or 10 years may be difficult because all past data, not just available data, do not contain sufficient information. This may explain why machine-learning algorithms have often outperformed human experts in imaging or diagnostics, where most information is present in the data analyzed [8]. The advantage over moreclassic statistical models for longer-term risk prediction modeling is likely less evident [2]. This CORR Insights is a commentary on the article “Does Artificial Intelligence Outperform Natural Intelligence in Interpretation of Musculoskeletal Radiological Studies? A Systematic Review” by Groot and colleagues available at: DOI: 10.1097/CORR.0000000000001360. The author certifies that he, or anymembers of his immediate family, has no commercial associations (eg, consultancies, stock ownership, equity interest, patent/licensing arrangements, etc) that might pose a conflict of interest in connection with the submitted article. All ICMJE Conflict of Interest Forms for authors and Clinical Orthopaedics and Related Research editors and board members are on file with the publication and can be viewed on request. The opinions expressed are those of the writer, and do not reflect the opinion or policy of CORR or the Association of Bone and Joint Surgeons. R. Porcher ✉, Centre d’Epidémiologie Clinique, Hôpital Hôtel-Dieu, 1 Parvis NotreDame Place Jean-Paul II, 75004 Paris, France, Email: raphael.porcher@aphp.fr R. Porcher, Université de Paris, CRESS UMR1153, INSERM, INRA, F-75004 Paris, France; Centre d’Epidémiologie Clinique, AP-HP, Hôtel-Dieu, F-75004 Paris, France","",""
0,"F. LeRon Shults","Progress in simulating human geography: Assemblage theory and the practice of multi-agent artificial intelligence modeling",2021,"","","","",57,"2022-07-13 09:22:08","","10.1177/03091325211059567","","",,,,,0,0.00,0,1,1,"Over the last few years, there has been an explosion of interest in assemblage theory among human geographers. During this same period, a growing number of scholars in the field have utilized computational methodologies to simulate the complex adaptive systems they study. However, very little attention has been paid to the connections between these two developments. This article outlines those connections and argues that more explicitly integrating assemblage theory and computer modeling can encourage a more robust philosophical understanding of both and facilitate progress in scientific research on the ways in which complex socio-material systems form and transform.","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",58,"2022-07-13 09:22:08","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",59,"2022-07-13 09:22:08","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
6,"T. Sammour, S. Bedrikovetski","Radiomics for Diagnosing Lateral Pelvic Lymph Nodes in Rectal Cancer: Artificial Intelligence Enabling Precision Medicine?",2020,"","","","",60,"2022-07-13 09:22:08","","10.1245/s10434-020-08978-6","","",,,,,6,3.00,3,2,2,"","",""
10,"A. Lin, Márton Kolossváry, I. Išgum, P. Maurovich-Horvat, P. Slomka, D. Dey","Artificial intelligence: improving the efficiency of cardiovascular imaging",2020,"","","","",61,"2022-07-13 09:22:08","","10.1080/17434440.2020.1777855","","",,,,,10,5.00,2,6,2,"ABSTRACT Introduction Artificial intelligence (AI) describes the use of computational techniques to mimic human intelligence. In healthcare, this typically involves large medical datasets being used to predict a diagnosis, identify new disease genotypes or phenotypes, or guide treatment strategies. Noninvasive imaging remains a cornerstone for the diagnosis, risk stratification, and management of patients with cardiovascular disease. AI can facilitate every stage of the imaging process, from acquisition and reconstruction, to segmentation, measurement, interpretation, and subsequent clinical pathways. Areas covered In this paper, we review state-of-the-art AI techniques and their current applications in cardiac imaging, and discuss the future role of AI as a precision medicine tool. Expert opinion Cardiovascular medicine is primed for scalable AI applications which can interpret vast amounts of clinical and imaging data in greater depth than ever before. AI-augmented medical systems have the potential to improve workflow and provide reproducible and objective quantitative results which can inform clinical decisions. In the foreseeable future, AI may work in the background of cardiac image analysis software and routine clinical reporting, automatically collecting data and enabling real-time diagnosis and risk stratification.","",""
9,"X. Tian","Application of Artificial Intelligence in Computer Network Technology",2020,"","","","",62,"2022-07-13 09:22:08","","","","",,,,,9,4.50,9,1,2,"with the deepening of science and technology, the original capabilities of computer network technology, such as data operation and word meaning interpretation, have been unable to meet the actual needs of modern users. It has become an inevitable choice for computer network technology to adapt to the development of the times to improve its humanization and intelligence level. Artificial intelligence enables computers to replace human beings to complete more complex work, which can save working time and improve working efficiency. At the same time, it can also promote people to enjoy more intelligent services, realize the innovation and development of science and technology, and promote the long-term sustainable development of society. Therefore, this paper expounds the application of artificial intelligence in computer network technology, and helps people to better understand this measure, providing necessary foundation for the further development of artificial intelligence in the future.","",""
1,"Udo Schlegel, E. Cakmak, D. Keim","ModelSpeX: Model Specification Using Explainable Artificial Intelligence Methods",2020,"","","","",63,"2022-07-13 09:22:08","","10.2312/MLVIS.20201100","","",,,,,1,0.50,0,3,2,"Explainable artificial intelligence (XAI) methods aim to reveal the non-transparent decision-making mechanisms of black-box models. The evaluation of insight generated by such XAI methods remains challenging as the applied techniques depend on many factors (e.g., parameters and human interpretation). We propose ModelSpeX, a visual analytics workflow to interactively extract human-centered rule-sets to generate model specifications from black-box models (e.g., neural networks). The workflow enables to reason about the underlying problem, to extract decision rule sets, and to evaluate the suitability of the model for a particular task. An exemplary usage scenario walks an analyst trough the steps of the workflow to show the applicability.","",""
7,"J. Espinoza, Le Thanh Dong","Artificial Intelligence Tools for Refining Lung Cancer Screening",2020,"","","","",64,"2022-07-13 09:22:08","","10.3390/jcm9123860","","",,,,,7,3.50,4,2,2,"Nearly one-quarter of all cancer deaths worldwide are due to lung cancer, making this disease the leading cause of cancer death among both men and women. The most important determinant of survival in lung cancer is the disease stage at diagnosis, thus developing an effective screening method for early diagnosis has been a long-term goal in lung cancer care. In the last decade, and based on the results of large clinical trials, lung cancer screening programs using low-dose computer tomography (LDCT) in high-risk individuals have been implemented in some clinical settings, however, this method has various limitations, especially a high false-positive rate which eventually results in a number of unnecessary diagnostic and therapeutic interventions among the screened subjects. By using complex algorithms and software, artificial intelligence (AI) is capable to emulate human cognition in the analysis, interpretation, and comprehension of complicated data and currently, it is being successfully applied in various healthcare settings. Taking advantage of the ability of AI to quantify information from images, and its superior capability in recognizing complex patterns in images compared to humans, AI has the potential to aid clinicians in the interpretation of LDCT images obtained in the setting of lung cancer screening. In the last decade, several AI models aimed to improve lung cancer detection have been reported. Some algorithms performed equal or even outperformed experienced radiologists in distinguishing benign from malign lung nodules and some of those models improved diagnostic accuracy and decreased the false-positive rate. Here, we discuss recent publications in which AI algorithms are utilized to assess chest computer tomography (CT) scans imaging obtaining in the setting of lung cancer screening.","",""
7,"R. Trasolini, M. Byrne","Artificial intelligence and deep learning for small bowel capsule endoscopy",2020,"","","","",65,"2022-07-13 09:22:08","","10.1111/den.13896","","",,,,,7,3.50,4,2,2,"Capsule endoscopy is ideally suited to artificial intelligence‐based interpretation given its reliance on pattern recognition in still images. Time saving viewing modes and lesion detection features currently available rely on machine learning algorithms, a form of artificial intelligence. Current software necessitates close human supervision given poor sensitivity relative to an expert reader. However, with the advent of deep learning, artificial intelligence is becoming increasingly reliable and will be increasingly relied upon. We review the major advances in artificial intelligence for capsule endoscopy in recent publications and briefly review artificial intelligence development for historical understanding. Importantly, recent advancements in artificial intelligence have not yet been incorporated into practice and it is immature to judge the potential of this technology based on current platforms. Remaining regulatory and standardization hurdles are being overcome and artificial intelligence‐based clinical applications are likely to proliferate rapidly.","",""
0,"A. Hussein, A. Chehab, A. Kayssi, I. Elhajj","An Artificial Intelligence Resiliency System (ARS)",2020,"","","","",66,"2022-07-13 09:22:08","","10.1007/978-3-030-52067-0_28","","",,,,,0,0.00,0,4,2,"","",""
6,"Andreas Holzinger, R. Goebel, M. Mengel, Heimo Müller, Yuzuru Tanaka","Artificial Intelligence and Machine Learning for Digital Pathology: State-of-the-Art and Future Challenges",2020,"","","","",67,"2022-07-13 09:22:08","","10.1007/978-3-030-50402-1","","",,,,,6,3.00,1,5,2,"","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",68,"2022-07-13 09:22:08","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
2,"R. Stidham","Artificial Intelligence for Understanding Imaging, Text, and Data in Gastroenterology.",2020,"","","","",69,"2022-07-13 09:22:08","","","","",,,,,2,1.00,2,1,2,"Artificial intelligence (AI) could change the practice of gastroenterology through its ability to both acquire and analyze information with speed, reproducibility, and, potentially, insight that may exceed that of human medical specialists. AI is powered by computational methods that allow machines to replicate clinical pattern recognition used by gastroenterology specialists to interpret endoscopic or cross-sectional images; understand the meaning and intent of medical documents; and merge different types of data to infer a diagnosis, prognosis, or expected outcome. Ongoing research is studying the use of AI for automated interpretation of text from colonoscopy and clinical documents for improved quality and patient phenotyping as well as enhanced detection and descriptions of polyps and other endoscopic lesions, and for predicting the probability of future therapeutic response early in a treatment course. This article introduces emerging technologies of natural language processing, machine vision, and machine learning for data analytics, and describes current and future applications in gastroenterology.","",""
3,"Baseer Ahmad, Judy E. Kim, E. Rahimy","Fundamentals of artificial intelligence for ophthalmologists.",2020,"","","","",70,"2022-07-13 09:22:08","","10.1097/ICU.0000000000000679","","",,,,,3,1.50,1,3,2,"PURPOSE OF REVIEW As artificial intelligence continues to develop new applications in ophthalmic image recognition, we provide here an introduction for ophthalmologists and a primer on the mechanisms of deep learning systems.   RECENT FINDINGS Deep learning has lent itself to the automated interpretation of various retinal imaging modalities, including fundus photography and optical coherence tomography. Convolutional neural networks (CNN) represent the primary class of deep neural networks applied to these image analyses. These have been configured to aid in the detection of diabetes retinopathy, AMD, retinal detachment, glaucoma, and ROP, among other ocular disorders. Predictive models for retinal disease prognosis and treatment are also being validated.   SUMMARY Deep learning systems have begun to demonstrate a reliable level of diagnostic accuracy equal or better to human graders for narrow image recognition tasks. However, challenges regarding the use of deep learning systems in ophthalmology remain. These include trust of unsupervised learning systems and the limited ability to recognize broad ranges of disorders.","",""
4,"P. Regitnig, Heimo Müller, Andreas Holzinger","Expectations of Artificial Intelligence for Pathology",2020,"","","","",71,"2022-07-13 09:22:08","","10.1007/978-3-030-50402-1_1","","",,,,,4,2.00,1,3,2,"","",""
0,"Beilei Wang, Jie Jing, Xiaochun Huang, Cheng Hua, Qin Qin, Y. Jia, Zhiyong Wang, Lei Jiang, Bai Gao, Les J. Wu, Xianfei Zeng, Fubo Wang, Chuanbin Mao, Shanrong Liu","Establishment of a Knowledge‐and‐Data‐Driven Artificial Intelligence System with Robustness and Interpretability in Laboratory Medicine",2022,"","","","",72,"2022-07-13 09:22:08","","10.1002/aisy.202100204","","",,,,,0,0.00,0,14,1,"Laboratory medicine plays an important role in clinical diagnosis. However, no laboratory‐based artificial intelligence (AI) diagnostic system has been applied in current clinical practice due to the lack of robustness and interpretability. Although many attempts have been made, it is still difficult for doctors to adopt the existing machine learning (ML) patterns in interpreting laboratory (lab) big data. Here, a knowledge‐and‐data‐driven laboratory diagnostic system is developed, termed AI‐based Lab tEst tO diagNosis (AI LEON), by integrating an innovative knowledge graph analysis framework and “mixed XGboost and Genetic Algorithm (MiXG)” technique to simulate the doctor's laboratory‐based diagnosis. To establish AI LEON, we included 89 116 949 laboratory data and 10 423 581 diagnosis data points from 730 113 participants. Among them, 686 626 participants were recruited for training and validating purposes with the remaining for testing purposes. AI LEON automatically identified and analyzed 2071 lab indexes, resulting in multiple disease recommendations that involved 441 common diseases in ten organ systems. AI LEON exhibited outstanding transparency and interpretability in three universal clinical application scenarios and outperformed human physicians in interpreting lab reports. AI LEON is an advanced intelligent system that enables a comprehensive interpretation of lab big data, which substantially improves the clinical diagnosis.","",""
423,"Andreas Holzinger, G. Langs, H. Denk, K. Zatloukal, Heimo Müller","Causability and explainability of artificial intelligence in medicine",2019,"","","","",73,"2022-07-13 09:22:08","","10.1002/widm.1312","","",,,,,423,141.00,85,5,3,"Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. However, their weakness was in dealing with uncertainties of the real world. Through the introduction of probabilistic learning, applications became increasingly successful, but increasingly opaque. Explainable AI deals with the implementation of transparency and traceability of statistical black‐box machine learning methods, particularly deep learning (DL). We argue that there is a need to go beyond explainable AI. To reach a level of explainable medicine we need causability. In the same way that usability encompasses measurements for the quality of use, causability encompasses measurements for the quality of explanations. In this article, we provide some necessary definitions to discriminate between explainability and causability as well as a use‐case of DL interpretation and of human explanation in histopathology. The main contribution of this article is the notion of causability, which is differentiated from explainability in that causability is a property of a person, while explainability is a property of a system","",""
19,"P. Sengupta, D. Adjeroh","Will Artificial Intelligence Replace the Human Echocardiographer?: Clinical Considerations",2018,"","","","",74,"2022-07-13 09:22:08","","10.1161/CIRCULATIONAHA.118.037095","","",,,,,19,4.75,10,2,4,"An older population with an increased prevalence of cardiovascular disease and an aging workforce are engendering a state of healthcare crisis in cardiology.1 Most cardiologists now face an unprecedented time crunch as they rush through their appointments to perform and interpret more and more procedures. The need to multitask creates exhaustion leading to burnout and frequent reporting errors.2 The recent interest in using artificial intelligence techniques, such as machine learning, may offer a solution to reduce physician workload including repetitive and tedious tasks involved in diagnosing and analyzing patient data and imaging. To this end, the study by Zhang and colleagues3 in this issue of Circulation adds to the growing enthusiasm for developing a machine learning algorithm that automates several facets of echocardiography measurement and interpretation. Zhang and colleagues used a deep learning model that has enjoyed spectacular success in addressing computer vision problems including image classification, face recognition, robot navigation, and driverless cars to name a few. Although traditional machine learning workflow includes an initial stage of feature engineering and selection from the data for classification, deep learning methods attempt to learn the important features directly from the raw image data (with minimal preprocessing). Zhang and colleagues applied an algorithm that has triumphed in image recognition tasks and reported a 96% accuracy for distinguishing between broad echocardiographic view classes (eg, parasternal long axis from short axis, or an apical view) and an 84% accuracy overall (including partially obscured views). These results are consistent with a recent study that applied deep learning with convolutional neural networks for view classification of echocardiograms.4 However, Zhang et al notably used a deeper architecture with more layers (18 versus 11), considered a larger number of echocardiography view classes (23 versus 15 views), and applied their technique to a larger data set (14 035 versus 267 echocardiographic studies). The authors also reported an overall metric of accuracy of image segmentation ranging from 72% to 90% for image segmentation. Although deep learning has been explored previously for segmenting the left ventricle,5 the work by Zhang et al was much more extensive with additional cardiac segments beyond the left ventricle and a larger data set, involving millions of images from 14 035 studies. Moreover, the authors succeeded in going a step beyond simple classification and segmentation by providing an algorithm for automated quantification of cardiac structure and function. The comparison with manually recorded measurements, however, showed wide limits of agreements emphasizing the potential real-world variability of echocardiography measurements. Independent verification from a core laboratory or the use of a gold standard like cardiac magnetic resonance was © 2018 American Heart Association, Inc.","",""
1,"I. Suleimenov, Y. Vitulyova, A. Bakirov, O. Gabrielyan","Artificial Intelligence: what is it?",2020,"","","","",75,"2022-07-13 09:22:08","","10.1145/3397125.3397141","","",,,,,1,0.50,0,4,2,"Based on the principle of dialectic symmetry formulated by the philosophy of dialectic positivism, an interpretation of the concept of ""artificial intelligence"" is proposed. This principle assumes the existence of a hierarchy of information objects, similar to the hierarchy, which reflects different levels of organization of matter (mechanical, chemical, biological, social). The construction of a hierarchy of information objects - information processing systems - allows us to interpret in the same way the essence of both artificial intelligence and the intelligence that a human being is endowed with. These are information processing systems referring to the highest levels of the specified hierarchy.","",""
1,"H. K. Ha","Editorial for “Deep‐Learning‐Based Artificial Intelligence for PI‐RADS Classification to Assist Multiparametric Prostate MRI Interpretation: A Development Study”",2020,"","","","",76,"2022-07-13 09:22:08","","10.1002/jmri.27254","","",,,,,1,0.50,1,1,2,"Many methodological changes for diagnosing prostate cancer, including prostate-specific antigen, digital rectal examination, prostate ultrasonography, and magnetic resonance imaging (MRI), have evolved over the past decades, of which multiparametric (mp)MRI is clinically considered the most useful diagnostic modality to detect clinically significant prostate cancer. Accordingly, the European and American Urologic Association recommend MRI before biopsy, regardless of whether a previous prostate biopsy is conducted or not. However, before the introduction of the Prostate Imaging-Reporting and Data System (PI-RADS), the implementation and interpretation of MRI was inconsistent among institutions, and these problems began to be resolved with the introduction of PI-RADS to establish standardization in prostate mpMRI acquisition, interpretation, and reporting in 2012. In 2019, we reported the promising data of diagnostic accuracy of mpMRI with the final pathology findings for radical prostatectomy specimens in detection of prostate cancer. In this study, the sensitivity, specificity, and negative predictive value of mpMRI with PI-RADS was 75.5%, 77.0%, and 79.8% for clinically significant cancer, and 75.7%, 77.7%, and 79.5%, for pathological index tumors, respectively. Based on a meta-analysis of 21 studies (3857 patients) concerning the diagnostic performance of PI-RADS, Woo et al reported a pooled sensitivity and specificity of 0.89 (95% confidence interval [CI] 0.86–0.92) and 0.73 (95% CI 0.60–0.83), respectively. However, some studies have reported relatively poor correlation between the prostate cancer detection rate in PI-RADS 5 lesions (86.9%) and only 39.1% for category 4 lesions. This difference seems to be due to the interreader reading, which can be inferred from single-center studies and experienced radiologists generally report higher interreader agreement than multi-institution results with radiologists having variable experience levels. Recently, an interesting study suggested that even experienced radiologists showed only moderate reproducibility. This heterogeneity in the current studies result from mainly human interpretation because image acquisition and tissue confirmation are somewhat standardized now. In this issue of JMRI, Sanford et al report on the clinical application of deep-learning-based artificial intelligence (AI) for PI-RADS classifications to assist mpMRI. They introduced a deep-learning-based image classification AI system that assigns a PI-RADS score to a lesion detected and segmented by a radiologist and showed that the cancer detection rate of deep-learning-based AI was similar to an expert radiologist in classification of PI-RADS. There are some limitations to this study. First, the agreement of the AI system with the expert radiologist was only moderate (kappa 0.40), even if the expert’s analysis is not perfect. Another limitation is they did not compare the AI results with the whole-prostate mapping, because sample error should always be considered when a prostate biopsy was done. Recently, AI-based techniques have been established by examining a large number of medical images (called “radiomics”) as a possible alternative to traditional “human” interpretation and many applications of AI-based methods have been published for cancer diagnostics. However, the optimal use of AI in clinical practice, especially for detection of prostate cancer, is still ongoing. In order for AI to achieve a clear field of diagnosis, a well-organized, prospective study with a large number of patients in collaboration with radiologists, pathologists, and urologists is required.","",""
0,"David A. Hindin","Artificial Intelligence and Machine Learning: Implications for Surgery",2020,"","","","",77,"2022-07-13 09:22:08","","10.1007/978-3-030-49100-0_23","","",,,,,0,0.00,0,1,2,"","",""
14,"Derek J. Van Booven, M. Kuchakulla, Raghav Pai, F. Frech, Reshna Ramasahayam, P. Reddy, M. Parmar, R. Ramasamy, H. Arora","A Systematic Review of Artificial Intelligence in Prostate Cancer",2021,"","","","",78,"2022-07-13 09:22:08","","10.2147/RRU.S268596","","",,,,,14,14.00,2,9,1,"Abstract The diagnosis and management of prostate cancer involves the interpretation of data from multiple modalities to aid in decision making. Tools like PSA levels, MRI guided biopsies, genomic biomarkers, and Gleason grading are used to diagnose, risk stratify, and then monitor patients during respective follow-ups. Nevertheless, diagnosis tracking and subsequent risk stratification often lend itself to significant subjectivity. Artificial intelligence (AI) can allow clinicians to recognize difficult relationships and manage enormous data sets, which is a task that is both extraordinarily difficult and time consuming for humans. By using AI algorithms and reducing the level of subjectivity, it is possible to use fewer resources while improving the overall efficiency and accuracy in prostate cancer diagnosis and management. Thus, this systematic review focuses on analyzing advancements in AI-based artificial neural networks (ANN) and their current role in prostate cancer diagnosis and management.","",""
6,"Wilfried Niehueser, G. Boak","Introducing artificial intelligence into a human resources function",2020,"","","","",79,"2022-07-13 09:22:08","","10.1108/ict-10-2019-0097","","",,,,,6,3.00,3,2,2," Purpose The purpose of this paper is to examine the attitudes of employees in a company dedicated to strategic recruitment towards the introduction of artificial intelligence (AI) into their work processes and to consider the implications for training and development.   Design/methodology/approach Semi-structured interviews were carried out with seven employees who were using the new technology. Survey data was gathered from 109 employees who had not, at the time of the research, used the new technology.   Findings The introduction of AI considerably improved the speed and efficiency of the work processes. The research found that those employees who had used the new technology were positive about its effects, indicating that it was easy to use, robust and highly productive. A proportion of employees who had not, at the time of the research, used the new system, were less sure that it would improve their ability to do their job. Implications for introducing such a system and for employee training are discussed.   Research limitations/implications This is a relatively small sample in one organisation; further research should be undertaken to assess whether these findings apply more widely.   Practical implications If these attitudes are found elsewhere, there are a number of simple, practical suggestions for how to introduce AI into similar work processes.   Originality/value The use of AI is a topic attracting increasing interest and speculation, but there is as yet little empirical research on factors affecting its introduction and use. ","",""
9,"J. Sung, C. Stewart, B. Freedman","Artificial intelligence in health care: preparing for the fifth Industrial Revolution",2020,"","","","",80,"2022-07-13 09:22:08","","10.5694/mja2.50755","","",,,,,9,4.50,3,3,2,"AI comprises any digital system “that mimics human reasoning capabilities, including pattern recognition, abstract reasoning and planning”.1 It includes the concept of machine learning, where machines are able to learn from experience in ways that mimic human behaviour, but with the ability to assimilate much more data and with potential for greater accuracy and speed. Machine learning is a research field that has seen recent advances due to exponential increases in computing power (a phenomenon known as Moore’s law), algorithmic coding that mimics the human cognitive process (deep learning), and access to large, linked sources of big data. The scope of AI can be specific, performing narrowly defined tasks (narrow AI) such as image interpretation, or more general, applying knowledge and skills in different contexts (general AI) such as making a diagnosis and predicting disease outcome. On the other hand, machine learning can also be designated “supervised”, in which a dataset is provided for the algorithm to evaluate its performance, or “unsupervised”, in which the machine is allowed to extract unknown potential features in developing an algorithm.","",""
3,"E. Sala, Stephan Ursprung","Artificial Intelligence in Radiology: The Computer's Helping Hand Needs Guidance.",2020,"","","","",81,"2022-07-13 09:22:08","","10.1148/ryai.2020200207","","",,,,,3,1.50,2,2,2,"A intelligence (AI) is not entirely new to the medical field. We are accustomed to applying tools that have been developed with a varying degree of human and computer input in our clinical practice. Representative examples include handcrafted diagnostic algorithms to triage patients presenting with acute illness (1), statistically derived scores for osteoporotic fracture risk assessment (2), and decision trees for the differentiation of benign and malignant ovarian masses (3). Common to all these tools is that changes to input parameters lead to predictable changes in model output, making them easy to interrogate and understand. More sophisticated, deep learning (DL)–based models employed in decision support systems have been implemented in clinical practice for the automated interpretation of electrocardiograms (4) and detection and classification of lesions on mammography (5). Although DL-based models have exciting potential to solve complex problems, their black box approach faces skepticism despite advances in interpretability and explainability (6). The recent, widespread availability of hardware and software for the development of AI solutions for medicine has inspired an exponential increase in publications. Data-rich medical specialties such as radiology have become a particular focus of rapid development. However, there are ample scope and encouraging initiatives for AI to support the delivery of care from general practice, primary care, the emergency department, and specialist diagnostics to patient self-care (7). This study by Tadavarthi and colleagues (8) has examined the market of AI-enabled image analysis solutions for radiology and provides recommendations for the evaluation of AI tools before purchase. In their market study, the authors illustrate how most solutions are focused on highvolume conditions. Unsurprisingly, many solutions focus on support for lesion detection and quantification rather than decision support for diagnosis and recommendations for management where regulatory stakes and hurdles are higher. Yet only a minority of solutions advertised at the Radiological Society of North America and Society of Imaging Informatics in Medicine annual meetings between November 2016 and June 2019 have received approval for the American or European market. This finding is indicative of a rapidly developing field where, after years of purely scientific development, the first tools start undergoing consolidation, approval, and marketing. The sole focus on solutions advertised at North American conferences risks missing tools by smaller companies with lower marketing budgets and introducing a geographic bias. Indeed, several other solutions have achieved Conformité Européenne marking or U.S. Food and Drug Administration (FDA) approval. Such approval or their equivalent in other territories is a precondition for the implementation of products, but it is by no means sufficient to identify clinically beneficial and financially viable tools. Overall, the adoption of these algorithms into clinical practice is emerging, and further work is needed to transform the scientific enthusiasm for developing advanced AI tools with a broader scope into clinically workable solutions. For tracking the ongoing market, surveys like this study (dating from November 2019) date quickly, leaving a gap for a living review and other market watchers. Tadavarthi et al contribute to a growing number of recommendations for the acquisition and adoption of AI solutions in medicine with a particular focus on radiology (9). They raise important considerations to determine whether an AI tool is a viable solution for an individual service. In addition, one might want to consider the following criteria: Artificial Intelligence in Radiology: The Computer’s Helping Hand Needs Guidance","",""
1,"A. Waheed, A. K, H. M","ASSESSING THE ROLE OF ARTIFICIAL INTELLIGENCE IN THE DESIGN OF DRUG DELIVERY SYSTEMS",2020,"","","","",82,"2022-07-13 09:22:08","","10.32553/ijmsdr.v4i12.725","","",,,,,1,0.50,0,3,2,"Over ten years, increasing the interest has been fascinated towards the appeal of intelligent retrieval (IR) technology for data interpretation and illuminate the biological or transmitted information, speed up drug invention, and pinpointing of the selective small-molecule modulator control or rare particle and projection of their behavior. To make use of biomaterials, synthetic resin, fats, along IR is upcoming for the manufacture of drug deliverables. The request of the computerized workflows and databases for quick calculation of the vast amounts of data and artificial neural networks (ANNs) for growth of the narrative proposition and treatment schemes, forecast of disease development, and judgment of the pharmacological description of drug candidates may consequently improve treatment outcomes. Target fishing (TG) by quick projection or identification of the biological quarry might be of great help for linking quarry to the new substance.AI and TF methods in union with human knowledge may indeed transform the present-day diagnostic strategies, meanwhile verifying approaches are necessary to overcome the possible challenges and make certain higher perfection. In this review, the importance of AI and TF in the growth of drugs and transport systems and the possible challenging topics have been spotlighted.","",""
7,"Efrén Pérez Santín, Raquel Rodríguez Solana, María de las Nieves González García, M. D. García Suárez, Gerardo David Blanco Díaz, María Dolores Cima Cabal, J. Moreno Rojas, J. I. López Sánchez","Toxicity prediction based on artificial intelligence: A multidisciplinary overview",2021,"","","","",83,"2022-07-13 09:22:08","","10.1002/wcms.1516","","",,,,,7,7.00,1,8,1,"The use and production of chemical compounds are subjected to strong legislative pressure. Chemical toxicity and adverse effects derived from exposure to chemicals are key regulatory aspects for a multitude of industries, such as chemical, pharmaceutical, or food, due to direct harm to humans, animals, plants, or the environment. Simultaneously, there are growing demands on the authorities to replace traditional in vivo toxicity tests carried out on laboratory animals (e.g., European Union REACH/3R principles, Tox21 and ToxCast by the U.S. government, etc.) with in silica computational models. This is not only for ethical aspects, but also because of its greater economic and time efficiency, as well as more recently because of their superior reliability and robustness than in vivo tests, mainly since the entry into the scene of artificial intelligence (AI)‐based models, promoting and setting the necessary requirements that these new in silico methodologies must meet. This review offers a multidisciplinary overview of the state of the art in the application of AI‐based methodologies for the fulfillment of regulatory‐related toxicological issues.","",""
1,"Giampaolo Collecchia","[Human and artificial intelligence: comparison and clash of cultures].",2018,"","","","",84,"2022-07-13 09:22:08","","10.1702/3080.30726","","",,,,,1,0.25,1,1,4,". Human and artificial intelligence: comparison and clash of cultures. Machine learning has become ubiquitous and indispensible for solving complex problems in most sciences. As patients' conditions and medical technologies become more complex, its role will continue to grow. However the risk is of over reliance on these systems: no amount of algorithmic finesse or computing power can squeeze out information that is not present. In fact, clinical data alone have relatively limited predictive power for hospital readmissions that may have more to do with social determinants of health. Combining machine-learning software with the clinical judgement and a wise interpretation of information from health care professionals will help to increase the integration between digital world and real practice.","",""
167,"C. Langlotz, Bibb Allen, B. Erickson, Jayashree Kalpathy-Cramer, K. Bigelow, T. Cook, A. Flanders, M. Lungren, D. Mendelson, J. Rudie, Ge Wang, K. Kandarpa","A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop.",2019,"","","","",85,"2022-07-13 09:22:08","","10.1148/radiol.2019190613","","",,,,,167,55.67,17,12,3,"Imaging research laboratories are rapidly creating machine learning systems that achieve expert human performance using open-source methods and tools. These artificial intelligence systems are being developed to improve medical image reconstruction, noise reduction, quality assurance, triage, segmentation, computer-aided detection, computer-aided classification, and radiogenomics. In August 2018, a meeting was held in Bethesda, Maryland, at the National Institutes of Health to discuss the current state of the art and knowledge gaps and to develop a roadmap for future research initiatives. Key research priorities include: 1, new image reconstruction methods that efficiently produce images suitable for human interpretation from source data; 2, automated image labeling and annotation methods, including information extraction from the imaging report, electronic phenotyping, and prospective structured image reporting; 3, new machine learning methods for clinical imaging data, such as tailored, pretrained model architectures, and federated machine learning methods; 4, machine learning methods that can explain the advice they provide to human users (so-called explainable artificial intelligence); and 5, validated methods for image de-identification and data sharing to facilitate wide availability of clinical imaging data sets. This research roadmap is intended to identify and prioritize these needs for academic research laboratories, funding agencies, professional societies, and industry.","",""
8,"Imran Ahmed, Gwanggil Jeon, F. Piccialli","From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where",2022,"","","","",86,"2022-07-13 09:22:08","","10.1109/tii.2022.3146552","","",,,,,8,8.00,3,3,1,"Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications.","",""
10,"Bo Zhao, Shaozeng Zhang, Chunxue Xu, Yifan Sun, Chengbin Deng","Deep fake geography? When geospatial data encounter Artificial Intelligence",2021,"","","","",87,"2022-07-13 09:22:08","","10.1080/15230406.2021.1910075","","",,,,,10,10.00,2,5,1,"ABSTRACT The developing convergence of Artificial Intelligence and GIScience has raised a concern on the emergence of deep fake geography and its potentials in transforming human perception of the geographic world. Situating fake geography under the context of modern cartography and GIScience, this paper presents an empirical study to dissect the algorithmic mechanism of falsifying satellite images with non-existent landscape features. To demonstrate our pioneering attempt at deep fake detection, a robust approach is then proposed and evaluated. Our proactive study warns of the emergence and proliferation of deep fakes in geography just as “lies” in maps. We suggest timely detections of deep fakes in geospatial data and proper coping strategies when necessary. More importantly, it is encouraged to cultivate a critical geospatial data literacy and thus to understand the multi-faceted impacts of deep fake geography on individuals and human society.","",""
0,"Olivia M. Brown, B. Dillman","Proceedings of the Robust Artificial Intelligence System Assurance (RAISA) Workshop 2022",2022,"","","","",88,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,2,1,"The Robust Artificial Intelligence System Assurance (RAISA) workshop will focus on research, development and application of robust artificial intelligence (AI) and machine learning (ML) systems. Rather than studying robustness with respect to particular ML algorithms, our approach will be to explore robustness assurance at the system architecture level, during both development and deployment, and within the human-machine teaming context. While the research community is converging on robust solutions for individual AI models in specific scenarios, the problem of evaluating and assuring the robustness of an AI system across its entire life cycle is much more complex. Moreover, the operational context in which AI systems are deployed necessitates consideration of robustness and its relation to principles of fairness, privacy, and explainability.","",""
0,"Ethan Stahl, Steven L. Blumer","A Basic Primer of Artificial Intelligence for Radiologists",2022,"","","","",89,"2022-07-13 09:22:08","","10.1097/01.CDR.0000804996.57509.75","","",,,,,0,0.00,0,2,1,"Artificial intelligence (AI) comprises computer systems that behave in ways previously thought to require human intelligence.1 AI and related technologies are increasingly prevalent in business and society and are beginning to be applied to health care.2 Within health care, AI has increasingly influenced the field of radiology, and its role is likely only to grow in the future. Within radiology, AI has demonstrated benefits in the areas of image analysis and interpretation, various noninterpretive domains, and resident training. And yet, AI remains vaguely and incompletely understood by a great many practicing radiologists, radiology residents, and students considering a career in radiology. The purpose of this article is to describe the primary current and potential future applications of AI to the field of radiology and to define some of the key terms used in discussions of AI. This article is meant to provide readers with a clear, foundational understanding of AI in radiology and to equip radiologists with literacy and fluency in the AI lexicon.","",""
10,"David A. Broniatowski","Psychological Foundations of Explainability and Interpretability in Artificial Intelligence",2021,"","","","",90,"2022-07-13 09:22:08","","10.6028/NIST.IR.8367","","",,,,,10,10.00,10,1,1,"In this paper, we make the case that interpretability and explainability are distinct requirements for machine learning systems. To make this case, we provide an overview of the literature in experimental psychology pertaining to interpretation (especially of numerical stimuli) and comprehension. We find that interpretation refers to the ability to contextualize a model’s output in a manner that relates it to the system’s designed functional purpose, and the goals, values, and preferences of end users. In contrast, explanation refers to the ability to accurately describe the mechanism, or implementation, that led to an algorithm’s output, often so that the algorithm can be improved in some way. Beyond these definitions, our review shows that humans differ from one another in systematic ways, that affect the extent to which they prefer to make decisions based on detailed explanations versus less precise interpretations. These individual differences, such as personality traits and skills, are associated with their abilities to derive meaningful interpretations from precise explanations of model output. This implies that system output should be tailored to different types of users.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",91,"2022-07-13 09:22:08","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
8,"R. D. Bülow, Daniel Dimitrov, P. Boor, J. Sáez-Rodríguez","How will artificial intelligence and bioinformatics change our understanding of IgA Nephropathy in the next decade?",2021,"","","","",92,"2022-07-13 09:22:08","","10.1007/s00281-021-00847-y","","",,,,,8,8.00,2,4,1,"","",""
6,"A. Allam, S. Feuerriegel, M. Rebhan, M. Krauthammer","Analyzing Patient Trajectories With Artificial Intelligence.",2021,"","","","",93,"2022-07-13 09:22:08","","10.2196/29812","","",,,,,6,6.00,2,4,1,"In digital medicine, patient data typically record health events over time (eg, through electronic health records, wearables, or other sensing technologies) and thus form unique patient trajectories. Patient trajectories are highly predictive of the future course of diseases and therefore facilitate effective care. However, digital medicine often uses only limited patient data, consisting of health events from only a single or small number of time points while ignoring additional information encoded in patient trajectories. To analyze such rich longitudinal data, new artificial intelligence (AI) solutions are needed. In this paper, we provide an overview of the recent efforts to develop trajectory-aware AI solutions and provide suggestions for future directions. Specifically, we examine the implications for developing disease models from patient trajectories along the typical workflow in AI: problem definition, data processing, modeling, evaluation, and interpretation. We conclude with a discussion of how such AI solutions will allow the field to build robust models for personalized risk scoring, subtyping, and disease pathway discovery.","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",94,"2022-07-13 09:22:08","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",95,"2022-07-13 09:22:08","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
13,"R. Iezzi, S. Goldberg, B. Merlino, A. Posa, V. Valentini, R. Manfredi","Artificial Intelligence in Interventional Radiology: A Literature Review and Future Perspectives",2019,"","","","",96,"2022-07-13 09:22:08","","10.1155/2019/6153041","","",,,,,13,4.33,2,6,3,"The term “artificial intelligence” (AI) includes computational algorithms that can perform tasks considered typical of human intelligence, with partial to complete autonomy, to produce new beneficial outputs from specific inputs. The development of AI is largely based on the introduction of artificial neural networks (ANN) that allowed the introduction of the concepts of “computational learning models,” machine learning (ML) and deep learning (DL). AI applications appear promising for radiology scenarios potentially improving lesion detection, segmentation, and interpretation with a recent application also for interventional radiology (IR) practice, including the ability of AI to offer prognostic information to both patients and physicians about interventional oncology procedures. This article integrates evidence-reported literature and experience-based perceptions to assist not only residents and fellows who are training in interventional radiology but also practicing colleagues who are approaching to locoregional mini-invasive treatments.","",""
13,"Enrico W. Coiera","The Price of Artificial Intelligence",2019,"","","","",97,"2022-07-13 09:22:08","","10.1055/s-0039-1677892","","",,,,,13,4.33,13,1,3,"Summary Introduction : Whilst general artificial intelligence (AI) is yet to appear, today’s narrow AI is already good enough to transform much of healthcare over the next two decades. Objective : There is much discussion of the potential benefits of AI in healthcare and this paper reviews the cost that may need to be paid for these benefits, including changes in the way healthcare is practiced, patients are engaged, medical records are created, and work is reimbursed. Results : Whilst AI will be applied to classic pattern recognition tasks like diagnosis or treatment recommendation, it is likely to be as disruptive to clinical work as it is to care delivery. Digital scribe systems that use AI to automatically create electronic health records promise great efficiency for clinicians but may lead to potentially very different types of clinical records and workflows. In disciplines like radiology, AI is likely to see image interpretation become an automated process with diminishing human engagement. Primary care is also being disrupted by AI-enabled services that automate triage, along with services such as telemedical consultations. This altered future may necessarily see an economic change where clinicians are increasingly reimbursed for value, and AI is reimbursed at a much lower cost for volume. Conclusion : AI is likely to be associated with some of the biggest changes we will see in healthcare in our lifetime. To fully engage with this change brings promise of the greatest reward. To not engage is to pay the highest price.","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",98,"2022-07-13 09:22:08","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",99,"2022-07-13 09:22:08","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
5,"Y. Yoon, Sekeun Kim, Hyuk-Jae Chang","Artificial Intelligence and Echocardiography",2021,"","","","",100,"2022-07-13 09:22:08","","10.4250/jcvi.2021.0039","","",,,,,5,5.00,2,3,1,"Artificial intelligence (AI) is evolving in the field of diagnostic medical imaging, including echocardiography. Although the dynamic nature of echocardiography presents challenges beyond those of static images from X-ray, computed tomography, magnetic resonance, and radioisotope imaging, AI has influenced all steps of echocardiography, from image acquisition to automatic measurement and interpretation. Considering that echocardiography often is affected by inter-observer variability and shows a strong dependence on the level of experience, AI could be extremely advantageous in minimizing observer variation and providing reproducible measures, enabling accurate diagnosis. Currently, most reported AI applications in echocardiographic measurement have focused on improved image acquisition and automation of repetitive and tedious tasks; however, the role of AI applications should not be limited to conventional processes. Rather, AI could provide clinically important insights from subtle and non-specific data, such as changes in myocardial texture in patients with myocardial disease. Recent initiatives to develop large echocardiographic databases can facilitate development of AI applications. The ultimate goal of applying AI to echocardiography is automation of the entire process of echocardiogram analysis. Once automatic analysis becomes reliable, workflows in clinical echocardiographic will change radically. The human expert will remain the master controlling the overall diagnostic process, will not be replaced by AI, and will obtain significant support from AI systems to guide acquisition, perform measurements, and integrate and compare data on request.","",""
4,"C. Mallio, C. Quattrocchi, B. Beomonte Zobel, P. Parizel","Artificial intelligence, chest radiographs, and radiology trainees: a powerful combination to enhance the future of radiologists?",2021,"","","","",101,"2022-07-13 09:22:08","","10.21037/qims-20-1306","","",,,,,4,4.00,1,4,1,"Quant Imaging Med Surg 2021;11(5):2204-2207 | http://dx.doi.org/10.21037/qims-20-1306 Work overload has become a major challenge for radiologists. The increasing demands upon radiologists’ time, expertise and energy depend not only on the absolute number of imaging examinations to be performed and reported (i.e., number of patients), but also on the progressively growing complexity of imaging datasets, in terms of the number of images to be analyzed, as well as the quality of information to be processed, especially in the case of advanced imaging examinations that require post-processing and detailed interpretation (1-3). Artificial intelligence (AI) is a breakthrough innovation involving computer-based algorithms tailored to analyze complex datasets (4,5). Moreover, AI is emerging as a potential game changer in many fields. In medical imaging for instance, AI showed promising results for lesion detection and quantification over a wide spectrum of clinical conditions, as well as speeding up workflows, improving accuracy, addressing resource scarcity, and reducing the costs of care (4-7). The most promising subset of AI is the so-called deep learning algorithm, in which the term “deep” is due to the artificial neural network architecture composed by multiple layers (8,9). To be effective as representative learning applications, deep learning algorithms require large amounts of imaging data for training. These models, that are able to automatically learn, and then label, features on archetypal images, have been shown to robustly mirror or even outperform humans in task-specific applications in some cases? (8-10). AI and deep learning are currently being tested for imaging processing in several anatomical regions and various clinical scenarios, including disorders of the chest (7,8). In this context, we read with great interest the recently published paper by Wu et al. (7), investigating the performance of AI model and human third-year radiology residents in interpreting chest radiographs. The novel deep learning AI algorithm that they tested was extensively trained with a large image database (i.e., 342,126 frontal chest radiographs), acquired at the emergency departments (ED) and urgent care settings in multiple hospitals. Anteroposterior (AP) and postero-anterior (PA) images were used to train the model, despite the comparison AI vs. human radiology residents was based on AP images only. Interestingly, the major results of the study showed no significant difference between the performance of the AI algorithm and human radiology residents in terms of sensitivity (P=0.66); however, specificity [reported for AI 0.980 (95% CI, 0.980–0.981)] and positive predictive value [reported for AI 0.730 (95% CI, 0.718–0.742)] showed statistically significant greater results for the AI algorithm (both with P<0.001). This work, based on the “humble” but impactful chest radiograph, which represents the most commonly performed imaging examination, is of seminal importance at least for three good reasons (7). Firstly, the authors demonstrated Editorial Commentary","",""
2,"Anjan Gudigar, Sneha Nayak, Jyothi Samanth, U. Raghavendra, A. A. J., P. Barua, Md Nazmul Hasan, E. Ciaccio, R. Tan, U. Rajendra Acharya","Recent Trends in Artificial Intelligence-Assisted Coronary Atherosclerotic Plaque Characterization",2021,"","","","",102,"2022-07-13 09:22:08","","10.3390/ijerph181910003","","",,,,,2,2.00,0,10,1,"Coronary artery disease is a major cause of morbidity and mortality worldwide. Its underlying histopathology is the atherosclerotic plaque, which comprises lipid, fibrous and—when chronic—calcium components. Intravascular ultrasound (IVUS) and intravascular optical coherence tomography (IVOCT) performed during invasive coronary angiography are reference standards for characterizing the atherosclerotic plaque. Fine image spatial resolution attainable with contemporary coronary computed tomographic angiography (CCTA) has enabled noninvasive plaque assessment, including identifying features associated with vulnerable plaques known to presage acute coronary events. Manual interpretation of IVUS, IVOCT and CCTA images demands scarce physician expertise and high time cost. This has motivated recent research into and development of artificial intelligence (AI)-assisted methods for image processing, feature extraction, plaque identification and characterization. We performed parallel searches of the medical and technical literature from 1995 to 2021 focusing respectively on human plaque characterization using various imaging modalities and the use of AI-assisted computer aided diagnosis (CAD) to detect and classify atherosclerotic plaques, including their composition and the presence of high-risk features denoting vulnerable plaques. A total of 122 publications were selected for evaluation and the analysis was summarized in terms of data sources, methods—machine versus deep learning—and performance metrics. Trends in AI-assisted plaque characterization are detailed and prospective research challenges discussed. Future directions for the development of accurate and efficient CAD systems to characterize plaque noninvasively using CCTA are proposed.","",""
0,"B. Kotiv, Igor A. Budko, Igor A. Ivanov, I. U. Trosko","Artificial intelligence using for medical diagnosis via implementation of expert systems",2021,"","","","",103,"2022-07-13 09:22:08","","10.17816/brmma63657","","",,,,,0,0.00,0,4,1,"Modern biomedical technologies development affords to provide the doctor with colossal amount of information about patients organism condition. However, the opportunity of using this data for medical diagnosis fully now is a distantive perspective only. The reason is a humans limited ability in assessment and interpretation this data arrays. The solution seems in artificial intelligence and expert systems wide introduction to medicine. Currently, almost all authors consider various options for constructing artificial neural networks as a way to implement artificial intelligence. This approach, which goes back to the fundamental theorem of A.N. Kolmogorov, the works of V.I. Arnold and Hecht-Nielsen [3], demonstrates excellent capabilities in a number of pattern recognition problems, which are reduced to revealing hidden details against the background of input noises. Much less often is mentioned such a method of modeling formal thinking as expert systems, which arose in the 1960s and then went into the shadows. Since the inception of cybernetics, computer programmers have tried to reproduce the mechanism of human thinking, that is, the task was to teach the computer to ""think"". The first known results in the field of creating and using intelligent systems were laid by the work of Norbert Wiener and G.S. Altshuller. At the same time, the creation of intelligent systems was reduced to the development of programs that solve problems using a variety of heuristic methods based on the property of human thinking to generalize.","",""
0,"T. Kronivets, Ye Tymoshenko, O. Diachenko, N. Ivanchenko, S. Iasechko","Artificial Intelligence as A Key Element of Digital Education",2021,"","","","",104,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,5,1,"Summary The article proposes a typology of the goals of using AI systems, understanding education (education as a system, education as a process, education as a result) and corresponding to significant trends in the development of education (increasing flexibility and decentralization of the global education system, personalization of the education process, digital fixation of competence-based educational outcomes). The article describes that in relation to the systemic aspect of education, AI technologies will be able to bring education management closer to the use of methods based on a significant amount of qualitative data and contribute to the formation of evidence-based educational policy. It is shown that problems with the interpretation of the decision-making model in administration directly affect the assessment of the effectiveness of artificial intelligence support for managerial decisions in the educational sphere. It is shown that the process of teaching and upbringing can be personalized and individualized with the support of AI through the formation of individual educational programs content, by the educational environment; methodological support of training courses; increasing the motivation and involvement of students. The transformation of models of interaction between educational subjects is ambiguous in terms of the impact on the autonomy and responsibility of the subjects, on the results of socialization and upbringing, on the labor intensity and transparency of the educational process, including in the light of the prospects for the emergence of ""human-AI"" systems as a trained agent. In the effective aspect of education, it was revealed that AI is attractive as a tool for monitoring and recording educational achievements and expended resources, capable of clarifying the links between educational activities and results.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",105,"2022-07-13 09:22:08","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
13,"Yuanbin Wang, P. Zheng, Tao Peng, Huayong Yang, J. Zou","Smart additive manufacturing: Current artificial intelligence-enabled methods and future perspectives",2020,"","","","",106,"2022-07-13 09:22:08","","10.1007/s11431-020-1581-2","","",,,,,13,6.50,3,5,2,"","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",107,"2022-07-13 09:22:08","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",108,"2022-07-13 09:22:08","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
27,"E. Mekov, M. Miravitlles, R. Petkov","Artificial intelligence and machine learning in respiratory medicine",2020,"","","","",109,"2022-07-13 09:22:08","","10.1080/17476348.2020.1743181","","",,,,,27,13.50,9,3,2,"ABSTRACT Introduction The application of artificial intelligence (AI) and machine learning (ML) in medicine and in particular in respiratory medicine is an increasingly relevant topic. Areas covered We aimed to identify and describe the studies published on the use of AI and ML in the field of respiratory diseases. The string ‘(((pulmonary) OR respiratory)) AND ((artificial intelligence) OR machine learning)’ was used in PubMed as a search strategy. The majority of studies identified corresponded to the area of chronic obstructive pulmonary disease (COPD), in particular to COPD and chest computed tomography scans, interpretation of pulmonary function tests, exacerbations and treatment. Another field of interest is the application of AI and ML to the diagnosis of interstitial lung disease, and a few other studies were identified on the fields of mechanical ventilation, interpretation of images on chest X-ray and diagnosis of bronchial asthma. Expert opinion ML may help to make clinical decisions but will not replace the physician completely. Human errors in medicine are associated with large financial losses, and many of them could be prevented with the help of AI and ML. AI is particularly useful in the absence of conclusive evidence of decision-making.","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",110,"2022-07-13 09:22:08","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",111,"2022-07-13 09:22:08","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
4,"D. Herman, D. Rhoads, W. Schulz, T. Durant","Artificial Intelligence and Mapping a New Direction in Laboratory Medicine: A Review.",2021,"","","","",112,"2022-07-13 09:22:08","","10.1093/clinchem/hvab165","","",,,,,4,4.00,1,4,1,"BACKGROUND Modern artificial intelligence (AI) and machine learning (ML) methods are now capable of completing tasks with performance characteristics that are comparable to those of expert human operators. As a result, many areas throughout healthcare are incorporating these technologies, including in vitro diagnostics and, more broadly, laboratory medicine. However, there are limited literature reviews of the landscape, likely future, and challenges of the application of AI/ML in laboratory medicine.   CONTENT In this review, we begin with a brief introduction to AI and its subfield of ML. The ensuing sections describe ML systems that are currently in clinical laboratory practice or are being proposed for such use in recent literature, ML systems that use laboratory data outside the clinical laboratory, challenges to the adoption of ML, and future opportunities for ML in laboratory medicine.   SUMMARY AI and ML have and will continue to influence the practice and scope of laboratory medicine dramatically. This has been made possible by advancements in modern computing and the widespread digitization of health information. These technologies are being rapidly developed and described, but in comparison, their implementation thus far has been modest. To spur the implementation of reliable and sophisticated ML-based technologies, we need to establish best practices further and improve our information system and communication infrastructure. The participation of the clinical laboratory community is essential to ensure that laboratory data are sufficiently available and incorporated conscientiously into robust, safe, and clinically effective ML-supported clinical diagnostics.","",""
5,"J. Espinoza, C. Dupont, Aubrie O’Rourke, S. Beyhan, Pavel Morales, A. Spoering, Kirsten J Meyer, A. Chan, Yongwook Choi, W. Nierman, K. Lewis, K. Nelson","Predicting antimicrobial mechanism-of-action from transcriptomes: A generalizable explainable artificial intelligence approach",2021,"","","","",113,"2022-07-13 09:22:08","","10.1371/journal.pcbi.1008857","","",,,,,5,5.00,1,12,1,"To better combat the expansion of antibiotic resistance in pathogens, new compounds, particularly those with novel mechanisms-of-action [MOA], represent a major research priority in biomedical science. However, rediscovery of known antibiotics demonstrates a need for approaches that accurately identify potential novelty with higher throughput and reduced labor. Here we describe an explainable artificial intelligence classification methodology that emphasizes prediction performance and human interpretability by using a Hierarchical Ensemble of Classifiers model optimized with a novel feature selection algorithm called Clairvoyance; collectively referred to as a CoHEC model. We evaluated our methods using whole transcriptome responses from Escherichia coli challenged with 41 known antibiotics and 9 crude extracts while depositing 122 transcriptomes unique to this study. Our CoHEC model can properly predict the primary MOA of previously unobserved compounds in both purified forms and crude extracts at an accuracy above 99%, while also correctly identifying darobactin, a newly discovered antibiotic, as having a novel MOA. In addition, we deploy our methods on a recent E. coli transcriptomics dataset from a different strain and a Mycobacterium smegmatis metabolomics timeseries dataset showcasing exceptionally high performance; improving upon the performance metrics of the original publications. We not only provide insight into the biological interpretation of our model but also that the concept of MOA is a non-discrete heuristic with diverse effects for different compounds within the same MOA, suggesting substantial antibiotic diversity awaiting discovery within existing MOA.","",""
5,"T. Mahmood, Muhammad Owais, Kyoung Jun Noh, Hyo Sik Yoon, J. Koo, A. Haider, H. Sultan, K. Park","Accurate Segmentation of Nuclear Regions with Multi-Organ Histopathology Images Using Artificial Intelligence for Cancer Diagnosis in Personalized Medicine",2021,"","","","",114,"2022-07-13 09:22:08","","10.3390/jpm11060515","","",,,,,5,5.00,1,8,1,"Accurate nuclear segmentation in histopathology images plays a key role in digital pathology. It is considered a prerequisite for the determination of cell phenotype, nuclear morphometrics, cell classification, and the grading and prognosis of cancer. However, it is a very challenging task because of the different types of nuclei, large intraclass variations, and diverse cell morphologies. Consequently, the manual inspection of such images under high-resolution microscopes is tedious and time-consuming. Alternatively, artificial intelligence (AI)-based automated techniques, which are fast and robust, and require less human effort, can be used. Recently, several AI-based nuclear segmentation techniques have been proposed. They have shown a significant performance improvement for this task, but there is room for further improvement. Thus, we propose an AI-based nuclear segmentation technique in which we adopt a new nuclear segmentation network empowered by residual skip connections to address this issue. Experiments were performed on two publicly available datasets: (1) The Cancer Genome Atlas (TCGA), and (2) Triple-Negative Breast Cancer (TNBC). The results show that our proposed technique achieves an aggregated Jaccard index (AJI) of 0.6794, Dice coefficient of 0.8084, and F1-measure of 0.8547 on TCGA dataset, and an AJI of 0.7332, Dice coefficient of 0.8441, precision of 0.8352, recall of 0.8306, and F1-measure of 0.8329 on the TNBC dataset. These values are higher than those of the state-of-the-art methods.","",""
4,"Jack Zhang, Naveenjyote Boora, Sarah Melendez, Abhilash Rakkunedeth Hareendranathan, J. Jaremko","Diagnostic Accuracy of 3D Ultrasound and Artificial Intelligence for Detection of Pediatric Wrist Injuries",2021,"","","","",115,"2022-07-13 09:22:08","","10.3390/children8060431","","",,,,,4,4.00,1,5,1,"Wrist trauma is common in children, typically requiring radiography for diagnosis and treatment planning. However, many children do not have fractures and are unnecessarily exposed to radiation. Ultrasound performed at bedside could detect fractures prior to radiography. Modern tools including three-dimensional ultrasound (3DUS) and artificial intelligence (AI) have not yet been applied to this task. Our purpose was to assess (1) feasibility, reliability, and accuracy of 3DUS for detection of pediatric wrist fractures, and (2) accuracy of automated fracture detection via AI from 3DUS sweeps. Children presenting to an emergency department with unilateral upper extremity injury to the wrist region were scanned on both the affected and unaffected limb. Radiographs of the symptomatic limb were obtained for comparison. Ultrasound scans were read by three individuals to determine reliability. An AI network was trained and compared against the human readers. Thirty participants were enrolled, resulting in scans from fifty-five wrists. Readers had a combined sensitivity of 1.00 and specificity of 0.90 for fractures. AI interpretation was indistinguishable from human interpretation, with all fractures detected in the test set of 36 images (sensitivity = 1.0). The high sensitivity of 3D ultrasound and automated AI ultrasound interpretation suggests that ultrasound could potentially rule out fractures in the emergency department.","",""
2,"Rishikesh Bamdale, Shreejeet Sahay, V. Khandekar","Natural Human Robot Interaction Using Artificial Intelligence: A Survey",2019,"","","","",116,"2022-07-13 09:22:08","","10.1109/IEMECONX.2019.8877044","","",,,,,2,0.67,1,3,3,"In the era of Artificial Intelligence and robotics, it’s imperative to have a friendly system to communicate with robots so they can play a very crucial role in every-day human life. Human Robot Interaction is the foremost system in robotics today to verbally communicate with a robot in a natural way. The major struggle of the interactive system not only lies in how to teach robots to speak but also in helping to make them understand the meanings and real-world around us. This article reviews the current novel and inventive technologies to have a perfect and robust interactive system, also the importance of natural communication along with the evolution of robots since an early age. The process of language understanding has its large significance in human-robot communication with the rising technology of Artificial Intelligence. Reinforcement Learning also will play a bigger role in understanding the natural language for robots. This paper is concluded by discussing various pitfalls, advantages and future scopes of different technical aspects of Human Robot Interaction, with the hope to have the absolute interactive robots in near future, that humans have always dreamed of.","",""
3,"M. Charalambides, C. Flohr, P. Bahadoran, R. Matin","New international reporting guidelines for clinical trials evaluating effectiveness of artificial intelligence interventions in dermatology: strengthening the SPIRIT of robust trial reporting",2021,"","","","",117,"2022-07-13 09:22:08","","10.1111/bjd.19616","","",,,,,3,3.00,1,4,1,"AI can refer to either machine learning or deep learning 1 The potential for AI and machine learning to improve the management of skin diseases is immense Artificial intelligence (AI) can be defined simply as the ability of computers to simulate intelligent human behaviour [Extracted from the article] Copyright of British Journal of Dermatology is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission However, users may print, download, or email articles for individual use This abstract may be abridged No warranty is given about the accuracy of the copy Users should refer to the original published version of the material for the full abstract (Copyright applies to all Abstracts )","",""
1,"Sara R. Jordan","Challenges of Artificial Intelligence Review in a Soft Law Environment",2021,"","","","",118,"2022-07-13 09:22:08","","10.1109/MTS.2021.3123743","","",,,,,1,1.00,1,1,1,"<bold>If artificial intelligence (AI)</bold> lives up to the claims of journalists, futurists, and tech companies, then AI stands to disrupt the landscape of human cognition, social order, and political power. Within a week’s span, AI can be discussed in both positive and utopian terms as well as in negative, even apocalyptic, terms. On the positive side, AI is described as an extraordinarily confident and capable F-16 pilot <xref ref-type=""bibr"" rid=""ref2"">[2]</xref>, a panoptic gastroenterologist who misses no part of a colonoscopy <xref ref-type=""bibr"" rid=""ref3"">[3]</xref>, the all-seeing solution to mapping climate change affected regions <xref ref-type=""bibr"" rid=""ref4"">[4]</xref>, and a smartphone application able to show your body with 12% less fat and give dieting advice to achieve that goal <xref ref-type=""bibr"" rid=""ref5"">[5]</xref>. Conversely, in a similar one-week period, AI is described as a tool for the surveillance of a minority population <xref ref-type=""bibr"" rid=""ref6"">[6]</xref>, a technique for identifying the whereabouts of political protestors or dissidents <xref ref-type=""bibr"" rid=""ref7"">[7]</xref>, a rogue system that delivers arbitrary scores on high-stakes examinations <xref ref-type=""bibr"" rid=""ref8"">[8]</xref>, and a harbinger of decline for reasoning, resilience, and emotional intelligence <xref ref-type=""bibr"" rid=""ref9"">[9]</xref>. Each of these assertions rests on the interpretation of both basic and applied AI research that may or may not be deployed into the production environment of normal human lives.","",""
2,"Neil R. Hogan, Ethan Q Davidge, Gabriela Corabian","On the Ethics and Practicalities of Artificial Intelligence, Risk Assessment, and Race.",2021,"","","","",119,"2022-07-13 09:22:08","","10.29158/JAAPL.200116-20","","",,,,,2,2.00,1,3,1,"Artificial intelligence (AI) has been put forth as a potential means of improving and expediting violence risk assessment in forensic psychiatry. Furthermore, it has been proffered as a means of mitigating bias by replacing subjective human judgements with unadulterated data-driven predictions. A recent ethics analysis of AI-informed violence risk assessment enumerated some potential benefits, ethics concerns, and recommendations for further discussion. The current review builds on this previous work by highlighting additional important practical and ethics considerations. These include extant technology for violence risk assessment, paradigmatic concerns with the application of AI to risk assessment and management, and empirical evidence of racial bias in the criminal justice system. Emphasis is given to problems of informed consent, maleficence (e.g., the known iatrogenic effects of overly punitive sanctions), and justice (particularly racial justice). AI appears well suited to certain medical applications, such as the interpretation of diagnostic images, and may well surpass human judgement in accuracy or efficiency with respect to some important tasks. Caution is necessary, however, when applying AI to processes like violence risk assessment that do not conform clearly to simple classification paradigms.","",""
1,"Yongzhong Li, Donglai Chen, Xuejie Wu, Wen-tao Yang, Yongbing Chen","A narrative review of artificial intelligence-assisted histopathologic diagnosis and decision-making for non-small cell lung cancer: achievements and limitations.",2021,"","","","",120,"2022-07-13 09:22:08","","10.21037/jtd-21-806","","",,,,,1,1.00,0,5,1,"Objective To summarize the current evidence regarding the applications, workflow, and limitations of artificial intelligence (AI) in the management of patients pathologically-diagnosed with lung cancer.   Background Lung cancer is one of the most common cancers and the leading cause of cancer-related deaths worldwide. AI technologies have been applied to daily medical workflow and have achieved an excellent performance in predicting histopathologic subtypes, analyzing gene mutation profiles, and assisting in clinical decision-making for lung cancer treatment. More advanced deep learning for classifying pathologic images with minimal human interactions has been developed in addition to the conventional machine learning scheme.   Methods Studies were identified by searching databases, including PubMed, EMBASE, Web of Science, and Cochrane Library, up to February 2021 without language restrictions.   Conclusions A number of studies have evaluated AI pipelines and confirmed that AI is robust and efficacious in lung cancer diagnosis and decision-making, demonstrating that AI models are a useful tool for assisting oncologists in health management. Although several limitations that pose an obstacle for the widespread use of AI schemes persist, the unceasing refinement of AI techniques is poised to overcome such problems. Thus, AI technology is a promising tool for use in diagnosing and managing lung cancer.","",""
1,"T. Pillay","Artificial intelligence in pathology and laboratory medicine",2021,"","","","",121,"2022-07-13 09:22:08","","10.1136/jclinpath-2021-207682","","",,,,,1,1.00,1,1,1,"Increased healthcare demand has placed pressure on laboratory medicine to improve turnover and optimise efficiency using digitalisation, automation and artificial intelligence (AI). This will bring new challenges for the clinical laboratory. Laboratorians need to understand the utility of AI, its limitations and implementation. The management of big data requires ready access and accurate and contextual analysis. AI uses complex algorithms and data from medical and laboratory data to mimic human analysis and this requires accurate and reliable data. The role of AI in laboratory medicine is rapidly expanding owing to recognition of its potential to improve detection, laboratory workflows, decision support and reduce costs and increase efficiency. In this thematic issue on AI, we have attempted to present an overview of the uses of AI in laboratory medicine and advances in the digitalisation of pathology. Rakha et al from the University of Nottingham and Google Health provide an erudite overview of current and future applications of AI in pathology. The applications of AI in pathology range from prognostic/predictive applications to workflow and diagnostic applications to education as well as to the integration of other investigative data derived from genomics and radiology. It is clear that the trend of rapid deployment of AI will continue, but they highlight the gap between the translation process of discovery to clinical application, which they attribute to the fact that research and the clinical environment are often widely separated. The articles in this issue go to some length to highlight the areas of current and future applications in pathology. One area where digitalisation has progressed rapidly is in whole slide imaging. This allows slides to be transferred between locations. The value of digital neuropathology is illustrated in the paper in this issue by Williams and coauthors at the University of Leeds. This has also progressed towards the use of AI for interpretation of digital slides. There will be increased application of AI algorithms in the digital diagnostic workflow according to Stathonikos et al. The increased adoption of digital pathology allows the use of AI algorithms to facilitate automatic triaging and quality control along with assisted reading of whole slide images. There will be increased utilisation of diagnostic, prognostic and predictive algorithms based on AIdrive image analysis. Evans and coauthors describe the provision of highquality and costeffective histopathology to underserviced, remote areas, for example, in rural Canada, has been enabled by the application of digital pathology. Whole slide imaging has also found use in distant teaching as shown by that between the University of Toronto and the University of the West Indies. Immunohistochemistry is a technique that plays a crucial role in histopathology and traditionally the sections have been quantified visually by pathologists. This takes time and is subjective. Computer analysis offers the opportunity of standardised, quantifiable and highly reproducible scoring. The publication on ovarian cancer by Gentles et al illustrates this point elegantly and proves that automated scoring is reliable and superior to manual scoring and offers the reproducibility needed for highthroughput diagnostic applications. It is clear that cancer diagnosis will be one of the major growth areas for AI applications as with cancer being the leading cause of death and the most important obstacle to increased life expectancy. Deeplearning platforms for H&E analysis of slide are more sensitive to variations that escape the human eye and can offer improved fine tuning of disease prediction and prognostication and advancement of the goals of personalised and precision medicine. The review by Fitzgerald and coauthors examines how improved therapeutic stratification can be achieved in breast and prostate cancer using biomarkers and AI algorithms. They conclude that AI and machine learning will enhance precision oncology and ease the burden of pathologists and improve the capacity for reviewing high priority cases as well improve the quality and precision of diagnosis for patients. Bone marrow slide analysis will also benefit from machine learning and Baranova et al illustrate this with an open source learning tool for plasma cells. The quantitation of bone marrow plasma cell percentage is an important component of the diagnostic criteria for multiple myeloma. Using an open source digital pathology tool, QuPath, CD138positive bone marrow plasma cells were quantified. This was found to improve the speed and accuracy of cell counting. Big data analysis is a domain where the power of AI comes to the fore. This is particularly evident in chemical pathology where Punchoo et al provide a detailed overview of the applications of machine learning in the chemical pathology laboratory. Machine learning can be applied to diverse chemical pathology laboratory processes including clinical decision support, detection of errors, analysis of gels and discovery of biomarkers. Machine learning analysis offers the promise of rapid and standardised interpretation for digitised gel images in serum protein electrophoresis. The future is certainly bright and laboratorians and clinicians will need to be educated in the principles of machine learning in the framework of the appropriate regulatory and ethical frameworks.","",""
2,"Chiara Longoni, Andrey Fradkin, Luca Cian, Gordon Pennycook","News from Artificial Intelligence is Believed Less",2021,"","","","",122,"2022-07-13 09:22:08","","10.2139/SSRN.3787064","","",,,,,2,2.00,1,4,1,"Artificial Intelligence (AI) algorithms are now able to produce text virtually indistinguishable from text written by humans across a variety of domains. A key question, then, is whether people believe content from AI as much as content from humans. Trust in the (human generated) news media has been decreasing over time and AI is viewed as lacking human desires, and emotions, suggesting that AI news may be viewed as more accurate. Contrary to this, two preregistered experiments conducted on representative U.S. samples (combined N = 4,034) showed that people rated news produced by AI as being less accurate than news produced by humans. When news items were tagged as produced by AI (compared to a human), people were more likely to incorrectly rate them as inaccurate when they were actually true, and more likely to correctly rate them as inaccurate when they were indeed false. These results were robust to experimental paradigm (separate and joint evaluations), news item (actual veracity, age), and several respondent characteristics (e.g., political orientation). This effect is particularly important given the increasing use of AI algorithms in news production, and the associated ethical and governance pressures to disclose their use.","",""
2,"P. Kumar","Special issue on Artificial Intelligence in Engineering Education",2021,"","","","",123,"2022-07-13 09:22:08","","10.1002/cae.22398","","",,,,,2,2.00,2,1,1,"Artificial intelligence (AI) can be defined as the intelligence exhibited by machines and computers in accomplishing desired tasks in a similar way to how normal human beings think and act. Hence AI is also termed machine intelligence. For a computational system to be artificially intelligent, the system should possess the ability to understand the surrounding environment, make proper assumptions, and based on the circumstances make judicious decisions that maximize the possibilities of accomplishing goals most of the time. These AI‐enabled devices are also called Intelligent Agents. These intelligent agents use some mapping functions also termed cognitive functions, which take these environmental parameters and contextual information as inputs along with the goal to be accomplished and manipulate the right means to accomplish the targeted goal. AI can also be considered inter‐ disciplinary as it involves several other disciplines such as Machine Learning, Computer Vision, Cognitive Science, Neural Networks, Data Mining, Natural Language Processing (NLP), robotics, and mathematics. All these disciplines are related, and thereby intelligent agents are trained to understand and adapt to the surrounding environment according to the context. The use of AI spans across several applications such as Human–Computer Interaction (HCI) based smart agent development, devising smart surveillance solutions using computer vision, creating robust and stable decision making systems that can understand, evaluate, manipulate, analyze, and predict several novel patterns by processing large volumes of application data, development of multilingual systems that uses NLP to understand the language features used across the context and aid decision making and so on. Also, since its inception as an academic discipline in the 1950s, AI has grown leaps and bounds as a discipline, and its applications have stretched across several domains such as Retail and Business solutions, Manufacturing and Logistics, Automobiles, Business Analytics and Market predictions, Healthcare, Security Systems, and Education. One of the key emerging areas where extensive efforts are spent towards developing smart applications and agents is the educational domain. Gone are the days where the educational system was completely driven by humans, and the growth of AI‐enabled intelligent agents has set the tone by replacing most human work with that of smart agents. Educational systems use AI‐based agents to study the behavior of students and suggest suitable courses for them. Smart agents are nowadays deployed in classrooms for complete classroom monitoring that includes tracking attendance, monitoring classroom activities, student and staff behavior monitoring, and so on. Similarly, smart agents are deployed to scan through the contents available online and suggest suitable content to students according to the course and also according to the different levels of understanding of student fraternity. Also, computer vision‐based smart agents are deployed to study the state of mind of students when they undergo different courses and provide insightful information about their likeness towards a subject or course. This agent‐based information serves as useful information in deciding the teaching methodology and also framing of course contents. Also, smart systems play a vital role in analyzing student results and providing insightful information about student performance. Thus, it is imperative that AI has become an indispensable force to reckon with in the future forward across the educational domain. However, the major drawback in these artificially intelligent systems is that they are not always accurate with decision making and at times predict otherwise. Also, training the AI‐based agent to understand the contextual paradigm and surrounding environment is a challenge. This special issue on “Artificial Intelligence In Education” is focused on drawing original studies related to the development and refinement of smart agents that can be applied across the educational domain.","",""
5,"Shen Wang, Zhuobiao Qiao","Robust Pervasive Detection for Adversarial Samples of Artificial Intelligence in IoT Environments",2019,"","","","",124,"2022-07-13 09:22:08","","10.1109/ACCESS.2019.2919695","","",,,,,5,1.67,3,2,3,"Nowadays, artificial intelligence technologies (e.g., deep neural networks) have been used widely in the Internet of Things (IoT) to provide smart services and sensing data processing. The evolving neural network even exceeds the human cognitive level. However, the accuracy of these structures depends to some extent on the accuracy of the training data. Some well-designed generated antagonistic disturbances are sufficient to deceive model when added to images. Such attacks cause the classifiers trained by the neural network to misidentify the object and thus completely fail. On the other hand, the various existing defensive methods that have been proposed suffer from two criticisms. The first thing that bears the brunt is unsatisfactory detection rate due to low robustness toward the adversarial sample. Second, the excessive dependence on the output of specific network structure layers hinders the emergence of universal schemes. In this paper, we propose the large margin cosine estimation (LMCE) detection scheme to overcome the above shortcomings, making the detection independent and universal. We illustrate the principle of our approach and demonstrate the significance and analysis of some important parameters. Moreover, we model various types of adversarial attacks and establish proposed defense mechanisms against them and evaluate our approach from different aspects. This method has been clearly validated on a range of standard datasets including MNIST, CIFAR-10, and SVHN. The assessment strongly reflects the robustness and pervasive of this approach in the face of various white and semi-white box attacks.","",""
2,"Yi Yang, Jiasong Sun, Lu Huang","Artificial Intelligence Teaching Methods in Higher Education",2019,"","","","",125,"2022-07-13 09:22:08","","10.1007/978-3-030-29516-5_78","","",,,,,2,0.67,1,3,3,"","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",126,"2022-07-13 09:22:08","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",127,"2022-07-13 09:22:08","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
0,"Michael B Rüegsegger, M. Sommer","Deep Self-optimizing Artificial Intelligence for Tactical Analysis, Training and Optimization",2021,"","","","",128,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,2,1,"The increasing complexity of modern multi-domain conflicts has made their tactical and strategic understanding and the identification of appropriate courses of action challenging endeavours. Modelling and simulation as part of concept development and experimentation (CD&E) provide new insight at higher speed and lower cost than what physical manoeuvres can achieve. Amongst other, human-machine teaming through computer games is a powerful means of simulating defence scenarios at various abstraction levels. However, conventional human-machine interaction is time-consuming and restricted to pre-designed scenarios, e.g., in terms of pre-programmed conditional computer actions. If one side of the game could be taken by Artificial Intelligence (AI), this would increase the diversity of explored courses of actions and lead to a more robust and comprehensive analysis. If the AI plays both sides, this allows employing the Data Farming methodology and creating and analysing a database of a large number of investigated scenarios. To achieve a high degree of variability and generalization capability of the investigated scenarios, we employ combined Reinforcement Learning and search algorithms, which have demonstrated super-human performance in various complex planning problems. Such AI systems avoid the reliance on training data, human experience and predictions by learning tactics and strategy through exploration and self-optimization. In this contribution, we present the benefits and challenges of applying a Neural-Network-based Monte Carlo Tree Search algorithm for strategic planning and training in air-defence scenarios and virtual war-gaming with systems that are available currently or potentially in the future to the Swiss Armed Forces.","",""
0,"Karan Jaju, H. Thakkar","Impact of Artificial Intelligence and Internet of Things in Effective Handling of Coronavirus Crisis",2021,"","","","",129,"2022-07-13 09:22:08","","10.1007/978-981-16-2786-6_12","","",,,,,0,0.00,0,2,1,"","",""
0,"Dr. Payal K. Chandel, Siddharth Shahi","Converging Paths of Neuropsychology, Positivism and Artificial Intelligence",2021,"","","","",130,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,2,1,"There have been enormous debate upon Artificial Intelligence being a friend or foe to humankind. But a statement by Yann LeCun in which he said – “ Our intelligence is what makes us human, and AI is an extension of that quality” has very clearly pointed out that the concept of Artificial Intelligence is for the up gradation of human race and not for its end. In this paper an effort has been made to understand how Neuropsychology, Positivism and Artificial Intelligence work for a similar objective which is enhancement of human life, with so much difference within the mechanisms of these three disciplines. For this, we studied and explored a no. of articles associated with all these three domains and examined their working in order to gain a better understanding. We scrutinized some specific aspects and analyzed their behaviour in these three fields. From the review of studies it is pretty evident that AI does train the systems that can mimic human brain, carry out almost every function that a human brain does, and thus the concept of AI goes parallel to Neuropsychology, Neuroscience and the theory of Positivism which is about learning by sensation and interpretation from the environment.","",""
0,"I. Mohammed","ARTIFICIAL INTELLIGENCE: THE KEY TO SELF-DRIVING IDENTITY GOVERNANCE",2021,"","","","",131,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,1,1,"The main goal of this article is to examine how artificial intelligence is playing an increasingly important role in advancing identity governance. The speed of global digital change is accelerating, and businesses are under increasing pressure to guarantee that their technology can keep up with the times. Today's headlines often include stories about high-profile data leakage, which have a significant impact on a company's image and financial health [1]. The moment has come for businesses to invest in AIpowered identity security to remain abreast of security and compliance risks. Information technology, a shifting workforce, and an onslaught of compliance regulations have brought an unprecedented number of users, points of access, apps, and data, to the point that IT departments are struggling to stay up [1]. A human-centric approach to identity security can only scale so far, and with it comes inaccuracy in risk identification. Security requirements are becoming more complicated, decentralized, and integrated with business operations, owing to new methods of working enabled by cloud technology [2]. This implies that robust identity governance and access control are more critical than ever. In this paper, we examine the current status of the information technology environment and explain how artificial intelligence will help companies address their present issues relating to identity governance.","",""
0,"P. Bombicz","Artificial Intelligence and Machine Learning in Crystallography Editorial for Crystallography Reviews, Issue 2 of Volume27, 2021",2021,"","","","",132,"2022-07-13 09:22:08","","10.1080/0889311x.2021.2000094","","",,,,,0,0.00,0,1,1,"“Everythingwe love about civilization is a product of intelligence, so amplifying our human intelligence with artificial intelligence has the potential of helping civilization flourish like never before – as long as wemanage to keep the technology beneficial.” saidMax Tegmark, President of the Future of Life Institute [1]. There is half a century of evolution behind artificial intelligence (AI) and machine learning (ML). The exponentially developing technology can do a good job at narrow tasks for example in mathematics, modelling climate change, internet searches, facial recognition, speech recognition, driving autonomous cars, customer service, playing chess, or Facebook uses algorithms to block content that breaks its rules. It can be applied in automated stock trading, it is offered for the commercial sectors, solving business problems for public and private sectors. Science fiction often portrays artificial intelligence with human-like characteristics, which emerges conversations about the impact on society and around the ethics of AI. Artificial General or Super Intelligence is a theoretical form of AI, where it would have a self-aware consciousness that had the ability to solve problems surpassing the intelligence and capacity of the human brain. An example isHAL, the rogue computer assistant in 2001: A Space Odyssey. Back to reality, algorithms cannot understand the essence of humans: emotion, morality, culture, since these abilities cannot be expressed in mathematical equations. Artificial Intelligence enables problem-solving by the combination of computer science and robust datasets. Machine learning is the subfields of artificial intelligence. Deep learning refers to a neural network, which comprise of multiple hidden layers between the input and output layers. Machine learning and deep learning differs in the way how their algorithms learn.Machine learning ismore dependent on human intervention, what determines the hierarchy of features. A deep learning-based systemwould be able to achieve the same task in a much shorter time. MelanieVollmar andGwyndaf Evans from theDiamondLight Source Ltd., and from the Rosalind Franklin Institute, respectively, both in Harwell Science and Innovation Campus, Didcot, UK, review the “Machine learning applications in macromolecular X-ray crystallography” in Issue 2 of Volume 27 of Crystallography Reviews. We can quickly understand why introducing Artificial Intelligence is somuch investigated and needed at the Diamond Light Source reading the facts: throughout 2020 user access to MX beamlines was almost exclusively remote, in the 11 months from June 2020 over 33,000 data sets were measured, typically less than 3minutes being used for each crystal sample, the yearly quantities of measured data reach many Petabyte. We may learn from the article that AI can contribute to the question of crystallisability, to the detection of the presence of crystals in crystallisation trials, to forecast of experimental data and data analysis outcome, to have real-time","",""
0,"Nikolaos Siafakas","Do We Need a Hippocratic Oath for Artificial Intelligence Scientists?",2022,"","","","",133,"2022-07-13 09:22:08","","10.1609/aimag.v42i4.15090","","",,,,,0,0.00,0,1,1,"Artificial intelligence (AI) has been beneficial for humanity, improving many human activities. However, there are now significant dangers that may increase when AI reaches a human level of intelligence or superintelligence. It is paramount to focus on ensuring that AI is designed in a manner that is robustly beneficial for humans. The ethics and personal responsibilities of AI scientists could play an important role in continuing the constructive use of AI in the future. Lessons can be learnt from the long and successful history of medical ethics. Therefore, a Hippocratic Oath for AI scientists may increase awareness of the potential lethal threats of AI, enhance efforts to develop safe and beneficial AI to prevent corrupt practices and manipulations and invigorate ethical codes. The Hippocratic Oath in medicine, using simple universal principles, is a basis of human ethics, and in an analogous way, the proposed oath for AI scientists could enhance morality beyond biological consciousness and spread ethics across the universe.","",""
0,"Aabid Ali","Artificial Intelligence",2021,"","","","",134,"2022-07-13 09:22:08","","10.1017/9781009036719.007","","",,,,,0,0.00,0,1,1,"Artificial Intelligence may be defined as intelligence displayed by machines, systems or agents or by entities other than living beings. Apparently, the term seems simple but the definition bears deeper connotations. The terms intelligence and creativity have long been the prerogatives associated with the humans or have been the privileges enjoyed by them since the dawn of the creation. The views ‘creativity is computation’ or ‘cognition is computation’ and ‘mind as machine’ has offset the traditional theories, assumptions and interpretations held so far in the philosophy and theory of mind. AI’s push to impart intelligence to non-human entities to enable them to behave intelligently and creatively or as Boden would put it “to make computers do the sort of things that minds can do” (Boden 1) has challenged the very traditional fabric of our perception and comprehension, conception and construction related to our learning and living dispensations.","",""
9,"P. Narkhede, Rahee Walambe, Shruti Mandaokar, Pulkit Chandel, K. Kotecha, G. Ghinea","Gas Detection and Identification Using Multimodal Artificial Intelligence Based Sensor Fusion",2021,"","","","",135,"2022-07-13 09:22:08","","10.3390/asi4010003","","",,,,,9,9.00,2,6,1,"With the rapid industrialization and technological advancements, innovative engineering technologies which are cost effective, faster and easier to implement are essential. One such area of concern is the rising number of accidents happening due to gas leaks at coal mines, chemical industries, home appliances etc. In this paper we propose a novel approach to detect and identify the gaseous emissions using the multimodal AI fusion techniques. Most of the gases and their fumes are colorless, odorless, and tasteless, thereby challenging our normal human senses. Sensing based on a single sensor may not be accurate, and sensor fusion is essential for robust and reliable detection in several real-world applications. We manually collected 6400 gas samples (1600 samples per class for four classes) using two specific sensors: the 7-semiconductor gas sensors array, and a thermal camera. The early fusion method of multimodal AI, is applied The network architecture consists of a feature extraction module for individual modality, which is then fused using a merged layer followed by a dense layer, which provides a single output for identifying the gas. We obtained the testing accuracy of 96% (for fused model) as opposed to individual model accuracies of 82% (based on Gas Sensor data using LSTM) and 93% (based on thermal images data using CNN model). Results demonstrate that the fusion of multiple sensors and modalities outperforms the outcome of a single sensor.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",136,"2022-07-13 09:22:08","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",137,"2022-07-13 09:22:08","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
2,"J. Hernández-Orallo, B. S. Loe, L. Cheke, Fernando Martínez-Plumed, Seán Ó hÉigeartaigh","General intelligence disentangled via a generality metric for natural and artificial intelligence",2021,"","","","",138,"2022-07-13 09:22:08","","10.1038/s41598-021-01997-7","","",,,,,2,2.00,0,5,1,"","",""
7,"G. Porenta","Is There Value for Artificial Intelligence Applications in Molecular Imaging and Nuclear Medicine?",2019,"","","","",139,"2022-07-13 09:22:08","","10.2967/jnumed.119.227702","","",,,,,7,2.33,7,1,3,"Core competencies in molecular imaging and nuclear medicine include imaging with radioactive isotopes, pattern recognition, image interpretation, and report communication. In diagnostic imaging, nuclear medicine physicians communicate with referring physicians to establish indications for imaging studies, perform or supervise imaging procedures to obtain high-quality images, interpret images to compile medical reports, and communicate results to inform patients and their referring doctors. In many of these tasks, computers already are indispensable tools that enable or assist the work of physicians. How does artificial intelligence (AI) fit into this workflow (Fig. 1)? There is no universal definition of AI (1), but in the context of practical applications, AI can be considered a scientific discipline that uses computers to perform tasks usually requiring human cognition. Research topics on AI include pattern recognition, natural language processing, machine learning, problem solving, and knowledge representation. Thus, AI techniques apply to many core competencies in metabolic imaging and nuclear medicine, and this has led to an enormous interest and even hype about AI in medical imaging (2). AI applications at present dominate the technical exhibitions of international imaging conferences such as the 2019 European Congress of Radiology (https://ecronline.myesr.org/ecr2019/) and are prominently featured in the product portfolios of most commercial companies of medical imaging technology. AI applications have enabled a multibillion-dollar business model for the large Internet companies penetrating the consumer market in many ways, including Internet searches, social networks, or smartphone software. In consumer markets, value is measured by the willingness of a consumer to use or pay for a product. Therefore, the value of AI applications in consumer markets depends not on an intrinsic objective value but the perception of the customer. This value concept is well illustrated by a quote attributed to Charles Revson, the founder of a cosmetics company: ‘‘In the factory we make cosmetics, in the store we sell hope.’’ However, in medicine the business model and the value concept of a consumer market do not apply. Hope is essential when taking care of patients, but hope cannot serve as the foundation for medical decision making and patient stratification. Several decades ago, patients with extrasystoles after a myocardial infarction were commonly treated with antiarrhythmic drugs in the hope of preventing arrhythmic death. A large, randomized multicenter trial uncovered this hope as a deadly illusion and established that the antiarrhythmic therapy in fact increased arrhythmic mortality and caused premature death in thousands of patients. From this trial and others that were able to scientifically disprove suggested or assumed benefits based on hope and hype, rigorous and often laborious scientific methods have emerged that permit establishing, grading, or disproving the value of diagnostic and therapeutic procedures. For patients, value is generated if quality of life is improved, morbidity is reduced, or preventable mortality is eliminated. It is difficult or impossible for both patients and physicians to directly assess the value of medical products, interventions, or technology. Thus, science is essential to firmly guide patient care. International guidelines compiled by professional societies assess the value of diagnostic and therapeutic methods based on scientific evidence and, for each method, clearly state the class of recommendation for a particular use with an associated level of evidence. This science-based model of grading value for patient care has been universally adopted in the medical community. Currently, there is little scientific evidence for the value of AI applications in medical imaging. Several AI applications have received Food and Drug Administration approval (3), but this does not imply that AI applications at present are relevant for medical practice or that their value has been firmly established. Most AI applications are built from 3 essential components: complex computer algorithms, extensive computing resources, and large data sets. Algorithms and computing facilities are easily available at little or no cost. Many powerful AI algorithms are published as opensource code, such as TensorFlow (https://www.tensorflow.org) and Core ML (https://developer.apple.com/machine-learning/). Extensive computing power is offered instantaneously on demand through the large Internet companies. Recently, even smartphones have been equipped with high-power computing hardware, including neural network chips that enable intensive AI applications, such as facial identification or speech recognition. In contrast, large data sets are more difficult to collect and thus are the most critical component when building AI applications. Data are more important than hardware or software in determining the success of AI applications (4). Even highly complex AI algorithms cannot compensate for incomplete, inadequate, or low-quality data collection. Thus, the characteristics and validity of data sets need to be firmly established and made fully transparent when AI applications are investigated for a proposed clinical purpose. Collaborative efforts are frequently required to compile the large data sets, which need to include many thousands of data entries. Recently, the Mozilla Common Voice project (https://voice. mozilla.org/en) has published an open-source multilanguage data set of voice recordings from 40,000 people in 18 languages to foster and enable research in natural language processing. If AI applications are to be applied successfully in medical imaging, Received Mar. 18, 2019; revision accepted Apr. 3, 2019. For correspondence or reprints contact: Gerold Porenta, Ambulatorium Döbling, Heiligenstädterstrasse 62-64, 1190 Vienna, Austria. E-mail: gerold@porenta.com Published online May 3, 2019. COPYRIGHT© 2019 by the Society of Nuclear Medicine and Molecular Imaging. DOI: 10.2967/jnumed.119.227702","",""
11,"A. Ran, Jian Shi, Amanda K Ngai, Wai-Yin Chan, Poemen P. Chan, A. Young, Hon-Wah Yung, C. Tham, C. Cheung","Artificial intelligence deep learning algorithm for discriminating ungradable optical coherence tomography three-dimensional volumetric optic disc scans",2019,"","","","",140,"2022-07-13 09:22:08","","10.1117/1.NPh.6.4.041110","","",,,,,11,3.67,1,9,3,"Abstract. Spectral-domain optical coherence tomography (SDOCT) is a noncontact and noninvasive imaging technology offering three-dimensional (3-D), objective, and quantitative assessment of optic nerve head (ONH) in human eyes in vivo. The image quality of SDOCT scans is crucial for an accurate and reliable interpretation of ONH structure and for further detection of diseases. Traditionally, signal strength (SS) is used as an index to include or exclude SDOCT scans for further analysis. However, it is insufficient to assess other image quality issues such as off-centration, out of registration, missing data, motion artifacts, mirror artifacts, or blurriness, which require specialized knowledge in SDOCT for such assessment. We proposed a deep learning system (DLS) as an automated tool for filtering out ungradable SDOCT volumes. In total, 5599 SDOCT ONH volumes were collected for training (80%) and primary validation (20%). Other 711 and 298 volumes from two independent datasets, respectively, were used for external validation. An SDOCT volume was labeled as ungradable when SS was <5 or when any artifacts influenced the measurement circle or >25  %   of the peripheral area. Artifacts included (1) off-centration, (2) out of registration, (3) missing signal, (4) motion artifacts, (5) mirror artifacts, and (6) blurriness. An SDOCT volume was labeled as gradable when SS was ≥5, and there was an absence of any artifacts or artifacts only influenced <25  %   peripheral area but not the retinal nerve fiber layer calculation circle. We developed and validated a 3-D DLS based on squeeze-and-excitation ResNeXt blocks and experimented with different training strategies. The area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy were calculated to evaluate the performance. Heatmaps were generated by gradient-weighted class activation map. Our findings show that the presented DLS achieved a good performance in both primary and external validations, which could potentially increase the efficiency and accuracy of SDOCT volumetric scans quality control by filtering out ungradable ones automatically.","",""
2,"King-Ho Leung","The Picture of Artificial Intelligence and the Secularization of Thought",2019,"","","","",141,"2022-07-13 09:22:08","","10.1080/1462317X.2019.1605725","","",,,,,2,0.67,2,1,3,"ABSTRACT This article offers a critical interpretation of Artificial Intelligence (AI) as a philosophical notion which exemplifies a secular conception of thinking. One way in which AI notably differs from the conventional understanding of “thinking” is that, according to AI, “intelligence” or “thinking” does not necessarily require “life” as a precondition: that it is possible to have “thinking without life.” Building on Charles Taylor’s critical account of secularity as well as Hubert Dreyfus’ influential critique of AI, this article offers a theological analysis of AI’s “lifeless” picture of thinking in relation to the Augustinian conception of God as “Life itself.” Following this critical theological analysis, this article argues that AI’s notion of thinking promotes a societal privilege of certain rationalistic or calculative ways of thought over more existential or spiritual ways of thinking, and thereby fosters a secularization or de-spiritualization of thinking as an ethical human practice.","",""
2,"Jacques Biot","How will clinical practice be impacted by artificial intelligence?",2019,"","","","",142,"2022-07-13 09:22:08","","10.1684/ejd.2019.3536","","",,,,,2,0.67,2,1,3,"Currently, artificial intelligence (AI) heavily impacts all human activities, including medicine, where needs for data analysis and interpretation are high and where technology opens new perspectives. Considering that current treatments do not always cure all patients and may even harm certain of them, we have to recognize that AI may fill a great medical need, potentially supporting physicians’ efforts to refine diagnosis and to improve the relevance of the clinical diagnosis for each patient. As in other industries, this challenge implies changes in the repartition of medical and paramedical tasks. As repetitive tasks will disappear in the wake of automation, health care providers will ultimately regain truly an opportunity to focus on medicine, thereby ensuring an individual and holistic approach to each patient.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",143,"2022-07-13 09:22:08","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
2,"A. James","The Why, What, and How of Artificial General Intelligence Chip Development",2020,"","","","",144,"2022-07-13 09:22:08","","10.1109/TCDS.2021.3069871","","",,,,,2,1.00,2,1,2,"The AI chips increasingly focus on implementing neural computing at low power and cost. The intelligent sensing, automation, and edge computing applications have been the market drivers for AI chips. Increasingly, the generalisation, performance, robustness, and scalability of the AI chip solutions are compared with human-like intelligence abilities. Such a requirement to transit from application-specific to general intelligence AI chip must consider several factors. This article provides an overview of this cross-disciplinary field of study, elaborating on the generalisation of intelligence as understood in building artificial general intelligence (AGI) systems. This work presents a listing of emerging AI chip technologies, classification of edge AI implementations, and the funnel design flow for AGI chip development. Finally, the design consideration required for building an AGI chip is listed along with the methods for testing and validating it.","",""
0,"Yuejuan Jing, Jiangtao Wang","Design and Implementation of Work Evaluation Monitoring System under Artificial Intelligence Condition",2019,"","","","",145,"2022-07-13 09:22:08","","10.25236/IJNDES.19301","","",,,,,0,0.00,0,2,3,"At this stage, the development of science and technology in China is extremely fast, and the research of computer artificial intelligence technology is the best interpretation of human wisdom. The algorithm research of artificial intelligence technology continues to penetrate into various aspects. Work evaluation is a kind of human resource management technology and method to determine the relative value of positions. It shows a certain degree of scientificity and objectivity in post evaluation and salary rating. It is widely used in enterprises, but there are also many problems in its use. This paper expounds the related concepts of artificial intelligence technology and job evaluation, and then analyzes the current situation and existing problems in the evaluation of enterprise work in the context of artificial intelligence, and proposes the design and implementation of the work evaluation monitoring system, which is more for the enterprise in practice. Provide a reference for good operational evaluation.","",""
0,"H. Mcgrath, Colin Flanagan, Liaoyuan Zeng, Yiming Lei","Future of Artificial Intelligence in Anesthetics and Pain Management",2019,"","","","",146,"2022-07-13 09:22:08","","10.4236/jbm.2019.711010","","",,,,,0,0.00,0,4,3,"The potential of the second wave of Artificial Intelligence (AI) to change our lives beyond recognition is both exciting and challenging. AI has been around for over three decades, and this new approach of artificial intelligence, due to enhancements in technology, both software, and hardware, has resulted in the fact that human decision-making is considered inferior and erratic in many fields: none more so than medicine. Machine learning algorithms with access to large data sets can be trained to outperform clinicians in many respects. AI’s effectiveness in accurate diagnosis of various medical conditions and medical image interpretation is well documented. Modern AI technology has the potential to transform medicine to a level never seen before in terms of efficiency and accuracy; but is also potentially highly disruptive, creating insecurity and allowing the transfer of expert domain knowledge to machines.  Anesthetics is a complex medical discipline and assuming AI can easily replace experienced and knowledgeable medical practitioners is a very unrealistic expectation. AI can be used in anesthetics to develop, in some respects, more advanced clinical decision support tools based on machine learning. This paper focuses on the complexity of both AI developments, deep learning, neural networks, etc. and opportunities of AI in anesthetics for the future. It will review current advances in AI tools and hardware technologies as well as outlining how these can be used in the field of anesthetics.","",""
0,"E. Shekhovtsova","The topic of artificial intelligence in the anti-utopian novel by Alexander Zinoviev, “The Global Humane”: author's warnings and predictions",2019,"","","","",147,"2022-07-13 09:22:08","","10.18254/s258770110007540-6","","",,,,,0,0.00,0,1,3,"The paper considers the philosophical problems associated with the topic of artificial intelligence, raised by Alexander Zinoviev in his anti-utopia “Global humane”. An attempt is made to philosophical interpretation of the author’s meanings and assessment of the prognostic potentials of the book. The examples of anti-utopian plots examine the probability of primitivization of human intelligence in the era of a new sociopolitical and anthropological reality.","",""
7,"E. Loginov, V. Grigoriev, A. Shkuta, V. Bortalevich, D. Sorokin","The use of artificial intelligence’s elements to block the manifestations of individuals’ behavioral activity going beyond the quasi-stable states",2019,"","","","",148,"2022-07-13 09:22:08","","10.1088/1757-899X/516/1/012028","","",,,,,7,2.33,1,5,3,"The monitoring of the metastable states of individuals as a bifurcation point of development of intellectual dynamics of behavioural activity allows us to identify a set of characteristics of coherent-resonant clusters of manifestations of biophysical factors and information-cognitive nature. Conscious changes in the functioning modes of brain and human nervous system can be achieved by electromagnetic influence or purely informational influence as well as by the combined effect of both these factors. The arrangement of complex processes of informational influence is required to penetrate to the level of conscious (semantic) and unconscious (mental, emotional, meditative) interpretation of events when it is necessary to ensure sufficiently stable cognitive-behavioural stereotypes of individuals and their groups. Convergent informational and electromagnetic effects facilitate the effect on the brain, including the use of neuro-linguistic programming for this element with correction or even a complete change of the reflexive matrix (matrix of key reflexive reactions) with a corresponding change and fixation of the personality-style in the personality events to block the release of behavioural activity of individuals beyond quasi-stable states.","",""
19,"P. Mathur, S. Srivastava, Xiaowei Xu, J. Mehta","Artificial Intelligence, Machine Learning, and Cardiovascular Disease",2020,"","","","",149,"2022-07-13 09:22:08","","10.1177/1179546820927404","","",,,,,19,9.50,5,4,2,"Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",150,"2022-07-13 09:22:08","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
2,"Á. Alberich-Bayarri, A. Pastor, Rafael López González, Fabio García Castro","How to Develop Artificial Intelligence Applications",2019,"","","","",151,"2022-07-13 09:22:08","","10.1007/978-3-319-94878-2_5","","",,,,,2,0.67,1,4,3,"","",""
14,"K. Kusunose","Steps to use artificial intelligence in echocardiography",2020,"","","","",152,"2022-07-13 09:22:08","","10.1007/s12574-020-00496-4","","",,,,,14,7.00,14,1,2,"","",""
1,"B. A.","Informational Linguistics: Computer, Internet, Artificial Intelligence and Language",2019,"","","","",153,"2022-07-13 09:22:08","","","","",,,,,1,0.33,1,1,3,"Modern technological progress is clearly mediated via the informational and communicational conceptualizations, which are first of all of language nature. Interdependence and syncretism of human cognitive activity create unlimited demand for knowledge interpretation of certain semantic format – information. Informational Linguistics is a discipline, dedicated to the interdisciplinary investigation of the specifics of communication contents.","",""
3,"Pu Yanan, Yan Jilong, Zhang Heng","Using Artificial Intelligence to Achieve Auxiliary Training of Table Tennis Based on Inertial Perception Data",2021,"","","","",154,"2022-07-13 09:22:08","","10.3390/s21196685","","",,,,,3,3.00,1,3,1,"Compared with optical sensors, wearable inertial sensors have many advantages such as low cost, small size, more comprehensive application range, no space restrictions and occlusion, better protection of user privacy, and more suitable for sports applications. This article aims to solve irregular actions that table tennis enthusiasts do not know in actual situations. We use wearable inertial sensors to obtain human table tennis action data of professional table tennis players and non-professional table tennis players, and extract the features from them. Finally, we propose a new method based on multi-dimensional feature fusion convolutional neural network and fine-grained evaluation of human table tennis actions. Realize ping-pong action recognition and evaluation, and then achieve the purpose of auxiliary training. The experimental results prove that our proposed multi-dimensional feature fusion convolutional neural network has an average recognition rate that is 0.17 and 0.16 higher than that of CNN and Inception-CNN on the nine-axis non-professional test set, which proves that we can better distinguish different human table tennis actions and have a more robust generalization performance. Therefore, on this basis, we have better realized the enthusiast of table tennis the purpose of the action for auxiliary training.","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",155,"2022-07-13 09:22:08","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
1,"W. Monroe, F. Skidmore, David G. Odaibo, M. Tanik","HihO: accelerating artificial intelligence interpretability for medical imaging in IoT applications using hierarchical occlusion",2020,"","","","",156,"2022-07-13 09:22:08","","10.1007/S00521-020-05379-4","","",,,,,1,0.50,0,4,2,"","",""
2,"Karanjeet Choudhary, G. S. Gaba, R. Miglani, Lavish Kansal, Pardeep Kumar","Artificial intelligence and machine learning aided blockchain systems to address security vulnerabilities and threats in the industrial Internet of things",2021,"","","","",157,"2022-07-13 09:22:08","","10.1049/PBTE094E_CH13","","",,,,,2,2.00,0,5,1,"Advent of digital sensors and machines led to a significant acceleration in industrial evolution. The desire to automate industrial processes with minimum human intervention paved the way for the onset of a new era of technological nomenclature called the industrial Internet of things (IIoT). A remarkable feature of IIoT is its underlying architecture which allows the managers/engineers/supervisors to remotely operate and access the performance of their machines. Industries ranging from healthcare, finance, logistics, and power have witnessed a major performance increment and quality stabilization by transforming themselves into an IIoT empowered smart environment. However, this transformation has brought with itself a whole new set of challenges with cybersecurity being the paramount. The vulnerabilities like bugs and broken processes can lead to a serious compromise or even collapse of security mechanisms of IIoT networks. Such a situation will have a devastating impact on the financial health, reputation, and credibility of companies. After an extensive review of existing technologies, we believe that blockchain, artificial intelligence (AI), and machine learning (ML) can complement each other in building a revolutionary deterrent to negate malicious activities that in any form intend to harm the system. While, blockchain offers public/private/consortium relationships, ML and AI, on the other hand, follow the principle of supervised/ unsupervised/reinforcement learning and reactive/memory approaches, respectively. Based on the distributed ledger system, blockchain mechanisms can be aided with self-learning algorithms which will update and strengthen the database by learning each time the system suffers new forms of network attacks and intrusions. This process of learning will help build a robust system which can learn to optimize its deterrence procedures against different forms of attacks. It is due to these overwhelming benefits, blockchain, AI, and ML find applications in smart logistics, predictive maintenance, autonomous vehicles, intelligent manufacturing, and smart grid maintenance.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",158,"2022-07-13 09:22:08","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
2,"Thomas Garvin, Scott Kimbleton","Artificial intelligence as ally in hazard analysis",2021,"","","","",159,"2022-07-13 09:22:08","","10.1002/prs.12243","","",,,,,2,2.00,1,2,1,"Hazard analysis techniques have been around for many years, and have proven effective in the prevention of incidents and no doubt the saving of lives. Process hazard analysis (PHA) is now fairly robust and regulated, focused on overarching risks associated with the safe handling of hazardous materials and approaches to engineer‐out such risks. Occupational hazard analysis (OHA) is keenly focused on human activity, and personal protection in hazardous working conditions. Both approaches are critical ‐ but are often carried out separately, by different parts of an organization, which could result in an incomplete picture of the full set of operational risks in the field. Developing a holistic picture of both past and present dangers calls for a deep exploration of evidence. HAZOPs, PHA's, incident records and investigations provide expert analysis of hazards and mitigating strategies. Near‐miss reports and safety observations add a large amount of information as well; the reporting frequency of these “leading indicators” can be both a blessing and a curse, as time and available resources constrain the ability to analyze and detect hazard signals within. As important as analyzing the historical record is for lessons learned, the more recent observations could indicate new hazards or highlight concerning trends. These could feed valuable “real time” information back to operations and maintenance teams to improve risk assessments and task planning. Enter artificial intelligence (AI) as a means to analyze the large amount of written hazard analyses, reports and observations to quickly extract insights around hazardous conditions, activities, incident causes and risk mitigation measures. Trained to understand concepts and contexts in both process and personal safety, AI can provide a natural‐language information exploration environment for scanning thousands of documents in seconds and present common themes and related records. Not unlike us humans, AI learns from the past, informs the present and can help reduce risks in the future.","",""
2,"D. Edwards, Ciara McEnteggart, Y. Barnes-Holmes","A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",2022,"","","","",160,"2022-07-13 09:22:08","","10.3389/fpsyg.2022.745306","","",,,,,2,2.00,1,3,1,"Psychology has benefited from an enormous wealth of knowledge about processes of cognition in relation to how the brain organizes information. Within the categorization literature, this behavior is often explained through theories of memory construction called exemplar theory and prototype theory which are typically based on similarity or rule functions as explanations of how categories emerge. Although these theories work well at modeling highly controlled stimuli in laboratory settings, they often perform less well outside of these settings, such as explaining the emergence of background knowledge processes. In order to explain background knowledge, we present a non-similarity-based post-Skinnerian theory of human language called Relational Frame Theory (RFT) which is rooted in a philosophical world view called functional contextualism (FC). This theory offers a very different interpretation of how categories emerge through the functions of behavior and through contextual cues, which may be of some benefit to existing categorization theories. Specifically, RFT may be able to offer a novel explanation of how background knowledge arises, and we provide some mathematical considerations in order to identify a formal model. Finally, we discuss much of this work within the broader context of general semantic knowledge and artificial intelligence research.","",""
0,"Joe Hays, S. Ramamoorthy, Christian Tetzlaff","Editorial: Robust Artificial Intelligence for Neurorobotics",2021,"","","","",161,"2022-07-13 09:22:08","","10.3389/fnbot.2021.809903","","",,,,,0,0.00,0,3,1,"Neural computing is a powerful paradigm that has revolutionized machine learning. Building from early roots in the study of adaptive behavior and attempts to understand information processing in parallel and distributed neural architectures, modern neural networks have convincingly demonstrated successes in numerous areas—transforming the practice of computer vision, natural language processing, and even computational biology. Applications in robotics bring stringent constraints on size, weight and power constraints (SWaP), which challenge the developers of these technologies in new ways. Indeed, these requirements take us back to the roots of the field of neural computing, forcing us to ask how it could be that the human brain achieves with as little as 12 watts of power what seems to require entire server farms with state of the art computational and numerical methods. Likewise, even lowly insects demonstrate a degree of adaptivity and resilience that still defy easy explanation or computational replication. In this Research Topic, we have compiled the latest research addressing several aspects of these broadly defined challenge questions. As illustrated in Figure 1, the articles are organized into four prevailing themes: Sense, Think, Act, and Tools.","",""
167,"Max Tegmark","Life 3.0: Being Human in the Age of Artificial Intelligence",2017,"","","","",162,"2022-07-13 09:22:08","","","","",,,,,167,33.40,167,1,5,"New York Times Best Seller How will Artificial Intelligence affect crime, war, justice, jobs, society and our very sense of being human? The rise of AI has the potential to transform our future more than any other technologyand theres nobody better qualified or situated to explore that future than Max Tegmark, an MIT professor whos helped mainstream research on how to keep AI beneficial. How can we grow our prosperity through automation without leaving people lacking income or purpose? What career advice should we give todays kids? How can we make future AI systems more robust, so that they do what we want without crashing, malfunctioning or getting hacked? Should we fear an arms race in lethal autonomous weapons? Will machines eventually outsmart us at all tasks, replacing humans on the job market and perhaps altogether? Will AI help life flourish like never before or give us more power than we can handle? What sort of future do you want? This book empowers you to join what may be the most important conversation of our time. It doesnt shy away from the full range of viewpoints or from the most controversial issuesfrom superintelligence to meaning, consciousness and the ultimate physical limits on life in the cosmos.","",""
7,"R. Y. Goh, L. Lee, H. Seow, Kathiresan Gopal","Hybrid Harmony Search–Artificial Intelligence Models in Credit Scoring",2020,"","","","",163,"2022-07-13 09:22:08","","10.3390/e22090989","","",,,,,7,3.50,2,4,2,"Credit scoring is an important tool used by financial institutions to correctly identify defaulters and non-defaulters. Support Vector Machines (SVM) and Random Forest (RF) are the Artificial Intelligence techniques that have been attracting interest due to their flexibility to account for various data patterns. Both are black-box models which are sensitive to hyperparameter settings. Feature selection can be performed on SVM to enable explanation with the reduced features, whereas feature importance computed by RF can be used for model explanation. The benefits of accuracy and interpretation allow for significant improvement in the area of credit risk and credit scoring. This paper proposes the use of Harmony Search (HS), to form a hybrid HS-SVM to perform feature selection and hyperparameter tuning simultaneously, and a hybrid HS-RF to tune the hyperparameters. A Modified HS (MHS) is also proposed with the main objective to achieve comparable results as the standard HS with a shorter computational time. MHS consists of four main modifications in the standard HS: (i) Elitism selection during memory consideration instead of random selection, (ii) dynamic exploration and exploitation operators in place of the original static operators, (iii) a self-adjusted bandwidth operator, and (iv) inclusion of additional termination criteria to reach faster convergence. Along with parallel computing, MHS effectively reduces the computational time of the proposed hybrid models. The proposed hybrid models are compared with standard statistical models across three different datasets commonly used in credit scoring studies. The computational results show that MHS-RF is most robust in terms of model performance, model explainability and computational time.","",""
13,"Shen Li, Zigui Wang, L. Visser, E. Wisner, Hao Cheng","Pilot study: Application of artificial intelligence for detecting left atrial enlargement on canine thoracic radiographs",2020,"","","","",164,"2022-07-13 09:22:08","","10.1111/vru.12901","","",,,,,13,6.50,3,5,2,"Abstract Although deep learning has been explored extensively for computer‐aided medical imaging diagnosis in human medicine, very little has been done in veterinary medicine. The goal of this retrospective, pilot project was to apply the deep learning artificial intelligence technique using thoracic radiographs for detection of canine left atrial enlargement and compare results with those of veterinary radiologist interpretations. Seven hundred ninety‐two right lateral radiographs from canine patients with thoracic radiographs and contemporaneous echocardiograms were used to train, validate, and test a convolutional neural network algorithm. The accuracy, sensitivity, and specificity for determination of left atrial enlargement were then compared with those of board‐certified veterinary radiologists as recorded on radiology reports. The accuracy, sensitivity, and specificity were 82.71%, 68.42%, and 87.09%, respectively, using an accuracy driven variant of the convolutional neural network algorithm and 79.01%, 73.68%, and 80.64%, respectively, using a sensitivity driven variant. By comparison, accuracy, sensitivity, and specificity achieved by board‐certified veterinary radiologists was 82.71%, 68.42%, and 87.09%, respectively. Although overall accuracy of the accuracy driven convolutional neural network algorithm and veterinary radiologists was identical, concordance between the two approaches was 85.19%. This study documents proof‐of‐concept for application of deep learning techniques for computer‐aided diagnosis in veterinary medicine.","",""
6,"T. York, Heloise Jenney, G. Jones","Clinician and computer: a study on patient perceptions of artificial intelligence in skeletal radiography",2020,"","","","",165,"2022-07-13 09:22:08","","10.1136/bmjhci-2020-100233","","",,,,,6,3.00,2,3,2,"Background Up to half of all musculoskeletal injuries are investigated with plain radiographs. However, high rates of image interpretation error mean that novel solutions such as artificial intelligence (AI) are being explored. Objectives To determine patient confidence in clinician-led radiograph interpretation, the perception of AI-assisted interpretation and management, and to identify factors which might influence these views. Methods A novel questionnaire was distributed to patients attending fracture clinic in a large inner-city teaching hospital. Categorical and Likert scale questions were used to assess participant demographics, daily electronics use, pain score and perceptions towards AI used to assist in interpretation of their radiographs, and guide management. Results 216 questionnaires were included (M=126, F=90). Significantly higher confidence in clinician rather than AI-assisted interpretation was observed (clinician=9.20, SD=1.27 vs AI=7.06, SD=2.13), 95.4% reported favouring clinician over AI-performed interpretation in the event of disagreement. Small positive correlations were observed between younger age/educational achievement and confidence in AI-assistance. Students demonstrated similarly increased confidence (8.43, SD 1.80), and were over-represented in the minority who indicated a preference for AI-assessment over their clinicians (50%). Conclusions Participant’s held the clinician’s assessment in the highest regard and expressed a clear preference for it over the hypothetical AI assessment. However, robust confidence scores for the role of AI-assistance in interpreting skeletal imaging suggest patients view the technology favourably. Findings indicate that younger, more educated patients are potentially more comfortable with a role for AI-assistance however further research is needed to overcome the small number of responses on which these observations are based.","",""
6,"N. Gahungu, Robert Trueick, S. Bhat, P. Sengupta, G. Dwivedi","Current Challenges and Recent Updates in Artificial Intelligence and Echocardiography",2020,"","","","",166,"2022-07-13 09:22:08","","10.1007/s12410-020-9529-x","","",,,,,6,3.00,1,5,2,"","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",167,"2022-07-13 09:22:08","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",168,"2022-07-13 09:22:08","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
0,"A. Nechkin","Constitutional and Legal Status of Artificial Intelligence in Russia: Present and Future",2020,"","","","",169,"2022-07-13 09:22:08","","10.17803/1729-5920.2020.165.8.078-085","","",,,,,0,0.00,0,1,2,"In the paper, the author uses general scientific and specific scientific methods of cognition to scrutinize the problems of constitutional and legal regulation of public relations in Russia, related to the widespread introduction of artificial intelligence technology. Based on the results of the research, the author concludes that modern Russian constitutional legislation, even in its current form, makes it possible to regulate the nascent social relations associated with the widespread introduction of artificial intelligence technology. In particular, it is noted that the provisions of the Constitution of the Russian Federation allow for an expanded interpretation of the concept ""personality"", covering not only a person, but also highly developed artificial intelligence. According to the author, the constitutional and legal status of highly developed artificial intelligence should be based on the image and likeness of the constitutional and legal status of a person. The only exceptions should be the following. First is legal personality, which by its legal nature should be extremely close to the legal personality of bodies and organizations and should arise from the moment the relevant decision is made by the competent state authority. Rights, freedoms and obligations should imply a limited amount of personal rights and freedoms, the complete absence of political and socioeconomic rights. The last exception is the limited passive dispositive capacity of artificial intelligence. In addition, the main element in the structure of the constitutional and legal status of artificial intelligence in Russia should be universal restrictions on its rights and freedoms, which would serve as analogues of natural human physiological restrictions and would not allow artificial intelligence to acquire evolutionary advantages over humans. Thus, the structure of the constitutional and legal status of artificial intelligence as a person can and should in the future look like this: legal personality; rights, freedoms and duties; guarantees that ensure the implementation of rights and freedoms; universal restrictions on rights and freedoms.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",170,"2022-07-13 09:22:08","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
8,"Zuolin Dong, Jiahong Wei, Xiaoyu Chen, Pengfei Zheng","Face Detection in Security Monitoring Based on Artificial Intelligence Video Retrieval Technology",2020,"","","","",171,"2022-07-13 09:22:08","","10.1109/ACCESS.2020.2982779","","",,,,,8,4.00,2,4,2,"With the rapid development of video monitoring, the massive information of the monitoring image has far exceeded the effective processing range of human resources. Intelligent video retrieval technology has become an increasingly indispensable part of video monitoring system. Intelligent video retrieval technology integrates video processing, computer vision and artificial intelligence, which greatly improves the efficiency of monitoring and the accuracy and linkage of monitoring system. Face recognition and other emerging technologies continue to rise and apply to the security monitoring system. Based on deep learning theory and face detection neural network, this paper proposes a video oriented cascaded intelligent face detection algorithm, which builds deep learning network by cascading multiple features, from edge features, contour features, local features to semantic features, and advances layer by layer. According to the last semantic features, the information of the input data is obtained to accurately realize the face detection under the non ideal condition. Simulation results show that the algorithm has good detection performance for single face and multi face images, and has strong robustness for rotating face. At the same time, the algorithm is fast and can basically meet the requirements of real-time face detection.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",172,"2022-07-13 09:22:08","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
7,"Jingguang Han, Yuyun Huang, Shaofeng Liu, Kieran Towey","Artificial intelligence for anti-money laundering: a review and extension",2020,"","","","",173,"2022-07-13 09:22:08","","10.1007/s42521-020-00023-1","","",,,,,7,3.50,2,4,2,"","",""
8,"John T. O’Brien, Cassidy Nelson","Assessing the Risks Posed by the Convergence of Artificial Intelligence and Biotechnology.",2020,"","","","",174,"2022-07-13 09:22:08","","10.1089/hs.2019.0122","","",,,,,8,4.00,4,2,2,"Rapid developments are currently taking place in the fields of artificial intelligence (AI) and biotechnology, and applications arising from the convergence of these 2 fields are likely to offer immense opportunities that could greatly benefit human health and biosecurity. The combination of AI and biotechnology could potentially lead to breakthroughs in precision medicine, improved biosurveillance, and discovery of novel medical countermeasures as well as facilitate a more effective public health emergency response. However, as is the case with many preceding transformative technologies, new opportunities often present new risks in parallel. Understanding the current and emerging risks at the intersection of AI and biotechnology is crucial for health security specialists and unlikely to be achieved by examining either field in isolation. Uncertainties multiply as technologies merge, showcasing the need to identify robust assessment frameworks that could adequately analyze the risk landscape emerging at the convergence of these 2 domains.This paper explores the criteria needed to assess risks associated with Artificial intelligence and biotechnology and evaluates 3 previously published risk assessment frameworks. After highlighting their strengths and limitations and applying to relevant Artificial intelligence and biotechnology examples, the authors suggest a hybrid framework with recommendations for future approaches to risk assessment for convergent technologies.","",""
6,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2: toward universal blueprints for vaccine designs",2020,"","","","",175,"2022-07-13 09:22:08","","10.1101/2020.04.21.052084","","",,,,,6,3.00,1,11,2,"The global population is at present suffering from a pandemic of Coronavirus disease 2019 (COVID-19), caused by the novel coronavirus Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). The goals of this study were to use artificial intelligence (AI) to predict blueprints for designing universal vaccines against SARS-CoV-2, that contain a sufficiently broad repertoire of T-cell epitopes capable of providing coverage and protection across the global population. To help achieve these aims, we profiled the entire SARS-CoV-2 proteome across the most frequent 100 HLA-A, HLA-B and HLA-DR alleles in the human population, using host-infected cell surface antigen presentation and immunogenicity predictors from the NEC Immune Profiler suite of tools, and generated comprehensive epitope maps. We then used these epitope maps as input for a Monte Carlo simulation designed to identify statistically significant “epitope hotspot” regions in the virus that are most likely to be immunogenic across a broad spectrum of HLA types. We then removed epitope hotspots that shared significant homology with proteins in the human proteome to reduce the chance of inducing off-target autoimmune responses. We also analyzed the antigen presentation and immunogenic landscape of all the nonsynonymous mutations across 3400 different sequences of the virus, to identify a trend whereby SARS-COV-2 mutations are predicted to have reduced potential to be presented by host-infected cells, and consequently detected by the host immune system. A sequence conservation analysis then removed epitope hotspots that occurred in less-conserved regions of the viral proteome. Finally, we used a database of the HLA genotypes of approximately 22 000 individuals to develop a “digital twin” type simulation to model how effective different combinations of hotspots would work in a diverse human population, and used the approach to identify an optimal constellation of epitopes hotspots that could provide maximum coverage in the global population. By combining the antigen presentation to the infected-host cell surface and immunogenicity predictions of the NEC Immune Profiler with a robust Monte Carlo and digital twin simulation, we have managed to profile the entire SARS-CoV-2 proteome and identify a subset of epitope hotspots that could be harnessed in a vaccine formulation to provide a broad coverage across the global population.","",""
6,"Y. Mori, S. Kudo, M. Misawa, K. Takeda, T. Kudo, H. Itoh, M. Oda, K. Mori","Artificial Intelligence for Colorectal Polyp Detection and Characterization",2020,"","","","",176,"2022-07-13 09:22:08","","10.1007/s11938-020-00287-x","","",,,,,6,3.00,1,8,2,"","",""
4,"R. Thomson, J. Schoenherr","Knowledge-to-Information Translation Training (KITT): An Adaptive Approach to Explainable Artificial Intelligence",2020,"","","","",177,"2022-07-13 09:22:08","","10.1007/978-3-030-50788-6_14","","",,,,,4,2.00,2,2,2,"","",""
4,"S. Kulikov, A. V. Shirokova","Artificial intelligence, culture and education",2020,"","","","",178,"2022-07-13 09:22:08","","10.1007/s00146-020-01026-7","","",,,,,4,2.00,2,2,2,"","",""
1,"Charles P B Vanderpool","Artificial Intelligence and Gastroenterology: Expanding Technology.",2020,"","","","",179,"2022-07-13 09:22:08","","10.1097/MPG.0000000000002986","","",,,,,1,0.50,1,1,2,"T he concept of ‘‘machine learning’’ and ‘‘artificial intelligence (AI)’’ within medicine may elicit a different response based on the individual. For some, machine learning and AI in medicine may be associated with technology taking the place of humanphysician led medical expertise. For others, the idea of machine learning in medicine is seen as an example of technology advancement. Regardless, it is a concept that is gaining traction and attention because of the abundance of possibilities related to this technology. A search in PubMed.gov garners over 45,000 search results for ‘‘machine learning,’’ the majority being published within the last 5 years. If you use an internet search engine, you will obtain even more search results for this term. So what is machine learning? Machine learning is based on algorithms that utilize statistics to identify patterns. It provides a system that can automatically learn from experience – but experience based on data and not based on human experience or reaction. This technology is heavily employed in many day-to-day services, including video and music streaming sites, social media sites, and voice assistant services. In these instances, data are collected and machine learning predicts what you will want next. So how can machine learning be applied to pediatric gastroenterology? In the January 2020 issue of Journal of Pediatric Gastroenterology and Nutrition (JPGN), Patel et al provided an in-depth review of AI and machine learning applied to gastrointestinal diagnostics. This review discussed important terminology within the practice of machine learning that is essential to understanding the science behind this technology (1). As discussed within this review, AI has applications within gastrointestinal endoscopy (polyp detection, celiac disease, IBD), endomicroscopy, video capsule endoscopy, and radiographic imaging interpretation (1). In this month’s issue of JPGN, Dhaliwal et al explore one such possible application of machine learning within pediatric inflammatory bowel disease (IBD) – differentiation of colonic IBD. Differentiation of ulcerative colitis (UC) from Crohn disease is a difficult process and has been a topic of multiple publications itself, including a 2007 clinical report from NASPGHAN and CCFA (2), and more recently, diagnostic criteria published by the Pediatric IBD (PIBD) Porto group of ESPGHAN (3). As mentioned by Dhaliwal et al, the PIBD classification algorithm focuses on features pointing away from a diagnosis of UC. In their machine-learning model, the authors evaluated 73 patients and 28 specific disease features. Their model not only incorporated features from the PIBD algorithm but also included disease features typical of UC (primarily histologic features—see Table 1 of publication). Through machine-learning analysis of disease features, they were able to identify 7 features (3 histologic and 4 endoscopic—see Table 2 of publication) that accurately distinguished between UC and colonic CD. As my music streaming service often reminds me, interaction (thus submitting more data) within the service improves algorithm accuracy. Similar could be said for this study, which represented a specific patient population from a single center. The power of this publication may not be its immediate generalization to pediatric IBD in its entirety. The concept and potential performance of an AIbased diagnostic algorithm within pediatric IBD is, however, promising. AI and machine learning have the potential to analyze large data sets, provide meaningful data-driven algorithms free of human bias, and could contribute to data-driven standard care practices. Variation in care is a known issue throughout medicine, including pediatric IBD (4). Utilizing models, such as this may help us in our quest to become better physicians, making informed diagnoses and decisions that lead to improved patient outcomes. The study by Dhaliwal et al is a step in this direction. Ideas and models such as this are likely to shape the practice of medicine in the future. Human emotion, reaction, and experience should never be completely removed from the art of medicine but utilization of technology can improve the science of medicine and further our ability to care for our patients. Change is on the horizon; count me in the camp that views AI and machine learning as important technology innovation.","",""
1,"Alicia Lai","Artificial Intelligence, LLC: Corporate Personhood as Tort Reform",2020,"","","","",180,"2022-07-13 09:22:08","","10.2139/ssrn.3677360","","",,,,,1,0.50,1,1,2,"Our legal system has long tried to fit the square peg of artificial intelligence (AI) technologies into the round hole of the current tort regime, overlooking the inability of traditional liability schemes to address the nuances of how AI technology creates harms. The current tort regime deals out rough justice—using strict liability for some AI products and using the negligence rule for other AI services—both of which are insufficiently tailored to achieve public policy objectives.    Under a strict liability regime where manufacturers are always held liable for the faults of their technology regardless of knowledge or precautionary measures, firms are incentivized to play it safe and stifle innovation. But even with this cautionary stance, the goals of strict liability cannot be met due to the unique nature of AI technology: its mistakes are merely “efficient errors”—they appropriately surpass the human baseline, they are game theory problems intended for a jury, they are necessary to train a robust system, or they are harmless but misclassified.    Under a negligence liability regime where the onus falls entirely on consumers to prove the element of causation, victimized consumers are left without sufficient recourse or compensation. Many critiques have been leveled against the “black-box” nature of algorithms.    This paper proposes a new framework to regulate artificial intelligence technologies: bestowing corporate personhood to AI systems. First, the corporate personality trait of “limited liability” strikes an optimal balance in determining liability—it would both compensate victims (for instance, through obligations to carry insurance and a straightforward burden of causation) while holding manufacturers responsible only when the infraction is egregious (for instance, through veil-piercing). Second, corporate personhood is “divisible”—meaning not all corporate personality traits need to be granted—which circumvents many of the philosophical criticisms of giving AI the complete set of rights of full legal personhood.","",""
1,"Assil Benchaaben, Felipe Guimaraes, Emmanuel Prestat, A. Kassambara, Mounia Filahi, Caroline Laugé, T. Sbarrato, J. Fieschi","Abstract 870: Immunoscore®workflow enhanced by artificial intelligence",2020,"","","","",181,"2022-07-13 09:22:08","","10.1158/1538-7445.am2020-870","","",,,,,1,0.50,0,8,2,"Artificial Intelligence (AI) along with Machine Learning (ML) techniques has long promised to accelerate Digital Pathology (DP) based cancer diagnosis. Despite the consensus regarding the value of AI, the lack of visibility of how ML algorithms work, prevents their wider adoption for human in vitro diagnostic (IVD) in a highly regulated environment. A common ground becomes necessary in order to fully benefit from ML capabilities. HalioDx Immunoscore® was the first immune scoring test validated for IVD use leveraging advanced image analysis. In brief, for each tumor sample, 2 slides are stained using an automated immunohistochemistry instrument: one with CD3 and one with CD8 ready-to-use monoclonal antibodies (HalioDx) followed by detection with DAB and counterstaining. Digital images of stained slides are obtained using a whole slide scanner and analyzed by a software program (Immunoscore® Analyzer, HalioDx)1. Current workflow relies only on Computer Vision (CV) techniques for image analysis leading to the calculation of the Immunoscore®. We have used ML to improve HalioDx Immunoscore® software program, streamline the workflow, decrease hands-on and computation times. In summary, to design the new workflow, each DP steps were considered as independent applications. CV remains applied to the cell detection. A Convolutional Neural Network, along with a UNET architecture, were used to recognize Regions of Interest (ROI) and image-related artifacts during the analysis. Intermediary validation steps by a trained operator were maintained in order to review CV and AI steps and guarantee a complete equivalence versus the standardized original DP protocol. The Intersection over the Union of two regions (IoU) was used as performance and equivalency metric. Compared to Ground Truth, the ML algorithm improves the accuracy of the ROI detection versus the CV based algorithm, resulting in a dramatic decrease of the ROI computing time (from 3h to 5min) as well as in a reduced need for manual correction. We demonstrated that ML applied to the Immunoscore® DP workflow for ROI detection results in reduced time-to result and overall improved robustness of the analysis. The equivalency study showed the importance of a well-curated dataset to maximize model9s accuracy and performance. Finally, the verification and validation phase demonstrated the ML based workflow readiness for regulatory approval. 1Hermitte F. J Immunother Cancer. 2016 Sep 20;4:57. doi: 10.1186/s40425-016-0161-x. Citation Format: Assil Benchaaben, Felipe Machado Guimaraes, Emmanuel Prestat, Alboukadel Kassambara, Mounia Filahi, Caroline Lauge, Thomas Sbarrato, Jacques Fieschi. Immunoscore® workflow enhanced by artificial intelligence [abstract]. In: Proceedings of the Annual Meeting of the American Association for Cancer Research 2020; 2020 Apr 27-28 and Jun 22-24. Philadelphia (PA): AACR; Cancer Res 2020;80(16 Suppl):Abstract nr 870.","",""
1,"N. Corrêa, N. D. Oliveira","Dynamic Models Applied to Value Learning in Artificial Intelligence",2020,"","","","",182,"2022-07-13 09:22:08","","10.13140/RG.2.2.35369.01126/2","","",,,,,1,0.50,1,2,2,"Experts in Artificial Intelligence (AI) development predict that advances in the development of intelligent systems and agents will reshape vital areas in our society. Nevertheless, if such an advance is not made prudently and critically-reflexively, it can result in negative outcomes for humanity. For this reason, several researchers in the area are trying to develop a robust, beneficial, and safe concept of AI for the preservation of humanity and the environment. Currently, several of the open problems in the field of AI research arise from the difficulty of avoiding unwanted behaviors of intelligent agents and systems, and at the same time specifying what we want such systems to do, especially when we look for the possibility of intelligent agents acting in several domains over the long term. It is of utmost importance that artificial intelligent agents have their values aligned with human values, given the fact that we cannot expect an AI to develop human moral values simply because of its intelligence, as discussed in the Orthogonality Thesis. Perhaps this difficulty comes from the way we are addressing the problem of expressing objectives, values, and ends, using representational cognitive methods. A solution to this problem would be the dynamic approach proposed by Dreyfus, whose phenomenological philosophy shows that the human experience of being-in-the-world in several aspects is not well represented by the symbolic or connectionist cognitive method, especially in regards to the question of learning values. A possible approach to this problem would be to use theoretical models such as SED (situated embodied dynamics) to address the values learning problem in AI.","",""
0,"K. Shrivastav, N. Taneja, P. Arambam, Vandana Bhatia, S. Batra, Harpreet Singh, E. Abed, P. Ranjan, Rajiv Janardhanan∗h","An Artificial Intelligence Enabled Multimedia Tool for Rapid Screening of Cervical Cancer",2020,"","","","",183,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,9,2,"Cervical cancer is a major public health challenge. Further mitigation of cervical cancer can greatly benefit from development of innovative and disruptive technologies for its rapid screening and early detection. The primary objective of this study is to contribute to this aim through large scale screening by development of Artificial Intelligence enabled Intelligent Systems as they can support human cancer experts in making more precise and timely diagnosis. Our current study is focused on development of a robust and interactive algorithm for analysis of colposcope-derived images analysis and a diagnostic tool/scale namely the OMThe Onco-Meter. This tool was trained and tested on 300 InEmail addresses: kdshrivastav@amity.edu (Kumar Dron Shrivastav), ntaneja@amity.edu (Neha Taneja), priyadarshini@batrahospitaldelhi.org (Priyadarshini Arambam), vbhatia2@amity.edu (Vandana Bhatia), shelly.batra@opasha.org (Shelly Batra), crbhmrc1@batrahospitaldelhi.org (Shelly Batra), hsingh@bmi.icmr.org.in (Harpreet Singh), abed@isr.umd.edu (Eyad H. Abed), ranjan.p@srmap.edu.in (Priya Ranjan), rjanardhanan@amity.edu (Rajiv Janardhanan∗) Preprint submitted to The Lancet Digital Health June 1, 2020 dian subjects/patients yielding 77% accuracy with a sensitivity of 83.56% and a specificity of 59.25%. OM-The Oncometer is capable of classifying cervigrams into cervical dysplasia, carcinoma in− situ (CIS) and invasive cancer(IC). Programming language R has been used to implement and compute earth mover distances (EMD) to characterize different diseases labels associated with cervical cancer, computationally. Deployment of automated tools will facilitate early diagnosis in a noninvasive manner leading to a timely clinical intervention for cervical cancer patients upon detection at a Primary Health Care (PHC).The tool developed in this study will aid clinicians to design timely intervention strategies aimed at improving the clinical prognosis of patients.","",""
0,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dental Diagnostics: Chances and challenges",2020,"","","","",184,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. is a using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning and conduct, e.g. image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, a, predictive, preventive and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to (1) limited data availability, accessibility, structure and comprehensiveness, (2) lacking methodological rigor and standards in their development, (3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, e.g. by improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Last, trustworthiness into and generalizability of dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"Shanqi Pang Dr, Yongmei Li Prof","Artificial Intelligence Techniques for Cyber Security Applications",2020,"","","","",185,"2022-07-13 09:22:08","","10.46532/ijaict-2020021","","",,,,,0,0.00,0,2,2,"Considering the enhancement in technology, criminals have been using cyberspace in order to commit many crimes. Therefore, it should be noted that cybercrimes are exposed to a number of threats and intrusions if not safeguarded well. Human and physical intervention tend not to be very adequate for the protection and tracking of such infrastructure, that is why there should be the establishment of multifaceted cyber defense networks, which are flexible, robust, and adjustable in order sense a massive collection of invasion and creation of real-time choices. Nevertheless, significant number of bio-related computing techniques of AI (artificial intelligence) tend to be increasing hence a significant role is played in detecting and preventing cybercrime. The main aim of this paper is outlining the actual advancement that have been made possible due to the application of AI methods for the fight against cybercrimes, in order to reveal how the methods are efficient in sensing and preventing cyber invasions, also providing a brief overview of the future works. Keywords— Computational intelligence, Artificial Intelligence, Intrusion detection and prevention systems, Cyber crime","",""
90,"M. Alsharqi, W. Woodward, J. Mumith, D. C. Markham, R. Upton, P. Leeson","Artificial intelligence and echocardiography",2018,"","","","",186,"2022-07-13 09:22:08","","10.1530/ERP-18-0056","","",,,,,90,22.50,15,6,4,"Echocardiography plays a crucial role in the diagnosis and management of cardiovascular disease. However, interpretation remains largely reliant on the subjective expertise of the operator. As a result inter-operator variability and experience can lead to incorrect diagnoses. Artificial intelligence (AI) technologies provide new possibilities for echocardiography to generate accurate, consistent and automated interpretation of echocardiograms, thus potentially reducing the risk of human error. In this review, we discuss a subfield of AI relevant to image interpretation, called machine learning, and its potential to enhance the diagnostic performance of echocardiography. We discuss recent applications of these methods and future directions for AI-assisted interpretation of echocardiograms. The research suggests it is feasible to apply machine learning models to provide rapid, highly accurate and consistent assessment of echocardiograms, comparable to clinicians. These algorithms are capable of accurately quantifying a wide range of features, such as the severity of valvular heart disease or the ischaemic burden in patients with coronary artery disease. However, the applications and their use are still in their infancy within the field of echocardiography. Research to refine methods and validate their use for automation, quantification and diagnosis are in progress. Widespread adoption of robust AI tools in clinical echocardiography practice should follow and have the potential to deliver significant benefits for patient outcome.","",""
0,"S. Pushpendra, Sahu Navneet Kumar","Human Voice Identification using Artificial Intelligence",2015,"","","","",187,"2022-07-13 09:22:08","","","","",,,,,0,0.00,0,2,7,"Human identification using biometric is gaining more and more attention. It has been shown that combining different biometric modalities increases the robustness and enables to achieve better performances than single modality. In this context, this book presents an effective method to combine voice and fingerprint features for biometric authentication. For each task, up-to-date methods are analyzed based on the analysis, an integrated solution for speech and fingerprint recognition is developed. The extracted features are used to form input matrix which is stored as a database. For feature extraction we have used MatLab toolbox and image processing toolbox. For recognition and verification of purpose we have used neural network toolbox. Main aim is to design Human identification system which can be used for detecting right person.","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",188,"2022-07-13 09:22:08","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
5,"I. Karabulatova","Possibilities of artificial intelligence in assessing the impact of potentially dangerous texts in modern news discourse: problem of statement",2020,"","","","",189,"2022-07-13 09:22:08","","10.1051/shsconf/20208801001","","",,,,,5,2.50,5,1,2,"The relevance of the stated problem reflects the study of the “friend-foe” dichotomy, which is clearly represented in the modern news discourse, since it reflects the most significant problems for society: migration, the COVID-19 pandemic, crime, various confrontations, problems of socially vulnerable citizens, etc. The subject of the research is to Refine the parameters for evaluating potentially dangerous texts for the subsequent creation of a library of software modules for theming and classifying news messages, including using AI technologies. Hypothesis: the proposed parameters of the system of interpretation of potentially dangerous text increase the chances of determining the prognostic level of the degree of propensity to illegal actions, so the creation of a digital library will help to quickly analyze the levels of potential dangers for the recipient. The use of digital technologies for psycholinguistic assessment of potentially dangerous texts optimizes the search and tracking of such texts, contributing to the development of measures to ensure the safety of the human psyche in conditions of massive impact on the recipient in order to change his personal attitudes. The author raises the problem of creating a single digital platform for evaluating such texts, noting the need for linguistic priority when creating semantic markup, which will allow us to qualitatively rank potentially dangerous texts. Such work requires the application of interdisciplinary efforts of specialists in the fields of linguistics, psychology, mythology, history, sociology, political science, cultural studies, mathematics, computer science and Digital Humanities. The practical value is unquestionable, since psycholinguodiagnostics of a person does not correlate with the potential danger of texts produced by such a person in society.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",190,"2022-07-13 09:22:08","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",191,"2022-07-13 09:22:08","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
58,"E. Ranschaert, S. Morozov, P. Algra","Artificial Intelligence in Medical Imaging",2019,"","","","",192,"2022-07-13 09:22:08","","10.1007/978-3-319-94878-2","","",,,,,58,19.33,19,3,3,"","",""
0,"A. Barrie, R. Smith, C. Hickman, I. Erlich, A. Campbell","P-287 An assessment of agreement between automated embryo annotation, through artificial intelligence, and manual embryo annotation",2022,"","","","",193,"2022-07-13 09:22:08","","10.1093/humrep/deac107.276","","",,,,,0,0.00,0,5,1,"      How strong is the agreement between embryo morphokinetic annotations performed by experienced embryologists compared to an automated embryo annotation system based on artificial intelligence (AI)?        Agreement between manual and automated annotation as determined by the interclass correlation coefficient (ICC) revealed strong or very strong agreement for all analysed morphokinetic variables.        Transitioning from time-lapse imaging to embryo selection for transfer, freezing or discard involves annotation; the action of converting images to numerical data. Numerical data can be used as input to selection models quantifying embryo viability. Currently, embryos are manually annotated by the embryologist which can be subjective and time-consuming. As such, clinics prioritise a manageable number of variables to annotate, leading to a range of clinic practices. There is the additional challenge of operator variation, despite the development of standardised definitions and quality assurance schemes. AI may help resolve these challenges.        Retrospective comparative analysis, including 2442 embryos from IVF and ICSI cycles, from four private fertility clinics belonging to the same group in the UK. All the embryos cultured in a time-lapse incubator (EmbryoScope,Vitrolife) between January 2016 and 2019 were included in the study. Manual annotations (MA) versus automated annotations (AA) were compared using a two-way, mixed interclass correlation coefficient (ICC), which produced five categories of agreement, very weak(0-0.20), weak(0.21-0.40), moderate(0.41-0.60), strong(0.61-0.80), very strong(0.81-1.00).        Videos were manually annotated by experienced embryologists from pronuclei fading (tPNf) to time of expanded blastocyst (tEB) with all cell stages annotated in between (time to two-cell (t2), three-cell (t3), four-cell (t4), five-cell (t5), six-cell (t6), seven-cell (t7), eight-cell (t8), nine-cell (t9), morula (tM), start of blastulation (tSB) and full blastocyst (tB)). Blind to human annotations, and without any training, the same videos were annotated by CHLOE (Fairtility) to produce automated annotation data.        Of the expected annotations, AA did not provide a result for 15.4% of the MA(3235/21008). Very strong agreement(0.81-1.00) between MA and AA was found for tPNf, t2, t3, t5, t6, tM, tSB, tB, tEB. Strong agreement(0.61-0.80) was found for t4, t7, t8 and t9+. Outliers in the AA data, defined as one standard deviation from the MA, were interrogated further for five key morphokinetic parameters; t2, t5, t8, tSB and tB. A total of 269 outliers were identified.  For t2 outliers(n = 14,6%), the average time difference was 5.97h(range;5.50-24.44h). All embryos with a t2 outlier were classed as either poor(PQ) or average quality(AQ).  The t5 outliers(n = 45,19%) had an average time difference of 2.84h(range;9.33-36.69h). 96%(n = 43) of these embryos were classed as PQ(n = 25,56%) or AQ(n = 18,40%).  Outliers for t8(138,58%) were, on average, 17.53h different between MA and AA(range;12.68-40.35h). 94%(n = 130)of these embryos were classed as PQ(n = 77,56%) or AQ(n = 53,38%).  The tSB outliers(n = 28,12%) had an average time difference of 3.58h(range;0.71-14.39h). 89%(n = 25) of these embryos were classed as PQ(n = 16,57%) or AQ(n = 9,32%).  Finally, outliers associated with tB(n = 44,18%) had an average time difference of 6.39h(range;0.02-33.67h). 95%(n = 42) of these embryos were classed as PQ(n = 38,86%) or AQ(n = 4,9%).  Almost 15%(n = 40) of the embryos had outliers in more than one of the five morphokinetic parameters.        The findings for this study reflect the capabilities of a specific AI-based annotation algorithm against the practice in multiple clinics in the same group and country. The automated annotation algorithm was not trained on this dataset prior to validation, which is encouraging for generalisability.        AI is ideally suited to resolve annotation challenges. This study demonstrates that where embryo quality is poor, annotation could be skewed both when performed manually and automatically. Once robustness is demonstrated, AI tools such as CHLOE, may allow clinics to process clinical data efficiently, objectively and consistently.        None ","",""
4,"Weixiao Chen","Artificial Intelligence Recognition Simulation of 3D Multimedia Visual Image Based on Sparse Representation Algorithm",2020,"","","","",194,"2022-07-13 09:22:08","","10.1109/ACCESS.2020.3006774","","",,,,,4,2.00,4,1,2,"With the rapid development of computer networks and multimedia technologies, images, which are important carriers of information dissemination, have made human cognition of things easier. Image recognition is a basic research task in computer vision, multimedia search, image understanding and other fields. This paper proposes a hierarchical feature learning structure that is completely automatically based on the original pixels of the image, and uses the K-SVD (K-Singular Value Decomposition) algorithm with label consistency constraints to train the discriminant dictionary. For different types of image data sets, the algorithm only extracts image blocks. After dense sampling, an efficient OMP (Orthogonal Matching Pursuit) encoder is used to obtain a layered sparse representation. The improved SIFT (Scale Invariant Feature Transform) algorithm is used to solve the difficult problem of multimedia visual image stereo matching. The feature point extraction and stereo matching of multimedia visual images, different scales and different viewpoint images are analyzed separately. Aiming at a large number of low-dimensional geometric features of 3D images, this paper studies the extraction and sorting strategies of low-dimensional geometric features of 3D images. A sparse representation method for 3D images is proposed, and the sparseness of image features is evaluated. This further improves the accuracy of 3D image representation and the robustness of 3D image recognition algorithms.","",""
1,"Sow Chen Wei, Yun-Huoy Choo, A. Muda, Lee Chien Sing","A Survey of Explainable Artificial Intelligence in Bio-signals Analysis",2022,"","","","",195,"2022-07-13 09:22:08","","10.2174/2666255815666220516141153","","",,,,,1,1.00,0,4,1,"  In contrast to the high rate of interest in artificial intelligence (AI) for business, the rate of AI adoption is much lower. It has been found that lack of consumer trust would adversely influence consumer’s evaluations of information given by AI. Hence the need for explanations in model results.    This is especially the case in clinical practice and juridical enforcement where improvements in prediction and interpretation are crucial. Bio-signals analysis such as EEG diagnosis usually involves complex learning models, which are difficult to explain. Therefore, the explanatory module is imperative if results is to be released to the general public. This research shows a systematic review of explainable artificial intelligence (XAI) advancement in the research community. Recent XAI efforts on bio-signals analysis were reviewed. The explanatory models are found to be in favor compared to the interpretable model approach due to the popularity of deep learning models in many use cases.    The verification and validation of explanatory models appear to be one of the crucial gaps in XAI bio-signals research. Currently, human expert evaluation is the easiest validation approach. Although the human directed approach is highly trusted by the bio-signals community, but it suffers from persona and social bias issues.    Hence, future research should investigate on more objective evaluation measurements towards achieving the characteristics of inclusiveness, reliability, transparency, and consistency in XAI framework. ","",""
9,"Fu Xiao, Zhengxin Guo, Yingying Ni, Xiaohui Xie, Sabita Maharjan, Yan Zhang","Artificial Intelligence Empowered Mobile Sensing for Human Flow Detection",2018,"","","","",196,"2022-07-13 09:22:08","","10.1109/MNET.2018.1700356","","",,,,,9,2.25,2,6,4,"Intelligent human detection based on WiFi is a technique that has recently attracted a significant amount of interest from research communities. The use of ubiquitous WiFi to detect the number of queuing persons can facilitate dynamic planning and appropriate service provisioning. In this article, we propose HFD, one of the first schemes to leverage WiFi signals to estimate the number of queuing persons by employing classifiers from machine learning in a device-free manner. In the proposed HFD scheme, we first utilize the sliding window method to filter and remove the outliers. We extract two characteristics, skewness and kurtosis, as the identification features. Then, we use the support vector machine (SVM) to classify these two features to estimate the number of people in the current queue. Finally, we combine our scheme with the latest Fresnel Zone model theory to determine whether someone is in or out, and thus dynamically adjust the detected value. We implement a proof-of-concept prototype upon commercial WiFi devices and evaluate it in both conference room and corridor scenarios. The experimental results show that the accuracy of our proposed HFD detection can be maintained at about 90 percent with high robustness.","",""
0,"Oren Shimoni, S. Shimoni","Artificial intelligence in echocardiography is here and more to come",2022,"","","","",197,"2022-07-13 09:22:08","","10.1007/s10554-022-02559-2","","",,,,,0,0.00,0,2,1,"","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",198,"2022-07-13 09:22:08","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
7,"Mir Riyanul Islam, Mobyen Uddin Ahmed, Shaibal Barua, S. Begum","A Systematic Review of Explainable Artificial Intelligence in Terms of Different Application Domains and Tasks",2022,"","","","",199,"2022-07-13 09:22:08","","10.3390/app12031353","","",,,,,7,7.00,2,4,1,"Artificial intelligence (AI) and machine learning (ML) have recently been radically improved and are now being employed in almost every application domain to develop automated or semi-automated systems. To facilitate greater human acceptability of these systems, explainable artificial intelligence (XAI) has experienced significant growth over the last couple of years with the development of highly accurate models but with a paucity of explainability and interpretability. The literature shows evidence from numerous studies on the philosophy and methodologies of XAI. Nonetheless, there is an evident scarcity of secondary studies in connection with the application domains and tasks, let alone review studies following prescribed guidelines, that can enable researchers’ understanding of the current trends in XAI, which could lead to future research for domain- and application-specific method development. Therefore, this paper presents a systematic literature review (SLR) on the recent developments of XAI methods and evaluation metrics concerning different application domains and tasks. This study considers 137 articles published in recent years and identified through the prominent bibliographic databases. This systematic synthesis of research articles resulted in several analytical findings: XAI methods are mostly developed for safety-critical domains worldwide, deep learning and ensemble models are being exploited more than other types of AI/ML models, visual explanations are more acceptable to end-users and robust evaluation metrics are being developed to assess the quality of explanations. Research studies have been performed on the addition of explanations to widely used AI/ML models for expert users. However, more attention is required to generate explanations for general users from sensitive domains such as finance and the judicial system.","",""
59,"A. Arabameri, B. Pradhan, K. Rezaei, Chang-Wook Lee","Assessment of Landslide Susceptibility Using Statistical- and Artificial Intelligence-Based FR-RF Integrated Model and Multiresolution DEMs",2019,"","","","",200,"2022-07-13 09:22:08","","10.3390/RS11090999","","",,,,,59,19.67,15,4,3,"Landslide is one of the most important geomorphological hazards that cause significant ecological and economic losses and results in billions of dollars in financial losses and thousands of casualties per year. The occurrence of landslide in northern Iran (Alborz Mountain Belt) is often due to the geological and climatic conditions and tectonic and human activities. To reduce or control the damage caused by landslides, landslide susceptibility mapping (LSM) and landslide risk assessment are necessary. In this study, the efficiency and integration of frequency ratio (FR) and random forest (RF) in statistical- and artificial intelligence-based models and different digital elevation models (DEMs) with various spatial resolutions were assessed in the field of LSM. The experiment was performed in Sangtarashan watershed, Mazandran Province, Iran. The study area, which extends to 1,072.28 km2, is severely affected by landslides, which cause severe economic and ecological losses. An inventory of 129 landslides that occurred in the study area was prepared using various resources, such as historical landslide records, the interpretation of aerial photos and Google Earth images, and extensive field surveys. The inventory was split into training and test sets, which include 70 and 30% of the landslide locations, respectively. Subsequently, 15 topographic, hydrologic, geologic, and environmental landslide conditioning factors were selected as predictor variables of landslide occurrence on the basis of literature review, field works and multicollinearity analysis. Phased array type L-band synthetic aperture radar (PALSAR), ASTER (Advanced Spaceborne Thermal Emission and Reflection Radiometer), and SRTM (Shuttle Radar Topography Mission) DEMs were used to extract topographic and hydrologic attributes. The RF model showed that land use/land cover (16.95), normalised difference vegetation index (16.44), distance to road (15.32) and elevation (13.6) were the most important controlling variables. Assessment of model performance by calculating the area under the receiving operating characteristic curve parameter showed that FR–RF integrated model (0.917) achieved higher predictive accuracy than the individual FR (0.865) and RF (0.840) models. Comparison of PALSAR, ASTER, and SRTM DEMs with 12.5, 30 and 90 m spatial resolution, respectively, with the FR–RF integrated model showed that the prediction accuracy of FR–RF–PALSAR (0.917) was higher than FR–RF–ASTER (0.865) and FR–RF–SRTM (0.863). The results of this study could be used by local planners and decision makers for planning development projects and landslide hazard mitigation measures.","",""
