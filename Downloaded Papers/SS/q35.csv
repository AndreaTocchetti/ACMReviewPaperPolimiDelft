Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
5,"Zhuolin Yang, Zhikuan Zhao, Hengzhi Pei, Boxin Wang, Bojan Karlas, Ji Liu, Heng Guo, Bo Li, Ce Zhang","End-to-end Robustness for Sensing-Reasoning Machine Learning Pipelines",2020,"","","","",1,"2022-07-13 09:23:31","","","","",,,,,5,2.50,1,9,2,"As machine learning (ML) being applied to many mission-critical scenarios, certifying ML model robustness becomes increasingly important. Many previous works focuses on the robustness of independent ML and ensemble models, and can only certify a very small magnitude of the adversarial perturbation. In this paper, we take a different viewpoint and improve learning robustness by going beyond independent ML and ensemble models. We aim at promoting the generic Sensing-Reasoning machine learning pipeline which contains both the sensing (e.g. deep neural networks) and reasoning (e.g. Markov logic networks (MLN)) components enriched with domain knowledge. Can domain knowledge help improve learning robustness? Can we formally certify the end-to-end robustness of such an ML pipeline?  We first theoretically analyze the computational complexity of checking the provable robustness in the reasoning component. We then derive the provable robustness bound for several concrete reasoning components. We show that for reasoning components such as MLN and a specific family of Bayesian networks it is possible to certify the robustness of the whole pipeline even with a large magnitude of perturbation which cannot be certified by existing work. Finally, we conduct extensive real-world experiments on large scale datasets to evaluate the certified robustness for Sensing-Reasoning ML pipelines.","",""
0,"Suleyman Emre Isik, Ali Eren Aytekin, Halil Vurus","A machine learning approach for abstraction and reasoning problems without large amounts of data",2022,"","","","",2,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,3,1,"Journal of Emerging Investigators • www.emerginginvestigators.org level abstraction-reasoning ability which makes it difficult for algorithms to handle volatile and hard-to-predict real-life problems. The problems caused by this task-based nature necessitated flexibility and robustness for certain broader subfields of AI, such as L5 self-driving, domestic robotics, or personal assistants; there is even increasing interest in generality itself (e.g., developmental robotics, artificial general intelligence) (2, 3). The first and most important step to take in order to offer an approach that is closer to human intelligence is to examine the concept of intelligence and to define it in the most useful way. Various definitions have been made for intelligence in the past. Legg and Hutter summarized the definitions made in the context of artificial intelligence research as follows: ""Intelligence measures a person's ability to achieve goals in a wide and varied environment (4)."" Two main characteristics are emphasized here: a task-goal focus and generalizability to a wide range of environments. Accordingly, while human intelligence can perform tasks with its high ability, these abilities can also be generalized for new tasks in new environments (skill acquisition). This feature is a mechanism that human nature has developed in line with evolutionary psychology to solve new unknown tasks and problems (5, 6). In the direction of the development of AI, many approaches have emerged to develop and evaluate AI models. One of them is the human observational approach that examines, judges, and scores the system’s inputs and outputs. This is a highly subjective, difficult, and expensive method to automate. White-box analysis, on the other hand, is inspecting the implementation of the system to determine its input-output response and score it (e.g., an algorithm that plays “Connect Four”) (7). Peer confrontation, for example, is having the system compete against either other AIs or humans. This is the preferred mode of evaluation for player-versus-player games, such as chess. The benchmarking approach, which is based on enabling the system through algorithms to produce outputs for a ""test set"" of inputs (or environments) for which the desired outcome is known (solvable by humans), is another of the most valuable approaches for the evaluation of artificial intelligence. In particular, it is reproducible (test set fixed), scalable (cheap to run the evaluation multiple times), easy to set up, and flexible enough to be applied to a wide variety of possible tasks (8). For this reason, benchmarking has been an important part of progress in artificial intelligence A machine learning approach for abstraction and reasoning problems without large amounts of data","",""
1,"G. Fagogenis","Increasing the robustness of autonomous systems to hardware degradation using machine learning",2016,"","","","",3,"2022-07-13 09:23:31","","","","",,,,,1,0.17,1,1,6,"Autonomous systems perform predetermined tasks (missions) with minimum supervision. In most applications, the state of the world changes with time. Sensors are employed to measure part or whole of the world’s state. However, sensors often fail amidst operation; feeding as such decision-making with wrong information about the world. Moreover, hardware degradation may alter dynamic behaviour, and subsequently the capabilities, of an autonomous system; rendering the original mission infeasible. This thesis applies machine learning to yield powerful and robust tools that can facilitate autonomy in modern systems. Incremental kernel regression is used for dynamic modelling. Algorithms of this sort are easy to train and are highly adaptive. Adaptivity allows for model adjustments, whenever the environment of operation changes. Bayesian reasoning provides a rigorous framework for addressing uncertainty. Moreover, using Bayesian Networks, complex inference regarding hardware degradation can be answered. Specifically, adaptive modelling is combined with Bayesian reasoning to yield recursive estimation algorithms that are robust to sensor failures. Two solutions are presented by extending existing recursive estimation algorithms from the robotics literature. The algorithms are deployed on an underwater vehicle and the performance is assessed in real-world experiments. A comparison against standard filters is also provided. Next, the previous algorithms are extended to consider sensor and actuator failures jointly. An algorithm that can detect thruster failures in an Autonomous Underwater Vehicle has been developed. Moreover, the algorithm adapts the dynamic model online to compensate for the detected fault. The performance of this algorithm was also tested in a real-world application. One step further than hardware fault detection, prognostics predict how much longer can a particular hardware component operate normally. Ubiquitous sensors in modern systems render data-driven prognostics a viable solution. However, training is based on skewed datasets; datasets where the samples from the faulty region of operation are much fewer than the ones from the healthy region of operation. This thesis presents a prognostic algorithm that tackles the problem of imbalanced (skewed) datasets.","",""
4,"N. Alaya, S. Yahia, M. Lamolle","Predicting the Empirical Robustness of the Ontology Reasoners based on Machine Learning Techniques",2015,"","","","",4,"2022-07-13 09:23:31","","10.5220/0005599800610073","","",,,,,4,0.57,1,3,7,"Reasoning with ontologies is one of the core tasks of research in Description Logics. A variety of reasoners    with highly optimized algorithms have been developed to allow inference tasks on expressive ontology    languages such as OWL (DL). However, unexpected behaviours of reasoner engines is often observed in practice.    Both reasoner time efficiency and result correctness would vary across input ontologies, which is hardly    predictable even for experienced reasoner designers. Seeking for better understanding of reasoner empirical    behaviours, we propose to use supervised machine learning techniques to automatically predict reasoner robustness    from its previous running. For this purpose, we introduced a set of comprehensive ontology features.    We conducted huge body of experiments for 6 well known reasoners and using over 1000 ontologies from the    OREâ2014 corpus. Our learning results show that we could build highly accuracy reasoner robustness predictive    models. Moreover, by interpreting these models, it would be possible to gain insights about particular    ontology features likely to be reasoner robustness degrading factors.","",""
18,"C. Rudin, David Edwin Carlson","The Secrets of Machine Learning: Ten Things You Wish You Had Known Earlier to be More Effective at Data Analysis",2019,"","","","",5,"2022-07-13 09:23:31","","10.1287/educ.2019.0200","","",,,,,18,6.00,9,2,3,"Despite the widespread usage of machine learning throughout organizations, there are some key principles that are commonly missed. In particular: 1) There are at least four main families for supervised learning: logical modeling methods, linear combination methods, case-based reasoning methods, and iterative summarization methods. 2) For many application domains, almost all machine learning methods perform similarly (with some caveats). Deep learning methods, which are the leading technique for computer vision problems, do not maintain an edge over other methods for most problems (and there are reasons why). 3) Neural networks are hard to train and weird stuff often happens when you try to train them. 4) If you don't use an interpretable model, you can make bad mistakes. 5) Explanations can be misleading and you can't trust them. 6) You can pretty much always find an accurate-yet-interpretable model, even for deep neural networks. 7) Special properties such as decision making or robustness must be built in, they don't happen on their own. 8) Causal inference is different than prediction (correlation is not causation). 9) There is a method to the madness of deep neural architectures, but not always. 10) It is a myth that artificial intelligence can do anything.","",""
1,"Aida Rahmattalabi, Alice Xiang","Promises and Challenges of Causality for Ethical Machine Learning",2022,"","","","",6,"2022-07-13 09:23:31","","","","",,,,,1,1.00,1,2,1,"In recent years, there has been increasing interest in causal reasoning for designing fair decision-making systems due to its compatibility with legal frameworks, interpretability for human stakeholders, and robustness to spurious correlations inherent in observational data, among other factors. The recent attention to causal fairness, however, has been accompanied with great skepticism due to practical and epistemological challenges with applying current causal fairness approaches in the literature. Motivated by the long-standing empirical work on causality in econometrics, social sciences, and biomedical sciences, in this paper we lay out the conditions for appropriate application of causal fairness under the""potential outcomes framework.""We highlight key aspects of causal inference that are often ignored in the causal fairness literature. In particular, we discuss the importance of specifying the nature and timing of interventions on social categories such as race or gender. Precisely, instead of postulating an intervention on immutable attributes, we propose a shift in focus to their perceptions and discuss the implications for fairness evaluation. We argue that such conceptualization of the intervention is key in evaluating the validity of causal assumptions and conducting sound causal analysis including avoiding post-treatment bias. Subsequently, we illustrate how causality can address the limitations of existing fairness metrics, including those that depend upon statistical correlations. Specifically, we introduce causal variants of common statistical notions of fairness, and we make a novel observation that under the causal framework there is no fundamental disagreement between different notions of fairness. Finally, we conduct extensive experiments where we demonstrate our approach for evaluating and mitigating unfairness, specially when post-treatment variables are present.","",""
0,"M. Christakis, Hasan Ferit Eniser, J. Hoffmann, A. Singla, Valentin Wüstholz","Specifying and Testing k-Safety Properties for Machine-Learning Models",2022,"","","","",7,"2022-07-13 09:23:31","","10.48550/arXiv.2206.06054","","",,,,,0,0.00,0,5,1,"Machine-learning models are becoming increasingly prevalent in our lives, for instance assisting in image-classification or decision-making tasks. Consequently, the reliability of these models is of critical importance and has resulted in the development of numerous approaches for validating and verifying their robustness and fairness. However, beyond such specific properties, it is challenging to specify, let alone check, general functional-correctness expectations from models. In this paper, we take inspiration from specifications used in formal methods, expressing functional-correctness properties by reasoning about k different executions—socalled k-safety properties. Considering a credit-screening model of a bank, the expected property that ""if a person is denied a loan and their income decreases, they should still be denied the loan"" is a 2-safety property. Here, we show the wide applicability of k-safety properties for machine-learning models and present the first specification language for expressing them. We also operationalize the language in a framework for automatically validating such properties using metamorphic testing. Our experiments show that our framework is effective in identifying property violations, and that detected bugs could be used to train better models.","",""
0,"Mohammadreza Amirian, Lukas Tuggener, R. Chavarriaga, Y. Satyawan, F. Schilling, F. Schwenker, Thilo Stadelmann","Two to trust : AutoML for safe modelling and interpretable deep learning for robustness",2020,"","","","",8,"2022-07-13 09:23:31","","10.21256/ZHAW-20217","","",,,,,0,0.00,0,7,2,"With great power comes great responsibility. The success of machine learning, especially deep learning, in research and practice has attracted a great deal of interest, which in turn necessitates increased trust. Sources of mistrust include matters of model genesis (“Is this really the appropriate model?”) and interpretability (“Why did the model come to this conclusion?”, “Is the model safe from being easily fooled by adversaries?”). In this paper, two partners for the trustworthiness tango are presented: recent advances and ideas, as well as practical applications in industry in (a) Automated machine learning (AutoML), a powerful tool to optimize deep neural network architectures and finetune hyperparameters, which promises to build models in a safer and more comprehensive way; (b) Interpretability of neural network outputs, which addresses the vital question regarding the reasoning behind model predictions and provides insights to improve robustness against adversarial attacks.","",""
9,"Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, B. Schölkopf, Kun Zhang","Adversarial Robustness through the Lens of Causality",2021,"","","","",9,"2022-07-13 09:23:31","","","","",,,,,9,9.00,1,8,1,"The adversarial vulnerability of deep neural networks has attracted significant attention in machine learning. From a causal viewpoint, adversarial attacks can be considered as a specific type of distribution change on natural data. As causal reasoning has an instinct for modeling distribution change, we propose to incorporate causality into mitigating adversarial vulnerability. However, causal formulations of the intuition of adversarial attack and the development of robust DNNs are still lacking in the literature. To bridge this gap, we construct a causal graph to model the generation process of adversarial examples and define the adversarial distribution to formalize the intuition of adversarial attacks. From a causal perspective, we find that the label is spuriously correlated with the style (content-independent) information when an instance is given. The spurious correlation implies that the adversarial distribution is constructed via making the statistical conditional association between style information and labels drastically different from that in natural distribution. Thus, DNNs that fit the spurious correlation are vulnerable to the adversarial distribution. Inspired by the observation, we propose the adversarial distribution alignment method to eliminate the difference between the natural distribution and the adversarial distribution. Extensive experiments demonstrate the efficacy of the proposed method. Our method can be seen as the first attempt to leverage causality for mitigating adversarial vulnerability.","",""
0,"Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, B. Scholkopf, Kun Zhang","CausalAdv: Adversarial Robustness through the Lens of Causality",2021,"","","","",10,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,8,1,"The adversarial vulnerability of deep neural networks has attracted signiﬁcant at-tention in machine learning. As causal reasoning has an instinct for modeling distribution change, it is essential to incorporate causality into analyzing this speciﬁc type of distribution change induced by adversarial attacks. However, causal formulations of the intuition of adversarial attacks and the development of robust DNNs are still lacking in the literature. To bridge this gap, we construct a causal graph to model the generation process of adversarial examples and deﬁne the adversarial distribution to formalize the intuition of adversarial attacks. From the causal perspective, we study the distinction between the natural and adversarial distribution and conclude that the origin of adversarial vulnerability is the focus of models on spurious correlations. Inspired by the causal understanding, we propose the Causal -inspired Adv ersarial distribution alignment method, CausalAdv, to eliminate the difference between natural and adversarial distributions by considering spurious correlations. Extensive experiments demonstrate the efﬁcacy of the proposed method. Our work is the ﬁrst attempt towards using causality to understand and mitigate the adversarial vulnerability.","",""
0,"Joao Marques-Silva","Automated Reasoning in Explainable AI",2021,"","","","",11,"2022-07-13 09:23:31","","10.3233/faia210109","","",,,,,0,0.00,0,1,1,"The envisioned applications of machine learning (ML) in high-risk and safetycritical applications hinge on systems that are robust in their operation and that can be trusted. Automated reasoning offers the solution to ensure robustness and to guarantee trust. This talk overviews recent efforts on applying automated reasoning tools in explaining black-box (and so non-interpretable) ML models [6], and relates such efforts with past work on reasoning about inconsistent logic formulas [11]. Moreover, the talk details the computation of rigorous explanations of black-box models, and how these serve for assessing the quality of widely used heuristic explanation approaches. The talk also covers important properties of rigorous explanations, including duality relationships between different kinds of explanations [7,5,4]. Finally, the talk briefly overviews ongoing work on mapping practical efficient [8,3] but also tractable explainability [9,10,2,1].","",""
2,"H. Hadj-Mabrouk","Case-based reasoning for safety assessment of critical software",2020,"","","","",12,"2022-07-13 09:23:31","","10.3233/idt-200016","","",,,,,2,1.00,2,1,2,"The commissioning of a new guided or automated rail transport system requires an in-depth analysis of all the methods, techniques, procedures, regulations and safety standards to ensure that the risk level of the future system does not present any danger likely to jeopardize the safety of travelers. Among these numerous safety methods implemented to guarantee safety at the system, automation, hardware and software level, there is a method called ""Software Errors and Effects Analysis (SEEA)"" whose objective is to determine the nature and the severity of the consequences of software failures, to propose measures to detect errors and finally to improve the robustness of the software. In order to strengthen and rationalize this SEEA method, we have agreed to use machine learning techniques and in particular Case-Based Reasoning (CBR) in order to assist the certification experts in their difficult task of assessing completeness and the consistency of safety of critical software equipment. The main objective consists, from a set of data in the form of accident scenarios or incidents experienced on rail transport systems (experience feedback), to exploit by automatic learning this mass of data to stimulate the imagination of certification experts and assist them in their crucial task of researching scenarios of potential accidents not taken into account during the design phase of new critical software. The originality of the tool developed lies not only in its ability to model, capitalize, sustain and disseminate SEEA expertise, but it represents the first research on the application of CBR to SEEA. In fact, in the field of rail transport, there are currently no software tools for assisting SEEAs based on machine learning techniques and in particular based on CBR.","",""
1,"Nikhil Naik, P. Nuzzo","Robustness Contracts for Scalable Verification of Neural Network-Enabled Cyber-Physical Systems",2020,"","","","",13,"2022-07-13 09:23:31","","10.1109/MEMOCODE51338.2020.9315118","","",,,,,1,0.50,1,2,2,"The proliferation of artificial intelligence based systems in all walks of life raises concerns about their safety and robustness, especially for cyber-physical systems including multiple machine learning components. In this paper, we introduce robustness contracts as a framework for compositional specification and reasoning about the robustness of cyber-physical systems based on neural network (NN) components. Robustness contracts can encompass and generalize a variety of notions of robustness which were previously proposed in the literature. They can seamlessly apply to NN-based perception as well as deep reinforcement learning (RL)-enabled control applications. We present a sound and complete algorithm that can efficiently verify the satisfaction of a class of robustness contracts on NNs by leveraging notions from Lagrangian duality to identify system configurations that violate the contracts. We illustrate the effectiveness of our approach on the verification of NN-based perception systems and deep RL-based control systems.","",""
173,"Xiaodong Liu, Yelong Shen, Kevin Duh, Jianfeng Gao","Stochastic Answer Networks for Machine Reading Comprehension",2017,"","","","",14,"2022-07-13 09:23:31","","10.18653/v1/P18-1157","","",,,,,173,34.60,43,4,5,"We propose a simple yet robust stochastic answer network (SAN) that simulates multi-step reasoning in machine reading comprehension. Compared to previous work such as ReasoNet which used reinforcement learning to determine the number of steps, the unique feature is the use of a kind of stochastic prediction dropout on the answer module (final layer) of the neural network during the training. We show that this simple trick improves robustness and achieves results competitive to the state-of-the-art on the Stanford Question Answering Dataset (SQuAD), the Adversarial SQuAD, and the Microsoft MAchine Reading COmprehension Dataset (MS MARCO).","",""
1,"T. Hinrichs, Greg Dunham, Kenneth D. Forbus","Analogical Learning in Tactical Decision Games",2021,"","","","",15,"2022-07-13 09:23:31","","","","",,,,,1,1.00,0,3,1,"Tactical Decision Games (TDGs) are military conflict scenarios presented both textually and graphically on a map. These scenarios provide a challenging domain for machine learning because they are open-ended, highly structured, and typically contain many details of varying relevance. We have developed a problem-solving component of an interactive companion system that proposes military tasks to solve TDG scenarios using a combination of analogical retrieval, mapping, and constraint propagation. We use this problem-solving component to explore analogical learning. In this paper, we describe the problems encountered in learning for this domain, and the methods we have developed to address these, such as partition constraints on analogical mapping correspondences and the use of incremental remapping to improve robustness. We present the results of learning experiments that show improvement in performance through the simple accumulation of examples, despite a weak domain theory. Content Areas: Case-Based Reasoning, Machine Learning","",""
8,"A. Mitrokhin, P. Sutor, Douglas Summers-Stay, C. Fermüller, Y. Aloimonos","Symbolic Representation and Learning With Hyperdimensional Computing",2020,"","","","",16,"2022-07-13 09:23:31","","10.3389/frobt.2020.00063","","",,,,,8,4.00,2,5,2,"It has been proposed that machine learning techniques can benefit from symbolic representations and reasoning systems. We describe a method in which the two can be combined in a natural and direct way by use of hyperdimensional vectors and hyperdimensional computing. By using hashing neural networks to produce binary vector representations of images, we show how hyperdimensional vectors can be constructed such that vector-symbolic inference arises naturally out of their output. We design the Hyperdimensional Inference Layer (HIL) to facilitate this process and evaluate its performance compared to baseline hashing networks. In addition to this, we show that separate network outputs can directly be fused at the vector symbolic level within HILs to improve performance and robustness of the overall model. Furthermore, to the best of our knowledge, this is the first instance in which meaningful hyperdimensional representations of images are created on real data, while still maintaining hyperdimensionality.","",""
1,"Hiranmay Ghosh","Deep Learning for Visual Cognition",2020,"","","","",17,"2022-07-13 09:23:31","","10.1002/9781119527886.ch8","","",,,,,1,0.50,1,1,2,"The reliance on machine learning in cognitive systems is further justified as it is not always possible to equip an intelligent agent with prior knowledge. In the modern times, the field of machine learning has been dominated by deep learning based on artificial neural networks. This chapter introduces deep learning for visual cognition. It starts with a brief introduction to deep neural networks (DNN) and some basic reusable configurations to realize various learning algorithms. The chapter discusses various modes of learning realized through DNN in some illustrative computer vision tasks. It presents a broad overview of the architecture of the networks and the principles involved. The chapter focuses on DNN‐based implementations of visual attention models, which is crucial for alleviating information overload in cognitive systems. It presents some research on synthesizing Bayesian reasoning with DNNs, aimed at improving the robustness of inferences. Finally, the chapter concludes with some salient observations on the topic.","",""
2,"E. Blasch, Zheng Liu, Yufeng Zheng, U. Majumder, A. Aved, P. Zulch","Multisource deep learning for situation awareness",2019,"","","","",18,"2022-07-13 09:23:31","","10.1117/12.2519236","","",,,,,2,0.67,0,6,3,"The resurgence of interest in artificial intelligence (AI) stems from impressive deep learning (DL) performance such as hierarchical supervised training using a Convolutional Neural Network (CNN). Current DL methods should provide contextual reasoning, explainable results, and repeatable understanding that require evaluation methods. This paper discusses DL techniques using multimodal (or multisource) information that extend measures of performance (MOP). Examples of joint multi-modal learning include imagery and text, video and radar, and other common sensor types. Issues with joint multimodal learning challenge many current methods and care is needed to apply machine learning methods. Results from Deep Multimodal Image Fusion (DMIF) using Electro-optical and infrared data demonstrate performance modeling based on distance to better understand DL robustness and quality to provide situation awareness.","",""
5,"M. Selfridge, D. J. Dickerson, S. F. Biggs","Cognitive Expert Systems and Machine Learning: Artificial Intelligence Research at the University of Connecticut",1987,"","","","",19,"2022-07-13 09:23:31","","10.1609/AIMAG.V8I1.577","","",,,,,5,0.14,2,3,35,"In order for next-generation expert systems to demonstrate the performance, robustness, flexibility, and learning ability of human experts, they will have to be based on cognitive models of expert human reasoning and learning. We call such next-generation systems cognitive expert systems. Research at the Artificial Intelligence Laboratory at the University of Connecticut is directed toward understanding the principles underlying cognitive expert systems and developing computer programs embodying those principles. The Causal Model Acquisition System (CMACS) learns causal models of physical mechanisms by understanding real-world natural language explanations of those mechanisms. The going Concern Expert ( GCX) uses business and environmental knowledge to assess whether a company will remain in business for at least the following year. The Business Information System (BIS) acquires business and environmental knowledge from in-depth reading of real-world news stories. These systems are based on theories of expert human reasoning and learning, and thus represent steps toward next-generation cognitive expert systems.","",""
79,"R. Raina, A. Ng, Christopher D. Manning","Robust Textual Inference Via Learning and Abductive Reasoning",2005,"","","","",20,"2022-07-13 09:23:31","","","","",,,,,79,4.65,26,3,17,"We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., 2000). An abductive theorem prover then tries to find the minimum ""cost"" set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.","",""
1,"Fernando Martínez-Plumed, David Castellano Falcón, Carlos Monserrat Aranda, J. Hernández-Orallo","When AI Difficulty Is Easy: The Explanatory Power of Predicting IRT Difficulty",2022,"","","","",21,"2022-07-13 09:23:31","","10.1609/aaai.v36i7.20739","","",,,,,1,1.00,0,4,1,"One of challenges of artificial intelligence as a whole is robustness. Many issues such as adversarial examples, out of distribution performance, Clever Hans phenomena, and the wider areas of AI evaluation and explainable AI, have to do with the following question: Did the system fail because it is a hard instance or because something else? In this paper we address this question with a generic method for estimating IRT-based instance difficulty for a wide range of AI domains covering several areas, from supervised feature-based classification to automated reasoning. We show how to estimate difficulty systematically using off-the-shelf machine learning regression models. We illustrate the usefulness of this estimation for a range of applications.","",""
0,"Qilin Xiong, Chun Liao, Zhenhong Yang, W. Gao","A Method for Accelerating YOLO by Hybrid Computing Based on ARM and FPGA",2021,"","","","",22,"2022-07-13 09:23:31","","10.1145/3508546.3508576","","",,,,,0,0.00,0,4,1,"CNN has promoted the rapid development of target recognition and detection technology. By comparison with machine learning, it has faster detection speed and higher robustness. However, the deployment of the CNN network model often needs more computing resources, which hinders the application of artificial intelligence technology. In this paper, the authors use the hybrid architecture of ARM and FPGA to deploy a You Only Look Once (YOLO) model on the FPGA to improve the efficiency of target recognition and detection under condition of low resources consumption and low power consumption. YOLO is a one-stage real-time detection model and it has high detection speed and remarkable accuracy. High-level Synthesis (HLS) is a fast development and verification technology of FPGA based on C/C++. We use HLS to implement the pipeline mechanism and complete the parallel calculation of convolution, thereby constructing a forward reasoning model of YOLOv3-tiny. In order to accelerate the forward inference process of YOLO, we combine convolution with batch normalization. The FPGA we use in the paper is Xilinx Zynq-7035 containing system on chip (SoC). We build the software and hardware co-architecture of ARM and FPGA on Zynq-7035, which makes full use of the logic control advantages of ARM and the logic computing advantages of FPGA. In the end, we achieve 28.99 GOP/S speed with only 3.715W power consumption. Finally, compared with the Ryzen 5 3600, we achieve 41.3inference speed at a lower clock rate.","",""
0,"Fang Ding, A. Wang, Qianbin Zhang","Lane Line Identification and Research Based on Markov Random Field",2022,"","","","",23,"2022-07-13 09:23:31","","10.3390/wevj13060106","","",,,,,0,0.00,0,3,1,"In view of the poor robustness and low accuracy in lane line identification based on digital image processing, this paper proposes a Markov random field intelligent algorithm based on machine learning to identify lane lines. The complete lane line identification steps are as follows: First, high-quality traffic scenario images are created by means of image preprocessing, which includes image graying, grayscale transformation, and the extraction of regions of interest (ROIs). Then, the images are modeled according to Markov random field theory, and model reasoning is performed based on the binary graph cut method. In the reasoning process, to achieve accurate lane line segmentation, i.e., the optimal solution of the model, the energy potential function is introduced to optimize the binary graph cut method. Finally, the lane line pixel label is marked according to the segmentation result. The experiments showed that the algorithm could accurately segment the lane line pixels after only 10 iterations, indicating that the identification method has good performance in both reasoning speed and identification accuracy, which takes account of both accuracy and real-time processing, and can meet the requirements of lane recognition for lightweight automatic driving systems.","",""
51,"U. Furbach, Ingo Glöckner, Björn Pelzer","An application of automated reasoning in natural language question answering",2010,"","","","",24,"2022-07-13 09:23:31","","10.3233/AIC-2010-0461","","",,,,,51,4.25,17,3,12,"The LogAnswer system is an application of automated reasoning to the field of open domain question answering. In order to find answers to natural language questions regarding arbitrary topics, the system integrates an automated theorem prover in a framework of natural language processing tools. The latter serve to construct an extensive knowledge base automatically from given textual sources, while the automated theorem prover makes it possible to derive answers by deductive reasoning. In the paper, we discuss the requirements to the prover that arise in this application, especially concerning efficiency and robustness. The proposed solution rests on incremental reasoning, relaxation of the query (if no proof of the full query is found), and other techniques. In order to improve the robustness of the approach to gaps of the background knowledge, the results of deductive processing are combined with shallow linguistic features by machine learning.","",""
19,"Xizhao Wang, Abdallah Bashir Musa","Advances in neural network based learning",2014,"","","","",25,"2022-07-13 09:23:31","","10.1007/s13042-013-0220-2","","",,,,,19,2.38,10,2,8,"","",""
2,"Jean-Baptiste Tristan, Joseph Tassarotti, Koundinya Vajjha, Michael L. Wick, A. Banerjee","Verification of ML Systems via Reparameterization",2020,"","","","",26,"2022-07-13 09:23:31","","","","",,,,,2,1.00,0,5,2,"As machine learning is increasingly used in essential systems, it is important to reduce or eliminate the incidence of serious bugs. A growing body of research has developed machine learning algorithms with formal guarantees about performance, robustness, or fairness. Yet, the analysis of these algorithms is often complex, and implementing such systems in practice introduces room for error. Proof assistants can be used to formally verify machine learning systems by constructing machine checked proofs of correctness that rule out such bugs. However, reasoning about probabilistic claims inside of a proof assistant remains challenging. We show how a probabilistic program can be automatically represented in a theorem prover using the concept of \emph{reparameterization}, and how some of the tedious proofs of measurability can be generated automatically from the probabilistic program. To demonstrate that this approach is broad enough to handle rather different types of machine learning systems, we verify both a classic result from statistical learning theory (PAC-learnability of decision stumps) and prove that the null model used in a Bayesian hypothesis test satisfies a fairness criterion called demographic parity.","",""
1,"Cemal Erdem, Ethan M. Bensman, Arnab Mutsuddy, Michael M. Saint-Antoine, M. Bouhaddou, R. Blake, William B. Dodd, Sean M. Gross, Laura M. Heiser, F. Feltus, M. Birtwistle","A Simple and Efficient Pipeline for Construction, Merging, Expansion, and Simulation of Large-Scale, Single-Cell Mechanistic Models",2020,"","","","",27,"2022-07-13 09:23:31","","10.1101/2020.11.09.373407","","",,,,,1,0.50,0,11,2,"The current era of big biomedical data accumulation and availability brings data integration opportunities for leveraging its totality to make new discoveries and/or clinically predictive models. Black-box statistical and machine learning methods are powerful for such integration, but often cannot provide mechanistic reasoning, particularly on the single-cell level. While single-cell mechanistic models clearly enable such reasoning, they are predominantly “small-scale”, and struggle with the scalability and reusability required for meaningful data integration. Here, we present an open-source pipeline for scalable, single-cell mechanistic modeling from simple, annotated input files that can serve as a foundation for mechanistic data integration. As a test case, we convert one of the largest existing single-cell mechanistic models to this format, demonstrating robustness and reproducibility of the approach. We show that the model cell line context can be changed with simple replacement of input file parameter values. We next use this new model to test alternative mechanistic hypotheses for the experimental observations that interferon-gamma (IFNG) inhibits epidermal growth factor (EGF)-induced cell proliferation. Model- based analysis suggested, and experiments support that these observations are better explained by IFNG-induced SOCS1 expression sequestering activated EGF receptors, thereby downregulating AKT activity, as opposed to direct IFNG-induced upregulation of p21 expression. Overall, this new pipeline enables large-scale, single-cell, and mechanistically-transparent modeling as a data integration modality complementary to machine learning.","",""
1,"Orpaz Goldstein, Mohammad Kachuee, Kimmo Kärkkäinen, M. Sarrafzadeh","Target-Focused Feature Selection Using Uncertainty Measurements in Healthcare Data",2020,"","","","",28,"2022-07-13 09:23:31","","10.1145/3383685","","",,,,,1,0.50,0,4,2,"Healthcare big data remains under-utilized due to various incompatibility issues between the domains of data analytics and healthcare. The lack of generalizable iterative feature acquisition methods under budget and machine learning models that allow reasoning with a model’s uncertainty are two examples. Meanwhile, a boost to the available data is currently under way with the rapid growth in the Internet of Things applications and personalized healthcare. For the healthcare domain to be able to adopt models that take advantage of this big data, machine learning models should be coupled with more informative, germane feature acquisition methods, consequently adding robustness to the model’s results. We introduce an approach to feature selection that is based on Bayesian learning, allowing us to report the level of uncertainty in the model, combined with false-positive and false-negative rates. In addition, measuring target-specific uncertainty lifts the restriction on feature selection being target agnostic, allowing for feature acquisition based on a target of focus. We show that acquiring features for a specific target is at least as good as deep learning feature selection methods and common linear feature selection approaches for small non-sparse datasets, and surpasses these when faced with real-world data that is larger in scale and sparseness.","",""
0,"L. A. Passos, D. Jodas, L. C. Ribeiro, T. P. Moreira, J. Papa","O^2PF: Oversampling via Optimum-Path Forest for Breast Cancer Detection",2020,"","","","",29,"2022-07-13 09:23:31","","10.1109/CBMS49503.2020.00100","","",,,,,0,0.00,0,5,2,"Breast cancer is among the most deadly diseases, distressing mostly women worldwide. Although traditional methods for detection have presented themselves as valid for the task, they still commonly present low accuracies and demand considerable time and effort from professionals. Therefore, a computer-aided diagnosis (CAD) system capable of providing early detection becomes hugely desirable. In the last decade, machine learning-based techniques have been of paramount importance in this context, since they are capable of extracting essential information from data and reasoning about it. However, such approaches still suffer from imbalanced data, specifically on medical issues, where the number of healthy people samples is, in general, considerably higher than the number of patients. Therefore this paper proposes the O2PF, a data oversampling method based on the unsupervised Optimum-Path Forest Algorithm. Experiments conducted over the full oversampling scenario state the robustness of the model, which is compared against three well-established oversampling methods considering three breast cancer and three general-purpose tasks for medical issues datasets.","",""
28,"Yiqun Xie, E. Eftelioglu, Reem Y. Ali, Xun Tang, Yan Li, Ruhi Doshi, S. Shekhar","Transdisciplinary Foundations of Geospatial Data Science",2017,"","","","",30,"2022-07-13 09:23:31","","10.3390/ijgi6120395","","",,,,,28,5.60,4,7,5,"Recent developments in data mining and machine learning approaches have brought lots of excitement in providing solutions for challenging tasks (e.g., computer vision). However, many approaches have limited interpretability, so their success and failure modes are difficult to understand and their scientific robustness is difficult to evaluate. Thus, there is an urgent need for better understanding of the scientific reasoning behind data mining and machine learning approaches. This requires taking a transdisciplinary view of data science and recognizing its foundations in mathematics, statistics, and computer science. Focusing on the geospatial domain, we apply this crucial transdisciplinary perspective to five common geospatial techniques (hotspot detection, colocation detection, prediction, outlier detection and teleconnection detection). We also describe challenges and opportunities for future advancement.","",""
18,"A. Stassopoulou, M. Dikaiakos","A Probabilistic Reasoning Approach for Discovering Web Crawler Sessions",2007,"","","","",31,"2022-07-13 09:23:31","","10.1007/978-3-540-72524-4_29","","",,,,,18,1.20,9,2,15,"","",""
1,"Laura Isabel Galindez Olascoaga, Wannes Meert, Nimish Shah, Guy Van den Broeck, M. Verhelst","On Hardware-Aware Probabilistic Frameworks for Resource Constrained Embedded Applications",2019,"","","","",32,"2022-07-13 09:23:31","","10.1109/EMC2-NIPS53020.2019.00023","","",,,,,1,0.33,0,5,3,"Edge reasoning attempts to mitigate latency and privacy shortcomings of cloud computing paradigms. However, it introduces additional challenges linked to the devices' resource constraints and the applications' dynamic conditions. To address these challenges, we have proposed a hardware-aware probabilistic framework that optimizes the target machine learning model under actual hardware constraints. This framework relies on tractable probabilistic models, as they facilitate efficient inference, while exhibiting a number of traits relevant to the application range of interest: robustness to missing data, joint prediction capabilities, explainability, and small data needs. In this work, we expand on this framework by introducing a discriminative-generative approach to model learning, which retains the robustness of a generative model under missing data but can potentially improve its discriminative performance. In addition, we demonstrate how the applicability of this framework goes beyond classification tasks, and can be used for density estimation tasks, relevant to applications such as mobile speaker verification.","",""
0,"Yang Cai, R. Stumpf, M. Tomlinson, T. Wynne, S. Chung, Xavier Boutonnier","Interactive Spatiotemporal Reasoning",2009,"","","","",33,"2022-07-13 09:23:31","","10.1007/978-1-84800-269-2_14","","",,,,,0,0.00,0,6,13,"","",""
0,"A. Stassopoulou, M. Dikaiakos","' s personal copy Web robot detection : A probabilistic reasoning approach",2009,"","","","",34,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,2,13,"In this paper, we introduce a probabilistic modeling approach for addressing the problem of Web robot detection from Web-server access logs. More specifically, we construct a Bayesian network that classifies automatically access log sessions as being crawleror human-induced, by combining various pieces of evidence proven to characterize crawler and human behavior. Our approach uses an adaptive-threshold technique to extract Web sessions from access logs. Then, we apply machine learning techniques to determine the parameters of the probabilistic model. The resulting classification is based on the maximum posterior probability of all classes given the available evidence. We apply our method to real Web-server logs and obtain results that demonstrate the robustness and effectiveness of probabilistic reasoning for crawler detection. 2008 Elsevier B.V. All rights reserved.","",""
1,"D. Neelima, J. Karthik, K. John, S. Gowthami, Janmenjoy Nayak","Soft Computing-Based Intrusion Detection Approaches: An Analytical Study",2018,"","","","",35,"2022-07-13 09:23:31","","10.1007/978-981-13-0514-6_61","","",,,,,1,0.25,0,5,4,"","",""
14,"J. Miralles, M. López-Sánchez, Maria Salamó, Pedro Avila, J. Rodríguez-Aguilar","Robust Regulation Adaptation in Multi-Agent Systems",2013,"","","","",36,"2022-07-13 09:23:31","","10.1145/2517328","","",,,,,14,1.56,3,5,9,"Adaptive organisation-centred multi-agent systems can dynamically modify their organisational components to better accomplish their goals. Our research line proposes an abstract distributed architecture (2-LAMA) to endow an organisation with adaptation capabilities. This article focuses on regulation-adaptation based on a machine learning approach, in which adaptation is learned by applying a tailored case-based reasoning method. We evaluate the robustness of the system when it is populated by non compliant agents. The evaluation is performed in a peer-to-peer sharing network scenario. Results show that our proposal significantly improves system performance and can cope with regulation violators without incorporating any specific regulation-compliance enforcement mechanisms.","",""
6,"Fangming Ye","Knowledge-Driven Board-Level Functional Fault Diagnosis",2016,"","","","",37,"2022-07-13 09:23:31","","10.1007/978-3-319-40210-9","","",,,,,6,1.00,6,1,6,"","",""
44,"David Ahn, S. F. Adafre, M. de Rijke","Towards Task-Based Temporal Extraction and Recognition",2005,"","","","",38,"2022-07-13 09:23:31","","","","",,,,,44,2.59,15,3,17,"We seek to improve the robustness and portability of tem- poral information extraction systems by incorporating data-driven tech- niques. We present two sets of experiments pointing us in this direction. The first shows that machine-learning-based recognition of temporal ex- pressions not only achieves high accuracy on its own but can also improve rule-based normalization. The second makes use of a staged normaliza- tion architecture to experiment with machine learned classifiers for cer- tain disambiguation sub-tasks within the normalization task.","",""
44,"L. Zadeh","The roles of soft computing and fuzzy logic in the conception, design and deployment of intelligent systems",1996,"","","","",39,"2022-07-13 09:23:31","","10.1109/FUZZY.1997.616336","","",,,,,44,1.69,44,1,26,"Summary form only given. Soft computing (SC) is a consortium of methodologies which provide a foundation for intelligent systems. The principal methods are fuzzy logic (FL), neurocomputing (NC), genetic computing (GC) and probabilistic computing (PC), with PC subsuming evidential reasoning, uncertainty management and some machine learning theory. The main contribution of FL is a methodology for dealing with imprecision, approximate reasoning, fuzzy information granulation and computing with words; that of NC system identification, learning and adaption; that of CC systematized random research, tuning and optimization; and that of PC decision analysis and uncertainty management. The guiding principle of soft computing is: Exploit the tolerance for imprecision, uncertainty and partial truth to achieve tractability, robustness, low solution cost and better rapport with reality. The 4 methods are complementary rather than competitive. Their use in combination leads to hybrid intelligent systems. The most visible of such systems are neuro-fuzzy systems. The ubiquity of intelligent systems is certain to have a profound impact on the ways in which man-made systems are conceived, designed, manufactured, employed and interacted with. This is the perspective in which basic issues relating to soft computing and intelligent systems are addressed.","",""
23,"A. Stassopoulou, M. Dikaiakos","Crawler Detection: A Bayesian Approach",2006,"","","","",40,"2022-07-13 09:23:31","","10.1109/ICISP.2006.7","","",,,,,23,1.44,12,2,16,"In this paper, we introduce a probabilistic modeling approach for addressing the problem of Web robot detection from Web-server access logs. More specifically, we construct a Bayesian network that classifies automatically access-log sessions as being crawler- or human-induced, by combining various pieces of evidence proven to characterize crawler and human behavior. Our approach uses machine learning techniques to determine the parameters of the probabilistic model. We apply our method to real Web-server logs and obtain results that demonstrate the robustness and effectiveness of probabilistic reasoning for crawler detection","",""
30,"Johan Bos, K. Markert","Recognising Textual Entailment with Robust Logical Inference",2005,"","","","",41,"2022-07-13 09:23:31","","10.1007/11736790_23","","",,,,,30,1.76,15,2,17,"","",""
1,"P. Perner","Ultra Sonic Image Segmentation and Interpretation based on CBR",,"","","","",42,"2022-07-13 09:23:31","","","","",,,,,1,0.00,1,1,,"The existing image interpretation systems lack robustness and accuracy. They cannot adapt to changing environmental conditions and to new objects. The application of machine learning to image interpretation is the next logical step. Our proposed approach aims at the development of dedicated machine learning techniques at all levels of image interpretation in a systematic fashion. In the paper we propose a system, which uses Case-Based Reasoning (CBR) to optimize image segmentation at the low level according to changing image acquisition conditions and image quality. The intermediate-level unit extracts the case representation used by the high-level unit for further processing. At the high level, CBR is employed to dynamically adapt image interpretation.","",""
12,"C. Bauckhage, M. Hanheide, S. Wrede, Thomas Käster, M. Pfeiffer, G. Sagerer","Vision Systems with the Human in the Loop",2005,"","","","",43,"2022-07-13 09:23:31","","10.1155/ASP.2005.2375","","",,,,,12,0.71,2,6,17,"The emerging cognitive vision paradigm deals with vision systems that apply machine learning and automatic reasoning in order to learn from what they perceive. Cognitive vision systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are cognitive vision systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.","",""
0,"Peer-Olaf Siebers","Hongmei He (intelligent System Lab, University of Bristol): Soft Computing Approaches under the Framework of Hierarchical Decision Making or Classification System",2010,"","","","",44,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,12,"Hongmei He (Intelligent System Lab, University of Bristol): Soft Computing Approaches Under the Framework of Hierarchical Decision Making or Classification System With the development of AI, we can see there are a surprising number of the brain functions of the human Intelligent System (IS) are quite similar to those of an artificial IS, since most artificial ISs are modelled through naturally emulating human intelligence. A wide variety of approaches have been utilised in the functional design of artificial ISs. For example, fuzzy logic for robustness, decision trees for the transparency of reasoning, machine learning for knowledge learning, semantics for understandability, probabilistic reasoning, and neural computing, etc.","",""
12,"P. Perner","CBR-Based Ultra Sonic Image Interpretation",2000,"","","","",45,"2022-07-13 09:23:31","","10.1007/3-540-44527-7_41","","",,,,,12,0.55,12,1,22,"","",""
9,"J. Aberdeen, J. Burger, D. Connolly, Susan Roberts, M. Vilain","MITRE-Bedford: description of the ALEMBIC system as used for MUC-4",1992,"","","","",46,"2022-07-13 09:23:31","","10.3115/1072064.1072097","","",,,,,9,0.30,2,5,30,"The ALEMBIC text understanding system fielded at MUC-4 by MITRE-Bedford is primarily based on natural language techniques. ALEMBIC is a research prototype that is intended to explore several major areas of investigation:• Error recovery, involving primarily issues of semi-parsing and recovery of plausible attachments.• Robustness, involving primarily issues of uncertain reasoning and tractable inference.• Self-extensibility, focusing primarily on machine learning of natural language and user-configurable semantics.• System integration, through SGML (the Standard Generalized Markup Language), both at the level of meaning analysis and at the overall application level.","",""
1,"E. Kitsios, M. Doumpos, C. Zopounidis","CREDIT CARD APPLICATION ASSESSMENT USING A NEURO-FUZZY CLASSIFICATION SYSTEM",2006,"","","","",47,"2022-07-13 09:23:31","","10.25102/FER.2006.01.01","","",,,,,1,0.06,0,3,16,"Credit cards constitute one of the most common forms of consumer loans. The main purpose of this paper is to apply fuzzy data analysis to the credit scoring problem. A neuro-fuzzy classification technique is compared to the logistic regression approach and novel machine learning algorithms that are currently being investigated as credit scoring methods. The 10-fold cross-validation procedure is performed to analyze the generalization properties and the robustness of the developed models. Neuro-fuzzy classification systems allow for prior knowledge to be imbedded in the analysis and utilize human expertise in the form of fuzzy if then rules to provide an insight into the reasoning mechanism behind the credit approval/rejection decision. This feature is particularly useful in financial applications such as credit granting, where credit analysts should be in a position to provide an explanation for their decisions.","",""
3,"J. Aberdeen, J. Burger, D. Connolly, Susan Roberts, M. Vilain","Mitre-Bedford: description of the Alembic system as used for MUC-5",1993,"","","","",48,"2022-07-13 09:23:31","","10.3115/1072017.1072033","","",,,,,3,0.10,1,5,29,"The Alembic text understanding system fielded at MUC-5 by MITRE is an extensive rewrite of the system we presented at MUC-4. Alembic is a research prototype that is still young, and is thus in the process of ongoing development. Our work is part of an internally-funded research initiative aimed at processing open source texts, i.e., free natural language texts drawn from broadcast transcripts, news wires, etc. This initiative explores several major research areas:• Error recovery, primarily involving issues of semi-parsing and recovery of plausible attachments.• Robustness, primarily involving issues of uncertain reasoning and tractable inference.• Self-extensibility, focusing primarily on machine learning of natural language and user-configurable semantics.• System integration, through SGML (the Standard Generalized Markup Language), both at the level of meaning analysis and at the overall application level.","",""
3,"古橋 武","Advances in fuzzy logic, neural networks and genetic algorithms : IEEE/Nagoya-University World Wisepersons Workshop, Nagoya, Japan, August 9-10, 1994 : selected papers",1995,"","","","",49,"2022-07-13 09:23:31","","","","",,,,,3,0.11,3,1,27,"Fuzzy associative memory system and its application to multi-modal interface.- Hybrid connectionist fuzzy systems for speech recognition and the use of connectionist production systems.- Fuzzy gaussian potential neural networks using a functional reasoning.- Recurrent fuzzy logic using neural network.- Information aggregating networks based on extended Sugeno's fuzzy integral.- A neuro-fuzzy architecture for high performance classification.- Investigation of stability and robustness of a fuzzy traction control system.- Knowledge-based rules for control of the sake (Ginjoshu) making process and their application in fuzzy control.- A framework for studying the effects of dynamic crossover, mutation, and population sizing in genetic algorithms.- Unsupervised/supervised learning for RBF-fuzzy system.- Genetic algorithms for the development of fuzzy controllers for mobile robots.- A new approach to genetic based machine learning and an efficient finding of fuzzy rules.- A neuro-money recognition using optimized masks by GA.- Genetic-fuzzy systems for financial decision making.","",""
3,"Suk Joon Hong, B. Bennett","Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning and Machine Learning",2020,"","","","",50,"2022-07-13 09:23:31","","10.4230/OASIcs.LDK.2021.41","","",,,,,3,1.50,2,2,2,"The Winograd Schema Challenge (WSC) is a common-sense reasoning task that requires background knowledge. In this paper, we contribute to tackling WSC in four ways. Firstly, we suggest a keyword method to define a restricted domain where distinctive high-level semantic patterns can be found. A thanking domain was defined by key-words, and the data set in this domain is used in our experiments. Secondly, we develop a high-level knowledge-based reasoning method using semantic roles which is based on the method of Sharma [2019]. Thirdly, we propose an ensemble method to combine knowledge-based reasoning and machine learning which shows the best performance in our experiments. As a machine learning method, we used Bidirectional Encoder Representations from Transformers (BERT) [Kocijan et al., 2019]. Lastly, in terms of evaluation, we suggest a ""robust"" accuracy measurement by modifying that of Trichelair et al. [2018]. As with their switching method, we evaluate a model by considering its performance on trivial variants of each sentence in the test set.","",""
0,"Kaiyu Yang","1 Machine Learning for Reasoning",2021,"","","","",51,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,1,"Reasoning is a core component of human intelligence that machines still struggle with. I do research in the field of artificial intelligence, with the long-term goal of building machines that reason precisely, systematically, in ways that are interpretable and robust to ambiguity in real-world environments. My research advances towards this goal by attempting to combine the complementary strengths of machine learning and symbolic reasoning. My graduate research has focused on developing machine learning models that represent reasoning via symbolic proofs. They show the promise of new learning paradigms that I envision to be more robust, interpretable, and trustworthy for deployment in real-world high-stake applications. Symbolic reasoning is precise and generalizes systematically to unseen scenarios. But it has been restricted to domains amenable to rigid formalization. In contrast, machine learning has the flexibility to handle noisy and ambiguous domains that are hard to formalize. But predominant machine learning models, such as deep neural networks, are notoriously uninterpretable, data-hungry, and incapable of generalizing outside the training data distribution. Integrating the strengths of both approaches is essential for building flexible reasoning machines with precise and systematic generalization. However, due to the discrete nature of symbolic reasoning, such integration may require a radical departure from the predominant paradigm of gradient-based learning. And my research tries to answer what that alternative form of learning might look like.","",""
0,"Carlo Mehli, K. Hinkelmann, S. Jüngling","Decision Support combining Machine Learning, Knowledge Representation and Case-Based Reasoning",2021,"","","","",52,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,3,1,"Knowledge and knowledge work are essential for the success of companies nowadays. Decisions are based on knowledge and better knowledge leads to more informed decisions. Therefore, the management of knowledge and support of decision making has increasingly become a source of competitive advantage for organizations. The current research uses a design science research approach (DSR) with the aim to improve the decision making of a knowledge intensive process such as the student admission process, which is done manually until now. In the awareness phase of the DSR process, the case study research method is applied to analyze the decision making and the knowledge that is needed to derive the decisions. Based on the analysis of the application scenario, suitable methods to support decision making were identified. The resulting system design is based on a combination of Case-Based Reasoning (CBR) and Machine Learning (ML). The proposed system design and prototype has been validated using triangulation evaluation, to assess the impact of the proposed system on the application scenario. The evaluation revealed that the additional hints from CBR and ML can assist the deans of the study program to improve the knowledge management and increase the quality, transparency and consistency of the decision-making process in the student application process. Furthermore, the proposed approach fosters the exchange of knowledge among the different process participants involved and codifies previously tacit knowledge to some extent and provides relevant externalized knowledge to decision makers at the required moment. The designed prototype showcases how ML and CBR methodologies can be combined to support decision making in knowledge intensive processes and finally concludes with potential recommendations for future research.","",""
0,"Botros N. Hanna, Linyu Lin, Paridhi Athe, T. Son, N. Dinh","Trusting Machine Learning in Nuclear Plant Control: A Reasoning-Based Discrepancy Checker",2021,"","","","",53,"2022-07-13 09:23:31","","10.13182/t124-34310","","",,,,,0,0.00,0,5,1,"","",""
9,"Filippos Gouidis, Alexandros Vassiliades, T. Patkos, Antonis A. Argyros, Nick Bassiliades, D. Plexousakis","A Review on Intelligent Object Perception Methods Combining Knowledge-based Reasoning and Machine Learning",2019,"","","","",54,"2022-07-13 09:23:31","","","","",,,,,9,3.00,2,6,3,"Object perception is a fundamental sub-field of Computer Vision, covering a multitude of individual areas and having contributed high-impact results. While Machine Learning has been traditionally applied to address related problems, recent works also seek ways to integrate knowledge engineering in order to expand the level of intelligence of the visual interpretation of objects, their properties and their relations with their environment. In this paper, we attempt a systematic investigation of how knowledge-based methods contribute to diverse object perception tasks. We review the latest achievements and identify prominent research directions.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",55,"2022-07-13 09:23:31","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
0,"Ying Zhao, Lauren Jones","Integrating Human Reasoning and Machine Learning to Classify Cyber Attacks",2020,"","","","",56,"2022-07-13 09:23:31","","10.1007/978-3-030-55692-1_8","","",,,,,0,0.00,0,2,2,"","",""
89,"C. Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, Chudi Zhong","Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",2021,"","","","",57,"2022-07-13 09:23:31","","","","",,,,,89,89.00,15,6,1,"Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the “Rashomon set” of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.1","",""
43,"Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, Zhi-Hua Zhou","Bridging Machine Learning and Logical Reasoning by Abductive Learning",2019,"","","","",58,"2022-07-13 09:23:31","","","","",,,,,43,14.33,11,4,3,"Perception and reasoning are two representative abilities of intelligence that are integrated seamlessly during human problem-solving processes. In the area of artificial intelligence (AI), the two abilities are usually realised by machine learning and logic programming, respectively. However, the two categories of techniques were developed separately throughout most of the history of AI. In this paper, we present the abductive learning targeted at unifying the two AI paradigms in a mutually beneficial way, where the machine learning model learns to perceive primitive logic facts from data, while logical reasoning can exploit symbolic domain knowledge and correct the wrongly perceived facts for improving the machine learning models. Furthermore, we propose a novel approach to optimise the machine learning model and the logical reasoning model jointly. We demonstrate that by using abductive learning, machines can learn to recognise numbers and resolve unknown mathematical operations simultaneously from images of simple hand-written equations. Moreover, the learned models can be generalised to longer equations and adapted to different tasks, which is beyond the capability of state-of-the-art deep learning models.","",""
77,"A. Qayyum, Junaid Qadir, M. Bilal, A. Al-Fuqaha","Secure and Robust Machine Learning for Healthcare: A Survey",2020,"","","","",59,"2022-07-13 09:23:31","","10.1109/RBME.2020.3013489","","",,,,,77,38.50,19,4,2,"Recent years have witnessed widespread adoption of machine learning (ML)/deep learning (DL) techniques due to their superior performance for a variety of healthcare applications ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx) using multi-dimensional medical images. Notwithstanding the impressive performance of ML/DL, there are still lingering doubts regarding the robustness of ML/DL in healthcare settings (which is traditionally considered quite challenging due to the myriad security and privacy issues involved), especially in light of recent results that have shown that ML/DL are vulnerable to adversarial attacks. In this paper, we present an overview of various application areas in healthcare that leverage such techniques from security and privacy point of view and present associated challenges. In addition, we present potential methods to ensure secure and privacy-preserving ML for healthcare applications. Finally, we provide insight into the current research challenges and promising directions for future research.","",""
0,"Junbo Wang, Amitangshu Pal, Qinglin Yang, K. Kant, Kaiming Zhu, Song Guo","Collaborative Machine Learning: Schemes, Robustness, and Privacy.",2022,"","","","",60,"2022-07-13 09:23:31","","10.1109/TNNLS.2022.3169347","","",,,,,0,0.00,0,6,1,"Distributed machine learning (ML) was originally introduced to solve a complex ML problem in a parallel way for more efficient usage of computation resources. In recent years, such learning has been extended to satisfy other objectives, namely, performing learning in situ on the training data at multiple locations and keeping the training datasets private while still allowing sharing of the model. However, these objectives have led to considerable research on the vulnerabilities of distributed learning both in terms of privacy concerns of the training data and the robustness of the learned overall model due to bad or maliciously crafted training data. This article provides a comprehensive survey of various privacy, security, and robustness issues in distributed ML.","",""
66,"Zhi-Hua Zhou","Abductive learning: towards bridging machine learning and logical reasoning",2019,"","","","",61,"2022-07-13 09:23:31","","10.1007/s11432-018-9801-4","","",,,,,66,22.00,66,1,3,"","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",62,"2022-07-13 09:23:31","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
20,"Hao Liu, Jiwen Lu, Minghao Guo, Suping Wu, Jie Zhou","Learning Reasoning-Decision Networks for Robust Face Alignment",2020,"","","","",63,"2022-07-13 09:23:31","","10.1109/TPAMI.2018.2885298","","",,,,,20,10.00,4,5,2,"In this paper, we propose an end-to-end reasoning-decision networks (RDN) approach for robust face alignment via policy gradient. Unlike the conventional coarse-to-fine approaches which likely lead to bias prediction due to poor initialization, our approach aims to learn a policy by leveraging raw pixels to reason a subset of shape candidates, sequentially making plausible decisions to remove outliers for robust initialization. To achieve this, we formulate face alignment as a Markov decision process by defining an agent, which typically interacts with a trajectory of states, actions, state transitions and rewards. The agent seeks an optimal shape searching policy over the whole shape space by maximizing a discounted sum of the received values. To further improve the alignment performance, we develop an LSTM-based value function to evaluate the shape quality. During the training procedure, we adjust the gradient of our value function in directions of the policy gradient. This prevents our training goal from being trapped into local optima entangled by both the pose deformations and appearance variations especially in unconstrained environments. Experimental results show that our proposed RDN consistently outperforms most state-of-the-art approaches on four widely-evaluated challenging datasets.","",""
1345,"D. Barber","Bayesian reasoning and machine learning",2012,"","","","",64,"2022-07-13 09:23:31","","10.1017/cbo9780511804779","","",,,,,1345,134.50,1345,1,10,"Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.","",""
165,"Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, R. Socher, Caiming Xiong","Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering",2019,"","","","",65,"2022-07-13 09:23:31","","","","",,,,,165,55.00,33,5,3,"Answering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions. Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents. Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path. Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.","",""
5,"Haoyu Ren, Darko Anicic, T. Runkler","The synergy of complex event processing and tiny machine learning in industrial IoT",2021,"","","","",66,"2022-07-13 09:23:31","","10.1145/3465480.3466928","","",,,,,5,5.00,2,3,1,"Focusing on comprehensive networking, the Industrial Internet-of-Things (IIoT) facilitates efficiency and robustness in factory operations. Various intelligent sensors play a central role, as they generate a vast amount of real-time data that can provide insights into manufacturing. Complex event processing (CEP) and machine learning (ML) have been developed actively in the last years in IIoT to identify patterns in heterogeneous data streams and fuse raw data into tangible facts. In a traditional compute-centric paradigm, the raw field data are continuously sent to the cloud and processed centrally. As IIoT devices become increasingly pervasive, concerns are raised since transmitting such an amount of data is energy-intensive, vulnerable to be intercepted, and subjected to high latency. Decentralized on-device ML and CEP provide a solution where data is processed primarily on edge devices. Thus communications can be minimized. However, this is no mean feat because most IIoT edge devices are resource-constrained with low power consumption. This paper proposes a framework that exploits ML and CEP's synergy at the edge in distributed sensor networks. By leveraging tiny ML and μCEP, we now shift the computation from the cloud to the resource-constrained IIoT devices and allow users to adapt on-device ML models and CEP reasoning rules flexibly on the fly. Lastly, we demonstrate the proposed solution and show its effectiveness and feasibility using an industrial use case of machine safety monitoring.","",""
3,"Phyo Htet Hein, Elisabeth Kames, Cheng Chen, Beshoy Morkos","Employing machine learning techniques to assess requirement change volatility",2021,"","","","",67,"2022-07-13 09:23:31","","10.1007/s00163-020-00353-6","","",,,,,3,3.00,1,4,1,"","",""
0,"W. Zong, Yang-Wai Chow, W. Susilo","Visual Analysis of Adversarial Examples in Machine Learning",2021,"","","","",68,"2022-07-13 09:23:31","","10.1007/978-981-33-6726-5_4","","",,,,,0,0.00,0,3,1,"","",""
0,"D. K. Chebanov, I. Mikhaylova, N. Tatevosova","Abstract PO086: Method for predicting the effectiveness of the developed immune dendritic cell vaccine in melanoma patients based on cell surface antigens and machine learning with non-classical logic",2021,"","","","",69,"2022-07-13 09:23:31","","10.1158/2326-6074.TUMIMM20-PO086","","",,,,,0,0.00,0,3,1,"Patients data: We had 39 patients of 2 categories: with an objective response on dendritic cell vaccine therapy (20) and with disease progression without a response (19). All of them had 21 biomarkers (antigen concentration) as features. The positive effect means that the patient responded to therapy. The features data has quantitative (continuous) values, but we made it categorical by determining the 6 intervals, so each of the biomarkers was replaced with 6 encoding (‘dummy’) variables with possible values 1 or 0, depending on if the patient’s biomarker value belongs to this interval. Methods: The machine learning algorithm for response prediction is called JSM method for automatic support of scientific research (JSM method ASSR). It allows conducting a plausible reasoning that is realized in hypotheses generating and keeping only those that remain after each database enlargement. The reasoning is based on the similarity of the objects, that can be obtained with patients’ (objects’) features intersection using the statements from the set theory. According to it, the object is representing by a set of features, and hypotheses about its belongings to a class are also sets of features, that are specific for the current class. So, for each class there is a separate amount of hypotheses is generating. On the prediction stage each object given for the prediction is being checked for how many hypotheses are entering into it, or, in other words – is a subset of this object. Based on this information prediction is making: it depends on which hypotheses (of which class) are prevailing in entering in the object. This kind of machine learning approach also allows us to get the reasons why the particular object is classified into his class. So it can be used not only for the classification problem but also for the knowledge discovery about effects’ reasons. We divided the database into 2 batches: source base (18 objects) and first enlargement (17 objects) for the learning, and the rest 4 objects were left for testing. The source base and its enlargement are being permutated during the learning process for more reliability and robustness. We applied a cross-validation, according to which each object was at least 1 time in the test group. So it was 10 learning launches with predictions: 9 with 4 test examples and the rest 1 - with 3 test examples. Results: On all 10 cross-validation launches, there were 26 correct predictions. Also were 5 cases with a failure, 5 false-positive predictions, and 3 false-negative ones. Recall of the model was 85%, and precision is 77%, F1 score = 0.81. We also obtained reasons, which were common for all the database permutation. It meant that patients who will not respond to therapy should have CD8 value at interval 39.9-54.1 and IRI at interval 0.29-0.7. Discussion: Actually 39 samples are a small amount of data even for the JSM method ASSR, but we showed the suitability of described approach for the quantity data predicting and the reasons extracting. With the enlargement of the source database, it will be possible to get higher results. Citation Format: Dmitrii K. Chebanov, Irina N. Mikhaylova, Nadezhda S. Tatevosova. Method for predicting the effectiveness of the developed immune dendritic cell vaccine in melanoma patients based on cell surface antigens and machine learning with non-classical logic [abstract]. In: Abstracts: AACR Virtual Special Conference: Tumor Immunology and Immunotherapy; 2020 Oct 19-20. Philadelphia (PA): AACR; Cancer Immunol Res 2021;9(2 Suppl):Abstract nr PO086.","",""
0,"Yan Zhou, Murat Kantarcioglu, B. Xi","A Game Theoretic Perspective on Adversarial Machine Learning and Related Cybersecurity Applications",2021,"","","","",70,"2022-07-13 09:23:31","","10.1002/9781119723950.ch13","","",,,,,0,0.00,0,3,1,"In cybersecurity applications where machine learning algorithms are increasingly used to detect vulnerabilities, a somewhat unique challenge arises as exploits targeting machine learning models are constantly devised by the attackers. Traditional machine learning models are no longer robust and reliable when they are under attack. The action and reaction between machine learning systems and the adversary can be modeled as a game between two or more players. Under well‐defined attack models, game theory can provide robustness guarantee for machine learning models that are otherwise vulnerable to application‐time data corruption. We review two cases of game theory‐based machine learning techniques: in one case, players play a zero sum game by following a minimax strategy, while in the other case, players play a sequential game with one player as the leader and the rest as the followers. Experimental results on e‐mail spam and web spam datasets are presented. In the zero sum game, we demonstrate that an adversarial SVM model built upon the minimax strategy is much more resilient to adversarial attacks than standard SVM and one‐class SVM models. We also show that optimal learning strategies derived to counter overly pessimistic attack models can produce unsatisfactory results when the real attacks are much weaker. In the sequential game, we demonstrate that the mixed strategy, allowing a player to randomize over available strategies, is the best solution in general without knowing what types of adversaries machine learning applications are facing in the wild. We also discuss scenarios where players' behavior may derail rational decision making and models that consider such decision risks.","",""
0,"F. Huettmann","From Data Mining with Machine Learning to Inference in Diverse and Highly Complex Data: Some Shared Experiences, Intellectual Reasoning and Analysis Steps for the Real World of Science Applications",2018,"","","","",71,"2022-07-13 09:23:31","","10.1007/978-3-319-96978-7_4","","",,,,,0,0.00,0,1,4,"","",""
0,"Murilo Cruz Lopes, Marília de Matos Amorim, V. S. Freitas, R. Calumby","Survival Prediction for Oral Cancer Patients: A Machine Learning Approach",2021,"","","","",72,"2022-07-13 09:23:31","","10.5753/kdmile.2021.17466","","",,,,,0,0.00,0,4,1,"There is a high incidence of oral cancer in Brazil, with 150,000 new cases estimated for 2020-2022. In most cases, it is diagnosed at an advanced stage and are related to many risk factors. The Registro Hospitalar de Câncer (RHC), managed by Instituto Nacional de Câncer (INCA), is a nation-wide database that integrates cancer registers from several hospitals in Brazil. RHC is mostly an administrative database but also include clinical, socioeconomic and hospitalization data for each patient with a cancer diagnostic in the country. For these patients, prognostication is always a difficult task a demand multi-dimensional analysis. Therefore, exploiting large-scale data and machine intelligence approaches emerge as promising tool for computer-aided decision support on death risk estimation. Given the importance of this context, some works have reported high prognostication effectiveness, however with extremely limited data collections, relying on weak validation protocols or simple robustness analysis. Hence, this work describes a detailed workflow and experimental analysis for oral cancer patient survival prediction considering careful data curation and strict validation procedures. By exploiting multiple machine learning algorithms and optimization techniques the proposed approach allowed promising survival prediction effectiveness with F1 and AuC-ROC over 0.78 and 0.80, respectively. Moreover, a detailed analysis have shown that the minimization of different types of prediction errors were achieved by different models, which highlights the importance of the rigour in this kind of validation.","",""
21,"Sebastian Robert, S. Büttner, C. Röcker, Andreas Holzinger","Reasoning Under Uncertainty: Towards Collaborative Interactive Machine Learning",2016,"","","","",73,"2022-07-13 09:23:31","","10.1007/978-3-319-50478-0_18","","",,,,,21,3.50,5,4,6,"","",""
209,"L. Bottou","From machine learning to machine reasoning",2011,"","","","",74,"2022-07-13 09:23:31","","10.1007/s10994-013-5335-x","","",,,,,209,19.00,209,1,11,"","",""
40,"Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang","LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",2020,"","","","",75,"2022-07-13 09:23:31","","10.24963/ijcai.2020/501","","",,,,,40,20.00,7,6,2,"Machine reading is a fundamental task for testing the capability of natural language understanding, which is closely related to human cognition in many aspects. With the rising of deep learning techniques, algorithmic models rival human performances on simple QA, and thus increasingly challenging machine reading datasets have been proposed. Though various challenges such as evidence integration and commonsense knowledge have been integrated, one of the fundamental capabilities in human reading, namely logical reasoning, is not fully investigated. We build a comprehensive dataset, named LogiQA, which is sourced from expert-written questions for testing human Logical reasoning. It consists of 8,678 QA instances, covering multiple types of deductive reasoning. Results show that state-of-the-art neural models perform by far worse than human ceiling. Our dataset can also serve as a benchmark for reinvestigating logical AI under the deep learning NLP setting. The dataset is freely available at this https URL","",""
219,"L. Oneto, S. Chiappa","Fairness in Machine Learning",2020,"","","","",76,"2022-07-13 09:23:31","","10.1007/978-3-030-43883-8_7","","",,,,,219,109.50,110,2,2,"","",""
0,"E. Kondrateva, Polina Belozerova, M. Sharaev, Evgeny Burnaev, A. Bernstein, I. Samotaeva","Machine learning models reproducibility and validation for MR images recognition",2020,"","","","",77,"2022-07-13 09:23:31","","10.1117/12.2559525","","",,,,,0,0.00,0,6,2,"In the present work, we introduce a data processing and analysis pipeline, which ensures the reproducibility of machine learning models chosen for MR image recognition. The proposed pipeline is applied to solve the binary classification problems: epilepsy and depression diagnostics based on vectorized features from MR images. This model is then assessed in terms of classification performance, robustness and reliability of the results, including predictive accuracy on unseen data. The classification performance achieved with our approach compares favorably to ones reported in the literature, where usually no thorough model evaluation is performed.","",""
0,"Suzanne V. Blackley, E. MacPhaul, Bianca Martin, Wenyu Song, J. Suzuki, Li Zhou","Using Natural Language Processing and Machine Learning to Identify Hospitalized Patients with Opioid Use Disorder",2020,"","","","",78,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,6,2,"Opioid use disorder (OUD) represents a global public health crisis that challenges classic clinical decision making. As existing hospital screening methods are resource-intensive, patients with OUD are significantly under-detected. An automated and accurate approach is needed to improve OUD identification so that appropriate care can be provided to these patients in a timely fashion. In this study, we used a large-scale clinical database from Mass General Brigham (MGB; formerly Partners HealthCare) to develop an OUD patient identification algorithm, using multiple machine learning methods. Working closely with an addiction psychiatrist, we developed a set of hand-crafted rules for identifying information suggestive of OUD from free-text clinical notes. We implemented a natural language processing (NLP)-based classification algorithm within the Medical Text Extraction, Reasoning and Mapping System (MTERMS) tool suite to automatically label patients as positive or negative for OUD based on these rules. We further used the NLP output as features to build multiple machine learning and a neural classifier. Our methods yielded robust performance for classifying hospitalized patients as positive or negative for OUD, with the best performing feature set and model combination achieving an F1 score of 0.97. These results show promise for the future development of a real-time tool for quickly and accurately identifying patients with OUD in the hospital setting.","",""
0,"Butch Quinto","Introduction to Machine Learning",2020,"","","","",79,"2022-07-13 09:23:31","","10.1007/978-1-4842-5669-5_1","","",,,,,0,0.00,0,1,2,"","",""
408,"Drew A. Hudson, Christopher D. Manning","Compositional Attention Networks for Machine Reasoning",2018,"","","","",80,"2022-07-13 09:23:31","","","","",,,,,408,102.00,204,2,4,"We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.","",""
1920,"A. Kurakin, Ian J. Goodfellow, Samy Bengio","Adversarial Machine Learning at Scale",2016,"","","","",81,"2022-07-13 09:23:31","","","","",,,,,1920,320.00,640,3,6,"Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a ""label leaking"" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.","",""
0,"D. Efremenko, Himani Jain, Jian Xu","Two Machine Learning Based Schemes for Solving Direct and Inverse Problems of Radiative Transfer Theory",2020,"","","","",82,"2022-07-13 09:23:31","","10.51130/graphicon-2020-2-3-45","","",,,,,0,0.00,0,3,2,"Artificial neural networks (ANNs) are used to substitute computationally expensive radiative transfer models (RTMs) and inverse operators (IO) for retrieving optical parameters of the medium. However, the direct parametrization of RTMs and IOs by means of ANNs has certain drawbacks, such as loss of generality, computations of huge training datasets, robustness issues etc. This paper provides an analysis of different ANN-related methods, based on our results and those published by other authors. In particular, two techniques are proposed. In the first method, the ANN substitutes the eigenvalue solver in the discrete ordinate RTM, thereby reducing the computational time. Unlike classical RTM parametrization schemes based on ANN, in this method the resulting ANN can be used for arbitrary geometry and layer optical thicknesses. In the second method, the IO is trained by using the real measurements (preprocessed Level-2 TROPOMI data) to improve the stability of the inverse operator. This method provides robust results even without applying the Tikhonov regularization method.","",""
39,"Yongming Rao, Jiwen Lu, Jie Zhou","Global-Local Bidirectional Reasoning for Unsupervised Representation Learning of 3D Point Clouds",2020,"","","","",83,"2022-07-13 09:23:31","","10.1109/cvpr42600.2020.00542","","",,,,,39,19.50,13,3,2,"Local and global patterns of an object are closely related. Although each part of an object is incomplete, the underlying attributes about the object are shared among all parts, which makes reasoning the whole object from a single part possible. We hypothesize that a powerful representation of a 3D object should model the attributes that are shared between parts and the whole object, and distinguishable from other objects. Based on this hypothesis, we propose to learn point cloud representation by bidirectional reasoning between the local structures at different abstraction hierarchies and the global shape without human supervision. Experimental results on various benchmark datasets demonstrate the unsupervisedly learned representation is even better than supervised representation in discriminative power, generalization ability, and robustness. We show that unsupervisedly trained point cloud models can outperform their supervised counterparts on downstream classification tasks. Most notably, by simply increasing the channel width of an SSG PointNet++, our unsupervised model surpasses the state-of-the-art supervised methods on both synthetic and real-world 3D object classification datasets. We expect our observations to offer a new perspective on learning better representation from data structures instead of human annotations for point cloud understanding.","",""
27,"L. Bottou","From machine learning to machine reasoning An essay",2013,"","","","",84,"2022-07-13 09:23:31","","","","",,,,,27,3.00,27,1,9,"A plausible definition of “reasoning” could be “algebraically manipulating previously acquired knowledge in order to answer a new question”. This definition covers firstorder logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated “all-purpose” inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.","",""
79,"Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva","Abduction-Based Explanations for Machine Learning Models",2018,"","","","",85,"2022-07-13 09:23:31","","10.1609/aaai.v33i01.33011511","","",,,,,79,19.75,26,3,4,"The growing range of applications of Machine Learning (ML) in a multitude of settings motivates the ability of computing small explanations for predictions made. Small explanations are generally accepted as easier for human decision makers to understand. Most earlier work on computing explanations is based on heuristic approaches, providing no guarantees of quality, in terms of how close such solutions are from cardinality- or subset-minimal explanations. This paper develops a constraint-agnostic solution for computing explanations for any ML model. The proposed solution exploits abductive reasoning, and imposes the requirement that the ML model can be represented as sets of constraints using some target constraint reasoning system for which the decision problem can be answered with some oracle. The experimental results, obtained on well-known datasets, validate the scalability of the proposed approach as well as the quality of the computed solutions.","",""
1,"Achim Reiz, M. Albadawi, K. Sandkuhl, Matthias Vahl, Dennis Sidin","Towards More Robust Fashion Recognition by Combining of Deep-Learning-Based Detection with Semantic Reasoning",2021,"","","","",86,"2022-07-13 09:23:31","","","","",,,,,1,1.00,0,5,1,"The company FutureTV produces and distributes self-produced videos in the fashion domain. It creates revenue through the placement of relevant advertising. The placement of apposite ads, though, requires an understanding of the contents of the videos. Until now, this tagging is created manually in a labor-intensive process. We believe that image recognition technologies can significantly decrease the need for manual involvement in the tagging process. However, the tagging of videos comes with additional challenges: Preliminary, new deep-learning models need to be trained on vast amounts of data obtained in a labor-intensive data-collection process. We suggest a new approach for the combining of deep-learning-based recognition with a semantic reasoning engine. Through the explicit declaration of knowledge fitting to the fashion categories present in the training data of the recognition system, we argue that it is possible to refine the recognition results and win extra knowledge beyond what is found in the neural net.","",""
0,"L. Valiant","How to Augment Learning with Reasoning?",2021,"","","","",87,"2022-07-13 09:23:31","","10.1145/3486622.0000001","","",,,,,0,0.00,0,1,1,"Learning is a cognitive phenomenon that has proved amenable both to theoretical analysis and exploitation as a technology. However, not all of cognition can be accounted for directly by learning. The question we ask here is whether one can build on the success of machine learning to address the broader goals of artificial intelligence. We regard reasoning as the major component of cognition that needs to be added. We suggest that the central challenge therefore is to unify the formulation of these two phenomena, learning and reasoning, into a single framework with a common semantics. In such a framework one would aim to learn rules with the same success that predicates can be learned by means of machine learning, and, at the same time, to reason with the rules with guarantees analogous to those of standard logic. We discuss how Robust Logic fulfils the role of such a theoretical framework. We also discuss the challenges of testing this experimentally on a significant scale, for tasks where one hopes to exceed the performance offered by learning alone.","",""
0,"Pedro Sanchez, J. Voisey, Tian Xia, H. Watson, Alison Q. ONeil, S. Tsaftaris","Causal Machine Learning for Healthcare and Precision Medicine",2022,"","","","",88,"2022-07-13 09:23:31","","10.48550/arXiv.2205.11402","","",,,,,0,0.00,0,6,1,"Causal machine learning (CML) has experienced increasing popularity in healthcare. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g. outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made whilst maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support (CDS) systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer’s disease (AD) to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and unstructured data, generalisation to out-of-distribution samples, and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges.","",""
0,"Anusha Manjunath Raykar, Ashwini K B","A Comparative Study of Machine Learning Algorithms on Intrusion Detection System",2022,"","","","",89,"2022-07-13 09:23:31","","10.53759/7669/jmc202202009","","",,,,,0,0.00,0,2,1,"To detect malicious activity, an intrusion detection system (IDS) automates the procedure of observing and reasoning events that take place in the computer network. The existing intrusion detection system is confined to particular sorts of malicious activity, and it may not be able to identify new types of malicious activity, thus ML techniques were employed to implement the detection system at a faster rate. The intrusion detection system employs ML technologies such as random forest and support vector machines. This system has three main modules: data preparation, feature mapping, modelling and accuracy analyser. In this paper accuracy and sensitivity of both the support vector and random forest algorithms will be compared, with the results verified at a faster rate. The results show that machine learning approaches can aid intrusion detection using a dataset (KDD '99) that also highlights the findings of the prediction model which can differentiate between intrusions and normal connections.","",""
11,"B. Celik, J. Vanschoren","Adaptation Strategies for Automated Machine Learning on Evolving Data",2020,"","","","",90,"2022-07-13 09:23:31","","10.1109/TPAMI.2021.3062900","","",,,,,11,5.50,6,2,2,"Automated Machine Learning (AutoML) systems have been shown to efficiently build good models for new datasets. However, it is often not clear how well they can adapt when the data evolves over time. The main goal of this study is to understand the effect of concept drift on the performance of AutoML methods, and which adaptation strategies can be employed to make them more robust to changes in the underlying data. To that end, we propose 6 concept drift adaptation strategies and evaluate their effectiveness on a variety of AutoML approaches for building machine learning pipelines, including Bayesian optimization, genetic programming, and random search with automated stacking. These are evaluated empirically on real-world and synthetic data streams with different types of concept drift. Based on this analysis, we propose ways to develop more sophisticated and robust AutoML techniques.","",""
0,"Xiaohong W. Gao, Alice Gao","COVID-CBR: A Deep Learning Architecture Featuring Case-Based Reasoning for Classification of COVID-19 from Chest X-Ray Images",2021,"","","","",91,"2022-07-13 09:23:31","","10.1109/ICMLA52953.2021.00214","","",,,,,0,0.00,0,2,1,"Background and Objectives: This study aims to assist rapid accurate diagnosis of COVID-19 based on chest x-ray (CXR) images to provide supplementary information, leading to screening program for early detection of COVID-19 based on CXR images by developing an interpretable, robust and performant AI system. Methods: A case-based reasoning approach built upon autoencoder deep learning architecture is applied to classify COVID-19 from other non-COVID-19 as well as normal subjects from chest x-ray images. The system integrates the interpretation and decision-making together by producing a set of profiles that in appearance resemble the training samples and hence explain the outcome of classifications. Three classes are studied, which are COVID-19 (n=250), other non-COVID-19 diseases (NCD) (n=384), including TB and ARDS, and normal (n=327). Results: This COVID-CBR system sustains the average sensitivity and specificity of 93.1±3.58% and 96.1±4.10% respectively for classification of these three classes. In comparison with the current state of the art, including COVID-Net, VGG-16 and other explainable AI systems, the developed COVID-CBR system appears to perform similar or better when classifying multi-class categories. Conclusion: This paper presents a case-based reasoning deep learning system for detection of COVID19 from chest x-ray images. Comparison with several state of the art systems is conducted. Although the improvement tends to be marginal, especially for VGG-16, the novelty of this work manifests its interpretable feature building upon case-based reasoning, leading to revealing this viral insight and hence ascertaining more effective treatment and drugs while maintaining being transparent. Furthermore, different from several other current explainable networks that highlight key regions or the points of an input that activate the network, i.e. heat maps, this work is constructed upon whole training images, i.e. case-based, whereby each training image belongs to one of the case clusters.","",""
9,"Doris Xin, Hui Miao, Aditya G. Parameswaran, Neoklis Polyzotis","Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities",2021,"","","","",92,"2022-07-13 09:23:31","","10.1145/3448016.3457566","","",,,,,9,9.00,2,4,1,"Machine learning (ML) is now commonplace, powering data-driven applications in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple times on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for optimization, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can reduce wasted computation cost by 50% without compromising the model deployment cadence.","",""
3,"Minsung Hong, R. Akerkar","Analytics and Evolving Landscape of Machine Learning for Emergency Response",2019,"","","","",93,"2022-07-13 09:23:31","","10.1007/978-3-030-15628-2_11","","",,,,,3,1.00,2,2,3,"","",""
3,"F. Lécué, B. Abeloos, Jonathan Anctil, Manuel Bergeron, Damien Dalla-Rosa, Simon Corbeil-Letourneau, Florian Martet, Tanguy Pommellet, L. Salvan, Simon Veilleux, M. Ziaeefard","Thales XAI Platform: Adaptable Explanation of Machine Learning Systems - A Knowledge Graphs Perspective",2019,"","","","",94,"2022-07-13 09:23:31","","","","",,,,,3,1.00,0,11,3,"Explanation in Machine Learning systems has been identified to be the main asset to have for large scale deployment of Artificial Intelligence (AI) in critical systems. Explanations could be example-, features-, semantics-based or even counterfactual to potentially action on an AI system; they could be represented in many different ways e.g., textual, graphical, or visual. All representations serve different means, purpose and operators. We built the first-of-its-kind XAI (eXplainable AI) platform for critical systems i.e., Thales XAI Platform which aims at serving explanations through various forms. This paper emphasizes on the semantics-based explanations for Machine Learning systems. 1 Explainable AI in Critical Systems Motivation: The current hype of Artificial Intelligence (AI) mostly refers to the success of Machine Learning (ML) and its sub-domain of deep learning. However industries operating with critical systems are either highly regulated, or require high level of certification and robustness. Therefore, such industry constraints do limit the adoption of non deterministic and ML systems. Answers to the question of explainability will be intrinsically connected to the adoption of AI in industry at scale. Indeed explanation, which could be used for debugging intelligent systems or deciding to follow a recommendation in real-time, will increase acceptance and (business) user trust. Explainable AI (XAI) is now referring to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. Focus: Thales XAI Platform is designed to provide explanation for a ML task (classification, regression, object detection, segmentation). Although Thales XAI Platform does provide different levels of explanation e.g., example-based, featuresbased, counterfactual using textual and visual representations, we emphasis only on the semantics-based explanation through knowledge graphs. ? Copyright c © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Critical Applications: From adapting a plane trajectory, stopping a train, refitting a boat to reconfiguring a satellite, all are examples of critical situations where explanation is a must-to-have to follow an AI system decision. 2 Why Knowledge Graphs for Explainable AI? State-of-the-Art Limitations: Most approaches limits explanation of ML systems to features involved in the data and model, or at best to examples, prototypes or counterfactuals. Explanation should go beyond correlation (features importance) and numerical similarity (local explanation). Opportunity: By expanding and linking initial (training, validation and test) data with entities in knowledge graphs, (i) context is encoded, (ii) connections and relations are exposed, and (iii) inference and causation are natively supported. Knowledge graphs are used for encoding better representation of data, structuring a ML model in a more interpretable way, and adopt a semantic similarity for local (instance-based) and global (model-based) explanation. 3 Thales XAI Platform: A Knowledge Graph Perspective (Semantic) Perspective: The platform is combining ML and reasoning functionalities to expose a human-like rational as explanation when (i) recognizing an object (in a raw image) of any class in a knowledge graph, (ii) predicting a link in a knowledge graph. Thales XAI Platform is using state-of-the-art Semantic Web tools for enriching input, output (class) data with DBpedia (4, 233, 000 resources) and domain-specific knowledge graphs, usually enterprise knowledge graphs. This is a crucial step for contextualizing training, validation, test data. Explainable ML Classifications: Starting from raw images, as unstructured data, but with class labels augmented with a domain knowledge graph, Thales XAI Platform relies on existing neural network architectures to build the most appropriate models. All confidence scores of output classes on any input image are updated based on the semantic description of the output classes. For instance, an input classified as a car will have a higher overall confidence score in case some properties of car in the knowledge graph are retrieved e.g., having wheels, being on a road. In addition the platform is embedding naturally explanation i.e., properties of the objects retrieved in both the raw data and knowledge graph. Explainable Relational Learning: Starting from relational data, structured as graph, and augmented with a domain knowledge graph, Thales XAI Platform relies on existing knowledge graph embeddings frameworks to build the most appropriate models. Explanation of any link prediction is retrieved by identifying representative hotspots in the knowledge graph i.e., connected parts of the graphs that negatively impact prediction accuracy when removed.","",""
3,"Haoyu Yang, Wen Chen, P. Pathak, Frank Gennari, Ya-Chieh Lai, Bei Yu","Automatic Layout Generation with Applications in Machine Learning Engine Evaluation",2019,"","","","",95,"2022-07-13 09:23:31","","10.1109/MLCAD48534.2019.9142121","","",,,,,3,1.00,1,6,3,"Machine learning-based lithography hotspot detection has been deeply studied recently, from varies feature extraction techniques to efficient learning models. It has been observed that such machine learning-based frameworks are providing satisfactory metal layer hotspot prediction results on known public metal layer benchmarks. In this work, we seek to evaluate how these machine learning-based hotspot detectors generalize to complicated patterns. We first introduce a automatic layout generation tool that can synthesize varies layout patterns given a set of design rules. The tool currently supports both metal layer and via layer generation. As a case study, we conduct hotspot detection on the generated via layer layouts with representative machine learning-based hotspot detectors, which shows that continuous study on model robustness and generality is necessary to prototype and integrate the learning engines in DFM flows. The source code of the layout generation tool will be available at https://github.com/phdyang007/layout-generation.","",""
6,"A. Soni, Dharamvir Dharmacharya, A. Pal, V. Srivastava, R. Shaw, Ankush Ghosh","Design of a Machine Learning-Based Self-driving Car",2021,"","","","",96,"2022-07-13 09:23:31","","10.1007/978-981-16-0598-7_11","","",,,,,6,6.00,1,6,1,"","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",97,"2022-07-13 09:23:31","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
5,"Ingo Glöckner, Karl-Heinz Weis","An Integrated Machine Learning and Case-Based Reasoning Approach to Answer Validation",2012,"","","","",98,"2022-07-13 09:23:31","","10.1109/ICMLA.2012.90","","",,,,,5,0.50,3,2,10,"We propose a case-based reasoning (CBR) approach to answer validation/answer scoring and reranking in question answering (QA) systems, where annotated answer candidates for known questions provide evidence for validating answer candidates for new questions. The use of CBR promises a continuous increase in answer quality, given user feedback that extends the case base. In the paper, we present the complete approach, emphasizing the use of CBR techniques, namely the structural case base, built with annotated MultiNet graphs, and corresponding graph similarity measures. We cover a priori relations to experienced answer candidates for former questions. We describe the adequate structuring of the case base and develop appropriate similarity measures. Finally we integrate CBR into an existing framework for answer validation and reranking that also includes logical answer validation and a shallow linguistic validation, using a learning-to-rank approach for the final answer ranking based on CBR-related features. In our experiments on QA@CLEF questions, the best learned models make heavy use of CBR features. The advantage already achieved by CBR will increase with time due to the automatic improvement with new user annotations given by relevance feedback.","",""
0,"Houpu Yao","Robust and Generalizable Machine Learning through Generative Models,Adversarial Training, and Physics Priors",2019,"","","","",99,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,3,"Machine learning has demonstrated great potential across a wide range of applications such as computer vision, robotics, speech recognition, drug discovery, material science, and physics simulation. Despite its current success, there are two major challenges for machine learning algorithms: limited robustness and generalizability. The robustness of a neural network is defined as the influence that input perturbations have on its final prediction. It has been shown that neural networks are very sensitive to input perturbations. For convolutional neural networks, its prediction can be totally different for input images that are visually indistinguishable to human eyes. Based on such property, hackers can reversely engineer the input to trick machine learning systems in targeted ways. These adversarial attacks have shown to be surprisingly effective, which has raised serious concerns over safety-critical applications like autonomous driving. In the meantime, how to improve the robustness of neural networks is still an open question. The generalizability of a neural network refers to its ability to be effective across a range of different inputs. On one hand, machine learning algorithms require a large number of samples from the data distribution in order to generalize well. It brings a big need for labeled data to perform supervised learning, and over-fitting on training data needs to be avoided for better generalization. On the other hand, machine learning models often fail to carry out reliable generalizations whenever there is a scarcity of supervised data. Many techniques have been proposed to improve the model generalizability; however, generalization with a few samples is still a challenging task. In this dissertation, we are thus motivated to improve the robustness and generalizability of neural networks. Firstly, unlike traditional bottom-up classifiers, we use a pre-trained generative model to perform top-down reasoning and infer the label information. The proposed generative classifier has shown to be promising in handling challenging classification tasks like adversarial attacks and input distribution shifts. Secondly, we focus on improving the network robustness and propose an extension to adversarial training by considering the transformation invariance. Proposed method improves the robustness over state-of-the-art methods by 2.5\% on MNIST, 3.7\% on CIFAR-10, and 1.1\% on restricted ImageNet. Thirdly, we focus on designing networks that generalize well at predicting physics response. Our physics prior knowledge is used to guide the designing of the network architecture, which enables efficient learning and inference. Proposed network is able to generalize well even when it is trained with a single image pair. Aerospace Engineering Doctoral Defense Robust and Generalizable Machine Learning through Generative Models, Adversarial Training, and Physics Prior Houpu Yao Advisor: Yi Ren July 12, 2019; 2:00 PM; ECG 237 School for Engineering of Matter, Transport and Energy","",""
3,"F. Lécué","Applying Machine Reasoning and Learning in Real World Applications",2016,"","","","",100,"2022-07-13 09:23:31","","10.1007/978-3-319-49493-7_7","","",,,,,3,0.50,3,1,6,"","",""
20,"Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae","Engineering problems in machine learning systems",2019,"","","","",101,"2022-07-13 09:23:31","","10.1007/s10994-020-05872-w","","",,,,,20,6.67,7,3,3,"","",""
2,"Sarath Shekkizhar, Antonio Ortega","Revisiting Local Neighborhood Methods in Machine Learning",2021,"","","","",102,"2022-07-13 09:23:31","","10.1109/DSLW51110.2021.9523409","","",,,,,2,2.00,1,2,1,"Several machine learning methods leverage the idea of locality by using k-nearest neighbor (KNN) techniques to design better pattern recognition models. However, the choice of KNN parameters such as k is often made experimentally, e.g., via cross-validation, leading to local neighborhoods without a clear geometric interpretation. In this paper, we replace KNN with our recently introduced polytope neighborhood scheme - Non Negative Kernel regression (NNK). NNK formulates neighborhood selection as a sparse signal approximation problem and is adaptive to the local distribution of samples in the neighborhood of the data point of interest. We analyze the benefits of local neighborhood construction based on NNK. In particular, we study the generalization properties of local interpolation using NNK and present data dependent bounds in the non asymptotic setting. The applicability of NNK in transductive few shot learning setting and for measuring distance between two datasets is demonstrated. NNK exhibits robust, superior performance in comparison to standard locally weighted neighborhood methods.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",103,"2022-07-13 09:23:31","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
0,"Yinyihong Liu","Airbnb Pricing Based on Statistical Machine Learning Models",2021,"","","","",104,"2022-07-13 09:23:31","","10.1109/CONF-SPML54095.2021.00042","","",,,,,0,0.00,0,1,1,"Being one of the largest online accommodation booking platforms, Airbnb has many hosts who are seeking for more proper prices to increase their booking rate. To develop a good pricing prediction model, this paper has employed machine learning models including KNN, MLR, LASSO regression, Ridge regression, Random Forest, Gradient Boosting and XGBoost etc. While past studies on Airbnb pricing have applied quantitative pricing, some face the problems that the models are not robust enough and some face the problem of not training the model plentily. To fill this gap, we give careful consideration in exploratory data analysis to make the dataset more reasonable, apply many robust models ranging from regularized regression to ensemble models and use cross validation and random search to tune each parameter in each model. In this way, we not only select XGBoost as the best model for price prediction with R2 score 0.6321, but also uncover the features which have statistical significance with the target price.","",""
0,"Uma Gunasilan","Debate as a learning activity for teaching programming: a case in the subject of machine learning",2021,"","","","",105,"2022-07-13 09:23:31","","10.1108/heswbl-01-2021-0006","","",,,,,0,0.00,0,1,1,"PurposeDebates are well known to encompass a variety of skills we would like higher education candidates to embody when they graduate.Design/methodology/approachDebates in a classroom with computer science as the main subject has been popular in high schools particularly with emerging issues around the area, however it does not have as an extensive similar documented outreach in tertiary education, particularly in the area of hard computer sciences and more recent concentrations of computer science, such as machine learning, artificial intelligence and cloud computing.FindingsTo explore further, the debate dataset had more methodologies applied and was split into training and testing sets, whose results were then compared by a standardized measure: Root Mean Square Error (RMSE) which is currently standard in the industry. The rationale of the approach is to quantify that debate activities have an immensely positive impact towards both the teaching and learning in technical subjects and needs to be more often and robustly used within higher education.Originality/valueThe rationale of the approach is that classroom debate activities equip students with verbal and social learning styles and an opportunity to engage with content in a way that is more comfortable than working with traditional lecture-and-laboratory style learning.","",""
0,"Wenxiu Xie, Christine Ji, Tianyong Hao, Chi-Yin Chow","Predicting the Easiness and Complexity of English Health Materials for International Tertiary Students With Linguistically Enhanced Machine Learning Algorithms: Development and Validation Study.",2021,"","","","",106,"2022-07-13 09:23:31","","10.2196/25110","","",,,,,0,0.00,0,4,1,"BACKGROUND There is an increasing body of research on the development of machine learning algorithms in the evaluation of online health educational resources for specific readerships. Machine learning algorithms are known for their lack of interpretability compared with statistics. Given their high predictive precision, improving the interpretability of these algorithms can help increase their applicability and replicability in health educational research and applied linguistics, as well as in the development and review of new health education resources for effective and accessible health education.   OBJECTIVE Our study aimed to develop a linguistically enriched machine learning model to predict binary outcomes of online English health educational resources in terms of their easiness and complexity for international tertiary students.   METHODS Logistic regression emerged as the best performing algorithm compared with support vector machine (SVM) (linear), SVM (radial basis function), random forest, and extreme gradient boosting on the transformed data set using L2 normalization. We applied recursive feature elimination with SVM to perform automatic feature selection. The automatically selected features (n=67) were then further streamlined through expert review. The finalized feature set of 22 semantic features achieved a similar area under the curve, sensitivity, specificity, and accuracy compared with the initial (n=115) and automatically selected feature sets (n=67). Logistic regression with the linguistically enhanced feature set (n=22) exhibited important stability and robustness on the training data of different sizes (20%, 40%, 60%, and 80%), and showed consistently high performance when compared with the other 4 algorithms (SVM [linear], SVM [radial basis function], random forest, and extreme gradient boosting).   RESULTS We identified semantic features (with positive regression coefficients) contributing to the prediction of easy-to-understand online health texts and semantic features (with negative regression coefficients) contributing to the prediction of hard-to-understand health materials for readers with nonnative English backgrounds. Language complexity was explained by lexical difficulty (rarity and medical terminology), verbs typical of medical discourse, and syntactic complexity. Language easiness of online health materials was associated with features such as common speech act verbs, personal pronouns, and familiar reasoning verbs. Successive permutation of features illustrated the interaction between these features and their impact on key performance indicators of the machine learning algorithms.   CONCLUSIONS The new logistic regression model developed exhibited consistency, scalability, and, more importantly, interpretability based on existing health and linguistic research. It was found that low and high linguistic accessibilities of online health materials were explained by 2 sets of distinct semantic features. This revealed the inherent complexity of effective health communication beyond current readability analyses, which were limited to syntactic complexity and lexical difficulty.","",""
0,"J. Figuerêdo, V. T. Sarinho, R. Calumby","Low-Cost Machine Learning for Effective and Efficient Bad Smells Detection",2021,"","","","",107,"2022-07-13 09:23:31","","10.5753/kdmile.2021.17468","","",,,,,0,0.00,0,3,1,"Bad smells are characteristics of software that indicate a code or design problem which can make information system hard to understand, evolve, and maintain. To address this problem, different approaches, manual and automated, have been proposed over the years, including more recently machine learning alternatives. However, despite the advances achieved, some machine learning techniques have not yet been effectively explored, such as the use of feature selection techniques. Moreover, it is not clear to what extent the use of numerous source-code features are necessary for reasonable bad smell detection success. Therefore, in this work we propose an approach using low-cost machine learning for effective and efficient detection of bad smells, through explicit feature selection. Our results showed that the selection allowed to statistically improve the effectiveness of the models. For some cases, the models achieved statistical equivalence, but relying on a highly reduced set of features. Indeed, by using explicit feature selection, simpler models such as Naive Bayes became statistically equivalent to robust models such as Random Forest. Therefore, the selection of features allowed keeping competitive or even superior effectiveness while also improving the efficiency of the models, demanding less computational resources for source-code preprocessing, model training and bad smell detection.","",""
0,"Wenxiu Xie, Christine Ji, Tianyong Hao, Chi-Yin Chow","Predicting the Easiness and Complexity of English Health Materials for International Tertiary Students With Linguistically Enhanced Machine Learning Algorithms: Development and Validation Study (Preprint)",2021,"","","","",108,"2022-07-13 09:23:31","","10.2196/preprints.25110","","",,,,,0,0.00,0,4,1,"  BACKGROUND  There is an increasing body of research on the development of machine learning algorithms in the evaluation of online health educational resources for specific readerships. Machine learning algorithms are known for their lack of interpretability compared with statistics. Given their high predictive precision, improving the interpretability of these algorithms can help increase their applicability and replicability in health educational research and applied linguistics, as well as in the development and review of new health education resources for effective and accessible health education.      OBJECTIVE  Our study aimed to develop a linguistically enriched machine learning model to predict binary outcomes of online English health educational resources in terms of their easiness and complexity for international tertiary students.      METHODS  Logistic regression emerged as the best performing algorithm compared with support vector machine (SVM) (linear), SVM (radial basis function), random forest, and extreme gradient boosting on the transformed data set using L2 normalization. We applied recursive feature elimination with SVM to perform automatic feature selection. The automatically selected features (n=67) were then further streamlined through expert review. The finalized feature set of 22 semantic features achieved a similar area under the curve, sensitivity, specificity, and accuracy compared with the initial (n=115) and automatically selected feature sets (n=67). Logistic regression with the linguistically enhanced feature set (n=22) exhibited important stability and robustness on the training data of different sizes (20%, 40%, 60%, and 80%), and showed consistently high performance when compared with the other 4 algorithms (SVM [linear], SVM [radial basis function], random forest, and extreme gradient boosting).      RESULTS  We identified semantic features (with positive regression coefficients) contributing to the prediction of easy-to-understand online health texts and semantic features (with negative regression coefficients) contributing to the prediction of hard-to-understand health materials for readers with nonnative English backgrounds. Language complexity was explained by lexical difficulty (rarity and medical terminology), verbs typical of medical discourse, and syntactic complexity. Language easiness of online health materials was associated with features such as common speech act verbs, personal pronouns, and familiar reasoning verbs. Successive permutation of features illustrated the interaction between these features and their impact on key performance indicators of the machine learning algorithms.      CONCLUSIONS  The new logistic regression model developed exhibited consistency, scalability, and, more importantly, interpretability based on existing health and linguistic research. It was found that low and high linguistic accessibilities of online health materials were explained by 2 sets of distinct semantic features. This revealed the inherent complexity of effective health communication beyond current readability analyses, which were limited to syntactic complexity and lexical difficulty. ","",""
8,"Mustafa Anil Koçak, David Ramirez, E. Erkip, D. Shasha","SafePredict: A Meta-Algorithm for Machine Learning That Uses Refusals to Guarantee Correctness",2017,"","","","",109,"2022-07-13 09:23:31","","10.1109/TPAMI.2019.2932415","","",,,,,8,1.60,2,4,5,"<italic>SafePredict</italic> is a novel meta-algorithm that works with any base prediction algorithm for online data to guarantee an arbitrarily chosen correctness rate, <inline-formula><tex-math notation=""LaTeX"">$1-\epsilon$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""kocak-ieq1-2932415.gif""/></alternatives></inline-formula>, by allowing refusals. Allowing refusals means that the meta-algorithm may refuse to emit a prediction produced by the base algorithm so that the error rate on non-refused predictions does not exceed <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq2-2932415.gif""/></alternatives></inline-formula>. The SafePredict error bound does not rely on any assumptions on the data distribution or the base predictor. When the base predictor happens not to exceed the target error rate <inline-formula><tex-math notation=""LaTeX"">$\epsilon$</tex-math><alternatives><mml:math><mml:mi>ε</mml:mi></mml:math><inline-graphic xlink:href=""kocak-ieq3-2932415.gif""/></alternatives></inline-formula>, SafePredict refuses only a finite number of times. When the error rate of the base predictor changes through time SafePredict makes use of a weight-shifting heuristic that adapts to these changes without knowing when the changes occur yet still maintains the correctness guarantee. Empirical results show that (i) SafePredict compares favorably with state-of-the-art confidence-based refusal mechanisms which fail to offer robust error guarantees; and (ii) combining SafePredict with such refusal mechanisms can in many cases further reduce the number of refusals. Our software is included in the supplementary material, which can be found on the Computer Society Digital Library at <uri>http://doi.ieeecomputersociety.org/10.1109/TPAMI.2019.2932415</uri>.","",""
3,"J. S. Mertoguno","Toward Autonomy: Symbiotic Formal and Statistical Machine Reasoning",2019,"","","","",110,"2022-07-13 09:23:31","","10.1109/CogMI48466.2019.00038","","",,,,,3,1.00,3,1,3,"Different types of machine learning, statistical types, where its knowledge in contained in set of numbers, and formal types, where its knowledge is contained in set of rules or statements, have their own strengths and weaknesses. We argue that their strengths and weaknesses are complementary, and develop a concept called Learn2Reason to harness their collective strength, without inheriting their weaknesses. The efficacy of Learn2Reason concept has been successfully demonstrated in software/binary analysis and cyber security areas. Adoption of the concept significantly improve the performance and scalability of software/binary analysis and cyber security applications and tools.","",""
0,"Ransalu Senanayake, Daniel J. Fremont, Mykel J. Kochenderfer, A. Lomuscio, D. Margineantu, Cheng Soon Ong","Guest Editorial: Special issue on robust machine learning",2021,"","","","",111,"2022-07-13 09:23:31","","10.1007/s10994-021-06113-4","","",,,,,0,0.00,0,6,1,"","",""
33,"B. Abdollahi, O. Nasraoui","Transparency in Fair Machine Learning: the Case of Explainable Recommender Systems",2018,"","","","",112,"2022-07-13 09:23:31","","10.1007/978-3-319-90403-0_2","","",,,,,33,8.25,17,2,4,"","",""
0,"T. Martin, S. Areibi, G. Grewal","Effective Machine-Learning Models for Predicting Routability During FPGA Placement",2021,"","","","",113,"2022-07-13 09:23:31","","10.1109/MLCAD52597.2021.9531243","","",,,,,0,0.00,0,3,1,"The ability to efficiently and accurately predict placement routability, while avoiding the large computational cost of performing routing, is an asset when seeking to reduce total placement and routing runtime. In this paper, we present a series of simple ML models and ensembles to predict the routability of a placement solution. Ensembles based on Bagging, Boosting and Stack of classifiers are introduced to produce more accurate and robust solutions than single/simple models. Our results show an improvement in prediction accuracy and runtime compared to the best published results in the literature.","",""
142,"A. Endert, W. Ribarsky, C. Turkay, B. Wong, I. Nabney, Ignacio Díaz Blanco, Fabrice Rossi","The State of the Art in Integrating Machine Learning into Visual Analytics",2017,"","","","",114,"2022-07-13 09:23:31","","10.1111/cgf.13092","","",,,,,142,28.40,20,7,5,"Visual analytics systems combine machine learning or other analytic techniques with interactive data visualization to promote sensemaking and analytical reasoning. It is through such techniques that people can make sense of large, complex data. While progress has been made, the tactful combination of machine learning and data visualization is still under‐explored. This state‐of‐the‐art report presents a summary of the progress that has been made by highlighting and synthesizing select research advances. Further, it presents opportunities and challenges to enhance the synergy between machine learning and visual analytics for impactful future research directions.","",""
0,"Chunning Song, Fang Li, Liang Xiao, Liangming Feng","Soft Sensor Modeling Based on Extreme Learning Machine and Case-Based Reasoning",2015,"","","","",115,"2022-07-13 09:23:31","","10.1109/IHMSC.2015.39","","",,,,,0,0.00,0,4,7,"Neural network (NN) and Case-based reasoning (CBR) have common advantages over other learning strategies. NN and CBR can be directly applied to the classification and regression problem without additional transform mechanisms. However, they all have disadvantages. The knowledge representation of NN is unreadable and this black box property restricts the application of NN to areas which needs proper explanations. Meanwhile CBR suffers from the feature-weighting problem, when CBR measures the distance between cases, some input features should be treated more importantly than others. This paper, we propose a hybrid prediction system of extreme learning machine (ELM) and Case-based reasoning (ELM-CBR). In our hybrid system, the feature weight set calculated from the trained ELM network plays the core role in connecting both the learning strategies, and the explanation on prediction can be given by presenting the most similar cases from the case base. Moreover, the prediction value of the Online Sequential Extreme Learning Machine also utilized in conjunction with the neighborhood information. This provides extended information for the query with most similar cases in the database. Finally, we present an application in the sugarcane juice clarification, experiments show that the hybrid system has a better recognition rate compared the k-NN and GA-CBR method.","",""
189,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, F. Hutter","Auto-sklearn: Efficient and Robust Automated Machine Learning",2019,"","","","",116,"2022-07-13 09:23:31","","10.1007/978-3-030-05318-5_6","","",,,,,189,63.00,32,6,3,"","",""
35,"F. V. Harmelen, A. T. Teije","A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems",2019,"","","","",117,"2022-07-13 09:23:31","","10.13052/jwe1540-9589.18133","","",,,,,35,11.67,18,2,3,"We propose a set of compositional design patterns to describe a large variety of systems that combine statistical techniques from machine learning with symbolic techniques from knowledge representation. As in other areas of computer science (knowledge engineering, software engineering, ontology engineering, process mining and others), such design patterns help to systematize the literature, clarify which combinations of techniques serve which purposes, and encourage re-use of software components. We have validated our set of compositional design patterns against a large body of recent literature.","",""
147,"Drew A. Hudson, Christopher D. Manning","Learning by Abstraction: The Neural State Machine",2019,"","","","",118,"2022-07-13 09:23:31","","","","",,,,,147,49.00,74,2,3,"We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.","",""
0,"Jonathan S. Kent, David Ménager","Indecision Trees: Learning Argument-Based Reasoning under Quantified Uncertainty",2022,"","","","",119,"2022-07-13 09:23:31","","10.48550/arXiv.2206.12252","","",,,,,0,0.00,0,2,1,". Using Machine Learning systems in the real world can often be problematic, with inexplicable black-box models, the assumed certainty of imperfect measurements, or providing a single classiﬁcation instead of a probability distribution. This paper introduces Indecision Trees, a modiﬁcation to Decision Trees which learn under uncertainty, can perform inference under uncertainty, provide a robust distribution over the possible labels, and can be disas-sembled into a set of logical arguments for use in other reasoning systems.","",""
1,"T. Klemas, Steve Chan","Harnessing Machine Learning, Data Analytics, and Computer-Aided Testing for Cyber Security Applications Achieving Sustained Cyber Resilience for Typical Attack Surface Configurations and Environments",2018,"","","","",120,"2022-07-13 09:23:31","","","","",,,,,1,0.25,1,2,4,"While media reports frequently highlight the exciting aspects of the cyber security field, many cyber security tasks are quite tedious and repetitive. At the same time, however, strong pattern recognition, deductive reasoning, and inference skills are required, as well as a high degree of situational awareness. As a direct consequence, the field of cyber security is replete with potential opportunities to apply data analytics, machine learning, computer aided testing, and other advanced approaches to reduce the frustration of cyber security operators by easing key challenges. In fact, given a typical range of cyber attack surfaces, leveraging these machine-enhanced analysis and decision approaches in conjunction with a robust defense-in-depth posture is a crucial step towards achieving sustained, predictable performance across typical cyber security tasks and promotes cyber resilience. This paper will both outline details for a near-term research effort and explore a variety of key opportunities to exploit these approaches with the objective of raising awareness, providing initial guidance to aid potential adopters, and developing effective strategies to incorporate them into existing cyber security constructs. Keywordsartificial intelligence; expert systems, machine learning; supervised learning, unsupervised learning, pattern recognition, spectral methods, k-means, modularity, Lagrange multiplier, optimization, anomaly detection, data analytics, data science, networks, cyber security operator, cyber defensive tools, cyber resilience.","",""
1,"S. Kuhn, M. Cracknell, A. Reading","The Utility of Machine Learning in Identification of Key Geophysical and Geochemical Datasets: A Case Study in Lithological Mapping in the Central African Copper Belt",2018,"","","","",121,"2022-07-13 09:23:31","","10.1071/ASEG2018abT7_3G","","",,,,,1,0.25,0,3,4,"Random Forests, a supervised machine learning algorithm, provides a robust, data driven means of predicting lithology from geophysical, geochemical and remote sensing data. As an essential part of input selection, datasets are ranked in order of importance to the classification outcome. Those ranked most important provide, on average, the most decisive split between lithological classes. These rankings provide explorers with an additional line of reasoning to complement conventional, geophysical and geochemical interpretation workflows. The approach shows potential to aid in identifying important criteria for distinguishing geological map units during early stage exploration. This can assist in directing subsequent expenditure towards the acquisition and further development of datasets which will be the most productive for mapping. In this case study, we use Random Forests to classify the lithology of a project in the Central African Copper-Belt, Zambia. The project area boasts extensive magnetic, radiometric, electromagnetic and multi-element geochemical coverage but only sparse geological observations. Under various training data paradigms, Random Forests produced a series of varying but closely related lithological maps. In this study, training data were restricted to outcrop, simulating the data available at the early stages of the project. Variable ranking highlighted those datasets which were of greatest importance to the result. Both geophysical and geochemical datasets were well represented in the highest ranking variables, reinforcing the importance of access to both data types. Further analysis showed that in many cases, the importance of high ranking datasets had a plausible geological explanation, often consistent with conventional interpretation. In other cases the method provides new insights, identifying datasets which may not have been considered from the outset of a new project.","",""
2,"Ziqiang Shi, Chaoliang Zhong, Yasuto Yokota, Wensheng Xia, Jun Sun","Robustness Evaluation of Deep Learning Models Based on Local Prediction Consistency",2019,"","","","",122,"2022-07-13 09:23:31","","10.1109/ICMLA.2019.00224","","",,,,,2,0.67,0,5,3,"It is important to estimate the performance gap of a given deep learning model on the target data set, since discrepancy or bias between source and target domains is a common and fundamental problem in the practice of machine learning techniques. Without any assumptions on data bias, such as label shift or covariate shift and without target data labels, we propose a robustness estimation method based on prediction consistency evaluation between source and target data in the neighborhood of the source samples. Considering outliers and whether the user provided model is fully trained, a variety of variant methods are also tried, including setting neighborhood threshold to average intra-class distance for each category and relative robustness. Furthermore, the time complexity of this method is O(nlogn), which is applicable for large datasets. Experiments on the handwritten digit recognition and Japanese handwriting recognition show that the proposed methods are effective.","",""
0,"Xiaoyu Lu","Modelling, inference and optimization in probabilistic machine learning",2018,"","","","",123,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,4,"Bayesian machine learning has gained tremendous attention in the machine learning community over the past few years. Bayesian methods offer a coherent reasoning for quantifying uncertainties in the decision making procedure, based on the Bayes rule. One of the core advantages of Bayesian methods is the separation of modelling and inference. In other words, the likelihood models are completely independent of the computation of the posterior distribution of the parameters. There are many Bayesian models that are widely used in the machine learning community. For example, non-parametric models such as Gaussian Processes and Dirichlet Processes are flexible models which are able to capture and learn the structure of the data. Bayesian deep learning models, which are based on neural networks, are another example of flexible Bayesian models that are rich enough to represent non-linear structures in the data. The process of inferring the posterior lies at the center of Bayesian inference. When computing the posterior distribution exactly is not feasible, due to intractability of the posterior and the computational or memory constraints, approximate Bayesian inference comes to play. In this PhD thesis, I develop and investigate various Bayesian modelling and inference techniques and apply them to multiple interesting domains and tasks. We begin with Tucker Gaussian Processes(TGP), a class of flexible non-parametric models based on Gaussian Processes (GP). We apply the method to 1) regression problems on structured input data, and 2) collaborative filtering problems where TGP offers an elegant way of incorporating side information. We demonstrate superior results compared with benchmarks on a number of examples across different domains. A closely related line of research based on GPs is Bayesian Optimization (BO). It is a black-box optimizer where one optimizes an objective function through subsequent queries about next input locations to be evaluated at. However, this method does not work well when the input space is non-Euclidean or combinatorial. We alleviate the problem by learning a low dimensional Euclidean representation of the combinatorial input space with variational inference, using Variational Auto-encoder (VAE). The optimization can then be conducted on the low dimensional embedding instead. We apply our method to Automatic Statistician and natural scene understanding, which give promising results. For approximate Bayesian inference, we first propose an algorithm called Relativistic Hamiltonian Monte Carlo (RHMC) which is a variant of MCMC. In particular, we replace Newton’s kinetic energy in the Hamiltonian with Einstein’s relativistic kinetic energy, which makes the algorithm more robust. There are several extensions to RHMC, including a stochastic gradient version for scalability, a thermostat version based on the temperature of the physical system and a resulting optimization algorithm which gives comparable performance compared with the state-of-the-art. Finally, we propose another sampling based inference method called the Adaptive Importance Sampling with Exploration and Exploitation (Daisee), where we look into the problem of exploration-exploitation in adaptive importance sampling through establishing a natural connection between importance sampling and multi-armed bandit problem. In particular, through a finite-time regret analysis we show that the regret of the proposed algorithm grows sublinearly with time. Further, we propose a hierarchical extension of Daisee to encourage exploration in the region with high uncertainty. The new models proposed in this thesis help to allow for more flexible Bayesian modelling and the inference techniques introduced can open new research directions for efficient and accurate posterior inference. These contribute to Bayesian inference and probabilistic machine learning.","",""
0,"L. Valiant","What needs to be added to machine learning?",2018,"","","","",124,"2022-07-13 09:23:31","","10.1145/3210713.3210716","","",,,,,0,0.00,0,1,4,"The question we ask is how to build on the success of machine learning to address the broader goals of artificial intelligence. We regard reasoning as the major component of cognition, other than learning, that needs to be incorporated. We suggest that the central challenge therefore is to unify the formulation of these two phenomena, learning and reasoning, whose conventional formulations are contradictory, into a single framework with a common semantics. We propose Robust Logic for this role, as a framework with a satisfactory theoretical basis. Testing it experimentally on a significant scale remains a major challenge for the future.","",""
2,"S. Siltanen, Takanori Ide","Electrical Impedance Tomography, Enclosure Method and Machine Learning",2020,"","","","",125,"2022-07-13 09:23:31","","10.1109/MLSP49062.2020.9231717","","",,,,,2,1.00,1,2,2,"Electrical impedance tomography (EIT) is a non-destructive imaging method, where a physical body is probed with electric measurements at the boundary, and information about the internal conductivity is extracted from the data. The enclosure method of Ikehata [J. Inv. III-Posed Prob. 8(2000)] recovers the convex hull of an inclusion of unknown conductivity embedded in known background conductivity. Practical implementations of the enclosure method are based on least-squares (LS) fitting of lines to noise-robust values of the so-called indicator function. It is shown how a convolutional neural network instead of LS fitting improves the accuracy of the enclosure method significantly while retaining interpretability.","",""
217,"Ian J. Goodfellow, Nicolas Papernot, P. Mcdaniel","Cleverhans V0.1: an Adversarial Machine Learning Library",2016,"","","","",126,"2022-07-13 09:23:31","","","","",,,,,217,36.17,72,3,6,"cleverhans is a software library that provides standardized reference implementations of adversarial example construction techniques and adversarial training. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models’ performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section 1 provides an overview of adversarial examples in machine learning and of the cleverhans software. Section 2 presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section 3 describes how to report benchmark results using the library. Section 4 describes the versioning system.","",""
2,"Luca Pulina","Engineering portfolios of Machine Learning algorithms to solve complex tasks in Robotics and Automated Reasoning",2010,"","","","",127,"2022-07-13 09:23:31","","10.3233/AIC-2010-0471","","",,,,,2,0.17,2,1,12,"This report provides a summary of a dissertation focusing in the application of Machine Learning (ML) techniques to solve complex tasks both in Robotics and Automated Reasoning. In particular, we focus on the contributions achieved in engineering ML techniques to yield a robust solver for quantified Boolean formulas.","",""
28,"Jiuwen Cao, K. Zhang, Hongwei Yong, Xiaoping Lai, Badong Chen, Zhiping Lin","Extreme Learning Machine With Affine Transformation Inputs in an Activation Function",2019,"","","","",128,"2022-07-13 09:23:31","","10.1109/TNNLS.2018.2877468","","",,,,,28,9.33,5,6,3,"The extreme learning machine (ELM) has attracted much attention over the past decade due to its fast learning speed and convincing generalization performance. However, there still remains a practical issue to be approached when applying the ELM: the randomly generated hidden node parameters without tuning can lead to the hidden node outputs being nonuniformly distributed, thus giving rise to poor generalization performance. To address this deficiency, a novel activation function with an affine transformation (AT) on its input is introduced into the ELM, which leads to an improved ELM algorithm that is referred to as an AT-ELM in this paper. The scaling and translation parameters of the AT activation function are computed based on the maximum entropy principle in such a way that the hidden layer outputs approximately obey a uniform distribution. Application of the AT-ELM algorithm in nonlinear function regression shows its robustness to the range scaling of the network inputs. Experiments on nonlinear function regression, real-world data set classification, and benchmark image recognition demonstrate better performance for the AT-ELM compared with the original ELM, the regularized ELM, and the kernel ELM. Recognition results on benchmark image data sets also reveal that the AT-ELM outperforms several other state-of-the-art algorithms in general.","",""
0,"J. Kernbach, V. Staartjes","Foundations of Machine Learning-Based Clinical Prediction Modeling: Part I-Introduction and General Principles.",2021,"","","","",129,"2022-07-13 09:23:31","","10.1007/978-3-030-85292-4_2","","",,,,,0,0.00,0,2,1,"","",""
0,"A. Barikova, Ya. Bernaziuk","Discretion in Applying Provisions of Law: Linguistic Prospects For AI and Machine Learning",2022,"","","","",130,"2022-07-13 09:23:31","","10.1149/10701.18545ecst","","",,,,,0,0.00,0,2,1,"The note presents the will of actions in using the provisions of the law as an assessment when making an opinion, or as a choice of a more favorable and correct conclusion from the number of varieties allowed by law. This legal appearance was presented in the guise of a targeted cause-and-effect graph, in which all actions are associated with a friend with another, are considered the reasons or consequences of a friend of a friend. Any of its vertex points is an event, an edge is an association, the orientation of the edges is from the corollary to the base. The features of the euro legislation on AI are considered. The essence of the artificial origin of the mind has been studied for making conclusions at personal discretion. The reprimand was made on the model of AI and machine learning, which have every chance to be: multifunctional, dynamic, expressed in the definitions of mathematical functions, risk models, credit optimization; static, expressed in relationships between data objects (chart of accounts, affairs between subjects). The Abstraction and Reasoning Corpus dataset has been demonstrated as a benchmark for robust AI. Methods of controlled machine learning have been discovered, encompassing authorized learning (""student's task""), inductive programming (""life experience""), predictive power (""scientist's task""), study campaign (""teacher's task""). The classification of arguments, methodologies and layouts has been determined for a discretionary judgment process with a pertinent case of the Euro Court of Human Rights.","",""
347,"S. Theodoridis","Machine Learning: A Bayesian and Optimization Perspective",2015,"","","","",131,"2022-07-13 09:23:31","","","","",,,,,347,49.57,347,1,7,"This tutorial text gives a unifying perspective on machine learning by covering bothprobabilistic and deterministic approaches -which are based on optimization techniques together with the Bayesian inference approach, whose essence liesin the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts. The book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models. All major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods. The latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling. Case studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied. MATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.","",""
14,"Hongfeng Li, Hong-Qin Zhao, Hong Li","Neural-Response-Based Extreme Learning Machine for Image Classification",2019,"","","","",132,"2022-07-13 09:23:31","","10.1109/TNNLS.2018.2845857","","",,,,,14,4.67,5,3,3,"This paper proposes a novel and simple multilayer feature learning method for image classification by employing the extreme learning machine (ELM). The proposed algorithm is composed of two stages: the multilayer ELM (ML-ELM) feature mapping stage and the ELM learning stage. The ML-ELM feature mapping stage is recursively built by alternating between feature map construction and maximum pooling operation. In particular, the input weights for constructing feature maps are randomly generated and hence need not be trained or tuned, which makes the algorithm highly efficient. Moreover, the maximum pooling operation enables the algorithm to be invariant to certain transformations. During the ELM learning stage, elastic-net regularization is proposed to learn the output weight. Elastic-net regularization helps to learn more compact and meaningful output weight. In addition, we preprocess the input data with the dense scale-invariant feature transform operation to improve both the robustness and invariance of the algorithm. To evaluate the effectiveness of the proposed method, several experiments are conducted on three challenging databases. Compared with the conventional deep learning methods and other related ones, the proposed method achieves the best classification results with high computational efficiency.","",""
3,"Finn Kuusisto, V. S. Costa, Zhonggang Hou, James A. Thomson, David Page, R. Stewart","Machine Learning to Predict Developmental Neurotoxicity with High-Throughput Data from 2D Bio-Engineered Tissues",2019,"","","","",133,"2022-07-13 09:23:31","","10.1109/ICMLA.2019.00055","","",,,,,3,1.00,1,6,3,"There is a growing need for fast and accurate methods for testing developmental neurotoxicity across several chemical exposure sources. Current approaches, such as in vivo animal studies, and assays of animal and human primary cell cultures, suffer from challenges related to time, cost, and applicability to human physiology. Prior work has demonstrated success employing machine learning to predict developmental neurotoxicity using gene expression data collected from human 3D tissue models exposed to various compounds. The 3D model is biologically similar to developing neural structures, but its complexity necessitates extensive expertise and effort to employ. By instead focusing solely on constructing an assay of developmental neurotoxicity, we propose that a simpler 2D tissue model may prove sufficient. We thus compare the accuracy of predictive models trained on data from a 2D tissue model with those trained on data from a 3D tissue model, and find the 2D model to be substantially more accurate. Furthermore, we find the 2D model to be more robust under stringent gene set selection, whereas the 3D model suffers substantial accuracy degradation. While both approaches have advantages and disadvantages, we propose that our described 2D approach could be a valuable tool for decision makers when prioritizing neurotoxicity screening.","",""
0,"Claudia d’Amato, N. Fanizzi, M. Grobelnik, Agnieszka Lawrynowicz, V. Svátek","The 2 nd International Workshop on Inductive Reasoning and Machine Learning for the Semantic Web Proceedings",2010,"","","","",134,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,5,12,"I will describe a novel meta-learning approach to optimizing the knowledge discovery or data mining (DM) process. This approach has three features that distinguish it from its predecessors. First, previous meta-learning research has focused exclusively on improving the learning phase of the DM process. More specifically, the goal of meta-learning has typically been to select the most appropriate algorithm and/or parameter settings for a given learning task. We adopt a more process-oriented approach whereby meta-learning is applied to design choices at different stages of the complete data mining process or workflow (hence the term meta-mining). Second, meta-learning for algorithm or model selection has consisted mainly in mapping dataset properties to the observed performance of algorithms viewed as black boxes. While several generations of researchers have worked intensively on characterizing datasets, little has been done to understand the internal mechanisms of the algorithms used. At best, a few have considered perceptible features of algorithms like their ease of implementation or their robustness to noise, or the interpretability of the models they produce. In contrast, our meta-learning approach complements dataset descriptions with an in-depth analysis and characterization of algorithms their underlying assumptions, optimization goals and strategies, together with the structure and complexity of the models and patterns they generate. Third, previous meta-learning approaches have been strictly (meta) data-driven. To make sense of the intricate relationships between tasks, data and algorithms at different stages of the data mining process, our meta-miner relies on extensive background knowledge concerning knowledge discovery itself. For this reason we have developed a data mining ontology, which defines the essential concepts and relations needed to represent and analyse data mining objects and processes. In addition, a DM knowledge base gathers assertions concerning data preprocessing and machine learning algorithms as well as their implementations in several open-source software packages. The DM ontology and knowledge base are domain-independent; they can be exploited in any application area to build databases describing domain-specific data analysis tasks, datasets and experiments. Aside from their direct utility in their respective target domains, such databases are the indispensable source of training and evaluation data for the meta-miner. These three features together lay the groundwork for semantic meta-mining, the process of mining DM meta-data on the basis of data mining expertise distilled in an ontology and knowledge base.","",""
1,"Ramkumar Harikrishnakumar, A. Dand, S. Nannapaneni, K. Krishnan","Supervised Machine Learning Approach for Effective Supplier Classification",2019,"","","","",135,"2022-07-13 09:23:31","","10.1109/ICMLA.2019.00045","","",,,,,1,0.33,0,4,3,"Supplier assessment plays a critical role in the supply chain management, which involves the flow of goods and services from the initial stage (raw material procurement) to the final stage (delivery). Supplier assessment is a multi-criteria decision-making (MCDM) approach that requires several criteria for the proper assessment of the suppliers. When there are several criteria involved, it makes the supplier assessment process more complicated. For a comprehensive and robust assessment process, we propose the use of supervised machine learning algorithms to classify various suppliers into four categories: excellent, good, satisfactory, and unsatisfactory. In this paper, supervised learning (classification) algorithms are applied for a supplier assessment problem where a model is trained based on the previous historical data and then tested on the new unseen data set. This method will provide an efficient way for supplier assessment that is more effective in terms of accuracy and time when compared to MCDM approach. Classification algorithms such as support vector machines (with linear, polynomial and radial basis kernels), logistic regression, k-nearest neighbors, and naïve Bayes methods are used to train the model and their performance is assessed against a test data. Finally, the performance measures from all the classification methods are used to assess the best supplier.","",""
0,"Muhammad Abdullah Hanif, R. Hafiz, M. Javed, Semeen Rehman, M. Shafique","Energy-Efficient Design of Advanced Machine Learning Hardware",2019,"","","","",136,"2022-07-13 09:23:31","","10.1007/978-3-030-04666-8_21","","",,,,,0,0.00,0,5,3,"","",""
27,"L. Longo","Argumentation for Knowledge Representation, Conflict Resolution, Defeasible Inference and Its Integration with Machine Learning",2016,"","","","",137,"2022-07-13 09:23:31","","10.1007/978-3-319-50478-0_9","","",,,,,27,4.50,27,1,6,"","",""
3,"Noureldin Laban, B. Abdellatif, H. M. Ebeid, H. Shedeed, M. Tolba","Machine Learning for Enhancement Land Cover and Crop Types Classification",2018,"","","","",138,"2022-07-13 09:23:31","","10.1007/978-3-030-02357-7_4","","",,,,,3,0.75,1,5,4,"","",""
34,"A. Sargolzaei, C. Crane, Alireza Abbaspour, S. Noei","A Machine Learning Approach for Fault Detection in Vehicular Cyber-Physical Systems",2016,"","","","",139,"2022-07-13 09:23:31","","10.1109/ICMLA.2016.0112","","",,,,,34,5.67,9,4,6,"A network of vehicular cyber-physical systems (VCPSs) can use wireless communications to interact with each other and the surrounding environment to improve transportation safety, mobility, and sustainability. However, cloud-oriented architectures are vulnerable to cyber attacks, which may endanger passenger and pedestrian safety and privacy, and cause severe property damage. For instance, a hacker can use message falsification attack to affect functionality of a particular application in a platoon of VCPSs. In this paper, a neural network-based fault detection technique is applied to detect and track fault data injection attacks on the cooperative adaptive cruise control layer of a platoon of connected vehicles in real time. A decision support system was developed to reduce the probability and severity of any consequent accident. A case study with its design specifications is demonstrated in detail. The simulation results show that the proposed method can improve system reliability, robustness, and safety.","",""
82,"Qian Yang, Jina Suh, N. Chen, Gonzalo A. Ramos","Grounding Interactive Machine Learning Tool Design in How Non-Experts Actually Build Models",2018,"","","","",140,"2022-07-13 09:23:31","","10.1145/3196709.3196729","","",,,,,82,20.50,21,4,4,"Machine learning (ML) promises data-driven insights and solutions for people from all walks of life, but the skill of crafting these solutions is possessed by only a few. Emerging research addresses this issue by creating ML tools that are easy and accessible to people who are not formally trained in ML (non-experts). This work investigated how non-experts build ML solutions for themselves in real life. Our interviews and surveys revealed unique potentials of non-expert ML, as well several pitfalls that non-experts are susceptible to. For example, many perceived percentage accuracy as a sole measure of performance, thus problematic models proceeded to deployment. These observations suggested that, while challenging, making ML easy and robust should both be important goals of designing novice-facing ML tools. To advance on this insight, we discuss design implications and created a sensitizing concept to demonstrate how designers might guide non-experts to easily build robust solutions.","",""
0,"Hsiao-Chi Li, Chang-Yu Cheng, Chia Chou, Chien-Chang Hsu, Meng-Lin Chang, Y. Chiu, J. Chai","Multi-Class Brain Age Discrimination Using Machine Learning Algorithm",2019,"","","","",141,"2022-07-13 09:23:31","","10.1109/ICMLC48188.2019.8949317","","",,,,,0,0.00,0,7,3,"Resting-state functional connectivity analyses have revealed a significant effect on the inter-regional interactions in brain. The brain age prediction based on resting-state functional magnetic resonance imaging has been proved as biomarkers to characterize the typical brain development and neuropsychiatric disorders. The brain age prediction model based on functional connectivity measurements derived from resting-state functional magnetic resonance imaging has received a lots of interest in recent years due to its great success in age prediction. However, some of the recent studies rely on experienced neuroscientist experts to select appropriate connectivity features in order to build a robust model for prediction while the others just selected the features based on trial-and-error test. Besides, the subjects used in this studies omitted some subjects that can be divided into two groups with less similarity which may confused the prediction model. In this study, we proposed a multi-class age categories discrimination method with the connectivity features selected via K-means clustering with no prior knowledge provided. The experimental results show that with K-means selected features the proposed model better discriminate multi-class age categories.","",""
57,"Lal Hussain","Detecting epileptic seizure with different feature extracting strategies using robust machine learning classification techniques by applying advance parameter optimization approach",2018,"","","","",142,"2022-07-13 09:23:31","","10.1007/s11571-018-9477-1","","",,,,,57,14.25,57,1,4,"","",""
0,"Sannasi Chakravarthy S R, H. Rajaguru","Deep Features with Improved Extreme Learning Machine for Breast Cancer Classification",2021,"","","","",143,"2022-07-13 09:23:31","","10.1109/ISCMI53840.2021.9654814","","",,,,,0,0.00,0,2,1,"Breast cancer classification problem is receiving more attention among researchers due to its global impact on women's healthcare. There is always a demand for research analysis in the earlier diagnosis of breast cancer. The paper proposes a new computer-aided diagnosis (CAD) framework which integrates deep learning and Extreme Learning Machine (ELM) for feature extrication and classification of breast cancer. The proposed CAD tool is very much helpful for radiologists in the earlier diagnosis of breast cancer using digital mammograms. Herein, the research uses the Sine-Cosine Crow-Search Optimization Algorithm (SC-CSOA) for improving the ELM’s classification performance. And to extricate the robust features from the input mammograms, the concept of transfer learning is applied. For that, the work adopts the three most efficient Residual Network (ResNet) families of CNN, namely ResNet18, ResNet50, and ResNet101 architectures. The input database used for evaluation is the INbreast dataset which comprises Full-Field Digital Mammogram (FFDM) images. At this point, the research compares the results obtained with the existing ELM and K-NN algorithms where it is found that the performance of the proposed framework provides the supreme classification (95.811% of accuracy) over others.","",""
9,"Yiwen Guo, Long Chen, Yurong Chen, Changshui Zhang","On Connections Between Regularizations for Improving DNN Robustness",2020,"","","","",144,"2022-07-13 09:23:31","","10.1109/tpami.2020.3006917","","",,,,,9,4.50,2,4,2,"This paper analyzes regularization terms proposed recently for improving the adversarial robustness of deep neural networks (DNNs), from a theoretical point of view. Specifically, we study possible connections between several effective methods, including input-gradient regularization, Jacobian regularization, curvature regularization, and a cross-Lipschitz functional. We investigate them on DNNs with general rectified linear activations, which constitute one of the most prevalent families of models for image classification and a host of other machine learning applications. We shed light on essential ingredients of these regularizations and re-interpret their functionality. Through the lens of our study, more principled and efficient regularizations can possibly be invented in the near future.","",""
11,"Daniel Harborne, C. Willis, Richard J. Tomsett, A. Preece","Integrating learning and reasoning services for explainable information fusion",2018,"","","","",145,"2022-07-13 09:23:31","","","","",,,,,11,2.75,3,4,4,"—We present a distributed information fusion system  able to integrate heterogeneous information processing services  based on machine learning and reasoning approaches. We focus  on higher (semantic) levels of information fusion, and highlight  the requirement for the component services, and the system as  a whole, to generate explanations of its outputs. Using a case  study approach in the domain of traffic monitoring, we introduce  component services based on (i) deep neural network approaches  and (ii) heuristic-based reasoning. We examine methods for  explanation generation in each case, including both transparency  (e.g, saliency maps, reasoning traces) and post-hoc methods  (e.g, explanation in terms of similar examples, identification of  relevant semantic objects). We consider trade-offs in terms of  the classification performance of the services and the kinds of  available explanations, and show how service integration offers  more robust performance and explainability.","",""
108,"W. Hong, A. Haimovich, R. A. Taylor","Predicting hospital admission at emergency department triage using machine learning",2018,"","","","",146,"2022-07-13 09:23:31","","10.1371/journal.pone.0201016","","",,,,,108,27.00,36,3,4,"Objective To predict hospital admission at the time of ED triage using patient history in addition to information collected at triage. Methods This retrospective study included all adult ED visits between March 2014 and July 2017 from one academic and two community emergency rooms that resulted in either admission or discharge. A total of 972 variables were extracted per patient visit. Samples were randomly partitioned into training (80%), validation (10%), and test (10%) sets. We trained a series of nine binary classifiers using logistic regression (LR), gradient boosting (XGBoost), and deep neural networks (DNN) on three dataset types: one using only triage information, one using only patient history, and one using the full set of variables. Next, we tested the potential benefit of additional training samples by training models on increasing fractions of our data. Lastly, variables of importance were identified using information gain as a metric to create a low-dimensional model. Results A total of 560,486 patient visits were included in the study, with an overall admission risk of 29.7%. Models trained on triage information yielded a test AUC of 0.87 for LR (95% CI 0.86–0.87), 0.87 for XGBoost (95% CI 0.87–0.88) and 0.87 for DNN (95% CI 0.87–0.88). Models trained on patient history yielded an AUC of 0.86 for LR (95% CI 0.86–0.87), 0.87 for XGBoost (95% CI 0.87–0.87) and 0.87 for DNN (95% CI 0.87–0.88). Models trained on the full set of variables yielded an AUC of 0.91 for LR (95% CI 0.91–0.91), 0.92 for XGBoost (95% CI 0.92–0.93) and 0.92 for DNN (95% CI 0.92–0.92). All algorithms reached maximum performance at 50% of the training set or less. A low-dimensional XGBoost model built on ESI level, outpatient medication counts, demographics, and hospital usage statistics yielded an AUC of 0.91 (95% CI 0.91–0.91). Conclusion Machine learning can robustly predict hospital admission using triage information and patient history. The addition of historical information improves predictive performance significantly compared to using triage information alone, highlighting the need to incorporate these variables into prediction models.","",""
33,"Ved P. Kafle, Y. Fukushima, P. Martinez-Julia, T. Miyazawa","Consideration On Automation of 5G Network Slicing with Machine Learning",2018,"","","","",147,"2022-07-13 09:23:31","","10.23919/ITU-WT.2018.8597639","","",,,,,33,8.25,8,4,4,"Machine learning has the capability to provide simpler solutions to complex problems by analyzing a huge volume of data in a short time, learning for adapting its functionality to dynamically changing environments, and predicting near future events with reasonably good accuracy. The 5G communication networks are getting complex due to emergence of unprecedentedly huge number of new connected devices and new types of services. Moreover, the requirements of creating virtual network slices suitable to provide optimal services for diverse users and applications are posing challenges to the efficient management of network resources, processing information about a huge volume of traffic, staying robust against all potential security threats, and adaptively adjustment of network functionality for time-varying workload. In this paper, we introduce about the envisioned 5G network slicing and elaborate the necessity of automation of network functions for the design, construction, deployment, operation, control and management of network slices. We then revisit the machine learning techniques that can be applied for the automation of network functions. We also discuss the status of artificial intelligence and machine learning related activities being progressed in standards development organizations and industrial forums.","",""
34,"Muhammad Abdullah Hanif, Faiq Khalid, Rachmad Vidya Wicaksana Putra, Semeen Rehman, M. Shafique","Robust Machine Learning Systems: Reliability and Security for Deep Neural Networks",2018,"","","","",148,"2022-07-13 09:23:31","","10.1109/IOLTS.2018.8474192","","",,,,,34,8.50,7,5,4,"Machine learning is commonly being used in almost all the areas that involve advanced data analytics and intelligent control. From applications like Natural Language Processing (NLP) to autonomous driving are based upon machine learning algorithms. An increasing trend is observed in the use of Deep Neural Networks (DNNs) for such applications. While the slight inaccuracy in applications like NLP does not have any severe consequences, it is not the same for other safety-critical applications, like autonomous driving and smart healthcare, where a small error can lead to catastrophic effects. Apart from high-accuracy DNN algorithms, there is a significant need for robust machine learning systems and hardware architectures that can generate reliable and trustworthy results in the presence of hardware-level faults while also preserving security and privacy. This paper provides an overview of the challenges being faced in ensuring reliable and secure execution of DNNs. To address the challenges, we present several techniques for analyzing and mitigating the reliability and security threats in machine learning systems.","",""
157,"L. Serafini, A. Garcez","Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge",2016,"","","","",149,"2022-07-13 09:23:31","","","","",,,,,157,26.17,79,2,6,"We propose Logic Tensor Networks: a uniform framework for integrating automatic learning and reasoning. A logic formalism called Real Logic is defined on a first-order language whereby formulas have truth-value in the interval [0,1] and semantics defined concretely on the domain of real numbers. Logical constants are interpreted as feature vectors of real numbers. Real Logic promotes a well-founded integration of deductive reasoning on a knowledge-base and efficient data-driven relational machine learning. We show how Real Logic can be implemented in deep Tensor Neural Networks with the use of Google's tensorflow primitives. The paper concludes with experiments applying Logic Tensor Networks on a simple but representative example of knowledge completion.","",""
58,"Youyang Qu, Shiva Raj Pokhrel, S. Garg, Longxiang Gao, Yong Xiang","A Blockchained Federated Learning Framework for Cognitive Computing in Industry 4.0 Networks",2021,"","","","",150,"2022-07-13 09:23:31","","10.1109/TII.2020.3007817","","",,,,,58,58.00,12,5,1,"Cognitive computing, a revolutionary AI concept emulating human brain's reasoning process, is progressively flourishing in the Industry 4.0 automation. With the advancement of various AI and machine learning technologies the evolution toward improved decision making as well as data-driven intelligent manufacturing has already been evident. However, several emerging issues, including the poisoning attacks, performance, and inadequate data resources, etc., have to be resolved. Recent research works studied the problem lightly, which often leads to unreliable performance, inefficiency, and privacy leakage. In this article, we developed a decentralized paradigm for big data-driven cognitive computing (D2C), using federated learning and blockchain jointly. Federated learning can solve the problem of “data island” with privacy protection and efficient processing while blockchain provides incentive mechanism, fully decentralized fashion, and robust against poisoning attacks. Using blockchain-enabled federated learning help quick convergence with advanced verifications and member selections. Extensive evaluation and assessment findings demonstrate D2C's effectiveness relative to existing leading designs and models.","",""
3,"Leonhard Applis, A. Panichella, A. Deursen","Assessing Robustness of ML-Based Program Analysis Tools using Metamorphic Program Transformations",2021,"","","","",151,"2022-07-13 09:23:31","","10.1109/ASE51524.2021.9678706","","",,,,,3,3.00,1,3,1,"Metamorphic testing is a well-established testing technique that has been successfully applied in various domains, including testing deep learning models to assess their robustness against data noise or malicious input. Currently, metamorphic testing approaches for machine learning (ML) models focused on image processing and object recognition tasks. Hence, these approaches cannot be applied to ML targeting program analysis tasks. In this paper, we extend metamorphic testing approaches for ML models targeting software programs. We present LAMPION, a novel testing framework that applies (semantics preserving) metamorphic transformations on the test datasets. LAMPION produces new code snippets equivalent to the original test set but different in their identifiers or syntactic structure. We evaluate LAMPION against CodeBERT, a state-of-the-art ML model for Code-To-Text tasks that creates Javadoc summaries for given Java methods. Our results show that simple transformations significantly impact the target model behavior, providing additional information on the models reasoning apart from the classic performance metric.","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",152,"2022-07-13 09:23:31","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
3,"Daniel Harborne, R. Raghavendra, C. Willis, Supriyo Chakraborty, P. Dewan, M. Srivatsa, Richard J. Tomsett, A. Preece","Reasoning and learning services for coalition situational understanding",2018,"","","","",153,"2022-07-13 09:23:31","","10.1117/12.2307009","","",,,,,3,0.75,0,8,4,"Situational understanding requires an ability to assess the current situation and anticipate future situations, requiring both pattern recognition and inference. A coalition involves multiple agencies sharing information and analytics. This paper considers how to harness distributed information sources, including multimodal sensors, together with machine learning and reasoning services, to perform situational understanding in a coalition context. To exemplify the approach we focus on a technology integration experiment in which multimodal data — including video and still imagery, geospatial and weather data — is processed and fused in a service-oriented architecture by heterogeneous pattern recognition and inference components. We show how the architecture: (i) provides awareness of the current situation and prediction of future states, (ii) is robust to individual service failure, (iii) supports the generation of ‘why’ explanations for human analysts (including from components based on ‘black box’ deep neural networks which pose particular challenges to explanation generation), and (iv) allows for the imposition of information sharing constraints in a coalition context where there is varying levels of trust between partner agencies.","",""
5,"Cristian Axenie, R. Tudoran, S. Bortoli, Mohamad Al Hajj Hassan, D. Foroni, G. Brasche","STARLORD: Sliding Window Temporal Accumulate-Retract Learning for Online Reasoning on Datastreams",2018,"","","","",154,"2022-07-13 09:23:31","","10.1109/ICMLA.2018.00181","","",,,,,5,1.25,1,6,4,"Nowadays, data sources, such as IoT devices, financial markets, and online services, continuously generate large amounts of data. Such data is usually generated at high frequencies and is typically described by non-stationary distributions. Querying these data sources brings new challenges for machine learning algorithms, which now need to be considered from the perspective of an evolving stream and not a static dataset. Under such scenarios, where data flows continuously, the challenge is how to transform the vast amount of data into information and knowledge, and how to adapt to data changes (i.e. drifts) and accumulate experience over time to support online decision-making. In this paper, we introduce STARLORD, a novel incremental computation method and system acting on data streams and capable of achieving low-latency (millisecond level) and high-throughput (thousands events/second/core) when learning from data streams. Moreover, the approach is able to adapt to data drifts and accumulate experience over time, and to use such knowledge to improve future learning and prediction performance, with resource usage guarantees. This is proven by our preliminary experiments where we built-in the framework in an open source stream engine (i.e. Apache Flink).","",""
101,"G. Lecu'e, M. Lerasle","Robust machine learning by median-of-means: Theory and practice",2017,"","","","",155,"2022-07-13 09:23:31","","10.1214/19-AOS1828","","",,,,,101,20.20,51,2,5,"We introduce new estimators for robust machine learning based on median-of-means (MOM) estimators of the mean of real valued random variables. These estimators achieve optimal rates of convergence under minimal assumptions on the dataset. The dataset may also have been corrupted by outliers on which no assumption is granted. We also analyze these new estimators with standard tools from robust statistics. In particular, we revisit the concept of breakdown point. We modify the original definition by studying the number of outliers that a dataset can contain without deteriorating the estimation properties of a given estimator. This new notion of breakdown number, that takes into account the statistical performances of the estimators, is non-asymptotic in nature and adapted for machine learning purposes. We proved that the breakdown number of our estimator is of the order of (number of observations)*(rate of convergence). For instance, the breakdown number of our estimators for the problem of estimation of a d-dimensional vector with a noise variance sigma^2 is sigma^2d and it becomes sigma^2 s log(d/s) when this vector has only s non-zero component. Beyond this breakdown point, we proved that the rate of convergence achieved by our estimator is (number of outliers) divided by (number of observation).  Besides these theoretical guarantees, the major improvement brought by these new estimators is that they are easily computable in practice. In fact, basically any algorithm used to approximate the standard Empirical Risk Minimizer (or its regularized versions) has a robust version approximating our estimators. As a proof of concept, we study many algorithms for the classical LASSO estimator. A byproduct of the MOM algorithms is a measure of depth of data that can be used to detect outliers.","",""
3,"Kwwabena Nuamah","Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",2021,"","","","",156,"2022-07-13 09:23:31","","","","",,,,,3,3.00,3,1,1,"An important aspect of artificial intelligence (AI) is the ability to reason in a step-by-step “algorithmic” manner that can be inspected and verified for its correctness. This is especially important in the domain of question answering (QA). We argue that the challenge of algorithmic reasoning in QA can be effectively tackled with a “systems” approach to AI which features a hybrid use of symbolic and sub-symbolic methods including deep neural networks. Additionally, we argue that while neural network models with end-to-end training pipelines perform well in narrow applications such as image classification and language modelling, they cannot, on their own, successfully perform algorithmic reasoning, especially if the task spans multiple domains. We discuss a few notable exceptions and point out how they are still limited when the QA problem is widened to include other intelligence-requiring tasks. However, deep learning, and machine learning in general, do play important roles as components in the reasoning process. In this position paper, we propose an approach to algorithm reasoning for QA, Deep Algorithmic Question Answering (DAQA), based on three desirable properties: interpretability, generalizability, and robustness which such an AI system should posses, and conclude that they are best achieved with a combination of hybrid and compositional AI.","",""
494,"Robert Geirhos, J. Jacobsen, Claudio Michaelis, R. Zemel, Wieland Brendel, M. Bethge, Felix Wichmann","Shortcut Learning in Deep Neural Networks",2020,"","","","",157,"2022-07-13 09:23:31","","10.1038/s42256-020-00257-z","","",,,,,494,247.00,71,7,2,"","",""
3,"Agnese Chiatti, E. Motta, E. Daga, G. Bardaro","Fit to Measure: Reasoning about Sizes for Robust Object Recognition",2020,"","","","",158,"2022-07-13 09:23:31","","","","",,,,,3,1.50,1,4,2,"Service robots can help with many of our daily tasks, especially in those cases where it is inconvenient or unsafe for us to intervene: e.g., under extreme weather conditions or when social distance needs to be maintained. However, before we can successfully delegate complex tasks to robots, we need to enhance their ability to make sense of dynamic, real world environments. In this context, the first prerequisite to improving the Visual Intelligence of a robot is building robust and reliable object recognition systems. While object recognition solutions are traditionally based on Machine Learning methods, augmenting them with knowledge based reasoners has been shown to improve their performance. In particular, based on our prior work on identifying the epistemic requirements of Visual Intelligence, we hypothesise that knowledge of the typical size of objects could significantly improve the accuracy of an object recognition system. To verify this hypothesis, in this paper we present an approach to integrating knowledge about object sizes in a ML based architecture. Our experiments in a real world robotic scenario show that this combined approach ensures a significant performance increase over state of the art Machine Learning methods.","",""
15,"Alina Barnett, F. Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, J. Lo, C. Rudin","IAIA-BL: A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography",2021,"","","","",159,"2022-07-13 09:23:31","","10.1038/s42256-021-00423-x","","",,,,,15,15.00,2,7,1,"","",""
130,"A. Subasi, Jasmin Kevric, Muhammed Abdullah Canbaz","Epileptic seizure detection using hybrid machine learning methods",2017,"","","","",160,"2022-07-13 09:23:31","","10.1007/s00521-017-3003-y","","",,,,,130,26.00,43,3,5,"","",""
53,"P. Maher, D. St. Clair","Uncertain reasoning in an ID3 machine learning framework",1993,"","","","",161,"2022-07-13 09:23:31","","10.1109/FUZZY.1993.327472","","",,,,,53,1.83,27,2,29,"Quinlan's ID3 is a symbolic machine learning algorithm which uses training examples as input and constructs a decision tree as output. One problem with the standard decision tree approach to machine learning is that uncertain data, either in training and/or testing, often produces poor classification accuracies. The UR-ID3 algorithm described combines uncertain reasoning with the rule set produced by ID3 to create a machine learning algorithm which is robust in the presence of uncertain training and testing data. Experimental results are presented which compare the new algorithm's performance with that of ID3 and backpropagation neural networks.<<ETX>>","",""
12,"N. Khoa, M. M. Alamdari, T. Rakotoarivelo, Ali Anaissi, Yang Wang","Structural Health Monitoring Using Machine Learning Techniques and Domain Knowledge Based Features",2018,"","","","",162,"2022-07-13 09:23:31","","10.1007/978-3-319-90403-0_20","","",,,,,12,3.00,2,5,4,"","",""
1,"Dominik Doldy, Josep Soler Garridoy","An energy-based model for neuro-symbolic reasoning on knowledge graphs",2021,"","","","",163,"2022-07-13 09:23:31","","10.1109/ICMLA52953.2021.00151","","",,,,,1,1.00,1,2,1,"Machine learning on graph-structured data has recently become a major topic in industry and research, finding many exciting applications such as recommender systems and automated theorem proving. We propose an energy-based graph embedding algorithm to characterize industrial automation systems, integrating knowledge from different domains like industrial automation, communications and cybersecurity. By combining knowledge from multiple domains, the learned model is capable of making context-aware predictions regarding novel system events and can be used to evaluate the severity of anomalies that might be indicative of, e.g., cybersecurity breaches. The presented model is mappable to a biologically-inspired neural architecture, serving as a first bridge between graph embedding methods and neuromorphic computing– uncovering a promising edge application for this upcoming technology.","",""
0,"P. Rasouli, Ingrid Chieh Yu","Analyzing and Improving the Robustness of Tabular Classifiers using Counterfactual Explanations",2021,"","","","",164,"2022-07-13 09:23:31","","10.1109/ICMLA52953.2021.00209","","",,,,,0,0.00,0,2,1,"Recent studies have revealed that Machine Learning (ML) models are vulnerable to adversarial perturbations. Such perturbations can be intentionally or accidentally added to the original inputs, evading the classifier’s behavior to misclassify the crafted samples. A widely-used solution is to retrain the model using data points generated by various attack strategies. However, this creates a classifier robust to some particular evasions and can not defend unknown or universal perturbations. Counterfactual explanations are a specific class of post-hoc explanation methods that provide minimal modification to the input features in order to obtain a particular outcome from the model. In addition to the resemblance of counterfactual explanations to the universal perturbations, the possibility of generating instances from specific classes makes such approaches suitable for analyzing and improving the model’s robustness. Rather than explaining the model’s decisions in the deployment phase, we utilize the distance information obtained from counterfactuals and propose novel metrics to analyze the robustness of tabular classifiers. Further, we introduce a decision boundary modification approach using customized counterfactual data points to improve the robustness of the models without compromising their accuracy. Our framework addresses the robustness of black-box classifiers in the tabular setting, which is considered an under-explored research area. Through several experiments and evaluations, we demonstrate the efficacy of our approach in analyzing and improving the robustness of black-box tabular classifiers.","",""
45,"T. Griffiths, Frederick Callaway, Michael Chang, Erin Grant, Falk Lieder","Doing more with less: meta-reasoning and meta-learning in humans and machines",2019,"","","","",165,"2022-07-13 09:23:31","","10.1016/j.cobeha.2019.01.005","","",,,,,45,15.00,9,5,3,"","",""
5,"Stavros Pitoglou, Y. Koumpouros, Athanasios Anastasiou","Using Electronic Health Records and Machine Learning to Make Medical-Related Predictions from Non-Medical Data",2018,"","","","",166,"2022-07-13 09:23:31","","10.1109/ICMLDE.2018.00021","","",,,,,5,1.25,2,3,4,"Objectives: Administrative HIS (Hospital Information System) and EHR (Electronic Health Record) data are characterized by lower privacy sensitivity, thus easier portability and handling, as well as higher information quality. In this paper we test the hypothesis that the application of machine learning techniques on data of this nature can be used to address prediction/forecasting problems in the Health IT domain. The novelty of this approach consists in that medical data (test results, diagnoses, doctors’ notes etc.) are not included in the predictors’ dataset. Moreover, there is limited need for separation of patient cohorts based on specific health conditions. Methods: We experiment with the prediction of the probability of early readmission at the time of a patient’s discharge. We extract real HIS data and perform data processing techniques. We then apply a series of machine learning algorithms (Logistic Regression, Support Vector Machine, Gaussian Naïve Bayes, K-Nearest Neighbors and Deep Multilayer Neural Network) and measure the performance of the emergent models. Results: All applied methods performed well above random guessing, even with minimal hyper-parameter tuning. Conclusions: Given that the experiments provide evidence in favor of the underlying hypothesis, future experimentation on more fine-tuned (thus more robust) models could result in applications suited for productive environments.","",""
290,"Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen","ReasoNet: Learning to Stop Reading in Machine Comprehension",2016,"","","","",167,"2022-07-13 09:23:31","","10.1145/3097983.3098177","","",,,,,290,48.33,73,4,6,"Teaching a computer to read and answer general questions pertaining to a document is a challenging yet unsolved problem. In this paper, we describe a novel neural network architecture called the Reasoning Network (ReasoNet) for machine comprehension tasks. ReasoNets make use of multiple turns to effectively exploit and then reason over the relation among queries, documents, and answers. Different from previous approaches using a fixed number of turns during inference, ReasoNets introduce a termination state to relax this constraint on the reasoning depth. With the use of reinforcement learning, ReasoNets can dynamically determine whether to continue the comprehension process after digesting intermediate results, or to terminate reading when it concludes that existing information is adequate to produce an answer. ReasoNets achieve superior performance in machine comprehension datasets, including unstructured CNN and Daily Mail datasets, the Stanford SQuAD dataset, and a structured Graph Reachability dataset.","",""
488,"Cha Zhang, Yunqian Ma","Ensemble Machine Learning: Methods and Applications",2012,"","","","",168,"2022-07-13 09:23:31","","","","",,,,,488,48.80,244,2,10,"It is common wisdom that gathering a variety of views and inputs improves the process of decision making, and, indeed, underpins a democratic society. Dubbed ensemble learning by researchers in computational intelligence and machine learning, it is known to improve a decision systems robustness and accuracy. Now, fresh developments are allowing researchers to unleash the power of ensemble learning in an increasing range of real-world applications. Ensemble learning algorithms such as boosting and random forest facilitate solutions to key computational issues such as face recognition and are now being applied in areas as diverse as object tracking and bioinformatics. Responding to a shortage of literature dedicated to the topic, this volume offers comprehensive coverage of state-of-the-art ensemble learning techniques, including the random forest skeleton tracking algorithm in the Xbox Kinect sensor, which bypasses the need for game controllers. At once a solid theoretical study and a practical guide, the volume is a windfall for researchers and practitioners alike.","",""
3,"Tao Fu","Forecasting Second-hand Housing Price using Artificial Intelligence and Machine Learning Techniques",2018,"","","","",169,"2022-07-13 09:23:31","","10.2991/mcei-18.2018.54","","",,,,,3,0.75,3,1,4,"In this era of information explosion, the development of science and technology changes with each passing day. Therefore, the automatic analysis of scientific and technological trends aims to help scientists extract useful information from a large number of academic conferences and scientific and technological documents, which is of great practical significance. Artificial Intelligence give us an useful techniques, this paper we use using artificial intelligence and machine learning techniques to fit and forecast house price, From the point of view of model, the prediction effect of support vector machine is the best, with strong stability, while neural network is the worst. As a contrast, linear regression and random forest have little difference between them. Introduction Artificial Intelligence is a new science of technology to study, develop and extend human intelligence theory, method, technology and application system. Artificial intelligence is the study of computer to simulate certain thinking processes and intelligent behaviors (such as learning, reasoning, thinking, planning, etc.). Enable the computer to achieve a higher level of application. Artificial intelligence will involve computer science, psychology, philosophy and linguistics. Corinna Cortes and Vapnik (1995) proposed support Vector Machine, which can improve the generalization ability of learning machine and minimize the empirical risk and confidence range by seeking the minimum structural risk[1].It can also be extended to other machine learning problems such as function fitting. Nello Cristianini and John Shawe-Taylor can be applied to support vector machine[2].A random forest is a classifier containing multiple decision trees, and the output categories are determined by the modes of the classes outputted by individual trees.Leo Breiman and Adele Cutler(1995) developed an algorithm to infer random forests[3], which was derived from random decision proposed by Tin Kam Ho of Bell Labs in 1995[4]. It improves the prediction accuracy of the model by summing up a large number of classification trees[5].Instead of traditional machine learning such as neural networks A new model of the. Artificial Neural Network (Ann), a hot research hot spot in artificial intelligence field since 1980s, Rumelhart, Hinton, William's(1986) developed BP algorithm has developed the radial basis function (RBF) basis function neural network for the first time[6].It has strong nonlinear fitting ability, can map any complex nonlinear relation, and the learning rules are simple, easy to realize by computer, and have strong robustness and memory ability. Nonlinear mapping ability and powerful self-learning ability. Methodologies Support Vector Machine. Support Vector Machine is based on the development of statistical learning theory. It systematically studies some fundamental problems in pattern recognition in the case of limited samples. The support Vector Machine regression (SVR) algorithm needs to define a loss function, which can ignore the errors in a range of real values, just like the SVM classification algorithm. This kind of function is insensitive loss. Figure 1shows the one-dimensional linear regression function with insensitive region. Copyright © 2018, the Authors. Published by Atlantis Press. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by-nc/4.0/). 269 8th International Conference on Mechatronics, Computer and Education Informationization (MCEI 2018) Advances in Computer Science Research (ACSR), volume 83","",""
0,"I. Bratko","Machine Learning and Qualitative Reasoning",1994,"","","","",170,"2022-07-13 09:23:31","","10.1007/BF00993980","","",,,,,0,0.00,0,1,28,"","",""
0,"F. Ekpenyong, G. Samakovitis, S. Kapetanakis, M. Petridis","Case Retrieval with Clustering for a Case-Based Reasoning and Inverse Problem Methodology: An Investigation of Financial Bubbles",2020,"","","","",171,"2022-07-13 09:23:31","","10.1007/978-3-030-70665-4_164","","",,,,,0,0.00,0,4,2,"","",""
0,"Dagmawi Alemu Moges, Rubungo Andre Niyongabo, Hong Qu","Multi-Perspective Reasoning Transformers",2021,"","","","",172,"2022-07-13 09:23:31","","10.1145/3457682.3457759","","",,,,,0,0.00,0,3,1,"Machine Reading Comprehension is defined as the ability of machines to read and understand unstructured text and answer questions about it. It is considered as a challenging task with wide range of enterprise applications. Wide range of natural language understanding and reasoning tasks are found embedded within machine reading comprehension datasets. This requires effective models with robust relational reasoning capabilities to answer complex questions. Reasoning in natural language is a long-term machine-learning goal and is critically needed for building intelligent agents. However, most papers heavily depend on underlying language modeling and thus pay little to no attention on creating effective reasoning models. This paper proposes a modified transformer architecture that effectively combines soft and hard attention to create multi-perspective reasoning model capable of tackling wide range of reasoning tasks. An attention mechanism that highlights the relational significance of input signals is considered as well. The result from this study shows performance gain as compared to its counterpart the transformer network on bAbI dataset, a natural language reasoning tasks.","",""
0,"Marie-Jeanne Lesot, C. Marsala","Fuzzy Approaches for Soft Computing and Approximate Reasoning: Theories and Applications - Dedicated to Bernadette Bouchon-Meunier",2021,"","","","",173,"2022-07-13 09:23:31","","10.1007/978-3-030-54341-9","","",,,,,0,0.00,0,2,1,"","",""
381,"Maximilian Nickel, Volker Tresp, H. Kriegel","Factorizing YAGO: scalable machine learning for linked data",2012,"","","","",174,"2022-07-13 09:23:31","","10.1145/2187836.2187874","","",,,,,381,38.10,127,3,10,"Vast amounts of structured information have been published in the Semantic Web's Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD's size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD's data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize non-deterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO~2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 ⋅ 1014 possible triples in the YAGO~2 core ontology.","",""
524,"S. Raschka","Python Machine Learning",2015,"","","","",175,"2022-07-13 09:23:31","","","","",,,,,524,74.86,524,1,7,"Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk and answer tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource.What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Keras and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success.Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization.Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.","",""
0,"Todd P. Huster","OWL query answering using machine learning",2015,"","","","",176,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,7,"Huster, Todd. M.S. Department of Computer Science and Engineering, Wright State University, 2015. OWL Query Answering Using Machine Learning. The formal semantics of the Web Ontology Language (OWL) enables automated reasoning over OWL knowledge bases, which in turn can be used for a variety of purposes including knowledge base development, querying and management. Automated reasoning is usually done by means of deductive (proof-theoretic) algorithms which are either provably sound and complete or employ approximate methods to trade some correctness for improved efficiency. As has been argued elsewhere, however, reasoning methods for the Semantic Web do not necessarily have to be based on deductive methods, and approximate reasoning using statistical or machine-learning approaches may bring improved speed while maintaining high precision and recall, and which furthermore may be more robust towards errors in the knowledge base and logical inconsistencies. In this thesis, we show that it is possible to learn a linear-time classifier that closely approximates deductive OWL reasoning in some settings. In particular, we specify a method for extracting feature vectors from OWL ontologies that enables the ID3 and AdaBoost classifiers to approximate OWL query answering for single answer variable queries. Amongst other ontologies, we evaluate our approach using the LUBM benchmark and the DCC ontology (a large real-world dataset about traffic in Dublin) and show considerable improvement over previous efforts.","",""
0,"Featurization As","The Third Army Research Office ( ARO ) Workshop on Adversarial Machine Learning Talk Abstracts and Bios Data",2018,"","","","",177,"2022-07-13 09:23:31","","","","",,,,,0,0.00,0,1,4,"The proliferation of machine learning (ML) and artificial intelligence (AI) systems for military and security applications creates substantial challenges for designing and deploying such mechanisms that would learn, adapt, reason and act with Dinky, Dirty, Dynamic, Deceptive, Distributed (D5) data. While Dinky and Dirty challenges have been extensively explored in ML theory, the Dynamic challenge has been a persistent problem in ML applications (when the statistical distribution of training data differs from that of test data). The most recent Deceptive challenge is a malicious distribution shift between training and test data that amplifies the effects of the Dynamic challenge to the complete breakdown of the ML algorithms. Using the MNIST dataset as a simple calibration example, we explore the following two questions: (1) What geometric and statistical characteristics of data distribution can be exploited by an adversary with a given magnitude of the attack? (2) What counter-measures can be used to protect the constructed decision rule (at the cost of somewhat decreased performance) against malicious distribution shift within a given magnitude of the attack? While not offering a complete solution to the problem, we collect and interpret obtained observations in a way that provides practical guidance for making more adversary-resistant choices in the design of ML algorithms. Bio: Rauf Izmailov is a Senior Research Scientist at Perspecta Labs and an established researcher in mathematical and computer models for networking and control systems, machine learning, optimization, and statistical data analysis. He has more than 20 years of industry experience (including AT&T Bell Labs and NEC Labs America) in research and technical leadership of R&D teams. With Dr. Vapnik, he co-invented the new machine learning paradigm, Learning Using Privileged Information (LUPI). He was the PI on the DARPA PPAML (“Probabilistic Programming for Advanced Machine Learning”) program and is currently the PI on the DARPA D3M (“Data-Driven Discovery of Models”) program and the analytics task leader on the DARPA LADS (“Leveraging the Analog Domain for Security”) program. He is also a co-PI on the AFOSR program “Science of Information, Computation, Learning and Fusion”. Adversarial Unsupervised Learning Abstract: Nowadays more and more data are gathered for detecting and preventing cyber attacks. In cyber security applications, data analytics techniques have to deal with active adversaries that try to deceive the data analytics models and avoid being detected. The existence of such adversarial behavior motivates the development of robust and resilient adversarial learning techniques for various tasks. Most of the existing work focused on adversarial classification techniques, which assumed the existence of a large amount of labeled data instances. However, in practice, labeling the data instances often requires costly and time-consuming human expertise and becomes a significant bottleneck. Nowadays more and more data are gathered for detecting and preventing cyber attacks. In cyber security applications, data analytics techniques have to deal with active adversaries that try to deceive the data analytics models and avoid being detected. The existence of such adversarial behavior motivates the development of robust and resilient adversarial learning techniques for various tasks. Most of the existing work focused on adversarial classification techniques, which assumed the existence of a large amount of labeled data instances. However, in practice, labeling the data instances often requires costly and time-consuming human expertise and becomes a significant bottleneck. Meanwhile, a large number of unlabeled instances can also be used to understand the adversaries' behavior. To address the above mentioned challenges, we develop a novel grid based adversarial clustering algorithm. Our adversarial clustering algorithm is able to identify the normal and abnormal regions, and to draw defensive walls around the centers of the normal objects utilizing game theoretic ideas. Our algorithm also identifies the overlapping areas within large mixed clusters, and outliers which may be potential anomalies. Bio: Bowei Xi received her Ph.D. in statistics from the Department of Statistics at the University of Michigan, Ann Arbor in 2004. She is an associate professor in the Department of Statistics at Purdue University. She was a visiting faculty in the Department of Statistics at Stanford University in summer 2007, and a visiting faculty at Statistical and Applied Mathematical Sciences Institute (SAMSI) from September 2012 to May 2013. Her research focuses on multidisciplinary work involving big datasets with complex structure from very different application areas including cyber security, Internet traffic, metabolomics, machine learning, and data mining. She has a US patent on an automatic system configuration tool and has filed another patent application for identification of blood-based metabolite biomarkers of pancreatic cancer. Limitations of the Lipschitz Constant as a Defense Against Adversarial Examples Abstract: Several recent papers have discussed utilizing Lipschitz constants to limit the susceptibility of neural networks to adversarial examples. We analyze recently proposed methods for computing the Lipschitz constant. We show that the Lipschitz constant may indeed enable adversarially robust neural networks. However, the methods currently employed for computing it suffer from theoretical and practical limitations. We argue that addressing this shortcoming is a promising direction for future research into certified adversarial defenses. Several recent papers have discussed utilizing Lipschitz constants to limit the susceptibility of neural networks to adversarial examples. We analyze recently proposed methods for computing the Lipschitz constant. We show that the Lipschitz constant may indeed enable adversarially robust neural networks. However, the methods currently employed for computing it suffer from theoretical and practical limitations. We argue that addressing this shortcoming is a promising direction for future research into certified adversarial defenses. Bio: Todd Huster is a research scientist at Perspecta Labs. He has extensive experience solving challenging problems in the fields of machine learning, remote sensing, evaluation methodologies, and symbolic reasoning. He holds an M.S. in Computer Science from Wright State University. Certified Defenses Against Adversarial Examples Abstract: While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this talk, I will present some methods based on convex relaxations (with a focus on semidefinite programming) that output a certificate that for a given network and test input, no attack can force the error to exceed a certain value. I will then discuss how these certification procedures can be incorporated into neural network training to obtain provably While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this talk, I will present some methods based on convex relaxations (with a focus on semidefinite programming) that output a certificate that for a given network and test input, no attack can force the error to exceed a certain value. I will then discuss how these certification procedures can be incorporated into neural network training to obtain provably robust networks. Finally, I will present some empirical results on the performance of attacks and different certificates on networks trained using different objectives. This is joint work with Jacob Steinhardt and Percy Liang. Bio: Aditi Raghunathan is a third year PhD student at Stanford University working with Percy Liang. She is a recipient of the Google PhD Fellowship in Machine Learning and the Open Philanthrophy Project AI Fellowship. She is primarily interested in making machine learning systems provably robust to adversarial perturbations. She is also interested in ensuring fairness in the outcomes of ML systems. She spent the summer of 2018 at Google Brain working with Ian Goodfellow and Alex Kurakin. Previously, she was an undergraduate at IIT Madras. Is Robust ML Really Robust? Abstract: Machine learning (ML) techniques are increasingly common in security applications, such as malware and intrusion detection. However, ML models are often susceptible to evasion attacks, in which an adversary makes changes to the input (such as malware) in order to avoid being detected. A conventional approach to evaluate ML robustness to such attacks, as well as to design robust ML, is by considering simplified feature-space models of attacks, where the attacker changes ML features directly to effect evasion, while minimizing or constraining the magnitude of this change. We investigate the effectiveness of this approach to designing robust ML in the face of attacks that can be realized in actual malware (realizable attacks). We demonstrate that in the context of structure-based PDF malware detection, such techniques appear to have limited effectiveness. On the other hand, they are quite effective with contentbased detectors. In either case, we show that augmenting the feature space models with conserved features (those that cannot be unilaterally modified without compromising malicious functionality","",""
0,"A. Shamsa, M. Paydayesh","Data-Driven Signal Recognition- A Machine Learning Application For The Real-Time Microseismic Monitoring",2018,"","","","",178,"2022-07-13 09:23:31","","10.3997/2214-4609.201803007","","",,,,,0,0.00,0,2,4,"A simple and robust machine learning technique is applied to automate signal detection and analyse recorded microseismic data. The method’s performance is tested and evaluated on real data. The fracture signals were well-detected using the proposed workflow and techniques when more data were introduced. In contrast to conventional methods, the techniques implemented herein described work on training the model prediction with additional data without restarting from the beginning, making them viable for continuous online learning. This method attempts to remove the burden of labour-intensive processing of microseismic data and replace it with a faster, cheaper, and more accurate way of achieving signal detection.","",""
0,"Qunxiong Zhu, Xiaohan Zhang, Yuan Xu, Yanlin He","Intelligent Measurement Modeling Using a Novel Multi-nonlinear Mapping Based Extreme Learning Machine Integrated with Partial Least Square Regression",2020,"","","","",179,"2022-07-13 09:23:31","","10.1109/DDCLS49620.2020.9275221","","",,,,,0,0.00,0,4,2,"Accurate intelligent measurement modeling plays a key role in complex process industries. However, establishing an accurate and robust measurement model tends to be more and more difficult because of the increasing complexity in terms of nonlinearity and collinearity of data. To solve this problem, a novel multi-nonlinear mapping based extreme learning machine integrated with partial least square regression is proposed in this paper. In the proposed model, two problems of nonlinearity and collinearity are effectively dealt with by using multi-nonlinear mapping and partial least square regression, respectively. For evaluating performance, empirical studies on a commonly used bench mark problem and a real-world application confirm that the presented method can obtain high accuracy and high stability performance for intelligent measurement.","",""
154,"V. Chernozhukov, D. Chetverikov, Mert Demirer, E. Duflo, Christian Hansen, W. Newey","Double machine learning for treatment and causal parameters",2016,"","","","",180,"2022-07-13 09:23:31","","10.1920/WP.CEM.2016.4916","","",,,,,154,25.67,26,6,6,"Most modern supervised statistical/machine learning (ML) methods are explicitly designed to solve prediction problems very well. Achieving this goal does not imply that these methods automatically deliver good estimators of causal parameters. Examples of such parameters include individual regression coffiecients, average treatment e ffects, average lifts, and demand or supply elasticities. In fact, estimators of such causal parameters obtained via naively plugging ML estimators into estimating equations for such parameters can behave very poorly. For example, the resulting estimators may formally have inferior rates of convergence with respect to the sample size n caused by regularization bias. Fortunately, this regularization bias can be removed by solving auxiliary prediction problems via ML tools. Speci ficially, we can form an efficient score for the target low-dimensional parameter by combining auxiliary and main ML predictions. The efficient score may then be used to build an efficient estimator of the target parameter which typically will converge at the fastest possible 1/v n rate and be approximately unbiased and normal, allowing simple construction of valid con fidence intervals for parameters of interest. The resulting method thus could be called a ""double ML"" method because it relies on estimating primary and auxiliary predictive models. Such double ML estimators achieve the fastest rates of convergence and exhibit robust good behavior with respect to a broader class of probability distributions than naive ""single"" ML estimators. In order to avoid overfi tting, following [3], our construction also makes use of the K-fold sample splitting, which we call cross- fitting. The use of sample splitting allows us to use a very broad set of ML predictive methods in solving the auxiliary and main prediction problems, such as random forests, lasso, ridge, deep neural nets, boosted trees, as well as various hybrids and aggregates of these methods (e.g. a hybrid of a random forest and lasso). We illustrate the application of the general theory through application to the leading cases of estimation and inference on the main parameter in a partially linear regression model and estimation and inference on average treatment eff ects and average treatment e ffects on the treated under conditional random assignment of the treatment. These applications cover randomized control trials as a special case. We then use the methods in an empirical application which estimates the e ffect of 401(k) eligibility on accumulated financial assets.","",""
1,"Adis Alihodzic, Eva Tuba, M. Tuba","An Improved Extreme Learning Machine Tuning by Flower Pollination Algorithm",2020,"","","","",181,"2022-07-13 09:23:31","","10.1007/978-3-030-28553-1_5","","",,,,,1,0.50,0,3,2,"","",""
1,"I. Bratko","Machine learning and qualitative reasoning",2004,"","","","",182,"2022-07-13 09:23:31","","10.1023/A:1022661713654","","",,,,,1,0.06,1,1,18,"","",""
0,"Shi Chen, Ming Jiang, Jinhui Yang, Qi Zhao","Attention in Reasoning: Dataset, Analysis, and Modeling",2021,"","","","",183,"2022-07-13 09:23:31","","10.1109/TPAMI.2021.3114582","","",,,,,0,0.00,0,4,1,"While attention has been an increasingly popular component in deep neural networks to both interpret and boost the performance of models, little work has examined how attention progresses to accomplish a task and whether it is reasonable. In this work, we propose an Attention with Reasoning capability (AiR) framework that uses attention to understand and improve the process leading to task outcomes. We first define an evaluation metric based on a sequence of atomic reasoning operations, enabling a quantitative measurement of attention that considers the reasoning process. We then collect human eye-tracking and answer correctness data, and analyze various machine and human attention mechanisms on their reasoning capability and how they impact task performance. To improve the attention and reasoning ability of visual question answering models, we propose to supervise the learning of attention progressively along the reasoning process and to differentiate the correct and incorrect attention patterns. We demonstrate the effectiveness of the proposed framework in analyzing and modeling attention with better reasoning capability and task performance. The code and data are available at \url{https://github.com/szzexpoi/AiR}.","",""
0,"B. Makni, Monireh Ebrahimi, Dagmar Gromann, Aaron Eberhart","Neuro-Symbolic Semantic Reasoning",2021,"","","","",184,"2022-07-13 09:23:31","","10.3233/faia210358","","",,,,,0,0.00,0,4,1,"Humans have astounding reasoning capabilities. They can learn from very few examples while providing explanations for their decision-making process. In contrast, deep learning techniques–even though robust to noise and very effective in generalizing across several fields including machine vision, natural language understanding, speech recognition, etc. –require large amounts of data and are mostly unable to provide explanations for their decisions. Attaining human-level robust reasoning requires combining sound symbolic reasoning with robust connectionist learning. However, connectionist learning uses low-level representations–such as embeddings–rather than symbolic representations. This challenge constitutes what is referred to as the Neuro-Symbolic gap. A field of study to bridge this gap between the two paradigms has been called neuro-symbolic integration or neuro-symbolic computing. This chapter aims to present approaches that contribute towards bridging the Neuro-Symbolic gap specifically in the Semantic Web field, RDF Schema (RDFS) and EL+ reasoning and to discuss the benefits and shortcomings of neuro-symbolic reasoning.","",""
0,"Xun Ge, Scott N. Wilson, Jackie T. Mania Singer, William Thompson, K. Kornelson, Jessica Lajos, Braden Roper, Javier Elizondo, S. Reeder, Leslie A. Williams, Margaret Kleiser","The Iteration of Design and Assessment for a Digital Game to Support Reasoning in a College Algebra Course",2021,"","","","",185,"2022-07-13 09:23:31","","10.1007/978-3-030-75142-5_12","","",,,,,0,0.00,0,11,1,"","",""
87,"Nicholas Wagner, J. Rondinelli","Theory-Guided Machine Learning in Materials Science",2016,"","","","",186,"2022-07-13 09:23:31","","10.3389/fmats.2016.00028","","",,,,,87,14.50,44,2,6,"Materials scientists are increasingly adopting the use of machine learning tools to discover hidden trends in data and make predictions. Applying concepts from data science without foreknowledge of their limitations and the unique qualities of materials data, however, could lead to errant conclusions. The differences that exist between various kinds of experimental and calculated data require careful choices of data processing and machine learning methods. Here, we outline potential pitfalls involved in using machine learning without robust protocols. We address some problems of overfitting to training data using decision trees as an example, rational descriptor selection in the field of perovskites, and preserving physical interpretability in the application of dimensionality reducing techniques such as principal component analysis. We show how proceeding without the guidance of domain knowledge can lead to both quantitatively and qualitatively incorrect predictive models.","",""
19,"M. Hausknecht, Wen-Ke Li, M. Mauk, P. Stone","Machine Learning Capabilities of a Simulated Cerebellum",2017,"","","","",187,"2022-07-13 09:23:31","","10.1109/TNNLS.2015.2512838","","",,,,,19,3.80,5,4,5,"This paper describes the learning and control capabilities of a biologically constrained bottom-up model of the mammalian cerebellum. Results are presented from six tasks: 1) eyelid conditioning; 2) pendulum balancing; 3) proportional–integral–derivative control; 4) robot balancing; 5) pattern recognition; and 6) MNIST handwritten digit recognition. These tasks span several paradigms of machine learning, including supervised learning, reinforcement learning, control, and pattern recognition. Results over these six domains indicate that the cerebellar simulation is capable of robustly identifying static input patterns even when randomized across the sensory apparatus. This capability allows the simulated cerebellum to perform several different supervised learning and control tasks. On the other hand, both reinforcement learning and temporal pattern recognition prove problematic due to the delayed nature of error signals and the simulator’s inability to solve the credit assignment problem. These results are consistent with previous findings which hypothesize that in the human brain, the basal ganglia is responsible for reinforcement learning, while the cerebellum handles supervised learning.","",""
16,"Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Ves Stoyanov, Xian Li","Few-shot Learning with Multilingual Language Models",2021,"","","","",188,"2022-07-13 09:23:31","","","","",,,,,16,16.00,2,21,1,"Large-scale autoregressive language models such as GPT-3 are few-shot learners that can perform a wide range of language tasks without fine-tuning. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual autoregressive language models on a balanced corpus covering a diverse set of languages, and study their fewand zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 translation directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We present a detailed analysis of where the model succeeds and fails, showing in particular that it enables cross-lingual in-context learning on some tasks, while there is still room for improvement on surface form robustness and adaptation to tasks that do not have a natural cloze form. Finally, we evaluate our models in social value tasks such as hate speech detection in 5 languages and find it has limitations similar to comparably sized GPT-3 models.","",""
3,"R. Drummond, Mathew C. Turner, S. Duncan","Reduced-Order Neural Network Synthesis with Robustness Guarantees",2021,"","","","",189,"2022-07-13 09:23:31","","10.1109/TNNLS.2022.3182893","","",,,,,3,3.00,1,3,1,"In the wake of the explosive growth in smartphones and cyber-physical systems, there has been an accelerating shift in how data are generated away from centralized data toward on-device-generated data. In response, machine learning algorithms are being adapted to run locally on board, potentially hardware-limited, devices to improve user privacy, reduce latency, and be more energy efficient. However, our understanding of how these device-orientated algorithms behave and should be trained is still fairly limited. To address this issue, a method to automatically synthesize reduced-order neural networks (having fewer neurons) approximating the input-output mapping of a larger one is introduced. The reduced-order neural network's weights and biases are generated from a convex semidefinite program that minimizes the worst case approximation error with respect to the larger network. Worst case bounds for this approximation error are obtained and the approach can be applied to a wide variety of neural networks architectures. What differentiates the proposed approach to existing methods for generating small neural networks, e.g., pruning, is the inclusion of the worst case approximation error directly within the training cost function, which should add robustness to out-of-sample data points. Numerical examples highlight the potential of the proposed approach. The overriding goal of this article is to generalize recent results in the robustness analysis of neural networks to a robust synthesis problem for their weights and biases.","",""
2,"Marine Picot, Francisco Messina, Malik Boudiaf, F. Labeau, I. B. Ayed, P. Piantanida","Adversarial Robustness via Fisher-Rao Regularization",2021,"","","","",190,"2022-07-13 09:23:31","","10.1109/TPAMI.2022.3174724","","",,,,,2,2.00,0,6,1,"Adversarial robustness has become a topic of growing interest in machine learning since it was observed that neural networks tend to be brittle. We propose an information-geometric formulation of adversarial defense and introduce Fire, a new Fisher-Rao regularization for the categorical cross-entropy loss, which is based on the geodesic distance between the softmax outputs corresponding to natural and perturbed input features. Based on the information-geometric properties of the class of softmax distributions, we derive an explicit characterization of the Fisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some interesting properties as well as connections with standard regularization metrics. Furthermore, we verify on a simple linear and Gaussian model, that all Pareto-optimal points in the accuracy-robustness region can be reached by Fire while other state-of-the-art methods fail. Empirically, we evaluate the performance of various classifiers trained with the proposed loss on standard datasets, showing up to a simultaneous 1% of improvement in terms of clean and robust performances while reducing the training time by 20% over the best-performing methods.","",""
146,"C. Kaliszyk, J. Urban","Learning-Assisted Automated Reasoning with Flyspeck",2012,"","","","",191,"2022-07-13 09:23:31","","10.1007/s10817-014-9303-3","","",,,,,146,14.60,73,2,10,"","",""
3,"Yunzhe Xue, Meiyan Xie, Usman Roshan","Towards adversarial robustness with 01 loss neural networks",2020,"","","","",192,"2022-07-13 09:23:31","","10.1109/ICMLA51294.2020.00204","","",,,,,3,1.50,1,3,2,"Motivated by the general robustness properties of the 01 loss we propose a single hidden layer 01 loss neural network trained with stochastic coordinate descent as a defense against adversarial attacks in machine learning. One measure of a model’s robustness is the minimum distortion required to make the input adversarial. This can be approximated with the Boundary Attack (Brendel et. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare the minimum distortion of the 01 loss network to the binarized neural network and the standard sigmoid activation network with cross-entropy loss all trained with and without Gaussian noise on the CIFAR10 benchmark binary classification between classes 0 and 1. Both with and without noise training we find our 01 loss network to have the largest adversarial distortion of the three models by non-trivial margins. To further validate these results we subject all models to substitute model black box attacks under different distortion thresholds and find that the 01 loss network is the hardest to attack across all distortions. At a distortion of 0.125 both sigmoid activated cross-entropy loss and binarized networks have almost 0% accuracy on adversarial examples whereas the 01 loss network is at 40%. Even though both 01 loss and the binarized network use sign activations their training algorithms are different which in turn give different solutions for robustness. Finally we compare our network to simple convolutional models under substitute model black box attacks and find their accuracies to be comparable. Our work shows that the 01 loss network has the potential to defend against black box adversarial attacks better than convex loss and binarized networks.","",""
1,"Y. Itoh, M. Adachi","Reconstructing Bifurcation Diagrams of Induction Motor Drives Using an Extreme Learning Machine",2017,"","","","",193,"2022-07-13 09:23:31","","10.1007/978-3-030-01520-6_6","","",,,,,1,0.20,1,2,5,"","",""
2,"Benjamin M. Marlin, T. Abdelzaher, G. Ciocarlie, Adam D. Cobb, Mark S. Dennison, Brian Jalaian, Lance M. Kaplan, Tiffany R. Raber, A. Raglin, P. Sharma, M. Srivastava, T. Trout, Meet P. Vadera, Maggie B. Wigness","On Uncertainty and Robustness in Large-Scale Intelligent Data Fusion Systems",2020,"","","","",194,"2022-07-13 09:23:31","","10.1109/CogMI50398.2020.00020","","",,,,,2,1.00,0,14,2,"The resurgence of AI in the recent decade dramatically changes the design of modern sensor data fusion systems, leading to new challenges, opportunities, and research directions. One of these challenges is the management of uncertainty. This paper develops a framework to reason about sources of uncertainty, develops representations of uncertainty, and investigates uncertainty mitigation strategies in modern intelligent data processing systems. Insights are developed into workflow composition that maximizes efficacy at accomplishing mission goals despite the sources of uncertainty, while leveraging a collaboration of humans, algorithms, and machine learning components.","",""
5,"L. Eliot","Authorized and Unauthorized Practices of Law: The Role of Autonomous Levels of AI Legal Reasoning",2020,"","","","",195,"2022-07-13 09:23:31","","","","",,,,,5,2.50,5,1,2,"Advances in Artificial Intelligence (AI) and Machine Learning (ML) that are being applied to legal efforts have raised controversial questions about the existent restrictions imposed on the practice-of-law. Generally, the legal field has sought to define Authorized Practices of Law (APL) versus Unauthorized Practices of Law (UPL), though the boundaries are at times amorphous and some contend capricious and self-serving, rather than being devised holistically for the benefit of society all told. A missing ingredient in these arguments is the realization that impending legal profession disruptions due to AI can be more robustly discerned by examining the matter through the lens of a framework utilizing the autonomous levels of AI Legal Reasoning (AILR). This paper explores a newly derived instrumental grid depicting the key characteristics underlying APL and UPL as they apply to the AILR autonomous levels and offers key insights for the furtherance of these crucial practice-of-law debates.","",""
0,"Mark H. Meng, Guangdong Bai, S. Teo, Zhe Hou, Yan Xiao, Yun Lin, Jin Song Dong","Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective",2022,"","","","",196,"2022-07-13 09:23:31","","10.1109/TDSC.2022.3179131","","",,,,,0,0.00,0,7,1,"—Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which concerns the reliability of a neural network when dealing with maliciously manipulated inputs, is one of the hottest topics in security and machine learning. In this work, we survey existing literature in adversarial robustness veriﬁcation for neural networks and collect 39 diversiﬁed research works across machine learning, security, and software engineering domains. We systematically analyze their approaches, including how robustness is formulated, what veriﬁcation techniques are used, and the strengths and limitations of each technique. We provide a taxonomy from a formal veriﬁcation perspective for a comprehensive understanding of this topic. We classify the existing techniques based on property speciﬁcation, problem reduction, and reasoning strategies. We also demonstrate representative techniques that have been applied in existing studies with a sample model. Finally, we discuss open questions for future research.","",""
2,"Jing Zhang, Bo Chen, Lingxi Zhang, Xirui Ke, Haipeng Ding","Neural-Symbolic Reasoning on Knowledge Graphs",2020,"","","","",197,"2022-07-13 09:23:31","","","","",,,,,2,1.00,0,5,2,"Knowledge graph reasoning is the fundamental component to support machine learning applications such as information extraction, information retrieval and recommendation. Since knowledge graph can be viewed as the discrete symbolic representations of knowledge, reasoning on knowledge graphs can naturally leverage the symbolic techniques. However, symbolic reasoning is intolerant of the ambiguous and noisy data. On the contrary, the recent advances of deep learning promote neural reasoning on knowledge graphs, which is robust to the ambiguous and noisy data, but lacks interpretability compared to symbolic reasoning. Considering the advantages and disadvantages of both methodologies, recent efforts have been made on combining the two reasoning methods. In this survey, we take a thorough look at the development of the symbolic reasoning, neural reasoning and the neural-symbolic reasoning on knowledge graphs. We survey two specific reasoning tasks, knowledge graph completion and question answering on knowledge graphs, and explain them in a unified reasoning framework. We also briefly discuss the future directions for knowledge graph reasoning.","",""
0,"Zhang Jing, Ren Yong-gong","Robust Multi-feature Extreme Learning Machine",2017,"","","","",198,"2022-07-13 09:23:31","","10.1007/978-3-030-01520-6_13","","",,,,,0,0.00,0,2,5,"","",""
0,"G. M. Daiyan, Leiting Chen, Chuan Zho, G. M. Nayeem","Fusion of Statistical Reasoning for Healing Highly Corrupted Image",2022,"","","","",199,"2022-07-13 09:23:31","","10.14569/ijacsa.2022.0130472","","",,,,,0,0.00,0,4,1,"—The accurate approximation of pixel value for preserving image details at a high concentration of noise has led the researchers to improve filters performance. A few image restoration filters are effective at lower density noise. Filters are commonly deployed for cameras, image processing tasks, medical image analysis, guided media data transmission, and real-time machine learning. This article proposes a mathematical model for the exact pixel value estimation at a high noise density for RGB and Gray images. The mathematical model is implemented to fuse statistical reasoning on the optimized mask sizes while preserving image details. Different parameter returns from the median filter, the trimmed median filter, the trimmed mean filter, and mood analysis form a mathematical function. The filter iteratively selects different schemes to calculate pixel values at different noise densities with minimum image information. Different processing masks are analyzed to preserve local data at specific image locations correctly in high density. A robust estimator counts false approximation of pixel values as discontinued, identified, and removed. At the post smoothening process, the filter recovers the misclassification of noise-free pixel and blur effects in the image. The qualitative experiments show satisfactory results in storing the details of the image from any image. The performance of the fusion filter is verified with visual quality and performance analysis matrices such as the image enhancement factor, the similarity indicator and the noise ratio from the peak signal.","",""
0,"Jianwei Wang, Deyun Chen","Few-Shot Object Detection Method Based on Knowledge Reasoning",2022,"","","","",200,"2022-07-13 09:23:31","","10.3390/electronics11091327","","",,,,,0,0.00,0,2,1,"Human beings have the ability to quickly recognize novel concepts with the help of scene semantics. This kind of ability is meaningful and full of challenge for the field of machine learning. At present, object recognition methods based on deep learning have achieved excellent results with the use of large-scale labeled data. However, the data scarcity of novel objects significantly affects the performance of these recognition methods. In this work, we investigated utilizing knowledge reasoning with visual information in the training of a novel object detector. We trained a detector to project the image representations of objects into an embedding space. Knowledge subgraphs were extracted to describe the semantic relation of the specified visual scenes. The spatial relationship, function relationship, and the attribute description were defined to realize the reasoning of novel classes. The designed few-shot detector, named KR-FSD, is robust and stable to the variation of shots of novel objects, and it also has advantages when detecting objects in a complex environment due to the flexible extensibility of KGs. Experiments on VOC and COCO datasets showed that the performance of the detector was increased significantly when the novel class was strongly associated with some of the base classes, due to the better knowledge propagation between the novel class and the related groups of classes.","",""
