Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
2,"Wenyan Yang, N. Strokina, N. Serbenyuk, J. Pajarinen, R. Ghabcheloo, J. Vihonen, M. M. Aref, Joni-Kristian Kämäräinen","Neural Network Controller for Autonomous Pile Loading Revised",2021,"","","","",1,"2022-07-13 09:27:29","","10.1109/ICRA48506.2021.9561804","","",,,,,2,2.00,0,8,1,"We have recently proposed two pile loading controllers that learn from human demonstrations: a neural network (NNet) [1] and a random forest (RF) controller [2]. In the field experiments the RF controller obtained clearly better success rates. In this work, the previous findings are drastically revised by experimenting summer time trained controllers in winter conditions. The winter experiments revealed a need for additional sensors, more training data, and a controller that can take advantage of these. Therefore, we propose a revised neural controller (NNetV2) which has a more expressive structure and uses a neural attention mechanism to focus on important parts of the sensor and control signals. Using the same data and sensors to train and test the three controllers, NNetV2 achieves better robustness against drastically changing conditions and superior success rate. To the best of our knowledge, this is the first work testing a learning-based controller for a heavy-duty machine in drastically varying outdoor conditions and delivering high success rate in winter, being trained in summer.","",""
12,"Jiahang Wang, Sheng Jin, Wentao Liu, Weizhong Liu, C. Qian, Ping Luo","When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks",2021,"","","","",2,"2022-07-13 09:27:29","","10.1109/CVPR46437.2021.01168","","",,,,,12,12.00,2,6,1,"Human pose estimation is a fundamental yet challenging task in computer vision, which aims at localizing human anatomical keypoints. However, unlike human vision that is robust to various data corruptions such as blur and pixelation, current pose estimators are easily confused by these corruptions. This work comprehensively studies and addresses this problem by building rigorous robust benchmarks, termed COCO-C, MPII-C, and OCHuman-C, to evaluate the weaknesses of current advanced pose estimators, and a new algorithm termed AdvMix is proposed to improve their robustness in different corruptions. Our work has several unique benefits. (1) AdvMix is model-agnostic and capable in a wide-spectrum of pose estimation models. (2) AdvMix consists of adversarial augmentation and knowledge distillation. Adversarial augmentation contains two neural network modules that are trained jointly and competitively in an adversarial manner, where a generator network mixes different corrupted images to confuse a pose estimator, improving the robustness of the pose estimator by learning from harder samples. To compensate for the noise patterns by adversarial augmentation, knowledge distillation is applied to transfer clean pose structure knowledge to the target pose estimator. (3) Extensive experiments show that AdvMix significantly increases the robustness of pose estimations across a wide range of corruptions, while maintaining accuracy on clean data in various challenging benchmark datasets.","",""
0,"Ioannis E. Polykretis, Guangzhi Tang, Praveenram Balachandar, K. Michmizos","A Spiking Neural Network Mimics the Oculomotor System to Control a Biomimetic Robotic Head Without Learning on a Neuromorphic Hardware",2022,"","","","",3,"2022-07-13 09:27:29","","10.1109/TMRB.2022.3155278","","",,,,,0,0.00,0,4,1,"Facilitated by the emergence of neuromorphic hardware, neuromorphic algorithms mimic the brain’s asynchronous computation to improve energy efficiency, low latency, and robustness, which are crucial for a wide variety of real-time robotic applications. However, the limited on-chip learning abilities hinder the applicability of neuromorphic computing to real-world robotic tasks. Biomimetism can overcome this limitation by complementing or replacing training with the knowledge of the brain’s connectome associated with the targeted behavior. By drawing inspiration from the human oculomotor network, we designed a spiking neural network (SNN) that tracked visual targets in real-time. We deployed the biomimetic controller on Intel’s Loihi neuromorphic processor to control an in-house robotic head. The robot’s behavior resembled the smooth pursuit and saccadic eye movements observed in humans, while the SNN on Loihi exhibited similar performance to a CPU-run PID controller. Interestingly, this behavior emerged from the SNN without training, which places the biomimetic design as an alternative to the energy- and data-greedy learning-based methods. This work reinforces our on-going efforts to devise energy-efficient autonomous robots that mimic the robustness and versatility of their biological counterparts.","",""
1,"M. H. Mozaffari, Chanho Kim, Won-sook Lee","Ultrasound Tongue Contour Extraction using Dilated Convolutional Neural Network",2019,"","","","",4,"2022-07-13 09:27:29","","10.1109/BIBM47256.2019.8983002","","",,,,,1,0.33,0,3,3,"One application of medical ultrasound imaging is to visualize and characterize human tongue shape and motion to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it requires knowledge about the tongue structure and ultrasound data interpretation for users to recognize tongue gestures. Moreover, quantitative analysis of tongue motion needs the tongue contour to be extracted, tracked and visualized automatically. This paper presents two novel deep neural networks that benefit from the ability of global prediction of encoding-decoding fully convolutional networks and the capability of full-resolution extraction of dilated convolutions. Assessment studies over datasets from different ultrasound machines disclosed the outstanding performances of the proposed models in terms of accuracy and robustness.","",""
0,"Zhenxiang Li, T. Zheng, Wang Yang, Hongyong Fu, Wenbo Wu","A Robust Fault Diagnosis Method for Rolling Bearings Based on Deep Convolutional Neural Network",2019,"","","","",5,"2022-07-13 09:27:29","","10.1109/phm-qingdao46334.2019.8943018","","",,,,,0,0.00,0,5,3,"Fault diagnosis of rolling bearings has been an important and challenging research issue. The existing conventional algorithms for diagnosing rolling bearings rely on artificial feature extraction requiring a wealth of knowledge of signal handling, expertise and human efforts, lacking adaptability. With the capacity for learning features from original signals automatically, deep learning methods can solve the shortcomings of conventional diagnosis methods. This paper puts forward a deep learning method for rolling bearing fault diagnosis based on two-dimensional convolutional neural network, called 2dCNN-FD. The method has the capability of automatic feature extraction and robust noise tolerance. Experimental results demonstrate that comparing with other traditional diagnosis algorithms, the 2dCNN-FD model achieves high diagnosis accuracy and better robustness under different noise conditions.","",""
8,"Yi Yang, F. Chen, Xiaoming Chen, Yan Dai, Zhenyang Chen, Jiang Ji, Tong Zhao","Video system for human attribute analysis using compact convolutional neural network",2016,"","","","",6,"2022-07-13 09:27:29","","10.1109/ICIP.2016.7532424","","",,,,,8,1.33,1,7,6,"Convolutional neural networks show their advantage in human attribute analysis (e.g. age, gender and ethnicity). However, they experience issues (e.g. robustness and responsiveness) when deployed in an intelligent video system. We propose one compact CNN model and apply it in our video system motivated by the full consideration of performance and usability. With the proposed web image mining and labelling strategy, we construct a large training set which covers various image conditions. The proposed CNN model successfully achieves a mean absolute error (MAE) of 3.23 years on the Morph 2 dataset, using the same test policy as our counterparts. This is the state-of-the-art score to our knowledge using CNN for age estimation. The proposed video analysis system employs this compact CNN model and demonstrated good performance in both dataset tests and deployment in real-world environments.","",""
2,"Yichuan Zhang, Yixing Lan, Qiang Fang, Xin Xu, Junxiang Li, Yujun Zeng","Efficient Reinforcement Learning from Demonstration via Bayesian Network-Based Knowledge Extraction",2021,"","","","",7,"2022-07-13 09:27:29","","10.1155/2021/7588221","","",,,,,2,2.00,0,6,1,"Reinforcement learning from demonstration (RLfD) is considered to be a promising approach to improve reinforcement learning (RL) by leveraging expert demonstrations as the additional decision-making guidance. However, most existing RLfD methods only regard demonstrations as low-level knowledge instances under a certain task. Demonstrations are generally used to either provide additional rewards or pretrain the neural network-based RL policy in a supervised manner, usually resulting in poor generalization capability and weak robustness performance. Considering that human knowledge is not only interpretable but also suitable for generalization, we propose to exploit the potential of demonstrations by extracting knowledge from them via Bayesian networks and develop a novel RLfD method called Reinforcement Learning from demonstration via Bayesian Network-based Knowledge (RLBNK). The proposed RLBNK method takes advantage of node influence with the Wasserstein distance metric (NIW) algorithm to obtain abstract concepts from demonstrations and then a Bayesian network conducts knowledge learning and inference based on the abstract data set, which will yield the coarse policy with corresponding confidence. Once the coarse policy's confidence is low, another RL-based refine module will further optimize and fine-tune the policy to form a (near) optimal hybrid policy. Experimental results show that the proposed RLBNK method improves the learning efficiency of corresponding baseline RL algorithms under both normal and sparse reward settings. Furthermore, we demonstrate that our RLBNK method delivers better generalization capability and robustness than baseline methods.","",""
0,"B. Mukunthan","A NEURAL NETWORK APPROACH FOR THE PRECISE PATTERN RECOGNITION OF HUMAN DNA",2012,"","","","",8,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,10,"The primary goal of bio informatics and neural networks solely is to increase our understanding of biological processes and focus on developing and applying computationally intensive techniques (e.g., pattern recognition, data mining, machine learning algorithms, and visualization) to achieve this goal. The neural networks exhibit characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, parallel and high speed information processing. Neural networks learn by examples they can therefore be trained with known examples of a problem to ‘acquire’ knowledge about it. Once appropriately trained, the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. The perfect blend made of bioinformatics and neural networks results in efficient pattern analysis techniques. The conventional techniques and algorithms employed by forensic scientists to assist in the identification of individuals on the basis of their respective DNA profiles involves more computational steps and mathematical formulas that leads to more time and space complexity resulting in complicated and less efficient algorithms which can be shorted out by emerging Artificial Neural Network approach.","",""
4,"H. Najafi","A neural network approach to digital data hiding based on the perceptual masking model of the human vision system",2010,"","","","",9,"2022-07-13 09:27:29","","10.1108/17563781011066693","","",,,,,4,0.33,4,1,12,"Purpose – The purpose of this paper is to present a novel approach for digital watermarking and steganography technique that uses neural networks. The performance of the proposed solution in terms of its capacity, transparency, and robustness is investigated.Design/methodology/approach – The proposed technique trains a neural network to learn the perceptual masking model of the human vision system. Once trained, the neural network identifies pixels whose most significant alteration will be least perceptible to the human eye. The image is then altered based on the network recommendation to include the watermark or the covert data.Findings – Experimental results demonstrate that the proposed technique offers excellent transparency and good capacity. In addition, since neural networks store their learned knowledge in a distributed fashion, steganalysis of the image without access to the network is very difficult, if not impossible. Results demonstrate good performance of the proposed solution in terms of its...","",""
5,"Mingke Xu, Fan Zhang, Wei Zhang","Head Fusion: Improving the Accuracy and Robustness of Speech Emotion Recognition on the IEMOCAP and RAVDESS Dataset",2021,"","","","",10,"2022-07-13 09:27:29","","10.1109/ACCESS.2021.3067460","","",,,,,5,5.00,2,3,1,"Speech Emotion Recognition (SER) refers to the use of machines to recognize the emotions of a speaker from his (or her) speech. SER benefits Human-Computer Interaction(HCI). But there are still many problems in SER research, e.g., the lack of high-quality data, insufficient model accuracy, little research under noisy environments, etc. In this paper, we proposed a method called Head Fusion based on the multi-head attention mechanism to improve the accuracy of SER. We implemented an attention-based convolutional neural network(ACNN) model and conducted experiments on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) data set. The accuracy is improved to 76.18% (weighted accuracy, WA) and 76.36% (unweighted accuracy, UA). To the best of our knowledge, compared with the state-of-the-art result on this dataset (76.4% of WA and 70.1% of WA), we achieved a UA improvement of about 6% absolute while achieving a similar WA. Furthermore, We conducted empirical experiments by injecting speech data with 50 types of common noises. We inject the noises by altering the noise intensity, time-shifting the noises, and mixing different noise types, to identify their varied impacts on the SER accuracy and verify the robustness of our model. This work will also help researchers and engineers properly add their training data by using speech data with the appropriate types of noises to alleviate the problem of insufficient high-quality data.","",""
37,"A. Murphy, S. Muldoon, D. Baker, Adam Lastowka, Brittany C. Bennett, Muzhi Yang, D. Bassett","Structure, function, and control of the human musculoskeletal network",2018,"","","","",11,"2022-07-13 09:27:29","","10.1371/journal.pbio.2002811","","",,,,,37,9.25,5,7,4,"The human body is a complex organism, the gross mechanical properties of which are enabled by an interconnected musculoskeletal network controlled by the nervous system. The nature of musculoskeletal interconnection facilitates stability, voluntary movement, and robustness to injury. However, a fundamental understanding of this network and its control by neural systems has remained elusive. Here we address this gap in knowledge by utilizing medical databases and mathematical modeling to reveal the organizational structure, predicted function, and neural control of the musculoskeletal system. We constructed a highly simplified whole-body musculoskeletal network in which single muscles connect to multiple bones via both origin and insertion points. We demonstrated that, using this simplified model, a muscle’s role in this network could offer a theoretical prediction of the susceptibility of surrounding components to secondary injury. Finally, we illustrated that sets of muscles cluster into network communities that mimic the organization of control modules in primary motor cortex. This novel formalism for describing interactions between the muscular and skeletal systems serves as a foundation to develop and test therapeutic responses to injury, inspiring future advances in clinical treatments.","",""
2,"Pingchuan Ma, Shuai Wang","MT-Teql: Evaluating and Augmenting Neural NLIDB on Real-world Linguistic and Schema Variations",2021,"","","","",12,"2022-07-13 09:27:29","","10.14778/3494124.3494139","","",,,,,2,2.00,1,2,1,"  Natural Language Interface to Database (NLIDB) translates human utterances into SQL queries and enables database interactions for non-expert users. Recently, neural network models have become a major approach to implementing NLIDB. However, neural NLIDB faces challenges due to variations in natural language and database schema design. For instance, one user intent or database conceptual model can be expressed in  various forms.  However, existing benchmarks, using hold-out datasets, cannot provide thorough understanding of how good neural NLIDBs really are in real-world situations and its robustness against such variations. A key difficulty is to annotate SQL queries for inputs under real-world variations, requiring considerable manual effort and expert knowledge.    To systematically assess the robustness of neural NLIDBs without extensive manual effort, we propose MT-Teql, a unified framework to benchmark NLIDBs against real-world language and schema variations. Inspired by recent advances in DBMS metamorphic testing, MT-Teql implements semantics-preserving transformations on utterances and database schemas to generate their variants. NLIDBs can thus be examined for robustness utilizing utterances/schemas and their variants without requiring manual intervention.  We benchmarked nine neural NLIDBs using 62,430 inputs and identified 15,433 defects. We analyzed potential root causes of defects and conducted a user study to show how MT-Teql can assist developers to systematically assess NLIDBs. We further show that the transformed (error-triggering) inputs can be used to augment popular NLIDBs and eliminate 46.5%(±5.0%) errors made by them without compromising their accuracy on standard benchmarks. We summarize lessons from this study that can provide insights to select and design NLIDBs that fit particular usage scenarios.","",""
9,"Ankeeta R. Patel, M. Joshi","Heart diseases diagnosis using neural network",2013,"","","","",13,"2022-07-13 09:27:29","","10.1109/ICCCNT.2013.6726740","","",,,,,9,1.00,5,2,9,"Neural network based systems have been used in past years in medical diagnosis applications because of their ability to learn human expertise and to utilize this knowledge for segregation. In this paper, neural based system is developed for heart diseases classification. The proposed system transforms sensor inputs to stroke stage classification. Multi layer feed forward network with back propagation learning algorithm is used. With a view to ascertain the efficacy of proposed system, performance is compared to other neural (system) based approaches. Simulation results show robustness of proposed system in all kind of test data given.","",""
1,"Wenlu Zhang, Lusi Li, Vincent Cheong, Bo Fu, Mehrdad Aliasgari","Deep Encoder-Decoder Neural Networks for Retinal Blood Vessels Dense Prediction",2021,"","","","",14,"2022-07-13 09:27:29","","10.2991/ijcis.d.210308.001","","",,,,,1,1.00,0,5,1,"Automatic segmentation of retinal blood vessels from fundus images is of great importance in assessing the condition of vascular network in human eyes. The task is primary challenging due to the low contrast of images, the variety of vessels and potential pathology. Previous studies have proposed shallow machine learning based methods to tackle the problem. However, these methods require specific domain knowledge, and the efficiency and robustness of these methods are not satisfactory for medical diagnosis. In recent years, deep learning models have made great progress in various segmentation tasks. In particular, Fully Convolutional Network and U-net have achieved promising results in end-to-end dense prediction tasks. In this study, we propose a novel encoder-decoder architecture based on the vanilla U-net architecture for retinal blood vessels segmentation. The proposed deep learning architecture integrates hybrid dilation convolutions and pixel transposed convolutions in the encoderdecoder model. Such design enables global dense feature extraction and resolves the common “gridding” and “checkerboard” issues in the regular U-net. Furthermore, the proposed network can be efficiently and directly implemented for any semantic segmentation applications. We evaluate the proposed network on two retinal blood vessels data sets. The experimental results show that our proposed model outperforms the baseline U-net model.","",""
0,"Fabrizio Russo, F. Toni","Causal Discovery and Injection for Feed-Forward Neural Networks",2022,"","","","",15,"2022-07-13 09:27:29","","10.48550/arXiv.2205.09787","","",,,,,0,0.00,0,2,1,"Neural networks have proven to be eective at solving a wide range of problems but it is often unclear whether they learn any meaningful causal relationship: this poses a problem for the robustness of neural network models and their use for high-stakes decisions. We propose a novel method overcoming this issue by injecting knowledge in the form of (possibly partial) causal graphs into feed-forward neural networks, so that the learnt model is guaranteed to conform to the graph, hence adhering to expert knowledge. This knowledge may be given up-front or during the learning process, to improve the model through human-AI collaboration. We apply our method to synthetic and real (tabular) data showing that it is robust against noise and can improve causal discovery and prediction performance in low data regimes.","",""
3,"H. Abdelkawy, N. Ayari, A. Chibani, Y. Amirat, F. Attal","Spatio-Temporal Convolutional Networks and N-Ary Ontologies for Human Activity-Aware Robotic System",2021,"","","","",16,"2022-07-13 09:27:29","","10.1109/LRA.2020.3047780","","",,,,,3,3.00,1,5,1,"Endowing a companion robot with cognitive abilities to recognize human daily activities, in particular from body skeletons information, is a significant challenge, which needs complex and novel approaches. Recently, most of the proposed approaches exploit the hand-crafted features or the predefined traversal rules techniques to recognize human daily activities from skeleton information, which often lead to the deficit of robustness and generalization. In this work, a novel hybrid framework for human activity-aware robotic system is proposed. In the low-level, a novel Spatio-Temporal Joint based Convolutional Neural Network (STJ-CNN) is proposed to recognize human daily activities in the ambient environments. In the high-level, novel representation and inference services based on Narrative Knowledge Representation Language (NKRL) are proposed to represent and combine the detected human activities with the ambient events, and to infer the semantic context of the detected activity. Empirical experiments on real-world datasets have been conducted, besides an online demonstration created to validate the proposed approach. The final results show that the proposed approach outperforms the baseline models with a significant improvement up to 24% in terms of $F$-score on DAHLIA dataset.","",""
1,"Jichang Ma, Hui Xie, K. Song, Hao Liu","A Bayesian Driver Agent Model for Autonomous Vehicles System Based on Knowledge-Aware and Real-Time Data",2021,"","","","",17,"2022-07-13 09:27:29","","10.3390/s21020331","","",,,,,1,1.00,0,4,1,"A key research area in autonomous driving is how to model the driver’s decision-making behavior, due to the fact it is significant for a self-driving vehicles considering their traffic safety and efficiency. However, the uncertain characteristics of vehicle and pedestrian trajectories affect urban roads, which poses severe challenges to the cognitive understanding and decision-making of autonomous vehicle systems in terms of accuracy and robustness. To overcome the abovementioned problems, this paper proposes a Bayesian driver agent (BDA) model which is a vision-based autonomous vehicle system with learning and inference methods inspired by human driver’s cognitive psychology. Different from the end-to-end learning method and traditional rule-based methods, our approach breaks the driving system up into a scene recognition module and a decision inference module. The perception module, which is based on a multi-task learning neural network (CNN), takes a driver’s-view image as its input and predicts the traffic scene’s feature values. The decision module based on dynamic Bayesian network (DBN) then makes an inferred decision using the traffic scene’s feature values. To explore the validity of the Bayesian driver agent model, we performed experiments on a driving simulation platform. The BDA model can extract the scene feature values effectively and predict the probability distribution of the human driver’s decision-making process accurately based on inference. We take the lane changing scenario as an example to verify the model, the intraclass correlation coefficient (ICC) correlation between the BDA model and human driver’s decision process reached 0.984. This work suggests a research in scene perception and autonomous decision-making that may apply to autonomous vehicle system.","",""
0,"Hazem A. A. Nomer, A. W. Mohamed, A. Yousef","GSK-RL: Adaptive Gaining-sharing Knowledge algorithm using Reinforcement Learning",2021,"","","","",18,"2022-07-13 09:27:29","","10.1109/NILES53778.2021.9600551","","",,,,,0,0.00,0,3,1,"Meta-heuristics and nature inspired algorithms have been prominent solvers for highly complex, nonlinear and hard optimization problems. The Gaining-Sharing Knowledge algorithm (GSK) is a recently proposed nature-inspired algorithm, inspired by human and their tendency towards growth and gaining and sharing knowledge with others. The GSK algorithm have been applied to different optimization problems and proved robustness compared to other nature-inspired algorithms. The GSK algorithm has two main control parameters kfand kr which controls how much individuals gain and share knowledge with their common society and circles or what they inherit from their parents. GSK has no control parameter adaptation scheme, the kf and kr are fixed for all individuals. In this paper we introduce an adaptation technique for the GSK algorithm by learning those parameters during search procedure of the algorithm. The new algorithm is dubbed as GSK-RL. The parameter controller in GSK-RL is a neural network trained using actor critic methods for reinforcement learning. The GSK-RL is compared against original GSK algorithm with its default parameters on CEC 2017 test suite functions for dimensions 10 and 30. The GSK-RL performed well on 10 dimensional problems but the performance started to degrade on 30 dimensional problems and it showed unstable behaviour on some functions that the controller has never been trained on before. This paper concludes that neither the state of the search algorithm as described for the RL model nor the reward function has a critical role in designing an RL-based controller for parameters of the GSK, however the training functions and the collected trajectories are the most important factor in designing such a controller.","",""
66,"Z. Zheng, Pengyu Hong","Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks",2018,"","","","",19,"2022-07-13 09:27:29","","","","",,,,,66,16.50,33,2,4,"It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategy to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks.","",""
0,"Hung, Sheng-kai","A Ball-Beam Balance Control System Using Fuzzy-Neural Network Algorithm",2011,"","","","",20,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,2,11,"It is necessary to find the mathematic model of the plant when we design the controller by classical control theory. Hence, the controller’s control ability is related to the plant which can be described accurately or not. If we want to make up intelligent control, it is necessary to get the system’s characteristics. Learning is the first step to achieve intelligent control. From learning, it can reduce the uncertain factor which can influence the dynamic system. Fuzzy control theory uses linguistic information, and it can transform human being’s knowledge and experiments to control rules. It has the better robustness and fault tolerance. Artificial neural network mimics a human brain’s parallel calculation. It has learning capability and it can be applied to system identification and estimate. The control theory combining with fuzzy reasoning system and artificial neural network not only have neural network’s learning capability, but also can build knowledge by extracting information form fuzzy logic. Hence it makes up neural network’s drawback which is always treated like a “black box”. This study utilizes the reasoning and learning ability of Fuzzy-Neural rules, and we will use the Fuzzy inference method to transfer the control behavior which cannot be expressed clearly to linguistic Fuzzy rule with manual operation device. We will combine they with Neural Networks to establish a ball-beam balance control system which could assimilate human expertise with less rule and mathematics, and learning capability. Keyword: Fuzzy Inference, Fuzzy-Neural Rule, Ball-Beam Balance Control System. References [1] C.C. Lee, “Fuzzy logic in control systems: Fuzzy logic control Part I, II, ” IEEE Trans. Syst., Man, Cybern., vol. 20, pp. 404-435, Mar. 1990. [2] J. R. Layne, K. M. Passino, and S. Yurkovich, “Fuzzy learning control for antiskid braking systems,” IEEE Trans. Contr. Syst. Technol., vol. 1, pp. 122-129, June 1993. [3] C.L. Huang and C.Y. Hsieh, “A Neuro-Adaptive Variable Structure Control for Partially Unknown Nonlinear Dynamic System and Its Application.” IEEE Trans. Contr. Syst. Technol., vol. 10, no. 2, pp. 263-271, Mar. 2002. [4] T. Yamakawa, “A Fuzzy Inference Engine in Nonlinear Analog Mode and Its Application to a Fuzzy Logic Control,” IEEE Transactions on Neural Networks, vol. 4, pp. 496-522, May 1993. [5] J. Bezdek, “Fuzzy Models what are they, and why?,” IEEE Trans. on Fuzzy Systems, vol. 1, Feb. 1993. [6] B. Kosko and S. Isaku, “Fuzzy Logic,” Scientific American, July 1993. [7] P. J. Antsaklis and K. M. Passino, eds., An Introduction To Intelligent and Autonomous Control, ch. Fuzzy and Neural Control, pp. 213-236, Norwell Massachusetts: Kluwer Academic Publishers, 1993. [8] B.Kosko, Neural Networks and Fuzzy Systems: A Dynamical Approach to Machine Intelligence. Englewood Cliffs, NJ: Prentice Hall, 1991. [9] S. I. Gallant, Neural Networks Learning and Expect Systems. Cambridge, Massachusetts: A Bradford Book, MIT Press, 1993. [10] B. Shahian and M Hassul, Control System Design Using Matlab, ch. Ball-on-Beam Balancer, pp. 465-476. Englewood Cliffs, NJ: Prentice Hall, 1994. [11] J. A. Franklin and H. Benbrahim, “Ball Balancer,” IEEE Control System, pp. 21-24, Feb. 1994. [12] C.M. Higgins and R. M. Goodman, “Fuzzy Rule-Based Networks for Control,” IEEE Trans. on Fuzzy Systems, vol. 2,pp. 82-88, Feb 1994. [13] B. Kosko and S. Isaku, “Fuzzy Logic,” Scientific American, July 1993. [14] J. Bezdek, “Fuzzy Models what are they, and why?,” IEEE Trans. on Fuzzy Systems, vol. 1, Feb 1993. [15] K.C. Ng and M. M. Trivedi, “Fuzzy logic controller and real-time implementation of a ball balancing beam,” in Applications of Fuzzy Logic Technology II, (Orlandor, FL), Apr 1995. [16] C.-I. Kao Y.-H. Kuo and J.-J. Chen, “A Fuzzy Neural Network Model and Its Hardware implementation,” IEEE Trans. on Fuzzy Systems, Vol. 1, pp.171-183, Aug 1993. [17] H. K. Kwan and Y. Cai, “A Fuzzy Neural Network and its Application to Pattern Recognition,” IEEE Trans. on Fuzzy Systems, Vol. 2, Issue 3, pp. 185-193, August 1994. [18] C.-L. Chen and W.-C. Chen, “Fuzzy Controller Design by Using Neural Network Techniques,” IEEE Trans. on Fuzzy Systems, Vol. 2, pp. 235-244, Aug 1994. [19] K. Hirota and W. Pedrycz, “OR/AND Neuraon in Modeling Fuzzy Set Connectives,” IEEE Trans. on Fuzzy Systems, Vol. 2, pp. 151-161, May 1994. [20] E. H. Mamdani, “Applications of Fuzzy Algorithms for Simple Dynamic Plant,” Proc. IEEE, Vol. 121, No. 12, pp. 1585-1588, 1974. [21] E. H. Mamdani and S.Assilian, “An Experiment in Linguistic Sythesis with a Fuzzy Logic Controller,” Int. Journal of Man Machine Studies, Vol. 7, No. 1, pp. 1-13, 1975. [22] W. Z. Qiao and M. Mizumoto, “PID Type Fuzzy Controllers and Parameters Adaptive Method,” Fuzzy Sets and Systems, Vol.78, pp.23-35,1996. [23] F. L. Lewis and K. Liu, “Towards a Paradigm for Fuzzy Logic Control,” Automatica, Vol. 32, No. 2, pp. 167-181, 1996. [24] C. C. Lee, “Fuzzy Logic in Control Systems: Fuzzy Logic Controller – Part I, Part II”, IEEE Trans. on Systems, Man, and Cybernetics, Vol. 20 No. 2, pp. 404-433, 1990. [25] H. Ishibuchi and H. Tanaka, “Neural Networks That Learn from Fuzzy If-Then Rules”, IEEE Trans. on Fuzzy Systems, Vol. 1, pp. 85-87, May 1993. [26] J. X. R.M.H. Cheng and S. LeQuoc, “Neuromorphic controller for AGV steering,” in Proceedings of IEEE Int. Conf. on Robotics and Automation, (Nice, France), Vol. 3, pp. 2057-2062, May 1992. [27] K. C. Ng and M. M. Trivedi, ”A Neurao-Fuzzy Controller for Mobile Robot Navigation and Multirobot Convoying”, IEEE Trans. on System, Man, and Cybernetics, Vol.28, No. 6, pp. 829-840, December 1998. [28] H. Ishibuchi and H. Tanaka, ”Neural Networks That Learn from Fuzzy IF-Then Rules”, IEEE Trans. on Fuzzy Systems, Vol. 1, pp.85-87, May 1993. [29] J. X. R.M.H. Cheng and S. LeQuoc, “Neuromorphic controller for AGV steering,” in Proceedings of IEEE Int. Conf. on Robotics and Automation, Vol. 3, pp.2057-2062, May 1992. [30] Gabriel Omar Alvarez Zapata, Roberto Kawakami Harrop Galvao, and Takashi Yoneyama, “Extracting Fuzzy Control Rules from Experimental Human Operator Data”, IEEE Trans. on Systems, Man, and Cybernetics, Vol. 29, No. 3, pp. 398-406. June 1999. [31] Li-Xin Wang, and Jerry M. Mendel,“Generating Fuzzy Rule by Learning from Examples”, IEEE Trans. On Systems, Man, and Cybernetics, Vol.22, NO.6,November/December, pp. 1414-1427, 1992.","",""
13,"Markus Wulfmeier, Dushyant Rao, I. Posner","Incorporating Human Domain Knowledge into Large Scale Cost Function Learning",2016,"","","","",21,"2022-07-13 09:27:29","","","","",,,,,13,2.17,4,3,6,"Recent advances have shown the capability of Fully Convolutional Neural Networks (FCN) to model cost functions for motion planning in the context of learning driving preferences purely based on demonstration data from human drivers. While pure learning from demonstrations in the framework of Inverse Reinforcement Learning (IRL) is a promising approach, we can benefit from well informed human priors and incorporate them into the learning process. Our work achieves this by pretraining a model to regress to a manual cost function and refining it based on Maximum Entropy Deep Inverse Reinforcement Learning. When injecting prior knowledge as pretraining for the network, we achieve higher robustness, more visually distinct obstacle boundaries, and the ability to capture instances of obstacles that elude models that purely learn from demonstration data. Furthermore, by exploiting these human priors, the resulting model can more accurately handle corner cases that are scarcely seen in the demonstration data, such as stairs, slopes, and underpasses.","",""
1,"Nemir Al-Azzawi","Human Action Recognition based on Hybrid Deep Learning Model and Shearlet Transform",2020,"","","","",22,"2022-07-13 09:27:29","","10.1109/ICITEE49829.2020.9271687","","",,,,,1,0.50,1,1,2,"The hybrid deep learning model has become common in all recent studies dealing with machine vision and human action recognition. Most of the accuracy in revealing knowledge of machine vision is in extracting important features, including segmentation of the image. This paper proposes a new model for recognizing human actions from video sequences by integrating repetitive, gated recurrent neural networks across multiple scales with shearlet-based image segmentation extraction. Segmentations are the most critical information to distinguish human action. The feature extraction can impact the complexity of the calculation and the performance of the algorithm. The idea is to increase training robustness and improve segmentation through the use of the shearlet transform. Hence, the video classification based on a recurrent neural network and shearlet transform will work optimally. The proposed approach is evaluated on human activity videos using KTH, UCF-101, and UCF Sports Action datasets. The experimental results showed state-of-the-art performance in comparison to current methods. The average resulting classification accuracy is 95.1% for the KTH datasets. That was the optimal case in our proposed model reached.","",""
9,"Alexander Hanbo Li, A. Sethy","Knowledge Enhanced Attention for Robust Natural Language Inference",2019,"","","","",23,"2022-07-13 09:27:29","","","","",,,,,9,3.00,5,2,3,"Neural network models have been very successful at achieving high accuracy on natural language inference (NLI) tasks. However, as demonstrated in recent literature, when tested on some simple adversarial examples, most of the models suffer a significant drop in performance. This raises the concern about the robustness of NLI models. In this paper, we propose to make NLI models robust by incorporating external knowledge to the attention mechanism using a simple transformation. We apply the new attention to two popular types of NLI models: one is Transformer encoder, and the other is a decomposable model, and show that our method can significantly improve their robustness. Moreover, when combined with BERT pretraining, our method achieves the human-level performance on the adversarial SNLI data set.","",""
16,"N. Shamsuddin, M. Mustafa, S. Husin, M. Taib","Classification of heart sounds using a multilayer feed-forward neural network",2005,"","","","",24,"2022-07-13 09:27:29","","10.1109/ASENSE.2005.1564512","","",,,,,16,0.94,4,4,17,"Cardiovascular diseases are among chronic diseases that seriously threaten human health. Medical experts sometimes listen to heart sounds through auscultation system, either from stethoscope or PCG (phonocardiogram), as one of the ways in diagnosing cardiovascular diseases. The auscultation process is subjective and largely depends on the experience, skill, knowledge or hearing ability of the physician to interpret heart conditions. This paper examines heart valve-related diseases using a multilayer feed-forward neural network (MFNN). The heart sounds were digitally filtered with moving average filter, segmented with sliding window and then reduced to an arbitrary frame of 64 points. After that, it is pre-processed by fast Fourier transform prior to feeding into the neural network for classification. To check for network robustness, the heart sound samples were injected with different level of noise. A total of 55 types of sample data were generated and used for classification. The study produces a 100% correct classification of eleven heart-valve diseases.","",""
16,"Huijuan Yang, J. Patra, C. W. Chan","An artificial neural network-based scheme for robust watermarking of audio signals",2002,"","","","",25,"2022-07-13 09:27:29","","10.1109/ICASSP.2002.5743970","","",,,,,16,0.80,5,3,20,"Digital watermarking is a technique by which the author information is embedded into the host signal (text, audio, image or video) that is imperceptible to the human senses. In this paper, we present a novel scheme for watermarking on audio signals using artificial neural networks (ANNs). The ANN is used to estimate the watermark scaling factor (WSP) intelligently from the knowledge of host audio signal. The power spectrum of the watermark signal remains below the minimum masking threshold (MMT) of the host signal when these WSFs are used in the watermarking process. This not only ensures inaudibility of the watermark signal, but also improves the capacity and robustness of the watermarking process. Using one music signal, we have shown the robustness of the scheme under some attacks to the watermarked audio signal.","",""
0,"N. Shamsuddin, M. N. Mistafal, S. Husin","Classification ofHeartSoundsUsing aMultilayer Feed-forward Neural Network",2005,"","","","",26,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,3,17,"Cardiovascular diseases areamong chronic diseases thatseriously threaten human health. Medical experts sometimes listen toheart sounds through auscultation system, either from stethoscope orPCG(phonocardiogram), asoneof thewaysindiagnosing cardiovascular diseases. The auscultation process issubjective andlargely depends ontheexperience, skill, knowledge or hearing ability ofthephysician tointerpret heart conditions. Thispaper examines heart valve-related diseases using a Multilayer Feed-forward Neural Network (MFNN). Theheart sounds weredigitally filtered with Moving Average Filter, segmented with sliding windowandthenreduced toanarbitrary frame of64points. After that, itispre-processed by FastFourier Transform prior tofeeding intothe neural network forclassification. To checkfor network robustness, theheart soundsamples were injected with different level ofnoise. A total of55 types ofsample data weregenerated andusedfor classification. Thestudy produces a 100%correct classification ofeleven heart-valve diseases.","",""
5,"Artur Jordão, R. Kloss, W. R. Schwartz","Latent HyperNet: Exploring the Layers of Convolutional Neural Networks",2018,"","","","",27,"2022-07-13 09:27:29","","10.1109/IJCNN.2018.8489506","","",,,,,5,1.25,2,3,4,"Since Convolutional Neural Networks (ConvNets) are able to simultaneously learn features and classifiers to discriminate different categories of activities, recent works have employed ConvNets approaches to perform human activity recognition (HAR) based on wearable sensors, allowing the removal of expensive human work and expert knowledge. However, these approaches have their power of discrimination limited mainly by the large number of parameters that compose the network and the reduced number of samples available for training. Inspired by this, we propose an accurate and robust approach, referred to as Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and projects them, individually, onto a low dimensionality (latent) space. Then, these latent features are concatenated and presented to a classifier. To demonstrate the robustness and accuracy of the LHN, we evaluate it using four different network architectures in five publicly available HAR datasets based on wearable sensors, which vary in the sampling rate and number of activities. We experimentally demonstrate that the proposed LHN is able to capture rich information, improving the results regarding the original ConvNets. Furthermore, the method outperforms existing state-of-the-art methods, on average, by 5.1 percentage points.","",""
3,"Yu Wenxian, Lu Jun, Wu Jianhui, Guo Guirong","Fuzzy sets-based neural network for pattern understanding",1993,"","","","",28,"2022-07-13 09:27:29","","10.1109/TENCON.1993.320143","","",,,,,3,0.10,1,4,29,"A fuzzy classification process model and a rational neural network topology are suggested and studied. A new method of constructing membership functions is proposed by using a self-organizing feature map network, kernel estimation of the probability distribution, and a consistent transformation between probability and possibility. Sugeno's (1974) fuzzy integral is briefly reviewed. Then, an improved fuzzy integral, which is based on double set measures, is proposed. The corresponding classification neural network is underlined and analyzed. This fuzzy set-based neural network can combine fact-level information with knowledge-level information consistently, and its classification process is almost identical to the human cognitive process. The given test results show that simultaneously high levels of robustness and accuracy for radar ship classification have been reached by using the proposed fuzzy set-based neural network.<<ETX>>","",""
0,"C. Brunger","Artificial Neural Network Modeling of Damaged Aircraft",1994,"","","","",29,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,28,"Abstract : Aircraft design and control techniques rely on the proper modeling of the aircraft's equations of motion. Many of the variables used in these equations are aerodynamic coefficients which are obtained from scale models in wind tunnel tests. In order to model damaged aircraft, every aerodynamic coefficient must be determined for every possible damage mechanism in every flight condition. Designing a controller for a damaged aircraft is particularly burdensome because knowledge of the effect of each damage mechanism on the model is required before the controller can be designed. Also, a monitoring system must be employed to decide when and how much damage has occurred in order to re configure the controller. Recent advances in artificial intelligence have made parallel distributed processors (artificial neural networks) feasible. Modeled on the human brain, the artificial neural network's strength lies in its ability to generalize from a given model. This thesis examines the robustness of the artificial neural network as a model for damaged aircraft.","",""
38,"L. Mo, Fan Li, Yanjia Zhu, Anjie Huang","Human physical activity recognition based on computer vision with deep learning model",2016,"","","","",30,"2022-07-13 09:27:29","","10.1109/I2MTC.2016.7520541","","",,,,,38,6.33,10,4,6,"Human activity recognition is an active research area in the computer science because it is widely used in the fields of the security monitoring, health assessment, human machine interaction and other human related content searching. In this paper, a computer vision model based on the deep learning algorithm is proposed, which can recognize the human physical activity based on the skeleton data of the human body from the sensor of Microsoft Kinect. This model uses the human skeletons data from the CAD-60 dataset to recognize the human physical activity without using any prior knowledge. It can reduce the works on the stage of data preprocessing and feature extraction. It can also improve the generalization performance and robustness of the model, and give a better understanding of the human physical activity. Different tricks which can improve the performance of the neural networks, such as some regularization methods and other activation functions are tested. Finally, a convolutional neural network is used for the feature extraction, and a multilayer perceptron is used as the following classifier. The model can recognize twelve types of activities and the accuracy rate is 81.8%. It demonstrates that it is very effective to use the convolutional neural network to supervised learning and this model applies to human physical activity recognition.","",""
2,"Xueying Wang, Yudong Guo, Zhongqi Yang, Juyong Zhang","Prior-Guided Multi-View 3D Head Reconstruction",2021,"","","","",31,"2022-07-13 09:27:29","","10.1109/TMM.2021.3111485","","",,,,,2,2.00,1,4,1,"Recovery of a 3D head model including the complete face and hair regions is still a challenging problem in computer vision and graphics. In this paper, we consider this problem using only a few multi-view portrait images as input. Previous multi-view stereo methods that have been based, either on optimization strategies or deep learning techniques, suffer from low-frequency geometric structures such as unclear head structures and inaccurate reconstruction in hair regions. To tackle this problem, we propose a prior-guided implicit neural rendering network. Specifically, we model the head geometry with a learnable signed distance field (SDF) and optimize it via an implicit differentiable renderer with the guidance of some human head priors, including the facial prior knowledge, head semantic segmentation information and 2D hair orientation maps. The utilization of these priors can improve the reconstruction accuracy and robustness, leading to a high-quality integrated 3D head model. Extensive ablation studies and comparisons with state-of-the-art methods demonstrate that our method can generate high-fidelity 3D head geometries with the guidance of these priors.","",""
180,"Zhijun Li, Zhicong Huang, W. He, C. Su","Adaptive Impedance Control for an Upper Limb Robotic Exoskeleton Using Biological Signals",2017,"","","","",32,"2022-07-13 09:27:29","","10.1109/TIE.2016.2538741","","",,,,,180,36.00,45,4,5,"This paper presents adaptive impedance control of an upper limb robotic exoskeleton using biological signals. First, we develop a reference musculoskeletal model of the human upper limb and experimentally calibrate the model to match the operator's motion behavior. Then, the proposed novel impedance algorithm transfers stiffness from human operator through the surface electromyography (sEMG) signals, being utilized to design the optimal reference impedance model. Considering the unknown deadzone effects in the robot joints and the absence of the precise knowledge of the robot's dynamics, an adaptive neural network control incorporating with a high-gain observer is developed to approximate the deadzone effect and robot's dynamics and drive the robot tracking desired trajectories without velocity measurements. In order to verify the robustness of the proposed approach, the actual implementation has been performed using a real robotic exoskeleton and a human operator.","",""
18,"Tzu-Yang Chen, Pai-Wen Ting, Min-Yu Wu, L. Fu","Learning a deep network with spherical part model for 3D hand pose estimation",2017,"","","","",33,"2022-07-13 09:27:29","","10.1109/ICRA.2017.7989303","","",,,,,18,3.60,5,4,5,"3D hand pose estimation is a hot research topic in recent years. It's been widely used in many advanced applications for virtual reality and human-computer interaction, since it provides a natural interface for communication between human and cyberspace. Despite the fast development of this field, it is still a difficult task due to the various challenges. In this paper, we aim to build a 3D hand pose estimation system which can correctly detect human hands and accurately estimate its pose using depth images. To guarantee the robustness of our system, we design a hand model called spherical part model (SPM), and train a deep convolutional neural network using this model. Moreover, to reduce the influence of human's omissions, we use a data-driven approach to integrate them together. Our network can more accurately estimate hand pose based on prior knowledge of human hand. To demonstrate the superiority of our method, a complete experiment is conducted on two public and one self-built datasets. The results show that our system can detect human hands with average precision at almost 90% and the average error distance of the pose estimation is about 10 millimeters, and is better than the other state of the art works.","",""
0,"Tongzhou Mu, Kaixiang Lin, Fei Niu, G. Thattai","Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning",2022,"","","","",34,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,4,1,"We present a two-step hybrid reinforcement learning (RL) policy that is designed to generate interpretable and robust hierarchical policies on the RL problem with graph-based input. Unlike prior deep reinforcement learning policies parameterized by an end-to-end black-box graph neural network, our approach disentangles the decision-making process into two steps. The first step is a simplified classification problem that maps the graph input to an action group where all actions share a similar semantic meaning. The second step implements a sophisticated rule-miner that conducts explicit one-hop reasoning over the graph and identifies decisive edges in the graph input without the necessity of heavy domain knowledge. This two-step hybrid policy presents human-friendly interpretations and achieves better performance in terms of generalization and robustness. Extensive experimental studies on four levels of complex text-based games have demonstrated the superiority of the proposed method compared to the state-of-the-art.","",""
2,"Artur Jordão, R. Kloss, W. R. Schwartz","Latent hypernet: Exploring all Layers from Convolutional Neural Networks",2017,"","","","",35,"2022-07-13 09:27:29","","","","",,,,,2,0.40,1,3,5,"Since Convolutional Neural Networks (ConvNets) are able to simultaneously learn features and classifiers to discriminate different categories of activities, recent works have employed ConvNets approaches to perform human activity recognition (HAR) based on wearable sensors, allowing the removal of expensive human work and expert knowledge. However, these approaches have their power of discrimination limited mainly by the large number of parameters that compose the network and the reduced number of samples available for training. Inspired by this, we propose an accurate and robust approach, referred to as Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and projects them, individually, onto a low dimensionality space (latent). Then, these latent features are concatenated and presented to a classifier. To demonstrate the robustness and accuracy of the LHN, we evaluate it using four different networks architectures in five publicly available HAR datasets based on wearable sensors, which vary in the sampling rate and number of activities. Our experiments demonstrate that the proposed LHN is able to produce rich information, improving the results regarding the original ConvNets. Furthermore, the method outperforms existing state-of-the-art methods.","",""
14,"Haofeng Li, Guanbin Li, Yizhou Yu","ROSA: Robust Salient Object Detection Against Adversarial Attacks",2019,"","","","",36,"2022-07-13 09:27:29","","10.1109/TCYB.2019.2914099","","",,,,,14,4.67,5,3,3,"Recently, salient object detection has witnessed remarkable improvement owing to the deep convolutional neural networks which can harvest powerful features for images. In particular, the state-of-the-art salient object detection methods enjoy high accuracy and efficiency from fully convolutional network (FCN)-based frameworks which are trained from end to end and predict pixel-wise labels. However, such framework suffers from adversarial attacks which confuse neural networks via adding quasi-imperceptible noises to input images without changing the ground truth annotated by human subjects. To our knowledge, this paper is the first one that mounts successful adversarial attacks on salient object detection models and verifies that adversarial samples are effective on a wide range of existing methods. Furthermore, this paper proposes a novel end-to-end trainable framework to enhance the robustness for arbitrary FCN-based salient object detection models against adversarial attacks. The proposed framework adopts a novel idea that first introduces some new generic noise to destroy adversarial perturbations, and then learns to predict saliency maps for input images with the introduced noise. Specifically, our proposed method consists of a segment-wise shielding component, which preserves boundaries and destroys delicate adversarial noise patterns and a context-aware restoration component, which refines saliency maps through global contrast modeling. The experimental results suggest that our proposed framework improves the performance significantly for state-of-the-art models on a series of datasets.","",""
43,"Long Chen, Xuemin Hu, Wei Tian, Hong Wang, D. Cao, Feiyue Wang","Parallel planning: a new motion planning framework for autonomous driving",2019,"","","","",37,"2022-07-13 09:27:29","","10.1109/JAS.2018.7511186","","",,,,,43,14.33,7,6,3,"Motion planning is one of the most significant technologies for autonomous driving. To make motion planning models able to learn from the environment and to deal with emergency situations, a new motion planning framework called as “ parallel planning ” is proposed in this paper. In order to generate sufficient and various training samples, artificial traffic scenes are firstly constructed based on the knowledge from the reality. A deep planning model which combines a convolutional neural network ( CNN ) with the Long Short-Term Memory module ( LSTM ) is developed to make planning decisions in an end-to-end mode. This model can learn from both real and artificial traffic scenes and imitate the driving style of human drivers. Moreover, a parallel deep reinforcement learning approach is also presented to improve the robustness of planning model and reduce the error rate. To handle emergency situations, a hybrid generative model including a variational auto-encoder ( VAE ) and a generative adversarial network ( GAN ) is utilized to learn from virtual emergencies generated in artificial traffic scenes. While an autonomous vehicle is moving, the hybrid generative model generates multiple video clips in parallel, which correspond to different potential emergency scenarios. Simultaneously, the deep planning model makes planning decisions for both virtual and current real scenes. The final planning decision is determined by analysis of real observations. Leveraging the parallel planning approach, the planner is able to make rational decisions without heavy calculation burden when an emergency occurs.","",""
20,"Wei Wei, E. Huerta, B. Whitmore, Janice C. Lee, S. Hannon, R. Chandar, D. Dale, K. Larson, D. Thilker, L. Úbeda, M. Boquien, M. Chevance, J. Kruijssen, A. Schruba, G. Blanc, E. Congiu","Deep transfer learning for star cluster classification: I. application to the PHANGS–HST survey",2019,"","","","",38,"2022-07-13 09:27:29","","10.1093/mnras/staa325","","",,,,,20,6.67,2,16,3,"We present the results of a proof-of-concept experiment which demonstrates that deep learning can successfully be used for production-scale classification of compact star clusters detected in HST UV-optical imaging of nearby spiral galaxies in the PHANGS-HST survey. Given the relatively small and unbalanced nature of existing, human-labelled star cluster datasets, we transfer the knowledge of neural network models for real-object recognition to classify star clusters candidates into four morphological classes. We show that human classification is at the 66%:37%:40%:61% agreement level for the four classes considered. Our findings indicate that deep learning algorithms achieve 76%:63%:59%:70% for a star cluster sample within 4Mpc < D <10Mpc. We tested the robustness of our deep learning algorithms to generalize to different cluster images using the first data obtained by PHANGS-HST of NGC1559, which is more distant at D = 19Mpc, and found that deep learning produces classification accuracies 73%:42%:52%:67%. We furnish evidence for the robustness of these analyses by using two different neural network models for image classification, trained multiple times from the ground up to assess the variance and stability of our results. We quantified the importance of the NUV, U, B, V and I images for morphological classification with our deep learning models, and find that the V-band is the key contributor as human classifications are based on images taken in that filter. This work lays the foundations to automate classification for these objects at scale, and the creation of a standardized dataset.","",""
2,"Y. Qin, L. Mo, Jing Ye, Z. Du","Multi-channel features fitted 3D CNNs and LSTMs for human activity recognition",2016,"","","","",39,"2022-07-13 09:27:29","","10.1109/ICSENST.2016.7796232","","",,,,,2,0.33,1,4,6,"Human activity recognition has been widely used in many fields, especially in video surveillance and virtual reality, etc. The paper investigates a general feature combination method for a relatively new 3D CNNs and LSTMs fusion model in human activity recognition. All the features used in this combination method are from human activity videos without manually extracting features or any prior knowledge, and the model has good generalization performance. Through extracting multi-channel features of the motion optical flow vector, grayscale and body edge, putting them to 3D convolutional neural network, and processing time characteristics within Long-Short Term Memory neural network, the recognition rate of the model rises greatly. The experiment selects KTH dataset as the data source. The model based on RGB is used to compare with the model based on multi-channel features. It shows that multi-channel features can improve recognition accuracy rate obviously, and have great robustness in different scenes, which proves that it is an efficient feature combination method fitted 3D CNNs and LSTMs.","",""
32,"M. Vakalopoulou, G. Chassagnon, N. Bus, R. Marini, E. Zacharaki, M. Revel, N. Paragios","AtlasNet: Multi-atlas Non-linear Deep Networks for Medical Image Segmentation",2018,"","","","",40,"2022-07-13 09:27:29","","10.1007/978-3-030-00937-3_75","","",,,,,32,8.00,5,7,4,"","",""
17,"Ismael Abdulrahman, G. Radman","Wide-Area-Based Adaptive Neuro-Fuzzy SVC Controller for Damping Interarea Oscillations",2018,"","","","",41,"2022-07-13 09:27:29","","10.1109/CJECE.2018.2868754","","",,,,,17,4.25,9,2,4,"Low-frequency interarea oscillation is a major problem in interconnected power systems with weak tie-lines that causes several stability problems if not damped. Fuzzy logic controller can generate human knowledge-based control rules to solve complex nonlinear problems. Unlike a neural network, fuzzy systems cannot learn from data, and it takes a long time to modify the membership functions. The adaptive neuro-fuzzy inference system (ANFIS) is a robust and intelligent system that integrates the capabilities of fuzzy logic and neural networks with several advantages such as adaptability, robustness, rapidity, and flexibility. In this paper, an ANFIS-based controller is proposed for controlling the reactive power provided by static var compensator to damp interarea oscillations. The controller input is a remote signal provided by a wide-area measurement system, and it is calculated as the center-of-inertia difference of generator rotor speed deviations. Moreover, a proportional-plus-derivative time-delay compensator with adaptive parameters is added to the controller to reduce the influence of time delay. A two-area four-machine test system is used and simulated with a Simulink-based package developed for the work of this paper. The time-domain simulations and frequency response analysis demonstrate the capability of the proposed controller to effectively damp interarea oscillations, under a small- and large-scale disturbances and against a wide range of time delays and load uncertainty.","",""
1,"杨. Y. Yun, 岳柱 Yue Zhu","Human Body Target Recognition Under Occlusion Based on Fusion of Image Contour Moment and Harris Angular Points",2013,"","","","",42,"2022-07-13 09:27:29","","10.3788/YJYXS20132802.0273","","",,,,,1,0.11,1,2,9,"For the human object recognition under occlusion,the human characteristics description are vulnerably effected under occlusion,but the head and shoulder of the human body are less susceptible to the characteristics of the block,put forward a new method based on the human head and shoulder mixed contour features for human object recognition under occlusion.First,using background subtraction method to separate the human body from the complex background,and then using a priori knowledge of the human body to extract the head and shoulder parts,then the contour moment invariant and Harris angular points are extracted and fused into a mixed feature,finally put the mixed feature into BP neural network to recognize.The experiments show that the method has better robustness and higher recognition rate.","",""
0,"","Institutional Knowledge at Singapore Management University Towards effective content-based music retrieval with multiple acoustic feature composition",,"","","","",43,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,0,,"— In this paper, we present a new approach to con- structing music descriptors to support efﬁcient content-based music retrieval and classiﬁcation. The system applies multiple musical properties combined with a hybrid architecture based on principal component analysis (PCA) and a multilayer perceptron neural network. This architecture enables straightforward incorporation of multiple musical feature vectors, based on properties such as timbral texture, pitch, and rhythm structure, into a single low-dimensioned vector that is more effective for classiﬁcation than the larger individual feature vectors. The use of supervised training enables incorporation of human musical perception that further enhances the classiﬁcation process. We compare our approach with state of the art techniques and demonstrate its effectiveness on content-based music retrieval. In addition, exten-sive experimental study illustrates its effectiveness and robustness against various kinds of audio alteration.","",""
1,"Na Wang, Jingwen Yu, Lei Wang, Xiaomei Hao","Application of Intelligent Control in Medical Education",2019,"","","","",44,"2022-07-13 09:27:29","","10.1007/978-981-15-1468-5_157","","",,,,,1,0.33,0,4,3,"","",""
0,"Baole Wei, Min Yu, Kai Chen, Jianguo Jiang","Deep-BIF: Blind Image Forensics Based on Deep Learning",2019,"","","","",45,"2022-07-13 09:27:29","","10.1109/dsc47296.2019.8937712","","",,,,,0,0.00,0,4,3,"Digital images are widely used in all aspects of human society because of their intuitiveness, such as computer forensics and scientific research. Tampering digital images in special fields maliciously, may change the information contained therein, form false information, and cause harm to society. At present, most of the mainstream image forensics algorithms are limited by their dependence on image capture devices or lack of robustness to complex images. We hope to get rid of the above limitations by virtue of the excellent feature extraction ability of deep learning. In this work, we proposed a novel method for blind image forensics analysis based on convolutional neural networks named Deep-BIF. Furthermore, we integrated the rich models for steganalysis of digital images into our network, for the purpose of guiding network training progress with several artificial prior knowledge. We tested our method on CASIA v2.0 dataset and achieved 0.976 in terms of accuracy.","",""
2,"Yongsheng Zhao, Jun Wu, Yifeng Zhu, Hongxiang Yu, R. Xiong","A learning framework towards real-time detection and localization of a ball for robotic table tennis system",2017,"","","","",46,"2022-07-13 09:27:29","","10.1109/RCAR.2017.8311842","","",,,,,2,0.40,0,5,5,"As a real-time serving system interacting with a highly dynamic environment, robotic table tennis system has a high requirement against the accuracy and robustness of real-time detection and localization of a ping-pong ball. Relative to its size, the ball is a high speed flying-spinning object. The existing methods use general features such as color and shape to detect and localize the ball, which rigidly depends on the prior knowledge. Their performance is susceptible to the change of the environment, e.g., the light condition, the color of ball, and the disturbance of human players' presence in the image. In this paper, we propose a learning framework that trains a convolutional neural network to detect and localize a ball with high accuracy. It learns useful features from data directly without any prior knowledge. Therefore, the proposed method can effectively deal with the situation when the ball's color is changing in real-time. And it is more robust to the light condition and the disturbance of human players' presence. The effectiveness and accuracy of the method is verified using the collected data set, in comparison with the state-of-the-art method.","",""
4,"J. García, F. Maciá, A. Soriano, F. Flórez","A Multi-Agent System uses Artificial Neural Networks to Model the Biological Regulation of the Lower Urinary Tract",2002,"","","","",47,"2022-07-13 09:27:29","","","","",,,,,4,0.20,1,4,20,"The robustness that shows the biological regulation of the human lower urinary tract provides a suggestive paradigm for the artificial control. The biological regulator consists of a heterogeneous group of nervous centres that act cooperatively, in a distributed way. That regulation conforms a behaviour of several types (autonomous work or conscious one) and it reduces the consequences in situations of bad operation. Related to that system, we propose a model of the paradigm of heterogeneous and distributed control that can be found in biological systems. The objective is to artificially reproduce the benefits of robustness in order to use it in the control of natural systems and artificial devices. The distributed aspects have been obtained using multiple intelligent agents, each one of which represents one of the biological centres. The interaction pattern among agents provides a heuristic based on the OAM neural network (Orthogonal Associative Memory). The knowledge has been added to the system by training, using correct patterns of behaviour of the urinary tract and wrong behaviour patterns due to the inoperability in up to two of the agents (representing deficiencies in up to two nervous centres at the same time). The experiments show that the model is robust and it satisfies the expectations of providing a model of the regulator system that allows to break into fragments the problem, in simple modules with own entity each. Key-Words: Multi-Agent Systems, Distributed Artificial Intelligence, Neural Networks, Lower Urinary Tract.","",""
13,"S. Caselli, E. Faldella, B. Fringuelli, F. Zanichelli","A hybrid system for knowledge-based synthesis of robot grasps",1993,"","","","",48,"2022-07-13 09:27:29","","10.1109/IROS.1993.583849","","",,,,,13,0.45,3,4,29,"Addresses the grasp synthesis problem arising in task planning for robotic dextrous hands. For this purpose, a hybrid architecture is proposed, which relies on symbolic and subsymbolic computations to exploit heterogeneous sources of knowledge, such as practical experience learned through experiments with a real device, heuristic rules gained from human observation, geometric reasoning and, when applicable, analytical results. After a preliminary discussion of representation levels and techniques, this paper describes the design of a tool for selecting the feasible grasps of a robotic hand under various situations and for ranking them according to task-oriented criteria. The interaction of a rule-based expert system with a neural network-based classifier provides support to both explicit reasoning and direct learning from experience. The features taken into account by the tool are object geometry, hand kinematic capabilities, task requirements, (in terms of both accessibility and robustness) and workspace constraints.","",""
1,"Horng-Chang Yang","Multiresolution neural networks for image edge detection and restoration",1994,"","","","",49,"2022-07-13 09:27:29","","","","",,,,,1,0.04,1,1,28,"One of the methods for building an automatic visual system is to borrow the properties of the human visual system (HVS). Artificial neural networks are based on this doctrine and they have been applied to image processing and computer vision. This work focused on the plausibility of using a class of Hopfield neural networks for edge detection and image restoration.    To this end, a quadratic energy minimization framework is presented. Central to this framework are relaxation operations, which can be implemented using the class of Hopfield neural networks. The role of the uncertainty principle in vision is described, which imposes a limit on the simultaneous localisation in both class and position space. It is shown how a multiresolution approach allows the trade off between position and class resolution and ensures both robustness in noise and efficiency of computation. As edge detection and image restoration are ill-posed, some a priori knowledge is needed to regularize these problems. A multiresolution network is proposed to tackle the uncertainty problem and the regularization of these ill-posed image processing problems. For edge detection, orientation information is used to construct a compatibility function for the strength of the links of the proposed Hopfield neural network.    Edge detection 'results are presented for a number of synthetic and natural images which show that the iterative network gives robust results at low signal-to-noise ratios (0 dB) and is at least as good as many previous methods at capturing complex region shapes. For restoration, mean square error is used as the quadratic energy function of the Hopfield neural network. The results of the edge detection are used for adaptive restoration. Also shown are the results of restoration using the proposed iterative network framework.","",""
34,"Li-Chiu Chang, F. Chang, Ya-Hsin Tsai","Fuzzy exemplar‐based inference system for flood forecasting",2005,"","","","",50,"2022-07-13 09:27:29","","10.1029/2004WR003037","","",,,,,34,2.00,11,3,17,"Fuzzy inference systems have been successfully applied in numerous fields since they can effectively model human knowledge and adaptively make decision processes. In this paper we present an innovative fuzzy exemplar‐based inference system (FEIS) for flood forecasting. The FEIS is based on a fuzzy inference system, with its clustering ability enhanced through the Exemplar‐Aided Constructor of Hyper‐rectangles algorithm, which can effectively simulate human intelligence by learning from experience. The FEIS exhibits three important properties: knowledge extraction from numerical data, knowledge (rule) modeling, and fuzzy reasoning processes. The proposed model is employed to predict streamflow 1 hour ahead during flood events in the Lan‐Yang River, Taiwan. For the purpose of comparison the back propagation neural network (BPNN) is also performed. The results show that the FEIS model performs better than the BPNN. The FEIS provides a great learning ability, robustness, and high predictive accuracy for flood forecasting.","",""
19,"P. Koustoumpardis, N. Aspragathos","Fuzzy Logic Decision Mechanism Combined with a Neuro-Controller for Fabric Tension in Robotized Sewing Process",2003,"","","","",51,"2022-07-13 09:27:29","","10.1023/A:1022331830053","","",,,,,19,1.00,10,2,19,"","",""
6,"P. Kim","Improving handwritten numeral recognition using fuzzy logic",1997,"","","","",52,"2022-07-13 09:27:29","","10.1109/TENCON.1997.648263","","",,,,,6,0.24,6,1,25,"The author presents an improved method of handwritten numeral recognition using fuzzy logic. In handwritten numeral recognition, most recognition errors are found in confusing samples. To represent confusing features and improve recognition rates, he groups confusing numerals into confusion groups and builds fuzzy functions applying human knowledge. To use small and delicate features of numerals, he structurally represents a numeral as a sequence of primitive strokes and feature points. To compensate weaknesses of the structural method, he also uses a neural network method. Experimental results on collected test samples show the efficiency and robustness of the proposed method.","",""
27,"Masahiro Mitsuhara, Hiroshi Fukui, Yusuke Sakashita, Takanori Ogata, Tsubasa Hirakawa, Takayoshi Yamashita, H. Fujiyoshi","Embedding Human Knowledge in Deep Neural Network via Attention Map",2019,"","","","",53,"2022-07-13 09:27:29","","10.5220/0010335806260636","","",,,,,27,9.00,4,7,3,"In this work, we aim to realize a method for embedding human knowledge into deep neural networks. While the conventional method to embed human knowledge has been applied for non-deep machine learning, it is challenging to apply it for deep learning models due to the enormous number of model parameters. To tackle this problem, we focus on the attention mechanism of an attention branch network (ABN). In this paper, we propose a fine-tuning method that utilizes a single-channel attention map which is manually edited by a human expert. Our fine-tuning method can train a network so that the output attention map corresponds to the edited ones. As a result, the fine-tuned network can output an attention map that takes into account human knowledge. Experimental results with ImageNet, CUB-200-2010, and IDRiD demonstrate that it is possible to obtain a clear attention map for a visual explanation and improve the classification performance. Our findings can be a novel framework for optimizing networks through human intuitive editing via a visual interface and suggest new possibilities for human-machine cooperation in addition to the improvement of visual explanations.","",""
5985,"David Silver, Julian Schrittwieser, K. Simonyan, Ioannis Antonoglou, Aja Huang, A. Guez, T. Hubert, Lucas baker, Matthew Lai, A. Bolton, Yutian Chen, T. Lillicrap, Fan Hui, L. Sifre, George van den Driessche, T. Graepel, D. Hassabis","Mastering the game of Go without human knowledge",2017,"","","","",54,"2022-07-13 09:27:29","","10.1038/nature24270","","",,,,,5985,1197.00,599,17,5,"","",""
5,"Hang Su, Wen Qi, Zhijun Li, Ziyang Chen, G. Ferrigno, E. Momi","Deep Neural Network Approach in EMG-Based Force Estimation for Human–Robot Interaction",2021,"","","","",55,"2022-07-13 09:27:29","","10.1109/TAI.2021.3066565","","",,,,,5,5.00,1,6,1,"In the human–robot interaction, especially when hand contact appears directly on the robot arm, the dynamics of the human arm presents an essential component in human–robot interaction and object manipulation. Modeling and estimation of the human arm dynamics show great potential for achieving more natural and safer interaction. To enrich the dexterity and guarantee the accuracy of the manipulation, mapping the motor functionality of muscle using biosignals becomes a popular topic. In this article, a novel algorithm was constructed using deep learning to explore the potential model between surface electromyography (sEMG) signals of the human arm and interaction force for human–robot interaction. Its features were extracted by adopting the convolutional neural network from the sEMG signals automatically without using prior knowledge of the biomechanical model. The experiments prove the lower error ($< \text{0.4}\,N$) of the designed regression by comparing it with other approaches, such as artificial neural network and long short-term memory. It should be also mentioned that the antinoise ability is an important index to apply this technique in practical applications. Hence, we also add different Gaussian noises into the dataset to demonstrate the robustness against measurement noises by using the proposed model. Finally, it demonstrates the performance of the proposed algorithm using the Myo controller and KUKA LWR4+ robot.","",""
1,"Peng Lu, Yang Gao, Hao Xi, Yabin Zhang, Chao Gao, Bing Zhou, Hongpo Zhang, Liwei Chen, Xiaobo Mao","KecNet: A Light Neural Network for Arrhythmia Classification Based on Knowledge Reinforcement",2021,"","","","",56,"2022-07-13 09:27:29","","10.1155/2021/6684954","","",,,,,1,1.00,0,9,1,"Acquiring electrocardiographic (ECG) signals and performing arrhythmia classification in mobile device scenarios have the advantages of short response time, almost no network bandwidth consumption, and human resource savings. In recent years, deep neural networks have become a popular method to efficiently and accurately simulate nonlinear patterns of ECG data in a data-driven manner but require more resources. Therefore, it is crucial to design deep learning (DL) algorithms that are more suitable for resource-constrained mobile devices. In this paper, KecNet, a lightweight neural network construction scheme based on domain knowledge, is proposed to model ECG data by effectively leveraging signal analysis and medical knowledge. To evaluate the performance of KecNet, we use the Association for the Advancement of Medical Instrumentation (AAMI) protocol and the MIT-BIH arrhythmia database to classify five arrhythmia categories. The result shows that the ACC, SEN, and PRE achieve 99.31%, 99.45%, and 98.78%, respectively. In addition, it also possesses high robustness to noisy environments, low memory usage, and physical interpretability advantages. Benefiting from these advantages, KecNet can be applied in practice, especially wearable and lightweight mobile devices for arrhythmia classification.","",""
2,"Yang Lou, Yaodong He, Lin Wang, K. Tsang, Guanrong Chen","Knowledge-Based Prediction of Network Controllability Robustness",2020,"","","","",57,"2022-07-13 09:27:29","","10.1109/TNNLS.2021.3071367","","",,,,,2,1.00,0,5,2,"Network controllability robustness (CR) reflects how well a networked system can maintain its controllability against destructive attacks. Its measure is quantified by a sequence of values that record the remaining controllability of the network after a sequence of node-removal or edge-removal attacks. Traditionally, the CR is determined by attack simulations, which is computationally time-consuming or even infeasible. In this article, an improved method for predicting the network CR is developed based on machine learning using a group of convolutional neural networks (CNNs). In this scheme, a number of training data generated by simulations are used to train the group of CNNs for classification and prediction, respectively. Extensive experimental studies are carried out, which demonstrate that 1) the proposed method predicts more precisely than the classical single-CNN predictor; 2) the proposed CNN-based predictor provides a better predictive measure than the traditional spectral measures and network heterogeneity.","",""
6,"Xueyuan She, Yun Long, S. Mukhopadhyay","Improving Robustness of ReRAM-based Spiking Neural Network Accelerator with Stochastic Spike-timing-dependent-plasticity",2019,"","","","",58,"2022-07-13 09:27:29","","10.1109/IJCNN.2019.8851825","","",,,,,6,2.00,2,3,3,"Spike-timing-dependent-plasticity (STDP) is an unsupervised learning algorithm for spiking neural network (SNN), which promises to achieve deeper understanding of human brain and more powerful artificial intelligence. While conventional computing system fails to simulate SNN efficiently, process-inmemory (PIM) based on devices such as ReRAM can be used in designing fast and efficient STDP based SNN accelerators, as it operates in high resemblance with biological neural network. However, the real-life implementation of such design still suffers from impact of input noise and device variation. In this work, we present a novel stochastic STDP algorithm that uses spiking frequency information to dynamically adjust synaptic behavior. The algorithm is tested in pattern recognition task with noisy input and shows accuracy improvement over deterministic STDP. In addition, we show that the new algorithm can be used for designing a robust ReRAM based SNN accelerator that has strong resilience to device variation.","",""
0,"Bing Liu, G. Qi, Lu Pan, Shangfu Duan, Tianxing Wu","Incorporating Human Knowledge in Neural Relation Extraction with Reinforcement Learning",2019,"","","","",59,"2022-07-13 09:27:29","","10.1109/IJCNN.2019.8852431","","",,,,,0,0.00,0,5,3,"Relation Extraction (RE) aims at extracting semantic relation of entities from text and it is a crucial task in natural language processing. Deep neural network (DNN) based models have achieved excellent performance in RE. However, they still have several problems remaining to be addressed: (1) humans can hardly take measures to amend the DNN-based RE systems because it is difficult to encode human intention to guide them to capture desired patterns. (2) DNN-based RE models may suffer from not having sufficient background information for making predictions. To handle these issues, we propose an RE framework based on reinforcement learning, which can enhance existing DNN-based RE models by incorporating human knowledge including soft rules and relation evidence. The introduction of soft rules enable human to impose an effect on the RE result and correct the RE system, while the relation evidence help supplement the background information without limiting its types and sources. The experimental results show that our approach can reinforce existing DNN-based RE models effectively and outperforms state-of-the-art RE methods.","",""
22,"Bo Li, Cheng Han, Baoxing Bai","Hybrid approach for human posture recognition using anthropometry and BP neural network based on Kinect V2",2019,"","","","",60,"2022-07-13 09:27:29","","10.1186/S13640-018-0393-4","","",,,,,22,7.33,7,3,3,"","",""
3,"Artur Petrosyan, M. Sinkin, M. Lebedev, A. Ossadtchi","Decoding and interpreting cortical signals with a compact convolutional neural network",2021,"","","","",61,"2022-07-13 09:27:29","","10.1088/1741-2552/abe20e","","",,,,,3,3.00,1,4,1,"Objective. Brain–computer interfaces (BCIs) decode information from neural activity and send it to external devices. The use of Deep Learning approaches for decoding allows for automatic feature engineering within the specific decoding task. Physiologically plausible interpretation of the network parameters ensures the robustness of the learned decision rules and opens the exciting opportunity for automatic knowledge discovery. Approach. We describe a compact convolutional network-based architecture for adaptive decoding of electrocorticographic (ECoG) data into finger kinematics. We also propose a novel theoretically justified approach to interpreting the spatial and temporal weights in the architectures that combine adaptation in both space and time. The obtained spatial and frequency patterns characterizing the neuronal populations pivotal to the specific decoding task can then be interpreted by fitting appropriate spatial and dynamical models. Main results. We first tested our solution using realistic Monte-Carlo simulations. Then, when applied to the ECoG data from Berlin BCI competition IV dataset, our architecture performed comparably to the competition winners without requiring explicit feature engineering. Using the proposed approach to the network weights interpretation we could unravel the spatial and the spectral patterns of the neuronal processes underlying the successful decoding of finger kinematics from an ECoG dataset. Finally we have also applied the entire pipeline to the analysis of a 32-channel EEG motor-imagery dataset and observed physiologically plausible patterns specific to the task. Significance. We described a compact and interpretable CNN architecture derived from the basic principles and encompassing the knowledge in the field of neural electrophysiology. For the first time in the context of such multibranch architectures with factorized spatial and temporal processing we presented theoretically justified weights interpretation rules. We verified our recipes using simulations and real data and demonstrated that the proposed solution offers a good decoder and a tool for investigating motor control neural mechanisms.","",""
9,"A. Bhandare, D. Kaur","Designing Convolutional Neural Network Architecture Using Genetic Algorithms",2021,"","","","",62,"2022-07-13 09:27:29","","10.21307/ijanmc-2021-024","","",,,,,9,9.00,5,2,1,"Abstract In this paper, genetic algorithm (GA) is used to optimally determine the architecture of a convolutional neural network (CNN) that is used to classify handwritten numbers. The CNN is a class of deep feed-forward network, which have seen major success in the field of visual image analysis. During training, a good CNN architecture is capable of extracting complex features from the given training data; however, at present, there is no standard way to determine the architecture of a CNN. Domain knowledge and human expertise are required in order to design a CNN architecture. Typically architectures, The GA determine the exact architecture of a CNN by evolving the various hyper parameters of the architecture for a given application. The proposed method was tested on the MNIST dataset. The results show that the genetic algorithm is capable of generating successful CNN architectures. The proposed method performs the entire process of architecture generation without any human intervention.","",""
4,"N. Jain, Vedika Gupta, Shubham Shubham, Agam Madan, Ankit Chaudhary, K. Santosh","Understanding cartoon emotion using integrated deep neural network on large dataset",2021,"","","","",63,"2022-07-13 09:27:29","","10.1007/s00521-021-06003-9","","",,,,,4,4.00,1,6,1,"","",""
1,"Ke Ding, Tsukasa Kimura, Ken-ichi Fukui, M. Numao","EEG emotion Enhancement using Task-specific Domain Adversarial Neural Network",2021,"","","","",64,"2022-07-13 09:27:29","","10.1109/IJCNN52387.2021.9533310","","",,,,,1,1.00,0,4,1,"Electroencephalogram (EEG) signal has been widely applied in detecting human emotion. Individual differences limit the generalization in cross-subject classification since the release of emotion will be definitely different across persons even with the same emotion stimuli. Previous research utilizes domain adaptation to solve this problem in a leave-one-subject-out training that is learning common emotion-related features from many subjects and testing on a new subject, which requires abundant labeled data. This paper proposed a novel one-to-one domain adaptation method, the Task-specific Domain Adversarial Neural Network (T-DANN) which transfers knowledge from either one subject to predict on another subject or knowledge from one phase to predict on another phase within the same subject. Therefore, T-DANN is more flexible and requires much less data during training. T-DANN is an adversarial training method which adapts the conditional distribution between domains and adapts classification boundaries between classes simultaneously. Compared with data from different subjects, phase data from the same subject has much deeper correlation thus enhances the prediction of emotion in new phase. We evaluated our method on EEG emotion benchmark dataset SEED. The experiments showed that our proposed method outperformed other baseline methods in cross-subject adaptation. By cross-phase adaptation, our method achieved accuracy that approximately 3% lower than the state-of-the-art method but only used 1/14 labeled data, indicating the priority of our proposed method in real-time application.","",""
1,"Guanzhong Tian, Jun Chen, Xianfang Zeng, Yong Liu","Pruning by Training: A Novel Deep Neural Network Compression Framework for Image Processing",2021,"","","","",65,"2022-07-13 09:27:29","","10.1109/LSP.2021.3054315","","",,,,,1,1.00,0,4,1,"Filter pruning for a pre-trained convolutional neural network is most normally performed through human-made constraints or criteria such as norms, ranks, etc. Typically, the pruning pipeline comprises two-stage: first learn a sparse structure from the original model, then optimize the weights in the new prune model. One disadvantage of using human-made criteria to prune filters is that the design and selection of threshold criteria depend on complicated prior knowledge. Besides, the pruning process is less robust due to the impact of directly regularizing on filters. To address the problems mentioned, we propose an effective one-stage pruning framework: introducing a trainable collaborative layer to jointly prune and learn neural networks in one go. In our framework, we first add a binary collaborative layer for each original filter. Then, a new type of gradient estimator - asymptotic gradient estimator is first introduced to pass the gradient in the binary collaborative layer. Finally, we simultaneously learn the sparse structure and optimize the weights from the original model in the training process. Our evaluation results on typical benchmarks, CIFAR and ImageNet, demonstrate very promising results against other state-of-the-art filter pruning methods.","",""
49,"Ying Shen, Yang Deng, Min Yang, Yaliang Li, Nan Du, Wei Fan, Kai Lei","Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs",2018,"","","","",66,"2022-07-13 09:27:29","","10.1145/3209978.3210081","","",,,,,49,12.25,7,7,4,"Ranking question answer pairs has attracted increasing attention recently due to its broad applications such as information retrieval and question answering (QA). Significant progresses have been made by deep neural networks. However, background information and hidden relations beyond the context, which play crucial roles in human text comprehension, have received little attention in recent deep neural networks that achieve the state of the art in ranking QA pairs. In the paper, we propose KABLSTM, a Knowledge-aware Attentive Bidirectional Long Short-Term Memory, which leverages external knowledge from knowledge graphs (KG) to enrich the representational learning of QA sentences. Specifically, we develop a context-knowledge interactive learning architecture, in which a context-guided attentive convolutional neural network (CNN) is designed to integrate knowledge embeddings into sentence representations. Besides, a knowledge-aware attention mechanism is presented to attend interrelations between each segments of QA pairs. KABLSTM is evaluated on two widely-used benchmark QA datasets: WikiQA and TREC QA. Experiment results demonstrate that KABLSTM has robust superiority over competitors and sets state-of-the-art.","",""
3,"Yuxuan Zhao, Jin Yang, Jinlong Lin, Dunshan Yu, Xixin Cao","A 3D Convolutional Neural Network for Emotion Recognition based on EEG Signals",2020,"","","","",67,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207420","","",,,,,3,1.50,1,5,2,"As an important field of research in Human-Machine Interactions, emotion recognition based on the electroencephalography (EEG) signals has become common research. The traditional machine learning approaches use well-designed classifiers with hand-crafted features which may be limited to domain knowledge. Motivated by the outstanding performance of deep learning approaches in recognition tasks, we proposed a 3D convolutional neural network model to extract the spatial-temporal features automatically in the EEG signals. By the pre-processing method with baseline signals and the electrode topological structure relocated, the proposed model achieves a high accuracy rate of 96.61%, 96.43% in the Two class classification task (low/high arousal, low/high valence) and 93.53% in the Four class classification task (low arousal and low valence/high arousal and low valence/low arousal and high valence/high arousal and high valence) in the DEAP dataset, and 97.52%, 96.96% in the Two class classification task and 95.86% in the Four class classification task in the AMIGOS dataset.","",""
2,"Dongcheng Zhao, Yang Li, Yi Zeng, Jihang Wang, Qian Zhang","Spiking CapsNet: A Spiking Neural Network With A Biologically Plausible Routing Rule Between Capsules",2021,"","","","",68,"2022-07-13 09:27:29","","","","",,,,,2,2.00,0,5,1,"Spiking neural network (SNN) has attracted much attention due to their powerful spatio-temporal information representation ability. Capsule Neural Network (CapsNet) does well in assembling and coupling features at different levels. Here, we propose Spiking CapsNet by introducing the capsules into the modelling of spiking neural networks. In addition, we propose a more biologically plausible Spike Timing Dependent Plasticity routing mechanism. By fully considering the spatio-temporal relationship between the lowlevel spiking capsules and the high-level spiking capsules, the coupling ability between them is further improved. We have verified experiments on the MNIST and FashionMNIST datasets. Compared with other excellent SNN models, our algorithm still achieves high performance. Our Spiking CapsNet fully combines the strengthens of SNN and CapsNet, and shows strong robustness to noise and affine transformation. By adding different Salt-Pepper and Gaussian noise to the test dataset, the experimental results demonstrate that our Spiking CapsNet shows a more robust performance when there is more noise, while the artificial neural network can not correctly clarify. As well, our Spiking CapsNet shows strong generalization to affine transformation on the AffNIST dataset. Introduction Convolutional Neural Networks (CNNs) have obtained tremendous success in various domains, such as object classification (He et al. 2016), visual tracking (Danelljan et al. 2015), object segmentation (Chen et al. 2017), and so on due to the powerful feature representation ability. However, there still exist several limitations associated with CNNs. First, high-level features are obtained by low-level weighting features while ignoring the spatial relationship between them. A face is just a simple combination of the features of eyes, nose, and mouth. Even if the positions of these features change relatively, the classifier will still consider it to be a face. Secondly, the commonly used pooling operation *These authors contributed equally. Corresponding Author. is destructive to the spatial relationship. To tackle the problems, CapsNet (Sabour, Frosst, and Hinton 2017; Hinton, Sabour, and Frosst 2018) proposes the concept of capsules, which uses the vector or matrix instead of values to encode the information. It uses a group of neurons to denote more properties. Each neuron provides a scalar output that represents the attributes of the corresponding feature, such as position, color, and texture. The length of the vector represents the probability of these properties. In addition to the capsule concept, the routing scheme is used to ensure the output of the lower-capsule to the closely related higher-capsule. Although CapsNet mimics the multi-layer visual system with a parse tree-like structure, it is still far from the human brain’s information processing mechanism. Considered as the third-generation artificial neural network, the spiking neural networks (SNNs) (Roy, Jaiswal, and Panda 2019; Kim et al. 2019; Thiele et al. 2019; Zhang et al. 2019b), use the discrete spikes to transfer information, which is more biologically plausible and more energy efficient. The SNNs present strong sparsity and neurons that do not emit spikes do not update the network weights. In recent years, SNNs have significantly facilitated the development of event-based neuromorphic hardware platforms(Pei et al. 2019), showing desired low latency and high efficiency. On the other hand, due to the spike encoding mechanism, the SNNs are very robust to the input disturbance and have shown excellent performance in terms of anti-noise(Cheng et al. 2020; Chowdhury, Lee, and Roy 2020; Zhang et al. 2019a; Li et al. 2020; Uysal, Sathyendra, and Harris 2007). Many traditional SNN structures are inspired by brain area connections to imitate certain brain area functions. Still, it is hard to expand to a deeper network structure due to its complex network connections (Zhao et al. 2020b; Zhao, Zeng, and Xu 2018; Fang, Zeng, and Zhao 2021). To carry out more complex tasks, the feedforward fully connected structure is introduced (Zhang et al. 2018; Sun, Zeng, and Zhang 2021) to transmit information in the form of a fully connected way. However, this connection method will cause excessive parameters and overfitting, which is difficult to extend to deeper neural networks and more complex tasks. To tackle the problems, ar X iv :2 11 1. 07 78 5v 1 [ cs .N E ] 1 5 N ov 2 02 1 GLSNN (Zhao et al. 2020a) introduces the feedback connections to transfer the global error to the hidden layers to get the corresponding target. Combining with the local synaptic plasticity learning rules, the performance and stability are further improved. Convolutional neural networks have attracted wide attention due to their superior feature extraction capabilities. Recent works (Wu et al. 2018, 2019; Jin, Zhang, and Li 2018; Zhang and Li 2020) introduce the convolutional structures into the modelling of SNNs. The parameter sharing mechanism of convolutions dramatically reduces the number of parameters and can further deepen the structure of the SNNs and improve the performance of complex tasks. LISNN (Cheng et al. 2020) further enhances the performance of the SNNs and their robustness to noise by introducing the lateral connections. BackEISNN (Zhao, Zeng, and Li 2021) has demonstrated superior performance on multiple datasets by introducing self-feedback connections and the excitatory-inhibitory neurons. However, these structures all use pooling operations to ensure translation invariance, leading to the spatial information loss. To tackle the problems mentioned above, we introduce the capsule structure in the spiking neural network, so as to take full advantage of the spatial and temporal characteristics. In the capsule neural network domains, much work is integrated into the modelling of routing mechanisms, which can be roughly divided into two categories, the supervised and the unsupervised. For the unsupervised ones, the dynamic routing (Sabour, Frosst, and Hinton 2017) uses the inner product to denote the agreement. Furthermore, the vector capsule is replaced with the matrix, and the modified EM-algorithm is used to model the agreement between capsules (Hinton, Sabour, and Frosst 2018). The group equivariant capsule networks (Lenssen, Fey, and Libuschewski 2018) present a generic routing by agreement algorithm defined on elements of a group. (Choi et al. 2019) proposes a fast forward pass routing with attention modules to keep spatial attention. Riberio et al. (Ribeiro, Leontidis, and Kollias 2020) propose a routing algorithm derived from Variational Bayes to fit a gaussian mixture model. In (Tsai et al. 2020)’s work, the routing procedure resembles an inverted attention algorithm. (Zhang et al. 2021) generalizes the existing routing methods within the framework of weighted kernel density estimation. Efficient-CapsNet (Mazzia, Salvetti, and Chiaberge 2021) replaces the dynamic routing with a novel noniterative, highly parallelizable self-attention routing. For the supervised ones, Wang et al. (Wang and Liu 2018) formulate the routing strategy as an optimization problem that minimizes the distance between the current coupling distribution and its last states. (Li et al. 2018) approximates the routing process with a master and an aide branch to communicate in a fast, supervised, and one-time pass fashion. G-CapsNet (Chen and Crandall 2018) embeds the routing procedure into the optimization procedure and makes the coefficients trainable. Self-Routing (Hahn, Pyeon, and Kim 2019) routes each capsule independently by its subordinate routing network. STAR-CAPS (Ahmed and Torresani 2019) designs a straight-through attentive routing by utilizing attention modules augmented by differentiable binary routers. GF-CapsNet (Ding et al. 2020) adopts a supervised group-routing to equally spilled capsules into groups to reduce routing parameters. Both the supervised and the unsupervised ones only consider the spatial relationship between capsules while ignoring the temporal relationship. This paper adopts the biologically plausible Spike Timing Dependent Plasticity (STDP) (Bi and Poo 1998; Diehl and Cook 2015) for dynamic routing between the spiking capsules, which fully considers the causal relationship between capsules and significantly improves routing efficiency. This paper proposes the Spiking CapsNet, which can combine the characteristics of the capsule neural network and the spiking neural network well. And our contributions can be summarized below. • To our best knowledge, this is the first work to introduce the capsule structures into the modelling of SNNs, which can combine their rich spatio-temporal information processing capabilities. • We introduce a more biological routing algorithm between the spiking capsules to optimize the relationship between capsules in both spatial and temporal domains. The routing algorithm fully considers the spatial relationship between the part and the whole and the causality of the spike sequences in temporal domains. • The experimental results show that our proposed Spiking CapsNet does well on the MNIST and FashionMNIST datasets compared with the current best SNN. It can achieve the best noise robustness under different SaltPepper noise intensities and different variance of Gaussian noise. As well as, it shows excellent generalization and invariance to affine-transformations. Methods This section will introduce the learning and inference process of our proposed Spiking CapsNet in detail. Firstly, we describe the spiking neuron model, followed by the description of the capsule operation process, which is very different from the traditional value-based operation. Then, we will give a detailed description of our STDP routing mechanism. Finally, the introduction of the whole Spiking CapsNet will be given. Spiking Neuron Model","",""
248,"Lukas Schott, Jonas Rauber, M. Bethge, Wieland Brendel","Towards the first adversarially robust neural network model on MNIST",2018,"","","","",69,"2022-07-13 09:27:29","","","","",,,,,248,62.00,62,4,4,"Despite much effort, deep neural networks remain highly susceptible to tiny input perturbations and even for MNIST, one of the most common toy datasets in computer vision, no neural network model exists for which adversarial perturbations are large and make semantic sense to humans. We show that even the widely recognized and by far most successful defense by Madry et al. (1) overfits on the L-infinity metric (it's highly susceptible to L2 and L0 perturbations), (2) classifies unrecognizable images with high certainty, (3) performs not much better than simple input binarization and (4) features adversarial perturbations that make little sense to humans. These results suggest that MNIST is far from being solved in terms of adversarial robustness. We present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. We derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness on MNIST against L0, L2 and L-infinity perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class.","",""
2,"K. B. Low, U. U. Sheikh","Human Re-identification with Global and Local Siamese Convolution Neural Network",2017,"","","","",70,"2022-07-13 09:27:29","","10.12928/TELKOMNIKA.V15I2.6121","","",,,,,2,0.40,1,2,5,"Human re-identification is an important task in surveillance system to determine whether the same human re-appears in multiple cameras with disjoint views. Mostly, appearance based approaches are used to perform human re-identification task because they are less constrained than biometric based approaches. Most of the research works apply hand-crafted feature extractors and then simple matching methods are used. However, designing a robust and stable feature requires expert knowledge and takes time to tune the features. In this paper, we propose a global and local structure of Siamese Convolution Neural Network which automatically extracts features from input images to perform human re-identification task. Besides, most of the current human re-identification task in single-shot approaches do not consider occlusion issue due to lack of tracking information. Therefore, we apply a decision fusion technique to combine global and local features for occlusion cases in single-shot approaches.","",""
1,"Nazanin Fouladgar, Marjan Alirezaie, Kary Främling","CN-waterfall: a deep convolutional neural network for multimodal physiological affect detection",2021,"","","","",71,"2022-07-13 09:27:29","","10.1007/s00521-021-06516-3","","",,,,,1,1.00,0,3,1,"","",""
0,"Soroush Mahjoubi, Fan Ye, Yi Bao, Weina Meng, Xian Zhang","Identification and classification of exfoliated graphene flakes from microscopy images using a hierarchical deep convolutional neural network",2022,"","","","",72,"2022-07-13 09:27:29","","10.48550/arXiv.2203.15252","","",,,,,0,0.00,0,5,1,"Identiﬁcation of the mechanically exfoliated graphene ﬂakes and classiﬁcation of the thickness is important in the nanomanufacturing of next-generation materials and devices that overcome the bottleneck of Moore’s Law. Currently, identiﬁcation and classiﬁcation of exfoliated graphene ﬂakes are conducted by human via inspecting the optical microscope images. The existing state-of-the-art automatic identiﬁcation by machine learning is not able to accommodate images with different backgrounds while different backgrounds are unavoidable in experiments. This paper presents a deep learning method to automatically identify and classify the thickness of exfoliated graphene ﬂakes on Si/SiO2 substrates from optical microscope images with various settings and background colors. The presented method uses a hierarchical deep convolutional neural network that is capable of learning new images while preserving the knowledge from previous images. The deep learning model was trained and used to classify exfoliated graphene ﬂakes into monolayer (1L), bi-layer (2L), tri-layer (3L), four-to-six-layer (4-6L), seven-to-ten-layer (7-10L), and bulk categories. Compared with existing machine learning methods, the presented method possesses high accuracy and efﬁciency as well as robustness to the backgrounds and resolutions of images. The results indicated that our deep learning model has accuracy as high as 99% in identifying and classifying exfoliated graphene ﬂakes. This research will shed light on scaled-up manufacturing and characterization of graphene for advanced materials and devices.","",""
5,"Ting-Bing Xu, Cheng-Lin Liu","Deep Neural Network Self-Distillation Exploiting Data Representation Invariance",2020,"","","","",73,"2022-07-13 09:27:29","","10.1109/TNNLS.2020.3027634","","",,,,,5,2.50,3,2,2,"To harvest small networks with high accuracies, most existing methods mainly utilize compression techniques such as low-rank decomposition and pruning to compress a trained large model into a small network or transfer knowledge from a powerful large model (teacher) to a small network (student). Despite their success in generating small models of high performance, the dependence of accompanying assistive models complicates the training process and increases memory and time cost. In this article, we propose an elegant self-distillation (SD) mechanism to obtain high-accuracy models directly without going through an assistive model. Inspired by the invariant recognition in the human vision system, different distorted instances of the same input should possess similar high-level data representations. Thus, we can learn data representation invariance between different distorted versions of the same sample. Especially, in our learning algorithm based on SD, the single network utilizes the maximum mean discrepancy metric to learn the global feature consistency and the Kullback–Leibler divergence to constrain the posterior class probability consistency across the different distorted branches. Extensive experiments on MNIST, CIFAR-10/100, and ImageNet data sets demonstrate that the proposed method can effectively reduce the generalization error for various network architectures, such as AlexNet, VGGNet, ResNet, Wide ResNet, and DenseNet, and outperform existing model distillation methods with little extra training efforts.","",""
3,"Hailin Wang, Ke Qin, R. Zakari, Guisong Liu, Guoming Lu","Deep neural network-based relation extraction: an overview",2021,"","","","",74,"2022-07-13 09:27:29","","10.1007/s00521-021-06667-3","","",,,,,3,3.00,1,5,1,"","",""
9,"Min Yang, Chengming Li, Ying Shen, Qingyao Wu, Zhou Zhao, Xiaojun Chen","Hierarchical Human-Like Deep Neural Networks for Abstractive Text Summarization",2020,"","","","",75,"2022-07-13 09:27:29","","10.1109/TNNLS.2020.3008037","","",,,,,9,4.50,2,6,2,"Developing an abstractive text summarization (ATS) system that is capable of generating concise, appropriate, and plausible summaries for the source documents is a long-term goal of artificial intelligence (AI). Recent advances in ATS are overwhelmingly contributed by deep learning techniques, which have taken the state-of-the-art of ATS to a new level. Despite the significant success of previous methods, generating high-quality and human-like abstractive summaries remains a challenge in practice. The human reading cognition, which is essential for reading comprehension and logical thinking, is still relatively new territory and underexplored in deep neural networks. In this article, we propose a novel Hierarchical Human-like deep neural network for ATS (HH-ATS), inspired by the process of how humans comprehend an article and write the corresponding summary. Specifically, HH-ATS is composed of three primary components (i.e., a knowledge-aware hierarchical attention module, a multitask learning module, and a dual discriminator generative adversarial network), which mimic the three stages of human reading cognition (i.e., rough reading, active reading, and postediting). Experimental results on two benchmark data sets (CNN/Daily Mail and Gigaword) demonstrate that HH-ATS consistently and substantially outperforms the compared methods.","",""
0,"","Neural Network Training Using Genetic Algorithms Series In Machine Perception And Artificial Intelligence",2021,"","","","",76,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,0,1,"Knowledge-Based Intelligent Information and Engineering Systems 2Nature-inspired Methods in Chemometrics: Genetic Algorithms and Artificial Neural NetworksParallel Implementations of Backpropagation Neural Networks on TransputersEvolutionary Algorithms and Neural NetworksTraining Neural Networks Using Hybrids with Genetic AlgorithmsNeural Network Training Using Genetic AlgorithmsGene Expression ProgrammingTraining a Neural Network with a Genetic AlgorithmMethods and Applications of Artificial IntelligenceClassification and Learning Using Genetic AlgorithmsPractical Computer Vision Applications Using Deep Learning with CNNsIntelligent Hybrid SystemsNeurogenetic LearningAdvances in Neural Networks ISNN 2007Hybrid Intelligent SystemsEncyclopedia of Computer Science and TechnologyMachine LearningUsing a Genetic Algorithm in Training an Artificial Neural Network to Implement the XOR FunctionGenetic and Evolutionary Computation — GECCO 2004Handbook of Fuzzy ComputationNeural Network Data Analysis Using SimulnetTMArtificial Neural Nets and Genetic AlgorithmsApplied Soft Computing Technologies: The Challenge of ComplexityGenetic Algorithm for Artificial Neural Network Training for the Purpose of Automated Part RecognitionNEURAL NETWORKS, FUZZY LOGIC AND GENETIC ALGORITHMAutomatic Generation of Neural Network Architecture Using Evolutionary ComputationPGANETThe Sixth International Symposium on Neural Networks (ISNN 2009)Evolutionary Machine Learning TechniquesModeling Decisions for Artificial IntelligenceEmpirical Studies on the Utility of Genetic Algorithms for Training and Designing of Neural NetworksTraining Neural Networks Using Genetic AlgorithmsTraining feedforward neural networks using genetic algorithmsMetaheuristic Procedures for Training Neural NetworksArtificial Neural Nets and Genetic AlgorithmsNature-Inspired Computing: Concepts, Methodologies, Tools, and ApplicationsApplications of Evolutionary ComputingArtificial Intelligence and CreativityArtificial Neural Nets and Genetic AlgorithmsDeep Learning Using Genetic Algorithms Creativity is one of the least understood aspects of intelligence and is often seen as `intuitive' and not susceptible to rational enquiry. Recently, however, there has been a resurgence of interest in the area, principally in artificial intelligence and cognitive science, but also in psychology, philosophy, computer science, logic, mathematics, sociology, and architecture and design. This volume brings this work together and provides an overview of this rapidly developing field. It addresses a range of issues. Can computers be creative? Can they help us to understand human creativity? How can artificial intelligence (AI) enhance human creativity? How, in particular, can it contribute to the `sciences of the artificial', such as design? Does the new wave of AI (connectionism, geneticism and artificial life) offer more promise in these areas than classical, symbol-handling AI? What would the implications be for AI and cognitive science if computers could not be creative? These issues are explored in five interrelated parts, each of which is introducted and explained by a leading figure in the field. Prologue (Margaret Boden) Part I: Foundational Issues (Terry Dartnall) Part II: Creativity and Cognition (Graeme S. Halford and Robert Levinson) Part III: Creativity and Connectionism (Chris Thornton) Part IV: Creativity and Design (John Gero) Part V: Human Creativity Enhancement (Ernest Edmonds) Epilogue (Douglas Hofstadter) For researchers in AI, cognitive science, computer science, philosophy, psychology, mathematics, logic, sociology, and architecture and design; and anyone interested in the rapidly growing field of artificial intelligence and creativity.From the contents: Neural networks – theory and applications: NNs (= neural networks) classifier on continuous data domains– quantum associative memory – a new class of neuron-like discrete filters to image processing – modular NNs for improving generalisation properties – presynaptic inhibition modelling for image processing application – NN recognition system for a curvature primal sketch – NN based nonlinear temporalspatial noise rejection system – relaxation rate for improving Hopfield network – Oja's NN and influence of the learning gain on its dynamics Genetic algorithms – theory and applications: transposition: a biological-inspired mechanism to use with GAs (= genetic algorithms) – GA for decision tree induction – optimising decision classifications using GAs – scheduling tasks with intertask communication onto multiprocessors by GAs – design of robust networks with GA – effect of degenerate coding on GAs – multiple traffic signal control using a GA – evolving musical harmonisation – niched-penalty approach for constraint handling in GAs – GA with dynamic population size – GA with dynamic niche clustering for multimodal function optimisation Soft computing and uncertainty: self-adaptation of evolutionary constructed decision trees by information spreading – evolutionary programming of near optimal NNsArtificial neural networks and genetic algorithms both are areas of research","",""
1,"E. R., D. Jain, K. Kotecha, Sharnil Pandya, Sai Siddhartha Reddy, R. E, V. Varadarajan, Aniket Mahanti, S. V","Hybrid Deep Neural Network for Handling Data Imbalance in Precursor MicroRNA",2021,"","","","",77,"2022-07-13 09:27:29","","10.3389/fpubh.2021.821410","","",,,,,1,1.00,0,9,1,"Over the last decade, the field of bioinformatics has been increasing rapidly. Robust bioinformatics tools are going to play a vital role in future progress. Scientists working in the field of bioinformatics conduct a large number of researches to extract knowledge from the biological data available. Several bioinformatics issues have evolved as a result of the creation of massive amounts of unbalanced data. The classification of precursor microRNA (pre miRNA) from the imbalanced RNA genome data is one such problem. The examinations proved that pre miRNAs (precursor microRNAs) could serve as oncogene or tumor suppressors in various cancer types. This paper introduces a Hybrid Deep Neural Network framework (H-DNN) for the classification of pre miRNA in imbalanced data. The proposed H-DNN framework is an integration of Deep Artificial Neural Networks (Deep ANN) and Deep Decision Tree Classifiers. The Deep ANN in the proposed H-DNN helps to extract the meaningful features and the Deep Decision Tree Classifier helps to classify the pre miRNA accurately. Experimentation of H-DNN was done with genomes of animals, plants, humans, and Arabidopsis with an imbalance ratio up to 1:5000 and virus with a ratio of 1:400. Experimental results showed an accuracy of more than 99% in all the cases and the time complexity of the proposed H-DNN is also very less when compared with the other existing approaches.","",""
1,"Huilin Ge, Yuewei Dai, Zhiyu Zhu, Biao Wang","Robust face recognition based on multi-task convolutional neural network.",2021,"","","","",78,"2022-07-13 09:27:29","","10.3934/mbe.2021329","","",,,,,1,1.00,0,4,1,"PURPOSE Due to the lack of prior knowledge of face images, large illumination changes, and complex backgrounds, the accuracy of face recognition is low. To address this issue, we propose a face detection and recognition algorithm based on multi-task convolutional neural network (MTCNN).   METHODS In our paper, MTCNN mainly uses three cascaded networks, and adopts the idea of candidate box plus classifier to perform fast and efficient face recognition. The model is trained on a database of 50 faces we have collected, and Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and receiver operating characteristic (ROC) curve are used to analyse MTCNN, Region-CNN (R-CNN) and Faster R-CNN.   RESULTS The average PSNR of this technique is 1.24 dB higher than that of R-CNN and 0.94 dB higher than that of Faster R-CNN. The average SSIM value of MTCNN is 10.3% higher than R-CNN and 8.7% higher than Faster R-CNN. The Area Under Curve (AUC) of MTCNN is 97.56%, the AUC of R-CNN is 91.24%, and the AUC of Faster R-CNN is 92.01%. MTCNN has the best comprehensive performance in face recognition. For the face images with defective features, MTCNN still has the best effect.   CONCLUSIONS This algorithm can effectively improve face recognition to a certain extent. The accuracy rate and the reduction of the false detection rate of face detection can not only be better used in key places, ensure the safety of property and security of the people, improve safety, but also better reduce the waste of human resources and improve efficiency.","",""
15,"Wen-juan Wei, Bei Shi, Xin Guan, Jingyun Ma, Yachen Wang, Jing Liu","Mapping theme trends and knowledge structures for human neural stem cells: a quantitative and co-word biclustering analysis for the 2013–2018 period",2019,"","","","",79,"2022-07-13 09:27:29","","10.4103/1673-5374.257535","","",,,,,15,5.00,3,6,3,"Neural stem cells, which are capable of multi-potential differentiation and self-renewal, have recently been shown to have clinical potential for repairing central nervous system tissue damage. However, the theme trends and knowledge structures for human neural stem cells have not yet been studied bibliometrically. In this study, we retrieved 2742 articles from the PubMed database from 2013 to 2018 using “Neural Stem Cells” as the retrieval word. Co-word analysis was conducted to statistically quantify the characteristics and popular themes of human neural stem cell-related studies. Bibliographic data matrices were generated with the Bibliographic Item Co-Occurrence Matrix Builder. We identified 78 high-frequency Medical Subject Heading (MeSH) terms. A visual matrix was built with the repeated bisection method in gCLUTO software. A social network analysis network was generated with Ucinet 6.0 software and GraphPad Prism 5 software. The analyses demonstrated that in the 6-year period, hot topics were clustered into five categories. As suggested by the constructed strategic diagram, studies related to cytology and physiology were well-developed, whereas those related to neural stem cell applications, tissue engineering, metabolism and cell signaling, and neural stem cell pathology and virology remained immature. Neural stem cell therapy for stroke and Parkinson’s disease, the genetics of microRNAs and brain neoplasms, as well as neuroprotective agents, Zika virus, Notch receptor, neural crest and embryonic stem cells were identified as emerging hot spots. These undeveloped themes and popular topics are potential points of focus for new studies on human neural stem cells.","",""
0,"Zhen Zhang, Xiaoyan Yu, Xianwei Rong, M. Iwata","Spatial-Temporal Neural Network for P300 Detection",2021,"","","","",80,"2022-07-13 09:27:29","","10.1109/access.2021.3132024","","",,,,,0,0.00,0,4,1,"P300 spellers are common brain-computer interface (BCI) systems designed to transfer information between human brains and computers. In most P300 detections, the P300 signals are collected by averaging multiple electroencephalographic (EEG) changes to the same target stimuli, so the participants are obliged to endure multiple repeated stimuli. In this study, a spatial-temporal neural network (STNN) based on deep learning (DL) is proposed for P300 detection. It detects P300 signals by combining the outputs from a temporal unit and a spatial unit. The temporal unit is a flexible framework consisting of several temporal modules designed for analyzing brain potential changes in the time domain. The spatial unit combines one-dimensional convolutions (Conv1Ds) and linear layers to generalize P300 features from the space domain, and it can decode EEG signals recorded using different numbers of electrodes. Both amyotrophic lateral sclerosis (ALS) patients and healthy subjects can benefit from this study. In the within-subject P300 detection and the cross-subject P300 detection, our approach gained higher performance with fewer repeated stimuli than other comparative approaches. Furthermore, we applied the proposed STNN in the P300 detection challenge of BCI Competition III. The accuracy score was 89% in the fifth round of repeated stimuli, outperforming the best result in the literature (accuracy = 80%) to the best of our knowledge. The results demonstrate that the proposed STNN performs well with limited stimuli and is robust enough for various P300 detections. Our model can be found at: https://github.com/Zhangzhenkut/STNN.","",""
101,"G. Ning, Zhi Zhang, Zhiquan He","Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation",2017,"","","","",81,"2022-07-13 09:27:29","","10.1109/TMM.2017.2762010","","",,,,,101,20.20,34,3,5,"Human pose estimation using deep neural networks aims to map input images with large variations into multiple body keypoints, which must satisfy a set of geometric constraints and interdependence imposed by the human body model. This is a very challenging nonlinear manifold learning process in a very high dimensional feature space. We believe that the deep neural network, which is inherently an algebraic computation system, is not the most efficient way to capture highly sophisticated human knowledge, for example those highly coupled geometric characteristics and interdependence between keypoints in human poses. In this work, we propose to explore how external knowledge can be effectively represented and injected into the deep neural networks to guide its training process using learned projections that impose proper prior. Specifically, we use the stacked hourglass design and inception-resnet module to construct a fractal network to regress human pose images into heatmaps with no explicit graphical modeling. We encode external knowledge with visual features, which are able to characterize the constraints of human body models and evaluate the fitness of intermediate network output. We then inject these external features into the neural network using a projection matrix learned using an auxiliary cost function. The effectiveness of the proposed inception-resnet module and the benefit in guided learning with knowledge projection is evaluated on two widely used human pose estimation benchmarks. Our approach achieves state-of-the-art performance on both datasets.","",""
3,"A. Giannakidis, K. Kamnitsas, V. Spadotto, J. Keegan, Gillian Smith, B. Glocker, D. Rueckert, S. Ernst, M. Gatzoulis, D. Pennell, S. Babu-Narayan, D. Firmin","Fast Fully Automatic Segmentation of the Severely Abnormal Human Right Ventricle from Cardiovascular Magnetic Resonance Images Using a Multi-Scale 3D Convolutional Neural Network",2016,"","","","",82,"2022-07-13 09:27:29","","10.1109/SITIS.2016.16","","",,,,,3,0.50,0,12,6,"Cardiac magnetic resonance (CMR) is regarded as the reference examination for cardiac morphology in tetralogy of Fallot (ToF) patients allowing images of high spatial resolution and high contrast. The detailed knowledge of the right ventricular anatomy is critical in ToF management. The segmentation of the right ventricle (RV) in CMR images from ToF patients is a challenging task due to the high shape and image quality variability. In this paper we propose a fully automatic deep learning-based framework to segment the RV from CMR anatomical images of the whole heart. We adopt a 3D multi-scale deep convolutional neural network to identify pixels that belong to the RV. Our robust segmentation framework was tested on 26 ToF patients achieving a Dice similarity coefficient of 0.8281±0.1010 with reference to manual annotations performed by expert cardiologists. The proposed technique is also computationally efficient, which may further facilitate its adoption in the clinical routine.","",""
8,"Lorena Guachi, R. Guachi, F. Bini, F. Marinozzi","Automatic Colorectal Segmentation with Convolutional Neural Network",2018,"","","","",83,"2022-07-13 09:27:29","","10.14733/CADCONFP.2018.312-316","","",,,,,8,2.00,2,4,4,"Introduction: In the recent years, modern medicine uses image processing technique, such as image segmentation in Computer Aided Diagnosis System (CAD) in order to reduce the dependence of diagnosis by doctors’ knowledge and experience, as well as to locate the prior tissue lesions timely and effectively [6]. Medical image segmentation uses several imaging modalities (MRI, Computed Tomography (CT), Positron Emission Tomography (PET), X-RAY, Ultrasound). However, it is a challenge yet, due to added noise, artifacts, limitations, and unclear edges [8]. In this way, colon tissues segmentation in human abdominal CT images is the base of analysis and identification of cancer nidus, providing powerful information in a CAD, such as early polyps detection, which can reduce the incidence of colon cancer [3],[6],[14]. Colon segmentation techniques can also be used in colorectal tissues simulations to make preoperative plans and simulations of surgery [4]. Some colon segmentation algorithms are introduced in literature, each one having its own model, computational complexity, and overall quality. Such as Local region based active contours [6], which is based on local statistics of tissue of interest and background, instead of global statistics. In [15], an isotropic volume reconstructed from the CT images is used to extract a thick region encompassing the entire colon, where mean curvature, dimensionless ratio sphericity and minimum polyp size are used as parameters to filter anomalies and reduce false positives. Classifications of multispectral colorectal cancer tissues [5], classify tissues samples using convolutional neural network (CNN) and uses active contours technique to extract colorectal regions corresponding to pathological tissues. Although some works presented in literature have demonstrated how CNN provides effective results to analyze colon images, those works are based on the segmentation image regions containing pathological colorectal tissues [5],[7], and glandular colon structure [10]. On the contrary, the analysis of colon tissues as pre-processing task for applications, as tissues simulations, is our motivation to challenge the use of pixel-wise segmentation with CNN. In order to overcome the problem of misclassifying colon tissue pixels, in this paper, we propose a method for automatic colon tissues segmentation based on spatial features learned with CNN. The proposed method has been compared to three state-of-the-art methods. Preliminary experimental results demonstrate the proposed method achieves a higher robustness in terms of sensitivity and similarity, and reduces the number of misclassified colon tissue pixels.","",""
15,"S. Mahdavifar, A. Ghorbani","DeNNeS: deep embedded neural network expert system for detecting cyber attacks",2020,"","","","",84,"2022-07-13 09:27:29","","10.1007/s00521-020-04830-w","","",,,,,15,7.50,8,2,2,"","",""
1,"Liping Zhang","An intelligent information retrieval algorithm based on knowledge discovery and self-organizing feature map neural network",2016,"","","","",85,"2022-07-13 09:27:29","","10.1109/INVENTIVE.2016.7830120","","",,,,,1,0.17,1,1,6,"Information retrieval is usually referring to the text information retrieval, including information storage, organization, performance, many aspects, such as query, access and its core is the text indexing and retrieval of information. Under the trend of intelligent data analysis and mining, in this paper, we propose a novel information retrieval algorithm based on knowledge discovery and self-organizing feature map neural network. Knowledge discovery is one of the major intellectual activities of human, the current knowledge discovery activities are increasingly based on network data resources and environment. Enhance semantic correlation method, that is, on the basis of the existing association, found the correlation between the data source, a new connection between different sources of data, or further connection, this process is the process of knowledge discovery activities. For enhancement, we introduce the self-organizing feature map neural network into the method to integrate the semantic information. Since Kohonen self-organizing neural network is put forward, the self-organizing feature map algorithm as a kind of very effective clustering method, in the vector quantization and pattern recognition has been widely research and application. With the reasonable of the mentioned techniques, we propose the enhanced retrieval algorithm. The experimental simulation proves that our method obtains higher robustness and accuracy compared with the other state-of-the-art algorithms.","",""
15,"M. Gogate, K. Dashtipour, P. Bell, A. Hussain","Deep Neural Network Driven Binaural Audio Visual Speech Separation",2020,"","","","",86,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207517","","",,,,,15,7.50,4,4,2,"The central auditory pathway exploits the auditory signals and visual information sent by both ears and eyes to segregate speech from multiple competing noise sources and help disambiguate phonological ambiguity. In this study, inspired from this unique human ability, we present a deep neural network (DNN) that ingest the binaural sounds received at the two ears as well as the visual frames to selectively suppress the competing noise sources individually at both ears. The model exploits the noisy binaural cues and noise robust visual cues to improve speech intelligibility. The comparative simulation results in terms of objective metrics such as PESQ, STOI, SI-SDR and DBSTOI demonstrate significant performance improvement of the proposed audio-visual (AV) DNN as compared to the audio-only (A-only) variant of the proposed model. Finally, subjective listening tests with the real noisy AV ASPIRE corpus shows the superiority of the proposed AV DNN as compared to state-of-the-art approaches.","",""
8,"S. Saha, Rimita Lahiri, A. Konar, Bonny Banerjee, A. Nagar","Human skeleton matching for e-learning of dance using a probabilistic neural network",2016,"","","","",87,"2022-07-13 09:27:29","","10.1109/IJCNN.2016.7727411","","",,,,,8,1.33,2,5,6,"With the growing interest in the domain of human computer interaction (HCI) these days, budding research professionals are coming up with novel ideas of developing more versatile and flexible modes of communication between a man and a machine. Using the attributes of internet, the scientists have been able to create a web based social platform for learning any desired art by the subject himself/herself, and this particular procedure is termed as electronic learning or e-learning. In this paper, we propose a novel application of gesture dependent e-learning of dance. This e-learning procedure may provide help to many dance enthusiasts who cannot learn the art because of the scarcity of resources despite having great zeal. The paper mainly deals with recognition of different dance gestures of a trained user such that after detecting the discrepancies between the gestures shown and actually performed by a novice; the user can rectify his faults. The elementary knowledge of geometry has been employed to introduce the concept of planes in the feature extraction stage. Actually, five planes have been constructed to signify major body parts while keeping the synchronous parts in one unit. Then four distances and four angular features have been obtained to provide entire positional information of the different body joints. Finally, using a probabilistic neural network the dance gestures have been classified after training the said network with sufficient amount of data recorded from numerous subjects to maintain generality.","",""
0,"Srungeer Simha, J. Goudswaard, P. Devarakota, P. Somawanshi","Neural Network Assisted Seismic Velocity Editing",2019,"","","","",88,"2022-07-13 09:27:29","","10.2118/197919-ms","","",,,,,0,0.00,0,4,3,"  Normal Move-Out (NMO) velocity pick editing is the segregation of good and bad picks from an unsupervised auto-picking algorithm. As not all these picks are correct, manual velocity editing is required. This is time consuming, repetitive and typically requires a seismic expert for days to weeks. Automating it would require an algorithm that mimics the domain knowledge and expertise of a seismic processor; a deterministic approach would therefore likely fail. Alternatively, we propose a machine learning algorithm to identify valid time-velocity picks.  The proposed approach is a supervised classification approach which utilizes human interpreted velocity picks (1-5% of all picks) as training data. The algorithm learns to recognize the features of a valid velocity pick from metadata such as semblance energy, depth, areal location etc. and utilizes said understanding to segregate valid picks from invalid ones (multiples etc.) amongst the remaining velocity picks. The algorithm has been trained using synthetic NMO picks created by finite-difference forward modelling CMP data, including multiples, in the Marmousi model and auto-picking the move-out. The ground-truth NMO picks were created directly from the velocity model.  The trained classification neural network shows a very high > 97% accuracy on segregation of valid and invalid NMO velocity picks based on a 5% input data set. Further reduction of the training data set to 1% of velocity picks reduces test accuracy only by an additional 2 percentage points. Training and execution time of the neural network on a dataset of ~ 40000 velocity picks are also extremely fast (< 5 mins). Initial results on RMO picks also show a very similar performance characteristic.  The metadata for all valid picks spans a multi-dimensional feature space, from which the neural network constructs a non-linear selection criterion. A human can either manually QC each pick or perform attribute-based selection using only lower dimensional linear selection criteria. The robustness and speed of the neural network outperforms the manual editing while also reducing cycle time; the resulting velocity models will be superior, leading to improved signal processing and imaging results further in the processing sequence.  Automating velocity picking and editing has been a research objective for many years now, but only since the availability of modern computation and optimization algorithms can we properly deploy this to augment the high-quality modern velocity picking software and significantly decrease turn-around time by automating the picking and QC process.","",""
4,"Yu Yu, W. Lu, Yang Liu, Hong-Bo Zhu","Neural-Network-Based Root Mean Delay Spread Model for Ubiquitous Indoor Internet-of-Things Scenarios",2020,"","","","",89,"2022-07-13 09:27:29","","10.1109/JIOT.2020.2979766","","",,,,,4,2.00,1,4,2,"Massive robust communication demands among machines and humans are required in ubiquitous Internet-of-Things (IoT) applications. To design the appropriate communication system, the knowledge of the propagation characteristics for various IoTs scenarios is necessary. In this article, a measurement-based neural-network-based root-mean-square (RMS) delay spread model for ubiquitous indoor IoTs scenarios is presented. The proposed model is a two-layer feedforward neural network plus a random variable, characterizing the average RMS delay spread and uncertain shadowing effect, respectively. The neural network consists of five inputs, including transmitting/receiving antennas (Tx/Rx) separation, frequency, antenna height, environment, and line-of-sight/non-line-of-sight (LOS/NLOS) propagation condition, seven hidden layer neurons, and one output layer neuron. Compared with different configurations of the neural network, the hyperbolic tangent sigmoid functions and the Levenberg–Marquardt backpropagation algorithm are selected as neurons’ activation functions and training method, respectively. Additionally, the random variable is found to follow the normal distribution using the maximum-likelihood estimation. Finally, the novel model is experimentally validated to be accurate, general, and extensible compared with the conventional normally distributed RMS delay spread model. This model is well applicable to the design and planning of the ubiquitous communication links for future IoTs scenarios.","",""
7,"Muhammad Fayyaz, Mussarat Yasmin, Muhammad Sharif, M. Raza","J-LDFR: joint low-level and deep neural network feature representations for pedestrian gender classification",2020,"","","","",90,"2022-07-13 09:27:29","","10.1007/s00521-020-05015-1","","",,,,,7,3.50,2,4,2,"","",""
86,"Yilong Yang, Qingfeng Wu, Ming Qiu, Yingdong Wang, Xiaowei Chen","Emotion Recognition from Multi-Channel EEG through Parallel Convolutional Recurrent Neural Network",2018,"","","","",91,"2022-07-13 09:27:29","","10.1109/IJCNN.2018.8489331","","",,,,,86,21.50,17,5,4,"As a challenging pattern recognition task, automatic real-time emotion recognition based on multi-channel EEG signals is becoming an important computer-aided method for emotion disorder diagnose in neurology and psychiatry. Traditional machine learning approaches require to design and extract various features from single or multiple channels based on comprehensive domain knowledge. Consequently, these approaches may be an obstacle for non-domain experts. On the contrast, deep learning approaches have been used successfully in many recent literatures to learn features and classify different types of data. In this paper, baseline signals are considered and a simple but effective pre-processing method has been proposed to improve the recognition accuracy. Meanwhile, a hybrid neural network which combines `Convolutional Neural Network (CNN)’ and `Recurrent Neural Network (RNN)’ has been applied to classify human emotion states by effectively learning compositional spatial-temporal representation of raw EEG streams. The CNN module is used to mine the inter-channel correlation among physically adjacent EEG signals by converting the chain-like EEG sequence into 2D-like frame sequence. The LSTM module is adopted to mine contextual information. Experiments are carried out in a segment-level emotion identification task, on the DEAP benchmarking dataset. Our experimental results indicate that the proposed pre-processing method can increase emotion recognition accuracy by 32% approximately and the model achieves a high performance with a mean accuracy of 90.80% and 91.03% on valence and arousal classification task respectively.","",""
122,"Bowen Xu, Deheng Ye, Zhenchang Xing, Xin Xia, Guibin Chen, Shanping Li","Predicting semantically linkable knowledge in developer online forums via convolutional neural network",2016,"","","","",92,"2022-07-13 09:27:29","","10.1145/2970276.2970357","","",,,,,122,20.33,20,6,6,"Consider a question and its answers in Stack Overflow as a knowledge unit. Knowledge units often contain semantically relevant knowledge, and thus linkable for different purposes, such as duplicate questions, directly linkable for problem solving, indirectly linkable for related information. Recognising different classes of linkable knowledge would support more targeted information needs when users search or explore the knowledge base. Existing methods focus on binary relatedness (i.e., related or not), and are not robust to recognize different classes of semantic relatedness when linkable knowledge units share few words in common (i.e., have lexical gap). In this paper, we formulate the problem of predicting semantically linkable knowledge units as a multiclass classification problem, and solve the problem using deep learning techniques. To overcome the lexical gap issue, we adopt neural language model (word embeddings) and convolutional neural network (CNN) to capture word- and document-level semantics of knowledge units. Instead of using human-engineered classifier features which are hard to design for informal user-generated content, we exploit large amounts of different types of user-created knowledge-unit links to train the CNN to learn the most informative wordlevel and document-level features for the multiclass classification task. Our evaluation shows that our deep-learning based approach significantly and consistently outperforms traditional methods using traditional word representations and human-engineered classifier features.","",""
52,"Kasun Amarasinghe, K. Kenney, M. Manic","Toward Explainable Deep Neural Network Based Anomaly Detection",2018,"","","","",93,"2022-07-13 09:27:29","","10.1109/HSI.2018.8430788","","",,,,,52,13.00,17,3,4,"Anomaly detection in industrial processes is crucial for general process monitoring and process health assessment. Deep Neural Networks (DNNs) based anomaly detection has received increased attention in recent work. Albeit their high accuracy, the black-box nature of DNNs is a drawback in practical deployment. Especially in industrial anomaly detection systems, explanations of DNN detected anomalies are crucial. This paper presents a framework for DNN based anomaly detection which provides explanations of detected anomalies. The framework answers the following questions during online processing: 1) “why is it an anomaly?” and 2) “what is the confidence?” Further, the framework can be used offline to evaluate the “knowledge” of the trained DNN. The framework reduces the opaqueness of the DNN based anomaly detector and thus improves human operators' trust in the algorithm. This paper implements the first steps of the presented framework on the benchmark KDD-NSL dataset for Denial of Service (DoS) attack detection. Offline DNN explanations showed that the DNN was detecting DoS attacks based on features indicating destination of connection, frequency and amount of data transferred while showing an accuracy around 97%.","",""
4,"Stephan Günnemann","Graph Neural Networks: Adversarial Robustness",2022,"","","","",94,"2022-07-13 09:27:29","","10.1007/978-981-16-6054-2_8","","",,,,,4,4.00,4,1,1,"","",""
59,"H. Moayedi, Mansour Mosallanezhad, A. S. Rashid, Wan Amizah Wan Jusoh, M. A. Muazu","A systematic review and meta-analysis of artificial neural network application in geotechnical engineering: theory and applications",2019,"","","","",95,"2022-07-13 09:27:29","","10.1007/s00521-019-04109-9","","",,,,,59,19.67,12,5,3,"","",""
0,"U. Cnrs","Neural Network and Wavelet Multiresolution System for Human Being Detection",2017,"","","","",96,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,5,"ABSTRACT Many applications, in robotics, require identification of human being. Using complex methods, based on modelmatching are too computationally expensive and not always justified. We propose a fast and simple method for identification of human being. This method takes profit of the learning capabilities of a neural network. The idea is to train a neural network on some images of persons. In order to reduce the amount of this data (images), we use waveletmultiresolution propriety analysis that allows to bring significant information content of image. This one thus ischaracterised by its approximation at a given resolution. After the training phase, the generalization capabilities of the network allow it to identify no-learned images.We describe here the proposed method, and we present experimental results obtained on a data base of 437 images.Key words: Segmentation - Neural Network -Identification-Image Processing-Wavelet Multiresolution. 1. INTRODUCTION Human is able to localise and identify a human being very quickly, in different situations and with a good reliability.This capability is very robust: this one resists to important image changes due to modification of point of view or lightingconditions, etc....That why, the visual analysis by the humans has fascinated a lot of scientifics like Aristote or Darwin,since centuries. The automatic detection systems are interesting by theory knowledge that they will can bring to us aboutthe visual human system. But they have a lot of practical applications like: perception of autonomous vehicles, controlaccess (banks,..), etc.The connexionist models (neural networks) give a panoply of methods for classification, event detection and signal","",""
5,"D. Hagos, P. Engelstad, A. Yazidi, Ø. Kure","Recurrent Neural Network-Based Prediction of TCP Transmission States from Passive Measurements",2018,"","","","",97,"2022-07-13 09:27:29","","10.1109/NCA.2018.8548064","","",,,,,5,1.25,1,4,4,"Long Short-Term Memory (LSTM) neural networks are a state-of-the-art techniques when it comes to sequence learning and time series prediction models. In this paper, we have used LSTM-based Recurrent Neural Networks (RNN) for building a generic prediction model for Transmission Control Protocol (TCP) connection characteristics from passive measurements. To the best of our knowledge, this is the first work that attempts to apply LSTM for demonstrating how a network operator can identify the most important system-wide TCP per-connection states of a TCP client that determine a network condition (e.g., cwnd) from passive traffic measured at an intermediate node of the network without having access to the sender. We found out that LSTM learners outperform the state-of-the-art classical machine learning prediction models. Through an extensive experimental evaluation on multiple scenarios, we demonstrate the scalability and robustness of our approach and its potential for monitoring TCP transmission states related to network congestion from passive measurements. Our results based on emulated and realistic settings suggest that Deep Learning is a promising tool for monitoring system-wide TCP states from passive measurements and we believe that the methodology presented in our paper may strengthen future research work in the computer networking community.","",""
74,"Hong Liu, Juanhui Tu, Mengyuan Liu","Two-Stream 3D Convolutional Neural Network for Skeleton-Based Action Recognition",2017,"","","","",98,"2022-07-13 09:27:29","","","","",,,,,74,14.80,25,3,5,"It remains a challenge to efficiently extract spatialtemporal information from skeleton sequences for 3D human action recognition. Although most recent action recognition methods are based on Recurrent Neural Networks which present outstanding performance, one of the shortcomings of these methods is the tendency to overemphasize the temporal information. Since 3D convolutional neural network(3D CNN) is a powerful tool to simultaneously learn features from both spatial and temporal dimensions through capturing the correlations between three dimensional signals, this paper proposes a novel two-stream model using 3D CNN. To our best knowledge, this is the first application of 3D CNN in skeleton-based action recognition. Our method consists of three stages. First, skeleton joints are mapped into a 3D coordinate space and then encoding the spatial and temporal information, respectively. Second, 3D CNN models are seperately adopted to extract deep features from two streams. Third, to enhance the ability of deep features to capture global relationships, we extend every stream into multitemporal version. Extensive experiments on the SmartHome dataset and the large-scale NTU RGB-D dataset demonstrate that our method outperforms most of RNN-based methods, which verify the complementary property between spatial and temporal information and the robustness to noise.","",""
16,"Yifang Chen, Xiangui Kang, Z. J. Wang, Qiong Zhang","Densely Connected Convolutional Neural Network for Multi-purpose Image Forensics under Anti-forensic Attacks",2018,"","","","",99,"2022-07-13 09:27:29","","10.1145/3206004.3206013","","",,,,,16,4.00,4,4,4,"Multiple-purpose forensics has been attracting increasing attention worldwide. However, most of the existing methods based on hand-crafted features often require domain knowledge and expensive human labour and their performances can be affected by factors such as image size and JPEG compression. Furthermore, many anti-forensic techniques have been applied in practice, making image authentication more difficult. Therefore, it is of great importance to develop methods that can automatically learn general and robust features for image operation detectors with the capability of countering anti-forensics. In this paper, we propose a new convolutional neural network (CNN) approach for multi-purpose detection of image manipulations under anti-forensic attacks. The dense connectivity pattern, which has better parameter efficiency than the traditional pattern, is explored to strengthen the propagation of general features related to image manipulation detection. When compared with three state-of-the-art methods, experiments demonstrate that the proposed CNN architecture can achieve a better performance (i.e., with a 11% improvement in terms of detection accuracy under anti-forensic attacks). The proposed method can also achieve better robustness against JPEG compression with maximum improvement of 13% on accuracy under low-quality JPEG compression.","",""
0,"Rassa Ghavami Modegh, Ahmadali Salimi, H. Rabiee","LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks",2022,"","","","",100,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,3,1,"Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. The complex computation behind their reasoning is not sufficiently human-understandable to develop trust. External explainer methods have tried to interpret the network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection while improving the model’s performance. Moreover, several weakly-supervised knowledge injection methodologies are provided to enhance the process of training. We verified our claims by evaluating several LAP-extended models on three different datasets, including Imagenet. The proposed framework offers more valid humanunderstandable and more faithful-to-the-model interpretations than the commonly used white-box explainer methods.","",""
3,"Sanjeeva Gunetileke, R. Chaplin, R. M. Hodgson","The use of problem knowledge to improve the robustness of a fuzzy neural network",2000,"","","","",101,"2022-07-13 09:27:29","","10.1109/NNSP.2000.890147","","",,,,,3,0.14,1,3,22,"Neural networks generally take a long time to train. This is because the network is initialized using random values for the weights. These random values have no relationship to the problem to be solved. The network is also more likely to converge to a non-optimal solution when initialized with random weights. This paper discusses how a fuzzy neural network can be initialized using problem knowledge. This initialization method improves the network robustness when training using uncertain data. It is shown that the use of problem knowledge-based rules can compensate for the uncertainty in the training data.","",""
4,"Georgios Panagiotatos, N. Passalis, Alexandros Iosifidis, M. Gabbouj, A. Tefas","Curriculum-based Teacher Ensemble for Robust Neural Network Distillation",2019,"","","","",102,"2022-07-13 09:27:29","","10.23919/EUSIPCO.2019.8903112","","",,,,,4,1.33,1,5,3,"Neural network distillation is used for transferring the knowledge from a complex teacher network into a lightweight student network, improving in this way the performance of the student network. However, neural distillation does not always lead to consistent results, with several factors affecting the efficiency of the knowledge distillation process. In this paper it is experimentally demonstrated that the selected teacher can indeed have a significant effect on knowledge transfer. To overcome this limitation, we propose a curriculum-based teacher ensemble that allows for performing robust and efficient knowledge distillation. The proposed method is motivated by the way that humans learn through a curriculum, as well as supported by recent findings that hints to the existence of critical learning periods in neural networks. The effectiveness of the proposed approach, compared to various distillation variants, is demonstrated using three image datasets and different network architectures.","",""
3,"Shanlin Zhong, Junjie Zhou, Hong Qiao","Bioinspired Gain-Modulated Recurrent Neural Network for Controlling Musculoskeletal Robot.",2021,"","","","",103,"2022-07-13 09:27:29","","10.1109/TNNLS.2021.3071196","","",,,,,3,3.00,1,3,1,"The motor cortex can arouse abundant transient responses to generate complex movements with the regulation of neuromodulators, while its architecture remains unchanged. This characteristic endows humans with flexible and robust abilities in adapting to dynamic environments, which is exactly the bottleneck in the control of complex robots. In this article, inspired by the mechanisms of the motor cortex in encoding information and modulating motor commands, a biologically plausible gain-modulated recurrent neural network is proposed to control a highly redundant, coupled, and nonlinear musculoskeletal robot. As the characteristics observed in the motor cortex, this network is able to learn gain patterns for arousing transient responses to complete the desired movements, while the connections of synapses keep unchanged, and the dynamic stability of the network is maintained. A novel learning rule that mimics the mechanism of neuromodulators in regulating the learning process of the brain is put forward to learn gain patterns effectively. Meanwhile, inspired by error-based movement correction mechanism in the cerebellum, gain patterns learned from demonstration samples are leveraged as prior knowledge to improve calculation efficiency of the network in controlling novel movements. Experiments were conducted on an upper extremity musculoskeletal model with 11 muscles and a general articulated robot to perform goal-directed tasks. The results indicate that the gain-modulated neural network can effectively control a complex robot to complete various movements with high accuracy, and the proposed algorithms make it possible to realize fast generalization and incremental learning ability.","",""
2,"V. Bahrami, A. Kalhor, M. T. Masouleh","Dynamic model estimating and designing controller for the 2-DoF planar robot in interaction with cable-driven robot based on adaptive neural network",2021,"","","","",104,"2022-07-13 09:27:29","","10.3233/JIFS-210180","","",,,,,2,2.00,1,3,1,"This study intends to investigate the dynamic model estimation and the design of an adaptive neural network based controller for a passive planar robot, performing 2-DoF motion pattern which is in interaction with an actuated cable-driven robot. In fact, the main goal of applying this structure is to use a number of light cables to drive serial robot links and track the desired reference model by the robot’s end-effector. The under study system can be used as a rehabilitation setup which is helpful for those with arm disability. In this way, upon applying sliding mode error dynamics, it is necessary to determine a vector that contains the matrices related to the robot dynamics. However, finding these matrices requires the use of computational approaches such as Newton-Euler or Lagrange. In addition, since the purpose of this paper is to express comprehensive methods, so with increasing the number of links and degrees of freedom of the robot, finding the dynamics of the robot becomes more difficult. Therefore, the Adaptive Neural Network (ANN) with specific inputs has been used for estimation unknown matrices of the system and the controller design has been performed based on it. So, the main idea in using an adaptive controller is the fact there is no pre-knowledge for the dynamic modeling of the system since the human arm could have different dynamic properties. Hence, the controller is formed by an ANN and robust term. In this way, the adaptation laws of the parameters are extracted by Lyapunov approach, and as a result, as aforementioned, the asymptotic stability of the whole of the system is guaranteed. Simulation results certify the efficiency of the proposed method. Finally, using the Roots Mean Square Error (RMSE) criteria, it has been revealed that, in the presence of bounded disturbance with different amplitude, adding the robust term to the controller leads to improve the tracking error about 34% and 62%, respectively.","",""
0,"Hai Jiang, Jing Liu, H. Cheng","Short-Term TLE Uncertainty Estimation Using an Artificial Neural Network Model",2018,"","","","",105,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,3,4,"A growing number of space activities have created an orbital debris environment that poses increasing impact risks to existing space systems and human space flight. Accurate knowledge of orbit propagation errors of space debris is essential for many types of analyses, such as space surveillance network tasking, conjunction analysis etc. Unfortunately, for two-line elements (TLEs) this is not available. In this paper, a new short-term TLE uncertainty estimation method based on an artificial neural network model is proposed. Object properties, orbit type, space environment and prediction time-span are considered as the input of the network, the propagation errors in the direction of downrange, normal and conormald are as the output of the network. In order to assure the chosen orbit for training is not for an object using station keeping, only debris and R/B are used. The network’s efficiency is demonstrated with some objects with high ephemeris data. Overall, the method proves accurate, computationally fast, and robust, and is applicable to any object in the satellite catalogue, especially for those newly launched objects.","",""
10,"Chunling Cheng, Xianwei Wei, Zhou Jian","Emotion recognition algorithm based on convolution neural network",2017,"","","","",106,"2022-07-13 09:27:29","","10.1109/ISKE.2017.8258786","","",,,,,10,2.00,3,3,5,"Emotional recognition is a very challenging nature of the topic in the field of Brain — Computer Interface (BCI). This technology has been applied in many fields, such as The electroencephalogram (EEG) signals. The EEG signals can intuitively express the human emotional state and has attracted attentions of many researchers. Besides, it has a strong correlation during a period. To preserve the correlation, this paper presents an emotion recognition algorithm based on convolution neural network (ERACNN). In this paper, the EEG signals are pretreated, and then the parameters of CNN are selected. Finally, the classification model of emotion recognition is trained. Experimental results show that the results based on ERACNN is more robust than these based on Support Vector Machine (SVM). Besides, ERACNN can improve the classification accuracy of emotion recognition compared with the similar CNN algorithm.","",""
55,"Cassidy Laidlaw, Sahil Singla, S. Feizi","Perceptual Adversarial Robustness: Defense Against Unseen Threat Models",2020,"","","","",107,"2022-07-13 09:27:29","","","","",,,,,55,27.50,18,3,2,"We present adversarial attacks and defenses for the perceptual adversarial threat model: the set of all perturbations to natural images which can mislead a classifier but are imperceptible to human eyes. The perceptual threat model is broad and encompasses $L_2$, $L_\infty$, spatial, and many other existing adversarial threat models. However, it is difficult to determine if an arbitrary perturbation is imperceptible without humans in the loop. To solve this issue, we propose to use a {\it neural perceptual distance}, an approximation of the true perceptual distance between images using internal activations of neural networks. In particular, we use the Learned Perceptual Image Patch Similarity (LPIPS) distance. We then propose the {\it neural perceptual threat model} that includes adversarial examples with a bounded neural perceptual distance to natural images. Under the neural perceptual threat model, we develop two novel perceptual adversarial attacks to find any imperceptible perturbations to images which can fool a classifier. Through an extensive perceptual study, we show that the LPIPS distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model. Because the LPIPS threat model is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against 12 types of adversarial attacks and find that, for each attack, PAT achieves close to the accuracy of adversarial training against just that perturbation type. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial defense with this property.","",""
8,"Quan Zhou, Dezong Zhao, B. Shuai, Yanfei Li, Huw Williams, Hongming Xu","Knowledge Implementation and Transfer With an Adaptive Learning Network for Real-Time Power Management of the Plug-in Hybrid Vehicle",2021,"","","","",108,"2022-07-13 09:27:29","","10.1109/TNNLS.2021.3093429","","",,,,,8,8.00,1,6,1,"Essential decision-making tasks such as power management in future vehicles will benefit from the development of artificial intelligence technology for safe and energy-efficient operations. To develop the technique of using neural network and deep learning in energy management of the plug-in hybrid vehicle and evaluate its advantage, this article proposes a new adaptive learning network that incorporates a deep deterministic policy gradient (DDPG) network with an adaptive neuro-fuzzy inference system (ANFIS) network. First, the ANFIS network is built using a new global K-fold fuzzy learning (GKFL) method for real-time implementation of the offline dynamic programming result. Then, the DDPG network is developed to regulate the input of the ANFIS network with the real-world reinforcement signal. The ANFIS and DDPG networks are integrated to maximize the control utility (CU), which is a function of the vehicle’s energy efficiency and the battery state-of-charge. Experimental studies are conducted to testify the performance and robustness of the DDPG-ANFIS network. It has shown that the studied vehicle with the DDPG-ANFIS network achieves 8% higher CU than using the MATLAB ANFIS toolbox on the studied vehicle. In five simulated real-world driving conditions, the DDPG-ANFIS network increased the maximum mean CU value by 138% over the ANFIS-only network and 5% over the DDPG-only network.","",""
29,"C. Corbane, V. Syrris, F. Sabo, P. Politis, M. Melchiorri, M. Pesaresi, P. Soille, T. Kemper","Convolutional Neural Networks for Global Human Settlements Mapping from Sentinel-2 Satellite Imagery",2020,"","","","",109,"2022-07-13 09:27:29","","10.1007/S00521-020-05449-7","","",,,,,29,14.50,4,8,2,"","",""
19,"Xin Zhong, Pei-Chi Huang, Spyridon Mastorakis, F. Shih","An Automated and Robust Image Watermarking Scheme Based on Deep Neural Networks",2019,"","","","",110,"2022-07-13 09:27:29","","10.1109/TMM.2020.3006415","","",,,,,19,6.33,5,4,3,"Digital image watermarking is the process of embedding and extracting a watermark covertly on a cover-image. To dynamically adapt image watermarking algorithms, deep learning–based image watermarking schemes have attracted increased attention during recent years. However, existing deep learning–based watermarking methods neither fully apply the fitting ability to learn and automate the embedding and extracting algorithms, nor achieve the properties of robustness and blindness simultaneously. In this paper, a robust and blind image watermarking scheme based on deep learning neural networks is proposed. To minimize the requirement of domain knowledge, the fitting ability of deep neural networks is exploited to learn and generalize an automated image watermarking algorithm. A deep learning architecture is specially designed for image watermarking tasks, which will be trained in an unsupervised manner to avoid human intervention and annotation. To facilitate flexible applications, the robustness of the proposed scheme is achieved without requiring any prior knowledge or adversarial examples of possible attacks. A challenging case of watermark extraction from phone camera–captured images demonstrates the robustness and practicality of the proposal. The experiments, evaluation, and application cases confirm the superiority of the proposed scheme.","",""
27,"Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, D. Tao, M. Sugiyama","Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting",2020,"","","","",111,"2022-07-13 09:27:29","","10.1162/neco_a_01403","","",,,,,27,13.50,5,6,2,"Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from “natural” neural networks. We rigorously prove that ANV plays as an implicit regularizer of the mutual information between the training data and the learned model. This result theoretically guarantees ANV a strictly improved generalizability, robustness to label noise, and robustness to catastrophic forgetting. We then devise a neural variable risk minimization (NVRM) framework and neural variable optimizers to achieve ANV for conventional network architectures in practice. The empirical studies demonstrate that NVRM can effectively relieve overfitting, label noise memorization, and catastrophic forgetting at negligible costs.","",""
6,"Hoang-Quynh Le, Duy-Cat Can, T. Dang, Mai-Vu Tran, Quang-Thuy Ha, Nigel Collier","Improving chemical-induced disease relation extraction with learned features based on convolutional neural network",2017,"","","","",112,"2022-07-13 09:27:29","","10.1109/KSE.2017.8119474","","",,,,,6,1.20,1,6,5,"There have been an increasing number of various machine learning-based models successfully proposed and applied for automatic chemical-induced disease (CID) relation extraction. They, however, usually require carefully handcrafted rich feature sets, which rely on expert knowledge, thus require expensive human labor but normally still cannot generalize data well enough. In this paper, we propose a CID relation extraction model that learns features automatically through a Convolutional Neural Network (CNN) instead of traditional handcrafted features. We exploit the shortest dependency path between a disease and a chemical for identifying their CID relation. Dependency relations, with and without their direction information, are further investigated. Experimental results on benchmark datasets (namely the BioCreative V dataset) are very potential, demonstrating the effectiveness of our proposed model for CID relation extraction.","",""
0,"G. I. Parisi","Multimodal Learning of Actions with Deep Neural Network Self-Organization",2017,"","","","",113,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,5,"Perceiving the actions of other people is one of the most important social skills of human beings. We are able to reliably discern a variety of socially relevant information from people’s body motion such as intentions, identity, gender, and affective states. This ability is supported by highly developed visual skills and the integration of additional modalities that in concert contribute to providing a robust perceptual experience. Multimodal integration is a fundamental feature of the brain that together with widely studied biological mechanisms for action perception has served as inspiration for the development of artificial systems. However, computational mechanisms for processing and integrating knowledge reliably from multiple perceptual modalities are still to be fully investigated.  The goal of this thesis is to study and develop artificial learning architectures for action perception. In light of a wide understanding of the brain areas and underlying neural mechanisms for processing biological motion patterns, we propose a series of neural network models for learning multimodal action representations. Consistent with neurophysiological studies evidencing a hierarchy of cortical layers driven by the distribution of the input, we demonstrate how computational models of input-driven self-organization can account for the learning of action features with increasing complexity of representation. For this purpose, we introduce a novel model of recurrent self-organization for learning action features with increasingly large spatiotemporal receptive fields. Visual representations obtained through unsupervised learning are incrementally associated to symbolic action labels for the purpose of action classification.  From a multimodal perspective, we propose a model in which multimodal action representations can develop from neural network organization in terms of associative connectivity patterns between unimodal representations. We report a set of experiments showing that deep self-organizing hierarchies allow to learn statistically significant features of actions, with multimodal representations emerging from co-occurring audiovisual stimuli. We evaluated our neural network architectures on the tasks of human action recognition, body motion assessment, and the detection of abnormal behavior. Finally, we conducted two robot experiments that provide quantitative evidence for the advantages of multimodal integration for triggering sensory-driven motor behavior. The first scenario consists of an assistive task for the detection of falls, whereas in the second experiment we propose audiovisual integration in an interactive reinforcement learning scenario. Together, our results demonstrate that deep neural self-organization can account for robust action perception, yielding state-of-the-art performance also in the presence of sensory uncertainty and conflict.  The research presented in this thesis comprises interdisciplinary aspects of action perception and multimodal integration for the development of efficient neurocognitive architectures. While the brain mechanisms for multimodal perception are still to be fully understood, the proposed neural network architectures may be seen as a basis for modeling higher-level cognitive functions.","",""
2,"Yingying Wang, Ming Chang, Hongwei Chen, Yueou Ren, Qiuju Li","Research on Fault Diagnosis Expert System Fusing the Neural Network Knowledge",2011,"","","","",114,"2022-07-13 09:27:29","","10.1109/IHMSC.2011.54","","",,,,,2,0.18,0,5,11,"For a complicated system based on high technology, once a part breaks down, the entire system can not work normally. Moreover, due to the complexity of its structure and fault causes, the fault diagnosis of the system is also complex and indeterminate, a single test equipment can hardly finish a difficult diagnose task, and fault diagnosis expert system can resolve these problems effectively. The traditional diagnose expert systems have many problems such as the bottleneck of knowledge acquisition, the fragility of knowledge, the pool ability of self-study, the inefficient reasoning, and the monotonicity of reasoning, so there are certain limitations. But the artifical neural networks technology is a new system, it is an mathematical model that applies the structure like the joint of synapses in hypothalamic neurons, which has the strong ability to study, and can learn from samples, obtain knowledge, store it in the network in the form of weight and threshold, and it is easy to implement the parallel processing, has the character of association memory, own the better robust. it ability of adaptive self-study is manifested mainly in adjusting the weight of network according to the change of enviroment by learning algorithms, so as to adapt to the environmental change. But the neural network can not explain its own reasoning. Therefore we will apply the neural network to the expert knowledge system, which can make them learn each other's good points mutually for common progress, constructing the new neural network expert system. The system is applied to the power fault diagnosis, achieving good results.","",""
27,"Emre Çakir, Ezgi C. Ozan, T. Virtanen","Filterbank learning for deep neural network based polyphonic sound event detection",2016,"","","","",115,"2022-07-13 09:27:29","","10.1109/IJCNN.2016.7727634","","",,,,,27,4.50,9,3,6,"Deep learning techniques such as deep feedforward neural networks and deep convolutional neural networks have recently been shown to improve the performance in sound event detection compared to traditional methods such as Gaussian mixture models. One of the key factors of this improvement is the capability of deep architectures to automatically learn higher levels of acoustic features in each layer. In this work, we aim to combine the feature learning capabilities of deep architectures with the empirical knowledge of human perception. We use the first layer of a deep neural network to learn a mapping from a high-resolution magnitude spectrum to smaller amount of frequency bands, which effectively learns a filterbank for the sound event detection task. We initialize the first hidden layer weights to match with the perceptually motivated mel filterbank magnitude response. We also integrate this initialization scheme with context windowing by using an appropriately constrained deep convolutional neural network. The proposed method does not only result with better detection accuracy, but also provides insight on the frequencies deemed essential for better discrimination of given sound events.","",""
0,"A. Baidya, Joel Dapello, J. DiCarlo, Tiago Marques","Combining Different V1 Brain Model Variants to Improve Robustness to Image Corruptions in CNNs",2021,"","","","",116,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,4,1,"While some convolutional neural networks (CNNs) have surpassed human visual abilities in object classiﬁcation, they often struggle to recognize objects in images corrupted with different types of common noise patterns, highlighting a major limitation of this family of models. Recently, it has been shown that simulating a primary visual cortex (V1) at the front of CNNs leads to small improvements in robustness to these image perturbations. In this study, we start with the observation that different variants of the V1 model show gains for speciﬁc corruption types. We then build a new model using an ensembling technique, which combines multiple individual models with different V1 front-end variants. The model ensemble lever-ages the strengths of each individual model, leading to signiﬁcant improvements in robustness across all corruption categories and outperforming the base model by 38% on average. Finally, we show that using distillation it is possible to partially compress the knowledge in the ensemble model into a single model with a V1 front-end. While the ensembling and distillation techniques used here are hardly biologically-plausible, the results presented here demonstrate that by combining the speciﬁc strengths of different neuronal circuits in V1 it is possible to improve the robustness of CNNs for a wide range of perturbations.","",""
17,"Wanxiang Shen, X. Zeng, F. Zhu, Y. Wang, C. Qin, Ying Tan, Yu Yang Jiang, Y. Chen","Out-of-the-box deep learning prediction of pharmaceutical properties by broadly learned knowledge-based molecular representations",2021,"","","","",117,"2022-07-13 09:27:29","","10.1038/S42256-021-00301-6","","",,,,,17,17.00,2,8,1,"","",""
1268,"Robert Geirhos, Patricia Rubisch, Claudio Michaelis, M. Bethge, Felix Wichmann, Wieland Brendel","ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",2018,"","","","",118,"2022-07-13 09:27:29","","","","",,,,,1268,317.00,211,6,4,"Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNet-trained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on ""Stylized-ImageNet"", a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation.","",""
0,"Jing Huang","Knowledge graph representation learning and graph neural networks for language understanding",2022,"","","","",119,"2022-07-13 09:27:29","","10.1145/3534540.3534710","","",,,,,0,0.00,0,1,1,"As AI technologies become mature in natural language processing, speech recognition and computer vision, ""intelligent"" user interfaces emerge to handle complex and diverse tasks that require human-like knowledge and reasoning capability. In Part 1, I will present our recent work on knowledge graph representation learning using Graph Neural Networks (GNNs): the first approach is called orthogonal transform embedding (OTE), which integrates graph context into the embedding distance scoring function and improves prediction accuracy on complex relations such as the difficult N-to-1, 1-to-N and N-to-N cases; the second approach is called multi-hop attention GNN (MAGNA), a principled way to incorporate multi-hop context information into every layer of attention computation. MAGNA uses a diffusion prior on attention values, to efficiently account for all paths between the pair of disconnected nodes. Experimental results on knowledge graph completion as well as node classification benchmarks show that MAGNA achieves state-of-the-art results. In Part 2, I will present how we take advantage of GNNs for language understanding and reasoning tasks. We show that combined with large pre-trained language models and knowledge graph embeddings, GNNs are proven effective in multi-hop reading comprehension across documents, improving time sensitivity for question answering over temporal knowledge graphs, and constructing robust syntactic information for aspect-level sentiment analysis.","",""
2,"Simone Dari, Nikolay Kadrileev, E. Hüllermeier","A Neural Network-Based Driver Gaze Classification System with Vehicle Signals",2020,"","","","",120,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207709","","",,,,,2,1.00,1,3,2,"Driver monitoring can play an essential part in avoiding accidents by warning the driver and shifting the driver’s attention to the traffic scenery in time during critical situations. This may apply for the different levels of automated driving, for take-over requests as well as for driving in manual mode. A great proxy for this purpose has always been the driver’s gazing direction. The aim of this work is to introduce a robust gaze detection system. In this regard, we make several contributions that are novel in the area of gaze detection systems. In particular, we propose a deep learning approach to predict gaze regions, which is based on informative features such as eye landmarks and head pose angles of the driver. Moreover, we introduce different post-processing techniques that improve the accuracy by exploiting temporal information from videos and the availability of other vehicle signals. Last but not least, we confirm our method with a leave-one-driver-out cross-validation. Unlike previous studies, we do not use gazes to predict maneuver changes, but we consider the human-computer-interaction aspect and use vehicle signals to improve the performance of the estimation. The proposed system is able to achieve an accuracy of 92.3% outperforming earlier landmark-based gaze estimators.","",""
12,"Diego Manzanas Lopez, Patrick Musau, Hoang-Dung Tran, Taylor T. Johnson","Verification of Closed-loop Systems with Neural Network Controllers",2019,"","","","",121,"2022-07-13 09:27:29","","10.29007/btv1","","",,,,,12,4.00,3,4,3,"This benchmark suite presents a detailed description of a series of closed-loop control systems with artificial neural network controllers. In many applications, feed-forward neural networks are heavily involved in the implementation of controllers by learning and representing control laws through several methods such as model predictive control (MPC) and reinforcement learning (RL). The type of networks that we consider in this manuscript are feed-forward neural networks consisting of multiple hidden layers with ReLU activation functions and a linear activation function in the output layer. While neural network controllers have been able to achieve desirable performance in many contexts, they also present a unique challenge in that it is difficult to provide any guarantees about the correctness of their behavior or reason about the stability a system that employs their use. Thus, from a controls perspective, it is necessary to verify them in conjunction with their corresponding plants in closed-loop. While there have been a handful of works proposed towards the verification of closed-loop systems with feed-forward neural network controllers, this area still lacks attention and a unified set of benchmark examples on which verification techniques can be evaluated and compared. Thus, to this end, we present a range of closed-loop control systems ranging from two to six state variables, and a range of controllers with sizes in the range of eleven neurons to a few hundred neurons in more complex systems. Category: Academic Difficulty: High Acknowledgement The material presented in this paper is based upon work supported by the National Science Foundation (NSF) under grant number SHF 1736323, the Air Force Office of Scientific Research (AFOSR) through contract numbers FA9550-15-1-0258, FA9550-16-10246, and FA9550-18-1-0122, and the Defense Advanced Research Projects Agency (DARPA) through contract number FA8750-18-C-0089. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of AFOSR, DARPA, or NSF G. Frehse and M. Althoff (eds.), ARCH19 (EPiC Series in Computing, vol. 61), pp. 201–210 Closed-loop Systems with Neural Network Controllers Manzanas Lopez, Musau, Tran and Johnson 1 Context and Origins. In recent years, advances in Artficial Intelligence (AI) have enabled a diverse range of technologies that are directly impacting people’s everyday lives [16]. Particularly, within this space, machine learning methods such as Deep Learning (DL) have achieved levels of accuracy and performance that are competitive or better than humans for tasks such as pattern and image recognition [12], natural language processing [7], and knowledge representation and reasoning [15,22]. Despite these achievements, there have been reservations about incorporating them into safety critical systems [11] due to their susceptibility to unexpected and errant behavior from a slight perturbation in their inputs [18]. Furthermore, neural networks are often viewed as ""black boxes"" since the underlying operation of the neuron activations is often indiscernible [22]. In light of these challenges, there has been significant work towards the creation of methods and verification tools that can formally reason about the behavior of neural networks [22]. However, the vast majority of these techniques have only been able to deal with feed-forward neural networks with piecewise-linear activation functions [4]. Additionally, the bulk of these methods have primarily considered the verification of input-output properties of neural networks in isolation [22], and there are only a handful of works that have explicitly addressed the verification of closed-loop control systems with neural network controllers [5, 8, 19–21]. One of the central challenges in verifying neural network control systems is that applying existing methodology to these systems is not straightforward [9], and a simple combination of verification tools for non-linear ordinary differential equations along with a neural network reachability tool suffers from severe overestimation errors [5]. Still, the verification of closed loop neural network systems is deeply important as they naturally arise in safety critical systems [5] such as autonomous vehicles, and complex control systems that make use of model predictive control and reinforcement learning [16]. Thus, there is a compelling need for methods and advanced software tools that can effectively deal with the complexities exhibited by these systems [5]. Inspired by a shortage of verification methods for closed-loop neural network control systems in the research literature, the central contribution of this paper is the provision of a set of executable benchmarks that have been synthesized using methods such as reinforcement learning [17], and model predictive control [14]. The problems elucidated in the paper are modeled using Simulink/Stateflow (SLSF) and are available at the following github repository1. We aim to provide a thorough problem description to which the numerous tools and approaches for non-linear systems and neural network verification present in the research community can be evaluated and compared [22]. If the research community is able to devise acceptable solutions to the aformentioned challenges they will stimulate the development of robust and intelligent systems with the potential to bring unparalleled benefits to numerous application domains. 2 Description of benchmarks. In this manuscript, we present a set of linear and non-linear closed-loop systems with continuoustime plants and feedforward neural networks controllers trained using different controls schemes such as reinforcement learning or model predictive control (MPC). A typical architecture describing the structure of these systems is displayed in Figure 2.1. All the neural networks 1https://github.com/verivital/ARCH-2019","",""
7,"S. Bhattacharya, Samir Roy, S. Chowdhury","A neural network-based intelligent cognitive state recognizer for confidence-based e-learning system",2016,"","","","",122,"2022-07-13 09:27:29","","10.1007/s00521-016-2430-5","","",,,,,7,1.17,2,3,6,"","",""
13,"Shreya Ghosh, Abhinav Dhall, Garima Sharma, Sarthak Gupta, N. Sebe","Speak2Label: Using Domain Knowledge for Creating a Large Scale Driver Gaze Zone Estimation Dataset",2020,"","","","",123,"2022-07-13 09:27:29","","10.1109/ICCVW54120.2021.00324","","",,,,,13,6.50,3,5,2,"Labelling of human behavior analysis data is a complex and time consuming task. In this paper, a fully automatic technique for labelling an image based gaze behavior dataset for driver gaze zone estimation is proposed. Domain knowledge is added to the data recording paradigm and later labels are generated in an automatic manner using Speech To Text conversion (STT). In order to remove the noise in the STT process due to different illumination and ethnicity of subjects in our data, the speech frequency and energy are analysed. The resultant Driver Gaze in the Wild (DGW) dataset contains 586 recordings, captured during different times of the day including evenings. The large scale dataset contains 338 subjects with an age range of 18-63 years. As the data is recorded in different lighting conditions, an illumination robust layer is proposed in the Convolutional Neural Network (CNN). The extensive experiments show the variance in the dataset resembling real-world conditions and the effectiveness of the proposed CNN pipeline. The proposed network is also fine-tuned for the eye gaze prediction task, which shows the discriminativeness of the representation learnt by our network on the proposed DGW dataset. Project Page: https://sites.google.com/view/drivergazeprediction/home","",""
24,"Tianyu Kang, W. Ding, Luoyan Zhang, D. Ziemek, Kourosh Zarringhalam","A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data",2017,"","","","",124,"2022-07-13 09:27:29","","10.1186/s12859-017-1984-2","","",,,,,24,4.80,5,5,5,"","",""
2,"Sulaiman Khan, Hazrat Ali, Z. Ullah, N. Minallah, S. Maqsood, Abdul Hafeez","Higher Accurate Recognition of Handwritten Pashto Letters through Zoning Feature by using K-Nearest Neighbour and Artificial Neural Network",2019,"","","","",125,"2022-07-13 09:27:29","","10.14569/IJACSA.2018.091070","","",,,,,2,0.67,0,6,3,"This paper presents a recognition system for handwritten Pashto letters. However, handwritten character recognition is a challenging task. These letters not only differ in shape and style but also vary among individuals. The recognition becomes further daunting due to the lack of standard datasets for inscribed Pashto letters. In this work, we have designed a database of moderate size, which encompasses a total of 4488 images, stemming from 102 distinguishing samples for each of the 44 letters in Pashto. The recognition framework uses zoning feature extractor followed by K-Nearest Neighbour (KNN) and Neural Network (NN) classifiers for classifying individual letter. Based on the evaluation of the proposed system, an overall classification accuracy of approximately 70.05% is achieved by using KNN while 72% is achieved by using NN. Keywords—KNN, deep neural network, OCR, zoning technique, Pashto, character recognition, classification sectionIntroduction In this modern technological and digital age, optical character recognition (OCR) systems play a vital role in machine learning and automatic recognition problems. OCR is a section of software tool that converts printed text and images to machine readable form and enables the machine to recognize images or text like humans. OCR systems are commercially available for isolated languages, which include Chinese, English, Japanese, and others. However, few OCR systems are available for cursive languages such as Persian and Arabic and are not highly robust. To the best of our knowledge, there is no such commercial OCR system available for carved Pashto letters recognition; however, such systems exist in research labs. Handwritten letters recognition is a daunting task mainly because of variations in writing styles of different users. Handwritten letters recognition can be done either offline or online. Online character recognition is simpler and easier to implement due to the temporal based information such as velocity, time, number of strokes, and direction for writing. In addition, the trace of the pen is a few pixels wide so this does not require thinning techniques for classification. On the other hand, offline character recognition system implementation is even laborious due to high variations in writing and font styles of every user. In our paper, we present inscribed of handwritten Pashto letters. Pashto is a major language of Pashtun tribe in Pakistan and the official language of Afghanistan. In censes 2007 2009, it was estimated that about 40 60 millions of people around the world are native speakers of this language. Pashto letters can be shaped into six different formats, which make the recognition process challenging. Furthermore, the count of character dots and occurrence of these dots that varies from letter to letter make the problem challenging. In order to address these problems, research shows the use of high level features based on the structural information of letters. An OCR based system using deep learning network model that incorporates Biand Multi-dimensional long short term memory for printed Pashto text recognition has been suggested [1]. A web-based survey shows that Pashto script contains a huge number of unique ligature [2]. Such ligature makes the implementation of OCR system for carved Pashto challenging. As printed letters contain a constant shape/style and font size; thus, the said technique fails in our case due to higher higher variations in style and font in case of inscribed letters. Riaz et al. [3] has presented the development of an OCR system for cursive Pashto script using scale invariant feature transform and principle component analysis. In order to address this issue, we present a system for handwritten Pashto letters recognition, which has the following key contributions: • As there is no standard handwritten Pashto letters database for testing an algorithm; thus, one of the contribution of this work is to develop and present a medium-sized database of 4488 (102 samples for each letter) for further research work. • The second contribution of this research work is to provide a base result as a benchmark for Pashto language. For this purpose, the performance results of the state-of-the-art classifiers−KNN and deep Neural Network are used based on zoning features. • Our proposed handwritten Pashto letters recognition system is efficient, simple, and cost-effective. • We provide comprehensive results for analyzing the proposed system for handwritten Pashto letters recognition, which may help the researchers to further explore this area. This paper is divided in seven sections: Section I explains the related work. Section II captures the background informawww.ijacsa.thesai.org 1 | P a g e ar X iv :1 90 4. 03 39 1v 1 [ cs .C V ] 6 A pr 2 01 9 (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 9, No. 10, 2018 tion about the classifiers and feature extraction algorithm used in this research work. Section III delineates the methodology. Section IV discusses about the feature extraction, which is very important in the area of pattern recognition and machine learning while section V demonstrates the experimental results followed by the conclusions and future work in Section VI.","",""
3,"Ritabrata Sanyal, K. Chakrabarty","Two Stream Deep Convolutional Neural Network for Eye State Recognition and Blink Detection",2019,"","","","",126,"2022-07-13 09:27:29","","10.1109/IEMENTech48150.2019.8981102","","",,,,,3,1.00,2,2,3,"Eye state recognition and blink detection has been an important research problem in various fields like driver fatigue and drowsiness measurement, dry eye detection, video spoofing detection, psychological status analysis and many others. Hence an automated eye state classification and blink detection algorithm which is robust to a variety of conditions is required for this purpose. To this end, we propose a novel approach towards detection of eye blinks from a video stream by classifying the eye state of every frame as open or closed. First the eyes are localized from a frame with robust state-of-the-art facial landmark detectors. Then binary masks of the eyes are computed to capture and focus on how much the eyes are open. We propose a novel two stream convolutional neural network model which is jointly trained with the extracted eye patches, their masks as inputs and the corresponding eye state as output. With the eye state predicted by our network for every frame, we model a Finite State Machine to check for blinks by comparing number of consecutive frames with eyes closed against average human blink duration. Extensive experimentation has been done on a various number of popular benchmark datasets both for eye state classification and blink detection. Our proposed eye state classifier achieves a 3.2% and 3.86% improvement over the state-of-the-art in terms of accuracy and equal error rate (EER). The blink detector achieves a 1–2 % improvement over the state-of-the-art in terms of precision and recall. Hence our algorithm outperforms the existing methods for eye state classification and blink detection to the best of our knowledge.","",""
1,"Gang Xiang, Ruishi Lin","Robust Anomaly Detection for Multivariate Data of Spacecraft Through Recurrent Neural Networks and Extreme Value Theory",2021,"","","","",127,"2022-07-13 09:27:29","","10.1109/access.2021.3136505","","",,,,,1,1.00,1,2,1,"Spacecraft anomaly detection which could find anomalies in the telemetry or test data in advance and avoid the occurrence of catastrophic failures after taking corresponding measures has elicited the attention of researchers both in academia and aerospace industry. Current spacecraft anomaly detection systems require costly knowledge and human expertise to identify a true anomaly. Moreover, some new problems and challenges such as large volume of test data, imbalanced data distribution and the scarcity of faulty labeled samples have emerged. In this work, we propose an unsupervised anomaly detection algorithm combining Gated Recurrent Unit (GRU) based Recurrent Neural Network (RNN) and Extreme Value Theory (EVT). First, we develop a two-layer ensemble learning based predictor framework which stacks three GRU-based networks with different architectures to learn and capture the normal behavior of multiple channels of data. Then, the prediction errors are calculated and smoothed using Exponentially Weighted Moving Average (EWMA) algorithm. Next, we propose a detection rule setting anomaly threshold automatically through EVT which does not assume any parent distribution on the prediction errors. To the best of our knowledge, it is the first attempt that stacked GRU-based predictors with EVT has been employed into the spacecraft anomaly detection. Through extensive experiments conducted on public datasets as well as real data sampled from a launch vehicle, we show that the proposed detection algorithm is superior to other state-of-the-art anomaly detection approaches in terms of model performance and robustness.","",""
9,"Weiyi Huang, Qiang Qu, Min Yang","Interactive knowledge-enhanced attention network for answer selection",2020,"","","","",128,"2022-07-13 09:27:29","","10.1007/s00521-019-04630-x","","",,,,,9,4.50,3,3,2,"","",""
0,"Farhat Roohi","FUZZY CLUSTERING THROUGH NEURAL NETWORK",2018,"","","","",129,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,4,"Management of data has always been a key concern for scientist, scholars and industry alike. But information explosion due to information and communication technology boom has resulted in a world overloaded with data and information that too growing at an ever increasing exponential rate. Analyzing such big data requires robust techniques to first classify the data so the further analysis reduced to some manageable group of data. This way it becomes systematic and easy. But grouping of data comes at a cost of accuracy and precision of information, as group analysis works on averages and distance between data points within and between clusters is also a cause of concern. Therefore it is imperative to have such data clustering techniques which are fast, able to handle big data and classify data as per the natural logic to facilitate the process of finding knowledge hidden in the data. Fuzzy logic and artificial neural networks are such two concepts which have found increasing application in classification and clustering techniques which have made them more realistic accurate and precise. As such, apart from data clustering, neurofuzzy methodology is widely used in data mining, artificial intelligence, image recognition, knowledge management, control processes, etc. Neurofuzzy methodology performs better in terms finding sequences, associations and patterns in data besides having quick self-learning capability almost comparable to human intelligence. Against this backdrop the current paper attempts to create a conceptual understanding of neurofuzzy methodology and its application to data clustering.","",""
8,"Andrea E. Frank, A. Kubota, L. Riek","Wearable activity recognition for robust human-robot teaming in safety-critical environments via hybrid neural networks",2019,"","","","",130,"2022-07-13 09:27:29","","10.1109/IROS40897.2019.8968615","","",,,,,8,2.67,3,3,3,"In this work, we present a novel non-visual HAR system that achieves state-of-the-art performance on realistic SCE tasks via a single wearable sensor. We leverage surface electromyography and inertial data from a low-profile wearable sensor to attain performant robot perception while remaining unobtrusive and user-friendly. By capturing both convolutional and temporal features with a hybrid CNN-LSTM classifier, our system is able to robustly and effectively classify complex, full-body human activities with only this single sensor. We perform a rigorous analysis of our method on two datasets representative of SCE tasks, and compare performance with several prominent HAR algorithms. Results show our system substantially outperforms rival algorithms in identifying complex human tasks from minimal sensing hardware, achieving F1-scores up to 84% over 31 strenuous activity classes. To our knowledge, we are the first to robustly identify complex full-body tasks using a single, unobtrusive sensor feasible for real-world use in SCEs. Using our approach, robots will be able to more reliably understand human activity, enabling them to safely navigate sensitive, crowded spaces.","",""
95,"R. Savitha, S. Sundaram, N. Sundararajan","Metacognitive Learning in a Fully Complex-Valued Radial Basis Function Neural Network",2012,"","","","",131,"2022-07-13 09:27:29","","10.1162/NECO_a_00254","","",,,,,95,9.50,32,3,10,"Recent studies on human learning reveal that self-regulated learning in a metacognitive framework is the best strategy for efficient learning. As the machine learning algorithms are inspired by the principles of human learning, one needs to incorporate the concept of metacognition to develop efficient machine learning algorithms. In this letter we present a metacognitive learning framework that controls the learning process of a fully complex-valued radial basis function network and is referred to as a metacognitive fully complex-valued radial basis function (Mc-FCRBF) network. Mc-FCRBF has two components: a cognitive component containing the FC-RBF network and a metacognitive component, which regulates the learning process of FC-RBF. In every epoch, when a sample is presented to Mc-FCRBF, the metacognitive component decides what to learn, when to learn, and how to learn based on the knowledge acquired by the FC-RBF network and the new information contained in the sample. The Mc-FCRBF learning algorithm is described in detail, and both its approximation and classification abilities are evaluated using a set of benchmark and practical problems. Performance results indicate the superior approximation and classification performance of Mc-FCRBF compared to existing methods in the literature.","",""
1,"J. Constantin, A. Bigand, I. Constantin","Pooling spike neural network for fast rendering in global illumination",2019,"","","","",132,"2022-07-13 09:27:29","","10.1007/s00521-018-3941-z","","",,,,,1,0.33,0,3,3,"","",""
0,"Liu Yuezhang, Bo Li, Qifeng Chen","Evaluating adversarial robustness in simulated cerebellum",2020,"","","","",133,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,3,2,"It is well known that artificial neural networks are vulnerable to adversarial examples, in which great efforts have been made to improve the robustness. However, such examples are usually imperceptible to humans, thus their effect on biological neural circuits is largely unknown. This paper will investigate the adversarial robustness in a simulated cerebellum, a well-studied supervised learning system in computational neuroscience. Specifically, we propose to study three unique characteristics revealed in the cerebellum: (i) network width; (ii) long-term depression on the parallel fiber-Purkinje cell synapses; (iii) sparse connectivity in the granule layer, and hypothesize that they will be beneficial for improving robustness. To the best of our knowledge, this is the first attempt to examine the adversarial robustness in simulated cerebellum models. We wish to remark that both of the positive and negative results are indeed meaningful -- if the answer is in the affirmative, engineering insights are gained from the biological model into designing more robust learning systems; otherwise, neuroscientists are encouraged to fool the biological system in experiments with adversarial attacks -- which makes the project especially suitable for a pre-registration study.","",""
92,"Lang Chen, M. L. Ralph, T. Rogers","A unified model of human semantic knowledge and its disorders",2017,"","","","",134,"2022-07-13 09:27:29","","10.1038/s41562-016-0039","","",,,,,92,18.40,31,3,5,"","",""
31,"S. Kosbatwar","Pattern Association For Character Recognition By Back-Propagation Algorithm Using Neural Network Approach",2012,"","","","",135,"2022-07-13 09:27:29","","10.5121/IJCSES.2012.3112","","",,,,,31,3.10,31,1,10,"The use of artificial neural network in applications can dramatically simplify the code and improve quality of recognition while achieving good performance. Another benefit of using neural network in application is extensibility of the system – ability to recognize more character sets than initially defined. Most of traditional systems are not extensible enough. In this paper recognition of characters is possible by using neural network back propagation algorithm. What is neural network Neural network are simplified models of the biological nervous system and therefore have drawn their motivation from the kind of computing performed by a human brain. An NN in general is a highly interconnected of a large number of processing elements called neurons in an architecture inspired by the brain. An NN can be massively parallel and therefore is said to exhibit parallel distributed processing. Neural Network exhibits characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, and parallel and high speed information processing. Neural network learn by example. They can therefore be trained with known examples of a problem to acquire knowledge about it. Once appropriate trained the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. Neural network adopt various learning mechanism of which supervised learning and unsupervised learning methods have turned out to be very popular. In supervised learning, a teacher is assumed to be present during the learning process, i.e. the network aims to minimize he error between target (desired) output presented by the teacher and the computed output to achieve better performance. However, in unsupervised learning, there is no teacher present to hand over the desired output and the network therefore tries to learn by itself, organizing the input instances of the problem.NN Architecture has been broadly classified as single layer feed forward networks, multilayer feed forward networks and recurrent networks, over the year several other NN.Architecture have evolved .some of the well known NN system include backpropogation network, perceptron, ADALINE ,Boltzmann machine ,adaptive resonance theory, Self-organized feature map, and Hopfield network. Neural Network has been successfully applied to problem in the field of pattern recognition, image processing, data compression, forecasting and optimization to quote a few. International Journal of Computer Science & Engineering Survey (IJCSES) Vol.3, No.1, February 2012 128 Backpropagation algorithm The architecture of the neural network is the one of a basically backpropagation network with only one hidden layer (although it is the same techniques with more layers). The input layer is constituted of 35 neuron (one per input pixel in the matrix, of course)., they are 8 hidden neurons, and 26 output neurons(one per letter) in this problem domain of character recognition. The weight matrix gives the weight factor for each input of each neuron. These matrices are what we can call the memory of the neural network. The learning process is done by adjusting these weight so that for each given input the output is as near as possible of a wanted output (Here the full activation of the output neuron corresponding to the character to be recognized) [1]. The training patterns are applied in some random order one by one, and the weights are adjusted using the backpropagation learning law. Each application of the training set patterns is called a cycle. The patterns have to be applied for several training cycles to obtain the output error to an acceptable low value. Once the network is trained, it can be used to recall the appropriate pattern for a new input pattern. The computation for recall is straightforward, in the sense that the weights and the output functions of the units in different layers are used to compute the activation values and the output signals. The signals from the output layer correspond to the output[2]. Backpropagation learning emerged as the most significant result in the field of artificial neural networks. The backpropagation learning involves propagation of the error backwards from the output layer to the hidden layers in order to determine the update for the weights leading to the units in a hidden layer. The error at the output layer itself is computed using the difference between the desired output and the actual output at each of the output units. The actual output for a given input training pattern is determined by computing the outputs of units for each hidden layer in the forward pass of the input data. The error in the output is propagated backwards only to determine the weight updates [6].","",""
0,"Lige Yang, Liping Zheng, Lijuan Zheng","Research on Extraction of Human Information Entity Relationship Based on Improved Capsule Network",2020,"","","","",136,"2022-07-13 09:27:29","","10.1109/IWECAI50956.2020.00015","","",,,,,0,0.00,0,3,2,"Entity relation extraction is to learn the implicit semantic relations among entities from multiple entities of a single sentence. Extracting entity relationships from unstructured text information is a key step in building large-scale knowledge map, optimizing personalized search, machine translation and intelligent Q & A. At present, the more popular depth model of entity relationship extraction has a better effect on the relationship extraction of single entity pair, but the evaluation index data of the model is not high when it is extended to the situation of single sentence multi entity pair and document level complex semantics. In this paper, an improved capsule network model based on dynamic routing rules is introduced, and it is applied to the relationship extraction of multi entity pairs of unstructured human information in the field of literature. The capsule network uses the route iteration method to connect the capsules between different hidden layers, which makes the capsule network establish the position relationship between different features in the routing process. Therefore, the capsule network is more robust to the position and angle changes of the target than other neural networks, so as to avoid the loss of information. In the experiment, we use the improved capsule network model, transformer and CNN model to extract the entity relationship of human information. The experimental results show that the improved capsule network model can achieve high accuracy, recall rate and F1 value in the multi entity pair relation extraction of small language database in the field of literature.","",""
2,"Fang Wan, Chaoyang Song","Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs",2017,"","","","",137,"2022-07-13 09:27:29","","10.3389/frobt.2018.00086","","",,,,,2,0.40,1,2,5,"The human reasoning process is seldom a one-way process from an input leading to an output. Instead, it often involves a systematic deduction by ruling out other possible outcomes as a self-checking mechanism. In this paper, we describe the design of a hybrid neural network for logical learning that is similar to the human reasoning through the introduction of an auxiliary input, namely the indicators, that act as the hints to suggest logical outcomes. We generate these indicators by digging into the hidden information buried underneath the original training data for direct or indirect suggestions. We used the MNIST data to demonstrate the design and use of these indicators in a convolutional neural network. We trained a series of such hybrid neural networks with variations of the indicators. Our results show that these hybrid neural networks are very robust in generating logical outcomes with inherently higher prediction accuracy than the direct use of the original input and output in apparent models. Such improved predictability with reassured logical confidence is obtained through the exhaustion of all possible indicators to rule out all illogical outcomes, which is not available in the apparent models. Our logical learning process can effectively cope with the unknown unknowns using a full exploitation of all existing knowledge available for learning. The design and implementation of the hints, namely the indicators, become an essential part of artificial intelligence for logical learning. We also introduce an ongoing application setup for this hybrid neural network in an autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized grasping pose through logical learning.","",""
10,"Y. Alparslan, Jeremy Keim-Shenk, S. Khade, R. Greenstadt","Adversarial Attacks on Convolutional Neural Networks in Facial Recognition Domain",2020,"","","","",138,"2022-07-13 09:27:29","","","","",,,,,10,5.00,3,4,2,"Numerous recent studies have demonstrated how Deep Neural Network (DNN) classifiers can be fooled by adversarial examples, in which an attacker adds perturbations to an original sample, causing the classifier to misclassify the sample. Adversarial attacks that render DNNs vulnerable in real life represent a serious threat, given the consequences of improperly functioning autonomous vehicles, malware filters, or biometric authentication systems. In this paper, we apply Fast Gradient Sign Method to introduce perturbations to a facial image dataset and then test the output on a different classifier that we trained ourselves, to analyze transferability of this method. Next, we craft a variety of different attack algorithms on a facial image dataset, with the intention of developing untargeted black-box approaches assuming minimal adversarial knowledge, to further assess the robustness of DNNs in the facial recognition realm. We explore modifying single optimal pixels by a large amount, or modifying all pixels by a smaller amount, or combining these two attack approaches. While our single-pixel attacks achieved about a 15% average decrease in classifier confidence level for the actual class, the all-pixel attacks were more successful and achieved up to an 84% average decrease in confidence, along with an 81.6% misclassification rate, in the case of the attack that we tested with the highest levels of perturbation. Even with these high levels of perturbation, the face images remained fairly clearly identifiable to a human. We hope our research may help to advance the study of adversarial attacks on DNNs and defensive mechanisms to counteract them, particularly in the facial recognition domain.","",""
0,"M. Gregurić, S. Mandzuka, E. Ivanjko","Knowledge Integration by Using Adaptive Neural- fuzzy Networks for Ramp Metering",2018,"","","","",139,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,3,4,"An Adaptive Neuro-Fuzzy Inference System (ANFIS) is a neural network-based fuzzy inference system that includes combination of two soft-computing methods: Artificial Neural Networks (ANN) and fuzzy logic [1] Fuzzy logic has the ability to transform the qualitative aspects of human knowledge and insights into the process of precise quantitative analysis [2]. However, it is very problematic to transform the human thought into a rule based Fuzzy Inference System (FIS), and adequately adjust Membership Functions (MFs) of the mentioned FIS. ANFIS uses ANN’s ability of self-adaptation to the environment through the machine learning process in order to automatically adjust the MFs, and reduce the rate of errors in the determination of rules in FIS [2]. Fuzzy logic based approaches such as FIS are often used for ramp metering. Ramp metering as one of the control methods for urban motorways is formulated as the regulation of the on-ramp flow access rate into the motorway mainstream according to the several inputs. Most ramp metering algorithms based on fuzzy logic require a robust and comprehensive approach for adjusting of the FIS rule base and MFs in a complex non-linear environments such as the urban motorway traffic system.","",""
2,"Bang Wu, Chengqi Ma, S. Poslad, D. Selviah","An Adaptive Human Activity-Aided Hand-Held Smartphone-Based Pedestrian Dead Reckoning Positioning System",2021,"","","","",140,"2022-07-13 09:27:29","","10.3390/rs13112137","","",,,,,2,2.00,1,4,1,"Pedestrian dead reckoning (PDR), enabled by smartphones’ embedded inertial sensors, is widely applied as a type of indoor positioning system (IPS). However, traditional PDR faces two challenges to improve its accuracy: lack of robustness for different PDR-related human activities and positioning error accumulation over elapsed time. To cope with these issues, we propose a novel adaptive human activity-aided PDR (HAA-PDR) IPS that consists of two main parts, human activity recognition (HAR) and PDR optimization. (1) For HAR, eight different locomotion-related activities are divided into two classes: steady-heading activities (ascending/descending stairs, stationary, normal walking, stationary stepping, and lateral walking) and non-steady-heading activities (door opening and turning). A hierarchical combination of a support vector machine (SVM) and decision tree (DT) is used to recognize steady-heading activities. An autoencoder-based deep neural network (DNN) and a heading range-based method to recognize door opening and turning, respectively. The overall HAR accuracy is over 98.44%. (2) For optimization methods, a process automatically sets the parameters of the PDR differently for different activities to enhance step counting and step length estimation. Furthermore, a method of trajectory optimization mitigates PDR error accumulation utilizing the non-steady-heading activities. We divided the trajectory into small segments and reconstructed it after targeted optimization of each segment. Our method does not use any a priori knowledge of the building layout, plan, or map. Finally, the mean positioning error of our HAA-PDR in a multilevel building is 1.79 m, which is a significant improvement in accuracy compared with a baseline state-of-the-art PDR system.","",""
4,"H. A. Lafta, Z. Hassan","A Hybrid System Geno-Fuzzified Neural Network for Mobile Robot Control",2013,"","","","",141,"2022-07-13 09:27:29","","10.9734/BJMCS/2013/4587","","",,,,,4,0.44,2,2,9,"Aims: The goal of mobile robot is build system able to achieve tasks without human intervention in cluttered unknown environments. A main issue of an autonomous mobile robot is the design of an intelligent controller which enables the robot to navigate in a real world environment and avoiding obstacles especially in crowded and changing environment. Study Design: The controller uses genetic, fuzzy and neural to control of mobile robot. Place and Duration of Study: College Science, computer department, between September 2011 and December 2012. Methodology: In this search, fuzzy logic, genetic algorithm, and neural network (soft computing) are used to design an intelligent controller. This is due to the fact that fuzzy if-then rules are well suited for capturing the imprecise nature of human knowledge and reasoning processes. On the other hand, the neural networks are equipped for learning. Genetic algorithm has active role in the generating of fuzzy rules, it is designed to minimize the number of rules to minimum number. It is also helped to improve membership functions. Neural network is trained by using back propagation to increase efficiency of the work in time of arrive and get the shortest path to goal, it is obtained the steer angle of robot to the appropriate direction (avoid obstacles or get target). Results: The efficiency and robust of this work is appeared by using many different unknown environments that have different numbers, sizes and shapes of obstacles. The controller enables robot to avoid obstacles and reach goal with shortest distance (757 pixels) compared with other techniques(fuzzy controller and neuro-fuzzy controller),which owns the largest distance from same start position to the same end position and also less time(14 seconds). Conclusion: Geno – fuzzified – neural controller is efficient with different numbers, shapes, sizes of obstacles in unknown environments.","",""
480,"S. Bosse, D. Maniry, K. Müller, T. Wiegand, W. Samek","Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment",2016,"","","","",142,"2022-07-13 09:27:29","","10.1109/TIP.2017.2760518","","",,,,,480,80.00,96,5,6,"We present a deep neural network-based approach to image quality assessment (IQA). The network is trained end-to-end and comprises ten convolutional layers and five pooling layers for feature extraction, and two fully connected layers for regression, which makes it significantly deeper than related IQA models. Unique features of the proposed architecture are that: 1) with slight adaptations it can be used in a no-reference (NR) as well as in a full-reference (FR) IQA setting and 2) it allows for joint learning of local quality and local weights, i.e., relative importance of local quality to the global quality estimate, in an unified framework. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. We evaluate the proposed approach on the LIVE, CISQ, and TID2013 databases as well as the LIVE In the wild image quality challenge database and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different databases, indicating a high robustness of the learned features.","",""
12454,"Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun","Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",2015,"","","","",143,"2022-07-13 09:27:29","","10.1109/ICCV.2015.123","","",,,,,12454,1779.14,3114,4,7,"Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.","",""
7,"F. Lareyre, C. Adam, M. Carrier, J. Raffort","Automated Segmentation of the Human Abdominal Vascular System Using a Hybrid Approach Combining Expert System and Supervised Deep Learning",2021,"","","","",144,"2022-07-13 09:27:29","","10.3390/jcm10153347","","",,,,,7,7.00,2,4,1,"Background: Computed tomography angiography (CTA) is one of the most commonly used imaging technique for the management of vascular diseases. Here, we aimed to develop a hybrid method combining a feature-based expert system with a supervised deep learning (DL) algorithm to enable a fully automatic segmentation of the abdominal vascular tree. Methods: We proposed an algorithm based on the hybridization of a data-driven convolutional neural network and a knowledge-based model dedicated to vascular system segmentation. By using two distinct datasets of CTA from patients to evaluate independence to training dataset, the accuracy of the hybrid method for lumen and thrombus segmentation was evaluated compared to the feature-based expert system alone and to the ground truth provided by a human expert. Results: The hybrid approach demonstrated a better accuracy for lumen segmentation compared to the expert system alone (volume similarity: 0.8128 vs. 0.7912, p = 0.0006 and Dice similarity coefficient: 0.8266 vs. 0.7942, p < 0.0001). The accuracy for thrombus segmentation was also enhanced using the hybrid approach (volume similarity: 0.9404 vs. 0.9185, p = 0.0027 and Dice similarity coefficient: 0.8918 vs. 0.8654, p < 0.0001). Conclusions: By enabling a robust and fully automatic segmentation, the method could be used to develop real-time decision support to help in the management of vascular diseases.","",""
13,"R. del Amor, Sandra Morales, Adrián Colomer, M. Mogensen, Mikkel Jensen, N. Israelsen, O. Bang, V. Naranjo","Automatic Segmentation of Epidermis and Hair Follicles in Optical Coherence Tomography Images of Normal Skin by Convolutional Neural Networks",2020,"","","","",145,"2022-07-13 09:27:29","","10.3389/fmed.2020.00220","","",,,,,13,6.50,2,8,2,"Optical coherence tomography (OCT) is a well-established bedside imaging modality that allows analysis of skin structures in a non-invasive way. Automated OCT analysis of skin layers is of great relevance to study dermatological diseases. In this paper, an approach to detect the epidermal layer along with the follicular structures in healthy human OCT images is presented. To the best of the authors' knowledge, the approach presented in this paper is the only epidermis detection algorithm that segments the pilosebaceous unit, which is of importance in the progression of several skin disorders such as folliculitis, acne, lupus erythematosus, and basal cell carcinoma. The proposed approach is composed of two main stages. The first stage is a Convolutional Neural Network based on U-Net architecture. The second stage is a robust post-processing composed by a Savitzky-Golay filter and Fourier Domain Filtering to fully define the borders belonging to the hair follicles. After validation, an average Dice of 0.83 ± 0.06 and a thickness error of 10.25 μm is obtained on 270 human skin OCT images. Based on these results, the proposed method outperforms other state-of-the-art methods for epidermis segmentation. It demonstrates that the proposed image segmentation method successfully detects the epidermal region in a fully automatic way in addition to defining the follicular skin structures as main novelty.","",""
6,"Changhao Chen, Chris Xiaoxuan Lu, Bing Wang, A. Trigoni, A. Markham","DynaNet: Neural Kalman Dynamical Model for Motion Estimation and Prediction",2019,"","","","",146,"2022-07-13 09:27:29","","10.1109/TNNLS.2021.3112460","","",,,,,6,2.00,1,5,3,"Dynamical models estimate and predict the temporal evolution of physical systems. State-space models (SSMs) in particular represent the system dynamics with many desirable properties, such as being able to model uncertainty in both the model and measurements, and optimal (in the Bayesian sense) recursive formulations, e.g., the Kalman filter. However, they require significant domain knowledge to derive the parametric form and considerable hand tuning to correctly set all the parameters. Data-driven techniques, e.g., recurrent neural networks, have emerged as compelling alternatives to SSMs with wide success across a number of challenging tasks, in part due to their impressive capability to extract relevant features from rich inputs. They, however, lack interpretability and robustness to unseen conditions. Thus, data-driven models are hard to be applied in safety-critical applications, such as self-driving vehicles. In this work, we present DynaNet, a hybrid deep learning and time-varying SSM, which can be trained end-to-end. Our neural Kalman dynamical model allows us to exploit the relative merits of both SSM and deep neural networks. We demonstrate its effectiveness in the estimation and prediction on a number of physically challenging tasks, including visual odometry, sensor fusion for visual-inertial navigation, and motion prediction. In addition, we show how DynaNet can indicate failures through investigation of properties, such as the rate of innovation (Kalman gain).","",""
0,"Jumi Kalita, K. K. Sarma, P. Sarmah","Classification of Child Disability Using Artificial Neural Network",2014,"","","","",147,"2022-07-13 09:27:29","","10.1007/978-3-319-01285-8_6","","",,,,,0,0.00,0,3,8,"","",""
15,"S. Pathan","Pattern Association for character recognition by Back-Propagation algorithm using Neural Network approach",2012,"","","","",148,"2022-07-13 09:27:29","","","","",,,,,15,1.50,15,1,10,"The use of artificial neural network in applications can dramatically simplify the code and improve quality of recognition while achieving good performance. Another benefit of using neural network in application is extensibility of the system – ability to recognize more character sets than initially defined. Most of traditional systems are not extensible enough. In this paper recognition of characters is possible by using neural network back propagation algorithm. What is neural network Neural network are simplified models of the biological nervous system and therefore have drawn their motivation from the kind of computing performed by a human brain. An NN in general is a highly interconnected of a large number of processing elements called neurons in an architecture inspired by the brain. An NN can be massively parallel and therefore is said to exhibit parallel distributed processing. Neural Network exhibits characteristics such as mapping capabilities or pattern association, generalization, robustness, fault tolerance, and parallel and high speed information processing. Neural network learn by example. They can therefore be trained with known examples of a problem to acquire knowledge about it. Once appropriate trained the network can be put to effective use in solving ‘unknown’ or ‘untrained’ instances of the problem. Neural network adopt various learning mechanism of which supervised learning and unsupervised learning methods have turned out to be very popular. In supervised learning, a teacher is assumed to be present during the learning process, i.e. the network aims to minimize he error between target (desired) output presented by the teacher and the computed output to achieve better performance. However, in unsupervised learning, there is no teacher present to hand over the desired output and the network therefore tries to learn by itself, organizing the input instances of the problem.NN Architecture has been broadly classified as single layer feed forward networks, multilayer feed forward networks and recurrent networks, over the year several other NN.Architecture have evolved .some of the well known NN system include backpropogation network, perceptron, ADALINE ,Boltzmann machine ,adaptive resonance theory, Self-organized feature map, and Hopfield network. Neural Network has been successfully applied to problem in the field of pattern recognition, image processing, data compression, forecasting and optimization to quote a few.","",""
0,"Georgios Ioannides, Ioannis Kourouklides, A. Astolfi","Spatiotemporal dynamics in spiking recurrent neural networks using modified-full-FORCE on EEG signals",2021,"","","","",149,"2022-07-13 09:27:29","","10.1038/s41598-022-06573-1","","",,,,,0,0.00,0,3,1,"","",""
11,"Gamal K. O. Crichton, Simon Baker, Yufan Guo, A. Korhonen","Neural networks for open and closed Literature-based Discovery",2020,"","","","",150,"2022-07-13 09:27:29","","10.1371/journal.pone.0232891","","",,,,,11,5.50,3,4,2,"Literature-based Discovery (LBD) aims to discover new knowledge automatically from large collections of literature. Scientific literature is growing at an exponential rate, making it difficult for researchers to stay current in their discipline and easy to miss knowledge necessary to advance their research. LBD can facilitate hypothesis testing and generation and thus accelerate scientific progress. Neural networks have demonstrated improved performance on LBD-related tasks but are yet to be applied to it. We propose four graph-based, neural network methods to perform open and closed LBD. We compared our methods with those used by the state-of-the-art LION LBD system on the same evaluations to replicate recently published findings in cancer biology. We also applied them to a time-sliced dataset of human-curated peer-reviewed biological interactions. These evaluations and the metrics they employ represent performance on real-world knowledge advances and are thus robust indicators of approach efficacy. In the first experiments, our best methods performed 2-4 times better than the baselines in closed discovery and 2-3 times better in open discovery. In the second, our best methods performed almost 2 times better than the baselines in open discovery. These results are strong indications that neural LBD is potentially a very effective approach for generating new scientific discoveries from existing literature. The code for our models and other information can be found at: https://github.com/cambridgeltl/nn_for_LBD.","",""
25,"A. Vessoni, R. Herai, Jerome V. Karpiak, Angelica M S Leal, C. Trujillo, A. Quinet, L. F. Agnez Lima, C. Menck, A. Muotri","Cockayne syndrome-derived neurons display reduced synapse density and altered neural network synchrony.",2016,"","","","",151,"2022-07-13 09:27:29","","10.1093/hmg/ddw008","","",,,,,25,4.17,3,9,6,"Cockayne syndrome (CS) is a rare genetic disorder in which 80% of cases are caused by mutations in the Excision Repair Cross-Complementation group 6 gene (ERCC6). The encoded ERCC6 protein is more commonly referred to as Cockayne Syndrome B protein (CSB). Classical symptoms of CS patients include failure to thrive and a severe neuropathology characterized by microcephaly, hypomyelination, calcification and neuronal loss. Modeling the neurological aspect of this disease has proven difficult since murine models fail to mirror classical neurological symptoms. Therefore, a robust human in vitro cellular model would advance our fundamental understanding of the disease and reveal potential therapeutic targets. Herein, we successfully derived functional CS neural networks from human CS induced pluripotent stem cells (iPSCs) providing a new tool to facilitate studying this devastating disease. We identified dysregulation of the Growth Hormone/Insulin-like Growth Factor-1 (GH/IGF-1) pathway as well as pathways related to synapse formation, maintenance and neuronal differentiation in CSB neurons using unbiased RNA-seq gene expression analyses. Moreover, when compared to unaffected controls, CSB-deficient neural networks displayed altered electrophysiological activity, including decreased synchrony, and reduced synapse density. Collectively, our work reveals that CSB is required for normal neuronal function and we have established an alternative to previously available models to further study neural-specific aspects of CS.","",""
3,"Zachary A. Daniels, Logan Frank, Christopher Menart, M. Raymer, P. Hitzler","A framework for explainable deep neural models using external knowledge graphs",2020,"","","","",152,"2022-07-13 09:27:29","","10.1117/12.2558083","","",,,,,3,1.50,1,5,2,"Deep neural networks (DNNs) have become the gold standard for solving challenging classification problems, especially given complex sensor inputs (e.g., images and video). While DNNs are powerful, they are also brittle, and their inner workings are not fully understood by humans, leading to their use as “black-box” models. DNNs often generalize poorly when provided new data sampled from slightly shifted distributions; DNNs are easily manipulated by adversarial examples; and the decision-making process of DNNs can be difficult for humans to interpret. To address these challenges, we propose integrating DNNs with external sources of semantic knowledge. Large quantities of meaningful, formalized knowledge are available in knowledge graphs and other databases, many of which are publicly obtainable. But at present, these sources are inaccessible to deep neural methods, which can only exploit patterns in the signals they are given to classify. In this work, we conduct experiments on the ADE20K dataset, using scene classification as an example task where combining DNNs with external knowledge graphs can result in more robust and explainable models. We align the atomic concepts present in ADE20K (i.e., objects) to WordNet, a hierarchically-organized lexical database. Using this knowledge graph, we expand the concept categories which can be identified in ADE20K and relate these concepts in a hierarchical manner. The neural architecture we present performs scene classification using these concepts, illuminating a path toward DNNs which can efficiently exploit high-level knowledge in place of excessive quantities of direct sensory input. We hypothesize and experimentally validate that incorporating background knowledge via an external knowledge graph into a deep learning-based model should improve the explainability and robustness of the model.","",""
161,"A. Bhagoji, Daniel Cullina, Chawin Sitawarin, Prateek Mittal","Enhancing robustness of machine learning systems via data transformations",2017,"","","","",153,"2022-07-13 09:27:29","","10.1109/CISS.2018.8362326","","",,,,,161,32.20,40,4,5,"We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification.","",""
3,"M. K. Ebrahimpour, J. Falandays, S. Spevack, Ming-Hsuan Yang, D. Noelle","WW-Nets: Dual Neural Networks for Object Detection",2020,"","","","",154,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207407","","",,,,,3,1.50,1,5,2,"We propose a new deep convolutional neural network framework that uses object location knowledge implicit in network connection weights to guide selective attention in object detection tasks. Our approach is called What-Where Nets (WW-Nets), and it is inspired by the structure of human visual pathways. In the brain, vision incorporates two separate streams, one in the temporal lobe and the other in the parietal lobe, called the ventral stream and the dorsal stream, respectively. The ventral pathway from primary visual cortex is dominated by ""what"" information, while the dorsal pathway is dominated by ""where"" information. Inspired by this structure, we have proposed an object detection framework involving the integration of a ""What Network"" and a ""Where Network"". The aim of the What Network is to provide selective attention to the relevant parts of the input image. The Where Network uses this information to locate and classify objects of interest. In this paper, we compare this approach to state-of-the-art algorithms on the PASCAL VOC 2007 and 2012 and COCO object detection challenge datasets. Also, we compare out approach to human ""ground-truth"" attention. We report the results of an eye-tracking experiment on human subjects using images from PASCAL VOC 2007, and we demonstrate interesting relationships between human overt attention and information processing in our WW-Nets. Finally, we provide evidence that our proposed method performs favorably in comparison to other object detection approaches, often by a large margin. The code and the eye-tracking ground-truth dataset can be found at: https://github.com/mkebrahimpour.","",""
13,"Asuka Terai, Masanori Nakagawa","A Neural Network Model of Metaphor Understanding with Dynamic Interaction Based on a Statistical Language Analysis: Targeting a Human-Like Model",2007,"","","","",155,"2022-07-13 09:27:29","","10.1142/S0129065707001123","","",,,,,13,0.87,7,2,15,"The purpose of this paper is to construct a model that represents the human process of understanding metaphors, focusing specifically on similes of the form an ""A like B"". Generally speaking, human beings are able to generate and understand many sorts of metaphors. This study constructs the model based on a probabilistic knowledge structure for concepts which is computed from a statistical analysis of a large-scale corpus. Consequently, this model is able to cover the many kinds of metaphors that human beings can generate. Moreover, the model implements the dynamic process of metaphor understanding by using a neural network with dynamic interactions. Finally, the validity of the model is confirmed by comparing model simulations with the results from a psychological experiment.","",""
2,"Yue Hu, Budhitama Subagdja, A. Tan, Quanjun Yin","Vision-Based Topological Mapping and Navigation With Self-Organizing Neural Networks.",2021,"","","","",156,"2022-07-13 09:27:29","","10.1109/TNNLS.2021.3084212","","",,,,,2,2.00,1,4,1,"Spatial mapping and navigation are critical cognitive functions of autonomous agents, enabling one to learn an internal representation of an environment and move through space with real-time sensory inputs, such as visual observations. Existing models for vision-based mapping and navigation, however, suffer from memory requirements that increase linearly with exploration duration and indirect path following behaviors. This article presents e-TM, a self-organizing neural network-based framework for incremental topological mapping and navigation. e-TM models the exploration trajectories explicitly as episodic memory, wherein salient landmarks are sequentially extracted as ``events'' from streaming observations. A memory consolidation procedure then performs a playback mechanism and transfers the embedded knowledge of the environmental layout into spatial memory, encoding topological relations between landmarks. Fusion adaptive resonance theory (ART) networks, as the building block of the two memory modules, can generalize multiple input patterns into memory templates and, therefore, provide a compact spatial representation and support the discovery of novel shortcuts through inferences. For navigation, e-TM applies a transfer learning paradigm to integrate human demonstrations into a pretrained locomotion network for smoother movements. Experimental results based on VizDoom, a simulated 3-D environment, have shown that, compared to semiparametric topological memory (SPTM), a state-of-the-art model, e-TM reduces the time costs of navigation significantly while learning much sparser topological graphs.","",""
18,"Claudio Ciancio, G. Ambrogio, F. Gagliardi, R. Musmanno","Heuristic techniques to optimize neural network architecture in manufacturing applications",2016,"","","","",157,"2022-07-13 09:27:29","","10.1007/s00521-015-1994-9","","",,,,,18,3.00,5,4,6,"","",""
11,"I. Salgado, I. Chairez","Adaptive Unknown Input Estimation by Sliding Modes and Differential Neural Network Observer",2018,"","","","",158,"2022-07-13 09:27:29","","10.1109/TNNLS.2017.2730847","","",,,,,11,2.75,6,2,4,"In this paper, a differential neural network (DNN) implemented as a robust observer estimates the dynamics of perturbed uncertain nonlinear systems affected by exogenous unknown inputs. In the first stage, the identification error converges into a neighborhood around the origin. Then, the second-order sliding mode supertwisting algorithm implemented as a robust exact differentiator reconstructed the unknown inputs. The approach proposed in this paper can be applied in the case of full access to the state vector (identification problem) and in the case of partial access to the state vector (estimation problem). In the second case, the nonlinear system under study must have well-defined full relative degree with respect to the unknown input. Numerical examples showed the effectiveness of the proposed algorithm. The first example tested the DNN working as an identifier into a mathematical model describing the dynamics of a spatial minisatellite. The second example (with a DNN implemented as an observer) tested the methodology of this paper over a single link flexible robot manipulator represented in a canonical (Brunovsky) form. In both examples, the mathematical models served as data generators in the testing of the neural networks. Even when not exact mathematical description of both models was used in the input estimation, the accuracy obtained with the DNN is comparable with the case of applying a high-order differentiator with complete knowledge of the plant.","",""
11,"Timothée Lesort, Mathieu Seurin, Xinrui Li, Natalia Díaz Rodríguez, David Filliat","Deep unsupervised state representation learning with robotic priors: a robustness analysis",2019,"","","","",159,"2022-07-13 09:27:29","","10.1109/IJCNN.2019.8852042","","",,,,,11,3.67,2,5,3,"Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation metric of the learned representation that uses nearest neighbors in the state space and allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset.","",""
0,"Meng Yang, Haiping Huang, Lichao Huang, Nan Zhang, Jihong Wu, Huanming Yang, F. Mu","LOGO, a contextualized pre-trained language model of human genome flexibly adapts to various downstream tasks by fine-tuning",2021,"","","","",160,"2022-07-13 09:27:29","","10.21203/rs.3.rs-448927/v1","","",,,,,0,0.00,0,7,1,"  Interpretation of non-coding genome remains an unsolved challenge in human genetics due to impracticality of exhaustively annotate biochemically active elements in all conditions. Deep learning based computational approaches emerge recently to help interpretating non-coding regions. Here we present LOGO (Language of Genome), a self-attention based contextualized pre-trained language model that applies self-supervision techniques to learn bidirectional representations of unlabeled human reference genome and extend to a series of downstream tasks via fine-tuning. We also explore a novel knowledge embedded version of LOGO to incorporate prior human annotations. Experiments show that LOGO achieves 15% absolute improvement for promoter identification and up to 4.5% absolute improvement for enhancer-promoter interaction prediction. LOGO exhibits state-of-the-art predictive power on chromatin features with only 3% parameterization against fully supervised convolutional neural network, DeepSEA. Fine-tuned LOGO also shows outstanding performance in prioritizing non-coding variants associated with human diseases. In addition, we apply LOGO to interpret type 2 diabetes (T2D) GWAS signals and infer underlying regulatory mechanisms. We make a conceptual analogy between natural language and human genome and demonstrate LOGO is an accurate, fast, scalable, and robust framework with powerful adaptability to various tasks without substantial task-specific architecture modifications.","",""
6,"M. Akhlaghi, Sergey V. Sukhov","Knowledge Fusion in Feedforward Artificial Neural Networks",2018,"","","","",161,"2022-07-13 09:27:29","","10.1007/s11063-017-9712-5","","",,,,,6,1.50,3,2,4,"","",""
65,"D. Zugner, Stephan Gunnemann","Certifiable Robustness and Robust Training for Graph Convolutional Networks",2019,"","","","",162,"2022-07-13 09:27:29","","10.1145/3292500.3330905","","",,,,,65,21.67,33,2,3,"Recent works show that Graph Neural Networks (GNNs) are highly non-robust with respect to adversarial attacks on both the graph structure and the node attributes, making their outcomes unreliable. We propose the first method for certifiable (non-)robustness of graph convolutional networks with respect to perturbations of the node attributes1. We consider the case of binary node attributes (e.g. bag-of-words) and perturbations that are L0-bounded. If a node has been certified with our method, it is guaranteed to be robust under any possible perturbation given the attack model. Likewise, we can certify non-robustness. Finally, we propose a robust semisupervised training procedure that treats the labeled and unlabeled nodes jointly. As shown in our experimental evaluation, our method significantly improves the robustness of the GNNwith onlyminimal effect on the predictive accuracy. ACM Reference Format: Daniel Zügner and Stephan Günnemann. 2019. Certifiable Robustness and Robust Training for Graph Convolutional Networks. In The 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD ’19), August 4–8, 2019, Anchorage, AK, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3292500.3330905","",""
0,"Shruthi Gowda, Bahram Zonooz, E. Arani","InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness",2022,"","","","",163,"2022-07-13 09:27:29","","10.48550/arXiv.2206.05846","","",,,,,0,0.00,0,3,1,"Humans rely less on spurious correlations and trivial cues, such as texture, compared to deep neural networks which lead to better generalization and robustness. It can be attributed to the prior knowledge or the high-level cognitive inductive bias present in the brain. Therefore, introducing meaningful inductive bias to neural networks can help learn more generic and high-level representations and alleviate some of the shortcomings. We propose InBiaseD to distill inductive bias and bring shape-awareness to the neural networks. Our method includes a bias alignment objective that enforces the networks to learn more generic representations that are less vulnerable to unintended cues in the data which results in improved generalization performance. InBiaseD is less susceptible to shortcut learning and also exhibits lower texture bias. The better representations also aid in improving robustness to adversarial attacks and we hence plugin InBiaseD seamlessly into the existing adversarial training schemes to show a better trade-off between generalization and robustness.1","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",164,"2022-07-13 09:27:29","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
4,"Dighanchal Banerjee, Smriti Rani, Arun M. George, Arijit Chowdhury, S. Dey, A. Mukherjee, T. Chakravarty, A. Pal","Application of Spiking Neural Networks for Action Recognition from Radar Data",2020,"","","","",165,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9206853","","",,,,,4,2.00,1,8,2,"In the past two decades, radar-based human sensing has become a topic of intense research. Unlike vision-based techniques which require the use of camera, radars are unobtrusive and privacy preserving in nature. Further, radars are agnostic of the lighting conditions and can be used for through-the-wall imaging thereby making them hugely effective in many situations. Compact, affordable radars have been designed that can be easily integrated with remote monitoring systems. However, the classical machine learning techniques currently used for learning and inferring human actions from radar images are compute intensive, and require large volume of training data, making them unsuitable for deployment on the network edge. In this paper, we propose to use the concepts of neuromorphic computing and Spiking Neural Networks (SNN) to learn human actions from data captured by the radar. To the best our knowledge, this is the first attempt of using SNNs on micro-Doppler data from radars. Our SNN model is capable of learning spatial as well as temporal features from the data and our experiments have resulted in 85% accuracy which is comparable with the classical machine learning approaches that are typically used on similar data. Further, the use of neuromorphic and SNN concepts make our model deployable over evolving neuromorphic edge devices thereby making the entire approach more efficient in terms of data, computation and energy consumption.","",""
0,"Timothy Tadros","BUSTNESS IN DEEP NEURAL NETWORKS",2020,"","","","",166,"2022-07-13 09:27:29","","","","",,,,,0,0.00,0,1,2,"Current artificial neural networks (ANNs) can perform and excel at a variety of tasks ranging from image classification to spam detection through training on large datasets of labeled data. While the trained network may perform well on similar testing data, inputs that differ even slightly from the training data may trigger unpredictable behavior. Due to this limitation, it is possible to design inputs with very small perturbations that can result in misclassification. These adversarial attacks present a security risk to deployed ANNs and indicate a divergence between how ANNs and humans perform classification. Humans are robust at behaving in the presence of noise and are capable of correctly classifying objects that are noisy, blurred, or otherwise distorted. It has been hypothesized that sleep promotes generalization of knowledge and improves robustness against noise in animals and humans. In this work, we utilize a biologically inspired sleep phase in ANNs and demonstrate the benefit of sleep on defending against adversarial attacks as well as in increasing ANN classification robustness. We compare the sleep algorithm’s performance on various robustness tasks with two previously proposed adversarial defenses defensive distillation and fine-tuning. We report an increase in robustness after sleep phase to adversarial attacks as well as to general image distortions for three datasets: MNIST, CUB200, and a toy dataset. Overall, these results demonstrate the potential for biologically inspired solutions to solve existing problems in ANNs and guide the development of more robust, human-like ANNs.","",""
3,"D. Hudson, Maurice E. Cohen","Focus of attention in a neural network using meta knowledge",2000,"","","","",167,"2022-07-13 09:27:29","","10.1109/IJCNN.2000.857820","","",,,,,3,0.14,2,2,22,"An aspect that appears to be of great importance in human decision making is focus of attention. This focus determines the level of detail that should be considered in addressing the current situation. Classification neural networks as they currently exist generally rely on building an overall model based on the data presented. Implementation of a level of detail structure depends on hierarchical modeling. Neural networks at each level of detail must be trained separately, with each requiring different data sets for training and testing. In addition, a method for deciding which level is appropriate must be developed. In the work described in this paper, meta knowledge, a technique derived from knowledge-based reasoning, is used for transition between multiple levels. The meta knowledge described internally structures transitions among the neural network layers.","",""
0,"Yaou Zhao, Yuehui Chen, M. Jiang","A novel ensemble of probabilistic neural network for predicting protein-protein interactions",2012,"","","","",168,"2022-07-13 09:27:29","","10.1109/BMEI.2012.6513055","","",,,,,0,0.00,0,3,10,"The knowledge of protein-protein interactions (PPIs) in cells is indispensable for deep understanding the biological process. Although many computational methods have been developed for identification of PPIs, there are still many difficulties due to high computation complexity and noisy data. In this paper, we proposed an ensemble of probabilistic neural network (PNN) to predict PPIs from primary sequence which achieved promising results. The key advantage of the algorithm is that it combines variety of physicochemical property features to construct diverse individual classifiers for ensemble prediction. What makes the method much more attractive is that it not only generated much more diverse and robust individual classifiers, but also contains different interaction physicochemical information which dictated the structure and the function of proteins. Moreover, the PNN is robust to noise and trained easily, it is suitable for dealing with the large scale noisy PPIs data. Experiment results on H. pylori and Human datasets show that our proposed method performs at least 8% higher accuracy than the best of other related works.","",""
6,"V. Ariton, V. Palade","Human-like fault diagnosis using a neural network implementation of plausibility and relevance",2005,"","","","",169,"2022-07-13 09:27:29","","10.1007/s00521-004-0449-5","","",,,,,6,0.35,3,2,17,"","",""
4,"R. Ning, Jiang Li, Chunsheng Xin, Hongyi Wu","Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks",2021,"","","","",170,"2022-07-13 09:27:29","","10.1109/INFOCOM42981.2021.9488902","","",,,,,4,4.00,1,4,1,"This paper reports a new clean-label data poisoning backdoor attack, named Invisible Poison, which stealthily and aggressively plants a backdoor in neural networks. It converts a regular trigger to a noised trigger that can be easily concealed inside images for training NN, with the objective to plant a backdoor that can be later activated by the trigger. Compared with existing data poisoning backdoor attacks, this newfound attack has the following distinct properties. First, it is a blackbox attack, requiring zero-knowledge of the target model. Second, this attack utilizes ""invisible poison"" to achieve stealthiness where the trigger is disguised as ‘noise’, and thus can easily evade human inspection. On the other hand, this noised trigger remains effective in the feature space to poison training data. Third, the attack is practical and aggressive. A backdoor can be effectively planted with a small amount of poisoned data and is robust to most data augmentation methods during training. The attack is fully tested on multiple benchmark datasets including MNIST, Cifar10, and ImageNet10, as well as application specific data sets such as Yahoo Adblocker and GTSRB. Two countermeasures, namely Supervised and Unsupervised Poison Sample Detection, are introduced to defend the attack.","",""
4,"D. Bacciu, Daniele Di Sarli, Pouria Faraji, C. Gallicchio, A. Micheli","Federated Reservoir Computing Neural Networks",2021,"","","","",171,"2022-07-13 09:27:29","","10.1109/IJCNN52387.2021.9534035","","",,,,,4,4.00,1,5,1,"A critical aspect in Federated Learning is the aggregation strategy for the combination of multiple models, trained on the edge, into a single model that incorporates all the knowledge in the federation. Common Federated Learning approaches for Recurrent Neural Networks (RNNs) do not provide guarantees on the predictive performance of the aggregated model. In this paper we show how the use of Echo State Networks (ESNs), which are efficient state-of-the-art RNN models for time-series processing, enables a form of federation that is optimal in the sense that it produces models mathematically equivalent to the corresponding centralized model. Furthermore, the proposed method is compliant with privacy constraints. The proposed method, which we denote as Incremental Federated Learning, is experimentally evaluated against an averaging strategy on two datasets for human state and activity recognition.","",""
3,"Xinsong Zhang, Tianyi Liu, Pengshuai Li, Weijia Jia, Hai Zhao","Robust Neural Relation Extraction via Multi-Granularity Noises Reduction",2021,"","","","",172,"2022-07-13 09:27:29","","10.1109/tkde.2020.2964747","","",,,,,3,3.00,1,5,1,"Distant supervision is widely used to extract relational facts with automatically labeled datasets to reduce high cost of human annotation. However, current distantly supervised methods suffer from the common problems of word-level and sentence-level noises, which come from a large proportion of irrelevant words in a sentence and inaccurate relation labels for numerous sentences. The problems lead to unacceptable precision in relation extraction and are critical for the success of using distant supervision. In this paper, we propose a novel and robust neural approach to deal with both problems by reducing influences of the multi-granularity noises. Three levels of noises from word, sentence until knowledge type are carefully considered in this work. We first initiate a question-answering based relation extractor (QARE) to remove noisy words in a sentence. Then we use multi-focus multi-instance learning (MMIL) to alleviate the effects of sentence-level noise by utilizing wrongly labeled sentences properly. Finally, to enhance our method against all the noises, we initialize parameters in our method with a priori knowledge learned from the relevant task of entity type classification by transfer learning. Extensive experiments on both existing benchmark and an improved larger dataset demonstrate that our proposed approach remarkably achieves new state-of-the-art performance.","",""
2,"Hritik Bansal, Gantavya Bhatt, Pankaj Malhotra, Prathosh Ap","Systematic Generalization in Neural Networks-based Multivariate Time Series Forecasting Models",2021,"","","","",173,"2022-07-13 09:27:29","","10.1109/IJCNN52387.2021.9534469","","",,,,,2,2.00,1,4,1,"Systematic generalization aims to evaluate reasoning about novel combinations from known components, an intrinsic property of human cognition. In this work, we study systematic generalization of Neural Networks (NNs) in forecasting future time series of dependent variables in a dynamical system, conditioned on past time series of dependent variables, and past and future control variables. We focus on systematic generalization wherein the NN-based forecasting model should perform well on previously unseen combinations or regimes of control variables after being trained on a limited set of the possible regimes. For NNs to depict such out-of-distribution generalization, they should be able to disentangle the various dependencies between control variables and dependent variables. We hypothesize that a modular NN architecture guided by the readily-available knowledge of independence of control variables as a potentially useful inductive bias to this end. Through extensive empirical evaluation on a toy dataset and a simulated electric motor dataset, we show that our proposed modular NN architecture serves as a simple yet highly effective inductive bias that enabling better forecasting of the dependent variables up to large horizons in contrast to standard NNs, and indeed capture the true dependency relations between the dependent and the control variables.","",""
60,"Hassan Ismail Fawaz, G. Forestier, J. Weber, L. Idoumghar, Pierre-Alain Muller","Adversarial Attacks on Deep Neural Networks for Time Series Classification",2019,"","","","",174,"2022-07-13 09:27:29","","10.1109/IJCNN.2019.8851936","","",,,,,60,20.00,12,5,3,"Time Series Classification (TSC) problems are encountered in many real life data mining tasks ranging from medicine and security to human activity recognition and food safety. With the recent success of deep neural networks in various domains such as computer vision and natural language processing, researchers started adopting these techniques for solving time series data mining problems. However, to the best of our knowledge, no previous work has considered the vulnerability of deep learning models to adversarial time series examples, which could potentially make them unreliable in situations where the decision taken by the classifier is crucial such as in medicine and security. For computer vision problems, such attacks have been shown to be very easy to perform by altering the image and adding an imperceptible amount of noise to trick the network into wrongly classifying the input image. Following this line of work, we propose to leverage existing adversarial attack mechanisms to add a special noise to the input time series in order to decrease the network’s confidence when classifying instances at test time. Our results reveal that current state-of-the-art deep learning time series classifiers are vulnerable to adversarial attacks which can have major consequences in multiple domains such as food safety and quality assurance.","",""
14,"Juanhui Tu, Mengyuan Liu, Hong Liu","Skeleton-Based Human Action Recognition Using Spatial Temporal 3D Convolutional Neural Networks",2018,"","","","",175,"2022-07-13 09:27:29","","10.1109/ICME.2018.8486566","","",,,,,14,3.50,5,3,4,"It remains a challenge to extract spatial-temporal information from skeleton sequences for 3D human action recognition. Although most recent action recognition methods based on Recurrent Neural Networks (RNN) have achieved outstanding performance, one of the shortcomings of these methods is the tendency to overemphasize the temporal information. Since 3D Convolutional Neural Networks(3D CNN) can simultaneously learn features from both spatial and temporal dimensions through capturing correlations among three-dimensional signals, this paper proposes a novel two-stream model using 3D CNN. To our best knowledge, this is the first attempt to use 3D CNN in the field of skeleton-based action recognition. Our method consists of three stages. First, skeleton joints are mapped into a 3D coordinate space to encode the spatial and temporal information. Second, 3D CNN models are separately employed to extract deep features from both spatial and temporal stream. Third, to enhance the ability of discriminative features to capture global relationships, we extend each stream into multi-temporal version. Extensive experiments on the large-scale NTU RGB-D dataset and the public SmartHome dataset demonstrate that our method outperforms most of RNN-based methods, which verify the complementary property between spatial and temporal information and the robustness to noise.","",""
2,"R. Zaier","Design of Oscillatory Neural Network for Locomotion Control of Humanoid Robots",2012,"","","","",176,"2022-07-13 09:27:29","","10.5772/25470","","",,,,,2,0.20,2,1,10,"Standing and walking are very important activities for daily living, so that their absence or any abnormality in their performance causes difficulties in doing regular task independently. Analysis of human motion has traditionally been accomplished by subjectively through visual observations. By combining advanced measurement technology and biomechanical modeling, the human gait is today objectively quantified in what is known as Gait analysis. Gait analysis research and development is an ongoing activity. New models and methods continue to evolve. Recently, humanoid robotics becomes widely developing world-wide technology and currently represents one of the main tools not only to investigate and study human gaits but also to acquire knowledge on how to assist paraplegic walking of patient (Acosta-M arquez and Bradley, 2000). Towards a better control of humanoid locomotion, much work can be found in the literature that has been focused on the dynamics of the robot using the Zero Moment Point (ZMP) approach (Vukobratovic and Borovac, 2004). More recently, biologically inspired control strategies such as Central Pattern Generators (CPG) have been proposed to generate autonomously adaptable rhythmic movement (Grillner, 1975, 1985; Taga, 1995; Taga et. al, 1991). Despite the extensive research focus in this area, suitable autonomous control system that can adapt and interact safely with the surrounding environment while delivering high robustness are yet to be discovered. In this chapter, we deal with the design of oscillatory neural network for bipedal motion pattern generator and locomotion controller. The learning part of the system will be built based on the combination of simplified models of the system with an extensive and efficient use of sensory feedback (sensor fusion) as the main engine to stabilize and adapt the system against parameters changes. All motions including reflexes will be generated by a neural network (NN) that represents the lower layer of the system. Indeed, we believe that the NN would be the most appropriate code when dealing, to a certain limit, with the system behavior, which can be described by a set of ordinary differential equations (ODEs) (Zaier and Nagashima, 2002, 2004). The neural network will be augmented by neural controllers with sensory connections to maintain the stability of the system. Hence, the proposed learning method is expected to be much faster than the conventional ones. To validate the theoretical results, we used the humanoid robot “HOAP-3” of Fujitsu. The structure of the chapter is as follows: the first section will present an introduction on the conventional CPG based locomotion control as well as the Van der Pol Based Oscillator;","",""
1,"Zhiwen Xiao, Xin Xu, Huanlai Xing, R. Qu, Fuhong Song, Bowen Zhao","RNTS: Robust Neural Temporal Search for Time Series Classification",2021,"","","","",177,"2022-07-13 09:27:29","","10.1109/IJCNN52387.2021.9534392","","",,,,,1,1.00,0,6,1,"Over the years, a large number of deep learning algorithms have been developed for time series classification (TSC). These algorithms were usually invented by researchers with prior knowledge and experience. However, it is a critical challenge for beginners to design decent structures to address various TSC problems. To this end, we propose a robust neural temporal search (RNTS) framework for identifying the relationships and features in TSC data, which mainly contains a temporal search network and an attentional LSTM network. To be specific, inspired by the idea of neural architecture search (NAS), the temporal search network automatically transforms its structure for each dataset according to its characteristics, responsible for extracting basic features. The attentional LSTM network is used to explore the complex shapelets and relationships the former may ignore. Experimental results demonstrate that RNTS achieves the best overall performance on 24 standard datasets selected from the UCR 2018 archive, in terms of three measures based on the top-l accuracy, compared with a number of state-of-the-art approaches.","",""
58,"V. Kaburlasos, S. Papadakis, G. Papakostas","Lattice Computing Extension of the FAM Neural Classifier for Human Facial Expression Recognition",2013,"","","","",178,"2022-07-13 09:27:29","","10.1109/TNNLS.2012.2237038","","",,,,,58,6.44,19,3,9,"This paper proposes a fundamentally novel extension, namely, flrFAM, of the fuzzy ARTMAP (FAM) neural classifier for incremental real-time learning and generalization based on fuzzy lattice reasoning techniques. FAM is enhanced first by a parameter optimization training (sub)phase, and then by a capacity to process partially ordered (non)numeric data including information granules. The interest here focuses on intervals' numbers (INs) data, where an IN represents a distribution of data samples. We describe the proposed flrFAM classifier as a fuzzy neural network that can induce descriptive as well as flexible (i.e., tunable) decision-making knowledge (rules) from the data. We demonstrate the capacity of the flrFAM classifier for human facial expression recognition on benchmark datasets. The novel feature extraction as well as knowledge-representation is based on orthogonal moments. The reported experimental results compare well with the results by alternative classifiers from the literature. The far-reaching potential of fuzzy lattice reasoning in human-machine interaction applications is discussed.","",""
2,"K. H. Løkken, L. Aurdal, A. Brattli, H. C. Palm","Investigating robustness of adversarial camouflage (AC) for naval vessels",2020,"","","","",179,"2022-07-13 09:27:29","","10.1117/12.2573676","","",,,,,2,1.00,1,4,2,"The use of camouflage is widespread in the biological domain, and has also been used extensively by armed forces around the world in order to make visual detection and classification of objects of military interest more difficult. The recent advent of ever more autonomous military agents raises the questions of whether camouflage can have a similar effect on autonomous agents as it has on human agents, and if so, what kind of camouflage will be effective against such adversaries. In previous works, we have shown that image classifiers based on deep neural networks can be confused by patterns generated by generative adversarial networks (GANs). Specifically, we trained a classifier to distinguish between two ship types, military and civilian. We then used a GAN to generate patterns that, when overlaid on parts of military vessels (frigates), made the classifier confuse the modified frigates with civilian vessels. We termed such patterns ""adversarial camouflage"" (AC) since these patterns effectively camouflage the frigates with respect to the classifier. The type of adversarial attack described in our previous work is a so-called white box attack. This term describes adversarial attacks that are devised given full knowledge of the classifier under attack. This is as opposed to black box attacks, which describe attacks on unknown classifiers. In our context, the ultimate goal is to design a GAN that is capable of black box attacks, in other words: a GAN that will generate AC that has effect across a wide range of neural network classifiers. In the current work, we study techniques to improve the robustness of our GAN-based approach by investigating whether a GAN can be trained to fool a selection of several neural network-based classifiers, or reduce the confidence of the classifications to a degree which makes them unreliable. Our results indicate that it is indeed possible to weaken a wider range of neural network classifiers by training the generator on several classifiers.","",""
0,"A. Nawaz, A. S. Arora, W. Ali, Nikita T. Saxena, Mohd Shariq Khan, C. Yun, Moonyong Lee","Intelligent Human–Machine Interface: An Agile Operation and Decision Support for an ANAMMOX SBR System at a Pilot-Scale Wastewater Treatment Plant",2022,"","","","",180,"2022-07-13 09:27:29","","10.1109/tii.2022.3153468","","",,,,,0,0.00,0,7,1,"Eco-efficient anaerobic ammonium oxidation (ANAMMOX) can eliminate toxic nutrients from wastewater and has been used in several nutrient removal technologies. However, its implementation for robust operation remains challenging because of process nonlinearity and time-variant characteristic, higher energy consumption, excess sludge produced, and biomass loss during sludge pumping. Also, sensor failure, process startup, and shut down present additional difficulties. In this article, an intelligent human–machine interface using an advanced numerical solution for a knowledge-based system (called ANKSys) was developed by integrating the fully optimized-functionality (soft sensing, decision making, and simulating model) data driven by supervisory control. This control consists of advanced algorithms (artificial neural network, Kalman filter, principal component analysis, least-square technique/renowned root-mean-squared error) using commercial software (MATLAB R2018a, Microsoft Visual Studio IDE 2016, Microsoft SQL Server 2014, OPC Automation with XGT series programmable logic controller). The developed ANKSys can help in online monitoring and optimal process operation by assessing risk and failure occurrences, acquiring data for data analysis, and managing operating expenditure. In real-time implementation, ANKSys enhanced the energy efficiency, i.e., 16% of a pilot-scale “LEAOX” wastewater treatment plant located at Daegu, Republic of Korea. Using this strategy, an optimal and sustainable operation for the removal of biological nitrogen was achieved.","",""
0,"M. Swarna, N. Sudhakar, N. Vadaparthi","An effective tropical cyclone intensity estimation model using Convolutional Neural Networks",2021,"","","","",181,"2022-07-13 09:27:29","","10.54302/mausam.v72i2.616","","",,,,,0,0.00,0,3,1,"The tropical cyclones in India is a common natural disaster happening every year. As per the statistics, about three cyclones hit India's east coast in the Bay of Bengal, which damaged human lives, crops and property. It is essential to predict the cyclones in advance to prevent and reduce huge damage. The techniques used are based on numerical models that require vast expertise and higher skill sets to achieve better prediction accuracy. The usage of Convolutional Neural Networks shall overcome various issues like domain knowledge, the scope for human errors. Hence, in this paper, we attempted to predict cyclone intensity using Convolutional Neural Networks by proposing a simple and robust architecture for Tropical Cyclone intensity estimation. The results yielded better performance than the state-of-the-art techniques with reduced computation time.","",""
0,"Deboleena Roy","Exploring Methods for Efficient Learning in Neural Networks",2021,"","","","",182,"2022-07-13 09:27:29","","10.25394/PGS.15050121.V1","","",,,,,0,0.00,0,1,1,"In the past fifty years, Deep Neural Networks (DNNs) have evolved greatly from a single perceptron to complex multi-layered networks with non-linear activation functions. Today, they form the backbone of Artificial Intelligence, with a diverse application landscape, such as smart assistants, wearables, targeted marketing, autonomous vehicles, etc. The design of DNNs continues to change, as we push its abilities to perform more human-like tasks at an industrial scale.Multi-task learning and knowledge sharing are essential to human-like learning. Humans progressively acquire knowledge throughout their life, and they do so by remembering, and modifying prior skills for new tasks. In our first work, we investigate the representations learned by Spiking Neural Networks (SNNs), and how to share this knowledge across tasks. Our prior task was MNIST image generation using a spiking autoencoder. We combined the generative half of the autoencoder with a spiking audio-decoder for our new task, i.e audio-to-image conversion of utterances of digits to their corresponding images. We show that objects of different modalities carrying the same meaning can be mapped into a shared latent space comprised of spatio-temporal spike maps, and one can transfer prior skills, in this case, image generation, from one task to another, in a purely Spiking domain. Next, we propose Tree-CNN, an adaptive hierarchical network structure composed of Deep Convolutional Neural Networks(DCNNs) that can grow and learn as new data becomes available. The network organizes the incrementally available data into feature-driven super-classes and improves upon existing hierarchical CNN models by adding the capability of self-growth. While the above works focused solely on algorithmic design, the underlying hardware determines the efficiency of model implementation. Currently, neural networks are implemented in CMOS based digital hardware such as GPUs and CPUs. However, the saturating scaling trend of CMOS has garnered great interest in Non-Volatile Memory (NVM) technologies such as Spintronics and RRAM. However, most emerging technologies have inherent reliability issues, such as stochasticity and non-linear device characteristics. Inspired by the recent works in spin-based stochastic neurons, we studied the algorithmic impact of designing a neural network using stochastic activations. We trained VGG-like networks on CIFAR-10/100 with 4 different binary activations and analyzed the trade-off between deterministic and stochastic activations. NVM-based crossbars further promise fast and energy-efficient in-situ matrix-vector multiplications (MVM). However, the analog nature of computing in these NVM crossbars introduces approximations in the MVM operations, resulting in deviations from ideal output values. We first studied the impact of these non-idealities on the performance of vanilla DNNs under adversarial circumstances, and we observed that the non-ideal behavior interferes with the computation of the exact gradient of the model, which is required for adversarial image generation. In a non-adaptive attack, where the attacker is unaware of the analog hardware, analog computing offered varying degree of intrinsic robustness under all attack scenarios - Transfer, Black Box, and White Box attacks. We also demonstrated ``Hardware-in-Loop"" adaptive attacks that circumvent this robustness by utilizing the knowledge of the NVM model.Next, we explored the design of robust DNNs through the amalgamation of adversarial training and the intrinsic robustness offered by NVM crossbar based analog hardware. We studied the noise stability of such networks on unperturbed inputs and observed that internal activations of adversarially trained networks have lower Signal-to-Noise Ratio (SNR), and are sensitive to noise than vanilla networks. As a result, they suffer significantly higher performance degradation due to the non-ideal computations, on an average 2x accuracy drop. On the other hand, for adversarial images, the same networks displayed a 5-10% gain in robust accuracy due to the underlying NVM crossbar when the attack epsilon (the degree of input perturbations) was greater than the epsilon of the adversarial training. Our results indicate that implementing adversarially trained networks on analog hardware requires careful calibration between hardware non-idealities and training epsilon to achieve optimum robustness and performance.","",""
6,"R. Hamad, Masashi Kimura, Longzhi Yang, W. L. Woo, Bo Wei","Dilated causal convolution with multi-head self attention for sensor human activity recognition",2021,"","","","",183,"2022-07-13 09:27:29","","10.1007/S00521-021-06007-5","","",,,,,6,6.00,1,5,1,"","",""
7,"Brian Russell, A. McDaid, William Toscano, P. Hume","Moving the Lab into the Mountains: A Pilot Study of Human Activity Recognition in Unstructured Environments",2021,"","","","",184,"2022-07-13 09:27:29","","10.3390/s21020654","","",,,,,7,7.00,2,4,1,"Goal: To develop and validate a field-based data collection and assessment method for human activity recognition in the mountains with variations in terrain and fatigue using a single accelerometer and a deep learning model. Methods: The protocol generated an unsupervised labelled dataset of various long-term field-based activities including run, walk, stand, lay and obstacle climb. Activity was voluntary so transitions could not be determined a priori. Terrain variations included slope, crossing rivers, obstacles and surfaces including road, gravel, clay, mud, long grass and rough track. Fatigue levels were modulated between rested to physical exhaustion. The dataset was used to train a deep learning convolutional neural network (CNN) capable of being deployed on battery powered devices. The human activity recognition results were compared to a lab-based dataset with 1,098,204 samples and six features, uniform smooth surfaces, non-fatigued supervised participants and activity labelling defined by the protocol. Results: The trail run dataset had 3,829,759 samples with five features. The repetitive activities and single instance activities required hyper parameter tuning to reach an overall accuracy 0.978 with a minimum class precision for the one-off activity (climbing gate) of 0.802. Conclusion: The experimental results showed that the CNN deep learning model performed well with terrain and fatigue variations compared to the lab equivalents (accuracy 97.8% vs. 97.7% for trail vs. lab). Significance: To the authors knowledge this study demonstrated the first successful human activity recognition (HAR) in a mountain environment. A robust and repeatable protocol was developed to generate a validated trail running dataset when there were no observers present and activity types changed on a voluntary basis across variations in terrain surface and both cognitive and physical fatigue levels.","",""
2,"A. Soni, Vineet Richaria, Suneel Phulre","STOCK MARKET PREDICTION MODEL USING BACK PROPAGATION NEURAL NETWORK, SUPPORT VECTOR REGRESSION AND SUPPORT VECTOR MACHINE -FUZZY LOGIC",2013,"","","","",185,"2022-07-13 09:27:29","","","","",,,,,2,0.22,1,3,9,"The key to success stock market forecasting is achieving best result with minimum data artificial Neural Network, SVMs methods for stock market prediction have gradually becoming hot spot in the territory of traditional method. Aim of this paper to investigate robustness of prediction by comparing ANN, SVR and SVM-Fuzzy model. The study employs two years DOW data (monthly) of price values (input, low, high, output, and volume) as independent variables and daily close value as dependent (output) variable. Finally the performance is measured in terms parameters i.e. accuracy, memory used, error rate, and others. This research found that SVM-Fuzzy model outperforms better than ANN (back propagation) and SVR for data prediction. I. INTRODUCTION In the business and economic environment, it is very important to accurately predict various kinds of financial variables to develop proper strategies and avoid the risk of potentially large losses. Most stock traders nowadays depend on Intelligent Trading Systems which help them in predicting prices based on various situations and conditions .Machine learning techniques have introduced a new trend in prediction of stock market. These methods become more popular due to their predictive performance to minimize training error. Artificial Neural networks inspired by human brain cells 'activity can learn the data patterns and generalize their knowledge to recognize the future new patterns to reduce the expected error of learning machine and problem of over fitting. Support vector regression (SVR) employs the support vector machine (SVM) to tackle problems of function approximation and regression estimation. SVMs model uses structural risk","",""
162,"Matthew Wicker, Xiaowei Huang, M. Kwiatkowska","Feature-Guided Black-Box Safety Testing of Deep Neural Networks",2017,"","","","",186,"2022-07-13 09:27:29","","10.1007/978-3-319-89960-2_22","","",,,,,162,32.40,54,3,5,"","",""
16,"R. Miikkulainen","Natural Language Processing with Subsymbolic Neural Networks",2019,"","","","",187,"2022-07-13 09:27:29","","10.1201/9780367813239-8","","",,,,,16,5.33,16,1,3,"Natural language processing appears on the surface to be a strongly symbolic activity. Words are symbols that stand for objects and concepts in the real world, and they are put together into sentences that obey well-speci ed grammar rules. It is no surprise that for several decades natural language processing research has been dominated by the symbolic approach. Linguists have focused on describing language systems based on versions of the Universal Grammar. Arti cial Intelligence researchers have built large programs where linguistic and world knowledge is expressed in symbolic structures, usually in LISP. Relatively little attention has been paid to various cognitive e ects in language processing. Human language users perform di erently from their linguistic competence, that is, from their knowledge of how to communicate correctly using language. Some linguistic structures (such as deep embeddings) are harder to deal with than others. People make mistakes when they speak, but fortunately it is not that hard to understand language that is ungrammatical or cluttered with errors. Linguistic and symbolic arti cial intelligence theories have little to say about where such e ects come from. Yet if one wants to build machines that would communicate naturally with people, it is important to understand and model cognitive e ects in natural language processing.","",""
12,"Á. Martínez-González, M. Villamizar, Olivier Can'evet, J. Odobez","Efficient Convolutional Neural Networks for Depth-Based Multi-Person Pose Estimation",2019,"","","","",188,"2022-07-13 09:27:29","","10.1109/TCSVT.2019.2952779","","",,,,,12,4.00,3,4,3,"Achieving robust multi-person 2D body landmark localization and pose estimation is essential for human behavior and interaction understanding as encountered for instance in HRI settings. Accurate methods have been proposed recently, but they usually rely on rather deep Convolutional Neural Network (CNN) architecture, thus requiring large computational and training resources. In this paper, we investigate different architectures and methodologies to address these issues and achieve fast and accurate multi-person 2D pose estimation. To foster speed, we propose to work with depth images, whose structure contains sufficient information about body landmarks while being simpler than textured color images and thus potentially requiring less complex CNNs for processing. In this context, we make the following contributions. i) we study several CNN architecture designs combining pose machines relying on the cascade of detectors concept with lightweight and efficient CNN structures; ii) to address the need for large training datasets with high variability, we rely on semi-synthetic data combining multi-person synthetic depth data with real sensor backgrounds; iii) we explore domain adaptation techniques to address the performance gap introduced by testing on real depth images; iv) to increase the accuracy of our fast lightweight CNN models, we investigate knowledge distillation at several architecture levels which effectively enhance performance. Experiments and results on synthetic and real data highlight the impact of our design choices, providing insights into methods addressing standard issues normally faced in practical applications, and resulting in architectures effectively matching our goal in both performance and speed.","",""
20,"Xiuhui Wang, Jiajia Zhang, W. Yan","Gait recognition using multichannel convolution neural networks",2020,"","","","",189,"2022-07-13 09:27:29","","10.1007/s00521-019-04524-y","","",,,,,20,10.00,7,3,2,"","",""
104,"Weizhi Ma, Min Zhang, Yue Cao, Woojeong Jin, Chenyang Wang, Yiqun Liu, Shaoping Ma, Xiang Ren","Jointly Learning Explainable Rules for Recommendation with Knowledge Graph",2019,"","","","",190,"2022-07-13 09:27:29","","10.1145/3308558.3313607","","",,,,,104,34.67,13,8,3,"Explainability and effectiveness are two key aspects for building recommender systems. Prior efforts mostly focus on incorporating side information to achieve better recommendation performance. However, these methods have some weaknesses: (1) prediction of neural network-based embedding methods are hard to explain and debug; (2) symbolic, graph-based approaches (e.g., meta path-based models) require manual efforts and domain knowledge to define patterns and rules, and ignore the item association types (e.g. substitutable and complementary). In this paper, we propose a novel joint learning framework to integrate induction of explainable rules from knowledge graph with construction of a rule-guided neural recommendation model. The framework encourages two modules to complement each other in generating effective and explainable recommendation: 1) inductive rules, mined from item-centric knowledge graphs, summarize common multi-hop relational patterns for inferring different item associations and provide human-readable explanation for model prediction; 2) recommendation module can be augmented by induced rules and thus have better generalization ability dealing with the cold-start issue. Extensive experiments1 show that our proposed method has achieved significant improvements in item recommendation over baselines on real-world datasets. Our model demonstrates robust performance over “noisy” item knowledge graphs, generated by linking item names to related entities.","",""
33,"V. Nguyen, J. Starzyk, Wooi-Boon Goh, Daniel Jachyra","Neural Network Structure for Spatio-Temporal Long-Term Memory",2012,"","","","",191,"2022-07-13 09:27:29","","10.1109/TNNLS.2012.2191419","","",,,,,33,3.30,8,4,10,"This paper proposes a neural network structure for spatio-temporal learning and recognition inspired by the long-term memory (LTM) model of the human cortex. Our structure is able to process real-valued and multidimensional sequences. This capability is attained by addressing three critical problems in sequential learning, namely the error tolerance, the significance of sequence elements and memory forgetting. We demonstrate the potential of the framework with a series of synthetic simulations and the Australian sign language (ASL) dataset. Results show that our LTM model is robust to different types of distortions. Second, our LTM model outperforms other sequential processing models in a classification task for the ASL dataset.","",""
3,"C. Ranieri, R. Moioli, R. Romero, M. F. P. Araújo, M. Santana, Jhielson M. Pimentel, P. A. Vargas","Unveiling Parkinson’s Disease Features from a Primate Model with Deep Neural Networks",2020,"","","","",192,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207180","","",,,,,3,1.50,0,7,2,"Parkinson’s Disease (PD) is a neurodegenerative disorder with increasing prevalence in the world population and is Characterised by motor and cognitive symptoms. Although cortical EEG readings from PD-affected humans have being commonly used to feed different machine learning frameworks, the directly affected areas are concentrated in a group of subcortical nuclei and related areas, the so-called motor loop. As those areas may only be directly accessed through invasive procedures, such as Local Field Potential (LFP) measurements, most data collection must rely on animal models. To the best of our knowledge, no neural networks-based analysis centred on LFP data from the motor loop was reported so far. In this work, we trained and evaluated a set of deep neural networks on a dataset recorded from marmoset monkeys, with LFP readings from healthy and parkinsonian subjects. We analysed each trained neural network with respect to its inputs and representations from intermediate layers. CNN and ConvLSTM classifiers were applied, reaching accuracies up to 99.80%, as well as a CNN-based autoencoder, which has also shown to learn PD-related representations. The results and analysis provided further insights and foster research on the correlates of Parkinson’s Disease.","",""
8,"A. Nguyen, Jian Xu, Ming Jiang, D. K. Luu, Tong Wu, Wing-Kin Tam, Wenfeng Zhao, Markus W. Drealan, C. K. Overstreet, Qi Zhao, Jonathan Cheng, E. Keefer, Zhi Yang","A bioelectric neural interface towards intuitive prosthetic control for amputees.",2020,"","","","",193,"2022-07-13 09:27:29","","10.1088/1741-2552/abc3d3","","",,,,,8,4.00,1,13,2,"OBJECTIVE While prosthetic hands with independently actuated digits have become commercially available, state-of-the-art human-machine interfaces (HMI) only permit control over a limited set of grasp patterns, which does not enable amputees to experience sufficient improvement in their daily activities to make an active prosthesis useful.   APPROACH Here we present a technology platform combining fully-integrated bioelectronics, implantable intrafascicular microelectrodes and deep learning-based artificial intelligence (AI) to facilitate this missing bridge by tapping into the intricate motor control signals of peripheral nerves. The bioelectric neural interface includes an ultra-low-noise neural recording system to sense electroneurography (ENG) signals from microelectrode arrays implanted in the residual nerves, and AI models employing the recurrent neural network (RNN) architecture to decode the subject's motor intention.   MAIN RESULTS A pilot human study has been carried out on a transradial amputee. We demonstrate that the information channel established by the proposed neural interface is sufficient to provide high accuracy control of a prosthetic hand up to 15 degrees of freedom (DOF). The interface is intuitive as it directly maps complex prosthesis movements to the patient's true intention.   SIGNIFICANCE Our study layouts the foundation towards not only a robust and dexterous control strategy for modern neuroprostheses at a near-natural level approaching that of the able hand, but also an intuitive conduit for connecting human minds and machines through the peripheral neural pathways. (Clinical trial identifier: NCT02994160).","",""
8,"Masaki Uto, Masashi Okano","Robust Neural Automated Essay Scoring Using Item Response Theory",2020,"","","","",194,"2022-07-13 09:27:29","","10.1007/978-3-030-52237-7_44","","",,,,,8,4.00,4,2,2,"","",""
16,"S. Jang, H. Kwon","Perspectives on the neural connectivity of the fornix in the human brain",2014,"","","","",195,"2022-07-13 09:27:29","","10.4103/1673-5374.139459","","",,,,,16,2.00,8,2,8,"The fornix is involved in the transfer of information on episodic memory as a part of the Papez circuit. Diffusion tensor imaging enables to estimate the neural connectivity of the fornix. The anterior fornical body has high connectivity with the anterior commissure, and brain areas relevant to cholinergic nuclei (septal forebrain region and brainstem) and memory function (medial temporal lobe). In the normal subjects, by contrast, the posterior fornical body has connectivity with the cerebral cortex and brainstem through the splenium of the corpus callosum. We believe that knowledge of the neural connectivity of the fornix would be helpful in investigation of the neural network associated with memory and recovery mechanisms following injury of the fornix.","",""
16,"Alberto Marchisio, Giorgio Nanfa, Faiq Khalid, Muhammad Abdullah Hanif, M. Martina, M. Shafique","Is Spiking Secure? A Comparative Study on the Security Vulnerabilities of Spiking and Deep Neural Networks",2019,"","","","",196,"2022-07-13 09:27:29","","10.1109/IJCNN48605.2020.9207297","","",,,,,16,5.33,3,6,3,"Spiking Neural Networks (SNNs) claim to present many advantages in terms of biological plausibility and energy efficiency compared to standard Deep Neural Networks (DNNs). Recent works have shown that DNNs are vulnerable to adversarial attacks, i.e., small perturbations added to the input data can lead to targeted or random misclassifications. In this paper, we aim at investigating the key research question: ""Are SNNs secure?"" Towards this, we perform a comparative study of the security vulnerabilities in SNNs and DNNs w.r.t. the adversarial noise. Afterwards, we propose a novel black-box attack methodology, i.e., without the knowledge of the internal structure of the SNN, which employs a greedy heuristic to automatically generate imperceptible and robust adversarial examples (i.e., attack images) for the given SNN. We perform an in-depth evaluation for a Spiking Deep Belief Network (SDBN) and a DNN having the same number of layers and neurons (to obtain a fair comparison), in order to study the efficiency of our methodology and to understand the differences between SNNs and DNNs w.r.t. the adversarial examples. Our work opens new avenues of research towards the robustness of the SNNs, considering their similarities to the human brain's functionality.","",""
185,"T. G. Thuruthel, Benjamin Shih, C. Laschi, M. Tolley","Soft robot perception using embedded soft sensors and recurrent neural networks",2019,"","","","",197,"2022-07-13 09:27:29","","10.1126/scirobotics.aav1488","","",,,,,185,61.67,46,4,3,"Recurrent neural networks with an unstructured redundant soft sensor topology allow robust multimodal proprioceptive capabilities. Recent work has begun to explore the design of biologically inspired soft robots composed of soft, stretchable materials for applications including the handling of delicate materials and safe interaction with humans. However, the solid-state sensors traditionally used in robotics are unable to capture the high-dimensional deformations of soft systems. Embedded soft resistive sensors have the potential to address this challenge. However, both the soft sensors—and the encasing dynamical system—often exhibit nonlinear time-variant behavior, which makes them difficult to model. In addition, the problems of sensor design, placement, and fabrication require a great deal of human input and previous knowledge. Drawing inspiration from the human perceptive system, we created a synthetic analog. Our synthetic system builds models using a redundant and unstructured sensor topology embedded in a soft actuator, a vision-based motion capture system for ground truth, and a general machine learning approach. This allows us to model an unknown soft actuated system. We demonstrate that the proposed approach is able to model the kinematics of a soft continuum actuator in real time while being robust to sensor nonlinearities and drift. In addition, we show how the same system can estimate the applied forces while interacting with external objects. The role of action in perception is also presented. This approach enables the development of force and deformation models for soft robotic systems, which can be useful for a variety of applications, including human-robot interaction, soft orthotics, and wearable robotics.","",""
9,"Taro Makino, Stanislaw Jastrzebski, Witold Oleszkiewicz, Celin Chacko, Robin Ehrenpreis, N. Samreen, C. Chhor, Eric Kim, Jiyon Lee, K. Pysarenko, B. Reig, H. Toth, Divya Awal, Linda Du, A. Kim, James Park, D. Sodickson, L. Heacock, L. Moy, Kyunghyun Cho, Krzysztof J Geras","Differences between human and machine perception in medical diagnosis",2020,"","","","",198,"2022-07-13 09:27:29","","10.1038/s41598-022-10526-z","","",,,,,9,4.50,1,21,2,"","",""
2,"Jie Fang, Jianwu Lin","Prior knowledge distillation based on financial time series",2020,"","","","",199,"2022-07-13 09:27:29","","10.1109/INDIN45582.2020.9442199","","",,,,,2,1.00,1,2,2,"One of the major characteristics of financial time series is that they contain a large amount of nonstationary noise, which is challenging for deep neural networks. People normally use various features to address this problem. However, the performance of these features depends on the choice of hyper-parameters. In this paper, we propose to use neural networks to represent these indicators and train a large network constructed of smaller networks as feature layers to fine-tune the prior knowledge represented by the indicators. During back propagation, prior knowledge is transferred from human logic to machine logic via gradient descent. Prior knowledge is the neural network's deep belief and teaches the network to not be affected by non-stationary noise. Moreover, co-distillation is applied to distill the structure into a much smaller size to reduce redundant features and the risk of overfitting. In addition, the decisions of the smaller networks in terms of gradient descent are more robust and cautious than those of large networks. In numerical experiments, we find that our algorithm is faster and more accurate than traditional methods on real financial datasets. We also conduct experiments to verify the method.","",""
20,"A. Khasnobish, A. Jati, Garima Singh, S. Bhattacharyya, A. Konar, D. Tibarewala, Eunjin Kim, A. Nagar","Object-shape recognition from tactile images using a feed-forward neural network",2012,"","","","",200,"2022-07-13 09:27:29","","10.1109/IJCNN.2012.6252593","","",,,,,20,2.00,3,8,10,"The sense of touch is an extremely important sensory system in the human body which helps to understand object shape, texture, hardness in the world around us. Incorporating artificial haptic sensory systems in rehabilitative aids and in various other human computer interfaces is a thrust area of research presently. This paper presents a novel approach of shape recognition and classification from the tactile pressure images by touching the surface of various real life objects. Here four objects (viz. a planar surface, object with one edge, a cuboid i.e. object with two edges and a cylindrical object) are used for shape recognition. The obtained tactile pressure images of the object surfaces are subjected to segmentation, edge detection and a mapping procedure to finally reconstruct the particular object shapes. The reconstructed images are used as features. The processed tactile pressure images are classified with feed- forward neural network (FFNN) using extracted features. The classifier performance is tested with different signal-to-noise (SNR) ratios. Is is observed that classifier accuracy decreases with decrease in SNR, but at SNR value 6 i.e. when the noise power is one sixth of the signal power, the mean classification accuracy of the classifier is 88%. This shows the robustness of feed-forward neural network in the classification purpose. The performance of FFNN is compared with four classifiers (Linear Discriminant Analysis, Linear Support vector machine, Radial Basis Function SVM, k-Nearest Neighbor). FFNN performed best acquiring first rank with a average classification accuracy of 94.0%.","",""
