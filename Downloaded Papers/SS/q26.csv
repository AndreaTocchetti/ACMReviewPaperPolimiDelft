Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",1,"2022-07-13 09:22:16","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
4,"Tingting Wu, Yunwei Dong, Zhiwei Dong, Aziz Singa, Xiong Chen, Yu Zhang","Testing Artificial Intelligence System Towards Safety and Robustness: State of the Art",2020,"","","","",2,"2022-07-13 09:22:16","","","","",,,,,4,2.00,1,6,2,"With the increasing development of machine learning, conventional embedded systems cannot meet the requirement of current academic researches and industrial applications. Artificial Intelligence System (AIS) based on machine learning has been widely used in various safety-critical systems, such as machine vision, autonomous vehicles, collision avoidance system. Different from conventional embedded systems, AIS generates and updates control strategies through learning algorithms which make the control behaviors nondeterministic and bring about the test oracle problem in AIS testing procedure. There have been various testing approaches for AIS to guarantee the safety and robustness. However, few researches explain how to conduct AIS testing with a complete workflow systematically. This paper provides a comprehensive survey of existing testing techniques to detect the erroneous behaviors of AIS, and sums up the involved key steps and testing components in terms of test coverage criterion, test data generation, testing approach and common dataset. This literature review aims at organizing a standardized workflow and leading to a practicable insight and research trend towards AIS testing.","",""
51,"Shubham Sharma, Jette Henderson, Joydeep Ghosh","CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",2019,"","","","",3,"2022-07-13 09:22:16","","10.1145/3375627.3375812","","",,,,,51,17.00,17,3,3,"As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",4,"2022-07-13 09:22:16","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
14,"A. Zaji, H. Bonakdari","Robustness lake water level prediction using the search heuristic-based artificial intelligence methods",2019,"","","","",5,"2022-07-13 09:22:16","","10.1080/09715010.2018.1424568","","",,,,,14,4.67,7,2,3,"Abstract Lakes have a crucial role in the industrial, agricultural, environment, and drinking water fields. Accurate prediction of lake levels is one of the most important parameters in the reservoir management and lakeshore structure designing. The goal of the present study is to examine the robustness of two different Genetic Algorithm-based regression methods namely the Genetic Algorithm Artificial neural network (GAA) and the Genetic Programming (GP) by considering their performance in predicting the non-observed lakes. To do that, data collected from the four-year daily measurements of the Chahnimeh#1 lake in Eastern Iran were used for developing the GAA and GP models and after that, the performance of the considered models are examined to predict the lake water levels of an adjacent lake namely Chahnimeh#4 as the non-observed information. The results showed that both model has the ability to simulate adjacent lakes using the considered lake water levels for the training procedure. In addition, another goal is to develop simple, practical formulation for predicting the lake water level, So that, using the GP method, as the superior model, three different formulations are proposed in order to predict the one, three, and five days ahead lake water level, respectively.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",6,"2022-07-13 09:22:16","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",7,"2022-07-13 09:22:16","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",8,"2022-07-13 09:22:16","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",9,"2022-07-13 09:22:16","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",10,"2022-07-13 09:22:16","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",11,"2022-07-13 09:22:16","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",12,"2022-07-13 09:22:16","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
5,"M. E. Laino, Angela Ammirabile, A. Posa, Pierandrea Cancian, Sherif Shalaby, V. Savevski, E. Neri","The Applications of Artificial Intelligence in Chest Imaging of COVID-19 Patients: A Literature Review",2021,"","","","",13,"2022-07-13 09:22:16","","10.3390/diagnostics11081317","","",,,,,5,5.00,1,7,1,"Diagnostic imaging is regarded as fundamental in the clinical work-up of patients with a suspected or confirmed COVID-19 infection. Recent progress has been made in diagnostic imaging with the integration of artificial intelligence (AI) and machine learning (ML) algorisms leading to an increase in the accuracy of exam interpretation and to the extraction of prognostic information useful in the decision-making process. Considering the ever expanding imaging data generated amid this pandemic, COVID-19 has catalyzed the rapid expansion in the application of AI to combat disease. In this context, many recent studies have explored the role of AI in each of the presumed applications for COVID-19 infection chest imaging, suggesting that implementing AI applications for chest imaging can be a great asset for fast and precise disease screening, identification and characterization. However, various biases should be overcome in the development of further ML-based algorithms to give them sufficient robustness and reproducibility for their integration into clinical practice. As a result, in this literature review, we will focus on the application of AI in chest imaging, in particular, deep learning, radiomics and advanced imaging as quantitative CT.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",14,"2022-07-13 09:22:16","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
4,"José Daniel López-Cabrera, R. Orozco-Morales, Jorge Armando Portal-Díaz, Orlando Lovelle-Enríquez, M. Pérez-Díaz","Current limitations to identify covid-19 using artificial intelligence with chest x-ray imaging (part ii). The shortcut learning problem",2021,"","","","",15,"2022-07-13 09:22:16","","10.1007/s12553-021-00609-8","","",,,,,4,4.00,1,5,1,"","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",16,"2022-07-13 09:22:16","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",17,"2022-07-13 09:22:16","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
2,"E. Papachristos, I. Stefanou","Controlling earthquake-like instabilities using artificial intelligence",2021,"","","","",18,"2022-07-13 09:22:16","","","","",,,,,2,2.00,1,2,1,"Earthquakes are lethal and costly. This study aims at avoiding these catastrophic events by the application of injection policies retrieved through reinforcement learning. With the rapid growth of artificial intelligence, prediction-control problems are all the more tackled by function approximation models that learn how to control a specific task, even for systems with unmodeled/unknown dynamics and important uncertainties. Here, we show for the first time the possibility of controlling earthquakelike instabilities using state-of-the-art deep reinforcement learning techniques. The controller is trained using a reduced model of the physical system, i.e, the spring-slider model, which embodies the main dynamics of the physical problem for a given earthquake magnitude. Its robustness to unmodeled dynamics is explored through a parametric study. Our study is a first step towards minimizing seismicity in industrial projects (geothermal energy, hydrocarbons production, CO2 sequestration) while, in a second step for inspiring techniques for natural earthquakes control and prevention.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",19,"2022-07-13 09:22:16","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
25,"Abbas Abbaszadeh Shahri, S. Larsson, Crister Renkel","Artificial intelligence models to generate visualized bedrock level: a case study in Sweden",2020,"","","","",20,"2022-07-13 09:22:16","","10.1007/s40808-020-00767-0","","",,,,,25,12.50,8,3,2,"","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",21,"2022-07-13 09:22:16","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",22,"2022-07-13 09:22:16","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",23,"2022-07-13 09:22:16","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",24,"2022-07-13 09:22:16","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
47,"L. Faes, B. Geerts, Xiaoxuan Liu, L. Morgan, P. Watkinson, P. McCulloch","DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in clinical artificial intelligence.",2021,"","","","",25,"2022-07-13 09:22:16","","10.1038/s41591-021-01229-5","","",,,,,47,47.00,8,6,1,"","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",26,"2022-07-13 09:22:16","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",27,"2022-07-13 09:22:16","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",28,"2022-07-13 09:22:16","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
17,"Mosleh Hmoud Al-Adhaileh, Fawaz Waselallah Alsaade","Modelling and Prediction of Water Quality by Using Artificial Intelligence",2021,"","","","",29,"2022-07-13 09:22:16","","10.3390/SU13084259","","",,,,,17,17.00,9,2,1,"Artificial intelligence methods can remarkably reduce costs for water supply and sanitation systems and help ensure compliance with the quality of drinking and wastewater treatment. Therefore, modelling and predicting water quality to control water pollution has been widely researched. The novelty of the proposed system is presented to develop an efficient operation of monitoring drinking water to ensure a sustainable and friendly green environment. In this work, the adaptive neuro-fuzzy inference system (ANFIS) algorithm was developed to predict the water quality index (WQI). Feed-forward neural network (FFNN) and K-nearest neighbors were applied to classify water quality. The dataset has eight significant parameters, but seven parameters were considered to show significant values. The proposed methodology was developed based on these statistical parameters. Prediction results demonstrated that the ANFIS model was superior for the prediction of WQI values. Nevertheless, the FFNN algorithm achieved the highest accuracy (100%) for water quality classification (WQC). Furthermore, the ANFIS model accurately predicted WQI, and the FFNN model showed superior robustness in classifying the WQC. In addition, the ANFIS model showed accuracy during the testing phase, with a regression coefficient of 96.17% for predicting WQI, and the FFNN model achieved the highest accuracy (100%) for WQC. This proposed method, using advanced artificial intelligence, can aid in water treatment and management.","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",30,"2022-07-13 09:22:16","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",31,"2022-07-13 09:22:16","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
16,"Rakesh Chandra Joshi, Saumya Yadav, M. Dutta, C. Travieso-González","Efficient Multi-Object Detection and Smart Navigation Using Artificial Intelligence for Visually Impaired People",2020,"","","","",32,"2022-07-13 09:22:16","","10.3390/e22090941","","",,,,,16,8.00,4,4,2,"Visually impaired people face numerous difficulties in their daily life, and technological interventions may assist them to meet these challenges. This paper proposes an artificial intelligence-based fully automatic assistive technology to recognize different objects, and auditory inputs are provided to the user in real time, which gives better understanding to the visually impaired person about their surroundings. A deep-learning model is trained with multiple images of objects that are highly relevant to the visually impaired person. Training images are augmented and manually annotated to bring more robustness to the trained model. In addition to computer vision-based techniques for object recognition, a distance-measuring sensor is integrated to make the device more comprehensive by recognizing obstacles while navigating from one place to another. The auditory information that is conveyed to the user after scene segmentation and obstacle identification is optimized to obtain more information in less time for faster processing of video frames. The average accuracy of this proposed method is 95.19% and 99.69% for object detection and recognition, respectively. The time complexity is low, allowing a user to perceive the surrounding scene in real time.","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",33,"2022-07-13 09:22:16","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
13,"Yuanbin Wang, P. Zheng, Tao Peng, Huayong Yang, J. Zou","Smart additive manufacturing: Current artificial intelligence-enabled methods and future perspectives",2020,"","","","",34,"2022-07-13 09:22:16","","10.1007/s11431-020-1581-2","","",,,,,13,6.50,3,5,2,"","",""
10,"Zhao Jian, Qingyuan Zhang, Liying Tian","Market revenue prediction and error analysis of products based on fuzzy logic and artificial intelligence algorithms",2020,"","","","",35,"2022-07-13 09:22:16","","10.1007/s12652-019-01650-2","","",,,,,10,5.00,3,3,2,"","",""
9,"M. Gorris, S. Hoogenboom, M. Wallace, J. V. van Hooft","Artificial intelligence for the management of pancreatic diseases",2020,"","","","",36,"2022-07-13 09:22:16","","10.1111/den.13875","","",,,,,9,4.50,2,4,2,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine‐learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models.","",""
5,"C. Kyrkou, A. Papachristodoulou, A. Kloukiniotis, A. Papandreou, A. Lalos, K. Moustakas, T. Theocharides","Towards Artificial-Intelligence-Based Cybersecurity for Robustifying Automated Driving Systems Against Camera Sensor Attacks",2020,"","","","",37,"2022-07-13 09:22:16","","10.1109/isvlsi49217.2020.00-11","","",,,,,5,2.50,1,7,2,"CARAMEL is a European project that aims amongst others to improve and extend cyberthreat detection and mitigation techniques for automotive driving systems. This paper highlights the important role that advanced artificial intelligence and machine learning techniques can have in proactively addressing modern autonomous vehicle cybersecurity challenges and on mitigating associated safety risks when dealing with targetted attacks on a vehicle's camera sensors. The cybersecurity solutions developed by CARAMEL are based on powerful AI tools and algorithms to combat security risks in automated driving systems and will be hosted on embedded processors and platforms. As such, it will be possible to have a specialized anti-hacking device that addresses newly introduced technological dimensions for increased robustness and cybersecurity in addition to industry needs for high speed, low latency, functional safety, light weight, low power consumption.","",""
5,"David Abele, Sara D’Onofrio","Artificial Intelligence – The Big Picture",2020,"","","","",38,"2022-07-13 09:22:16","","10.1007/978-3-658-27941-7_2","","",,,,,5,2.50,3,2,2,"","",""
16,"Emily J. Allen, Ghislain St-Yves, Yihan Wu, J. Breedlove, Jacob S. Prince, Logan T Dowdle, Matthias Nau, B. Caron, F. Pestilli, I. Charest, J. B. Hutchinson, Thomas Naselaris, Kendrick Norris Kay","A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence",2021,"","","","",39,"2022-07-13 09:22:16","","10.1038/s41593-021-00962-x","","",,,,,16,16.00,2,13,1,"","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",40,"2022-07-13 09:22:16","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",41,"2022-07-13 09:22:16","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
6,"V. Barchasz, Valentin Gies, Sebastián Marzetti, H. Glotin","A novel low-power high speed accurate and precise DAQ with embedded artificial intelligence for long term biodiversity survey",2020,"","","","",42,"2022-07-13 09:22:16","","10.48465/FA.2020.0875","","",,,,,6,3.00,2,4,2,"Acoustic monitoring is a key feature for studying biodiver-sity. Recent works on very high frequency animal soundsopen new insights and challenges on biodiversity survey.In order to set a scaled monitoring, and to cover mostof the frequencies of the present species, a novel multi-channel ultra high velocity recorder has been designed,called Qualilife HighBlue. This paper presents its archi-tecture and characteristics. One of its most innovative fea-tures is an always-on ultra-low power wake-up, trigger-ing recordings when temporal and/or spectral interestingevents are detected. For this task, shallow neural net-works are embedded for advanced pattern detection, aswell as mixed signal features extractors. Several commu-nications devices are implemented, and the system can becustomised. Multiple deployments of this monitoring sys-tem over the world are presented in this paper to demon-strate its robustness, versatility and efficiency.","",""
12,"Nathalie A. Smuha","From a ‘race to AI’ to a ‘race to AI regulation’: regulatory competition for artificial intelligence",2021,"","","","",43,"2022-07-13 09:22:16","","10.1080/17579961.2021.1898300","","",,,,,12,12.00,12,1,1,"ABSTRACT Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is a possibility, a reality and a desirability.","",""
12,"M. Yoosefzadeh-Najafabadi, D. Tulpan, M. Eskandari","Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices",2021,"","","","",44,"2022-07-13 09:22:16","","10.3390/rs13132555","","",,,,,12,12.00,4,3,1,"Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",45,"2022-07-13 09:22:16","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
10,"S. Mukhopadhyay, Sumarga Kumar Sah Tyagi, N. Suryadevara, V. Piuri, F. Scotti, S. Zeadally","Artificial Intelligence-Based Sensors for Next Generation IoT Applications: A Review",2021,"","","","",46,"2022-07-13 09:22:16","","10.1109/JSEN.2021.3055618","","",,,,,10,10.00,2,6,1,"Sensors play a vital role in our daily lives and are an essential component for Internet of Things (IoT) based systems as they enable the IoT to collect data to take smart and intelligent decisions. Recent advances in IoT systems, applications, and technologies, including industrial Cyber-Physical Systems (CPSs), are being supported by a wide range of different types of sensors based on artificial intelligence (AI). These smart AI-based sensors are typically characterized by onboard intelligence and have the ability to communicate collaboratively or through the Internet. To achieve the high level of automation required in today’s smart IoT applications, sensors incorporated into nodes must be efficient, intelligent, context-aware, reliable, accurate, and connected. Such sensors must also be robust, safety- and privacy-aware for users interacting with them. Sensors leveraging advanced AI technologies, new capabilities have recently emerged which have the potential to detect, identify, and avoid performance degradation and discover new patterns. Along with knowledge from complex sensor datasets, they can promote product innovation, improve operation level, and open up novel business models. We review sensors, smart data processing, communication protocol, and artificial intelligence which will enable the deployment of AI-based sensors for next-generation IoT applications.","",""
10,"Bo Zhao, Shaozeng Zhang, Chunxue Xu, Yifan Sun, Chengbin Deng","Deep fake geography? When geospatial data encounter Artificial Intelligence",2021,"","","","",47,"2022-07-13 09:22:16","","10.1080/15230406.2021.1910075","","",,,,,10,10.00,2,5,1,"ABSTRACT The developing convergence of Artificial Intelligence and GIScience has raised a concern on the emergence of deep fake geography and its potentials in transforming human perception of the geographic world. Situating fake geography under the context of modern cartography and GIScience, this paper presents an empirical study to dissect the algorithmic mechanism of falsifying satellite images with non-existent landscape features. To demonstrate our pioneering attempt at deep fake detection, a robust approach is then proposed and evaluated. Our proactive study warns of the emergence and proliferation of deep fakes in geography just as “lies” in maps. We suggest timely detections of deep fakes in geospatial data and proper coping strategies when necessary. More importantly, it is encouraged to cultivate a critical geospatial data literacy and thus to understand the multi-faceted impacts of deep fake geography on individuals and human society.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",48,"2022-07-13 09:22:16","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
109,"Shilin Qiu, Qihe Liu, Shijie Zhou, Chunjiang Wu","Review of Artificial Intelligence Adversarial Attack and Defense Technologies",2019,"","","","",49,"2022-07-13 09:22:16","","10.3390/APP9050909","","",,,,,109,36.33,27,4,3,"In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Therefore, improving the robustness of AI systems against adversarial attacks has played an increasingly important role in the further development of AI. This paper aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. According to the target model’s different stages where the adversarial attack occurred, this paper expounds the adversarial attack methods in the training stage and testing stage respectively. Then, we sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world. Finally, we describe the existing adversarial defense methods respectively in three main categories, i.e., modifying data, modifying models and using auxiliary tools.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",50,"2022-07-13 09:22:16","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
31,"T. Ertekin, Qian Sun","Artificial Intelligence Applications in Reservoir Engineering: A Status Check",2019,"","","","",51,"2022-07-13 09:22:16","","10.3390/EN12152897","","",,,,,31,10.33,16,2,3,"This article provides a comprehensive review of the state-of-art in the area of artificial intelligence applications to solve reservoir engineering problems. Research works including proxy model development, artificial-intelligence-assisted history-matching, project design, and optimization, etc. are presented to demonstrate the robustness of the intelligence systems. The successes of the developments prove the advantages of the AI approaches in terms of high computational efficacy and strong learning capabilities. Thus, the implementation of intelligence models enables reservoir engineers to accomplish many challenging and time-intensive works more effectively. However, it is not yet astute to completely replace the conventional reservoir engineering models with intelligent systems, since the defects of the technology cannot be ignored. The trend of research and industrial practices of reservoir engineering area would be establishing a hand-shaking protocol between the conventional modeling and the intelligent systems. Taking advantages of both methods, more robust solutions could be obtained with significantly less computational overheads.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",52,"2022-07-13 09:22:16","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",53,"2022-07-13 09:22:16","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
9,"Seunghyeon Kim, Yeon-Hee Lee, Yung-kyun Noh, F. Park, Q-Schick Auh","Age-group determination of living individuals using first molar images based on artificial intelligence",2021,"","","","",54,"2022-07-13 09:22:16","","10.1038/s41598-020-80182-8","","",,,,,9,9.00,2,5,1,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",55,"2022-07-13 09:22:16","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
29,"Melanie Mitchell","Artificial Intelligence Hits the Barrier of Meaning",2019,"","","","",56,"2022-07-13 09:22:16","","10.3390/info10020051","","",,,,,29,9.67,29,1,3,"Today’s AI systems sorely lack the essence of human intelligence: Understanding the situations we experience, being able to grasp their meaning. The lack of humanlike understanding in machines is underscored by recent studies demonstrating lack of robustness of state-of-the-art deep-learning systems. Deeper networks and larger datasets alone are not likely to unlock AI’s “barrier of meaning”; instead the field will need to embrace its original roots as an interdisciplinary science of intelligence.","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",57,"2022-07-13 09:22:16","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",58,"2022-07-13 09:22:16","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",59,"2022-07-13 09:22:16","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
6,"A. Allam, S. Feuerriegel, M. Rebhan, M. Krauthammer","Analyzing Patient Trajectories With Artificial Intelligence.",2021,"","","","",60,"2022-07-13 09:22:16","","10.2196/29812","","",,,,,6,6.00,2,4,1,"In digital medicine, patient data typically record health events over time (eg, through electronic health records, wearables, or other sensing technologies) and thus form unique patient trajectories. Patient trajectories are highly predictive of the future course of diseases and therefore facilitate effective care. However, digital medicine often uses only limited patient data, consisting of health events from only a single or small number of time points while ignoring additional information encoded in patient trajectories. To analyze such rich longitudinal data, new artificial intelligence (AI) solutions are needed. In this paper, we provide an overview of the recent efforts to develop trajectory-aware AI solutions and provide suggestions for future directions. Specifically, we examine the implications for developing disease models from patient trajectories along the typical workflow in AI: problem definition, data processing, modeling, evaluation, and interpretation. We conclude with a discussion of how such AI solutions will allow the field to build robust models for personalized risk scoring, subtyping, and disease pathway discovery.","",""
6,"M. Krass, Peter Henderson, M. Mello, D. Studdert, Daniel E. Ho","How US law will evaluate artificial intelligence for covid-19",2021,"","","","",61,"2022-07-13 09:22:16","","10.1136/bmj.n234","","",,,,,6,6.00,1,5,1,"Daniel E Ho and colleagues explore the legal implications of using artificial intelligence in the response to covid-19 and call for more robust evaluation frameworks","",""
6,"Shona Nabwire, H. Suh, M. Kim, I. Baek, B. Cho","Review: Application of Artificial Intelligence in Phenomics",2021,"","","","",62,"2022-07-13 09:22:16","","10.3390/s21134363","","",,,,,6,6.00,1,5,1,"Plant phenomics has been rapidly advancing over the past few years. This advancement is attributed to the increased innovation and availability of new technologies which can enable the high-throughput phenotyping of complex plant traits. The application of artificial intelligence in various domains of science has also grown exponentially in recent years. Notably, the computer vision, machine learning, and deep learning aspects of artificial intelligence have been successfully integrated into non-invasive imaging techniques. This integration is gradually improving the efficiency of data collection and analysis through the application of machine and deep learning for robust image analysis. In addition, artificial intelligence has fostered the development of software and tools applied in field phenotyping for data collection and management. These include open-source devices and tools which are enabling community driven research and data-sharing, thereby availing the large amounts of data required for the accurate study of phenotypes. This paper reviews more than one hundred current state-of-the-art papers concerning AI-applied plant phenotyping published between 2010 and 2020. It provides an overview of current phenotyping technologies and the ongoing integration of artificial intelligence into plant phenotyping. Lastly, the limitations of the current approaches/methods and future directions are discussed.","",""
6,"Mainak Biswas, L. Saba, Tomaž Omerzu, A. Johri, N. N. Khanna, K. Višković, S. Mavrogeni, J. Laird, G. Pareek, M. Miner, A. Balestrieri, P. Sfikakis, A. Protogerou, D. Misra, V. Agarwal, G. Kitas, R. Kolluri, Aditya M. Sharma, V. Viswanathan, Z. Ruzsa, A. Nicolaides, J. Suri","A Review on Joint Carotid Intima-Media Thickness and Plaque Area Measurement in Ultrasound for Cardiovascular/Stroke Risk Monitoring: Artificial Intelligence Framework",2021,"","","","",63,"2022-07-13 09:22:16","","10.1007/s10278-021-00461-2","","",,,,,6,6.00,1,22,1,"","",""
17,"K. Assi, M. Shafiullah, K. Nahiduzzaman, Umer Mansoor","Travel-To-School Mode Choice Modelling Employing Artificial Intelligence Techniques: A Comparative Study",2019,"","","","",64,"2022-07-13 09:22:16","","10.3390/SU11164484","","",,,,,17,5.67,4,4,3,"Many techniques including logistic regression and artificial intelligence have been employed to explain school-goers mode choice behavior. This paper aims to compare the effectiveness, robustness, and convergence of three different machine learning tools (MLT), namely the extreme learning machine (ELM), support vector machine (SVM), and multi-layer perceptron neural network (MLP-NN) to predict school-goers mode choice behavior in Al-Khobar and Dhahran cities of the Kingdom of Saudi Arabia (KSA). It uses the students’ information, including the school grade, the distance between home and school, travel time, family income and size, number of students in the family and education level of parents as input variables to the MLT. However, their outputs were binary, that is, either to choose the passenger car or walking to the school. The study examined a promising performance of the ELM and MLP-NN suggesting their significance as alternatives for school-goers mode choice modeling. The performances of the SVM was satisfactory but not to the same level of significance in comparison with the other two. Moreover, the SVM technique is computationally more expensive over the ELM and MLP-NN. Further, this research develops a majority voting ensemble method based on the outputs of the employed MLT to enhance the overall prediction performance. The presented results confirm the efficacy and superiority of the ensemble method over the others. The study results are likely to guide the transport engineers, planners, and decision-makers by providing them with a reliable way to model and predict the traffic demand for transport infrastructures on the basis of the prevailing mode choice behavior.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",65,"2022-07-13 09:22:16","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",66,"2022-07-13 09:22:16","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",67,"2022-07-13 09:22:16","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
54,"X. Bui, Hoang Nguyen, Yosoon Choi, T. Nguyen-Thoi, Jian Zhou, Jie Dou","Prediction of slope failure in open-pit mines using a novel hybrid artificial intelligence model based on decision tree and evolution algorithm",2020,"","","","",68,"2022-07-13 09:22:16","","10.1038/s41598-020-66904-y","","",,,,,54,27.00,9,6,2,"","",""
4,"Matthew S. Lee, Shuanzeng Wei, J. Anaokar, R. Uzzo, A. Kutikov","Kidney cancer management 3.0: can artificial intelligence make us better?",2021,"","","","",69,"2022-07-13 09:22:16","","10.1097/MOU.0000000000000881","","",,,,,4,4.00,1,5,1,"Purpose of review Artificial intelligence holds tremendous potential for disrupting clinical medicine. Here we review the current role of artificial intelligence in the kidney cancer space. Recent findings Machine learning and deep learning algorithms have been developed using information extracted from radiomic, histopathologic, and genomic datasets of patients with renal masses. Summary Although artificial intelligence applications in medicine are still in their infancy, they already hold immediate promise to improve accuracy of renal mass characterization, grade, and prognostication. As algorithms become more robust and generalizable, artificial intelligence is poised to significantly disrupt kidney cancer care.","",""
4,"O. L. Saldanha, P. Quirke, N. West, J. James, M. Loughrey, H. Grabsch, M. Salto‐Tellez, E. Alwers, Didem Cifci, Narmin Ghaffari Laleh, T. Seibel, Richard Gray, G. Hutchins, H. Brenner, T. Yuan, T. Brinker, J. Chang-Claude, Firas Khader, A. Schuppert, T. Luedde, S. Foersch, H. Muti, C. Trautwein, M. Hoffmeister, D. Truhn, J. Kather","Swarm learning for decentralized artificial intelligence in cancer histopathology",2021,"","","","",70,"2022-07-13 09:22:16","","10.1038/s41591-022-01768-5","","",,,,,4,4.00,0,26,1,"","",""
4,"S. M. Tayyab, S. Chatterton, P. Pennacchi","Fault Detection and Severity Level Identification of Spiral Bevel Gears under Different Operating Conditions Using Artificial Intelligence Techniques",2021,"","","","",71,"2022-07-13 09:22:16","","10.3390/machines9080173","","",,,,,4,4.00,1,3,1,"Spiral bevel gears are known for their smooth operation and high load carrying capability; therefore, they are an important part of many transmission systems that are designed for high speed and high load applications. Due to high contact ratio and complex vibration signal, their fault detection is really challenging even in the case of serious defects. Therefore, spiral bevel gears have rarely been used as benchmarking for gears’ fault diagnosis. In this research study, Artificial Intelligence (AI) techniques have been used for fault detection and fault severity level identification of spiral bevel gears under different operating conditions. Although AI techniques have gained much success in this field, it is mostly assumed that the operating conditions under which the trained AI model is deployed for fault diagnosis are same compared to those under which the AI model was trained. If they differ, the performance of AI model may degrade significantly. In order to overcome this limitation, in this research study, an effort has been made to find few robust features that show minimal change due to changing operating conditions; however, they are fault discriminating. Artificial neural network (ANN) and K-nearest neighbors (KNN) are used as classifiers and both models are trained and tested by using the selected robust features for fault detection and severity assessment of spiral bevel gears under different operating conditions. A performance comparison between both classifiers is also carried out.","",""
5,"T. Mahmood, Muhammad Owais, Kyoung Jun Noh, Hyo Sik Yoon, J. Koo, A. Haider, H. Sultan, K. Park","Accurate Segmentation of Nuclear Regions with Multi-Organ Histopathology Images Using Artificial Intelligence for Cancer Diagnosis in Personalized Medicine",2021,"","","","",72,"2022-07-13 09:22:16","","10.3390/jpm11060515","","",,,,,5,5.00,1,8,1,"Accurate nuclear segmentation in histopathology images plays a key role in digital pathology. It is considered a prerequisite for the determination of cell phenotype, nuclear morphometrics, cell classification, and the grading and prognosis of cancer. However, it is a very challenging task because of the different types of nuclei, large intraclass variations, and diverse cell morphologies. Consequently, the manual inspection of such images under high-resolution microscopes is tedious and time-consuming. Alternatively, artificial intelligence (AI)-based automated techniques, which are fast and robust, and require less human effort, can be used. Recently, several AI-based nuclear segmentation techniques have been proposed. They have shown a significant performance improvement for this task, but there is room for further improvement. Thus, we propose an AI-based nuclear segmentation technique in which we adopt a new nuclear segmentation network empowered by residual skip connections to address this issue. Experiments were performed on two publicly available datasets: (1) The Cancer Genome Atlas (TCGA), and (2) Triple-Negative Breast Cancer (TNBC). The results show that our proposed technique achieves an aggregated Jaccard index (AJI) of 0.6794, Dice coefficient of 0.8084, and F1-measure of 0.8547 on TCGA dataset, and an AJI of 0.7332, Dice coefficient of 0.8441, precision of 0.8352, recall of 0.8306, and F1-measure of 0.8329 on the TNBC dataset. These values are higher than those of the state-of-the-art methods.","",""
4,"Z. Akkus, Yousof H. Aly, Itzhak Z. Attia, F. Lopez‐Jimenez, A. Arruda-Olson, P. Pellikka, S. Pislaru, G. Kane, P. Friedman, J. Oh","Artificial Intelligence (AI)-Empowered Echocardiography Interpretation: A State-of-the-Art Review",2021,"","","","",73,"2022-07-13 09:22:16","","10.3390/jcm10071391","","",,,,,4,4.00,0,10,1,"Echocardiography (Echo), a widely available, noninvasive, and portable bedside imaging tool, is the most frequently used imaging modality in assessing cardiac anatomy and function in clinical practice. On the other hand, its operator dependability introduces variability in image acquisition, measurements, and interpretation. To reduce these variabilities, there is an increasing demand for an operator- and interpreter-independent Echo system empowered with artificial intelligence (AI), which has been incorporated into diverse areas of clinical medicine. Recent advances in AI applications in computer vision have enabled us to identify conceptual and complex imaging features with the self-learning ability of AI models and efficient parallel computing power. This has resulted in vast opportunities such as providing AI models that are robust to variations with generalizability for instantaneous image quality control, aiding in the acquisition of optimal images and diagnosis of complex diseases, and improving the clinical workflow of cardiac ultrasound. In this review, we provide a state-of-the art overview of AI-empowered Echo applications in cardiology and future trends for AI-powered Echo technology that standardize measurements, aid physicians in diagnosing cardiac diseases, optimize Echo workflow in clinics, and ultimately, reduce healthcare costs.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",74,"2022-07-13 09:22:16","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",75,"2022-07-13 09:22:16","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",76,"2022-07-13 09:22:16","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",77,"2022-07-13 09:22:16","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",78,"2022-07-13 09:22:16","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",79,"2022-07-13 09:22:16","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",80,"2022-07-13 09:22:16","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
3,"H. Mohammed, S. Ismail","Proposition of new computer artificial intelligence models for shear strength prediction of reinforced concrete beams",2021,"","","","",81,"2022-07-13 09:22:16","","10.1007/S00366-021-01400-Z","","",,,,,3,3.00,2,2,1,"","",""
3,"M. Padmaja, S. Shitharth, K. Prasuna, Abhay Chaturvedi, P. Kshirsagar, A. Vani","Grow of Artificial Intelligence to Challenge Security in IoT Application",2021,"","","","",82,"2022-07-13 09:22:16","","10.1007/s11277-021-08725-4","","",,,,,3,3.00,1,6,1,"","",""
3,"Feng Xiao, Jintao Ke","Pricing, management and decision-making of financial markets with artificial intelligence: introduction to the issue",2021,"","","","",83,"2022-07-13 09:22:16","","10.1186/s40854-021-00302-9","","",,,,,3,3.00,2,2,1,"","",""
2,"Zahraa Bassyouni, I. Elhajj","Augmented Reality Meets Artificial Intelligence in Robotics: A Systematic Review",2021,"","","","",84,"2022-07-13 09:22:16","","10.3389/frobt.2021.724798","","",,,,,2,2.00,1,2,1,"Recently, advancements in computational machinery have facilitated the integration of artificial intelligence (AI) to almost every field and industry. This fast-paced development in AI and sensing technologies have stirred an evolution in the realm of robotics. Concurrently, augmented reality (AR) applications are providing solutions to a myriad of robotics applications, such as demystifying robot motion intent and supporting intuitive control and feedback. In this paper, research papers combining the potentials of AI and AR in robotics over the last decade are presented and systematically reviewed. Four sources for data collection were utilized: Google Scholar, Scopus database, the International Conference on Robotics and Automation 2020 proceedings, and the references and citations of all identified papers. A total of 29 papers were analyzed from two perspectives: a theme-based perspective showcasing the relation between AR and AI, and an application-based analysis highlighting how the robotics application was affected. These two sections are further categorized based on the type of robotics platform and the type of robotics application, respectively. We analyze the work done and highlight some of the prevailing limitations hindering the field. Results also explain how AR and AI can be combined to solve the model-mismatch paradigm by creating a closed feedback loop between the user and the robot. This forms a solid base for increasing the efficiency of the robotic application and enhancing the user’s situational awareness, safety, and acceptance of AI robots. Our findings affirm the promising future for robust integration of AR and AI in numerous robotic applications.","",""
2,"Chiara Longoni, Andrey Fradkin, Luca Cian, Gordon Pennycook","News from Artificial Intelligence is Believed Less",2021,"","","","",85,"2022-07-13 09:22:16","","10.2139/SSRN.3787064","","",,,,,2,2.00,1,4,1,"Artificial Intelligence (AI) algorithms are now able to produce text virtually indistinguishable from text written by humans across a variety of domains. A key question, then, is whether people believe content from AI as much as content from humans. Trust in the (human generated) news media has been decreasing over time and AI is viewed as lacking human desires, and emotions, suggesting that AI news may be viewed as more accurate. Contrary to this, two preregistered experiments conducted on representative U.S. samples (combined N = 4,034) showed that people rated news produced by AI as being less accurate than news produced by humans. When news items were tagged as produced by AI (compared to a human), people were more likely to incorrectly rate them as inaccurate when they were actually true, and more likely to correctly rate them as inaccurate when they were indeed false. These results were robust to experimental paradigm (separate and joint evaluations), news item (actual veracity, age), and several respondent characteristics (e.g., political orientation). This effect is particularly important given the increasing use of AI algorithms in news production, and the associated ethical and governance pressures to disclose their use.","",""
1,"M. Panahiazar, Nolan Chen, D. Lituiev, D. Hadley","Empowering study of breast cancer data with application of artificial intelligence technology: promises, challenges, and use cases",2021,"","","","",86,"2022-07-13 09:22:16","","10.1007/s10585-021-10125-8","","",,,,,1,1.00,0,4,1,"","",""
2,"P. Kumar","Special issue on Artificial Intelligence in Engineering Education",2021,"","","","",87,"2022-07-13 09:22:16","","10.1002/cae.22398","","",,,,,2,2.00,2,1,1,"Artificial intelligence (AI) can be defined as the intelligence exhibited by machines and computers in accomplishing desired tasks in a similar way to how normal human beings think and act. Hence AI is also termed machine intelligence. For a computational system to be artificially intelligent, the system should possess the ability to understand the surrounding environment, make proper assumptions, and based on the circumstances make judicious decisions that maximize the possibilities of accomplishing goals most of the time. These AI‐enabled devices are also called Intelligent Agents. These intelligent agents use some mapping functions also termed cognitive functions, which take these environmental parameters and contextual information as inputs along with the goal to be accomplished and manipulate the right means to accomplish the targeted goal. AI can also be considered inter‐ disciplinary as it involves several other disciplines such as Machine Learning, Computer Vision, Cognitive Science, Neural Networks, Data Mining, Natural Language Processing (NLP), robotics, and mathematics. All these disciplines are related, and thereby intelligent agents are trained to understand and adapt to the surrounding environment according to the context. The use of AI spans across several applications such as Human–Computer Interaction (HCI) based smart agent development, devising smart surveillance solutions using computer vision, creating robust and stable decision making systems that can understand, evaluate, manipulate, analyze, and predict several novel patterns by processing large volumes of application data, development of multilingual systems that uses NLP to understand the language features used across the context and aid decision making and so on. Also, since its inception as an academic discipline in the 1950s, AI has grown leaps and bounds as a discipline, and its applications have stretched across several domains such as Retail and Business solutions, Manufacturing and Logistics, Automobiles, Business Analytics and Market predictions, Healthcare, Security Systems, and Education. One of the key emerging areas where extensive efforts are spent towards developing smart applications and agents is the educational domain. Gone are the days where the educational system was completely driven by humans, and the growth of AI‐enabled intelligent agents has set the tone by replacing most human work with that of smart agents. Educational systems use AI‐based agents to study the behavior of students and suggest suitable courses for them. Smart agents are nowadays deployed in classrooms for complete classroom monitoring that includes tracking attendance, monitoring classroom activities, student and staff behavior monitoring, and so on. Similarly, smart agents are deployed to scan through the contents available online and suggest suitable content to students according to the course and also according to the different levels of understanding of student fraternity. Also, computer vision‐based smart agents are deployed to study the state of mind of students when they undergo different courses and provide insightful information about their likeness towards a subject or course. This agent‐based information serves as useful information in deciding the teaching methodology and also framing of course contents. Also, smart systems play a vital role in analyzing student results and providing insightful information about student performance. Thus, it is imperative that AI has become an indispensable force to reckon with in the future forward across the educational domain. However, the major drawback in these artificially intelligent systems is that they are not always accurate with decision making and at times predict otherwise. Also, training the AI‐based agent to understand the contextual paradigm and surrounding environment is a challenge. This special issue on “Artificial Intelligence In Education” is focused on drawing original studies related to the development and refinement of smart agents that can be applied across the educational domain.","",""
2,"P. W. Grimm, Maura R. Grossman, G. Cormack","Artificial Intelligence as Evidence",2021,"","","","",88,"2022-07-13 09:22:16","","","","",,,,,2,2.00,1,3,1,"This article explores issues that govern the admissibility of Artificial Intelligence (“AI”) applications in civil and criminal cases, from the perspective of a federal trial judge and two computer scientists, one of whom also is an experienced attorney. It provides a detailed yet intelligible discussion of what AI is and how it works, a history of its development, and a description of the wide variety of functions that it is designed to accomplish, stressing that AI applications are ubiquitous, both in the private and public sectors. Applications today include: health care, education, employment-related decision-making, finance, law enforcement, and the legal profession. The article underscores the importance of determining the validity of an AI application (i.e., how accurately the AI measures, classifies, or predicts what it is designed to), as well as its reliability (i.e., the consistency with which the AI produces accurate results when applied to the same or substantially similar circumstances), in deciding whether it should be admitted into evidence in civil and criminal cases. The article further discusses factors that can affect the validity and reliability of AI evidence, including bias of various types, “function creep,” lack of transparency and explainability, and the sufficiency of the objective testing of AI applications before they are released for public use. The article next provides an in-depth discussion of the evidentiary principles that govern whether AI evidence should be admitted in court cases, a topic which, at present, is not the subject of comprehensive analysis in decisional law. The focus of this discussion is on providing a step-by-step analysis of the most important issues, and the factors that affect decisions on whether to admit AI evidence. Finally, the article concludes with a discussion of practical suggestions intended to assist lawyers and judges as they are called upon to introduce, object to, or decide on whether to admit AI evidence. 1 Hon. Paul W. Grimm is a United States District Judge for the District of Maryland, and an adjunct professor at both the University of Maryland Carey School of Law and the University of Baltimore School of Law. Maura R. Grossman, J.D., Ph.D., is a Research Professor, and Gordon V. Cormack, Ph.D., is a Professor, in the David R. Cheriton School of Computer Science at the University of Waterloo. Professor Grossman is also an affiliate faculty member at the Vector Institute for Artificial Intelligence. Her work is funded, in part, by the National Sciences and Engineering Council of Canada (“NESERC”). The opinions expressed in this article are the authors’ own, and do not necessarily reflect the views of the institutions or organizations with which they are affiliated. NORTHWESTERN JOURNAL OF TECHNOLOGY AND INTELLECTUAL PROPERTY 10 INTRODUCTION .............................................................................................................. 10 I. WHAT IS “ARTIFICIAL INTELLIGENCE”? .................................................................... 14 II. WHY AI HAS COME TO THE FOREFRONT TODAY ...................................................... 17 III. THE AI TECHNOLOGY LANDSCAPE .......................................................................... 24 IV. USES OF AI IN BUSINESS AND LAW TODAY .............................................................. 32 V. ISSUES RAISED BY THE USE OF AI IN BUSINESS AND LAW TODAY ............................ 41 A. Bias ............................................................................................................... 42 B. Lack of Robust Testing for Validity and Reliability ....................................... 48 C. Failure to Monitor for Function Creep ......................................................... 51 D. Failure to Ensure Data Privacy and Data Protection .................................. 53 E. Lack of Transparency and Explainabilty ....................................................... 60 F. Lack of Accountability ................................................................................... 65 G. Lack of Resilience ......................................................................................... 72 VI. ESTABLISHING VALIDITY AND RELIABILITY ........................................................... 79 A. Testimony, Expert Testimony, or Technology? .............................................. 79 B. Benchmarks and Goodhart’s Law ................................................................. 82 VII. EVIDENTIARY PRINCIPLES THAT SHOULD BE CONSIDERED IN EVALUATING THE ADMISSIBILITY OF AI EVIDENCE IN CIVIL AND CRIMINAL TRIALS .................... 84 A. Adequacy of the Federal Rules of Evidence in Addressing the Admissibility of AI Evidence ......................................................................... 84 B. Relevance ...................................................................................................... 86 C. Authentication of AI Evidence ....................................................................... 90 D. Usefulness of the Daubert Factors in Determining Whether to Admit AI Evidence ....................................................................................................... 95 E. Practice Pointers for Lawyers and Judges .................................................... 97 CONCLUSION ............................................................................................................... 105","",""
1,"Michael Yankoski, W. Theisen, E. Verdeja, W. Scheirer","Artificial Intelligence for Peace: An Early Warning System for Mass Violence",2021,"","","","",89,"2022-07-13 09:22:16","","10.1007/978-3-030-74420-5_7","","",,,,,1,1.00,0,4,1,"","",""
1,"M. Mofatteh","Neurosurgery and artificial intelligence",2021,"","","","",90,"2022-07-13 09:22:16","","10.3934/Neuroscience.2021025","","",,,,,1,1.00,1,1,1,"Neurosurgeons receive extensive and lengthy training to equip themselves with various technical skills, and neurosurgery require a great deal of pre-, intra- and postoperative clinical data collection, decision making, care and recovery. The last decade has seen a significant increase in the importance of artificial intelligence (AI) in neurosurgery. AI can provide a great promise in neurosurgery by complementing neurosurgeons' skills to provide the best possible interventional and noninterventional care for patients by enhancing diagnostic and prognostic outcomes in clinical treatment and help neurosurgeons with decision making during surgical interventions to improve patient outcomes. Furthermore, AI is playing a pivotal role in the production, processing and storage of clinical and experimental data. AI usage in neurosurgery can also reduce the costs associated with surgical care and provide high-quality healthcare to a broader population. Additionally, AI and neurosurgery can build a symbiotic relationship where AI helps to push the boundaries of neurosurgery, and neurosurgery can help AI to develop better and more robust algorithms. This review explores the role of AI in interventional and noninterventional aspects of neurosurgery during pre-, intra- and postoperative care, such as diagnosis, clinical decision making, surgical operation, prognosis, data acquisition, and research within the neurosurgical arena.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",91,"2022-07-13 09:22:16","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",92,"2022-07-13 09:22:16","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",93,"2022-07-13 09:22:16","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",94,"2022-07-13 09:22:16","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",95,"2022-07-13 09:22:16","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
9,"J. Chen, Jen-Ting Chang","Route Choice Behaviour Modeling using IoT Integrated Artificial Intelligence",2021,"","","","",96,"2022-07-13 09:22:16","","10.36548/JAICN.2020.4.006","","",,,,,9,9.00,5,2,1,"Automatic Vehicle Identification (AVI) data is used to identify the location of a particular vehicle in and can also be used for route choice behaviour modelling. But the use of AVI doesn’t provide accurate information on OD pair and the particular route that is chosen. This problem is addressed in this paper using a semi-supervised learning method which can be used to identify the route on prior training. As the first step, the AVI trace is segregated into observation pairs using the Maximum Likelihood Estimation and then it is further joined with GPS co-ordinates to tackle the sparse issues. As the next step, the heterogeneity and correlation between the various pairs are determined using Mixed Logit model. As the final step, a relationship between the likelihood function and route choice model is established using Maximum to log-likelihood function. Based on the observations, the results are recorded and the proposed work shows significant improvement in the accuracy in route determination. The evaluation scenario shows that the proposed work could be expanded to a larger area. Moreover, the robustness of the system is illustrated using sensitivity analysis. This work uses AVI data with respect to its behaviour in routes through high penetration.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",97,"2022-07-13 09:22:16","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",98,"2022-07-13 09:22:16","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",99,"2022-07-13 09:22:16","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",100,"2022-07-13 09:22:16","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
0,"Pan Wang, Yangyang Zhong, Zhenan Yao","Modeling and Estimation of CO2 Emissions in China Based on Artificial Intelligence",2022,"","","","",101,"2022-07-13 09:22:16","","10.1155/2022/6822467","","",,,,,0,0.00,0,3,1,"Since China’s reform and opening up, the social economy has achieved rapid development, followed by a sharp increase in carbon dioxide (CO2) emissions. Therefore, at the 75th United Nations General Assembly, China proposed to achieve carbon peaking by 2030 and carbon neutrality by 2060. The research work on advance forecasting of CO2 emissions is essential to achieve the above-mentioned carbon peaking and carbon neutrality goals in China. In order to achieve accurate prediction of CO2 emissions, this study establishes a hybrid intelligent algorithm model suitable for CO2 emissions prediction based on China’s CO2 emissions and related socioeconomic indicator data from 1971 to 2017. The hyperparameters of Least Squares Support Vector Regression (LSSVR) are optimized by the Adaptive Artificial Bee Colony (AABC) algorithm to build a high-performance hybrid intelligence model. The research results show that the hybrid intelligent algorithm model designed in this paper has stronger robustness and accuracy with relative error almost within ±5% in the advance prediction of CO2 emissions. The modeling scheme proposed in this study can not only provide strong support for the Chinese government and industry departments to formulate policies related to the carbon peaking and carbon neutrality goals, but also can be extended to the research of other socioeconomic-related issues.","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",102,"2022-07-13 09:22:16","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
25,"Aphra Kerr, Marguerite Barry, John D. Kelleher","Expectations of artificial intelligence and the performativity of ethics: Implications for communication governance",2020,"","","","",103,"2022-07-13 09:22:16","","10.1177/2053951720915939","","",,,,,25,12.50,8,3,2,"This article draws on the sociology of expectations to examine the construction of expectations of ‘ethical AI’ and considers the implications of these expectations for communication governance. We first analyse a range of public documents to identify the key actors, mechanisms and issues which structure societal expectations around artificial intelligence (AI) and an emerging discourse on ethics. We then explore expectations of AI and ethics through a survey of members of the public. Finally, we discuss the implications of our findings for the role of AI in communication governance. We find that, despite societal expectations that we can design ethical AI, and public expectations that developers and governments should share responsibility for the outcomes of AI use, there is a significant divergence between these expectations and the ways in which AI technologies are currently used and governed in large scale communication systems. We conclude that discourses of ‘ethical AI’ are generically performative, but to become more effective we need to acknowledge the limitations of contemporary AI and the requirement for extensive human labour to meet the challenges of communication governance. An effective ethics of AI requires domain appropriate AI tools, updated professional practices, dignified places of work and robust regulatory and accountability frameworks.","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",104,"2022-07-13 09:22:16","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",105,"2022-07-13 09:22:16","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",106,"2022-07-13 09:22:16","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",107,"2022-07-13 09:22:16","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
5,"S. D. Krachai, A. Stambouli, M. D. Krachai, M. Bekhti","Experimental investigation of artificial intelligence applied in MPPT techniques",2019,"","","","",108,"2022-07-13 09:22:16","","10.11591/IJPEDS.V10.I4.PP2138-2147","","",,,,,5,1.67,1,4,3,"Nano-satellites are key features for sharing the space data and scientific researches. They embed subsystems that are fed from solar panels and batteries. Power generated from these panels is subject to environmental conditions, most important of them are irradiance and temperature. Optimizing the usage of this power versus environmental variations is a primary task. Synchronous DC-DC buck converter is used to control the power transferred from PV panels to the subsystems while maintaining operation at maximal power. In this paper, artificial intelligence techniques: neural networks and adaptive neural fuzzy inference systems (ANFIS) are used to accomplish the tracking task. Simulation and experimental results demonstrate their efficiency, robustness and tracking quality.","",""
2,"Yi Yang, Jiasong Sun, Lu Huang","Artificial Intelligence Teaching Methods in Higher Education",2019,"","","","",109,"2022-07-13 09:22:16","","10.1007/978-3-030-29516-5_78","","",,,,,2,0.67,1,3,3,"","",""
6,"B. Mahboub, M. Bataineh, H. Alshraideh, R. Hamoudi, Laila Salameh, A. Shamayleh","Prediction of COVID-19 Hospital Length of Stay and Risk of Death Using Artificial Intelligence-Based Modeling",2021,"","","","",110,"2022-07-13 09:22:16","","10.3389/fmed.2021.592336","","",,,,,6,6.00,1,6,1,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a highly infectious virus with overwhelming demand on healthcare systems, which require advanced predictive analytics to strategize COVID-19 management in a more effective and efficient manner. We analyzed clinical data of 2017 COVID-19 cases reported in the Dubai health authority and developed predictive models to predict the patient's length of hospital stay and risk of death. A decision tree (DT) model to predict COVID-19 length of stay was developed based on patient clinical information. The model showed very good performance with a coefficient of determination R2 of 49.8% and a median absolute deviation of 2.85 days. Furthermore, another DT-based model was constructed to predict COVID-19 risk of death. The model showed excellent performance with sensitivity and specificity of 96.5 and 87.8%, respectively, and overall prediction accuracy of 96%. Further validation using unsupervised learning methods showed similar separation patterns, and a receiver operator characteristic approach suggested stable and robust DT model performance. The results show that a high risk of death of 78.2% is indicated for intubated COVID-19 patients who have not used anticoagulant medications. Fortunately, intubated patients who are using anticoagulant and dexamethasone medications with an international normalized ratio of <1.69 have zero risk of death from COVID-19. In conclusion, we constructed artificial intelligence–based models to accurately predict the length of hospital stay and risk of death in COVID-19 cases. These smart models will arm physicians on the front line to enhance management strategies to save lives.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",111,"2022-07-13 09:22:16","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",112,"2022-07-13 09:22:16","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",113,"2022-07-13 09:22:16","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",114,"2022-07-13 09:22:16","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",115,"2022-07-13 09:22:16","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",116,"2022-07-13 09:22:16","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
3,"Pu Yanan, Yan Jilong, Zhang Heng","Using Artificial Intelligence to Achieve Auxiliary Training of Table Tennis Based on Inertial Perception Data",2021,"","","","",117,"2022-07-13 09:22:16","","10.3390/s21196685","","",,,,,3,3.00,1,3,1,"Compared with optical sensors, wearable inertial sensors have many advantages such as low cost, small size, more comprehensive application range, no space restrictions and occlusion, better protection of user privacy, and more suitable for sports applications. This article aims to solve irregular actions that table tennis enthusiasts do not know in actual situations. We use wearable inertial sensors to obtain human table tennis action data of professional table tennis players and non-professional table tennis players, and extract the features from them. Finally, we propose a new method based on multi-dimensional feature fusion convolutional neural network and fine-grained evaluation of human table tennis actions. Realize ping-pong action recognition and evaluation, and then achieve the purpose of auxiliary training. The experimental results prove that our proposed multi-dimensional feature fusion convolutional neural network has an average recognition rate that is 0.17 and 0.16 higher than that of CNN and Inception-CNN on the nine-axis non-professional test set, which proves that we can better distinguish different human table tennis actions and have a more robust generalization performance. Therefore, on this basis, we have better realized the enthusiast of table tennis the purpose of the action for auxiliary training.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",118,"2022-07-13 09:22:16","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
18,"Jocelyn Hui Lin Goh, Zhi Wei Lim, X. Fang, Ayesha Anees, S. Nusinovici, T. Rim, Ching-Yu Cheng, Yih-Chung Tham","Artificial Intelligence for Cataract Detection and Management.",2020,"","","","",119,"2022-07-13 09:22:16","","10.1097/01.APO.0000656988.16221.04","","",,,,,18,9.00,2,8,2,"The rising popularity of artificial intelligence (AI) in ophthalmology is fuelled by the ever-increasing clinical ""big data"" that can be used for algorithm development. Cataract is one of the leading causes of visual impairment worldwide. However, compared with other major age-related eye diseases, such as diabetic retinopathy, age-related macular degeneration, and glaucoma, AI development in the domain of cataract is still relatively underexplored. In this regard, several previous studies explored algorithms for automated cataract assessment using either slit lamp of color fundus photographs. However, several other study groups proposed or derived new AI-based calculation for pre-cataract surgery intraocular lens power. Along with advancements in digitization of clinical data, data curation for future cataract-related AI developmental work is bound to undergo significant improvements in the foreseeable future. Even though most of these previous studies reported early promising performances, limitations such as lack of robust, high-quality training data, and lack of external validations remain. In the next phase of work, apart from algorithm's performance, it will also be pertinent to evaluate deployment angles, feasibility, efficiency, and cost-effectiveness of these new cataract-related AI systems.","",""
2,"Thomas Garvin, Scott Kimbleton","Artificial intelligence as ally in hazard analysis",2021,"","","","",120,"2022-07-13 09:22:16","","10.1002/prs.12243","","",,,,,2,2.00,1,2,1,"Hazard analysis techniques have been around for many years, and have proven effective in the prevention of incidents and no doubt the saving of lives. Process hazard analysis (PHA) is now fairly robust and regulated, focused on overarching risks associated with the safe handling of hazardous materials and approaches to engineer‐out such risks. Occupational hazard analysis (OHA) is keenly focused on human activity, and personal protection in hazardous working conditions. Both approaches are critical ‐ but are often carried out separately, by different parts of an organization, which could result in an incomplete picture of the full set of operational risks in the field. Developing a holistic picture of both past and present dangers calls for a deep exploration of evidence. HAZOPs, PHA's, incident records and investigations provide expert analysis of hazards and mitigating strategies. Near‐miss reports and safety observations add a large amount of information as well; the reporting frequency of these “leading indicators” can be both a blessing and a curse, as time and available resources constrain the ability to analyze and detect hazard signals within. As important as analyzing the historical record is for lessons learned, the more recent observations could indicate new hazards or highlight concerning trends. These could feed valuable “real time” information back to operations and maintenance teams to improve risk assessments and task planning. Enter artificial intelligence (AI) as a means to analyze the large amount of written hazard analyses, reports and observations to quickly extract insights around hazardous conditions, activities, incident causes and risk mitigation measures. Trained to understand concepts and contexts in both process and personal safety, AI can provide a natural‐language information exploration environment for scanning thousands of documents in seconds and present common themes and related records. Not unlike us humans, AI learns from the past, informs the present and can help reduce risks in the future.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",121,"2022-07-13 09:22:16","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",122,"2022-07-13 09:22:16","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",123,"2022-07-13 09:22:16","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",124,"2022-07-13 09:22:16","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
14,"E. Kotter, E. Ranschaert","Challenges and solutions for introducing artificial intelligence (AI) in daily clinical workflow",2020,"","","","",125,"2022-07-13 09:22:16","","10.1007/s00330-020-07148-2","","",,,,,14,7.00,7,2,2,"","",""
14,"M. Yazdani-Asrami, Mehran Taghipour-Gorjikolaie, Wenjuan Song, Min Zhang, W. Yuan","Prediction of Nonsinusoidal AC Loss of Superconducting Tapes Using Artificial Intelligence-Based Models",2020,"","","","",126,"2022-07-13 09:22:16","","10.1109/ACCESS.2020.3037685","","",,,,,14,7.00,3,5,2,"Current is no longer sinusoidal in modern electric networks because of widespread use of power electronic-based equipments and nonlinear loads. Usually AC loss is calculated for pure sinusoidal current, while it is no longer accurate when current is nonsinusoidal. On the other hand, efficiency of cooling system in large scale power devices is dependent on accurate estimation and prediction of the heat load caused by AC loss in design stage. Therefore, estimation of nonsinusoidal AC loss of high temperature superconducting (HTS) material would be of great interest for designers of large-scale superconducting devices. In this paper, at first nonsinusoidal AC loss of a typical HTS tape was calculated under distorted currents using H-formulation finite element method. Then, a range of artificial intelligence (AI) models were implemented to predict AC loss of a typical HTS tape. In order to find the best and more adaptive AI model for nonsinusoidal AC loss prediction, different regression models are evaluated using Support Vector Machine regression model, Generalized Linear regression model, Decision Tree regression model, Feed Forward Neural Network based model, Adaptive Neuro Fuzzy Inference System based model, and Radial Basis Function Neural Network (RBFNN) based model. In order to evaluate robustness of developed models cross-validation technique is implemented on experimental data. To compare the performance of different AI models, four prediction measures were used: Theil’s U coefficients (U_Accuracy and U_Quality), Root Mean Square Error (RMSE) and Regression value (R-value). Obtained results show that best performance belongs to RBFNN based model and then ANFIS based model. U coefficients and RMSE values are obtained less than 0.005 and R-Value is become close to one by using RBFNN based model for testing data, which indicates high accuracy prediction performance.","",""
14,"I. Tyukin, D. Higham, A. Gorban","On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems",2020,"","","","",127,"2022-07-13 09:22:16","","10.1109/IJCNN48605.2020.9207472","","",,,,,14,7.00,5,3,2,"In this work we present a formal theoretical framework for assessing and analyzing two classes of malevolent action towards generic Artificial Intelligence (AI) systems. Our results apply to general multi-class classifiers that map from an input space into a decision space, including artificial neural networks used in deep learning applications. Two classes of attacks are considered. The first class involves adversarial examples and concerns the introduction of small perturbations of the input data that cause misclassification. The second class, introduced here for the first time and named stealth attacks, involves small perturbations to the AI system itself. Here the perturbed system produces whatever output is desired by the attacker on a specific small data set, perhaps even a single input, but performs as normal on a validation set (which is unknown to the attacker).We show that in both cases, i.e., in the case of an attack based on adversarial examples and in the case of a stealth attack, the dimensionality of the AI’s decision-making space is a major contributor to the AI’s susceptibility. For attacks based on adversarial examples, a second crucial parameter is the absence of local concentrations in the data probability distribution, a property known as Smeared Absolute Continuity. According to our findings, robustness to adversarial examples requires either (a) the data distributions in the AI’s feature space to have concentrated probability density functions or (b) the dimensionality of the AI’s decision variables to be sufficiently small. We also show how to construct stealth attacks on high-dimensional AI systems that are hard to spot unless the validation set is made exponentially large.","",""
14,"Claudia Gonzalez Viejo, S. Fuentes","Beer Aroma and Quality Traits Assessment Using Artificial Intelligence",2020,"","","","",128,"2022-07-13 09:22:16","","10.3390/fermentation6020056","","",,,,,14,7.00,7,2,2,"Increasing beer quality demands from consumers have put pressure on brewers to target specific steps within the beer-making process to modify beer styles and quality traits. However, this demands more robust methodologies to assess the final aroma profiles and physicochemical characteristics of beers. This research shows the construction of artificial intelligence (AI) models based on aroma profiles, chemometrics, and chemical fingerprinting using near-infrared spectroscopy (NIR) obtained from 20 commercial beers used as targets. Results showed that machine learning models obtained using NIR from beers as inputs were accurate and robust in the prediction of six important aromas for beer (Model 1; R = 0.91; b = 0.87) and chemometrics (Model 2; R = 0.93; b = 0.90). Additionally, two more accurate models were obtained from robotics (RoboBEER) to obtain the same aroma profiles (Model 3; R = 0.99; b = 1.00) and chemometrics (Model 4; R = 0.98; b = 1.00). Low-cost robotics and sensors coupled with computer vision and machine learning modeling could help brewers in the decision-making process to target specific consumer preferences and to secure higher consumer demands.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",129,"2022-07-13 09:22:16","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",130,"2022-07-13 09:22:16","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
13,"Mohammad Rasheed Khan, Zeeshan Tariq, A. Abdulraheem","Application of Artificial Intelligence to Estimate Oil Flow Rate in Gas-Lift Wells",2020,"","","","",131,"2022-07-13 09:22:16","","10.1007/s11053-020-09675-7","","",,,,,13,6.50,4,3,2,"","",""
12,"M. Pedersen, K. Verspoor, M. Jenkinson, M. Law, D. Abbott, G. Jackson","Artificial intelligence for clinical decision support in neurology",2020,"","","","",132,"2022-07-13 09:22:16","","10.1093/braincomms/fcaa096","","",,,,,12,6.00,2,6,2,"Abstract Artificial intelligence is one of the most exciting methodological shifts in our era. It holds the potential to transform healthcare as we know it, to a system where humans and machines work together to provide better treatment for our patients. It is now clear that cutting edge artificial intelligence models in conjunction with high-quality clinical data will lead to improved prognostic and diagnostic models in neurological disease, facilitating expert-level clinical decision tools across healthcare settings. Despite the clinical promise of artificial intelligence, machine and deep-learning algorithms are not a one-size-fits-all solution for all types of clinical data and questions. In this article, we provide an overview of the core concepts of artificial intelligence, particularly contemporary deep-learning methods, to give clinician and neuroscience researchers an appreciation of how artificial intelligence can be harnessed to support clinical decisions. We clarify and emphasize the data quality and the human expertise needed to build robust clinical artificial intelligence models in neurology. As artificial intelligence is a rapidly evolving field, we take the opportunity to iterate important ethical principles to guide the field of medicine is it moves into an artificial intelligence enhanced future.","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",133,"2022-07-13 09:22:16","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",134,"2022-07-13 09:22:16","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",135,"2022-07-13 09:22:16","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",136,"2022-07-13 09:22:16","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",137,"2022-07-13 09:22:16","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"S. Goto, K. Mahara, L. Beussink-Nelson, H. Ikura, Y. Katsumata, J. Endo, H. Gaggin, S. J. Shah, Y. Itabashi, C. Macrae, R. Deo","Artificial Intelligence-Enabled, Fully Automated Detection of Cardiac Amyloidosis Using Electrocardiograms and Echocardiograms.",2020,"","","","",138,"2022-07-13 09:22:16","","10.1101/2020.07.02.20141028","","",,,,,11,5.50,1,11,2,"Although individually uncommon, rare diseases collectively affect over 350 million patients worldwide and are increasingly the target of therapeutic development efforts. Unfortunately, the pursuit and use of such therapies have been hindered by a common challenge: patients with specific rare diseases are difficult to identify, especially if the conditions resemble more prevalent disorders. Cardiac amyloidosis is one such rare disease, which is characterized by deposition of misfolded proteins within the heart muscle resulting in heart failure and death. In recent years, specific therapies have emerged for cardiac amyloidosis and several more are under investigation, but because cardiac amyloidosis is mistaken for common forms of heart failure, it is typically diagnosed late in its course. As a possible solution, artificial intelligence methods could enable automated detection of rare diseases, but model performance must address low disease prevalence. Here we present an automated multi-modality pipeline for cardiac amyloidosis detection using two neural-network models; one using electrocardiograms (ECG) and the second using echocardiographic videos as input. These models were trained and validated on 3 and 5 academic medical centers (AMC), respectively, in the United States and Japan. Both models had excellent accuracy for detecting cardiac amyloidosis with C-statistics of 0.85-0.92 and 0.91-1.00 for the ECG and echocardiography models, respectively, with the latter outperforming expert diagnosis. Simulating deployment on 13,906 and 7775 patients with ECG-echocardiography paired data for AMC2 and AMC3 indicated a positive predictive value (PPV) for the ECG model of 4% and 3% at 61% and 54% recall, respectively. Pre-screening with ECG enhanced the echocardiography model performance from PPV 23% and 20% to PPV 58% and 53% at 64% recall, respectively for AMC2 and AMC3. In conclusion, we have developed a robust pipeline to augment detection of cardiac amyloidosis, which should serve as a generalizable strategy for other rare and intermediate frequency cardiac diseases with established or emerging therapies.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",139,"2022-07-13 09:22:16","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
9,"R. Haneef, M. Delnord, M. Vernay, E. Bauchet, R. Gaidelytė, H. Van Oyen, Z. Or, B. Pérez-Gómez, L. Palmieri, P. Achterberg, M. Tijhuis, M. Zaletel, S. Mathis-Edenhofer, O. Májek, H. Haaheim, H. Tolonen, A. Gallay","Innovative use of data sources: a cross-sectional study of data linkage and artificial intelligence practices across European countries",2020,"","","","",140,"2022-07-13 09:22:16","","10.1186/s13690-020-00436-9","","",,,,,9,4.50,1,17,2,"","",""
9,"A. Olabi, A. Nassef, C. Rodriguez, M. Abdelkareem, Hegazy Rezk","Application of artificial intelligence to maximize methane production from waste paper",2020,"","","","",141,"2022-07-13 09:22:16","","10.1002/er.5446","","",,,,,9,4.50,2,5,2,"This article proposes a methodology based on artificial intelligence to enhance methane production from waste paper. The proposed methodology combines fuzzy logic‐based modelling and modern optimization. Firstly, a robust Adaptive Network‐based Fuzzy Inference System model of methane production process through fuzzy logic modelling is created using experimental datasets. Second, a particle swarm optimizer was used to obtain the optimal process conditions. During the optimization procedure, the beating time and feedstock/inoculum ratio are employed as decision variables in order to maximize methane production. The obtained resulted from the proposed methodology are compared with those obtained by response surface methodology. The results of the comparison confirmed the superiority of the proposed methodology. The fuzzy model shows a better fitting to the experimental data compared to ANOVA. The fuzzy model showed a higher coefficient of determination and a lower value of root mean squared errors compared to ANOVA. Moreover, the proposed strategy, that is, modelling and optimization, is an effective method for increasing the biomethane yield at extended range conditions.","",""
8,"Dimitri Grün, F. Rudolph, Nils Gumpfer, J. Hannig, L. Elsner, B. Jeinsen, C. Hamm, A. Rieth, Michael Guckert, T. Keller","Identifying Heart Failure in ECG Data With Artificial Intelligence—A Meta-Analysis",2021,"","","","",142,"2022-07-13 09:22:16","","10.3389/fdgth.2020.584555","","",,,,,8,8.00,1,10,1,"Introduction: Electrocardiography (ECG) is a quick and easily accessible method for diagnosis and screening of cardiovascular diseases including heart failure (HF). Artificial intelligence (AI) can be used for semi-automated ECG analysis. The aim of this evaluation was to provide an overview of AI use in HF detection from ECG signals and to perform a meta-analysis of available studies. Methods and Results: An independent comprehensive search of the PubMed and Google Scholar database was conducted for articles dealing with the ability of AI to predict HF based on ECG signals. Only original articles published in peer-reviewed journals were considered. A total of five reports including 57,027 patients and 579,134 ECG datasets were identified including two sets of patient-level data and three with ECG-based datasets. The AI-processed ECG data yielded areas under the receiver operator characteristics curves between 0.92 and 0.99 to identify HF with higher values in ECG-based datasets. Applying a random-effects model, an sROC of 0.987 was calculated. Using the contingency tables led to diagnostic odds ratios ranging from 3.44 [95% confidence interval (CI) = 3.12–3.76] to 13.61 (95% CI = 13.14–14.08) also with lower values in patient-level datasets. The meta-analysis diagnostic odds ratio was 7.59 (95% CI = 5.85–9.34). Conclusions: The present meta-analysis confirms the ability of AI to predict HF from standard 12-lead ECG signals underlining the potential of such an approach. The observed overestimation of the diagnostic ability in artificial ECG databases compared to patient-level data stipulate the need for robust prospective studies.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",143,"2022-07-13 09:22:16","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",144,"2022-07-13 09:22:16","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",145,"2022-07-13 09:22:16","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
8,"S. Romero-Brufau, Kirk D. Wyatt, Patricia Boyum, Mindy Mickelson, Matthew Moore, Cheristi Cognetta-Rieke","Implementation of Artificial Intelligence-Based Clinical Decision Support to Reduce Hospital Readmissions at a Regional Hospital",2020,"","","","",146,"2022-07-13 09:22:16","","10.1055/s-0040-1715827","","",,,,,8,4.00,1,6,2,"BACKGROUND  Hospital readmissions are a key quality metric, which has been tied to reimbursement. One strategy to reduce readmissions is to direct resources to patients at the highest risk of readmission. This strategy necessitates a robust predictive model coupled with effective, patient-centered interventions.   OBJECTIVE  The aim of this study was to reduce unplanned hospital readmissions through the use of artificial intelligence-based clinical decision support.   METHODS  A commercially vended artificial intelligence tool was implemented at a regional hospital in La Crosse, Wisconsin between November 2018 and April 2019. The tool assessed all patients admitted to general care units for risk of readmission and generated recommendations for interventions intended to decrease readmission risk. Similar hospitals were used as controls. Change in readmission rate was assessed by comparing the 6-month intervention period to the same months of the previous calendar year in exposure and control hospitals.   RESULTS  Among 2,460 hospitalizations assessed using the tool, 611 were designated by the tool as high risk. Sensitivity and specificity for risk assignment were 65% and 89%, respectively. Over 6 months following implementation, readmission rates decreased from 11.4% during the comparison period to 8.1% (p < 0.001). After accounting for the 0.5% decrease in readmission rates (from 9.3 to 8.8%) at control hospitals, the relative reduction in readmission rate was 25% (p < 0.001). Among patients designated as high risk, the number needed to treat to avoid one readmission was 11.   CONCLUSION  We observed a decrease in hospital readmission after implementing artificial intelligence-based clinical decision support. Our experience suggests that use of artificial intelligence to identify patients at the highest risk for readmission can reduce quality gaps when coupled with patient-centered interventions.","",""
8,"R. Deo, Z. Yaseen, N. Al‐Ansari, Thong Nguyen-Huy, Trevor Ashley Mcpherson Langlands, Linda Galligan","Modern Artificial Intelligence Model Development for Undergraduate Student Performance Prediction: An Investigation on Engineering Mathematics Courses",2020,"","","","",147,"2022-07-13 09:22:16","","10.1109/access.2020.3010938","","",,,,,8,4.00,1,6,2,"A computationally efficient artificial intelligence (AI) model called Extreme Learning Machines (ELM) is adopted to analyze patterns embedded in continuous assessment to model the weighted score (WS) and the examination (EX) score in engineering mathematics courses at an Australian regional university. The student performance data taken over a six-year period in multiple courses ranging from the mid- to the advanced level and a diverse course offering mode (i.e., on-campus, ONC, and online, ONL) are modelled by ELM and further benchmarked against competing models: random forest (RF) and Volterra. With the assessments and examination marks as key predictors of WS (leading to a grade in the mid-level course), ELM (with respect to RF and Volterra) outperformed its counterpart models both for the ONC and the ONL offer. This generated relative prediction error in the testing phase, of only 0.74%, compared to about 3.12% and 1.06%, respectively, while for the ONL offer, the prediction errors were only 0.51% compared to about 3.05% and 0.70%. In modelling the student performance in advanced engineering mathematics course, ELM registered slightly larger errors: 0.77% (vs. 22.23% and 1.87%) for ONC and 0.54% (vs. 4.08% and 1.31%) for the ONL offer. This study advocates a pioneer implementation of a robust AI methodology to uncover relationships among student learning variables, developing teaching and learning intervention and course health checks to address issues related to graduate outcomes, and student learning attributes in the higher education sector.","",""
7,"S. Harmon, Palak G Patel, T. Sanford, Isabelle Caven, Rachael Iseman, T. Vidotto, C. Picanço, J. Squire, Samira Masoudi, Sherif Mehralivand, P. Choyke, D. Berman, B. Turkbey, T. Jamaspishvili","High throughput assessment of biomarkers in tissue microarrays using artificial intelligence: PTEN loss as a proof-of-principle in multi-center prostate cancer cohorts",2020,"","","","",148,"2022-07-13 09:22:16","","10.1038/s41379-020-00674-w","","",,,,,7,3.50,1,14,2,"","",""
8,"J. Kwon, Kyung-Hee Kim, K. Jeon, Soo Youn Lee, Jinsik Park, B. Oh","Artificial intelligence algorithm for predicting cardiac arrest using electrocardiography",2020,"","","","",149,"2022-07-13 09:22:16","","10.1186/s13049-020-00791-0","","",,,,,8,4.00,1,6,2,"","",""
8,"John T. O’Brien, Cassidy Nelson","Assessing the Risks Posed by the Convergence of Artificial Intelligence and Biotechnology.",2020,"","","","",150,"2022-07-13 09:22:16","","10.1089/hs.2019.0122","","",,,,,8,4.00,4,2,2,"Rapid developments are currently taking place in the fields of artificial intelligence (AI) and biotechnology, and applications arising from the convergence of these 2 fields are likely to offer immense opportunities that could greatly benefit human health and biosecurity. The combination of AI and biotechnology could potentially lead to breakthroughs in precision medicine, improved biosurveillance, and discovery of novel medical countermeasures as well as facilitate a more effective public health emergency response. However, as is the case with many preceding transformative technologies, new opportunities often present new risks in parallel. Understanding the current and emerging risks at the intersection of AI and biotechnology is crucial for health security specialists and unlikely to be achieved by examining either field in isolation. Uncertainties multiply as technologies merge, showcasing the need to identify robust assessment frameworks that could adequately analyze the risk landscape emerging at the convergence of these 2 domains.This paper explores the criteria needed to assess risks associated with Artificial intelligence and biotechnology and evaluates 3 previously published risk assessment frameworks. After highlighting their strengths and limitations and applying to relevant Artificial intelligence and biotechnology examples, the authors suggest a hybrid framework with recommendations for future approaches to risk assessment for convergent technologies.","",""
6,"S. Gulati, A. Emmanuel, Mehul V. Patel, Sophie Williams, A. Haji, B. Hayee, H. Neumann","Artificial intelligence in luminal endoscopy",2020,"","","","",151,"2022-07-13 09:22:16","","10.1177/2631774520935220","","",,,,,6,3.00,1,7,2,"Artificial intelligence is a strong focus of interest for global health development. Diagnostic endoscopy is an attractive substrate for artificial intelligence with a real potential to improve patient care through standardisation of endoscopic diagnosis and to serve as an adjunct to enhanced imaging diagnosis. The possibility to amass large data to refine algorithms makes adoption of artificial intelligence into global practice a potential reality. Initial studies in luminal endoscopy involve machine learning and are retrospective. Improvement in diagnostic performance is appreciable through the adoption of deep learning. Research foci in the upper gastrointestinal tract include the diagnosis of neoplasia, including Barrett’s, squamous cell and gastric where prospective and real-time artificial intelligence studies have been completed demonstrating a benefit of artificial intelligence–augmented endoscopy. Deep learning applied to small bowel capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. Prospective evaluation including the first randomised trial has been performed in the colon, demonstrating improved polyp and adenoma detection rates; however, these appear to be relevant to small polyps. There are potential additional roles of artificial intelligence relevant to improving the quality of endoscopic examinations, training and triaging of referrals. Further large-scale, multicentre and cross-platform validation studies are required for the robust incorporation of artificial intelligence–augmented diagnostic luminal endoscopy into our routine clinical practice.","",""
6,"N. Gahungu, Robert Trueick, S. Bhat, P. Sengupta, G. Dwivedi","Current Challenges and Recent Updates in Artificial Intelligence and Echocardiography",2020,"","","","",152,"2022-07-13 09:22:16","","10.1007/s12410-020-9529-x","","",,,,,6,3.00,1,5,2,"","",""
6,"N. Elkin-Koren","Contesting algorithms: Restoring the public interest in content filtering by artificial intelligence",2020,"","","","",153,"2022-07-13 09:22:16","","10.1177/2053951720932296","","",,,,,6,3.00,6,1,2,"In recent years, artificial intelligence has been deployed by online platforms to prevent the upload of allegedly illegal content or to remove unwarranted expressions. These systems are trained to spot objectionable content and to remove it, block it, or filter it out before it is even uploaded. Artificial intelligence filters offer a robust approach to content moderation which is shaping the public sphere. This dramatic shift in norm setting and law enforcement is potentially game-changing for democracy. Artificial intelligence filters carry censorial power, which could bypass traditional checks and balances secured by law. Their opaque and dynamic nature creates barriers to oversight, and conceals critical value choices and tradeoffs. Currently, we lack adequate tools to hold them accountable. This paper seeks to address this gap by introducing an adversarial procedure— – Contesting Algorithms. It proposes to deliberately introduce friction into the dominant removal systems governed by artificial intelligence. Algorithmic content moderation often seeks to optimize a single goal, such as removing copyright-infringing materials or blocking hate speech, while other values in the public interest, such as fair use or free speech, are often neglected. Contesting algorithms introduce an adversarial design which reflects conflicting values, and thereby may offer a check on dominant removal systems. Facilitating an adversarial intervention may promote democratic principles by keeping society in the loop. An adversarial public artificial intelligence system could enhance dynamic transparency, facilitate an alternative public articulation of social values using machine learning systems, and restore societal power to deliberate and determine social tradeoffs.","",""
6,"Jonathan Roberge, Marius Senneville, Kevin Morin","How to translate artificial intelligence? Myths and justifications in public discourse",2020,"","","","",154,"2022-07-13 09:22:16","","10.1177/2053951720919968","","",,,,,6,3.00,2,3,2,"Automated technologies populating today’s online world rely on social expectations about how “smart” they appear to be. Algorithmic processing, as well as bias and missteps in the course of their development, all come to shape a cultural realm that in turn determines what they come to be about. It is our contention that a robust analytical frame could be derived from culturally driven Science and Technology Studies while focusing on Callon’s concept of translation. Excitement and apprehensions must find a specific language to move past a state of latency. Translations are thus contextual and highly performative, transforming justifications into legitimate claims, translators into discursive entrepreneurs, and power relations into new forms of governance and governmentality. In this piece, we discuss three cases in which artificial intelligence was deciphered to the public: (i) the Montreal Declaration for a Responsible Development of Artificial Intelligence, held as a prime example of how stakeholders manage to establish the terms of the debate on ethical artificial intelligence while avoiding substantive commitment; (ii) Mark Zuckerberg’s 2018 congressional hearing, where he construed machine learning as the solution to the many problems the platform might encounter; and (iii) the normative renegotiations surrounding the gradual introduction of “killer robots” in military engagements. Of interest are not only the rational arguments put forward, but also the rhetorical maneuvers deployed. Through the examination of the ramifications of these translations, we intend to show how they are constructed in face of and in relation to forms of criticisms, thus revealing the highly cybernetic deployment of artificial intelligence technologies.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",155,"2022-07-13 09:22:16","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",156,"2022-07-13 09:22:16","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
2,"Neha Mohanta, R. Singh, Anuj Kumar Sharma","Online Monitoring System for Tool Wear and Fault Prediction Using Artificial Intelligence",2020,"","","","",157,"2022-07-13 09:22:16","","10.1109/IC3A48958.2020.233319","","",,,,,2,1.00,1,3,2,"With the advancement of technology and rise in the concept of intelligent machining, it is important to monitor the process in the real-time. Cutting Tool is one of the key element in the machining process. Cutting Tool wear is known to influence device life, surface quality and creation time. Due to this, an online device wears estimation and observing framework has been developed. This paper presents a robust method for the tool wear prediction using Artificial Intelligence. MATLAB programming is utilized as the stage programming to build up an easy to understand graphical UI (GUI) for real-time monitoring. The proposed methodology had a forecast accuracy of 95.7%, which might be considered as substantial and valid for Tool wear Monitoring","",""
4,"Mahbub Hossain, E. McKyer, P. Ma","Applications of artificial intelligence technologies on mental health research during COVID-19",2020,"","","","",158,"2022-07-13 09:22:16","","10.31235/osf.io/w6c9b","","",,,,,4,2.00,1,3,2,"The coronavirus disease (COVID-19) pandemic has impacted mental health globally. It is essential to deploy advanced research methodologies that may use complex data to draw meaningful inferences facilitating mental health research and policymaking during this pandemic. Artificial intelligence (AI) technologies offer a wide range of opportunities to leverage advancements in data sciences in analyzing health records, behavioral data, social media contents, and outcomes data on mental health. Several studies have reported the use of several AI technologies such as vector machines, neural networks, latent Dirichlet allocation, decision trees, and clustering to detect and treat depression, schizophrenia, Alzheimer’s disease, and other mental health problems. The applications of such technologies in the context of COVID-19 is still under development, which calls for further deployment of AI technologies in mental health research in this pandemic using clinical and psychosocial data through technological partnerships and collaborations. Lastly, policy-level commitment and deployment of resources to facilitate the use of robust AI technologies for assessing and addressing mental health problems during the COVID-19 pandemic.","",""
4,"S. Hoffman, Andy Podgurski","Artificial Intelligence and Discrimination in Health Care",2020,"","","","",159,"2022-07-13 09:22:16","","","","",,,,,4,2.00,2,2,2,"Artificial intelligence (AI) holds great promise for improved health-care outcomes. It has been used to analyze tumor images, to help doctors choose among different treatment options, and to combat the COVID-19 pandemic. But AI also poses new hazards. This Article focuses on a particular type of health-care harm that has thus far evaded significant legal scrutiny. The harm is algorithmic discrimination.    Algorithmic discrimination in healthcare occurs with surprising frequency. A well-known example is an algorithm used to identify candidates for “high risk care management” programs that routinely failed to refer racial minorities for these beneficial services. Some algorithms deliberately adjust for race in ways that hurt minority patients. For example, such algorithms have regularly underestimated African Americans’ risks of kidney stones, death from heart failure, and other medical problems.    The Article argues that algorithmic discrimination in medicine can violate civil rights laws such as Title VI and Section 1557 of the Affordable Care Act when it exacerbates health disparities or perpetuates inequities. It urges that algorithmic fairness constitute a key element in designing, validating, and implementing AI and that both legal and technical tools be deployed to promote fairness. To that end, we call for the reintroduction of the disparate impact theory as a robust litigation tool in the health-care arena and for the passage of an algorithmic accountability act. We also detail technical measures that AI developers and users should implement.","",""
3,"J. Banja","Obviously You, Maybe You, Artificial You: Exploring the Impact of Artificial Intelligence Technologies on Consciousness and Personal Identity",2020,"","","","",160,"2022-07-13 09:22:16","","10.1080/21507740.2020.1740349","","",,,,,3,1.50,3,1,2,"In the acknowledgements section of her 2019 book Artificial You, Susan Schneider relates that “This book was a delight to write.” (Schneider 2019, 153) It shows. The book is a delight to read. Artificial You is relatively short and, thankfully, without a lot of neurophilosophical jargon. Its primary objective is to present a multi-faceted exploration of how artificial intelligence (AI) and its related technologies might challenge our understanding of consciousness and our moral attitudes toward nonhumans, maybe-humans, and post humans. The first chapters of Schneider’s book explore what it would mean for an AI model to be conscious. Schneider’s initial response is the familiar: Consciousness means “it feels like something to be you.” (16) I’ve always found that characterization too obscure. Consider the robust conversation around whether slime molds are conscious (Skiles 2019). Slime molds don’t possess anything resembling the molecular constitution of neurons and neural networks, but they exhibit astonishingly intelligent-like, acutely adaptive responses to their environments. Whether they are conscious is baffling on two counts: It seems doubtful that they have a feeling of being aware, so they have no awareness of what it’s like to be them. But even if they did, how could humans know it? And if we could know it, what ethical platforms would we use to assess whether that awareness would be morally significant? Some microbiologists claim that slime molds have rudimentary consciousness while a “feeling like something to be you” implies a self-awareness that only certain higher vertebrates possess. My graduate days spent studying Husserl led me to understand consciousness as awareness of something, whose sophistication or acuity exists on a continuum—from a slime mold’s awareness of nutrients in its biomolecular environments to the exhausting self-awareness of a Kierkegaard or Henry James. But leaving the matter of “feeling like something to be you” unanswered allows Schneider a certain latitude in exploring the intersection of AI or advanced technologies with human cognition and identity. Thus, she asks early in the book: If humans choose to enhance themselves with advanced hardware like brain microchips that can dramatically improve memory or thinking, is there a point at which the accumulation of those enhancements would fracture our sense of identity and transcend our “humanness”? This problem is especially interesting if we consider the transhumanist aspiration of uploading one’s consciousness onto a computer. Schneider makes the provocative observation that a human consciousness previously subserved by human neurons but now uploaded into a computer whose mechanical substrate consists of transistorized parts no longer seems a human consciousness. When I upload my consciousness to a computer, what does consciousness “become”? Furthermore, if an essential aspect of human consciousness is my awareness of myself, especially understanding (or feeling) myself as patterns of neural events that enable and integrate memory, behaviors, cognitions and the like, then transmogrifying those neurological patterns into entirely new, artificial ones that a computer can run casts enormous doubt on whether they have retained their essential “humanness.” Again, when I upload my consciousness to a computer, what does it become? Do I remain me? Does it matter? Schneider argues that it certainly does matter as nothing short of the deepest moral questions humanity can pose to itself are at stake. Of course, a computer can be programed to relate what it feels like to be it. But how would we evaluate the moral status of a sophisticated, future AI whose cognitive and","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",161,"2022-07-13 09:22:16","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
2,"Hanguen Kim, Donghoon Kim, B. Park, Seung-Mok Lee","Artificial Intelligence Vision-Based Monitoring System for Ship Berthing",2020,"","","","",162,"2022-07-13 09:22:16","","10.1109/ACCESS.2020.3045487","","",,,,,2,1.00,1,4,2,"This paper proposes a novel artificial intelligence vision-based monitoring system (AVMS) for ship berthing. To dock a ship, it is necessary to accurately estimate the relative distance between the quay wall and the ship. However, maneuvering large ships near a port is a complicated and difficult procedure. Thus, tugboats push the ship and dock it at the berth under the supervision of a pilot, who receives distance information from a berthing aid system (BAS). The conventional BAS based on laser distance sensors, which is the most widely used approach, is high-priced and limited by the size of the ship. Additionally, if there is an obstacle between the ship and the berth, the distance cannot be measured, since it obscures the laser signal. To address this problem, we develop an AVMS sensor module composed of a low-priced camera, a differential global positioning system (DGPS) receiver, and an inertial measurement unit (IMU) with an algorithm to estimate the distance between ship and berth. To evaluate the performance of the proposed AVMS, field tests are performed at Ulsan port in Korea, and the results are compared with a conventional BAS. From the field test results, the AVMS provides highly accurate estimates and shows robust performance in poor weather conditions compared to the conventional BAS. The AVMS can measure the distance between ship and berth regardless of the size of the ship, since it has a wide field of view. In addition, it provides the pilot with real-time image information of the ship approaching the berth to obtain safe ship berthing.","",""
5,"M. Iqbal, Md. Faiz Iqbal Faiz","Active Surveillance for COVID-19 Through Artificial Intelligence Using Real-Time Speech-Recognition Mobile Application",2020,"","","","",163,"2022-07-13 09:22:16","","10.1109/ICCE-Taiwan49838.2020.9258276","","",,,,,5,2.50,3,2,2,"We propose a novel model of active surveillance for COVID-19 through artificial intelligence. Both past and recent events of viral disease outbreaks have shown us that we do not have effective methods to screen the whole population, and efforts are failing to stop the pandemics. Moreover, at this stage, social distancing and home quarantine are only measures to prevent the spread of COVID-19 infection. The purpose of our project is to introduce a robust method of using speech-recognition techniques through a mobile application in analyzing cough sounds of suspected people who previously were healthy, suffering from a respiratory ailment, and actively monitor the progress of their symptoms in real-time.","",""
2,"Sara Aqab, Muhammad Usman","Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing",2020,"","","","",164,"2022-07-13 09:22:16","","10.14569/ijacsa.2020.0110719","","",,,,,2,1.00,1,2,2,"Due to increased usage of digital technologies in all sectors and in almost all day to day activities to store and pass information, Handwriting character recognition has become a popular subject of research. Handwriting remains relevant, but people still want to have Handwriting copies converted into electronic copies that can be communicated and stored electronically. Handwriting character recognition refers to the computer's ability to detect and interpret intelligible Handwriting input from Handwriting sources such as touch screens, photographs, paper documents, and other sources. Handwriting characters remain complex since different individuals have different handwriting styles. This paper aims to report the development of a Handwriting character recognition system that will be used to read students and lectures Handwriting notes. The development is based on an artificial neural network, which is a field of study in artificial intelligence. Different techniques and methods are used to develop a Handwriting character recognition system. However, few of them focus on neural networks. The use of neural networks for recognizing Handwriting characters is more efficient and robust compared with other computing techniques. The paper also outlines the methodology, design, and architecture of the Handwriting character recognition system and testing and results of the system development. The aim is to demonstrate the effectiveness of neural networks for Handwriting character recognition.","",""
1,"Alicia Lai","Artificial Intelligence, LLC: Corporate Personhood as Tort Reform",2020,"","","","",165,"2022-07-13 09:22:16","","10.2139/ssrn.3677360","","",,,,,1,0.50,1,1,2,"Our legal system has long tried to fit the square peg of artificial intelligence (AI) technologies into the round hole of the current tort regime, overlooking the inability of traditional liability schemes to address the nuances of how AI technology creates harms. The current tort regime deals out rough justice—using strict liability for some AI products and using the negligence rule for other AI services—both of which are insufficiently tailored to achieve public policy objectives.    Under a strict liability regime where manufacturers are always held liable for the faults of their technology regardless of knowledge or precautionary measures, firms are incentivized to play it safe and stifle innovation. But even with this cautionary stance, the goals of strict liability cannot be met due to the unique nature of AI technology: its mistakes are merely “efficient errors”—they appropriately surpass the human baseline, they are game theory problems intended for a jury, they are necessary to train a robust system, or they are harmless but misclassified.    Under a negligence liability regime where the onus falls entirely on consumers to prove the element of causation, victimized consumers are left without sufficient recourse or compensation. Many critiques have been leveled against the “black-box” nature of algorithms.    This paper proposes a new framework to regulate artificial intelligence technologies: bestowing corporate personhood to AI systems. First, the corporate personality trait of “limited liability” strikes an optimal balance in determining liability—it would both compensate victims (for instance, through obligations to carry insurance and a straightforward burden of causation) while holding manufacturers responsible only when the infraction is egregious (for instance, through veil-piercing). Second, corporate personhood is “divisible”—meaning not all corporate personality traits need to be granted—which circumvents many of the philosophical criticisms of giving AI the complete set of rights of full legal personhood.","",""
1,"C. Siristatidis, A. Pouliakis","Flaws (and quality) in research today: can artificial intelligence intervene?",2020,"","","","",166,"2022-07-13 09:22:16","","10.1080/19396368.2020.1749727","","",,,,,1,0.50,1,2,2,"ABSTRACT The existing flaws in both conducting and reporting of research have been outlined and criticized in the past. Weak research design, poor methodology, lack of fresh ideas and poor reporting are the main points to blame. Issues have been continually raised on the types of results published, review process, sponsorship, notion, ethics, and incentives in publishing, the role of regulatory agencies and stakeholders, the role of funding, and the cooperation between funders and academic institutions and the training of both clinicians and methodologists or statisticians. As a result, there is loss of the utmost goal: the production of robust research to form recommendations to support pragmatic decision in a real-world context. We propose the construction of a model based on artificial intelligence that could assist stakeholders, clinicians, and patients to guide conducting the best quality of research. We briefly describe the levels of the workflow, including the input and output data collection, the feature extraction/selection, the architecture, and parameterization of the model, along with its training, operation, and refinement.","",""
1,"Hao Wang, Zhi-yuan Wang, Bendong Wang, Zhuo-qun Yu, Zhong-he Jin, J. Crassidis","An artificial intelligence enhanced star identification algorithm",2020,"","","","",167,"2022-07-13 09:22:16","","10.1631/FITEE.1900590","","",,,,,1,0.50,0,6,2,"An artificial intelligence enhanced star identification algorithm is proposed for star trackers in lost-in-space mode. A convolutional neural network model based on Vgg16 is used in the artificial intelligence algorithm to classify star images. The training dataset is constructed to achieve the networks’ optimal performance. Simulation results show that the proposed algorithm is highly robust to many kinds of noise, including position noise, magnitude noise, false stars, and the tracker’s angular velocity. With a deep convolutional neural network, the identification accuracy is maintained at 96% despite noise and interruptions, which is a significant improvement to traditional pyramid and grid algorithms.","",""
1,"M. N. N. Lima, Joyce V. B. Borba, G. C. Cassiano, M. Mottin, S. S. Mendonça, Arthur C. Silva, K. C. P. Tomaz, Juliana Calit, D. Bargieri, F. T. M. Costa, C. Andrade","Artificial Intelligence Applied to the Rapid Identification of New Antimalarial Candidates with Dual‐Stage Activity",2020,"","","","",168,"2022-07-13 09:22:16","","10.1002/cmdc.202000685","","",,,,,1,0.50,0,11,2,"Increasing reports of multidrug‐resistant malaria parasites urge the discovery of new effective drugs with different chemical scaffolds. Protein kinases play a key role in many cellular processes such as signal transduction and cell division, making them interesting targets in many diseases. Protein kinase 7 (PK7) is an orphan kinase from the Plasmodium genus, essential for the sporogonic cycle of these parasites. Here, we applied a robust and integrative artificial intelligence‐assisted virtual‐screening (VS) approach using shape‐based and machine learning models to identify new potential PK7 inhibitors with in vitro antiplasmodial activity. Eight virtual hits were experimentally evaluated, and compound LabMol‐167 inhibited ookinete conversion of Plasmodium berghei and blood stages of Plasmodium falciparum at nanomolar concentrations with low cytotoxicity in mammalian cells. As PK7 does not have an essential role in the Plasmodium blood stage and our virtual screening strategy aimed for both PK7 and blood‐stage inhibition, we conducted an in silico target fishing approach and propose that this compound might also inhibit P. falciparum PK5, acting as a possible dual‐target inhibitor. Finally, docking studies of LabMol‐167 with P. falciparum PK7 and PK5 proteins highlighted key interactions for further hit‐to lead optimization.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",169,"2022-07-13 09:22:16","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
0,"J. Eckroth","Evolution of a Robust Artificial Intelligence System: A Case Study of the Association for the Advancement of Artificial Intelligence’s AI-Alert",2020,"","","","",170,"2022-07-13 09:22:16","","","","",,,,,0,0.00,0,1,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 WINTER 2020 17 Robust artificial intelligence (AI) systems deployed in practice develop incrementally, from careful specification, development, experimentation, and refinement, to programs that are useful and used. The Association for the Advancement of Artificial Intelligence (AAAI)’s AI-Alert service is one such system read by thousands of AI students, faculty, and practicing professionals. The alert is received by about 12,000 subscribers each Tuesday and includes ten news stories about AI. Figure 1 shows part of a recent alert. AI-Alert is sponsored by AAAI and implemented and maintained by i2k Connect, Inc. Stories that make up the alert are pulled from AITopics.org, which is populated by an automated system. AITopics is a repository and advanced search engine for AI-related news, as well as conference, journal, and preprint articles, and classic texts. AITopics was founded more than twenty years ago and has undergone significant evolution in this time. Today, content is automatically acquired, enriched with metadata including topics and concept tags (keywords), and indexed on AITopics, resulting in about 150 to 250 new documents added to the site each day. These documents are mostly news stories from specific sources such as BBC and The New York Times, as well as stories posted on the #artificialintelligence Twitter hashtag (about 200,000 stories combined), but also include articles from AAAI conference publications (about 40,000 articles), AI Magazine (about 5,000  Since mid-2018, we have used a suite of artificial intelligence (AI) technologies to automatically generate the Association for the Advancement of Artificial Intelligence’s AI-Alert, a weekly email sent to all Association for the Advancement of Artificial Intelligence members and thousands of other subscribers. This alert contains ten news stories from around the web that focus on some aspect of AI, such as new AI inventions, AI’s use in various industries, and AI’s impacts in our daily lives. This alert was curated by-hand for a decade before we developed AI technology for automation, which we call “NewsFinder.” Recently, we redesigned this automation and ran a six-month experiment on user engagement to ensure the new approach was successful. This article documents our design considerations and requirements, our implementation (which involves web crawling, document classification, and a genetic algorithm for story selection), and our reflections after a year and a half since deploying this technology. Evolution of a Robust Artificial Intelligence System: A Case Study of the Association for the Advancement of Artificial Intelligence’s AI-Alert","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",171,"2022-07-13 09:22:16","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",172,"2022-07-13 09:22:16","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
16,"A. Arabameri, S. Saha, Kaustuv Mukherjee, T. Blaschke, Wei Chen, P. T. Ngo, S. Band","Modeling Spatial Flood using Novel Ensemble Artificial Intelligence Approaches in Northern Iran",2020,"","","","",173,"2022-07-13 09:22:16","","10.3390/rs12203423","","",,,,,16,8.00,2,7,2,"The uncertainty of flash flood makes them highly difficult to predict through conventional models. The physical hydrologic models of flash flood prediction of any large area is very difficult to compute as it requires lot of data and time. Therefore remote sensing data based models (from statistical to machine learning) have become highly popular due to open data access and lesser prediction times. There is a continuous effort to improve the prediction accuracy of these models through introducing new methods. This study is focused on flash flood modeling through novel hybrid machine learning models, which can improve the prediction accuracy. The hybrid machine learning ensemble approaches that combine the three meta-classifiers (Real AdaBoost, Random Subspace, and MultiBoosting) with J48 (a tree-based algorithm that can be used to evaluate the behavior of the attribute vector for any defined number of instances) were used in the Gorganroud River Basin of Iran to assess flood susceptibility (FS). A total of 426 flood positions as dependent variables and a total of 14 flood conditioning factors (FCFs) as independent variables were used to model the FS. Several threshold-dependent and independent statistical tests were applied to verify the performance and predictive capability of these machine learning models, such as the receiver operating characteristic (ROC) curve of the success rate curve (SRC) and prediction rate curve (PRC), efficiency (E), root-mean square-error (RMSE), and true skill statistics (TSS). The valuation of the FCFs was done using AdaBoost, frequency ratio (FR), and Boosted Regression Tree (BRT) models. In the flooding of the study area, altitude, land use/land cover (LU/LC), distance to stream, normalized differential vegetation index (NDVI), and rainfall played important roles. The Random Subspace J48 (RSJ48) ensemble method with an area under the curve (AUC) of 0.931 (SRC), 0.951 (PRC), E of 0.89, sensitivity of 0.87, and TSS of 0.78, has become the most effective ensemble in predicting the FS. The FR technique also showed good performance and reliability for all models. Map removal sensitivity analysis (MRSA) revealed that the FS maps have the highest sensitivity to elevation. Based on the findings of the validation methods, the FS maps prepared using the machine learning ensemble techniques have high robustness and can be used to advise flood management initiatives in flood-prone areas.","",""
199,"Dong Wook Kim, H. Jang, K. Kim, Youngbin Shin, S. Park","Design Characteristics of Studies Reporting the Performance of Artificial Intelligence Algorithms for Diagnostic Analysis of Medical Images: Results from Recently Published Papers",2019,"","","","",174,"2022-07-13 09:22:16","","10.3348/kjr.2019.0025","","",,,,,199,66.33,40,5,3,"Objective To evaluate the design characteristics of studies that evaluated the performance of artificial intelligence (AI) algorithms for the diagnostic analysis of medical images. Materials and Methods PubMed MEDLINE and Embase databases were searched to identify original research articles published between January 1, 2018 and August 17, 2018 that investigated the performance of AI algorithms that analyze medical images to provide diagnostic decisions. Eligible articles were evaluated to determine 1) whether the study used external validation rather than internal validation, and in case of external validation, whether the data for validation were collected, 2) with diagnostic cohort design instead of diagnostic case-control design, 3) from multiple institutions, and 4) in a prospective manner. These are fundamental methodologic features recommended for clinical validation of AI performance in real-world practice. The studies that fulfilled the above criteria were identified. We classified the publishing journals into medical vs. non-medical journal groups. Then, the results were compared between medical and non-medical journals. Results Of 516 eligible published studies, only 6% (31 studies) performed external validation. None of the 31 studies adopted all three design features: diagnostic cohort design, the inclusion of multiple institutions, and prospective data collection for external validation. No significant difference was found between medical and non-medical journals. Conclusion Nearly all of the studies published in the study period that evaluated the performance of AI algorithms for diagnostic analysis of medical images were designed as proof-of-concept technical feasibility studies and did not have the design features that are recommended for robust validation of the real-world clinical performance of AI algorithms.","",""
9,"E. Natsheh","Hybrid Power Systems Energy Management Based on Artificial Intelligence",2020,"","","","",175,"2022-07-13 09:22:16","","","","",,,,,9,4.50,9,1,2,"This thesis presents a novel adaptive scheme for energy management in stand-alone hybrid power systems. The proposed management system is designed to manage the power flow between the hybrid power system and energy storage elements in order to satisfy the load requirements based on artificial neural network (ANN) and fuzzy logic controllers.   The neural network controller is employed to achieve the maximum power point (MPP) for different types of photovoltaic (PV) panels, based on Levenberg Marquardt learning algorithm. The statistical analysis of the results indicates that the R2 value for the testing set was 0.99.   The advance fuzzy logic controller is developed to distribute the power among the hybrid system and to manage the charge and discharge current flow for performance optimization.  The developed management system performance was assessed using a hybrid system comprises PV panels, wind turbine, battery storage, and proton exchange membrane fuel cell (PEMFC). To improve the generating performance of the PEMFC and prolong its life, stack temperature is controlled by a fuzzy logic controller.  Moreover, perturb and observe (P&O) algorithm with two different controller techniques - the linear PI and the non-linear passivity-based controller (PBC) - are provided for a comparison with the proposed MPPT controller system. The comparison revealed the robustness of the proposed PV control system for solar irradiance and load resistance changes.  Real-time measured parameters and practical load profiles are used as inputs for the developed management system. The proposed model and its control strategy offer a proper tool for optimizing the hybrid power system performance, such as the one used in smart-house applications.  The research work also led to a new approach in monitoring PV power stations. The monitoring system enables system degradation early detection by calculating the residual difference between the model predicted and the actual measured power parameters. Measurements were taken over 21 month’s period; using hourly average irradiance and cell temperature. Good agreement was achieved between the theoretical simulation and the real time measurement taken the online grid connected solar power plant.","",""
13,"M. Ghasemi, A. Nassef, M. Al-Dhaifallah, Hegazy Rezk","Performance improvement of microbial fuel cell through artificial intelligence",2020,"","","","",176,"2022-07-13 09:22:16","","10.1002/er.5484","","",,,,,13,6.50,3,4,2,"The current work introduces an enhancement in the performance of the microbial fuel cell through estimating the optimal set of controlling parameters. The maximization of both power density (PD) and the percentage of chemical oxygen demand (COD) removal were considered as the enhancement in the cell's performance. Three main parameters in terms of performance as well as commercialization are the system's inputs; the Pt which takes the range of 0.1‐0.5 mg/cm2, the degree of sulphonation in sulfonated‐poly‐ether‐ether‐ketone that changes in the range of 20‐80%, and the rate of aeration of cathode which varies between 10 and 150 mL/min. From the experimental dataset, two robust adaptive neuro‐fuzzy inference system models based on the fuzzy logic technique have been constructed. The comparisons between the models' outputs and the experimental data showed well‐fitting in both training and testing datasets. The mean squared errors of the PD model, for testing and whole datasets, were found 2.575 and 0.909 while for the COD model it showed 19.242 and 6.791, respectively. Then, based on the two fuzzy models, a Particle Swarm Optimization algorithm has been used to determine the best parameters that maximize both of the PD and the COD removal of the cell. The optimization process was utilized for single and multi‐object optimization processes. In the single optimization, the resulting maximums of the PD and the COD removal were found 62.844 (mW/m2) and 99.99 (%), respectively. Whereas, in the multi‐object optimization, the values of 61.787 (mW/m2) and 96.21 (%) were reached as the maximums for the PD and COD, respectively. This implies that, in both cases of optimization processes, the adopted methodology can efficiently enhance the microbial fuel cell performances than the previous work.","",""
66,"Keping Yu, Zhiwei Guo, Yulian Shen, Wei Wang, Jerry Chun‐wei Lin, Takuro Sato","Secure Artificial Intelligence of Things for Implicit Group Recommendations",2021,"","","","",177,"2022-07-13 09:22:16","","10.1109/JIOT.2021.3079574","","",,,,,66,66.00,11,6,1,"The emergence of Artificial Intelligence of Things (AIoT) has provided novel insights for many social computing applications, such as group recommender systems. As the distances between people have been greatly shortened, there has been more general demand for the provision of personalized services aimed at groups instead of individuals. The existing methods for capturing group-level preference features from individuals have mostly been established via aggregation and face two challenges: 1) secure data management workflows are absent and 2) implicit preference feedback is ignored. To tackle these current difficulties, this article proposes secure AIoT for implicit group recommendations (SAIoT-GRs). For the hardware module, a secure Internet of Things structure is developed as the bottom support platform. For the software module, a collaborative Bayesian network model and noncooperative game are introduced as algorithms. This secure AIoT architecture is able to maximize the advantages of the two modules. In addition, a large number of experiments are carried out to evaluate the performance of SAIoT-GR in terms of efficiency and robustness.","",""
10,"T. Kleynhans, Catherine M. Schmidt Patterson, K. Dooley, D. Messinger, J. Delaney","An alternative approach to mapping pigments in paintings with hyperspectral reflectance image cubes using artificial intelligence",2020,"","","","",178,"2022-07-13 09:22:16","","10.1186/s40494-020-00427-7","","",,,,,10,5.00,2,5,2,"","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",179,"2022-07-13 09:22:16","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",180,"2022-07-13 09:22:16","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",181,"2022-07-13 09:22:16","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
132,"Y. Yang, C. S. Bang","Application of artificial intelligence in gastroenterology",2019,"","","","",182,"2022-07-13 09:22:16","","10.3748/wjg.v25.i14.1666","","",,,,,132,44.00,66,2,3,"Artificial intelligence (AI) using deep-learning (DL) has emerged as a breakthrough computer technology. By the era of big data, the accumulation of an enormous number of digital images and medical records drove the need for the utilization of AI to efficiently deal with these data, which have become fundamental resources for a machine to learn by itself. Among several DL models, the convolutional neural network showed outstanding performance in image analysis. In the field of gastroenterology, physicians handle large amounts of clinical data and various kinds of image devices such as endoscopy and ultrasound. AI has been applied in gastroenterology in terms of diagnosis, prognosis, and image analysis. However, potential inherent selection bias cannot be excluded in the form of retrospective study. Because overfitting and spectrum bias (class imbalance) have the possibility of overestimating the accuracy, external validation using unused datasets for model development, collected in a way that minimizes the spectrum bias, is mandatory. For robust verification, prospective studies with adequate inclusion/exclusion criteria, which represent the target populations, are needed. DL has its own lack of interpretability. Because interpretability is important in that it can provide safety measures, help to detect bias, and create social acceptance, further investigations should be performed.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",183,"2022-07-13 09:22:16","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",184,"2022-07-13 09:22:16","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",185,"2022-07-13 09:22:16","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",186,"2022-07-13 09:22:16","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",187,"2022-07-13 09:22:16","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
51,"Lu Minh Le, H. Ly, B. Pham, Vuong Minh Le, T. Pham, Duy-Hung Nguyen, Xuan-Tuan Tran, Tien-Thinh Le","Hybrid Artificial Intelligence Approaches for Predicting Buckling Damage of Steel Columns Under Axial Compression",2019,"","","","",188,"2022-07-13 09:22:16","","10.3390/ma12101670","","",,,,,51,17.00,6,8,3,"This study aims to investigate the prediction of critical buckling load of steel columns using two hybrid Artificial Intelligence (AI) models such as Adaptive Neuro-Fuzzy Inference System optimized by Genetic Algorithm (ANFIS-GA) and Adaptive Neuro-Fuzzy Inference System optimized by Particle Swarm Optimization (ANFIS-PSO). For this purpose, a total number of 57 experimental buckling tests of novel high strength steel Y-section columns were collected from the available literature to generate the dataset for training and validating the two proposed AI models. Quality assessment criteria such as coefficient of determination (R2), Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) were used to validate and evaluate the performance of the prediction models. Results showed that both ANFIS-GA and ANFIS-PSO had a strong ability in predicting the buckling load of steel columns, but ANFIS-PSO (R2 = 0.929, RMSE = 60.522 and MAE = 44.044) was slightly better than ANFIS-GA (R2 = 0.916, RMSE = 65.371 and MAE = 48.588). The two models were also robust even with the presence of input variability, as investigated via Monte Carlo simulations. This study showed that the hybrid AI techniques could help constructing an efficient numerical tool for buckling analysis.","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",189,"2022-07-13 09:22:16","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
2,"Sunny Raj","Towards Robust Artificial Intelligence Systems",2020,"","","","",190,"2022-07-13 09:22:16","","","","",,,,,2,1.00,2,1,2,"Adoption of deep neural networks (DNNs) into safety-critical and high-assurance systems has been hindered by the inability of DNNs to handle adversarial and out-of-distribution input. State-ofthe-art DNNs misclassify adversarial input and give high confidence output for out-of-distribution input. We attempt to solve this problem by employing two approaches, first, by detecting adversarial input and, second, by developing a confidence metric that can indicate when a DNN system has reached its limits and is not performing to the desired specifications. The effectiveness of our method at detecting adversarial input is demonstrated against the popular DeepFool adversarial image generation method. On a benchmark of 50,000 randomly chosen ImageNet adversarial images generated for CaffeNet and GoogLeNet DNNs, our method can recover the correct label with 95.76% and 97.43% accuracy, respectively. The proposed attribution-based confidence (ABC) metric utilizes attributions used to explain DNN output to characterize whether an output corresponding to an input to the DNN can be trusted. The attribution based approach removes the need to store training or test data or to train an ensemble of models to obtain confidence scores. Hence, the ABC metric can be used when only the trained DNN is available during inference. We test the effectiveness of the ABC metric against both adversarial and out-of-distribution input. We experimental demonstrate that the ABC metric is high for ImageNet input and low for adversarial input generated by FGSM, PGD, DeepFool, CW, and adversarial patch methods. For a DNN trained on MNIST images, ABC metric is high for in-distribution MNIST input and low for out-of-distribution Fashion-MNIST and notMNIST input.","",""
3,"Dercilio Junior Verly Lopes, G. S. Bobadilha, Karl Michael Grebner","A fast and robust artificial intelligence technique for wood knot detection",2020,"","","","",191,"2022-07-13 09:22:16","","10.15376/BIORES.15.4.9351-9361","","",,,,,3,1.50,1,3,2,"This study reports the feasibility of using deep convolutional neural networks (CNN), for automatically detecting knots on the surface of wood with high speed and accuracy. A limited dataset of 921 images were photographed in different contexts and divided into 80:20 ratio for training and validation, respectively. The “You only look once” (YoloV3) CNN-based architecture was adopted for training the neural network. The Adam gradient descent optimizer algorithm was used to iteratively minimize the generalized intersection-over-union loss function. Knots on the surface of wood were manually annotated. Images and annotations were analyzed by a stack of convolutional and fully connected layers with skipped connections. After training, model checkpoint was created and inferences on the validation set were made. The quality of results was assessed by several metrics: precision, recall, F1-score, average precision, and precision x recall curve. Results indicated that YoloV3 provided knot detection time of approximately 0.0102 s per knot with a relatively low false positive and false negative ratios. Precision, recall, f1-score metrics reached 0.77, 0.79, and 0.78, respectively. The average precision was 80%. With an adequate number of images, it is possible to improve this tool for use within sawmills in the forms of both workstation and mobile device applications.","",""
4,"Surabhi Kaul, Yogesh Kumar","Artificial Intelligence-based Learning Techniques for Diabetes Prediction: Challenges and Systematic Review",2020,"","","","",192,"2022-07-13 09:22:16","","10.1007/s42979-020-00337-2","","",,,,,4,2.00,2,2,2,"","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",193,"2022-07-13 09:22:16","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
47,"Chengjie Zheng, T. V. Johnson, Aakriti Garg, Michael V. Boland","Artificial intelligence in glaucoma",2019,"","","","",194,"2022-07-13 09:22:16","","10.1097/ICU.0000000000000552","","",,,,,47,15.67,12,4,3,"Purpose of review The use of computers has become increasingly relevant to medical decision-making, and artificial intelligence methods have recently demonstrated significant advances in medicine. We therefore provide an overview of current artificial intelligence methods and their applications, to help the practicing ophthalmologist understand their potential impact on glaucoma care. Recent findings Techniques used in artificial intelligence can successfully analyze and categorize data from visual fields, optic nerve structure [e.g., optical coherence tomography (OCT) and fundus photography], ocular biomechanical properties, and a combination thereof to identify disease severity, determine disease progression, and/or recommend referral for specialized care. Algorithms have become increasingly complex in recent years, utilizing both supervised and unsupervised methods of artificial intelligence. Impressive performance of these algorithms on previously unseen data has been reported, often outperforming standard global indices and expert observers. However, there remains no clearly defined gold standard for determining the presence and severity of glaucoma, which undermines the training of these algorithms. To improve upon existing methodologies, future work must employ more robust definitions of disease, optimize data inputs for artificial intelligence analysis, and improve methods of extracting knowledge from learned results. Summary Artificial intelligence has the potential to revolutionize the screening, diagnosis, and classification of glaucoma, both through the automated processing of large data sets, and by earlier detection of new disease patterns. In addition, artificial intelligence holds promise for fundamentally changing research aimed at understanding the development, progression, and treatment of glaucoma, by identifying novel risk factors and by evaluating the importance of existing ones.","",""
47,"T. Phong, Trong Trinh Phan, Indra Prakash, S. Singh, A. Shirzadi, K. Chapi, H. Ly, Lanh Si Ho, Nguyen Kim Quoc, B. Pham","Landslide susceptibility modeling using different artificial intelligence methods: a case study at Muong Lay district, Vietnam",2019,"","","","",195,"2022-07-13 09:22:16","","10.1080/10106049.2019.1665715","","",,,,,47,15.67,5,10,3,"Abstract Landslide is a natural hazard which causes huge loss of properties and human life in many places of the world. Mapping of landslide susceptibility is an important task for preventing and combating the landslides problems. Main objective of this study is to use different artificial intelligence methods namely support vector machines (SVM), artificial neural networks (ANN), logistic regression (LR), and reduced error-pruning tree (REPT) in the development of models for landslide susceptibility mapping of Muong Lay district of Vietnam. In total data of 217 landslide locations of the study area was used for the development and evaluation of the models. Nine landslide-conditioning factors were used for generating the datasets for training and validating the models. Results show that the SVM outperformed all other methods namely ANN, LR and REPT. Thus, it can be suggested that the SVM method is more useful in developing accurate and robust landslide prediction model.","",""
28,"Paul P. Momtaz","CEO  emotions and firm valuation in initial coin offerings: An artificial emotional intelligence approach",2020,"","","","",196,"2022-07-13 09:22:16","","10.1002/SMJ.3235","","",,,,,28,14.00,28,1,2,"CEO emotions are difficult to measure and hence empirically understudied. However, using artificial emotional intelligence, positive and negative affects can be identified from facial muscle contraction-relaxation patterns obtained from public CEO photos during initial coin offerings (ICOs), i.e., blockchain-based issuances of cryptocurrency tokens to raise growth capital. The results suggest that CEO affects impact firm valuation in two ways. First, CEOs’ own firm valuations conform more to those of industry peers if negative affects are pronounced (conformity mechanism). Second, investors use CEO affects as signals about firm value and discount when negative affects are salient (signaling mechanism). Negative affects can reduce firm value by up to 15%. Both mechanisms are stronger in the presence of asymmetric information and robust to tests of endogeneity.","",""
41,"C. Macrae","Governing the safety of artificial intelligence in healthcare",2019,"","","","",197,"2022-07-13 09:22:16","","10.1136/bmjqs-2019-009484","","",,,,,41,13.67,41,1,3,"Artificial intelligence (AI) has enormous potential to improve the safety of healthcare, from increasing diagnostic accuracy,1 to optimising treatment planning,2 to forecasting outcomes of care.3 However, integrating AI technologies into the delivery of healthcare is likely to introduce a range of new risks and amplify existing ones. For instance, failures in widely used software have the potential to quickly affect large numbers of patients4; hidden assumptions in underlying data and models can lead to AI systems delivering dangerous recommendations that are insensitive to local care processes,5 6 and opaque AI techniques such as deep learning can make explaining and learning from failure extremely difficult.7 8 To maximise the benefits of AI in healthcare and to build trust among patients and practitioners, it will therefore be essential to robustly govern the risks that AI poses to patient safety.  In a recent review in this journal, Challen and colleagues present an important and timely analysis of some of the key technological risks associated with the application of machine learning in clinical settings.9 Machine learning is a subfield of AI that focuses on the development of algorithms that are automatically derived and optimised through exposure to large quantities of exemplar ‘training’ data.10 The outputs of machine learning algorithms are essentially classifications of patterns that provide some sort of prediction—for instance, predicting whether an image shows a malignant melanoma or a benign mole.11 Some of the basic techniques of machine learning have existed for half a century or more, but progress in the field has accelerated rapidly due to advances in the development of ‘deep’ artificial neural networks12 combined with huge increases in computational power and the availability of enormous quantities of data. These techniques have underpinned recent public demonstrations of AI systems …","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",198,"2022-07-13 09:22:16","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
35,"J. Shapey, Guotai Wang, R. Dorent, A. Dimitriadis, Wenqi Li, I. Paddick, N. Kitchen, S. Bisdas, S. Saeed, S. Ourselin, R. Bradford, Tom Kamiel Magda Vercauteren","An artificial intelligence framework for automatic segmentation and volumetry of vestibular schwannomas from contrast-enhanced T1-weighted and high-resolution T2-weighted MRI.",2019,"","","","",199,"2022-07-13 09:22:16","","10.3171/2019.9.JNS191949","","",,,,,35,11.67,4,12,3,"OBJECTIVE Automatic segmentation of vestibular schwannomas (VSs) from MRI could significantly improve clinical workflow and assist in patient management. Accurate tumor segmentation and volumetric measurements provide the best indicators to detect subtle VS growth, but current techniques are labor intensive and dedicated software is not readily available within the clinical setting. The authors aim to develop a novel artificial intelligence (AI) framework to be embedded in the clinical routine for automatic delineation and volumetry of VS.   METHODS Imaging data (contrast-enhanced T1-weighted [ceT1] and high-resolution T2-weighted [hrT2] MR images) from all patients meeting the study's inclusion/exclusion criteria who had a single sporadic VS treated with Gamma Knife stereotactic radiosurgery were used to create a model. The authors developed a novel AI framework based on a 2.5D convolutional neural network (CNN) to exploit the different in-plane and through-plane resolutions encountered in standard clinical imaging protocols. They used a computational attention module to enable the CNN to focus on the small VS target and propose a supervision on the attention map for more accurate segmentation. The manually segmented target tumor volume (also tested for interobserver variability) was used as the ground truth for training and evaluation of the CNN. We quantitatively measured the Dice score, average symmetric surface distance (ASSD), and relative volume error (RVE) of the automatic segmentation results in comparison to manual segmentations to assess the model's accuracy.   RESULTS Imaging data from all eligible patients (n = 243) were randomly split into 3 nonoverlapping groups for training (n = 177), hyperparameter tuning (n = 20), and testing (n = 46). Dice, ASSD, and RVE scores were measured on the testing set for the respective input data types as follows: ceT1 93.43%, 0.203 mm, 6.96%; hrT2 88.25%, 0.416 mm, 9.77%; combined ceT1/hrT2 93.68%, 0.199 mm, 7.03%. Given a margin of 5% for the Dice score, the automated method was shown to achieve statistically equivalent performance in comparison to an annotator using ceT1 images alone (p = 4e-13) and combined ceT1/hrT2 images (p = 7e-18) as inputs.   CONCLUSIONS The authors developed a robust AI framework for automatically delineating and calculating VS tumor volume and have achieved excellent results, equivalent to those achieved by an independent human annotator. This promising AI technology has the potential to improve the management of patients with VS and potentially other brain tumors.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",200,"2022-07-13 09:22:16","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
